{
    "summary": "The code consists of functions for importing content, generating prompts and summaries using database data, error handling, and date extraction. It also features a retry decorator and utilizes SentenceTransformer model to filter notes based on tags and categories similarity indices. The code processes text content by removing bad words, creating/removing directories, fixing date formats, and gets titles from content. It parses command line arguments, sets default values, and outputs to the final directory after processing notes.",
    "details": [
        {
            "comment": "Code imports various modules and functions from other files for the purpose of processing content, removing unwanted notes, generating prompts, parsing dates, and manipulating file directories. The code seems to involve a complex set of operations that work together to achieve its intended functionality.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":0-43",
            "content": "import argparse\nimport shutil\nimport sys\nfrom sentence_transformers import SentenceTransformer\nimport traceback\nfrom remove_headline_from_markdown import (\n    remove_headline_from_lines,\n    join_lines_with_state,\n    NEWLINE,\n)\nsys.path.append(\n    \"/media/root/Toshiba XG3/works/prometheous/document_agi_computer_control\"\n)\nimport datetime\nimport inspect\nimport os\nimport re\nimport uuid\nfrom functools import lru_cache\nfrom typing import Callable, Iterable, Optional, TypeVar, Union\nimport pydantic\nfrom beartype import beartype\nfrom cache_db_context import (  # type:ignore\n    SourceIteratorAndTargetGeneratorParam,\n    TargetGeneratorParameter,\n    iterate_source_dir_and_generate_to_target_dir,\n)\nfrom custom_doc_writer import (  # type:ignore\n    assemble_prompt_components,\n    llm_context,\n    process_content_and_return_result,\n    assemble_prompt_components,\n)\nfrom dateparser_utils import (\n    parse_date_with_multiple_formats,\n    render_datetime_as_hexo_format,\n    CUSTOM_DATE_FORMATS,\n)\nfrom headline_match import (\n    modify_content_metadata,"
        },
        {
            "comment": "This code defines functions to process and generate markdown files. It includes functions for splitting and joining lines, generating a markdown file name, loading bad words from a file, and possibly handling the file content schema based on need.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":44-83",
            "content": "    parse_content_metadata,\n    JSONDict,\n    purify_dict,\n)\nfrom similarity_utils import SimilarityIndex, sentence_transformer_context\nfrom io_utils import load_file, write_file\nT = TypeVar(\"T\")\nDEFAULT_TOP_K = 7\nREQUIRED_FIELDS = (\"tags\", \"title\", \"description\", \"category\", \"date\")\nFIELDS_THAT_NEED_SUMMARY_TO_GENERATE = (\"tags\", \"title\", \"description\", \"category\")\nDATE_MITIGATION_FIELDS = (\"created\", \"modified\")\ndef generate_markdown_name():\n    file_id = str(uuid.uuid4())\n    fname = f\"{file_id}.md\"\n    return fname\n@beartype\ndef split_by_line(cnt: str, newline=NEWLINE):\n    myitems = cnt.split(newline)\n    myitems = [myit.strip() for myit in myitems]\n    myitems = [myit for myit in myitems if len(myit) > 0]\n    return myitems\n@beartype\ndef join_lines(lines: list[str], newline=NEWLINE):\n    return newline.join(lines)\ndef load_bad_words(fname: str):\n    cnt = load_file(fname)\n    mybadwords = split_by_line(cnt)\n    return mybadwords\n# should change the schema according to the need, only generate what is needed the most."
        },
        {
            "comment": "This code defines a few Pydantic models, and a function call_llm_once that uses the Large Language Model (LLM) to process prompts with an optional initial prompt. The LLM is called within the context of the init_prompt, and it returns a response that can be parsed into the specified pydantic_type. There's also a retry decorator applied to the call_llm_once function which allows for retrying if needed.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":86-128",
            "content": "# if filename is not date, use as title\n# if filename is date, perform title generation\n# TODO: constraint string generation\n# validation not working. and the llm does not pay attention to the constraints by the name\n# string_without_comma_period = Annotated[str, pydantic.Field(regex=r'^[^,^.]*$')]\n# string_without_comma_period_and_space = Annotated[str, pydantic.Field(regex=r'^[^,^ ^.]*$')]\n# suspicious chars being used in string, like the comma\nclass Categories(pydantic.BaseModel):\n    categories: list[str]\nclass Tags(pydantic.BaseModel):\n    tags: list[str]\nclass Category(pydantic.BaseModel):\n    category: str\nclass Title(pydantic.BaseModel):\n    title: str\nclass Description(pydantic.BaseModel):\n    description: str\n@beartype\ndef call_llm_once(init_prompt: str, prompt: str) -> str:\n    with llm_context(init_prompt) as model:\n        ret = model.run(prompt)\n        return ret\nfrom retrying import retry\n@beartype\ndef call_llm_once_and_parse(\n    init_prompt: str, prompt: str, pydantic_type: type[T], retry_times: int = 3"
        },
        {
            "comment": "This function generates a prompt for a JSON response fixer to fix the invalid data and parsing error message, providing hints for any potential issues like quote problems or incorrect format according to the schema.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":129-150",
            "content": ") -> T:\n    def generate_fix_init_prompt():\n        identity = \"You are a professional JSON response fixer. You can fix data failed to parsed as JSON.\"\n        task = \"You will be given the data to be fixed, the error message during parsing the data and return fixed response according to the schema, and a few hints.\"\n        fix_init_prompt = generate_init_prompt_with_schema(\n            identity, task, pydantic_type\n        )\n        return fix_init_prompt\n    @beartype\n    def generate_fix_prompt(response: str, error: str):\n        prompt_context_dict = {\n            \"Invalid data to be fixed\": response,\n            \"Parsing error message\": error,\n            \"Hint\": \"Check for quote issues, like using both double quotes inslde and around the string, or invalid format according to the schema.\",\n        }\n        fix_prompt = generate_json_prompt(prompt_context_dict)\n        return fix_prompt\n    @beartype\n    def fix_invalid_response(response: str, error: str):\n        fix_init_prompt = generate_fix_init_prompt()"
        },
        {
            "comment": "The code defines a function `generate_init_prompt_with_schema` that generates an initial prompt with a Pydantic schema included. It also includes functions to generate other prompts, retry functions, and cache getsource for generating LLM calls.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":151-190",
            "content": "        fix_prompt = generate_fix_prompt(response, error)\n        fix_response = call_llm_once(fix_init_prompt, fix_prompt)\n        ret = pydantic_type.parse_raw(fix_response)  # type:ignore\n        return ret\n    @retry(stop_max_attempt_number=retry_times)\n    def try_once():\n        response = call_llm_once(init_prompt, prompt)\n        try:\n            ret = pydantic_type.parse_raw(response)  # type: ignore\n        except:\n            error = traceback.format_exc(limit=1)\n            ret = fix_invalid_response(response, error)\n        return ret\n    return try_once()\n@lru_cache(maxsize=20)\ndef cached_getsource(obj):\n    source = inspect.getsource(obj)\n    return source\n@beartype\ndef generate_init_prompt_with_schema(identity: str, task: str, pydantic_schema):\n    schema_str = cached_getsource(pydantic_schema)\n    init_prompt = f\"\"\"{identity.strip()}\n{task.strip()}\nRespond strictly in following pydantic schema:\n```python\n{schema_str.strip()}\n```\n\"\"\"\n    return init_prompt\n@beartype\ndef generate_blogger_init_prompt_with_schema(task: str, schema_class: type):"
        },
        {
            "comment": "This code defines functions that generate initial prompts for an AI model to perform tasks such as recommending descriptions, titles, or categories for a given input. The `generate_item_recommended_init_prompt` function takes the item name and schema class as parameters and returns an initial prompt for the task. The other functions use this function to generate specific prompts for recommended descriptions, titles, and categories.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":191-220",
            "content": "    identity = \"You are a professional blogger.\"\n    init_prompt = generate_init_prompt_with_schema(identity, task, schema_class)\n    return init_prompt\ndef generate_item_recommended_init_prompt(\n    item_name: str, schema_class: type[T], max_num: Optional[int] = None\n):\n    components = [\n        f\"\"\"You will be given an article summary.\nYou will produce recommended {item_name}.\"\"\",\n        f\"\"\"You can most generate {max_num} {item_name}.\"\"\" if max_num else \"\",\n    ]\n    task = assemble_prompt_components(components)\n    init_prompt = generate_blogger_init_prompt_with_schema(task, schema_class)\n    return init_prompt, schema_class\ndef generate_description_recommended_init_script():\n    return generate_item_recommended_init_prompt(\"description\", Description)\ndef generate_title_recommended_init_script():\n    return generate_item_recommended_init_prompt(\"title\", Title)\n@beartype\ndef generate_category_recommender_init_prompt(max_num: int = DEFAULT_TOP_K):\n    return generate_item_recommended_init_prompt(\n        \"categories\", Categories, max_num=max_num"
        },
        {
            "comment": "This code contains several functions for generating different types of prompts for AI models. The `generate_tag_recommender_init_prompt` function generates an init prompt for recommending tags, while the `generate_item_chooser_init_prompt` function can generate prompts for choosing items (categories or tags) based on a given summary and recommended item. The code also includes functions to generate category chooser and tag chooser prompts, as well as a function to convert prompt context from a dictionary of key-value pairs to a string.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":221-254",
            "content": "    )\n@beartype\ndef generate_tag_recommender_init_prompt(max_num: int = DEFAULT_TOP_K):\n    return generate_item_recommended_init_prompt(\"tags\", Tags, max_num=max_num)\n@beartype\ndef generate_item_chooser_init_prompt(\n    item_name: str, objective: str, schema_class: type[T]\n):\n    task = f\"\"\"You will be given an article summary, similar {item_name} in database, and your recommended {item_name}.\nYou would prefer {item_name} in database if they match the summary.\nYou will choose {objective} that best matches the summary.\"\"\"\n    init_prompt = generate_blogger_init_prompt_with_schema(task, schema_class)\n    return init_prompt, schema_class\ndef generate_category_chooser_init_prompt():\n    return generate_item_chooser_init_prompt(\n        \"categories\", \"a single category\", Category\n    )\ndef generate_tag_chooser_init_prompt():\n    return generate_item_chooser_init_prompt(\"tags\", \"tags\", Tags)\ndef generate_prompt_context_from_prompt_context_dict(\n    prompt_context_dict: dict[str, str]\n):\n    prompt_context = \"\"\n    for k, v in prompt_context_dict.items():"
        },
        {
            "comment": "The code defines several functions for generating a prompt in JSON format. The `generate_prompt_context_from_prompt_context_dict` function takes a dictionary of prompt context and returns the formatted prompt context as a string. The `generate_json_prompt` function combines the prompt context with instructions to return a JSON response. The `generate_summary_prompt_context_dict` function creates a dictionary for the summary prompt context, and the `generate_json_prompt_with_summary` function generates a JSON prompt including the summary. Finally, the `generate_similar_and_recommended_items_prompt_context_dict` function creates a dictionary for similar and recommended items in a database.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":255-289",
            "content": "        prompt_context += f\"{k.strip().title()}:\\n{v.strip()}\\n\"\n    return prompt_context.strip()\ndef generate_json_prompt(prompt_context_dict: dict[str, str]):\n    prompt_context = generate_prompt_context_from_prompt_context_dict(\n        prompt_context_dict\n    )\n    # i miss ollama json format restrictions. can i have that?\n    prompt = f\"\"\"{prompt_context}\nResponse in JSON format (curly bracket key-value pairs):\n\"\"\"\n    return prompt\ndef generate_summary_prompt_context_dict(summary: str):\n    return {\"summary\": summary}\ndef generate_json_prompt_with_summary(summary: str):\n    prompt_context_dict = generate_summary_prompt_context_dict(summary)\n    ret = generate_json_prompt(prompt_context_dict)\n    return ret\n@beartype\ndef generate_similar_and_recommended_items_prompt_context_dict(\n    items_name: str, similar_items: list[str], recommended_items: list[str]\n):\n    ret = {\n        f\"similar {items_name} in database\": str(similar_items),\n        f\"your recommended {items_name}\": str(recommended_items),\n    }\n    return ret"
        },
        {
            "comment": "These functions generate JSON prompts for item, category, and tag choosers. They create a context dictionary by combining summary prompt context and similar/recommended items prompt context. The generated JSON prompt is returned.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":292-329",
            "content": "@beartype\ndef generate_items_chooser_json_prompt(\n    items_name: str,\n    summary: str,\n    similar_items: list[str],\n    recommended_items: list[str],\n):\n    prompt_context_dict = generate_summary_prompt_context_dict(summary)\n    prompt_context_dict.update(\n        generate_similar_and_recommended_items_prompt_context_dict(\n            items_name, similar_items, recommended_items\n        )\n    )\n    ret = generate_json_prompt(prompt_context_dict)\n    return ret\n@beartype\ndef generate_categories_chooser_json_prompt(\n    summary: str, similar_categories: list[str], recommended_categories: list[str]\n):\n    items_name = \"categories\"\n    return generate_items_chooser_json_prompt(\n        items_name, summary, similar_categories, recommended_categories\n    )\n@beartype\ndef generate_tags_chooser_json_prompt(\n    summary: str, similar_tags: list[str], recommended_tags: list[str]\n):\n    items_name = \"tags\"\n    return generate_items_chooser_json_prompt(\n        items_name, summary, similar_tags, recommended_tags\n    )\n@beartype"
        },
        {
            "comment": "The code defines three functions:\n1. `generate_recommended_items` generates recommended items using the provided prompt generator and summary.\n2. `generate_chosen_item` generates a chosen item based on the given summary, recommended items, similar items, and prompt generator.\n3. `generate_recommended_categories` generates recommended categories from the provided summary using the category recommender prompt generator.\n4. `generate_chosen_category` selects a chosen category from the recommended categories and similar categories based on the provided summary.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":330-364",
            "content": "def generate_recommended_items(\n    summary: str, init_prompt_generator: Callable[[], tuple[str, type[T]]]\n) -> T:\n    init_prompt, data_class = init_prompt_generator()\n    prompt = generate_json_prompt_with_summary(summary)\n    response = call_llm_once_and_parse(init_prompt, prompt, data_class)\n    return response\n@beartype\ndef generate_chosen_item(\n    summary: str,\n    recommended_items: list[str],\n    similar_items: list[str],\n    init_prompt_generator: Callable[[], tuple[str, type[T]]],\n) -> T:\n    init_prompt, data_class = init_prompt_generator()\n    prompt = generate_categories_chooser_json_prompt(\n        summary, similar_items, recommended_items\n    )\n    response = call_llm_once_and_parse(init_prompt, prompt, data_class)\n    return response\n@beartype\ndef generate_recommended_categories(summary: str):\n    response = generate_recommended_items(\n        summary, generate_category_recommender_init_prompt\n    )\n    return response.categories\n@beartype\ndef generate_chosen_category(\n    summary: str, recommended_categories: list[str], similar_categories: list[str]"
        },
        {
            "comment": "This code defines functions for generating recommended items and tags based on a given summary. It uses an item recommender to suggest items and a similarity index to find similar items. The chosen item or tag is determined by the item chooser function.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":365-404",
            "content": "):\n    response = generate_chosen_item(\n        summary,\n        recommended_categories,\n        similar_categories,\n        generate_category_chooser_init_prompt,\n    )\n    return response.category\n@beartype\ndef generate_recommended_tags(summary: str):\n    response = generate_recommended_items(summary, generate_tag_recommender_init_prompt)\n    return response.tags\n@beartype\ndef generate_chosen_tags(\n    summary: str, recommended_tags: list[str], similar_tags: list[str]\n):\n    response = generate_chosen_item(\n        summary,\n        recommended_tags,\n        similar_tags,\n        generate_tag_chooser_init_prompt,\n    )\n    return response.tags\n@beartype\ndef generate_item(\n    items_similarity_index: SimilarityIndex,\n    summary: str,\n    item_recommender: Callable[[str], list[str]],\n    item_chooser: Callable[[str, list[str], list[str]], T],\n    top_k: int = DEFAULT_TOP_K,\n) -> T:\n    recommended_items = item_recommender(summary)\n    similar_items = items_similarity_index.search(recommended_items, top_k=top_k)\n    ret = item_chooser(summary, recommended_items, similar_items)"
        },
        {
            "comment": "The code defines five functions: `generate_category`, `generate_tags`, `generate_title`, `generate_description`, and `generate_summary_prompt_base`. These functions are decorated with `@beartype` which suggests they are related to type hinting. The functions take various input parameters like summary, top_k, etc., and return the generated results. The code also includes helper function calls within the main function definitions.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":405-455",
            "content": "    return ret\n@beartype\ndef generate_category(\n    categories_similarity_index: SimilarityIndex,\n    summary: str,\n    top_k: int = DEFAULT_TOP_K,\n):\n    ret = generate_item(\n        categories_similarity_index,\n        summary,\n        generate_recommended_categories,\n        generate_chosen_category,\n        top_k=top_k,\n    )\n    return ret\n@beartype\ndef generate_tags(\n    tags_similarity_index: SimilarityIndex, summary: str, top_k: int = DEFAULT_TOP_K\n):\n    ret = generate_item(\n        tags_similarity_index,\n        summary,\n        generate_recommended_tags,\n        generate_chosen_tags,\n        top_k=top_k,\n    )\n    return ret\n@beartype\ndef generate_title(summary: str):\n    response = generate_recommended_items(\n        summary, generate_title_recommended_init_script\n    )\n    return response.title\n@beartype\ndef generate_description(summary: str):\n    response = generate_recommended_items(\n        summary, generate_description_recommended_init_script\n    )\n    return response.description\n@beartype\ndef generate_summary_prompt_base(word_limit: int):"
        },
        {
            "comment": "Function `generate_summary` takes in a chunk of text, the programming language used, and an optional previous comment, and returns a summary of the text under the given word limit. The function calls other helper functions to generate components for the prompt, which include the content, previous comment (if provided), and then assembles them together into a final prompt for summarization.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":456-495",
            "content": "    init_prompt = f\"\"\"You are reading text from file in chunks. You would understand what the text is about and return brief summary (under {word_limit} words).\"\"\"\n    return init_prompt\n@beartype\ndef generate_previous_comment_component(previous_comment: str = \"\"):\n    comp = (\n        f\"\"\"Previous comment:\n{previous_comment}\"\"\"\n        if previous_comment.strip()\n        else \"\"\n    )\n    return comp\n@beartype\ndef generate_content_component(content: str, programming_language=\"\"):\n    comp = f\"\"\"Content:\n```{programming_language}\n{content}\n```\"\"\"\n    return comp\n@beartype\ndef generate_summary_prompt_generator(programming_language: str):\n    @beartype\n    def prompt_generator(content: str, location: str, previous_comment: str = \"\"):\n        components = [\n            generate_content_component(content, programming_language),\n            generate_previous_comment_component(previous_comment),\n        ]\n        ret = assemble_prompt_components(components)\n        return ret\n    return prompt_generator\n@beartype\ndef generate_summary("
        },
        {
            "comment": "This code contains functions for generating a summary from content, getting a file's creation date and filename without extension. The `generate_summary` function takes in content, generates a prompt based on word limit, and processes the content using a language model to return a summary. The `get_date_obj_by_file_ctime` function retrieves a file's creation timestamp and converts it into a datetime object. Lastly, the `get_filename_without_extension` function extracts the filename from a filepath and removes any file extension.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":496-530",
            "content": "    content_without_metadata: str,\n    filename: str = \"<unknown>\",\n    word_limit: int = 30,\n    programming_language=\"markdown\",\n    char_limit: int = 1000,\n    line_limit: int = 15,\n    sample_size: Optional[int] = None,\n):\n    prompt_base = generate_summary_prompt_base(word_limit)\n    prompt_generator = generate_summary_prompt_generator(programming_language)\n    with llm_context(prompt_base) as model:\n        ret = process_content_and_return_result(\n            model,\n            prompt_generator,\n            filename,\n            content_without_metadata,\n            char_limit=char_limit,\n            line_limit=line_limit,\n            sample_size=sample_size,\n        )\n        return ret[\"summary\"]\n@beartype\ndef get_date_obj_by_file_ctime(filepath: str):\n    creation_timestamp = os.path.getctime(filepath)\n    date_obj = datetime.datetime.fromtimestamp(creation_timestamp)\n    return date_obj\n@beartype\ndef get_filename_without_extension(filepath: str):\n    base_filepath = os.path.basename(filepath)\n    filename_without_extension = re.sub(r\"\\.\\w+$\", \"\", base_filepath)"
        },
        {
            "comment": "The code defines three functions:\n1. get_date_obj_by_metadata() - extracts the date from metadata dictionary.\n2. get_date_obj_by_filepath() - extracts the date from the filename of the filepath provided.\n3. generate_date_obj() - tries to extract a date using either metadata or the filepath, and if it fails, falls back to extracting it from the file's creation time.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":531-563",
            "content": "    return filename_without_extension\n@beartype\ndef get_date_obj_by_metadata(metadata: JSONDict):\n    for field in DATE_MITIGATION_FIELDS:\n        value = metadata.get(field, None)\n        date_obj = None\n        if isinstance(value, datetime.datetime):\n            date_obj = value\n        elif isinstance(value, str):\n            date_obj = parse_date_with_multiple_formats(CUSTOM_DATE_FORMATS, value)\n        if date_obj is not None:\n            return date_obj\n@beartype\ndef get_date_obj_by_filepath(filepath: str):\n    filename_without_extension = get_filename_without_extension(filepath)\n    date_obj = parse_date_with_multiple_formats(\n        CUSTOM_DATE_FORMATS, filename_without_extension\n    )\n    return date_obj\n@beartype\ndef generate_date_obj(filepath: str, metadata: JSONDict):\n    maybe_methods = (\n        lambda: get_date_obj_by_metadata(metadata),\n        lambda: get_date_obj_by_filepath(filepath),\n    )\n    fallback = lambda: get_date_obj_by_file_ctime(filepath)\n    return maybe_with_fallback(maybe_methods, fallback)"
        },
        {
            "comment": "This code defines several functions for generating content, metadata, and formatting dates. It uses type hints to specify the expected types of input parameters and returns the generated results using the Beartype decorator for type checking and error handling.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":566-605",
            "content": "@beartype\ndef generate_date(filepath: str, metadata: JSONDict):\n    date_obj = generate_date_obj(filepath, metadata)\n    ret = render_datetime_as_hexo_format(date_obj)\n    return ret\n@beartype\ndef maybe_with_fallback(\n    maybe_methods: Iterable[Callable[[], Union[T, None]]], fallback: Callable[[], T]\n) -> T:\n    for it in maybe_methods:\n        obj = it()\n        if obj is not None:\n            return obj\n    return fallback()\n@beartype\ndef replace_double_quotes_as_single_quotes(content: str):\n    return content.replace('\"', \"'\")\n@beartype\ndef generate_content_metadata(\n    filepath: str,\n    content_without_metadata: str,\n    metadata: JSONDict,\n    tags_similarity_index: SimilarityIndex,\n    categories_similarity_index: SimilarityIndex,\n    tag_top_k: int = DEFAULT_TOP_K,\n    category_top_k: int = DEFAULT_TOP_K,\n    summary_word_limit: int = 30,\n    programming_language: str = \"markdown\",\n    char_limit: int = 1000,\n    line_limit: int = 15,\n    sample_size: Optional[int] = None,\n):\n    @beartype\n    def get_additional_metadata("
        },
        {
            "comment": "The code defines a function `remove_unwanted_notes.py` that takes missing fields and field-to-method dictionary as input, retrieves additional metadata for each missing field, and returns the purified dictionary of additional metadata. It also includes a generator function for new metadata with the possibility of changing the summary text based on content without metadata, word limit, programming language, character limit, line limit, and sample size.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":606-635",
            "content": "        missing_fields: Iterable[str], field_to_method: dict[str, Callable[[], str]]\n    ):\n        additional_metadata = {}\n        for field in missing_fields:\n            additional_metadata[field] = field_to_method[field]()\n        return purify_dict(additional_metadata)\n    @beartype\n    def generate_new_metadata(additional_metadata: JSONDict):\n        changed = False\n        new_metadata = metadata.copy()\n        if additional_metadata != {}:\n            changed = True\n            new_metadata.update(additional_metadata)\n        return new_metadata, changed\n    def build_field_generation_methods_with_summary():\n        summary = generate_summary(\n            content_without_metadata,\n            word_limit=summary_word_limit,\n            programming_language=programming_language,\n            char_limit=char_limit,\n            line_limit=line_limit,\n            sample_size=sample_size,\n        )\n        summary = replace_double_quotes_as_single_quotes(summary)\n        data = {\n            \"tags\": lambda: generate_tags("
        },
        {
            "comment": "Function `remove_unwanted_notes.py` contains a function that generates metadata for a note based on its summary, and another function that finds missing fields and builds field-to-method mapping. It also has a variable containing required fields for the metadata.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":636-661",
            "content": "                tags_similarity_index, summary, top_k=tag_top_k\n            ),\n            \"title\": lambda: generate_title(summary),\n            \"description\": lambda: generate_description(summary),\n            \"category\": lambda: generate_category(\n                categories_similarity_index, summary, top_k=category_top_k\n            ),\n        }\n        return data\n    def find_missing_fields_and_build_field_to_method():\n        field_to_method = {\n            \"date\": lambda: generate_date(filepath, metadata),\n        }\n        missing_fields = [\n            field for field in REQUIRED_FIELDS if field not in metadata.keys()\n        ]\n        if set(missing_fields).intersection(FIELDS_THAT_NEED_SUMMARY_TO_GENERATE):\n            field_to_method_with_summary = build_field_generation_methods_with_summary()\n            field_to_method.update(field_to_method_with_summary)\n        return missing_fields, field_to_method\n    def get_new_metadata_and_changed_flag():\n        (\n            missing_fields,\n            field_to_method,"
        },
        {
            "comment": "Iterate through notes directory, filtering .md files.\nCheck if file contains bad words and get modified metadata with additional fields.\nStore before and after processed file for cache verification.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":662-694",
            "content": "        ) = find_missing_fields_and_build_field_to_method()\n        additional_metadata = get_additional_metadata(missing_fields, field_to_method)\n        new_metadata, changed = generate_new_metadata(additional_metadata)\n        return new_metadata, changed\n    return get_new_metadata_and_changed_flag()\n@beartype\ndef check_if_contains_bad_words(content: str, bad_words: list[str]):\n    for word in bad_words:\n        if word in content:\n            return True\n    return False\n# use two hashs for cache varification\n# store filename before and after processing\n# one before processing, one after processing\n# store processed ones to some place for cacheing\n# you need to collect existing tags and categories before processing\n# collect only from file without bad words.\ndef check_if_has_markdown_file_extension(filename: str):\n    return filename.endswith(\".md\")\ndef iterate_and_get_markdown_filepath_from_notedir(notes_dir: str):\n    for filename in os.listdir(notes_dir):\n        if check_if_has_markdown_file_extension(filename):"
        },
        {
            "comment": "This code seems to be part of a function that extracts and updates existing tags and categories for notes, while also checking if the note content contains any bad words or unwanted tags. It returns a list of note paths along with updated tag and category information. The `check_bad_words_passed` function checks whether the note content contains any bad words.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":695-728",
            "content": "            source_path = os.path.join(notes_dir, filename)\n            yield source_path\n@beartype\ndef extract_and_update_existing_tags_and_categories(\n    content: str, existing_tags: set[str], existing_categories: set[str]\n):\n    has_metadata, metadata, _, _ = parse_content_metadata(content)\n    if has_metadata:\n        update_tags_and_categories_from_metadata(\n            metadata, existing_tags, existing_categories\n        )\n@beartype\ndef get_note_paths_without_bad_words_and_existing_tags_and_categories(\n    notes_dir: str, bad_words: list[str], cache_dir: str\n):\n    note_paths: list[str] = []\n    existing_tags: set[str] = set()\n    existing_categories: set[str] = set()\n    @beartype\n    def check_bad_words_passed(content: str, check_bad_words: bool):\n        if check_bad_words:\n            passed = not check_if_contains_bad_words(content, bad_words)\n        else:\n            passed = True\n        return passed\n    @beartype\n    def append_note_path_and_update_existing_tags_and_categories(\n        content: str,"
        },
        {
            "comment": "This code is iterating over a directory of markdown files and updating existing tags and categories for each note file. If the append_and_check_bad_words flag is True, it appends the filepath to the note_paths list after checking if the content has bad words. It also extracts and updates existing tags and categories for the given content. The code then calls iterate_dir_and_update_tags_and_categories on two directories: notes_dir with append_and_check_bad_words set to True, and cache_dir with append_and_check_bad_words set to False. Finally, it returns the note_paths, existing_tags, and existing_categories. The update_tags_set_from_metadata function updates a tags_set from metadata in a JSONDict.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":729-759",
            "content": "        filepath: str,\n        append_and_check_bad_words: bool,\n    ):\n        if check_bad_words_passed(content, append_and_check_bad_words):\n            if append_and_check_bad_words:\n                note_paths.append(filepath)\n            extract_and_update_existing_tags_and_categories(\n                content, existing_tags, existing_categories\n            )\n    @beartype\n    def iterate_dir_and_update_tags_and_categoiries(\n        dirpath: str, append_and_check_bad_words: bool = True\n    ):\n        for fpath in iterate_and_get_markdown_filepath_from_notedir(dirpath):\n            content = load_file(fpath)\n            append_note_path_and_update_existing_tags_and_categories(\n                content, fpath, append_and_check_bad_words\n            )\n    iterate_dir_and_update_tags_and_categoiries(\n        notes_dir,\n    )\n    iterate_dir_and_update_tags_and_categoiries(\n        cache_dir, append_and_check_bad_words=False\n    )\n    return note_paths, existing_tags, existing_categories\ndef update_tags_set_from_metadata(metadata: JSONDict, tags_set: set[str]):"
        },
        {
            "comment": "This function takes a JSON dictionary of metadata and two sets of categories and tags. It adds the category from the metadata to the categories set if it exists, and iterates over each tag in the \"tags\" list in the metadata (if present), adding each one to the tags set.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":760-796",
            "content": "    for tag in metadata.get(\"tags\", []):\n        tags_set.add(tag)\ndef update_categories_set_from_metadata(metadata: JSONDict, categories_set: set[str]):\n    category = metadata.get(\"category\", None)\n    if category:\n        categories_set.add(category)\n@beartype\ndef update_tags_and_categories_from_metadata(\n    metadata: JSONDict, tags_set: set[str], categories_set: set[str]\n):\n    update_tags_set_from_metadata(metadata, tags_set)\n    update_categories_set_from_metadata(metadata, categories_set)\n@beartype\ndef process_note_content_with_similarity_indices(\n    content: str,\n    source_path: str,\n    tags_similarity_index: SimilarityIndex,\n    categories_similarity_index: SimilarityIndex,\n    sample_size: Optional[int] = None,\n):\n    (\n        has_metadata,\n        metadata,\n        content_without_metadata,\n        first_match,\n    ) = parse_content_metadata(content)\n    new_metadata, changed = generate_content_metadata(\n        source_path,\n        content_without_metadata,\n        metadata,\n        tags_similarity_index,"
        },
        {
            "comment": "This code defines functions for processing and writing notes with similarity indices, getting existing note info from notes directory and bad words path. It loads content from source paths, processes the content using similarity indices, writes new content to target paths, gets note paths without bad words, and retrieves existing tags and categories.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":797-833",
            "content": "        categories_similarity_index,\n        sample_size=sample_size,\n    )\n    if changed:\n        return modify_content_metadata(content, has_metadata, new_metadata, first_match)\n    return content\n@beartype\ndef process_and_write_note_with_similarity_indices(\n    source_path: str,\n    target_path: str,\n    tags_similarity_index: SimilarityIndex,\n    categories_similarity_index: SimilarityIndex,\n    sample_size: Optional[int] = None,\n):\n    content = load_file(source_path)\n    new_content = process_note_content_with_similarity_indices(\n        content,\n        source_path,\n        tags_similarity_index,\n        categories_similarity_index,\n        sample_size=sample_size,\n    )\n    write_file(target_path, new_content)\n@beartype\ndef get_existing_note_info_from_notes_dir_and_bad_words_path(\n    notes_dir: str, bad_words_path: str, cache_dir: str\n):\n    bad_words = load_bad_words(bad_words_path)\n    (\n        note_paths,\n        existing_tags,\n        existing_categories,\n    ) = get_note_paths_without_bad_words_and_existing_tags_and_categories("
        },
        {
            "comment": "1. Generates a name for the processed note file\n2. Returns the full path to the processed note file in the target directory\n3. Creates a function that processes and writes a note, using similarity indices for tags and categories (if provided)\n4. Returns a function that can be used as a source walker, yielding paths of the note files from the given list of note paths",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":834-872",
            "content": "        notes_dir, bad_words, cache_dir\n    )\n    return (note_paths, existing_tags, existing_categories)\n@beartype\ndef generate_processed_note_path(param: TargetGeneratorParameter):\n    basename = generate_markdown_name()\n    ret = os.path.join(param.target_dir_path, basename)\n    return ret\n@beartype\ndef generate_process_and_write_note_method(\n    tags_similarity_index: SimilarityIndex,\n    categories_similarity_index: SimilarityIndex,\n    sample_size: Optional[int] = None,\n):\n    @beartype\n    def process_and_write_note(\n        source_path: str,\n        target_path: str,\n    ):\n        return process_and_write_note_with_similarity_indices(\n            source_path,\n            target_path,\n            tags_similarity_index,\n            categories_similarity_index,\n            sample_size=sample_size,\n        )\n    return process_and_write_note\n@beartype\ndef generate_source_walker_from_note_paths(note_paths: list[str]):\n    def source_walker(dirpath: str):\n        for fpath in note_paths:\n            yield dirpath, fpath"
        },
        {
            "comment": "Function returns a source walker and a target file generator from given note paths, using existing tags and categories similarity indices to filter out unwanted notes.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":874-903",
            "content": "    return source_walker\n@beartype\ndef prepare_note_iterator_extra_params(\n    note_paths: list[str],\n    sent_trans_model: SentenceTransformer,\n    existing_tags: set[str],\n    existing_categories: set[str],\n    sample_size: Optional[int] = None,\n):\n    @beartype\n    def create_similarity_index_with_candidates(candidates: Iterable[str]):\n        return SimilarityIndex(sent_trans_model, candidates)\n    def get_tags_and_categories_similarity_indices():\n        tags_similarity_index = create_similarity_index_with_candidates(existing_tags)\n        categories_similarity_index = create_similarity_index_with_candidates(\n            existing_categories\n        )\n        return tags_similarity_index, categories_similarity_index\n    def generate_source_walker_and_target_file_generator():\n        (\n            tags_similarity_index,\n            categories_similarity_index,\n        ) = get_tags_and_categories_similarity_indices()\n        source_walker = generate_source_walker_from_note_paths(note_paths)\n        target_file_generator = generate_process_and_write_note_method("
        },
        {
            "comment": "This code defines a function that iterates over note paths, skips any with bad words, and writes the remaining notes to cache. The function uses a SentenceTransformer model for similarity calculations and requires additional parameters such as existing tags, categories, and sample size (optional). It also includes a nested function that prepares the source iterator and target file generator.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":904-931",
            "content": "            tags_similarity_index, categories_similarity_index, sample_size=sample_size\n        )\n        return source_walker, target_file_generator\n    return generate_source_walker_and_target_file_generator()\n@beartype\ndef iterate_note_paths_without_bad_words_and_write_to_cache(\n    param: SourceIteratorAndTargetGeneratorParam,\n    note_paths: list[str],\n    existing_tags: set[str],\n    existing_categories: set[str],\n    sample_size: Optional[int] = None,\n) -> list[str]:\n    with sentence_transformer_context() as sent_trans_model:\n        source_walker, target_file_generator = prepare_note_iterator_extra_params(\n            note_paths,\n            sent_trans_model,\n            existing_tags,\n            existing_categories,\n            sample_size=sample_size,\n        )\n        return iterate_source_dir_and_generate_to_target_dir(\n            param,\n            source_walker=source_walker,\n            target_path_generator=generate_processed_note_path,\n            target_file_geneator=target_file_generator,"
        },
        {
            "comment": "This code defines several functions related to working with note files and directories. The `walk_notes_source_dir_and_write_to_cache_dir` function walks through the source directory, excluding any file paths containing \"bad words\", and writes the valid file paths to the cache directory. The `remove_and_create_dir` function removes an existing directory if it exists, then creates a new one at the same path. The `fix_date_and_get_title_in_content` function parses content metadata from a file's content and returns the new content with fixed date format and title.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":932-972",
            "content": "            join_source_dir=False,\n        )\n@beartype\ndef walk_notes_source_dir_and_write_to_cache_dir(\n    param: SourceIteratorAndTargetGeneratorParam,\n    bad_words_path: str,\n    sample_size: Optional[int] = None,\n):\n    (\n        note_paths,\n        existing_tags,\n        existing_categories,\n    ) = get_existing_note_info_from_notes_dir_and_bad_words_path(\n        param.source_dir_path, bad_words_path, param.target_dir_path\n    )\n    return iterate_note_paths_without_bad_words_and_write_to_cache(\n        param, note_paths, existing_tags, existing_categories, sample_size=sample_size\n    )\n@beartype\ndef remove_and_create_dir(dirpath: str):\n    if os.path.exists(dirpath):\n        shutil.rmtree(dirpath)\n    os.mkdir(dirpath)\n@beartype\ndef fix_date_and_get_title_in_content(filepath: str, content: str) -> tuple[str, str]:\n    def fix_date_and_get_title():\n        (\n            has_metadata,\n            metadata,\n            _,\n            first_match,\n        ) = parse_content_metadata(content)\n        @beartype\n        def get_new_content_and_title() -> tuple[str, str]:"
        },
        {
            "comment": "This code seems to be part of a larger program that processes and formats text content. It includes functions for modifying content with metadata, processing parsed metadata, removing headlines from lines, reformat title, and fixing the date in cache and writing to final directory. The specific code snippet appears to return the new content and title after processing.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":973-1008",
            "content": "            title = metadata.get(\"title\", \"\")\n            date = generate_date(filepath, metadata)\n            metadata[\"date\"] = date\n            new_content = modify_content_metadata(\n                content, has_metadata, metadata, first_match\n            )\n            return new_content, title\n        def process_parsed_metadata():\n            title = \"\"\n            new_content = content\n            if has_metadata:\n                if metadata is not None:\n                    new_content, title = get_new_content_and_title()\n            return new_content, title\n        return process_parsed_metadata()\n    return fix_date_and_get_title()\n@beartype\ndef remove_headline_from_content(content: str, title: str):\n    lines = split_by_line(content)\n    new_lines = remove_headline_from_lines(lines, title)\n    return join_lines_with_state(new_lines)\n@beartype\ndef reformat_title(content: str, title: str):\n    return content.replace(title, title.title(), 1)\n@beartype\ndef fix_date_in_cache_and_write_to_final_dir(\n    processed_cache_paths: list[str], final_dir: str"
        },
        {
            "comment": "This code is parsing command line arguments for a program. It sets default values for the notes source directory, cache directory, final directory, database file path, bad words file path, and sample size. The parse_params function returns these values as a tuple of type SourceIteratorAndTargetGeneratorParam, string, string, and integer.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":1009-1031",
            "content": "):\n    remove_and_create_dir(final_dir)\n    for path in processed_cache_paths:\n        content = load_file(path)\n        content, title = fix_date_and_get_title_in_content(path, content)\n        content = remove_headline_from_content(content, title)\n        content = reformat_title(content, title)\n        new_path = os.path.join(final_dir, os.path.basename(path))\n        write_file(new_path, content)\n@beartype\ndef parse_params() -> tuple[SourceIteratorAndTargetGeneratorParam, str, str, int]:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--notes-source-dir\", type=str, default=\"notes\")\n    parser.add_argument(\"--cache-dir\", type=str, default=\"cache\")\n    parser.add_argument(\"--final-dir\", type=str, default=\"source/_posts\")\n    parser.add_argument(\"--db-path\", type=str, default=\"cache_db.json\")\n    parser.add_argument(\"--bad-words-path\", type=str, default=\"bad_words.txt\")\n    parser.add_argument(\"--sample-size\", type=int, default=10)\n    args = parser.parse_args()\n    param = SourceIteratorAndTargetGeneratorParam("
        },
        {
            "comment": "This code is parsing command line parameters, then walking through a source directory, processing notes and writing them to a cache directory. Finally, it fixes the date in the cache files and writes them to a final output directory.",
            "location": "\"/media/root/Prima/hexo_blog_demo/blog_template/docs/src/remove_unwanted_notes.py\":1032-1048",
            "content": "        source_dir_path=args.notes_source_dir,\n        target_dir_path=args.cache_dir,\n        db_path=args.db_path,\n    )\n    return param, args.bad_words_path, args.final_dir, args.sample_size\ndef main():\n    param, bad_words_path, final_dir, sample_size = parse_params()\n    processed_cache_paths = walk_notes_source_dir_and_write_to_cache_dir(\n        param, bad_words_path, sample_size=sample_size\n    )\n    fix_date_in_cache_and_write_to_final_dir(processed_cache_paths, final_dir)\nif __name__ == \"__main__\":\n    main()"
        }
    ]
}