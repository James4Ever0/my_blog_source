[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "James' Blog",
    "section": "",
    "text": "Hi there, I am James Brown, an independent researcher of Artificial General Intelligence.\nI made the code of this blog open sourced."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "James’ Blog",
    "section": "",
    "text": "cybergod related projects\n\n\n\n\n\n\n\nCybergod\n\n\nProjects\n\n\nClones\n\n\nGitHub\n\n\nQ-Star\n\n\nQStarLearning\n\n\nopen_qstar\n\n\n\n\nA compilation of various projects related to Cybergod, which are clones from different GitHub repositories such as Q-Star, QStarLearning, open_qstar, Video-Pre-Training, SingularGPT, GPT-4V-Act, gpt-eyes, self-operating-computer, gpt4v-browsing, CogVLM, and AppAgent. These projects aim to develop various tools and models for diverse purposes within the Cybergod framework.\n\n\n\n\n\n\nDec 25, 2023\n\n\n\n\n\n\n\n\nWaydroid installation steps\n\n\n\n\n\n\n\nWaydroid\n\n\nUbuntu\n\n\nInstallation\n\n\nNetwork issues\n\n\nFirewalld\n\n\nUfw\n\n\nWifi switch\n\n\n\n\nThis article provides step-by-step instructions for installing Waydroid on Ubuntu and offers troubleshooting tips for network issues. It explains how to enable firewalld or ufw to resolve connectivity problems, while also clarifying the difference between the wifi switch and its effect on connectivity.\n\n\n\n\n\n\nDec 21, 2023\n\n\n\n\n\n\n\n\nRAG in my mind\n\n\n\n\n\n\n\nLLMs\n\n\nImage generation\n\n\nTagging\n\n\nCategories\n\n\nEmbeddings\n\n\nSearch\n\n\nMedia Generation\n\n\n\n\nThis article explores the application of Large Language Models (LLMs) in generating various elements such as images, tags, categories, and embeddings for content. It also delves into the capabilities of these models to perform full-text and vector searches, generate query words and media, update relevance based on user preferences, and even generate new queries for content.\n\n\n\n\n\n\nDec 20, 2023\n\n\n\n\n\n\n\n\nException Phobia in Python\n\n\n\n\n\n\n\nPython\n\n\npylint\n\n\nunspecified exceptions\n\n\nerror handling\n\n\nmicroservices\n\n\nlogging\n\n\nbest practices\n\n\n\n\nThis text provides guidance on utilizing the Python utility ‘pylint’ to identify unspecified exceptions in a Python file and proposes constructing microservices and tracking failures for enhanced error management.\n\n\n\n\n\n\nDec 18, 2023\n\n\n\n\n\n\n\n\nRX580 16g used as AI accelerator\n\n\n\n\n\n\n\nRX580\n\n\n16g\n\n\nAI accelerator\n\n\ngfx803\n\n\nGitHub\n\n\nDIY build\n\n\nGraphics card\n\n\n\n\nThis article discusses the process of using an RX580 16g graphics card with the codename `gfx803` as an AI accelerator. The user is provided with a GitHub link to build it themselves.\n\n\n\n\n\n\nDec 9, 2023\n\n\n\n\n\n\n\n\nHow to fix OpenCL platform not found issue on android\n\n\n\n\n\n\n\nAndroid\n\n\nOpenCL\n\n\nOneplus Ace2V\n\n\nLLama.cpp\n\n\nLD_LIBRARY_PATH\n\n\nEnvironment Variables\n\n\nSolution\n\n\n\n\nThis article provides a solution to the OpenCL platform not found issue on Android when running llama.cpp on Oneplus Ace2V by instructing users to set the LD_LIBRARY_PATH environment variable.\n\n\n\n\n\n\nDec 9, 2023\n\n\n\n\n\n\n\n\nHow to create cybergod\n\n\n\n\n\n\n\nAI\n\n\nAgent\n\n\nLearning\n\n\nHistorical Data\n\n\nPrediction\n\n\nWorld Model\n\n\nSuperagents\n\n\n\n\nThis article delves into the creation of an advanced AI agent that utilizes historical data for learning and forecasting future events to earn rewards. Additionally, the agent interacts with a world model to prevent cheating and establishes a hierarchy of superagents.\n\n\n\n\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\nCreating Cybergod: A Digital Entity to Continue Your Legacy\n\n\n\n\n\n\n\ncybergod\n\n\ndigital entity\n\n\nauthor continuity\n\n\nfraud protection\n\n\nmemories inheritance\n\n\nresources inheritance\n\n\ntechnology\n\n\n\n\nThe author proposes the concept of Cybergod, a digital entity designed to continue their existence and provide protection against fraud and uncertainties. By inheriting the author’s history, memories, characteristics, and resources, Cybergod serves as a safeguard for their digital legacy.\n\n\n\n\n\n\nDec 5, 2023\n\n\n\n\n\n\n\n\nHuggingface Mirror Sites\n\n\n\n\n\n\n\nHuggingface\n\n\nmirror sites\n\n\nnetwork issues\n\n\nhf-mirror.com\n\n\naliendao.cn\n\n\nsolutions\n\n\ndata accessibility\n\n\n\n\nThis article discusses the use of Huggingface mirror sites to resolve network issues. It provides information on full and partial mirror site options, including https://hf-mirror.com/ for a complete mirror and https://aliendao.cn/#/ for a partial mirror.\n\n\n\n\n\n\nDec 3, 2023\n\n\n\n\n\n\n\n\nSeek for cooperation and solution sharing\n\n\n\n\n\n\n\nautomotive\n\n\ncomputer research\n\n\nautomation projects\n\n\nhardware control\n\n\nmachine learning algorithms\n\n\ndatasets\n\n\nrobotics\n\n\nbrowser-based playgrounds\n\n\nAI documentation\n\n\nsemantic search\n\n\n\n\nThis article explores the latest developments in automotive computer research and automation projects. It delves into various aspects such as hardware control, machine learning algorithms, datasets, robotics, browser-based playgrounds, AI documentation, and semantic search, providing insights into how these technologies are advancing the field of automotive computing.\n\n\n\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\nModify chrome/chromium policies from snap store\n\n\n\n\n\n\n\nchrome\n\n\nchromium\n\n\nsnap\n\n\npolicies\n\n\ndirectories\n\n\nmodification\n\n\nmanagement\n\n\n\n\nThis article provides a step-by-step guide on how to modify Chrome and Chromium policies from the Snap Store by accessing specific directories: `/var/snap/chromium/current/policies/` for Chrome and `/var/snap/chromium/current/policies/managed/` for Chromium.\n\n\n\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\nHide magisk\n\n\n\n\n\n\n\nMagisk\n\n\nUpdating\n\n\nShizuku\n\n\nThird-party app\n\n\nAndroid apps\n\n\nSystem applications\n\n\nWhitelist mode\n\n\n\n\nThis article provides step-by-step instructions on how to update Magisk and install Shizuku, a third-party app for Android that allows users to run apps as system applications. The guide also explains how to enable whitelist mode for enhanced functionality.\n\n\n\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\nDocument your code with AI, and use client-side compute resources\n\n\n\n\n\n\n\nTensorFlow.js\n\n\nCode documentation\n\n\nClient-side compute resources\n\n\nPrecomputed vector spaces\n\n\nSearching\n\n\nLocal storage\n\n\nCustomization\n\n\n\n\nThis article discusses the utilization of TensorFlow.js for code documentation and client-side computations, leveraging precomputed vector spaces for search functionality, and employing local storage for customization purposes.\n\n\n\n\n\n\nDec 1, 2023\n\n\n\n\n\n\n\n\nCybergod discord channel\n\n\n\n\n\n\n\nDiscord\n\n\nCybergod\n\n\nInvitation Link\n\n\nAgicomputercontrol\n\n\nRepository\n\n\nIntegration\n\n\n\n\nThis text discusses a Discord channel named ‘Cybergod’ which can be joined using the invitation link https://discord.gg/y9BrdMfA. It is set to be integrated into an agi-computer-control repository, suggesting collaboration and communication among its members.\n\n\n\n\n\n\nNov 30, 2023\n\n\n\n\n\n\n\n\nGooey: Argparse as GUI\n\n\n\n\n\n\n\nGUI\n\n\ncommand-line\n\n\ntool\n\n\nconversion\n\n\nprogram\n\n\ninteraction\n\n\ninterface\n\n\n\n\nGooey is a powerful tool that enables users to transform command-line programs into user-friendly GUI applications. By providing an intuitive graphical interface, Gooey simplifies the interaction with these programs and makes them more accessible for non-technical users.\n\n\n\n\n\n\nNov 27, 2023\n\n\n\n\n\n\n\n\nCreate sparse matrix based liquid state machine\n\n\n\n\n\n\n\nsparse matrix\n\n\nliquid state machine\n\n\ntensorly\n\n\ntorch\n\n\nefficient data processing\n\n\ncomplex datasets\n\n\nbrain neurons\n\n\n\n\nThis text explains the process of creating a sparse matrix-based liquid state machine using tensorly and torch libraries. It focuses on efficient data processing for intricate datasets such as brain neurons.\n\n\n\n\n\n\nNov 14, 2023\n\n\n\n\n\n\n\n\nHow to Clean Up Chocolatey’s Cache with the choco-cleaner.ps1 Script\n\n\n\n\n\n\n\nChocolatey\n\n\ncache\n\n\nclean\n\n\nPowerShell\n\n\nscript\n\n\ninstructions\n\n\n\n\nThis text provides instructions on how to clean up Chocolatey’s cache by running a PowerShell script called ‘choco-cleaner.ps1’.\n\n\n\n\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\nHome Assistant Installation & Setups\n\n\n\n\n\n\n\nHome Assistant\n\n\nInstallation\n\n\nFlashable .iso images\n\n\nVirtual machines\n\n\nBackup creation\n\n\nSupervisor settings updates\n\n\nTroubleshooting\n\n\nha banner\n\n\nOpenClash\n\n\nOpenWrt\n\n\nNanoPi R2S\n\n\n\n\nThis article guides you through the installation and setup process of Home Assistant using flashable .iso images or virtual machines. It covers essential steps such as creating backups, updating supervisor settings, troubleshooting with `ha banner`, and recommends utilizing OpenClash, OpenWrt, and NanoPi R2S for a more seamless experience.\n\n\n\n\n\n\nNov 5, 2023\n\n\n\n\n\n\n\n\nMastering System Events: Script Execution with @reboot and systemd\n\n\n\n\n\n\n\nsystem events\n\n\nscripts\n\n\ncrontab\n\n\nstartup\n\n\nsuspend\n\n\nshutdown\n\n\nsystemd\n\n\n\n\nThis article provides a detailed explanation of how to run scripts before and after system events such as startup, suspend, and shutdown. It covers using the `@reboot&grave; command with `crontab -e` for startup event management and explains how to write scripts in `/lib/systemd/system-*` directories for handling other system events.\n\n\n\n\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\namdgpu, rocm and pytorch\n\n\n\n\n\n\n\nAMDGPU\n\n\nROCM\n\n\nPyTorch\n\n\nVulkan\n\n\nOpenGL\n\n\nDirectML\n\n\nTensorFlow\n\n\n\n\nThis article addresses the challenges faced while using AMDGPU, ROCM, and PyTorch. It proposes alternative solutions such as Vulkan/OpenGL or DirectML for integrated graphics cards instead of ROCM, and advises checking the Pytorch nightly repo for up-to-date builds.\n\n\n\n\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\nwindows & office activation, install windows in virtualbox\n\n\n\n\n\n\n\nWindows activation\n\n\nMicrosoft Office activation\n\n\nVirtualBox installation\n\n\nBlog post\n\n\nMassgrave.dev\n\n\nInstallation guide\n\n\nTechnical instructions\n\n\n\n\nThis article provides instructions for activating Windows and Microsoft Office, as well as installing them in a VirtualBox environment. It also includes a link to a blog post with more detailed steps. The website mentioned is massgrave.dev.\n\n\n\n\n\n\nOct 6, 2023\n\n\n\n\n\n\n\n\nforce to use docker mirror instead of pulling from docker.io\n\n\n\n\n\n\n\nDocker\n\n\nConfiguration\n\n\nMirror\n\n\nBaidubce.com\n\n\nPulling\n\n\nImage\n\n\nTutorial\n\n\n\n\nThis article guides you through the process of configuring Docker to pull images from a specific mirror, such as baidubce.com, instead of the default docker.io. The article also explains that the configuration may not work until you explicitly pull from the specified mirror.\n\n\n\n\n\n\nOct 5, 2023\n\n\n\n\n\n\n\n\ncpu/gpu temperature monitor\n\n\n\n\n\n\n\ncpu\n\n\ngpu\n\n\ntemperature monitoring\n\n\ntools\n\n\narchey4\n\n\nosx-core-temp\n\n\napple_sensors\n\n\n\n\nThis article discusses various tools for monitoring CPU and GPU temperatures across different platforms. The tools mentioned include Archey4, Osx-core-temp, Apple_sensors, Smctemp, Coretemp, and Psensor.\n\n\n\n\n\n\nOct 4, 2023\n\n\n\n\n\n\n\n\n网上接单注意\n\n\n\n\n\n\n\nsecurity\n\n\ncybersecurity\n\n\nvirtual machines\n\n\nonline tasks\n\n\nphysical machine safety\n\n\ncomputer protection\n\n\nunknown applications\n\n\n\n\nThis article highlights the significance of performing online tasks within a virtual machine to ensure security and safeguard physical machines from unidentified applications.\n\n\n\n\n\n\nSep 30, 2023\n\n\n\n\n\n\n\n\nprerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections\n\n\n\n\n\n\n\nvirtual environments\n\n\ndocker environments\n\n\nisolation\n\n\nfixed-size mountpoints\n\n\nautogpt\n\n\nopen interpreter\n\n\nCybergod\n\n\n\n\nThis article discusses the secure setup of virtual or Docker environments for agents like Autogpt, Open Interpreter, and Cybergod. It emphasizes the importance of isolation, fixed-size mountpoints, and self-contracts in crypto exchanges to ensure a safe and efficient user experience.\n\n\n\n\n\n\nSep 29, 2023\n\n\n\n\n\n\n\n\nbilibili dark reader mod\n\n\n\n\n\n\n\nbilibili\n\n\nwebsite customization\n\n\ndark reader\n\n\nfilter mode toggles\n\n\nappearance modification\n\n\ntools for website modification\n\n\nuser solutions\n\n\n\n\nThis user discusses various ways to customize or modify the appearance of a website called “bilibili” using tools like Dark Reader and filter mode toggles.\n\n\n\n\n\n\nSep 29, 2023\n\n\n\n\n\n\n\n\nProcess Monitoring and Notification Tools: A Comprehensive List\n\n\n\n\n\n\n\nprocess_monitoring\n\n\nnotification_tools\n\n\nwatchdogd\n\n\nsupervisord\n\n\ngosuv\n\n\npush.js\n\n\napprise\n\n\npython-pushover\n\n\ndashboard_tools\n\n\nReportr/dashboard\n\n\nd2-admin\n\n\ntermui\n\n\nplotly/dash\n\n\nParallels/rq-dashboard\n\n\n\n\nThis article discusses various process monitoring and notification tools like watchdogd, supervisord, gosuv, push.js, apprise, and python-pushover, as well as dashboard tools such as Reportr/dashboard, d2-admin, termui, plotly/dash, and Parallels/rq-dashboard.\n\n\n\n\n\n\nSep 26, 2023\n\n\n\n\n\n\n\n\nMaintaining Stability with Mount –Bind: Detaching and Reattaching Linux Disks\n\n\n\n\n\n\n\nlinux\n\n\ndisks\n\n\nstability\n\n\nmount–bind\n\n\ndetachment\n\n\nreattachment\n\n\ncommand\n\n\n\n\nThis article provides a guide on how to preserve system stability while detaching and reattaching Linux disks using the `mount –bind` command, ensuring data consistency and seamless disk management.\n\n\n\n\n\n\nSep 26, 2023\n\n\n\n\n\n\n\n\nIntroducing Ntfy: A Service for Publishing Messages and Monitoring Statuses on a Dashboard\n\n\n\n\n\n\n\nntfy\n\n\nservice\n\n\nmessage queues\n\n\ndashboard\n\n\n\n\nNtfy is a service that enables users to publish messages through message queues and monitor statuses on a dashboard, providing an efficient way to manage and track notifications.\n\n\n\n\n\n\nSep 21, 2023\n\n\n\n\n\n\n\n\nguidelines on designing ai systems\n\n\n\n\n\n\n\nAI\n\n\nDesigning AI Systems\n\n\nDistance-based Agents\n\n\nLangChain\n\n\nAutogen\n\n\nAgency\n\n\nSelf-Improvement\n\n\n\n\nThis text provides guidelines for designing AI systems, advocating for an agent-based approach rather than a role-based one. It highlights the usage of tools like LangChain, Autogen, Agently, and ModelScope-Agent, as well as emphasizing the importance of thinking like an expert, setting example goals, and allowing the AI to self-improve.\n\n\n\n\n\n\nSep 17, 2023\n\n\n\n\n\n\n\n\nsync notes between multiple platforms/devices\n\n\n\n\n\n\n\nsync\n\n\nnotes\n\n\nplatforms\n\n\ndevices\n\n\nwebhooks\n\n\nGit\n\n\nsynchronization\n\n\n\n\nThis article explores the challenges of syncing notes across multiple platforms and devices. It proposes using webhooks or comparing Git’s latest HEAD hash at regular intervals as potential solutions for achieving efficient synchronization.\n\n\n\n\n\n\nSep 16, 2023\n\n\n\n\n\n\n\n\nfilename issue on lexar m1\n\n\n\n\n\n\n\nLexar M1\n\n\nfilename issues\n\n\nRclone\n\n\ncustom encoding rules\n\n\nSMB connections\n\n\ndata transfer\n\n\nstorage solutions\n\n\n\n\nThis text explores the file name issues encountered with Lexar M1 and offers a solution using Rclone’s custom encoding rules specifically designed for SMB connections.\n\n\n\n\n\n\nSep 10, 2023\n\n\n\n\n\n\n\n\nfire prevention and smart switches\n\n\n\n\n\n\n\nfire prevention\n\n\ndistributed computing\n\n\nsmart switches\n\n\nsafety measures\n\n\nfirebots\n\n\nfirerolls\n\n\nhuman safety\n\n\n\n\nThis article discusses the importance of fire prevention in distributed computing, highlighting the use of smart switches and safety measures to protect data and devices. Additionally, it touches upon the concepts of firebots and firerolls, as well as considering human safety.\n\n\n\n\n\n\nSep 9, 2023\n\n\n\n\n\n\n\n\nUnderstanding Captchas: Assessing Capabilities, Not Behaviors\n\n\n\n\n\n\n\nCaptchas\n\n\nPublic Automated Turing Tests\n\n\nAssess Capabilities\n\n\nNot Behaviors\n\n\nArtificial Intelligence\n\n\nSecurity\n\n\nComputer Science\n\n\n\n\nCaptchas, designed as public automated Turing tests, serve the purpose of evaluating capabilities rather than behaviors.\n\n\n\n\n\n\nSep 4, 2023\n\n\n\n\n\n\n\n\nUnlocking the Secrets of Dreams: Brainwave Translation Explained\n\n\n\n\n\n\n\nbrainwave translation\n\n\ndream extraction\n\n\ntext\n\n\naudio\n\n\nvisuals\n\n\nmelodies\n\n\n\n\nThis article discusses the process of brainwave translation, which aims to convert information from dreams into various forms such as text, audio, visuals, and melodies. The technique potentially offers a way to access valuable insights and experiences from the subconscious mind.\n\n\n\n\n\n\nSep 3, 2023\n\n\n\n\n\n\n\n\nrecycle bin, trash can cli alternative\n\n\n\n\n\n\n\nmacos\n\n\nterminal\n\n\ntrash\n\n\ncli\n\n\ntrash-cli\n\n\ncmdutils\n\n\ncmd-recycle\n\n\n\n\nLearn how to empty the trash on MacOS using a terminal and discover an alternative cross-platform CLI tool called ‘trash-cli’ for managing your personal recycle bin. Additionally, explore other related tools such as cmdutils, cmd-recycle, and nircmd for Windows.\n\n\n\n\n\n\nAug 19, 2023\n\n\n\n\n\n\n\n\nfilesystem cache\n\n\n\n\n\n\n\nfilesystem\n\n\ncache\n\n\nRust\n\n\ncatfs\n\n\nrclone\n\n\nremote caching\n\n\nbackend\n\n\n\n\nThis text introduces ‘catfs’, a filesystem cache built in Rust, and highlights that rclone, a file management tool, now supports a ‘cache’ backend for remote caching.\n\n\n\n\n\n\nAug 17, 2023\n\n\n\n\n\n\n\n\nreset windows server password\n\n\n\n\n\n\n\nWindows Server\n\n\nPassword reset\n\n\nchntpw\n\n\nUtilman.exe\n\n\ncmd.exe\n\n\nnet user command\n\n\nCommand prompt\n\n\n\n\nThis article provides a step-by-step guide on how to reset a Windows Server password when it cannot be fixed by `chntpw`. The process involves swapping `Utilman.exe` with `cmd.exe`, accessing the command prompt through widgets, and using the `net user` command to reset the password.\n\n\n\n\n\n\nAug 16, 2023\n\n\n\n\n\n\n\n\nresource utilization monitor tool\n\n\n\n\n\n\n\nLinux\n\n\nResource Utilization\n\n\nMonitoring Tools\n\n\nhtop\n\n\ns-tui\n\n\nRAM\n\n\nCPU/GPU Temperatures\n\n\n\n\nThis resource utilization monitor tool is specifically designed for Linux systems, providing features such as htop to track RAM usage and processes, along with s-tui for monitoring CPU/GPU temperatures. It is a helpful tool for keeping an eye on system resources in real-time.\n\n\n\n\n\n\nAug 13, 2023\n\n\n\n\n\n\n\n\nnotable tips\n\n\n\n\n\n\n\navoiding\n\n\nslashes\n\n\nnote\n\n\nnames\n\n\nsyncing\n\n\nprogram\n\n\nissues\n\n\n\n\nThis article provides tips on how to avoid slashes in note names to prevent syncing program issues. By following these guidelines, users can ensure that their notes are properly synced across different devices and platforms without encountering any problems.\n\n\n\n\n\n\nAug 12, 2023\n\n\n\n\n\n\n\n\nExploring Alternative Linux Cd Managers: Goto, Go-Shell, Up, and AutoJump\n\n\n\n\n\n\n\nLinux\n\n\ncd managers\n\n\nGoto\n\n\nGo-Shell\n\n\nUp\n\n\nAutoJump\n\n\nshells\n\n\n\n\nThis article discusses various Linux cd managers, comparing their features and compatibility with different shells. Alternatives such as Goto (supporting bash & zsh), Go-Shell (compatible with PowerShell), Up (capable of navigating to parent directory and supporting fish, bash, zsh) and AutoJump (a popular choice) are examined in detail.\n\n\n\n\n\n\nAug 8, 2023\n\n\n\n\n\n\n\n\naldente windows & linux alternative\n\n\n\n\n\n\n\nlaptop battery\n\n\noverheating prevention\n\n\nbattery damage\n\n\ncharge thresholds\n\n\nrecalibration\n\n\nThinkPad laptops\n\n\nplatform-specific instructions\n\n\n\n\nThis article offers guidance on preventing computer overheating and battery damage by configuring charge thresholds and recalibration for laptop batteries. It provides platform-specific instructions, such as using tlp/tlpui tools on ThinkPad laptops and considering alternative solutions like UPS+NUC. The advice applies to both Linux and Windows systems.\n\n\n\n\n\n\nAug 7, 2023\n\n\n\n\n\n\n\n\nSetting Docker Container Storage Quota with Overlay and Different Storage Drivers\n\n\n\n\n\n\n\nDocker\n\n\ncontainer\n\n\nstorage\n\n\nquota\n\n\noverlay\n\n\nXFS\n\n\ndevmapper\n\n\n\n\nThis article provides a detailed explanation on how to set Docker container storage quota using the `–storage-opt` option with overlay on XFS, and offers examples with various storage drivers such as devmapper, zfs, and vfs. Additionally, it guides you through changing the `data-root` configuration in `/etc/docker/daemon.json` and editing the `/etc/fstab` file to further customize your Docker container’s storage settings.\n\n\n\n\n\n\nJul 30, 2023\n\n\n\n\n\n\n\n\nControlling Computers with Hardware Operations and Software Tools: A Comprehensive Guide\n\n\n\n\n\n\n\ncomputer control\n\n\nhardware operations\n\n\nsoftware tools\n\n\nCyberTron\n\n\nLarq\n\n\nUSB Gadget\n\n\nOTG cables\n\n\n\n\nThis article explores the process of controlling computers using hardware operations and software tools. It covers various applications and methods, such as CyberTron, Larq, USB Gadget with OTG cables, Taiwan data cables, scrcpy, HID instructions, power management, Deep Freeze or Live CD mechanisms, and Python wrappers for usb-gadget.\n\n\n\n\n\n\nJul 27, 2023\n\n\n\n\n\n\n\n\nPython DSL\n\n\n\n\n\n\n\nPython\n\n\nDSL tools\n\n\nTextX\n\n\nSyntax highlighting\n\n\nLSP support\n\n\nPly\n\n\nLex-yacc functionality\n\n\nDhParser\n\n\nLark Parser\n\n\n\n\nThis article provides an overview of several Python-based domain-specific language (DSL) tools, such as TextX with syntax highlighting and LSP support, Ply offering lex-yacc functionality, DhParser, and Lark Parser. These tools are designed to help developers create and analyze DSLs efficiently within the Python ecosystem.\n\n\n\n\n\n\nJul 14, 2023\n\n\n\n\n\n\n\n\npython encoding issue\n\n\n\n\n\n\n\npython\n\n\nwindows\n\n\nencoding\n\n\nutf-8\n\n\n-X utf8=1\n\n\nsys.flags.utf8_mode\n\n\nsolution\n\n\n\n\nThe text dives into a Python encoding problem encountered on Windows systems. It proposes two solutions: running the interpreter with the `-X utf8=1` flag or setting `sys.flags.utf8_mode`. This ensures proper handling of Unicode characters and eliminates any potential encoding issues in Python scripts.\n\n\n\n\n\n\nJul 5, 2023\n\n\n\n\n\n\n\n\nIncremental testing, build tools, cacheing, logging\n\n\n\n\n\n\n\nPython testing\n\n\nLogging best practices\n\n\nError handling\n\n\nAlternative libraries\n\n\nEnum class\n\n\npytest caching\n\n\nRedis LRU cache for decorators\n\n\n\n\nThis article explores Python testing methods, logging best practices, and error handling techniques. It also introduces alternative libraries, such as enum class, pytest caching, Redis LRU cache for decorators, build tools, type checking, code static analysis, automation tools like pydoit, SCons, and Rake. The article aims to provide insights into various Python tools and their applications for effective development and maintenance.\n\n\n\n\n\n\nJun 16, 2023\n\n\n\n\n\n\n\n\n夏天制冷装置\n\n\n\n\n\n\n\nsummer\n\n\nair conditioning\n\n\nstanding desks\n\n\ntreadmills\n\n\nhome appliances\n\n\ncarpet cushions\n\n\nfloor tiles\n\n\n\n\nThis article discusses various summer cooling solutions such as air conditioning units, standing desks with treadmill features, and other home appliances like carpet cushions with built-in fans, floor tiles, humidifiers, dehumidifiers, potassium permanganate, soft to hard AC vent panels, strong adhesive tape, water-cooled air conditioners, and portable air conditioners with dual air vents.\n\n\n\n\n\n\nMay 21, 2023\n\n\n\n\n\n\n\n\nAGI that controls computer\n\n\n\n\n\n\n\nAI optimization\n\n\nbootable OS methods\n\n\ntokenizers\n\n\nembeddings\n\n\nOBS control\n\n\nPython\n\n\naudio recording\n\n\nmacOS\n\n\nLinux\n\n\nneural networks\n\n\nwebdav-cli\n\n\nfile operations\n\n\nvideo recording\n\n\nffmpeg\n\n\nUbuntu\n\n\nXorg\n\n\nUTM VM disks\n\n\nresizing\n\n\n\n\nThis article discusses various techniques such as optimizing AI models, utilizing different methods for creating bootable operating systems, working with tokenizers and embeddings, controlling OBS through Python programming, recording audio on macOS and Linux platforms, exploring complex neural network libraries, performing file operations using webdav-cli, capturing videos using Python and ffmpeg, forcing Ubuntu to utilize Xorg, and resizing virtual machine disks in UTM.\n\n\n\n\n\n\nMay 4, 2023\n\n\n\n\n\n\n\n\ncomprehensive page dump from multiple devices\n\n\n\n\n\n\n\ndata capturing\n\n\nweb pages\n\n\nbrowser extensions\n\n\nprivacy\n\n\nComprehensive Research series\n\n\nChrome\n\n\nFirefox\n\n\n\n\nThis article discusses methods for capturing data from web pages and chat messages while ensuring privacy. It covers browser extensions like the ‘Comprehensive Research’ series, copying tabs as Markdown in Chrome and Firefox, addressing an Android issue, and providing file path information.\n\n\n\n\n\n\nApr 5, 2023\n\n\n\n\n\n\n\n\nfaster python\n\n\n\n\n\n\n\nPython\n\n\nPypy\n\n\nPerformance\n\n\nSpeed\n\n\nCompilation\n\n\nCodon\n\n\nStatic Executables\n\n\n\n\nThis article explores the advancements in Python performance, specifically mentioning Pypy’s remarkable speed and how Codon leverages Python syntax to generate static executables.\n\n\n\n\n\n\nApr 4, 2023\n\n\n\n\n\n\n\n\nRSIBreak, Break Reminder\n\n\n\n\n\n\n\nRSI\n\n\nSmartwatch\n\n\nWearOS\n\n\nApple\n\n\nCustomization\n\n\n3D printed cases\n\n\nShapeways\n\n\n\n\nRSIBreak is a smartwatch app designed to prevent RSI injuries. It is compatible with WearOS and Apple alternatives, offering customization options such as 3D printed cases from Shapeways or DIY solutions on macOS. Additionally, alternatives like BreakTimer are available for various platforms.\n\n\n\n\n\n\nApr 4, 2023\n\n\n\n\n\n\n\n\nWebproxy, clash, proxy.py\n\n\n\n\n\n\n\nproxy\n\n\nwebsites\n\n\nUltraviolet\n\n\nTitanium Network\n\n\nHoly Unblocker\n\n\nGitHub\n\n\nWeb development\n\n\n\n\nIntroducing a new method for proxying websites directly within another website using the Ultraviolet project from Titanium Network, demonstrated through Holy Unblocker’s website. Includes links to holyub-alike websites and related GitHub topics.\n\n\n\n\n\n\nApr 3, 2023\n\n\n\n\n\n\n\n\nMarkdown to PDF\n\n\n\n\n\n\n\nmarkdown\n\n\nPDF\n\n\nPython 3\n\n\nPhantomJS\n\n\nconversion\n\n\nnpm\n\n\nmarkdown-pdf\n\n\n\n\nThis text outlines the process of transforming Markdown files into PDFs using Python 3 and the PhantomJS library, as well as introducing an npm package called markdown-pdf that facilitates this conversion.\n\n\n\n\n\n\nApr 3, 2023\n\n\n\n\n\n\n\n\nask chatgpt how to create an ai model for controlling computer under human instruction\n\n\n\n\n\n\n\nAI\n\n\nGPT\n\n\nRNN/LSTM\n\n\nViT\n\n\nScreenshots\n\n\nNatural Language Instructions\n\n\nKeyboard/Mouse Events\n\n\n\n\nThis article discusses an AI model that utilizes GPT, RNN/LSTM, and ViT to process input data from various sources such as screenshots, natural language instructions, and keyboard/mouse events. The model first extracts features using ViT, then encodes instructions with GPT, followed by processing the combined features through LSTM/RNN. Finally, it decodes the output into events utilizing CNNs, RobertaModel, and GPT2LMHeadModel.\n\n\n\n\n\n\nApr 3, 2023\n\n\n\n\n\n\n\n\nChatGPT Local Version\n\n\n\n\n\n\n\nGGML\n\n\nLoRA\n\n\nLangChain\n\n\nLLM inference\n\n\nQuantization\n\n\nRegular hardware\n\n\nConversational LLMs\n\n\n\n\nThis article highlights the use of GGML, LoRA, and LangChain to improve LLM inference on standard hardware by overcoming storage and computation limitations. Quantization techniques are employed, and an API is implemented to retrieve tokens from a server for matching behavior. The provided reference projects focus on conversational LLMs.\n\n\n\n\n\n\nApr 2, 2023\n\n\n\n\n\n\n\n\nfastapi, celery, task queue, websocket\n\n\n\n\n\n\n\nFastAPI\n\n\nCelery\n\n\nTask queues\n\n\nWeb sockets\n\n\nJinja2 whitespace issues\n\n\nUvicorn import\n\n\nOpenapi.json client code generation\n\n\n\n\nThis article delves into the integration of FastAPI, Celery, and task queues with web sockets. It covers various topics like resolving Jinja2 whitespace issues, working with uvicorn import, utilizing openapi.json client code generation for documentation purposes, adding metadata to enhance docs, and sharing locks across multiple processes. Additionally, it provides useful resources for advanced usage.\n\n\n\n\n\n\nApr 2, 2023\n\n\n\n\n\n\n\n\nchatgpt clones, computer automation with ai\n\n\n\n\n\n\n\nRWKV\n\n\nlanguage models\n\n\nHugging Face\n\n\nBaize\n\n\nDolly\n\n\nLLaMA NLP models\n\n\ndownload links\n\n\ninstallation instructions\n\n\nfine-tuned models\n\n\nAlpaca\n\n\n\n\nThis article introduces the RWKV language models available on Hugging Face and discusses various NLP models such as Baize, Dolly, LLaMA, and Alpaca. It provides download links, installation instructions for these models, and information about fine-tuned models like Alpaca based on LLaMA.\n\n\n\n\n\n\nApr 2, 2023\n\n\n\n\n\n\n\n\n批量扫描书 批量学习理解全流程\n\n\n\n\n\n\n\nbook scanning\n\n\nbatch scanning\n\n\nlearning books\n\n\ndual-sided scanner\n\n\nbook binding machine\n\n\nOCR recognition\n\n\nlatex recognition\n\n\n\n\nThis article discusses the process of batch scanning and learning books, including tips on cutting, scanning, binding, and storing. It also covers recognizing content using OCR and latex recognition tools, indexing, searching for content, and utilizing BM25 search and visual recognition to restore the original structure in markdown format. The article suggests adding organized data to ChatGPT or RETRO models’ pre-trained datasets.\n\n\n\n\n\n\nMar 6, 2023\n\n\n\n\n\n\n\n\nAutomating Freelance Job Offers: AI-Powered System for Paper Writing Industry\n\n\n\n\n\n\n\nAI\n\n\nProject Development\n\n\nFreelance Jobs\n\n\nData Collection\n\n\nMachine Learning\n\n\nQuote Generation\n\n\nQuestion-Answering System\n\n\n\n\nThis article discusses the development of an AI-driven project designed to automate responses to freelance job offers, gather data from multiple platforms, and train a machine learning model for crafting personalized quotes. The goal is to create a pay-per-answer question-answering system specifically tailored for the paper writing industry.\n\n\n\n\n\n\nMar 5, 2023\n\n\n\n\n\n\n\n\n适合夏天佩戴的耳机\n\n\n\n\n\n\n\nearphones\n\n\nsummer\n\n\nopen-back\n\n\nCanyon\n\n\nPhilips SHP9500\n\n\nSennheiser Portapro\n\n\nApple AirPods Max\n\n\nSony WH-1000XM4\n\n\n\n\nDiscover the perfect earphones for summer with this guide. From open-back options like Canyon, Philips SHP9500, and Sennheiser Portapro to closed-back choices such as Apple AirPods Max and Sony WH-1000XM4 (Haidian version), find the ideal audio companion for warm weather activities.\n\n\n\n\n\n\nMar 4, 2023\n\n\n\n\n\n\n\n\nLive Share Plugin, Clipboard syncing, peer programming, collaboration, multi-user editing\n\n\n\n\n\n\n\ncollaborative programming\n\n\nLive Share\n\n\nCrossclip\n\n\nCodeShare\n\n\nclipboard syncing\n\n\ncode sharing\n\n\ninstant messaging\n\n\n\n\nThis text dives into the world of collaborative programming tools, showcasing various options such as Live Share, Crossclip, and CodeShare. These tools enable seamless clipboard syncing, code sharing, and instant messaging across different platforms, making collaboration between developers easier and more efficient.\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\na comprehensive list of ai tools, may not be free, just for reference?\n\n\n\n\n\n\n\nAI\n\n\nSocial Media Engagement\n\n\nImage Generation\n\n\nContent Creation\n\n\nColorization\n\n\nAbstract Creation\n\n\nText Rephrasing\n\n\n\n\nAI tools are revolutionizing social media, image generation, and content creation by offering features such as colorization, abstract art, and text rephrasing. Tools like Hootsuite, Crystal Knows, Hama.app, MovieToEmoji, and Summari help with tasks ranging from music production to personalized videos, enhancing user engagement and productivity.\n\n\n\n\n\n\nFeb 19, 2023\n\n\n\n\n\n\n\n\ngenerate docx document from python docstring\n\n\n\n\n\n\n\npython\n\n\ndocstrings\n\n\npdoc3\n\n\npandoc\n\n\ndocxcompose\n\n\ndocumentation\n\n\ngeneration\n\n\n\n\nThis article details a method to generate DOCX documents from Python docstrings. It explains the process of installing and using pdoc3, pandoc, and docxcompose to convert, clean, and compose the required files. The step-by-step guide ensures easy understanding and implementation for developers.\n\n\n\n\n\n\nFeb 19, 2023\n\n\n\n\n\n\n\n\nmacos cleanup disk and ram\n\n\n\n\n\n\n\nsudo purge\n\n\nMacOS\n\n\nRAM issue\n\n\ndisk space\n\n\nsystem performance\n\n\n\n\nThis article gives detailed instructions on how to use the `sudo purge` command, which can help resolve a RAM issue on MacOS by cleaning up disk space and improving system performance. It is recommended for users who are experiencing issues related to low memory or slow system performance.\n\n\n\n\n\n\nFeb 18, 2023\n\n\n\n\n\n\n\n\nExample Pydoc\n\n\n\n\n\n\n\npython\n\n\nfunction\n\n\nparameters\n\n\nclass\n\n\ninstance_variables\n\n\nmethod\n\n\noptional_parameter\n\n\n\n\nThis article discusses a Python function called `some_random_method` that takes three parameters. It also introduces a class named `Dog`, which has both instance and class variables. The class contains the `bark` method, which can take an optional ‘loud’ parameter and returns ‘woof’. The existence of this method was generated by pdoc version 0.10.0.\n\n\n\n\n\n\nFeb 17, 2023\n\n\n\n\n\n\n\n\nsetup ssh server on windows, enable key based authentication to windows ssh server\n\n\n\n\n\n\n\nssh\n\n\nwindows\n\n\ntutorial\n\n\nserver setup\n\n\nkey-based authentication\n\n\nsshd config\n\n\nsecurity\n\n\n\n\nThis article provides a step-by-step guide on how to install and configure an SSH server on Windows, secure it with key-based authentication, and customize the SSHD configuration.\n\n\n\n\n\n\nFeb 15, 2023\n\n\n\n\n\n\n\n\ntext-processing.com, free text mining and natural language processing\n\n\n\n\n\n\n\ntext-processing.com\n\n\nfree tools\n\n\ntext mining\n\n\nNLP\n\n\nSentiment Analysis\n\n\nStemming\n\n\ndaily limit\n\n\n\n\ntext-processing.com is a platform providing free access to various text mining and NLP tools such as Sentiment Analysis, Stemming, Part-of-Speech Tagging, Chunking, Phrase Extraction, and Named Entity Recognition. Users can utilize these features up to 1000 calls per IP address every day.\n\n\n\n\n\n\nFeb 14, 2023\n\n\n\n\n\n\n\n\nautocad dwg to dxf, extract text from dwg files\n\n\n\n\n\n\n\nAutocad\n\n\nDWG to DXF conversion\n\n\nODA File Converter\n\n\nLibreDWG\n\n\nText extraction\n\n\nFreeCAD\n\n\nCommand-line usage\n\n\n\n\nThis text offers step-by-step guidance on how to convert Autocad DWG files into DXF format utilizing the ODA File Converter tool and retrieve text from DWG files with LibreDWG. It also provides an example of command-line usage and a link to FreeCAD for further exploration.\n\n\n\n\n\n\nFeb 14, 2023\n\n\n\n\n\n\n\n\nproxy.py forward localhost proxy to public ip address\n\n\n\n\n\n\n\nproxy\n\n\nlocalhost proxy\n\n\npublic IP address\n\n\nrouter settings\n\n\nport forwarding\n\n\nProxyPoolPlugin\n\n\nexposing localhost\n\n\n\n\nThis article provides instructions on utilizing proxy.py to establish a localhost proxy that redirects traffic to a publicly accessible IP address, enabling users to expose their sole localhost proxy without modifying router configurations. The process involves specifying the public proxy’s port and IP address, incorporating the ProxyPoolPlugin plugin, and supplying the necessary localhost:8981 proxy pool information.\n\n\n\n\n\n\nFeb 13, 2023\n\n\n\n\n\n\n\n\nIssues while developing pyjom\n\n\n\n\n\n\n\nAI\n\n\nPyjom\n\n\nUpdates\n\n\nPlatforms\n\n\nViral trends\n\n\nBaidu API\n\n\n\n\npyjom’s updates focus on improving user experience by fixing timeouts, enabling features for popular platforms, monitoring viral trends, and leveraging data from the Baidu API to enhance its capabilities.\n\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n\n\nusing default pypi.org/simple index\n\n\n\n\n\n\n\nPyPI\n\n\npip\n\n\npackage installer\n\n\nEdgeGPT\n\n\nlatest versions\n\n\npermanently\n\n\ntemporarily\n\n\n\n\nThis text describes the process of setting the PyPI index for `pip`, Python’s package installer, to access the latest versions of packages like `EdgeGPT`. This can be done either permanently or temporarily, ensuring you have access to the most up-to-date software.\n\n\n\n\n\n\nFeb 10, 2023\n\n\n\n\n\n\n\n\nopenai account registration\n\n\n\n\n\n\n\nOpenAI\n\n\nRegistration\n\n\nChinese Phone Number\n\n\nIndia\n\n\nSMS Activation\n\n\nTempumail\n\n\nTemporary Email\n\n\n\n\nThis tutorial provides step-by-step instructions on how to create an OpenAI account using a Chinese phone number and temporary email addresses from Tempumail, making it possible to bypass potential restrictions and issues.\n\n\n\n\n\n\nFeb 9, 2023\n\n\n\n\n\n\n\n\npython diagram/flowchart generator and markdown to word converter\n\n\n\n\n\n\n\nPython\n\n\nLibraries\n\n\nDiagrams\n\n\nFlowcharts\n\n\npyflowchart\n\n\ndiagrams\n\n\npydiagrams\n\n\n\n\nThis article explores different Python libraries for creating diagrams and flowcharts, including pyflowchart, diagrams, and pydiagrams. It also includes installation instructions for dependencies like Graphviz on Debian-based systems.\n\n\n\n\n\n\nFeb 8, 2023\n\n\n\n\n\n\n\n\ndifferential equations: ODE (Ordinary Differential Equation), SDE (Stochastic Differential Equation), DDE (Delay Differential Equation), DAE (Differential Algebraic Equation)\n\n\n\n\n\n\n\ndifferential equations\n\n\nmathematical models\n\n\nphysics\n\n\nengineering\n\n\neconomics\n\n\nodes\n\n\nsdes\n\n\nddes\n\n\ndaes\n\n\n\n\nDifferential equations are a type of mathematical model utilized across various disciplines such as physics, engineering, and economics to establish relationships between variables and their derivatives. These equations come in different forms, including Ordinary Differential Equations (ODEs), Stochastic Differential Equations (SDEs), Delay Differential Equations (DDEs), and Distributional Differential Equations (DAEs), each designed to account for specific system properties or uncertainties.\n\n\n\n\n\n\nFeb 8, 2023\n\n\n\n\n\n\n\n\nWindows 10 system debloating, windows operating system optimization, winget, windows commandline package manager\n\n\n\n\n\n\n\nWindows 10\n\n\nperformance\n\n\nWinget\n\n\nKMS activator\n\n\ntelemetry\n\n\nsystem drive\n\n\nrun dialog\n\n\n\n\nThis article offers tips on boosting Windows 10 performance using tools like Winget and KMS activator, along with steps such as disabling telemetry and cleaning the system drive. It also explains how to create custom commands for the run dialog by leveraging silent run support through a configuration file.\n\n\n\n\n\n\nFeb 8, 2023\n\n\n\n\n\n\n\n\nChoosing the Perfect AR/VR Glasses: Clear, Comfortable, and Well-Ventilated\n\n\n\n\n\n\n\nAR/VR glasses\n\n\nclear lenses\n\n\nedge-to-edge clarity\n\n\nlightweight design\n\n\nhat or headband compatible\n\n\nventilation for heat dissipation\n\n\nselecting AR/VR glasses\n\n\n\n\nThis article provides a guide for choosing AR/VR glasses that offer a clear, edge-to-edge viewing experience without blurriness and are lightweight for comfortable wear. Additionally, the design should allow for proper ventilation to manage heat dissipation and be compatible with hats or headbands.\n\n\n\n\n\n\nFeb 6, 2023\n\n\n\n\n\n\n\n\nrecreating cloudpss\n\n\n\n\n\n\n\ncloud platform\n\n\nCloudPss alternative\n\n\nopen-source software\n\n\nGridLAB-D\n\n\nOpenModelica\n\n\nGridAPPS-D\n\n\nenergy internet analysis\n\n\n\n\nThis article explains how to create a cloud platform similar to CloudPss for energy internet analysis using open-source software such as GridLAB-D, OpenModelica, and GridAPPS-D. The process involves setting up the required infrastructure, configuring the software components, and integrating them into a functional platform. This approach provides an alternative solution to traditional cloud platforms, making it more accessible for researchers and practitioners in the field of energy internet analysis.\n\n\n\n\n\n\nFeb 4, 2023\n\n\n\n\n\n\n\n\n能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测\n\n\n\n\n\n\n\nenergy_system_simulation\n\n\nJModelica\n\n\nScilab\n\n\nScicos\n\n\nModelica_simulations\n\n\nPyPSA\n\n\nPowerGAMA\n\n\npsst\n\n\nGridLAB-D\n\n\nOpenDSS\n\n\nMATPower\n\n\nAMS\n\n\nJulia\n\n\nOpenAI_Gym\n\n\nAndes\n\n\nDPSim\n\n\nCalliope\n\n\nTESPy\n\n\nXcos\n\n\npower_system_analysis\n\n\nenergy_market_participation\n\n\noptimization\n\n\n\n\nThis article compares various energy system simulation tools, discussing their capabilities in areas such as Modelica simulations with JModelica, Scilab, and Scicos; power system analysis with PyPSA, PowerGAMA, psst, GridLAB-D, OpenDSS, MATPower, AMS, Julia, and OpenAI Gym; optimization and energy market participation with Andes, DPSim, Calliope, TESPy, and Xcos. The article provides insight into the strengths and weaknesses of each tool, helping readers make informed decisions when selecting a suitable simulation tool for their needs.\n\n\n\n\n\n\nFeb 3, 2023\n\n\n\n\n\n\n\n\nlessons learned from premiere pro plugin job\n\n\n\n\n\n\n\nPremier Pro plugin\n\n\nPython setup\n\n\nAvoiding PyInstaller\n\n\nNotetaking\n\n\nFair compensation\n\n\nLessons learned\n\n\nVideo editing software\n\n\n\n\nThis text discusses the valuable lessons learned while working on a Premier Pro plugin job. The author highlights the importance of correctly setting up Python using scripts, avoiding time-consuming compilers like PyInstaller, keeping detailed notes throughout the project, and ensuring fair compensation for services provided.\n\n\n\n\n\n\nJan 30, 2023\n\n\n\n\n\n\n\n\nspider, web scraping, captcha bypass\n\n\n\n\n\n\n\nGithub\n\n\nspider collections\n\n\nweb scraping tools\n\n\nlearnspider\n\n\nZhihu.com\n\n\nresource limitations\n\n\nrecommendations\n\n\n\n\nThis article discusses different spider collections and web scraping tools found on Github. It points out the drawbacks of certain existing resources and suggests a particular one (learnspider) for practical use. Additionally, it introduces another collection specifically designed for Zhihu.com.\n\n\n\n\n\n\nJan 18, 2023\n\n\n\n\n\n\n\n\n影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection\n\n\n\n\n\n\n\nvideo summarization\n\n\nBilibili anime videos\n\n\naria2p\n\n\npyaria2\n\n\nChinese torrent sites\n\n\nRSS feeds\n\n\nnetprogressbar server\n\n\n\n\nThis article dives into video summarization techniques and methods for acquiring content, specifically focusing on Bilibili’s anime videos. It demonstrates the use of command-line tools like aria2p and pyaria2 to download anime videos from Chinese torrent sites. The process involves selecting files, utilizing search engines, subscribing to RSS feeds, formatting episode numbers, and setting up a netprogressbar server for tracking progress.\n\n\n\n\n\n\nJan 16, 2023\n\n\n\n\n\n\n\n\nAPFS for Linux\n\n\n\n\n\n\n\nAPFS\n\n\nfile transfer\n\n\noperating systems\n\n\nKali\n\n\nkernel module\n\n\nread-only adapter\n\n\nread and write support\n\n\n\n\nThis article provides details on two methods for transferring files between operating systems using APFS (Apple File System). The first option is a read-only adapter that can be used to transfer files to Kali, while the second option offers both read and write support but requires installing a kernel module.\n\n\n\n\n\n\nJan 15, 2023\n\n\n\n\n\n\n\n\nlibrary genesis, getting latest ebooks for free\n\n\n\n\n\n\n\nebooks\n\n\nfree ebooks\n\n\nforeign languages\n\n\nnon-educational content\n\n\nLibGen.is\n\n\nbook search engine\n\n\nAmazon Kindle\n\n\n\n\nLibGen.is is a Russian ebook search engine that offers the latest free ebooks in various languages and genres, including non-educational content. It can be useful for finding books on popular topics or those from Amazon Kindle.\n\n\n\n\n\n\nJan 15, 2023\n\n\n\n\n\n\n\n\ntorrent search engines\n\n\n\n\n\n\n\ntorrent search engines\n\n\nanime torrent searching\n\n\nTorrenthunt\n\n\nTelegram bot\n\n\nmulti-torrent searching\n\n\nTorrent Search API\n\n\nNodeJS\n\n\nNotflix\n\n\nPeerflix\n\n\n1337x\n\n\nNyaa\n\n\nBangume.moe\n\n\nDongmanhuaYuan (动漫花园)\n\n\nRSS subscription\n\n\nglobal sorting\n\n\n\n\nThis article discusses various torrent search engines and bots, specifically focusing on general and anime torrent searching. It highlights tools like Torrenthunt, a Telegram bot for multi-torrent searching, the Torrent Search API in NodeJS, Notflix for magnet links on 1337x with Peerflix, Nyaa for sorting anime torrents, Bangume.moe, and DongmanhuaYuan (动漫花园) with RSS subscription capabilities but lacking global sorting.\n\n\n\n\n\n\nJan 15, 2023\n\n\n\n\n\n\n\n\nopentimelineio: unified format for media editors?\n\n\n\n\n\n\n\nOpenTimelineIO\n\n\nunified format\n\n\nmedia editors\n\n\nFinal Cut Pro\n\n\nAdobe Premiere\n\n\nKdenlive\n\n\nPython interface\n\n\n\n\nOpenTimelineIO is a versatile and widely compatible format designed to facilitate seamless communication between different media editing software. With adapters available for popular editors like Final Cut Pro, Adobe Premiere, and Kdenlive, it provides a unified interface using Python. However, some adapters for certain systems are still incomplete.\n\n\n\n\n\n\nJan 15, 2023\n\n\n\n\n\n\n\n\n正方教务系统sql注入\n\n\n\n\n\n\n\nSQL injection\n\n\nASMX URL\n\n\nXiàngfāng Jiaodǎo Xìtǐng\n\n\ncyber attack\n\n\nschool vulnerability\n\n\nretaliation\n\n\nweb security\n\n\n\n\nThis article discusses a SQL injection attack on the ‘正方教务系统’ (Xiàngfāng Jiaodǎo Xìtǐng) using an ASMX URL. The text proposes utilizing this vulnerability as a means of retaliation against a school.\n\n\n\n\n\n\nJan 14, 2023\n\n\n\n\n\n\n\n\nmacbook is freezing cold to use at winter\n\n\n\n\n\n\n\nMacBook\n\n\nwinter\n\n\ncold\n\n\nfingerless gloves\n\n\ntrousers\n\n\nprotection\n\n\nproductivity\n\n\n\n\nThe MacBook is found to be uncomfortable to use in cold weather. Users suggest using fingerless gloves or wearing trousers under wrists as protective measures.\n\n\n\n\n\n\nJan 14, 2023\n\n\n\n\n\n\n\n\nrecaptcha solving, proxy providers\n\n\n\n\n\n\n\nRecaptcha\n\n\nSolving Services\n\n\nProxy Providers\n\n\nCheap Proxy\n\n\nBotright\n\n\nAnycaptcha.com\n\n\n\n\nThis article discusses recaptcha solving services and proxy providers, offering suggestions for a low-cost proxy service (proxy-cheap) and various recaptcha solving options including free libraries like Botright and paid solutions such as Anycaptcha.com.\n\n\n\n\n\n\nJan 14, 2023\n\n\n\n\n\n\n\n\ntranslate.com, webhooks, make money by translation\n\n\n\n\n\n\n\nwebhooks\n\n\njob acquisition\n\n\ntranslate.com\n\n\nPayoneer\n\n\nacceleration\n\n\n\n\nThe text explores the utilization of webhooks to expedite job acquisition on translate.com, a translation platform that compensates users through Payoneer.\n\n\n\n\n\n\nJan 14, 2023\n\n\n\n\n\n\n\n\nMedium Subscription Bypass\n\n\n\n\n\n\n\nscribe.rip\n\n\nMedium articles\n\n\nunblocked version\n\n\nSourcehunt\n\n\nalternative hosting\n\n\ntrending\n\n\nmost read\n\n\n\n\nScribe.rip is a website that offers an unblocked version of restricted Medium articles without additional features like ‘trending’, ‘user homepage’, or ‘most read’ sections. Instead of using `medium.com` links, it recommends replacing them with `scribe.rip`. The source code for hosting your own Scribe instance is also available on Sourcehunt.\n\n\n\n\n\n\nJan 13, 2023\n\n\n\n\n\n\n\n\n床上用键盘的技巧：垫枕头\n\n\n\n\n\n\n\nspace-saving\n\n\ncold-weather\n\n\nbed\n\n\nkeyboard\n\n\nblankets\n\n\npillows\n\n\ncomfort\n\n\n\n\nThis text presents a practical solution for typing comfortably on a keyboard while using thick blankets in cold weather. By placing two pillows on either side of the legs, it helps create enough space to type without being restricted by the blanket’s pressure on hands and feet.\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\npyttsx3 cross platform tts generator\n\n\n\n\n\n\n\npyttsx3\n\n\ntext-to-speech\n\n\nlibrary\n\n\ncross-platform\n\n\nvoice\n\n\nlanguage\n\n\nspeech-rate\n\n\n\n\nThe ‘pyttsx3’ library is a cross-platform Text to Speech generator, offering language-specific voice options, adjustable speech rate, and file saving capabilities for playback. It utilizes default engines on Windows and macOS, and requires espeak for Linux.\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n\n\nstop background jobs\n\n\n\n\n\n\n\ncommand-line\n\n\nbackground jobs\n\n\nstopping processes\n\n\nlisting job numbers\n\n\nkilling processes\n\n\nkill command\n\n\nunix\n\n\n\n\nThe article discusses a command-line approach to stopping background jobs by listing the running job numbers and utilizing the ‘kill’ command to terminate the associated processes.\n\n\n\n\n\n\nJan 10, 2023\n\n\n\n\n\n\n\n\nEverything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots\n\n\n\n\n\n\n\nvideos\n\n\nsocial media\n\n\nvideo editing tools\n\n\nlive streaming\n\n\ndata analysis\n\n\nviral videos\n\n\nsuccess prediction\n\n\n\n\nThis article highlights the importance of using effective video editing tools and analyzing social media data to create, improve, and predict the success of viral videos and live streaming content. It delves into various methods and techniques that can help enhance the impact of such content, ultimately leading to increased engagement and visibility on social media platforms.\n\n\n\n\n\n\nJan 9, 2023\n\n\n\n\n\n\n\n\ninstall neo4j as systemd service\n\n\n\n\n\n\n\nNeo4j\n\n\ngraph database\n\n\nsystemd service\n\n\nLinux\n\n\ninstallation guide\n\n\nconfiguration file\n\n\ntutorial\n\n\n\n\nThis instruction offers a configuration file to simplify the installation and management of Neo4j, a graph database, as a systemd service on Linux-based systems.\n\n\n\n\n\n\nJan 5, 2023\n\n\n\n\n\n\n\n\nautonomous lazero bot, controlling computer using natural language instructions\n\n\n\n\n\n\n\nautonomous robot control\n\n\nnatural language\n\n\nmultimodal models\n\n\nMagma\n\n\nVersatile-Diffusion\n\n\nAI-based reinforcement learning\n\n\nGUI testing\n\n\nGUIs\n\n\nGUI automation\n\n\n\n\nThis text explores the concept of autonomous robot control through natural language and advanced multimodal models such as Magma and Versatile-Diffusion. Additionally, it delves into AI-driven reinforcement learning for GUI testing using projects like RT-1, SayCan, VIMA, Glider Tasklet Crawler, and Sadam’s RL-based bug detection in GUIs.\n\n\n\n\n\n\nJan 2, 2023\n\n\n\n\n\n\n\n\nAI tools collections\n\n\n\n\n\n\n\nAI\n\n\nTools Collections\n\n\nFuturepedia\n\n\nCreatives\n\n\nFuturetools\n\n\nZhihu\n\n\nGetinference\n\n\n\n\nThis article highlights various AI tools collections, including Futurepedia, Creatives, and Futuretools. It also refers to a Zhihu post and Getinference.\n\n\n\n\n\n\nDec 30, 2022\n\n\n\n\n\n\n\n\nteach puppies to speak english (video script)\n\n\n\n\n\n\n\npuppies\n\n\nlanguage\n\n\ncognitive limitations\n\n\ntraining\n\n\nevolution\n\n\n\n\nThis article discusses the cognitive limitations of puppies that prevent them from naturally learning human languages. It also explains that evolution is a natural process that is not influenced by intention.\n\n\n\n\n\n\nDec 28, 2022\n\n\n\n\n\n\n\n\n怎样清理嗓子 鼻腔里面的痰液\n\n\n\n\n\n\n\nEustachian tube\n\n\nThroat mucus\n\n\nNasal passages\n\n\nEar earlobe\n\n\nSore area\n\n\nFace\n\n\nNeck and jaw\n\n\n\n\nThis article provides a method for clearing mucus from the throat and nasal passages by using ear pressure, opening the Eustachian tube’s passage, and blowing or coughing out the mucus. It also suggests pressing on any sore areas in the face, neck, or jaw to help with relief.\n\n\n\n\n\n\nDec 28, 2022\n\n\n\n\n\n\n\n\nhow to use ai to generate video, distribute them and advertise\n\n\n\n\n\n\n\nAI\n\n\nAnimoto\n\n\nTargeted audience strategies\n\n\nVideo editors\n\n\nAdobe Premiere Pro\n\n\nDaVinci Resolve\n\n\nFinal Cut Pro\n\n\n\n\nAI tools like Animoto enable the creation of targeted audience strategies with human input, while advanced AI-powered video editors such as Adobe Premiere Pro, DaVinci Resolve, and Final Cut Pro provide personalized marketing campaigns and messaging.\n\n\n\n\n\n\nDec 28, 2022\n\n\n\n\n\n\n\n\ndark reader pdf dark theme\n\n\n\n\n\n\n\ndark reader\n\n\nPDF\n\n\ncustom stylesheets\n\n\nimprove dark theme\n\n\nsource code search\n\n\n\n\nThe Dark Reader PDF extension enhances the dark theme experience by identifying and applying custom style sheets to improve readability, particularly when accessing PDF files.\n\n\n\n\n\n\nDec 25, 2022\n\n\n\n\n\n\n\n\nspring cloud, spring boot, rabbitmq in kotlin\n\n\n\n\n\n\n\nKotlin\n\n\nSpring Boot\n\n\nMicroservices\n\n\nService Discovery\n\n\nCircuit Breaking\n\n\nRabbitMQ\n\n\nGradle\n\n\n\n\nThis article discusses the development of a Kotlin Spring Boot application with properties files and annotations, utilizing microservices, Spring Cloud integrations for service discovery and circuit breaking, and RabbitMQ communication through amqp-client library. The article also compares frameworks based on performance and maintenance ease, recommending Gradle as a package builder for Kotlin applications.\n\n\n\n\n\n\nDec 23, 2022\n\n\n\n\n\n\n\n\nspring, orm, kotlin, yaml config, jsp\n\n\n\n\n\n\n\nkotlin\n\n\norm\n\n\nlibraries\n\n\nhibernate\n\n\nroom\n\n\nexposed\n\n\nktor-exposed\n\n\n\n\nKotlin ORM libraries like Hibernate, Room, and Exposed offer type-safe SQL queries through Ktor-Exposed for database connections. Spring Framework in Kotlin leverages AOP for cross-cutting concerns and includes basic MVC controllers. JSP can be used with Spring Boot to create apps, handle requests, and process HTTP GETs using the @GetMapping annotation.\n\n\n\n\n\n\nDec 22, 2022\n\n\n\n\n\n\n\n\nunmount disks forcefully\n\n\n\n\n\n\n\nunmount\n\n\nforcefully\n\n\ndisk\n\n\npartition\n\n\nprocess\n\n\nlazy unmount\n\n\nNFS\n\n\n\n\nThis tutorial teaches you how to forcefully unmount disks by killing the process using it, handling lazy unmounts, and force unmounting on NFS. It provides detailed explanations and examples for each method.\n\n\n\n\n\n\nDec 18, 2022\n\n\n\n\n\n\n\n\ntelegram bot: pyrogram\n\n\n\n\n\n\n\nPyrogram\n\n\nTelegram bot library\n\n\nPython programming language\n\n\nInteracting with user and bot accounts\n\n\nTelegram bots\n\n\n\n\nPyrogram is a Telegram bot library written in Python, enabling interaction with both user and bot accounts.\n\n\n\n\n\n\nDec 18, 2022\n\n\n\n\n\n\n\n\npyro and pymc3 basics\n\n\n\n\n\n\n\nprobabilistic programming\n\n\nPyro\n\n\nPyMC3\n\n\nBeta-Binomial likelihoods\n\n\nMCMC techniques\n\n\nGamma priors\n\n\nmodel creation\n\n\n\n\nPyro and PyMC3 are programming languages designed for probabilistic programming. PyMC3, in particular, utilizes Beta-Binomial likelihoods, Markov Chain Monte Carlo (MCMC) techniques, and Gamma priors for creating models, sampling data, and calculating statistics.\n\n\n\n\n\n\nDec 18, 2022\n\n\n\n\n\n\n\n\nelo rating system\n\n\n\n\n\n\n\nElo rating system\n\n\nPlayer skills evaluation\n\n\nTwo-player games\n\n\nChess\n\n\nPython code\n\n\nRating updates\n\n\nk-factor\n\n\n\n\nThe Elo rating system is a widely-used method for evaluating the relative skills of players in two-player games such as chess. It assigns ratings to players and updates them based on the results of their matches. The Python code provided here demonstrates how to implement the Elo rating system, taking into account a k-factor that determines the magnitude of the change in player ratings.\n\n\n\n\n\n\nDec 18, 2022\n\n\n\n\n\n\n\n\nlet chatgpt describe how to build itself\n\n\n\n\n\n\n\nreinforcement learning\n\n\nAI agents\n\n\nGPT-2\n\n\nPPO\n\n\nalgorithms\n\n\nefficient instruction processing\n\n\ntask performance\n\n\n\n\nThis article explores the use of reinforcement learning algorithms like GPT-2, PPO, and different types of learning approaches such as unsupervised, supervised, and semi-supervised learning for training AI agents to efficiently process instructions and perform tasks.\n\n\n\n\n\n\nDec 18, 2022\n\n\n\n\n\n\n\n\npyro object detection, 3d convolution on video, remove watermark in video\n\n\n\n\n\n\n\ndeep_learning\n\n\nPyTorch\n\n\nwatermark_detection\n\n\nCNN\n\n\n3D_convolution\n\n\nobject_detection\n\n\nPyro\n\n\n\n\nThis article provides a detailed explanation of training deep learning models in PyTorch for watermark location detection using CNN and object detection with the Pyro library. The process involves implementing 3D convolution on video frames and defining layers for object detection from available Pyro resources.\n\n\n\n\n\n\nDec 16, 2022\n\n\n\n\n\n\n\n\npyro audio segmentation and classification\n\n\n\n\n\n\n\nGPT-2\n\n\nperformance\n\n\nhuman feedback\n\n\nhyperparameter adjustments\n\n\nPyro\n\n\nprobabilistic programming\n\n\naudio segmentation\n\n\nclassification\n\n\nMCMC\n\n\nvariational inference\n\n\n\n\nThis article explores techniques for improving the performance of GPT-2, a popular language model. By incorporating human feedback and fine-tuning hyperparameters, the model’s capabilities can be further enhanced. Additionally, the article delves into using Pyro, a probabilistic programming framework, to address tasks such as audio segmentation and classification through advanced algorithms like MCMC and variational inference.\n\n\n\n\n\n\nDec 16, 2022\n\n\n\n\n\n\n\n\nchatgpt on pyro and pytorch\n\n\n\n\n\n\n\nPyro\n\n\nText generation\n\n\nPyTorch\n\n\nObject detection\n\n\nImage watermark removal\n\n\nHidden states\n\n\nCustom datasets\n\n\n\n\nThis article discusses the use of Pyro and PyTorch for tasks such as text generation, object detection, and image watermark removal. The first comment focuses on the importance of hidden states in generating text using Pyro, while the second comment emphasizes training custom datasets and employing RNN/Transformer models for natural language generation with PyTorch.\n\n\n\n\n\n\nDec 16, 2022\n\n\n\n\n\n\n\n\nreset usb\n\n\n\n\n\n\n\nlinux\n\n\nhard disk detection\n\n\nreset-usb.sh script\n\n\nUSB controllers\n\n\nKali Linux\n\n\nimprovements\n\n\nsub-scripts\n\n\n\n\nThe reset-usb.sh script is a solution to hard disk detection issues in Linux, specifically addressing USB controller problems. It works by utilizing sub-scripts and a for loop to unbind and rebind the controllers, with suggested enhancements for Kali Linux.\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\nuseful java patterns\n\n\n\n\n\n\n\nJava\n\n\nKotlin\n\n\nTutorials\n\n\nStream API\n\n\nList Comprehension\n\n\nSwitch Expressions\n\n\nEclipse\n\n\nJetBrains Plugin\n\n\nBeanshell Syntax Highlighting\n\n\nArray Element Occurrences\n\n\n\n\nThis guide offers tutorials in Java and Kotlin, covering patterns like Java Stream, list comprehension, switch expressions, and iterating through lists with indices. Additionally, it discusses eclipse and JetBrains plugin support for BeanShell syntax highlighting. The guide also teaches various methods to count array element occurrences in both languages.\n\n\n\n\n\n\nDec 15, 2022\n\n\n\n\n\n\n\n\nrare package managers, alternative jvm languages and java study hints\n\n\n\n\n\n\n\npackage_managers\n\n\nrare_languages\n\n\nJVM_alternatives\n\n\nKotlin\n\n\nScala\n\n\nGroovy\n\n\nClojure\n\n\nlanguage_integration\n\n\nConan\n\n\nCLibs\n\n\nVcpkg\n\n\njavac_doc\n\n\nGraalVM\n\n\npolyglot\n\n\n\n\nThe text explores package managers for less common languages, such as Conan, CLibs, and Vcpkg. It also delves into JVM alternatives like Kotlin, Scala, Groovy, and Clojure. Furthermore, it covers tools like javac doc and GraalVM’s polyglot, which facilitate language integration.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\nweb scraping logic\n\n\n\n\n\n\n\nweb scraping\n\n\ndata extraction\n\n\nwebsites\n\n\nproxies\n\n\ncookies\n\n\ndata storage\n\n\ncategorization\n\n\n\n\nWeb scraping is the process of extracting data from websites by selecting targets and utilizing proxies or cookies for access, storing the content in compatible formats, categorizing it, and linking it for efficient retrieval.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\nlazero search engine update logic\n\n\n\n\n\n\n\ndocprompting\n\n\nColBERT\n\n\nRoBERTa\n\n\nsearch engine update\n\n\nfile lists\n\n\nindex scanning\n\n\nminibatches\n\n\n\n\nThis article discusses an efficient method for updating a search engine using advanced tools such as docprompting, ColBERT, and RoBERTa. The process involves managing file lists, scanning new files based on the index, merging, saving, and removing old indexes while also handling large datasets in minibatches when necessary.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\npopular ai competition platforms (may with notebook support)\n\n\n\n\n\n\n\nAI competition platforms\n\n\nNotebook support\n\n\n阿里天池\n\n\nDatafountain\n\n\n和鲸社区\n\n\nKaggle\n\n\nAistudio\n\n\n\n\nPopular AI competition platforms that support notebooks include 阿里天池, Datafountain, 和鲸社区, Kaggle, and Aistudio.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\ndubbo and python xmlrpc\n\n\n\n\n\n\n\nDubbo\n\n\nPython\n\n\nXML-RPC\n\n\nremote procedure call\n\n\nnumpy arrays\n\n\ntutorials\n\n\nDubbo services\n\n\n\n\nThis article compares Dubbo and Python’s XML-RPC as remote procedure call technologies, discussing their capabilities in handling native structures like numpy arrays. It also provides tutorial links for detecting if Dubbo services are functioning normally, along with warnings against ads when opening specific URLs.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\nturing-project and his works on AI and NLP\n\n\n\n\n\n\n\nAI\n\n\nNLP\n\n\nTuring-Project\n\n\nAntiFraudChatBot\n\n\nVideo Transfer\n\n\nMegatron\n\n\nYuan 1.0\n\n\nDCT-Net\n\n\n\n\nTuring-Project focuses on Artificial Intelligence and Natural Language Processing, developing innovative tools such as AntiFraudChatBot and Video Transfer. They have collaborated with technologies like Megatron, Yuan 1.0, and DCT-Net for various applications. However, their work is only accessible for a limited time before restrictions are applied.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\nvirtual phone numbers and public/anonymous accounts\n\n\n\n\n\n\n\nvirtual phone numbers\n\n\npublic accounts\n\n\nanonymous accounts\n\n\nservice providers\n\n\nbilibili\n\n\ncookies\n\n\nad posting\n\n\n\n\nThis article explores the concept of using virtual phone numbers and anonymous accounts to interact with service providers, access websites like bilibili, store cookies, and monetize these accounts through ad posting. It also highlights the use of Bugmenot for aid in accessing such services.\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\ndownload/collect info of hack tools\n\n\n\n\n\n\n\npackage information\n\n\nman command\n\n\nGitHub API\n\n\npackage managers\n\n\nsearch skills\n\n\nprogramming language libraries\n\n\ntools\n\n\n\n\nThis article discusses different methods for accessing package information and improving search skills using tools like the ‘man’ command, GitHub API, and package managers. It also provides tips on utilizing programming language libraries to enhance your search capabilities.\n\n\n\n\n\n\nDec 12, 2022\n\n\n\n\n\n\n\n\nbadass tricks, earning plans\n\n\n\n\n\n\n\nsoftware viruses\n\n\nencrypted porn/copyrighted material sharing\n\n\ncryptocurrency mining through GitHub\n\n\nmoney laundering\n\n\nGitHub automation with Terraform\n\n\ndetecting malicious activities\n\n\nonline security\n\n\n\n\nThis text highlights various methods for carrying out malicious activities online, including planting viruses in software, sharing encrypted adult content and copyrighted material, and mining cryptocurrency through GitHub. The importance of money laundering to avoid detection is stressed, and the use of Terraform for automating GitHub tasks is suggested.\n\n\n\n\n\n\nDec 11, 2022\n\n\n\n\n\n\n\n\nfree proxies: openit proxy pool has been seized, what to do\n\n\n\n\n\n\n\nfree proxies\n\n\nClash\n\n\nSSR\n\n\nProxy\n\n\nShadowSocks\n\n\nV2Ray\n\n\nFanqiang\n\n\n\n\nThis article provides insights into accessing free proxies using tools like Clash, SSR, Proxy, ShadowSocks, V2Ray, and Fanqiang. It recommends searching GitHub for updated repositories and utilizing resources such as proxyscan.io, Telegram bots, self-hosted options, or cloud/CI alternatives. Additionally, Lantern is suggested to be used alongside Clash-ctl controllers.\n\n\n\n\n\n\nDec 11, 2022\n\n\n\n\n\n\n\n\ndocker usage issues\n\n\n\n\n\n\n\nDocker\n\n\nMySQL\n\n\nDatabases\n\n\nVolumes\n\n\nPip URLs\n\n\nContainer Management\n\n\nNetworking\n\n\n\n\nThis article delves into the practicalities of using Docker, addressing various tasks like logging into MySQL, configuring databases, managing volumes, optimizing pip URLs, exporting/importing containers, tweaking port mappings, creating custom networks, assigning IPs, and troubleshooting container communication problems. Comments A and B provide valuable insights and tips for efficient Docker usage.\n\n\n\n\n\n\nDec 11, 2022\n\n\n\n\n\n\n\n\nAwesome Transformer & Transfer Learning in NLP\n\n\n\n\n\n\n\ntransformers\n\n\nGPT-NeoX\n\n\nOPT\n\n\nconversational AI\n\n\nBERT tools\n\n\ntext generation\n\n\nlanguage classification\n\n\n\n\nRecent advancements in Transformers technology have enabled the creation of large language models such as GPT-NeoX and OPT, which have significantly improved conversational AI capabilities. BERT tools are now used for text generation, question answering, and language classification using open-source resources like Hugging Face’s Transformers library and TensorFlow 2.0 for multi-lingual modeling.\n\n\n\n\n\n\nDec 10, 2022\n\n\n\n\n\n\n\n\nnodejs NODE_PATH for npm global package installation\n\n\n\n\n\n\n\nnpm\n\n\nNODE_PATH\n\n\nenvironment variable\n\n\nglobal package installation\n\n\noperating systems\n\n\nZSH\n\n\nBash\n\n\nFish\n\n\nWindows\n\n\nTermux\n\n\nKali\n\n\nMacOS\n\n\n\n\nThis article provides a comprehensive guide on how to set the NODE_PATH environment variable for npm global package installation across different operating systems. It explains the process in detail for ZSH, Bash, Fish, Windows, Termux, Kali, and MacOS, ensuring proper importing of packages from specific paths without any issues.\n\n\n\n\n\n\nDec 10, 2022\n\n\n\n\n\n\n\n\npwntools usage example\n\n\n\n\n\n\n\nrctf\n\n\npython\n\n\npwntools\n\n\nsolving\n\n\nremote server\n\n\ndata processing\n\n\nx value\n\n\n\n\nThis Python script utilizes pwntools to tackle a RCTF problem. It establishes a connection with a remote server, processes data received, and outputs values Q, T, U, and NUM. The script employs frequency analysis on the data to identify the most frequently occurring positions of a specific x value, ultimately cracking it.\n\n\n\n\n\n\nDec 10, 2022\n\n\n\n\n\n\n\n\nmake a quantum computer at home\n\n\n\n\n\n\n\nquantum computer\n\n\nopen source software\n\n\nhardware project\n\n\nCAD\n\n\n3D printing\n\n\nPCB manufacturing\n\n\nprofitable project\n\n\n\n\nThis article explores the idea of building a quantum computer at home using open-source software and hardware, along with skills such as CAD, 3D printing, and PCB manufacturing. However, it encourages readers to consider alternative projects with more potential for profit.\n\n\n\n\n\n\nDec 10, 2022\n\n\n\n\n\n\n\n\ntyping backtick “`” with my current splitable keyboard\n\n\n\n\n\n\n\ntyping\n\n\nkeyboard\n\n\nbacktick\n\n\nsplitable\n\n\nalternative method\n\n\ncomputer keyboard\n\n\nsymbols\n\n\n\n\nThe text explores the challenges of typing a backtick symbol using a splitable keyboard and presents an alternative technique to efficiently input this special character.\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\nadd certificate to termux, especially for fastgithub\n\n\n\n\n\n\n\nTermux\n\n\ncertificate\n\n\nfastgithub\n\n\nopenssl-tools\n\n\nadd-trusted-certificate\n\n\ncurl\n\n\nchromebook\n\n\n\n\nThis article provides detailed instructions on how to add a certificate to Termux for fastgithub, including steps for installing OpenSSL tools and using the add-trusted-certificate command. Additionally, an alternative method is explained for chromebooks involving nginx and configuring proxy settings.\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\nthe most powerful work environment setup, introduced by us\n\n\n\n\n\n\n\nwork_environment\n\n\nwireless_keyboard\n\n\ntyping_training\n\n\ncomputer_stands\n\n\nproduct_bundling\n\n\nadvertising\n\n\nmedia_content\n\n\n\n\nA comprehensive guide is provided on how to create a lucrative work environment by developing a sleek, splitable wireless keyboard, optimizing typing training software with an intuitive interface, enhancing computer stands for seamless connectivity, bundling products together, and incorporating ads alongside media content.\n\n\n\n\n\n\nDec 9, 2022\n\n\n\n\n\n\n\n\nmake-a-video and its related text to video projects\n\n\n\n\n\n\n\ntext-to-video\n\n\nmake-a-video\n\n\nMaria\n\n\nOFA\n\n\nGEN-2\n\n\nCogVideo\n\n\nNuwa\n\n\nMoCoGAN\n\n\ntgan-pytorch\n\n\nRedditube\n\n\nNingyov\n\n\nmultimodal\n\n\ndeep learning\n\n\nvideo generation\n\n\n\n\nText-to-video projects like make-a-video, Maria, OFA, GEN-2, CogVideo, Nuwa, MoCoGAN, tgan-pytorch, Redditube, and Ningyov employ multimodal techniques with distinctive features, leveraging deep learning for diverse video generation tasks.\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n\n\nlearn about ai hacking\n\n\n\n\n\n\n\nAI hacking tools\n\n\nnetwork analysis\n\n\nDeepLocker\n\n\nAcunetix\n\n\nNessus\n\n\nHashcat\n\n\nbrute-force attack\n\n\nMD5 hash type\n\n\nJohn the Ripper\n\n\nAircrack-ng\n\n\n\n\nAI hacking tools, such as network analysis and custom malware creators like DeepLocker, are becoming increasingly popular for efficient attacks. These tools can also be legally used for security research and testing with tools like Acunetix and Nessus. Hashcat is a powerful password-cracking tool used for generating and outputting password lists in the terminal and is often employed in brute-force attack mode with MD5 hash type. John the Ripper and Aircrack-ng are other popular AI hacking tools.\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n\n\ntalk to openai chatgpt to learn a few on paraphrasing, title generation\n\n\n\n\n\n\n\nAI\n\n\ntext generation\n\n\nparaphrasing\n\n\nlanguage models\n\n\nLSA\n\n\nLDA\n\n\nPython\n\n\n\n\nThis article delves into AI techniques for text generation and paraphrasing, specifically exploring language models like LSA and LDA in Python. Comment A dives into word matrix decomposition to create attention-grabbing titles, while Comment B discusses the capabilities and drawbacks of Latent Semantic Analysis (LSA) in paraphrasing.\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n\n\naccess kali on chromebook or anywhere\n\n\n\n\n\n\n\nKali Linux\n\n\nChromebook\n\n\nTTYD\n\n\nX11VNC\n\n\nNovnc\n\n\nClipboard Sharing\n\n\nCommand Line\n\n\n\n\nThis tutorial provides step-by-step instructions for accessing Kali Linux on Chromebook using ttyd, x11vnc, and novnc. It includes detailed setup procedures for each tool, demonstrates novnc’s clipboard sharing feature, and offers the necessary commands to help users make the most of their experience.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\n0day exploits, AFL(american fuzzy lop), AFL++\n\n\n\n\n\n\n\nfuzzing\n\n\nAFL\n\n\nAFL++\n\n\nvulnerability discovery\n\n\nseed generation\n\n\nSkyfire\n\n\nLearn&Fuzz\n\n\nstatic analysis\n\n\ndynamic analysis\n\n\nLSTM\n\n\nRL\n\n\nILF\n\n\nVUzzer\n\n\nGreyOne\n\n\nefficiency metrics\n\n\nsoftware testing\n\n\n\n\nThis article delves into the world of fuzzing tools like AFL and AFL++ for identifying vulnerabilities. It also covers seed generation techniques such as Skyfire and Learn&Fuzz. Furthermore, it explores static and dynamic analysis methods including LSTM, RL, ILF, VUzzer, GreyOne, and discusses efficiency metrics in software testing.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\nhuman-in-the-loop AI training and models\n\n\n\nhuman-in-the-loop AI\nGitHub topics\ndalle-flow\nargilla\nrefinery\nHuman-In-The-Loop-Learning\nMariusmcl's instructGPT-PyTorch\nCarperAI's TRLx\n\n\n\nThis article dives into human-in-the-loop AI training and models, specifically examining GitHub topics such as Dalle-flow, Argilla, Refinery, Human-in-the-loop-learning, Mariusmcl's InstructGPT-PyTorch, and CarperAI's TRLx. The discussion focuses on how these tools and methodologies are transforming the AI landscape by involving human feedback in training processes.\n\n\n\n`Dec 7, 2022`{=html}\n\n\n\n\n\n\nRL, trajectory prediction, model predictive control\n\n\n\n\n\n\n\nReinforcement Learning\n\n\nTrajectory Prediction\n\n\nModel Predictive Control\n\n\nddpg-usv-asmc\n\n\nDeep-Reinforcement-Learning-Algorithms-with-PyTorch\n\n\nstable-baselines3\n\n\nPPO\n\n\n\n\nThis article delves into Reinforcement Learning (RL), trajectory prediction, and model predictive control. It highlights related projects such as ddpg-usv-asmc, Deep-Reinforcement-Learning-Algorithms-with-PyTorch, stable-baselines3, and PPO. Additionally, it provides further resources for exploring deep RL.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\nuseful sources on cyber attack\n\n\n\n\n\n\n\ncybersecurity\n\n\ntools\n\n\nresources\n\n\ninformation gathering\n\n\nvulnerabilities\n\n\nsecurity analysis\n\n\nrisk management\n\n\n\n\nThis article highlights several cybersecurity tools and resources, including theHarvester, Shodan, Metagoofil, Searchcode, SpiderFoot, and Babel X. These tools aid in information gathering and exploiting vulnerabilities for security analysis and risk management.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\nsome notes just like me: today i learned (til)\n\n\n\n\n\n\n\nGitHub\n\n\nrepository\n\n\nTIL\n\n\nlearning\n\n\ninsights\n\n\nbenthecoder\n\n\n\n\nThis article discusses a GitHub repository called ‘Today I Learned’ (TIL), where users share their daily learnings and insights. The repository, accessible at this link, encourages continuous learning and knowledge sharing among its community.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\nCyber Grand Challenge DARPA machine automated cyber attack\n\n\n\n\n\n\n\nDARPA\n\n\nmachine learning\n\n\nsoftware exploits\n\n\nassembly\n\n\nPython\n\n\nNeural Machine Translation\n\n\nnatural language descriptions\n\n\n\n\nThe DARPA competition utilizes machine learning to generate software exploits in assembly and Python using Neural Machine Translation for natural language descriptions. This includes modifying Java bytecode and filtering HTML requests.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\n直接调用安卓方法 frida 直接调用二进制里面的方法\n\n\n\n\n\n\n\nFrida\n\n\nAndroid\n\n\nSoftware framework\n\n\nBinary code\n\n\nMethod calling\n\n\nHooking native methods\n\n\nArticle links\n\n\n\n\nThe text offers a compilation of articles that guide users on utilizing Frida, an open-source software framework, to interact with Android methods and modify native code through direct function calls and hook implementations.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\ntools from breachforums\n\n\n\n\n\n\n\ncybersecurity\n\n\nSecurity\n\n\nhacking\n\n\nNetwork Scanning\n\n\nwebapp\n\n\nwebhooks\n\n\nport scanning\n\n\npassword recovery\n\n\nQualysGuard\n\n\nWebInspect\n\n\nHashcat\n\n\n\n\nThis article discusses popular security tools used for various tasks such as web application scanning, port scanning, and password recovery. It provides examples of tools like QualysGuard, WebInspect, Hashcat, L0phtCrack, IKECrack, Medusa, Cain and Abel, and Zenmap, which are commonly utilized in the field of cybersecurity.\n\n\n\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\nmirror sites change\n\n\n\n\n\n\n\nTaobao\n\n\nnpm mirror sites\n\n\nblocking IP ranges\n\n\nproxies\n\n\ntopsap\n\n\npip\n\n\nindex URL\n\n\n\n\nBoth comments address the issue of Taobao’s npm mirror sites blocking specific IP ranges, leading to the need for proxies. They offer potential solutions such as using topsap or configuring pip with a new index URL.\n\n\n\n\n\n\nDec 6, 2022\n\n\n\n\n\n\n\n\nSEO search engine optimization SEMrush alternative\n\n\n\n\n\n\n\nSEO\n\n\nSemrush alternatives\n\n\nopen-source tools\n\n\ncompetitive analysis\n\n\nkeyword research\n\n\nbacklink research\n\n\ncontent optimization\n\n\n\n\nThis article delves into open-source alternatives to Semrush for conducting various SEO tasks such as competitive analysis, keyword research, backlink research, content optimization, rank tracking, and site auditing. It highlights various tools and resources that are freely available online and can be used by businesses and individuals alike.\n\n\n\n\n\n\nDec 6, 2022\n\n\n\n\n\n\n\n\nchatgpt\n\n\n\n\n\n\n\ngenerative_question_answering\n\n\nreinforcement_learning_language_models\n\n\nopenai\n\n\ncarperai\n\n\nrallio67s_dataset\n\n\nkoboldai\n\n\nopt\n\n\ngpt_neo\n\n\nsentence_transformers\n\n\nchatgpt_deployment\n\n\nmarketing_customer_service\n\n\n\n\nThis article delves into the integration of generative question-answering and reinforcement learning in language models. It highlights projects such as OpenAI, CarperAI, Rallio67’s dataset, KoboldAI, OPT, GPT-Neo, Sentence Transformers, ChatGPT deployment, and various marketing/customer service applications.\n\n\n\n\n\n\nDec 6, 2022\n\n\n\n\n\n\n\n\nraspberry pi tweaks\n\n\n\n\n\n\n\nWiFi\n\n\nWifi switch\n\n\nwireless network\n\n\nNetwork Scanning\n\n\nwifi\n\n\nSSL pinning\n\n\nremote connection\n\n\nRaspberry Pi\n\n\nWi-Fi troubleshooting\n\n\n5G connectivity\n\n\nFrequency adjustment\n\n\nSSID scanning\n\n\nLogin credentials update\n\n\nDHCPCD service recovery\n\n\nDocker Wi-Fi connection\n\n\n\n\nIn this article, you will learn how to troubleshoot and configure Wi-Fi connections on a Raspberry Pi. You will discover how to work with 5G connectivity, adjust frequencies, scan for SSIDs, update login credentials, and recover the DHCPCD service. Additionally, you will set Wi-Fi connection details specifically for use with Docker.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nmake game cheats, buy game cheats, game hacks\n\n\n\n\n\n\n\ngame cheats\n\n\naimbots\n\n\ngame hacking\n\n\nreverse engineering\n\n\nscreen reading\n\n\nmouse/keyboard control\n\n\nuseful resources\n\n\n\n\nThis article explores the world of game cheats, particularly aimbots and game hacking as a form of reverse engineering. It delves into the process of creating and acquiring these cheats, which often involve reading the screen and controlling mouse/keyboard actions. Additionally, it highlights useful resources such as Guided Hacking and Phantom Overlay for those interested in this field.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nddddocr captcha resolve recognition\n\n\n\n\n\n\n\nddddocr\n\n\ncaptcha recognition\n\n\nBaidu RotNet\n\n\nPyPi installation\n\n\ntutorials\n\n\nimage processing\n\n\nartificial intelligence\n\n\n\n\nddddocr is a captcha recognition and resolution tool specifically designed for Baidu RotNet. It can be installed from PyPi and tutorials are available to guide its usage.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nctf related\n\n\n\n\n\n\n\nCapture the Flag\n\n\nCTF competitions\n\n\nctfhub.com\n\n\nctftime.org\n\n\nctf-tools\n\n\nctf-wiki.org\n\n\nresources for CTF participants\n\n\n\n\nThis article highlights three valuable resources for participants in Capture the Flag (CTF) competitions: ctfhub.com, ctftime.org, and ctf-tools from ctf-wiki.org. These websites and tools offer useful information and assistance to help competitors navigate and excel in CTF events.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\n(de)obfustication, junk code insertion and removal\n\n\n\n\n\n\n\ndeobfuscation\n\n\njunk code\n\n\npackers\n\n\nThemida\n\n\nCode Virtualizer\n\n\nVMProtect\n\n\nExeCryptor\n\n\nPDF guide\n\n\nGitHub topics\n\n\nIdA Pro\n\n\n\n\nThis text delves into the process of (de)obfustication, which encompasses techniques such as adding or removing redundant code and employing packers like Themida, Code Virtualizer, VMProtect, and ExeCryptor. The article furnishes details on a PDF and GitHub topics addressing protectors and junk code generators, along with a guide on utilizing IdA Pro for removing unnecessary code.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nthemida unpacker\n\n\n\n\n\n\n\nCACANi software\n\n\nThemida unpacker\n\n\nunlicense\n\n\nmanual unpacking\n\n\ndissatisfaction\n\n\nsoftware review\n\n\ntedious process\n\n\n\n\nA user shares their disappointment with the CACANi software and looks for ways to unpack Themida or obtain an unlicense. They explain that manually unpacking Themida is a cumbersome task.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nnctf writeups\n\n\n\n\n\n\n\nNCTF\n\n\n2022 competition\n\n\nguide\n\n\nbinwalk\n\n\nGitHub repositories\n\n\nSQL injection\n\n\nchallenges\n\n\n\n\nJoin the NCTF 2022 competition and get ready to put your skills to the test! The summary outlines essential resources such as binwalk, GitHub repositories, and SQL injection techniques to help you conquer the challenges. Get started today and showcase your talents on the global stage!\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nopenai codex chatgpt dalle-2 account registration\n\n\n\n\n\n\n\nChatGPT\n\n\nDALL-E 2\n\n\nregistration\n\n\nresources\n\n\ndiscord chats\n\n\nsearch engines\n\n\npaid sources\n\n\n\n\nThis article provides various resources for registering OpenAI’s ChatGPT and DALL-E 2 accounts. The resources include discord chats, search engines, paid sources, SMS platforms, tutorials, and warnings about possible blocking during the registration process.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nwebpage translator plugin\n\n\n\n\n\n\n\nwebpage\n\n\ntranslator\n\n\nplugin\n\n\nbrowser\n\n\nsoftware\n\n\non-the-fly\n\n\ninformation\n\n\n\n\nA webpage translator plugin for browsers or similar software that enables users to translate webpages in real-time, facilitating access to information in unfamiliar languages.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nvxworks binary reverse engineering\n\n\n\n\n\n\n\nreverse engineering\n\n\nVxPwn\n\n\nVxWorks\n\n\nembedded devices analysis\n\n\nVxHunter\n\n\nNOE7701\n\n\ndevice backdoors\n\n\n\n\nCapstone is a versatile tool used for reverse engineering, particularly in the analysis of VxPwn exploits and VxWorks-based embedded devices. With its compatibility with VxHunter, it facilitates in-depth examination of these systems. Additionally, Capstone can reveal hidden backdoors within NOE7701 devices.\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nBypassing Web Application Firewalls with bapp: A Comprehensive Guide\n\n\n\n\n\n\n\nWAF\n\n\nbypass\n\n\nWeb Application Firewalls\n\n\nbapp\n\n\nhacken.io\n\n\nPortSwigger Store\n\n\nguide\n\n\n\n\nLearn how to bypass Web Application Firewalls (WAFs) with the help of a guide available at hacken.io/discover and a tool called bapp for WAF bypass. The bapp tool is also available in the PortSwigger store.\n\n\n\n\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\nExploring Python Libraries and Resources for Nmap Network Scanning\n\n\n\n\n\n\n\nPython\n\n\nNmap\n\n\nNetwork Scanning\n\n\nLibraries\n\n\nResources\n\n\n\n\nThis article provides an overview of several Python libraries and resources available for working with the Nmap network scanning tool. It covers python3-nmap, nmapthon, and python-nmap, along with their respective documentation, allowing readers to choose the best option for their needs.\n\n\n\n\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\nMastering Metasploit Python Scripting: Tutorial and Projects\n\n\n\n\n\n\n\nMetasploit\n\n\nPython scripting\n\n\nTutorial\n\n\npymetasploit3\n\n\npymetasploit\n\n\nMSFRPC library\n\n\n\n\nThis blog post delves into Metasploit Python scripting, providing a tutorial for those interested. It also highlights two projects related to this subject: pymetasploit3 and pymetasploit. The latter is described as a comprehensive MSFRPC library.\n\n\n\n\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\nCracking BurpSuite Pro: Exploiting Web App Vulnerabilities with Python API Client\n\n\n\n\n\n\n\nBurpSuite Pro\n\n\nWeb application security\n\n\nVulnerability scanning\n\n\n0day exploits\n\n\nDynamic web apps\n\n\nPython unofficial API client\n\n\nSecurity tool\n\n\n\n\nBurpSuite Pro is a comprehensive web application security tool designed to identify common vulnerabilities and 0day exploits in dynamic web applications. With its ability to be cracked, it offers an extra layer of protection against potential threats. Additionally, a Python unofficial API client is available for enhanced functionality and customization.\n\n\n\n\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\nDiscovering Zero-Day Exploits and Vulnerabilities in School Management Systems\n\n\n\n\n\n\n\nedusrc\n\n\nbluecms\n\n\nzero-day exploits\n\n\nvulnerabilities\n\n\nschool management systems\n\n\nsecurity issues\n\n\n\n\nA list of potential zero-day exploits and vulnerabilities in school management systems, including links to resources for understanding and mitigating the ‘edusrc 0day’ and ‘bluecms 0day’ issues.\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\n\n\nExploiting Log4j Vulnerability with Fofa API: A Comprehensive Guide\n\n\n\n\n\n\n\nLog4j\n\n\nvulnerability\n\n\nexploit\n\n\nFofa API\n\n\nsearching\n\n\nquerying techniques\n\n\nresources\n\n\n\n\nThis article discusses the exploitation of the Log4j vulnerability using Fofa API, offering resources for effective search and query techniques.\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\n\n\nhackthebox\n\n\n\n\n\n\n\ncybersecurity\n\n\nHackTheBox\n\n\nvirtual hacking environment\n\n\nalternatives\n\n\n11topbestalternatives.com/hack-the-box/\n\n\nalternativeto.net/software/hack-the-box/\n\n\nwriteups\n\n\n\n\nHackTheBox is a cybersecurity platform that provides users with a virtual hacking environment for practice and training. Unlike traditional CTF competitions, HackTheBox features real servers to enhance the learning experience. While there are alternatives such as 11topbestalternatives.com/hack-the-box/ and alternativeto.net/software/hack-the-box/, the platform can be accessed through its official website. Additionally, numerous writeups and guides are available online to assist users in their training.\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\n\n\nhacker forums\n\n\n\n\n\n\n\nhacker forums\n\n\ncybersecurity websites\n\n\ntools\n\n\nresources\n\n\nexploits\n\n\nservices\n\n\nprofessionals\n\n\n\n\nThis article highlights various hacker forums and cybersecurity websites that offer valuable resources and tools to professionals in the field, including but not limited to: Leakbase, Breached, Xss, phrack.org, whitehats.com, nhs8.com, packetstormsecurity.com, and securityfocus.com.\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\nExploring Popular AI Libraries and Tools for Various Tasks\n\n\n\nAI\nLibraries\nTools\nRecommendation systems\nSurprise\nLightFM\nTime series forecasting\nProphet\nSubword embeddings\nBpemb\nXGBoost\nChakin\nH2O AutoML\nAwesome H2O\nNumenta's Nupic doc\nDESlib\nTFlearn\n\n\n\nThis article highlights popular AI libraries and tools for different tasks, such as recommendation systems (Surprise, LightFM), time series forecasting (Prophet), subword embeddings (Bpemb), and more including XGBoost, Chakin, H2O AutoML, Awesome H2O, Numenta's Nupic doc, DESlib, and TFlearn. Each library is explained in detail to help readers understand their features and capabilities.\n\n\n\n`Nov 28, 2022`{=html}\n\n\n\n\n\n\nMastering Anonymous Payment Methods and Disguised Email Addresses\n\n\n\n\n\n\n\nanonymous payment methods\n\n\ndisguised email addresses\n\n\nmagnet links\n\n\npassword-protected content\n\n\nviruses\n\n\n\n\nThis article delves into the creation of anonymous payment methods and the usage of masked email addresses for activities such as generating magnet links, producing password-protected adult content or software with viruses. It offers insights into techniques to protect privacy and carry out potentially sensitive transactions.\n\n\n\n\n\n\nNov 28, 2022\n\n\n\n\n\n\n\n\nMastering Interactive Interfaces and GUIs with Python\n\n\n\n\n\n\n\ninteractive_interfaces\n\n\nGUIs\n\n\nCustomTkinter\n\n\nCLI_tools\n\n\nRich\n\n\nTextual\n\n\ncommand_lines\n\n\n\n\nThis article covers interactive interfaces, focusing on GUIs built with CustomTkinter and CLI tools such as Rich and Textual. It also provides resources for mastering command lines, XPath testing, shell commands, and implementing design patterns in Python, along with live searching techniques.\n\n\n\n\n\n\nNov 27, 2022\n\n\n\n\n\n\nHy Programming Language Enhancements for Automation and IDE Support\n\n\n\nhy programming language\nautomatic reloading\nexception handling\nautomation tool\nexpression wrapping\nIDE support\nVim, Emacs, Neovim's Nelean plugin\n\n\n\nThe article highlights updates to the hy programming language, introducing features such as automatic reloading and enhanced exception handling. These modifications allow hy to be utilized as an automation tool and overcome constraints with expression wrapping. The improvements also benefit IDE support, particularly in Vim, Emacs, and Neovim's Nelean plugin.\n\n\n\n`Nov 25, 2022`{=html}\n\n\n\n\n\n\nIntroducing the Open-Source Chinese Font ‘LxgwWenKai’ Based on Klee One\n\n\n\n\n\n\n\nOpen-source\n\n\nChinese font\n\n\nLxgwWenKai\n\n\nGitHub\n\n\nKlee One font\n\n\nFont design\n\n\nTypography\n\n\n\n\nLxgwWenKai is an open-source Chinese font inspired by the Klee One font, available on GitHub. It features a clean and modern appearance that is suitable for various design projects.\n\n\n\n\n\n\nNov 22, 2022\n\n\n\n\n\n\n\n\nlua python bridge\n\n\n\n\n\n\n\nLua Python Bridge\n\n\nLunatic Python\n\n\nLanguage integration\n\n\nCommunication\n\n\nProgramming languages\n\n\nSoftware tools\n\n\n\n\nThis article discusses the Lua Python Bridge, focusing on the ‘Lunatic Python’ tool that allows for easy communication between the Lua and Python programming languages.\n\n\n\n\n\n\nNov 12, 2022\n\n\n\n\n\n\n\n\nsplash: webpage rendering service\n\n\n\n\n\n\n\nwebpage rendering\n\n\nanimation capabilities\n\n\nSplash service\n\n\ndocumentation\n\n\nSplash documentation\n\n\n\n\nSplash is a webpage rendering service offering animation capabilities, further detailed in the Splash documentation.\n\n\n\n\n\n\nNov 12, 2022\n\n\n\n\n\n\n\n\nCall python in clojure, clojure-python bridge\n\n\n\n\n\n\n\nPython\n\n\nClojure\n\n\nlibpython-clj\n\n\nIntegration\n\n\nProgramming Languages\n\n\nSoftware Development\n\n\nEmbedding\n\n\n\n\nThis article explores the integration between Python and Clojure using the libpython-clj library. The author explains how to call Python functions from Clojure or embed Clojure code within Python, making it easier to leverage the strengths of both languages in a single project.\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\ncall ruby from python\n\n\n\n\n\n\n\nruby\n\n\npython\n\n\ninteroperability\n\n\ntools\n\n\nrb_call\n\n\npuby\n\n\nlanguage\n\n\n\n\nThis article discusses two tools, rb_call and puby, which enable Python programs to call Ruby functions and leverage Ruby libraries. These tools promote seamless interaction between Python and Ruby, enhancing the interoperability between the two languages.\n\n\n\n\n\n\nNov 11, 2022\n\n\n\n\n\n\n\n\nBDD behavior driven development\n\n\n\n\n\n\n\nBDD\n\n\nSoftware development\n\n\nTest-Driven Development\n\n\nDomain-Driven Design\n\n\nHuman-readable tests\n\n\nBehave\n\n\npytest-bdd\n\n\n\n\nBDD (Behavior Driven Development) is a software development approach that combines the benefits of Test-Driven Development (TDD) and Domain-Driven Design (DDD). It emphasizes writing tests in a human-readable format using natural language, allowing for better collaboration between stakeholders. The content provides resources for two popular BDD frameworks: Behave and pytest-bdd.\n\n\n\n\n\n\nNov 9, 2022\n\n\n\n\n\n\n\n\ngenerate noise image, noise video, noise audio with ffmpeg for test\n\n\n\n\n\n\n\nffmpeg\n\n\nnoise videos\n\n\nnoise images\n\n\nTV noise simulation\n\n\nvideo generation\n\n\nimage generation\n\n\nvideo editing\n\n\n\n\nIn this article, you will learn how to generate noise videos and images using the ffmpeg software. The commands demonstrated will teach you how to create a 5-second TV noise video by employing different methods.\n\n\n\n\n\n\nNov 9, 2022\n\n\n\n\n\n\n\n\nneo4j, mindsdb, milvus, peewee\n\n\n\n\n\n\n\nPython\n\n\nNeo4j Graph Data Science\n\n\nSQLAlchemy\n\n\nLightwood AutoML\n\n\nPeewee ORM\n\n\nMilvus Vector Databases\n\n\nPypika\n\n\n\n\nLearn how to use Python for Neo4j Graph Data Science, and explore SQLAlchemy monkey patches, Lightwood AutoML framework, and Peewee ORM. Discover the documentation for Milvus vector databases, Neo4j, Pypher, neopy, pygds, Pypika for SQL query building, mindsdb_native, and mindsdb_python_sdk for native Python mindsdb usage.\n\n\n\n\n\n\nNov 9, 2022\n\n\n\n\n\n\n\n\nRemove bad/large files from git repo history\n\n\n\n\n\n\n\nBFG Repo Cleaner\n\n\nGitHub\n\n\nSensitive data removal\n\n\njar file\n\n\nbrew installation\n\n\nalternative tools\n\n\nconversion cheat sheet\n\n\n\n\nThis article provides step-by-step instructions on how to remove sensitive data from a GitHub repository using BFG Repo Cleaner. It highlights the benefits of using BFG over other tools and offers a conversion cheat sheet for those who prefer using Git Filter-Repo.\n\n\n\n\n\n\nNov 8, 2022\n\n\n\n\n\n\n\n\n百度贴吧app接口\n\n\n\n\n\n\n\nBaidu\n\n\nTieba\n\n\napp\n\n\nAPI\n\n\nhomepage\n\n\ncommunities\n\n\nchannels\n\n\n\n\nThe Baidu Tieba app API enables access to various sections such as the homepage, communities, channels, and messaging. It offers features like hot searches, recommended content, trending topics, live streaming, video section, and communication with other users.\n\n\n\n\n\n\nNov 8, 2022\n\n\n\n\n\n\n\n\nHot Reloading, Exception Capture\n\n\n\n\n\n\n\nHot Reloading\n\n\nException Capture\n\n\nPython Code Refactoring\n\n\nReloading\n\n\njurigged\n\n\nDebugPy\n\n\nReloadium\n\n\n\n\nThis article discusses Hot Reloading and Exception Capture tools like reloading, jurigged, DebugPy, and Reloadium that assist Python developers in efficiently refactoring code by allowing them to quickly modify and test changes without requiring a program restart.\n\n\n\n\n\n\nNov 8, 2022\n\n\n\n\n\n\n\n\nReact Native\n\n\n\n\n\n\n\nreact native\n\n\ncross-platform development\n\n\nmobile apps\n\n\ndesktop apps\n\n\ndevelopment tools\n\n\nNativeScript\n\n\nKivy\n\n\nRoboto\n\n\n\n\nReact Native is a popular tool for creating cross-platform mobile and desktop apps, offering real-time feedback to developers as they make changes. Similar tools in the market include NativeScript, Kivy, and Roboto.\n\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n\n\n国信iquant平台分析\n\n\n\n\n\n\n\nquantitative trading\n\n\n国信iquant\n\n\n迅投qmt\n\n\nXtQuant\n\n\nGitHub\n\n\nqmt mini mode\n\n\n国盛证券\n\n\n\n\nThis blog post provides a collection of links and information about the 国信iquant quantitative trading platform, built upon the 迅投qmt platform. It offers resources for downloading and installing the platform, as well as guidance on using its mini mode in 国盛证券. The author also mentions XtQuant’s GitHub repository and other related platforms.\n\n\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n\n\n\nmixing different version of python libraries and pass environment variables beforehand\n\n\n\n\n\n\n\nmpython3\n\n\nPython scripts\n\n\nEnvironment variables\n\n\nJAVA_HOME\n\n\nPYTHONPATH\n\n\nLibrary version mixing\n\n\n\n\nThis article provides a guide on using the `mpython3` command to execute Python scripts. It explains how to set environment variables such as JAVA_HOME and PYTHONPATH beforehand, ensuring correct compatibility with different library versions.\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n\n\nRegister a New File in Android Gallery using Beanshell Code\n\n\n\n\n\n\n\nandroid\n\n\ngallery\n\n\nBeanshell code\n\n\nbroadcast intent\n\n\nmedia scanner\n\n\nfile registration\n\n\nAndroid development\n\n\n\n\nLearn how to register a new file in the Android gallery using Beanshell code. The article explains the process of sending a broadcast intent to scan a specific file and adding it to the Android media scanner, allowing the file to be accessible within the gallery.\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n\n\nbilibili直播api 直播工具 自动直播 自动推流\n\n\n\n\n\n\n\nBilibili\n\n\nLive streaming\n\n\nAutomation tools\n\n\nShop on Bilibili\n\n\nContent generation\n\n\nMonitoring\n\n\nRendering\n\n\n\n\nThis article explores various tools and techniques for automating Bilibili live streaming, including setting up an online store on the platform, strategies for starting live broadcasts, as well as options for content creation, monitoring, and rendering.\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n\n\nandroid packet capture\n\n\n\n\n\n\n\nAndroid\n\n\npacket capture\n\n\nSSL pinning\n\n\nFrida scripts\n\n\nJustTrustMe Xposed\n\n\nSSLUnpinning Xposed\n\n\napk-mitm\n\n\nPCAPdroid-API\n\n\nHTTP proxy\n\n\nADB\n\n\n\n\nThis article explores Android packet capture methods, including disabling SSL pinning and utilizing tools like Frida scripts, JustTrustMe Xposed, SSLUnpinning Xposed, apk-mitm, or PCAPdroid-API. Additionally, it provides step-by-step instructions for setting up an HTTP proxy via ADB.\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n\n\nadb wifi always on\n\n\n\n\n\n\n\nADB\n\n\nAndroid\n\n\nWiFi\n\n\nSecurity\n\n\nPassword Protection\n\n\nEnabling\n\n\nDisabling\n\n\n\n\nThis article provides step-by-step instructions on how to enable and disable ADB over WiFi on Android devices. It also emphasizes the importance of implementing password protection for security reasons.\n\n\n\n\n\n\nNov 4, 2022\n\n\n\n\n\n\n\n\nDiscover ‘问财选股’: The Comprehensive Stock Selection Platform and Python Implementation\n\n\n\n\n\n\n\nstock_selection\n\n\nWenCai XuanGǔ\n\n\nPython\n\n\nAPI\n\n\nfinance\n\n\ninvestment\n\n\nplatform\n\n\n\n\nIntroducing ‘问财选股’ (WenCai XuanGǔ), a stock selection platform with an official website and API tutorial. It also has a Python implementation called ‘pywencai’, providing users with tools for making informed investment decisions.\n\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n\n\nMastering Android Reverse Engineering Tools: IDA, Ghidra, Frida, GDA and Flowdroid\n\n\n\n\n\n\n\nandroid\n\n\nreverse engineering\n\n\nida\n\n\nghidra\n\n\nfrida\n\n\ngda\n\n\nflowdroid\n\n\n\n\nThis article provides a comprehensive guide on Android reverse engineering tools, specifically focusing on IDA, Ghidra, Frida, GDA, and Flowdroid. It explains how to use Frida to attach an existing process and demonstrates its usage with WeChat as an example.\n\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n\n\ntencent jce\n\n\n\n\n\n\n\nTencent JCE\n\n\nTCP protocol\n\n\nProtobuf\n\n\njcestruct\n\n\ndata transmission\n\n\nTcpCommunication module\n\n\nPython programming\n\n\n\n\nTencent JCE is a TCP protocol that shares similarities with Protobuf. It utilizes jcestruct for implementation and can be employed by executing ‘python -m jce’ along with the data. Through TCP communication, the transmitted data can be acquired and deciphered using Python’s TcpCommunication module.\n\n\n\n\n\n\nNov 3, 2022\n\n\n\n\n\n\n\n\nqzone send shuoshuo\n\n\n\n\n\n\n\nQzone automation\n\n\nModules and tools\n\n\nReplacing qzone module\n\n\nLogging in via QR code\n\n\nUploading files with Playwright\n\n\nAnimeAPI for shuoshuo\n\n\nAutomating activities\n\n\n\n\nThis article explores different methods for automating Qzone activities using various modules and tools. It covers replacing the qzone module, logging in via QR code, uploading files with Playwright, and utilizing the AnimeAPI for more than just sending shuoshuo.\n\n\n\n\n\n\nOct 31, 2022\n\n\n\n\n\n\n\n\nkeyword extraction, topic modeling, sentence embedding\n\n\n\n\n\n\n\nNLP\n\n\nkeyword extraction\n\n\ntopic modeling\n\n\nsummarization\n\n\nAllenNLP-models\n\n\nBERT Lang Street\n\n\ndeepmatch\n\n\nfuzzywuzzy\n\n\nstopwordsISO\n\n\nsumy\n\n\npyTextrank\n\n\n\n\nThis article delves into Natural Language Processing (NLP) techniques and tools, discussing methods like keyword extraction, topic modeling, and summarization. It explores popular libraries such as AllenNLP-models, BERT Lang Street, deepmatch, fuzzywuzzy, stopwordsISO, sumy, and pyTextrank, which can be utilized for various NLP tasks.\n\n\n\n\n\n\nOct 29, 2022\n\n\n\n\n\n\n\n\nnvidia driver switch alternatives\n\n\n\n\n\n\n\nNVIDIA\n\n\nDrivers\n\n\nAlternatives\n\n\ntesla-450\n\n\nGLX Configuration\n\n\nCommand Line\n\n\n\n\nThe article explores the options for replacing NVIDIA drivers without resorting to switching them. It suggests utilizing the tesla-450 driver specifically for Alpharetta, and provides a command for updating the GLX configuration with NVIDIA.\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\nuse javascript/html/css to create mobile app, simplifying the processing of creating app\n\n\n\n\n\n\n\nmobile apps\n\n\nJavaScript\n\n\nHTML\n\n\nCSS\n\n\nApache Cordova\n\n\nre-com library\n\n\nReagent\n\n\nClojureScript\n\n\n\n\nDiscover the process of creating mobile apps using JavaScript, HTML, and CSS with Apache Cordova framework or delve into re-com library for Reagent that utilizes ClojureScript components.\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\npeewee related notes\n\n\n\n\n\n\n\nPeewee\n\n\nSQLite ORM\n\n\nFull-text search\n\n\nJSON support\n\n\nGet/update/create actions\n\n\nBaseModel boilerplate code\n\n\nEnhancements\n\n\n\n\nPeewee is an SQLite ORM that offers advanced features like full-text search and JSON support. It also proposes enhancements for get/update/create actions and aims to simplify BaseModel boilerplate code, making it a powerful tool for database operations.\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n临时存储文件 temp fiiles host api\n\n\n\n\n\n\n\ntemporary_file_hosting\n\n\nanonyfiles\n\n\npomf\n\n\nuguu_api\n\n\ncatbox_moe\n\n\ntmpfiles\n\n\ntransfer.sh\n\n\n\n\nThis article discusses temporary file hosting services like Anonyfiles, Pomf-based temp files, Uguu API, Catbox.Moe, TmpFiles, and Transfer.sh, which offer file storage for sharing purposes, fan rewards, and screenshot capturing. The article also highlights various supporting tools such as ShareX, PyUpload, Catmoe Recommend Tools, and Uguu Tools.\n\n\n\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\nb站根据视频内容自动生成推荐的标签\n\n\n\n\n\n\n\nBilibili\n\n\nUpload Restriction\n\n\n30 Seconds Interval\n\n\nAPIs\n\n\nMetadata Tagging\n\n\nPC Web Version\n\n\n\n\nBilibili, a popular Chinese video-sharing platform, has introduced two new APIs for its PC web versions. These APIs aim to restrict users from uploading videos too frequently, by enforcing a one-upload-every-30-seconds policy. Additionally, the platform now automatically generates tags for videos using metadata, enhancing searchability and organization.\n\n\n\n\n\n\nOct 25, 2022\n\n\n\n\n\n\n\n\n关于伪原创的方法总结 自动软文生成器 一键生成软文 伪原创 文案生成器 自动生成软文\n\n\n\n\n\n\n\ncontent_improvement\n\n\npseudo-originality\n\n\nrearrangement\n\n\nintegration\n\n\ncentral_theme\n\n\nscientific_collections\n\n\ntitle_modification\n\n\n\n\nThis article provides insights into various methods to enhance the quality of pseudo-original content. It suggests techniques such as reorganizing and blending information, emphasizing a primary topic, utilizing scientific databases, modifying headings, and refining textual elements.\n\n\n\n\n\n\nOct 24, 2022\n\n\n\n\n\n\n\n\n股票数据源 tick级别数据源 逐笔交易\n\n\n\n\n\n\n\nstock data\n\n\nAPIs\n\n\nTradeX.dll\n\n\nBQTradeX\n\n\nQuantaxis\n\n\nTdxTradeServer\n\n\nNewSinaFinance API\n\n\n\n\nThis article provides resources for acquiring and processing tick-level stock data, such as APIs like TradeX.dll and BQTradeX, and tools like Quantaxis and TdxTradeServer. It specifically focuses on obtaining day, minute, and tick-level data from China’s NewSinaFinance API.\n\n\n\n\n\n\nOct 22, 2022\n\n\n\n\n\n\n\n\n关于做直播 about live streaming\n\n\n\n\n\n\n\nlive broadcast\n\n\nuser experience\n\n\nPython\n\n\nQR code detection\n\n\ncontent filtering\n\n\nchat interactions\n\n\nreward systems\n\n\nlow latency streaming\n\n\nad management\n\n\n\n\nThis article dives into optimizing live broadcasts for an enhanced user experience. It explores the use of Python in a web browser along with various features such as QR code detection, content filtering, interactive chats, reward systems, low latency streaming, and ad management to improve the overall quality and engagement of live broadcasts.\n\n\n\n\n\n\nOct 21, 2022\n\n\n\n\n\n\n\n\n短网址生成器\n\n\n\n\n\n\n\nshort_url\n\n\nBilibili\n\n\nTikTok\n\n\nDouyin\n\n\nQR codes\n\n\nonline_tools\n\n\nsocial_media\n\n\n\n\nThis article highlights the challenge of locating a functional short URL generator, with only Bilibili’s short link being deemed usable. It also speculates that TikTok and Douyin might have similar features but are disinterested in managing them, proposing QR codes as an alternative solution.\n\n\n\n\n\n\nOct 21, 2022\n\n\n\n\n\n\n\n\nMonetizing Bilibili Content with GIFs, QR Codes, and JSON Modification\n\n\n\n\n\n\n\nBilibili\n\n\nPromote content\n\n\nMonetize content\n\n\nGIFs\n\n\nQR codes\n\n\nJSON data\n\n\nAndroid intents\n\n\n\n\nThis article discusses various methods to promote and monetize content on Bilibili, including utilizing GIFs, QR codes, and modifying JSON data for Android intents using Frida. The techniques covered can help creators increase engagement and generate income through their work on the platform.\n\n\n\n\n\n\nOct 18, 2022\n\n\n\n\n\n\n\n\nAGI playground, a place for AGI to act/code freely\n\n\n\n\n\n\n\nartificial intelligence\n\n\nAGI\n\n\nAI playground\n\n\ninterfaces\n\n\nterminal\n\n\nGUI\n\n\nAPI\n\n\n\n\nThis article delves into the topic of artificial general intelligence (AGI) and proposes establishing an AI model training playground. It stresses the significance of utilizing diverse interfaces, such as terminal, GUI, API, and network, for effective AGI development. The author shares their background in AGI research, including projects like AGI, lazero, metalazero, NSJail with Docker, and Firejail.\n\n\n\n\n\n\nOct 16, 2022\n\n\n\n\n\n\n\n\nandroid remote control, app automation\n\n\n\n\n\n\n\nDocker\n\n\npkl\n\n\nAndroid automation\n\n\ndevice discovery\n\n\npy-scrcpy-client\n\n\nemulator support on MacOS M1\n\n\nmonitoring lock/unlock states on Linux\n\n\n\n\nThis text discusses the usage of Docker and pkl for automating Android devices. It covers device discovery, remote control through py-scrcpy-client, emulator support on MacOS M1, and monitoring lock/unlock states on Linux.\n\n\n\n\n\n\nOct 15, 2022\n\n\n\n\n\n\n\n\nmitmchat\n\n\n\n\n\n\n\nMITM attacks\n\n\nDelayed MITM\n\n\nImage embeddings\n\n\nReverse search\n\n\nTopic detection\n\n\nStrangers communication\n\n\nUnknowingly discussing topics\n\n\n\n\nYukio explores delayed MITM attacks, utilizing image embeddings and reverse search to identify instances where strangers inadvertently discuss the same topic prior to disconnecting.\n\n\n\n\n\n\nOct 14, 2022\n\n\n\n\n\n\n\n\n自媒体违禁词获取平台 在线更新违禁词语 censored word online query with latest update\n\n\n\n\n\n\n\nbanned_words\n\n\nonline_platform\n\n\ninternet_media\n\n\nquerying_and_updating\n\n\ntutorial\n\n\ncontent_moderation\n\n\nword_filtering\n\n\n\n\nThe article presents an online platform that allows users to check and modify the list of banned words in internet media. The platform’s tutorial link is also provided.\n\n\n\n\n\n\nOct 12, 2022\n\n\n\n\n\n\n\n\nvideo phash, video deduplication\n\n\n\n\n\n\n\nvideo compression\n\n\nvideo phash\n\n\ndeduplication\n\n\nframe extraction\n\n\nextending video length\n\n\naudio altering\n\n\nbackground music\n\n\n\n\nThis article discusses a method called ‘video phash’ or ‘video deduplication’ for compressing videos. The technique involves extracting one frame from every few frames, lengthening the video and modifying the audio while adding background music. It also recommends not to directly copy videos, change their order, remove watermarks, and extract subtitles by combining content from various sources.\n\n\n\n\n\n\nOct 11, 2022\n\n\n\n\n\n\n\n\npalette extraction from images 色彩搭配提取\n\n\n\n\n\n\n\ncolor\n\n\npalette\n\n\nextraction\n\n\nimages\n\n\ngenerative\n\n\nmatplotlib\n\n\ncolormaps\n\n\nhaishoku\n\n\n\n\nColor palette extraction is a process of obtaining colors from images. Generative methods, like matplotlib colormaps, and extractive methods, such as haishoku, can be used for this purpose. Python and Node.js offer various resources to decide colors based on foreground/background or image colors.\n\n\n\n\n\n\nOct 11, 2022\n\n\n\n\n\n\n\n\nmy notes on paper, hand-written scripts backup\n\n\n\n\n\n\n\nMacBook\n\n\ncommand line\n\n\nGit\n\n\nbackups\n\n\nsyncing notes\n\n\nattachments\n\n\ncommit\n\n\n\n\nThese instructions provide a step-by-step guide on how to sync hand-written notes and scripts backup on a MacBook using the command line and Git. The process involves copying files to a different folder, attaching necessary files, pulling updates from the main branch, and finally committing the changes. This method ensures that your data remains secure and up-to-date.\n\n\n\n\n\n\nOct 11, 2022\n\n\n\n\n\n\n\n\nanime video sites\n\n\n\n\n\n\n\nanime\n\n\nwebsite\n\n\nanime themes\n\n\nvideos\n\n\nthemes\n\n\npopular\n\n\ninformation\n\n\n\n\nDiscover the world of popular anime videos and their captivating themes on the comprehensive website, ‘anime themes’. Dive into an extensive collection of information that will enhance your appreciation for these beloved animated series.\n\n\n\n\n\n\nOct 10, 2022\n\n\n\n\n\n\n\n\nvideo generation/modification (vfx) from text\n\n\n\n\n\n\n\nAI\n\n\nvideo generation\n\n\ntext-to-video\n\n\ntools\n\n\nModelScope\n\n\nHugging Face\n\n\nGitHub\n\n\nsubtitles\n\n\nediting\n\n\nAudioLM\n\n\nmusic composition\n\n\n\n\nAI video generation tools such as Text2Video-Zero, Phenaki Video, Imagen-PyTorch, and Make-a-Video-PyTorch are revolutionizing the video production process. These platforms enable users to generate videos using source material quality, editing capabilities, subtitles, color changes, and even music composition through Google’s AudioLM. Access to these tools is available on ModelScope, Hugging Face, and GitHub.\n\n\n\n\n\n\nOct 9, 2022\n\n\n\n\n\n\n\n\nasync requests with python, used for clash multiple proxy delays\n\n\n\n\n\n\n\nasynchronous requests\n\n\npython libraries\n\n\ndelay management\n\n\nproxies\n\n\naiohttp\n\n\naiohttp-requests\n\n\nrequests-async\n\n\nhttp3\n\n\nmany_requests\n\n\ncurequests\n\n\nasks\n\n\ntrip\n\n\nrequest-futures\n\n\nasynchronous non-blocking servers\n\n\ntrequests\n\n\n\n\nThis article explores different Python libraries for managing asynchronous requests, specifically useful in dealing with delays caused by proxy conflicts. Libraries covered include aiohttp, aiohttp-requests, requests-async (and its successor http3), many_requests, curequests, asks, trip, and request-futures. Additionally, the article delves into asynchronous non-blocking servers, with a focus on trequests.\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\nlazero search tool document preparation\n\n\n\n\n\n\n\nmeta search engine\n\n\nLazure\n\n\ncomprehensive searches\n\n\nstatic resources\n\n\ndynamic resources\n\n\nmarkdown pages\n\n\nGitHub repos\n\n\n\n\nLazure is a meta search engine designed to provide comprehensive searches by aggregating information from various sources, such as static pages and repositories on GitHub, as well as dynamic resources like RSS feeds and social media platforms.\n\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n\n\niot search engines, ip search engines, vulnerable device/server discovery\n\n\n\n\n\n\n\nIoT\n\n\nIP address search engines\n\n\nShodan\n\n\nZoomeye\n\n\nFofa\n\n\nCensys\n\n\nNetwork reconnaissance\n\n\n\n\nThe article delves into the world of IoT and IP address search engines, such as Shodan, Zoomeye, Fofa, and Censys. It also explores various tools available for discovering vulnerable devices/servers and conducting network reconnaissance.\n\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n\n\nmini server, portable server, itx, Mac studio\n\n\n\n\n\n\n\nmini-ITX computer\n\n\nMac Studio comparison\n\n\ncost efficiency\n\n\npower consumption\n\n\nhardware options\n\n\ncooling solutions\n\n\ncase design\n\n\n\n\nThis article compares the cost, power consumption, and hardware options between a mini-ITX computer with high RAM capacity and Apple’s Mac Studio. The discussion covers cooling solutions and case design to prevent overheating.\n\n\n\n\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n\nMastering Command-Line Tools for JSON/HTML Filtering and Formatting\n\n\n\n\n\n\n\ncommand-line\n\n\nJSON filtering\n\n\nHTML formatting\n\n\njq\n\n\njqterm\n\n\nhtmlq\n\n\npup\n\n\n\n\nThis text discusses command-line tools for filtering and formatting JSON/HTML, including jq, jqterm, htmlq, and pup. These tools are essential for hackers to efficiently manipulate data, search, and extract information using regular expressions and filters.\n\n\n\n\n\n\nSep 28, 2022\n\n\n\n\n\n\n\n\nlenovo tb-7304n unlock bootloader\n\n\n\n\n\n\n\nLenovo TB-7304N\n\n\nBootloader unlocking\n\n\nLenovo support\n\n\nIMEI number\n\n\nSerial number\n\n\nXiaomi Max\n\n\nRelevant websites\n\n\n\n\nThis article discusses the challenges of unlocking the bootloader on a Lenovo TB-7304N device and offers guidance on contacting Lenovo for support. The device has a 7-inch screen similar to the Xiaomi Max, and it includes an IMEI number (865486031642692) and serial number (HGCFWF7D). Additionally, it provides links to helpful websites for more information.\n\n\n\n\n\n\nSep 27, 2022\n\n\n\n\n\n\n\n\ncommandline search engine bridger\n\n\n\n\n\n\n\nsemantic search\n\n\nPython libraries\n\n\ncommand line tools\n\n\nSlashdot\n\n\nSourceForge\n\n\nAI-assisted search\n\n\nmedevel.com\n\n\n\n\nThis article explores semantic search techniques using Python libraries, examines command line tools for platforms like Slashdot and SourceForge, delves into AI-assisted search libraries, and provides a curated list of search engines from medevel.com/os.\n\n\n\n\n\n\nSep 26, 2022\n\n\n\n\n\n\n\n\n微软小冰 机器人 用requests库访问最好\n\n\n\n\n\n\n\nJavaScript\n\n\nBing search results\n\n\nChat conversation data\n\n\nAPI calls\n\n\nChatbot\n\n\nMessaging platform applications\n\n\nqingyunke.com\n\n\n\n\nThe JavaScript code handles Bing search results, chat conversation data, and API calls for chatbot or messaging platform applications. It works with qingyunke.com and Microsoft’s small ice robot communication.\n\n\n\n\n\n\nSep 25, 2022\n\n\n\n\n\n\n\n\n涩图api setu bot\n\n\n\n\n\n\n\nSetu Bot API\n\n\nexplicit content\n\n\nerotic images\n\n\nanime clips\n\n\nQQ groups\n\n\npersonal columns\n\n\nNSFW\n\n\n\n\nThis article discusses the Setu Bot API, which enables sharing of explicit content such as erotic images and anime clips. The bot supports posting in QQ groups, personal columns, and adding to videos. It handles both second-hand and third-hand explicit images with adjustable content scale. Users are advised against using R18 content and to be cautious about NSFW content.\n\n\n\n\n\n\nSep 25, 2022\n\n\n\n\n\n\n\n\ngenerate publickey again with rsa private key\n\n\n\n\n\n\n\nRSA\n\n\npublic key generation\n\n\nGit repo sync\n\n\ndeploying public keys\n\n\nduplicate prevention\n\n\n\n\nThis article explains the process of generating a new public key using an RSA private key. It is important when deploying public keys to avoid duplicates, particularly when utilizing the Git repo sync tool.\n\n\n\n\n\n\nSep 25, 2022\n\n\n\n\n\n\n\n\n日站之随想\n\n\n\n\n\n\n\ndaily scanning\n\n\ncomputing power\n\n\nvulnerabilities\n\n\ncybersecurity\n\n\nsearch engines\n\n\nexploits\n\n\nhacking\n\n\nsecurity\n\n\nvulnerability\n\n\nsandbox environment\n\n\ncode repository\n\n\n\n\nThis article delves into daily scanning, a technique that leverages free computing power by identifying and exploiting vulnerabilities in smaller websites. It provides insights on utilizing tools, setting up a secure environment, creating a code repository, and employing search engines for acquiring information and links. The endgame involves infecting sites with viruses or conducting AI experiments.\n\n\n\n\n\n\nSep 25, 2022\n\n\n\n\n\n\n\n\nIntroducing LAVIS: A Library for Language-Vision Intelligence with Cross-Modal Implementations\n\n\n\n\n\n\n\nLAVIS\n\n\nlanguage-vision intelligence\n\n\ninformation retrieval\n\n\nJina\n\n\ncross-modal implementations\n\n\nAI library\n\n\nmultimodal processing\n\n\n\n\nLAVIS is a library that specializes in language-vision intelligence and allows for efficient information retrieval. It offers various cross-modal implementations and works seamlessly with Jina, providing an integrated solution for your AI needs.\n\n\n\n\n\n\nSep 25, 2022\n\n\n\n\n\n\n\n\ndark web search engine\n\n\n\n\n\n\n\ndark web\n\n\nsearch engines\n\n\nOnionSearch\n\n\nAhmia\n\n\nDarksearchio\n\n\nhaystack.onion\n\n\ngjobqjj7wyczbqie.onion\n\n\n\n\nDark Web Search Engines: Tools like OnionSearch, Ahmia, and Darksearchio allow access to various darknet search engines such as haystack.onion and gjobqjj7wyczbqie.onion. These search engines provide a way to navigate and find information on the dark web, which is often used for illicit activities and anonymous communication.\n\n\n\n\n\n\nSep 24, 2022\n\n\n\n\n\n\n\n\nimage blur detection, image quality assessment\n\n\n\n\n\n\n\nimage blur detection\n\n\nimage quality assessment\n\n\nLaplacian transform\n\n\nFourier transform\n\n\nConvolutional Neural Networks\n\n\ndeep learning\n\n\ntraditional methods\n\n\n\n\nThis article dives into the world of image blur detection, exploring both traditional and deep learning-based methods. Traditional techniques make use of Laplacian and Fourier transforms, while deep learning approaches harness the power of Convolutional Neural Networks (CNNs) to classify or score images for blur identification.\n\n\n\n\n\n\nSep 23, 2022\n\n\n\n\n\n\n\n\ntrainable bezier curve multiparameter regressor\n\n\n\n\n\n\n\nBezier curves\n\n\nMultiparameter regression\n\n\nTrainable regressor\n\n\nCurve creation\n\n\nSkew adjustment\n\n\nInput value evaluation\n\n\n\n\nThis text details the development of a trainable Bezier curve multiparameter regressor, which involves creating functions for generating curves, adjusting for skew, and evaluating input values. The creation and evaluation process are discussed in detail, providing insights into how this powerful tool can be used in various applications.\n\n\n\n\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\nimage resize, image padding, image scanning\n\n\n\n\n\n\n\nPython\n\n\nOpenCV\n\n\nImage Resizing\n\n\nImage Cropping\n\n\nTarget Size\n\n\nConditions\n\n\nProcessing\n\n\n\n\nThis Python code uses OpenCV to resize and crop images according to specified conditions, ultimately processing them into smaller versions.\n\n\n\n\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\n语音转文字 stt speech to text\n\n\n\n\n\n\n\nspeech-to-text\n\n\nconversion methods\n\n\nonline tools\n\n\noffline solutions\n\n\nAPIs\n\n\nopen-source libraries\n\n\nmultiple languages\n\n\n\n\nThis article explores the different methods and tools available for speech-to-text conversion, including online and offline options such as APIs, open-source libraries, and software implementations. These solutions support multiple languages and translation capabilities.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nstory continuation, story-dalle able to generate story and image at the same time\n\n\n\n\n\n\n\nstory-dalle\n\n\nAI technology\n\n\nStory generation\n\n\nImage generation\n\n\nGitHub link\n\n\nCode snippet\n\n\nContinuation\n\n\n\n\nThis article discusses a story continuation tool called ‘story-dalle’, which uses AI technology to generate both the story and its accompanying image simultaneously. The code for this innovative application can be found on the provided GitHub link.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\naudio-visual active speaker detection\n\n\n\n\n\n\n\nAudio-Visual\n\n\nActive Speaker Detection\n\n\nLeaderboard\n\n\nSPL+\n\n\nSpeech Recognition\n\n\nAdvancements in Technology\n\n\nIdentifying Speakers\n\n\n\n\nThis article explores the advancements in audio-visual active speaker detection technology, discussing recent developments and potential references to a leaderboard and SPL+. The article delves into the identification of speakers within an audiovisual context and how these technologies are evolving.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nAGI (Artificial General Intelligence) related projects\n\n\n\n\n\n\n\nAI\n\n\nAGI\n\n\nDeep Reinforcement Learning\n\n\nCognitive Science\n\n\nSensor-based Learning\n\n\nGitHub\n\n\nPapers\n\n\n\n\nThis article explores various AI projects, including AGI, deep reinforcement learning, cognitive science, and sensor-based learning. Additionally, it provides resources such as GitHub repositories and papers to assist those interested in further understanding these cutting-edge technologies.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nvideo quality assessment, audio quality assessment\n\n\n\n\n\n\n\nvideo_quality\n\n\naudio_quality\n\n\nbenchmarks\n\n\nVQA\n\n\nSSIM\n\n\nMOSCATO\n\n\nPython_package\n\n\n\n\nThis article delves into the topic of assessing video and audio quality. It highlights benchmarks for evaluating quality, introduces a swift VQA tool, explores SSIM-based VQA methods, and presents MOSCATO, a Python package specifically designed to evaluate audio quality.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nspeech recognition\n\n\n\n\n\n\n\nspeech recognition\n\n\nMFCC\n\n\nHMM\n\n\naudio processing\n\n\nnatural language processing\n\n\nmachine learning\n\n\nartificial intelligence\n\n\n\n\nThis article explores the use of Mel Frequency Cepstral Coefficients (MFCC) and Hidden Markov Models (HMM) for speech recognition. It delves into how these techniques can be employed to accurately transcribe spoken words, improve language processing systems, and enhance human-computer interaction. The article provides insights on the algorithms’ principles, their applications, and potential areas of advancement.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nmindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series\n\n\n\n\n\n\n\nMachine Learning\n\n\nTime Series Data Processing\n\n\nHidden Markov Models\n\n\nPython Library\n\n\nProbability Models\n\n\nUnivariate Distributions\n\n\nMultivariate Distributions\n\n\n\n\nIn this article, the author compares MindsDB and Pomegranate. MindsDB is a platform that specializes in machine learning using time series data processing with hidden Markov models. On the other hand, Pomegranate is a Python library that provides probability models like mixture and hidden Markov models for univariate and multivariate distributions.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\njavascript python bridge\n\n\n\n\n\n\n\nJavaScript\n\n\nPython\n\n\nBridge\n\n\nGUI\n\n\nDevelopment\n\n\nNPM\n\n\nModules\n\n\n\n\nThe JavaScript Python Bridge is a tool that bridges the gap between JavaScript and Python, enabling seamless integration between the two languages. This bridge can be installed through npm and provides functions for importing Python modules and accessing global variables in JavaScript. It opens up possibilities for GUI development using libraries like tkinter.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nopencv corner detection\n\n\n\n\n\n\n\nOpenCV\n\n\nFast algorithm\n\n\nCorner detection\n\n\nImage processing\n\n\nFAST object\n\n\nfast_true.png\n\n\nfast_false.png\n\n\n\n\nThis code utilizes OpenCV’s Fast algorithm to detect corners in an image, initializing the FAST object with default values and saving the results as ‘fast_true.png’ and ‘fast_false.png’. The Fast algorithm is a feature detection method that helps locate feature points or interest points in an image which can be useful for various computer vision tasks.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\ncolor transfer between images, histogram based style transfer\n\n\n\n\n\n\n\ncolor transfer\n\n\nimage manipulation\n\n\nhistogram-based style transfer\n\n\nvideo effects\n\n\npicture enhancement\n\n\nPython code\n\n\nimage color matching\n\n\n\n\nThis text explains a method for color transfer between images, specifically using histogram-based style transfer to create vibrant effects in videos or pictures. It provides installation instructions and example Python code for image color matching using histogram matching.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nffmpeg中英文对照 ffmpeg filter reference translated\n\n\n\n\n\n\n\nvideo_filters\n\n\nimprove_video_quality\n\n\nstabilization\n\n\ncolor_correction\n\n\nneural_networks\n\n\nnoise_reduction\n\n\nclarity_enhancement\n\n\n\n\nVideo filters enhance the quality of footage by performing tasks such as stabilization, color correction, and utilizing neural networks to minimize noise, improve clarity, and resolve problems like flickering or rain in videos.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nnumpy and pandas deduplication\n\n\n\n\n\n\n\nNumpy\n\n\nDuplicate removal\n\n\nArrays\n\n\nnp.unique()\n\n\nPandas\n\n\nDrop_duplicates\n\n\nDupandas\n\n\n\n\nThis article explains how to remove duplicates from numpy arrays using np.unique(). Additionally, it provides resources on dupandas for custom rules and the pandas drop_duplicates function.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nobject tracking, video\n\n\n\n\n\n\n\nobject tracking\n\n\nOpenCV algorithms\n\n\nMeanshift\n\n\nCAMshift\n\n\nOptical Flow\n\n\nidentifying objects\n\n\navoiding duplicate processes\n\n\n\n\nThis text discusses object tracking in video using OpenCV algorithms such as Meanshift, CAMshift, and Optical Flow. It emphasizes identifying the object first before starting tracking and avoiding duplicate processes when detection overlaps with an existing object.\n\n\n\n\n\n\nSep 17, 2022\n\n\n\n\n\n\n\n\nleaderboards, paperswithcode.com\n\n\n\n\n\n\n\nleaderboards\n\n\npaperswithcode.com\n\n\nKaggle\n\n\ntask categorization\n\n\nscrapers\n\n\naistudio.baidu.com\n\n\ntime-saving\n\n\n\n\nLeaderboards on platforms like paperswithcode.com, Kaggle, and aistudio.baidu.com offer various tasks with best models for each task, but basic task categorization can take time. These platforms provide helpful categories before searching or needing them.\n\n\n\n\n\n\nSep 15, 2022\n\n\n\n\n\n\n\n\npython retry libraries\n\n\n\n\n\n\n\nPython\n\n\nretry libraries\n\n\nautomation\n\n\ntemporary issues\n\n\nerror handling\n\n\n\n\nThis text introduces three Python retry libraries - retrying, retry, and retry2. These libraries simplify the process of automatically retrying operations that may fail due to transient issues or errors, making it easier for developers to handle such scenarios efficiently.\n\n\n\n\n\n\nSep 14, 2022\n\n\n\n\n\n\n\n\nscrape podcasts, filter keywords, convert voices by gender and pitch\n\n\n\n\n\n\n\npodcasts\n\n\nscraping\n\n\nfiltering\n\n\nvoice filtering\n\n\ngender\n\n\npitch\n\n\nlive streaming\n\n\n\n\nThis article explores various methods for scraping and filtering podcasts. It discusses techniques like voice filtering by gender and pitch, live streaming, name filtering, review sorting, audio enhancement, and separating voices from music. The text also references popular platforms such as iTunes and Ximalaya FM. Additionally, it suggests using summarization or extracted keywords for advanced search capabilities. Related GitHub links are provided.\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\nopencv-python wrappers, without boilerplates\n\n\n\n\n\n\n\nOpenCV\n\n\nPython\n\n\nimutils\n\n\ncaer\n\n\nimage processing\n\n\nvideo loading\n\n\nboilerplate code\n\n\n\n\nThis article discusses Python wrappers for OpenCV, specifically highlighting imutils by PyImagesearch and caer libraries. These libraries offer streamlined solutions for tasks like image resizing, processing, and video loading without requiring boilerplate code. The article provides a link to access further documentation on these tools.\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\npaddlepaddle applications\n\n\n\n\n\n\n\nAI platform\n\n\nPaddlePaddle\n\n\nNLP models\n\n\nBERT\n\n\nELECTRA\n\n\nAgriculture\n\n\nHealthcare\n\n\n\n\nPaddlePaddle is an AI platform providing optimized pre-trained NLP models like BERT and ELECTRA, applicable to diverse fields such as agriculture, healthcare, sports, machine translation, image classification, and natural language processing.\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\nExploring Chinese Music Platform APIs and Repositories\n\n\n\n\n\n\n\nAPIs\n\n\nChinese music platforms\n\n\nListen1\n\n\nMusicafe\n\n\nMusicGet\n\n\nGitHub\n\n\nRepositories\n\n\n\n\nThe article provides a comprehensive list of APIs and repositories associated with popular Chinese music platforms like Listen1, Musicafe, MusicGet, etc. It also includes links to their respective GitHub pages for users to delve deeper into these services.\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\naudio watermark removal\n\n\n\n\n\n\n\nDeep Audio Prior\n\n\nDAP\n\n\nAudio watermarks\n\n\nFFmpeg\n\n\nSound separation\n\n\nWatermarker removal\n\n\nMusic sounds\n\n\n\n\nThis article explains a technique to remove audio watermarks from recordings using Deep Audio Prior (DAP) and FFmpeg. DAP separates the sounds with watermarkers, creating individual music sounds and the corresponding watermarker, allowing for easy removal of the watermark.\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\nAudio and Music Tools\n\n\n\n\n\n\n\naudio processing\n\n\ntools\n\n\nfiller words removal\n\n\nediting audio/video\n\n\nmachine learning\n\n\nguitar audio enhancement\n\n\nCleanvoice AI\n\n\nDescript\n\n\nRevoldiv\n\n\nAudioStellar\n\n\nBeepbox\n\n\nAudacity\n\n\nAudiomass\n\n\nVB-Audio Virtual Apps\n\n\nrecording webinars\n\n\nmixing audio for broadcasting\n\n\nZoom and YouTube\n\n\nmultiple audio sources\n\n\n\n\nThis article delves into the world of audio processing tools, exploring options for tasks like removing filler words, editing audio/video, enhancing guitar audio using machine learning, and creating and sharing music. Some popular tools mentioned include Cleanvoice AI, Descript, Revoldiv, AudioStellar, Beepbox, Audacity, Audiomass, and VB-Audio Virtual Apps. These tools can be used for various purposes such as recording webinars, mixing audio for broadcasting on Zoom and YouTube, and working with multiple audio sources.\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nsong recognition, music recognition api, music discovery, audio search, audio fingerprint\n\n\n\n\n\n\n\nmusic discovery\n\n\nexpert choices\n\n\nmachine learning\n\n\nSpotify API\n\n\nLast.fm API\n\n\nself-hosted Shazam\n\n\nUbuntu 18.04\n\n\n\n\nThe article delves into different approaches for music discovery, such as relying on experts’ recommendations, leveraging machine learning algorithms and utilizing APIs from platforms like Spotify and Last.fm. Additionally, it explores the possibility of building one’s own Shazam-like algorithm or song recognition system in Ubuntu 18.04.\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nMastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More\n\n\n\n\n\n\n\nvideo uploading\n\n\narticle uploading\n\n\ncover images\n\n\nintroductions\n\n\ntags (metadata)\n\n\ncollection information\n\n\nanalyzing videos\n\n\n\n\nThis article covers various aspects of uploading videos and articles, including adding cover images, introductions, tags, and collection information. Additionally, it explains how to analyze videos through cropping and improving quality, find related content using tags, and explore platform-specific API requirements for functions like speech and music separation, subtitle recognition, and download capabilities.\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nuse pyscenedetect dynamically in program\n\n\n\n\n\n\n\npyscenedetect\n\n\nvideo\n\n\nscene detection\n\n\nFFmpeg\n\n\nsplicing\n\n\nvideo gradients\n\n\ncode snippet\n\n\n\n\nThe pydantic schema can be used to describe a class in Python. In this case, the `Description` class is defined as a base model. The summary provided describes the purpose and functionality of the `pyscenedetect` library, which assists with dynamically detecting scenes in videos while accounting for possible issues like splicing and video gradients. A code snippet demonstrating how to use this library and FFmpeg to identify and segment a video into scenes is also provided.\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nelinks/lynx with python: how to speed up headless website browsing/parsing/scraping with cookies\n\n\n\n\n\n\n\nspeeding up website browsing\n\n\nwebsite parsing and scraping\n\n\nelinks/lynx\n\n\nPython\n\n\nopen-source tools\n\n\nNewsCrawl\n\n\nGeneral News Extractor\n\n\n\n\nThis article explores ways to improve the speed of website browsing, parsing, and scraping using elinks/lynx and Python. It introduces open-source tools like NewsCrawl for sentiment analysis and General News Extractor for news content extraction. Additionally, it covers customizing headless puppeteer/phantomjs and utilizing readability and jsdom to enhance the process.\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nExploring FFmpeg’s Advanced Encoding, Conversion, and Audio Functionality\n\n\n\n\n\n\n\nFFmpeg\n\n\nspeeding up encoding\n\n\nV4L2 device video encoding\n\n\nframe conversion to PNG\n\n\nre-encoding bypass\n\n\nH.26 exporting\n\n\nHDR video conversion\n\n\nframe extraction\n\n\naudio/video data retrieval\n\n\nAVI/FLV to MP3 conversion\n\n\ncustom audio quality parameters\n\n\n\n\nThis article showcases the versatile capabilities of FFmpeg, a powerful tool for speeding up encoding processes and offering features such as V4L2 device video encoding, frame conversion to PNG, re-encoding bypass, H.26 exporting, HDR video conversion, frame extraction, audio/video data retrieval, AVI/FLV to MP3 conversion, and custom audio quality parameters.\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n\n\nmotion vector estimation, motion vector export, ffmpeg advanced usage\n\n\n\n\n\n\n\nFFmpeg\n\n\nPyAV\n\n\nvideo interpolation\n\n\nframe extraction\n\n\nvideo extractor\n\n\nvideo transition\n\n\nvideo processing\n\n\nmotion vector extraction\n\n\nscene change detection\n\n\nsubtitle removal\n\n\nframe interpolation\n\n\nFFmpeg image resizing algorithms\n\n\n\n\nThis article delves into motion vector extraction, scene change detection, subtitle removal, and frame interpolation using PyAV with FFmpeg. Additionally, it covers FFmpeg’s image resizing algorithms such as ‘sinc’, ‘lanczos’, and ‘spline’. The article also explores logging options, rounding methods, chroma interpolation, luma/chroma component handling, and the ‘bitexact’ option for exact pixel handling.\n\n\n\n\n\n\nSep 11, 2022\n\n\n\n\n\n\n\n\nUnlocking the Power of AI: Exploring Deep Learning Datasets and Resources\n\n\n\n\n\n\n\ndeeplearning\n\n\ndatasets\n\n\nclassification\n\n\nevaluation\n\n\naudio\n\n\nvideo\n\n\nmachinelearning\n\n\n\n\nThis article discusses a range of datasets suitable for deep learning, classification, and evaluation tasks. It highlights a collection of 100 audio and video datasets, a website specifically dedicated to video datasets, as well as the YouTube-8m dataset. These resources are valuable for AI projects involving data analysis and machine learning duties.\n\n\n\n\n\n\nSep 11, 2022\n\n\n\n\n\n\n\n\nrandom giphy gifs\n\n\n\n\n\n\n\nGiphy\n\n\nAPI Keys\n\n\nSDK\n\n\nImplementation Details\n\n\nDocumentation\n\n\nLibraries\n\n\nServices\n\n\n\n\nThis article discusses Giphy’s API and SDK keys, implementation details, and provides access to documentation and libraries for using their gif services. The comments offer insights on how to effectively integrate Giphy’s offerings into various projects.\n\n\n\n\n\n\nSep 11, 2022\n\n\n\n\n\n\n\n\ngfw circumvention, download youtube videos, scrape banned websites\n\n\n\n\n\n\n\nbypassing internet restrictions\n\n\nYouTube video downloaders\n\n\nweb scraping\n\n\nBinder alternative to Google Colab\n\n\nContinuous Integration services\n\n\nGitHub CI\n\n\nCircleCI and Azure Pipelines\n\n\n\n\nThis article delves into techniques for circumventing internet limitations, obtaining YouTube video downloads, and web scraping from restricted sites. It suggests employing platforms like Binder as replacements to Google Colab, while also examining an assortment of Continuous Integration (CI) services offered by GitHub and other providers including CircleCI and Azure Pipelines. The article emphasizes the significance of accessing results promptly through coding.\n\n\n\n\n\n\nSep 10, 2022\n\n\n\n\n\n\n\n\ncopyright issues circumvention\n\n\n\n\n\n\n\ncopyright\n\n\nfan communities\n\n\nciting sources\n\n\nlarge fan bases\n\n\nbackground music\n\n\ncircumvention\n\n\nintellectual property\n\n\n\n\nThis article highlights the significance of adhering to copyright laws and avoiding circumvention while drawing content from large fan communities. It emphasizes the importance of properly citing sources and specifying the background music used, ensuring compliance with legal guidelines.\n\n\n\n\n\n\nSep 9, 2022\n\n\n\n\n\n\n\n\nexpect send special control chars\n\n\n\n\n\n\n\nspecial characters\n\n\nexpect send\n\n\ncommand line\n\n\nterminal\n\n\nprogramming tools\n\n\nUNIX systems\n\n\nreference blog post\n\n\n\n\nThis article explores the use of special control characters in conjunction with ‘expect send’ commands, providing a deeper understanding of their functionality and purpose. For more detailed information, refer to the accompanying blog post.\n\n\n\n\n\n\nSep 8, 2022\n\n\n\n\n\n\n\n\ncalling java from python\n\n\n\n\n\n\n\nJava\n\n\nPython\n\n\njpype\n\n\npyjnius\n\n\nlingua\n\n\ntext analysis\n\n\nlanguage detection\n\n\n\n\nThis article discusses the process of calling Java code from Python using jpype or pyjnius libraries, allowing for seamless integration between the two languages. Additionally, it covers the usage of the com.github.pemistahl.lingua.api library to detect the language within a given text.\n\n\n\n\n\n\nSep 8, 2022\n\n\n\n\n\n\n\n\nstationary logo finders and moving logo finders\n\n\n\n\n\n\n\nlogo finder\n\n\nstationary logo finder\n\n\nmoving logo finder\n\n\ncommand-line tool\n\n\nrepository\n\n\noutdated\n\n\nWatermark Removal, Deep Image Prior, Inpainting, Generate Watermark Mask\n\n\n\n\nThis article discusses two types of logo finders, stationary and moving. The stationary logo finder is a command-line tool, while the overall logo finding repository may be outdated. To find related information, one can refer to a ‘Watermark Removal, Deep Image Prior, Inpainting, Generate Watermark Mask’ bookmark folder on a MacBook Chrome browser.\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\nwhat is causing my mac to freeze when kali is offline\n\n\n\n\n\n\n\nMac\n\n\nKali Linux\n\n\nZeroTier One\n\n\nFreezing issue\n\n\nScript modification\n\n\nTuntap\n\n\nN2N Kali\n\n\n\n\nThe article delves into a Mac freezing issue that occurs when Kali is offline. Suspecting modified scripts, the user pinpoints ZeroTier One as the primary culprit, specifically mentioning `load_tuntap_launch_n2n_kali_root.sh`, `nginx_with_kali_finder.sh`, and `launch.sh` as potential problem areas.\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\nrectangle related calculation\n\n\n\n\n\n\n\npolygons\n\n\nrectangles\n\n\nconversion tools\n\n\nrectirization\n\n\nextractrect\n\n\nrectlinear polygon decomposition\n\n\nimage processing\n\n\n\n\nThis article explores the techniques of transforming polygons into rectangles using tools like rectirization, extractrect, and rectlinear polygon decomposition. These methods are useful in various applications such as computer vision, robotics, and digital mapping.\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\nvapoursynth 光流算法 补帧 画面优化 denoising\n\n\n\n\n\n\n\nVapourSynth\n\n\nvideo processing\n\n\noptical flow algorithms\n\n\nframe interpolation\n\n\ndenoising\n\n\nPython scripting\n\n\nnazobase\n\n\nDBmbk\n\n\nffmpeg\n\n\n\n\nVapourSynth is a powerful video processing tool that utilizes optical flow algorithms, frame interpolation, and denoising. It seamlessly integrates with other tools like nazobase, DBmbk, and ffmpeg to enhance video quality. With support for Python scripting, users can customize the tool according to their specific requirements. VapourSynth also leverages techniques such as nazorip Bezier curve, gamma curve, convolution, and flowpy for advanced image processing capabilities.\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\nmetahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm\n\n\n\n\n\n\n\nMakeHuman\n\n\nBlender\n\n\nlip sync\n\n\nmocap\n\n\nVRM files\n\n\nreal-time human body tracking\n\n\nimport/export\n\n\n\n\nThis article delves into the world of MakeHuman, a popular software for model making. It covers various techniques and tools used in Blender to achieve lip sync and mocap effects. Additionally, it highlights several libraries useful for real-time human body tracking and VRM file import/export.\n\n\n\n\n\n\nSep 6, 2022\n\n\n\n\n\n\n盗版影视站\n\n\n\npiracy\nwebsites\nNafidramovies\nTzfile\nDdrk\nTelegram's lovesource\nNetflixstar.top\n\n\n\nThe text discusses several websites, such as Nafidramovies, Tzfile, Ddrk, Telegram's lovesource, and Netflixstar.top, that offer unauthorized access to pirated movies and TV shows.\n\n\n\n`Sep 6, 2022`{=html}\n\n\n\n\n\n\ndeepl免费翻译 免费白嫖\n\n\n\n\n\n\n\nDeepL API\n\n\nanti-scraping measures\n\n\nrequest structure analysis\n\n\nnaming conventions\n\n\nbypassing systems\n\n\nchallenges\n\n\nabusing the system\n\n\n\n\nThe comments discuss efforts to circumvent DeepL API’s anti-scraping mechanisms by examining request structures and identifying consistent naming conventions. Despite these potential vulnerabilities, the commenters ultimately decide against abusing the system due to its complexity.\n\n\n\n\n\n\nSep 6, 2022\n\n\n\n\n\n\n\n\nrectangle packing, polygon to rectangle decomposition\n\n\n\n\n\n\n\nrectangle packing\n\n\npolygon decomposition\n\n\ncomputer graphics\n\n\nrobotics\n\n\nmanufacturing optimization\n\n\ngeometry algorithms\n\n\napplied mathematics\n\n\n\n\nThis article explores the concepts of rectangle packing and polygon to rectangle decomposition. Rectangle packing involves fitting rectangles into a given space, while polygon decomposition focuses on breaking down a polygon into rectangles. These techniques can be applied in various fields like computer graphics, robotics, and manufacturing optimization.\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n补帧 插帧 提高帧数\n\n\n\n\n\n\n\nvideo quality\n\n\nsuper resolution\n\n\nReal-CUGAN\n\n\ncolorization\n\n\nDAIN\n\n\nRIFE\n\n\nVapourSynth\n\n\nWaifu2x\n\n\nRealESRGAN\n\n\n\n\nThis article discusses various video quality enhancement techniques such as super resolution with Real-CUGAN, colorization, and algorithms like DAIN, RIFE, VapourSynth, Waifu2x, and RealESRGAN. These techniques can improve clarity and frame rates but may have an impact on speed or image quality.\n\n\n\n\n\n\nSep 3, 2022\n\n\n\n\n\n\n\n\nyaml special token cause error to pyyaml\n\n\n\n\n\n\n\nPyYAML\n\n\nYAML\n\n\nSpecial Token\n\n\nErrors\n\n\nConversion\n\n\nDocumentation\n\n\n\n\nThe YAML special token ‘!’ can cause errors in PyYaml. To avoid these issues, it is recommended to convert the token to ‘!!str’ and revert the change when writing back. For more information, consult the full documentation available at pyyaml.org/wiki/PyYAMLDocumentation.\n\n\n\n\n\n\nSep 2, 2022\n\n\n\n\n\n\n\n\nUnderstanding WeChat Pay and Alipay: The Popular Payment Systems in China\n\n\n\n\n\n\n\nWeChat Pay\n\n\nAlipay\n\n\npayment systems\n\n\nsending money\n\n\nreceiving money\n\n\nQR codes\n\n\nmobile payments\n\n\n\n\nWeChat Pay and Alipay are popular payment systems in China that facilitate sending and receiving money, as well as scanning and generating QR codes for transactions.\n\n\n\n\n\n\nSep 1, 2022\n\n\n\n\n\n\n\n\n一堆电子书 可能适合作为pdf搜索的起点\n\n\n\n\n\n\n\nebooks\n\n\nwiki format\n\n\nApache Tika\n\n\nXapian\n\n\nannotation\n\n\ncollaboration\n\n\norganization\n\n\n\n\nThis article explores the process of converting e-books to wiki format, utilizing tools such as Apache Tika and Xapian for enhanced annotation and teamwork. The method not only improves organization and searchability of digital literature but also brings to light the limitations of conventional paper books.\n\n\n\n\n\n\nAug 31, 2022\n\n\n\n\n\n\n\n\n影视聚合 社交聚合 网盘聚合搜索引擎\n\n\n\n\n\n\n\nonline tools\n\n\ncloud storage platforms\n\n\nBaidu\n\n\nAliYun\n\n\nMega\n\n\nvideo search\n\n\nlearning resources\n\n\n\n\nThis article provides a comprehensive list of 15 online tools that enable users to search and aggregate resources from cloud storage platforms like Baidu, AliYun, and Mega. These tools offer various features such as video search and learning resource search, making it easier for users to access and discover content. Additionally, the article highlights top-rated platforms along with their access methods, ensuring that users can easily navigate and make the most out of these online resources.\n\n\n\n\n\n\nAug 31, 2022\n\n\n\n\n\n\n\n\nchemical shit, cheminformatics\n\n\n\n\n\n\n\nChemical Shit\n\n\nCheminformatics\n\n\nComputational Chemistry\n\n\nChemical Analysis\n\n\nSoftware Tools\n\n\nChemical Reactions\n\n\nChemical Properties\n\n\n\n\nThis text discusses the topic of ‘chemical shit’ and ‘cheminformatics,’ which is a field that utilizes computational methods and software tools to analyze chemical structures, properties, and reactions. The phrase ‘chemical shit’ may refer to a specific issue or problem within this field, but additional context is required for clarity.\n\n\n\n\n\n\nAug 29, 2022\n\n\n\n\n\n\n\n\nthe formula search engine, latex enabled, textbook search engine\n\n\n\n\n\n\n\nsearch engines\n\n\nformulas\n\n\ntextbooks\n\n\nlatex2sympy\n\n\nMathpix\n\n\nim2markup\n\n\nonline tools\n\n\n\n\nThis article explores different search engines for finding formulas and textbooks, specifically highlighting latex2sympy, Mathpix, and im2markup.\n\n\n\n\n\n\nAug 27, 2022\n\n\n\n\n\n\n\n\nUnlocking the Potential of AI-Assisted Live Streaming and Audience Data\n\n\n\n\n\n\n\nAI\n\n\nLive Streaming\n\n\nAudience Data Utilization\n\n\nContent Classification\n\n\nMiscommunication\n\n\nApologetic Interactions\n\n\nUser Engagement\n\n\n\n\nThe article discusses AI-assisted live streaming, its capabilities in audience data utilization for content classification, and how it handles miscommunication and apologetic interactions between users.\n\n\n\n\n\n\nAug 26, 2022\n\n\n\n\n\n\n\n\non building the lua torch library\n\n\n\n\n\n\n\nim2latex\n\n\ntensorflow\n\n\npytorch\n\n\ninstallation\n\n\nhardware damage\n\n\nsafety precautions\n\n\nguide\n\n\n\n\nIn this article, you will learn how to install and use im2latex with TensorFlow and PyTorch. Additionally, the article covers important safety precautions and potential hardware damage considerations when running ‘im2latex-tensorflow’. By following these instructions, you can ensure a safe and successful implementation of im2latex in your TensorFlow or PyTorch projects.\n\n\n\n\n\n\nAug 26, 2022\n\n\n\n\n\n\n\n\nscan this picture and index the whole video/document/ppt/textbook!\n\n\n\n\n\n\n\nimage_scanning\n\n\nmath_formulas\n\n\nnon_max_suppression\n\n\nocr\n\n\ncopyright\n\n\nchargrid\n\n\nimagematch\n\n\n\n\nThis article explores techniques for scanning images and documents containing mathematical formulas using non-max suppression and image search libraries such as Chargrid OCR or Image Match, ensuring compliance with copyright laws while minimizing manual formatting.\n\n\n\n\n\n\nAug 25, 2022\n\n\n\n\n\n\n\n\n关于人类发展规律和需求的随想\n\n\n\n\n\n\n\nideas\n\n\nsocial media\n\n\n人类\n\n\n随想\n\n\n\n\nThe text explores the concept that acquiring substantial amounts of information is crucial for accomplishment in diverse domains, and highlights the distinction between strong and weak correlations.\n\n\n\n\n\n\nAug 23, 2022\n\n\n\n\n\n\n\n\n递归搜索 启发式搜索\n\n\n\n\n\n\n\nadvanced search\n\n\ninformation gathering\n\n\nsearch\n\n\nsemantic search\n\n\n\n\nThis article explores different search techniques, such as collaborative filtering and recommendation engines, along with random and heuristic libraries. It delves into scraping Twitch chat and predicting memes, detecting trending topics or videos using official APIs, recursive searching with filters and updates, topic modeling via Gensim, and identifying fake news in web browsers.\n\n\n\n\n\n\nAug 23, 2022\n\n\n\n\n\n\n\n\nGenerating 3D Models from Images with the 3d-Moments Tool\n\n\n\n\n\n\n\n3d-models\n\n\n3d-video\n\n\nimage-processing\n\n\nmachine-learning\n\n\ntool\n\n\n\n\nThis text discusses a method to create 3D models from multiple similar images and generate a 3D video using the tool ‘3d-moments’. The process involves analyzing the images to extract depth information, which is then used to build a 3D model. This technology has various applications in industries like gaming, architecture, and film making.\n\n\n\n\n\n\nAug 22, 2022\n\n\n\n\n\n\n\n\nHardware Simulator\n\n\n\n\n\n\n\nhardware\n\n\nspice\n\n\n\n\nPySpice is a hardware simulator that leverages ngspice and xyce as backend tools, allowing users to simulate various electronic components such as MOS, JFET, diodes, and more.\n\n\n\n\n\n\nAug 22, 2022\n\n\n\n\n\n\n\n\n连续区间 离散区间 从离散数据中获得离散区间 交并补\n\n\n\n\n\n\n\ninterval\n\n\nmath\n\n\nmathematica\n\n\nsympy\n\n\nwolfram\n\n\n\n\nThis Python script utilizes SymPy for performing various interval operations. It allows you to manage, merge, and sort sets of intervals, detect overlaps, convert continuous data into intervals, solve unions, filter short intervals, and transform interval sets into tuples. The provided functions enable you to obtain a merged interval tuple list and easily handle and manipulate interval sets.\n\n\n\n\n\n\nAug 22, 2022\n\n\n\n\n\n\n\n\nOCR tools\n\n\n\n\n\n\n\nocr\n\n\npicture to text\n\n\n\n\nThis article compares various OCR (Optical Character Recognition) tools like tesseract.js, ChineseOCR, chineseocr_lite, TrWebOCR, paddleocr, easyocr, and PearOCR. These tools support multiple languages, different text directions, and handwriting recognition with varying capabilities.\n\n\n\n\n\n\nAug 20, 2022\n\n\n\n\n\n\n\n\nmacbook air usage notes\n\n\n\n\n\n\n\nbody posture\n\n\nhealth\n\n\nlife style\n\n\nmacbook\n\n\nwork\n\n\n\n\nThe user expresses dissatisfaction with the usability and comfort of their MacBook Air, mentioning that they need to use multiple props and pillows for a suitable position and still encounter instability.\n\n\n\n\n\n\nAug 19, 2022\n\n\n\n\n\n\n\n\nA good/bad proposal on v2ray\n\n\n\n\n\n\n\nanonymous\n\n\nonion router\n\n\nv2ray\n\n\nvpn\n\n\n\n\nThis proposal aims to enhance the efficiency of communication by allowing the use of multiple V2Ray clients and servers, while also utilizing a single outbound network, similar to how the onion router operates.\n\n\n\n\n\n\nAug 18, 2022\n\n\n\n\n\n\n\n\nbackup schedules\n\n\n\n\n\n\n\nschedule\n\n\n\n\nThe article discusses backup schedules for a system, covering both offline backups to disk and online backups to cloud disks. It also provides guidance on setting up notification systems and determining timetables for regular intervals of execution.\n\n\n\n\n\n\nAug 18, 2022\n\n\n\n\n\n\n\n\npyjom schedules\n\n\n\n\n\n\n\npyjom\n\n\nschedule\n\n\n\n\nThis article features discussions on various video and audio processing projects. These projects cover a wide range of tasks such as Natural Language Understanding (NLU), trending topic discovery, loudness improvement, watermark removal, enhanced highlight algorithms, voice changing technology, locating older content, and live streaming for quality enhancement.\n\n\n\n\n\n\nAug 18, 2022\n\n\n\n\n\n\n\n\n2022-08-18-03-35-56\n\n\n\n\n\n\n\ndiary\n\n\n\n\nThe author implemented schedules to prioritize their projects, with the primary objective being general schedule creation and a secondary goal of completing the development of a dog video generator.\n\n\n\n\n\n\nAug 17, 2022\n\n\n\n\n\n\n\n\nself-learning schedules\n\n\n\n\n\n\n\nAGI\n\n\nfinance\n\n\nfinancial\n\n\nquantatitive trading\n\n\nschedule\n\n\nstock\n\n\n\n\nThis personal study plan covers various topics including reviewing past notes, revisiting history, studying finance and quantitative trading, and exploring artificial general intelligence. Tasks involved range from completing unfinished notes to designing algorithms and executing shell commands.\n\n\n\n\n\n\nAug 17, 2022\n\n\n\n\n\n\n\n\nhacking schedules\n\n\n\n\n\n\n\nschedule\n\n\n\n\nThis article provides insights on locating free hacking tutorials and optimizing hacking schedules. It covers various indexing tools, search engines, GitHub coin mining, SEO enhancements, and utilizes popular hacking tools such as Frida, Cutter, Radare2, and solves CTF challenges.\n\n\n\n\n\n\nAug 17, 2022\n\n\n\n\n\n\n\n\nVisual Disk Usage Manager, Visual Disk Cleaner\n\n\n\n\n\n\n\nstub\n\n\nsystem manage\n\n\n\n\nThis article provides an overview of popular disk usage management tools available for Linux systems, including Baobab for Gnome and Filelight for KDE. Additionally, Qdirstat is introduced as another useful option for managing disk space.\n\n\n\n\n\n\nAug 17, 2022\n\n\n\n\n\n\n\n\nModel Zoo\n\n\n\n\n\n\n\nmodel zoo\n\n\npyjom\n\n\nstub\n\n\n\n\nThis article highlights different model zoos and resources available for finding and utilizing task-specific models across multiple platforms. Some of the popular platforms discussed are HuggingFace, MindSpore, ModelScope, Intel, OpenVino, Jina, CoreML, PaddleHub, PyTorch, TensorFlow, and Model Garden.\n\n\n\n\n\n\nAug 17, 2022\n\n\n\n\n\n\n\n\nissues related to fastgithub and other self-signed certificates in language-specific package managers\n\n\n\n\n\n\n\npackage manager\n\n\nself-signed certificate\n\n\nsystem manage\n\n\n\n\nThis article addresses the issue of slow download speeds caused by self-signed certificates in language-specific package managers like npm and yarn. It proposes solutions such as using cnpm, a version of the npm command-line interface that uses a different registry, and configuring binary distribution file mirrors to improve performance.\n\n\n\n\n\n\nAug 15, 2022\n\n\n\n\n\n\n\n\n自动内容发布 多平台发布 管理多个自媒体平台 automatic content posting in multiple platforms\n\n\n\n\n\n\n\nauto post\n\n\nauto publishing\n\n\nbot\n\n\nmedia manage\n\n\npyjom\n\n\nstub\n\n\n\n\nDiscover how to automatically post your content on various platforms like Toutiao, WordPress, Zhihu, Jiathisay, Juejin, CSDN, and Typecho with just one click. Boost your personal productivity by syncing effortlessly across multiple content platforms.\n\n\n\n\n\n\nAug 14, 2022\n\n\n\n\n\n\n\n\n哔哩哔哩 直播姬 2d模型 3d模型\n\n\n\n\n\n\n\nanime character segmentation\n\n\nanimoji\n\n\navatarkit\n\n\nimage segmentation\n\n\npyjom\n\n\ntalking head\n\n\nvideo driven model\n\n\nvideo generator\n\n\nvtuber\n\n\nwaifu segmentation\n\n\n\n\nThis article delves into the development of anime-style avatars, emphasizing the significance of 3D models, Linux compatibility, and face tracking tools. It explores various techniques such as moeflow, AniSeg, NextHuman Beta0.9, FaceRig, Style GAN, Python, and facial landmark detection for creating digital people and animating them. Furthermore, it discusses applications like Animoji, VTuber talking heads, and live streaming in the context of this avatar development.\n\n\n\n\n\n\nAug 13, 2022\n\n\n\n\n\n\n\n\ngitter developer tokens and qq opqbot, reverse engineering qq protocols and more\n\n\n\n\n\n\n\nchatbot\n\n\nchatbot framework\n\n\nopqbot\n\n\npyjom\n\n\nqq\n\n\nreverse engineering\n\n\nstub\n\n\n\n\nOpqbot, a tool for logging into Gitter.im using a device JSON file, has been discussed in terms of compatibility and login issues. Additionally, alternative QQ protocol analysis tools have been mentioned as options.\n\n\n\n\n\n\nAug 13, 2022\n\n\n\n\n\n\n\n\nforce pty allocation when spinning up tmux over ssh\n\n\n\n\n\n\n\npty\n\n\nssh\n\n\nsystem manage\n\n\nterminal\n\n\ntmux\n\n\n\n\nThis article discusses two different approaches to fixing the ‘not a terminal’ error when attaching to a tmux session. Comment A offers alternative command options specific to Kali Linux, while Comment B provides instructions on how to configure the OpenSSH SSH client for pseudo-terminal allocation.\n\n\n\n\n\n\nAug 13, 2022\n\n\n\n\n\n\n\n\nAutomatic CMCC network switching\n\n\n\n\n\n\n\nnetwork\n\n\nonline\n\n\nstub\n\n\nsystem avaliablity\n\n\n白嫖\n\n\n\n\nThis text provides a detailed guide on automatic network switching for CMCC (China Mobile Communications Group) network, discussing how to avoid bandwidth limitations and automate the process using Kali Linux, with instructions for various devices such as macOS and Linux. It also explains different connection methods based on CMCC availability and offers manual internet switching options to save power.\n\n\n\n\n\n\nAug 12, 2022\n\n\n\n\n\n\n\n\nthe kali command on macos\n\n\n\n\n\n\n\nhost discovery\n\n\nremote control\n\n\nservice\n\n\nsystem manage\n\n\n\n\nThis article provides a comprehensive guide on troubleshooting Kali Linux on MacOS, covering various topics such as offline debugging, utilizing Peer-to-Peer (P2P) networks to improve connection speed, using dynamic connectors, storing Redis values, and setting the Redis working directory to optimize disk space utilization.\n\n\n\n\n\n\nAug 11, 2022\n\n\n\n\n\n\n\n\nramfs on macos, linux and windows\n\n\n\n\n\n\n\nramfs\n\n\nsystem manage\n\n\n\n\nThis article offers step-by-step instructions on how to create and mount a RAM disk on different operating systems such as Linux, macOS, and Windows. It covers various methods including the use of imdisk and eram tools.\n\n\n\n\n\n\nAug 11, 2022\n\n\n\n\n\n\n\n\nNoRepeat flag in pyjom producer\n\n\n\n\n\n\n\nfeature request\n\n\npyjom\n\n\n\n\nThe NoRepeat flag in pyjom producer ensures that consecutive clip sequences do not have the same file source and that no identical clips are included in the render sequence, preventing repetition and enhancing video production quality.\n\n\n\n\n\n\nAug 11, 2022\n\n\n\n\n\n\n\n\nCopy Symlink itself to change pyjom’s location, install easyd services for macos local pyjom watchdog\n\n\n\n\n\n\n\nlaunchd\n\n\nmacos\n\n\nrelocation\n\n\nservice\n\n\nsystem manage\n\n\n\n\nThis article provides a step-by-step guide on how to troubleshoot and fix issues related to pyjom’s location on macOS. It covers the process of disabling sync-related services, installing pyjom watchdog and syncdog services locally, and offers solutions for common problems encountered during this process.\n\n\n\n\n\n\nAug 11, 2022\n\n\n\n\n\n\n\n\nLinux Fan Not Spinning, GPU Fan Not Spinning\n\n\n\n\n\n\n\nfan\n\n\nhardware\n\n\nlinux\n\n\nsecurity\n\n\nsystem manage\n\n\nthermal\n\n\n\n\nThis article explains how to troubleshoot and resolve a fan issue on a Linux machine by installing i8kctl and thermald, configuring pwmconfig with Expect for fan control, and allowing sufficient time for the fans to reach full speed.\n\n\n\n\n\n\nAug 11, 2022\n\n\n\n\n\n\n\n\nPython suggest binary file name extension\n\n\n\n\n\n\n\nidea\n\n\nmedia recognization\n\n\npyjom\n\n\n\n\nThe article explores the use of Python to detect media file corruption. It proposes a method to identify potential corrupted files by suggesting binary file name extensions for error checking with media readers. This can be achieved by testing with a text file having a media file extension.\n\n\n\n\n\n\nAug 10, 2022\n\n\n\n\n\n\n\n\nTime Machine Alternative for linux/windows\n\n\n\n\n\n\n\nbackup\n\n\nstub\n\n\ntime machine\n\n\n\n\nLinux-Timemachine is a versatile backup solution that serves as an alternative to Time Machine on Linux, Windows, and MacOS. It utilizes rsync for efficient backup support and employs hardlinks for streamlined management of backups.\n\n\n\n\n\n\nAug 10, 2022\n\n\n\n\n\n\n\n\nvim session restore\n\n\n\n\n\n\n\neditor\n\n\nrestore session\n\n\nvim\n\n\n\n\nThis text discusses different techniques to save, restore, and manage the session states in Vim and Neovim editors. It covers various plugins for efficient session management, auto-saving workspaces, and maintaining undo history.\n\n\n\n\n\n\nAug 10, 2022\n\n\n\n\n\n\n\n\nsync tabs across different browsers\n\n\n\n\n\n\n\nstub\n\n\nsync\n\n\nsystem manage\n\n\n\n\nThis article introduces ‘Tab-Session Manager’, a tool that allows users to manage their browser sessions by integrating with Google account. The software is capable of offline syncing without relying on Google Cloud and works on newly opened tabs. However, it does not seem to integrate with existing tabs.\n\n\n\n\n\n\nAug 10, 2022\n\n\n\n\n\n\n\n\nx11vnc test on kali\n\n\n\n\n\n\n\ncredential\n\n\nremote control\n\n\nstub\n\n\ntest\n\n\nVNC\n\n\n\n\nThis article provides detailed instructions on how to install and run x11vnc on a Kali Linux system. However, it also recommends using Nomachine instead due to its NX-based foundation. The article includes a password and various example command lines for proper execution.\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\nawesome-data-labeling\n\n\n\n\n\n\n\nAI\n\n\ndata labeling\n\n\ndataset creation\n\n\nML\n\n\npyjom\n\n\nsupervised\n\n\n\n\nThis article introduces several open-source tools for image and video data labeling, such as OpenLabeler, Anno-Mage, CATMAID, and makesense.ai. Additionally, it covers 2D/3D tools that can be applied to various applications, including neural morphology and LIDAR datasets.\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\nfind an unused random local port and announce it on redis\n\n\n\n\n\n\n\nRedis\n\n\nPython script\n\n\nRedis port\n\n\nUnused local port\n\n\nRedis library\n\n\nredis-py\n\n\nfinding an unused port\n\n\n\n\nThe article provides a detailed explanation of a Python script designed to find an unused local port and store it in Redis. It demonstrates the implementation using redis-py and the Python Redis library, making it easy for developers to understand and utilize this method for their projects.\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\nsystemd on linux, maintainence details\n\n\n\n\n\n\n\nlinux\n\n\nservice\n\n\nsystem manage\n\n\nsystemd\n\n\n\n\nThis article provides instructions for managing systemd services and viewing logs on Linux. It includes sample configuration files for various applications such as frpc, pyjom_webdav_rclone, clash_fastgithub, tujia_scraper_qq_bot, tempthrottle, and sync_git_repos_syncdog.\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\ndisco diffusion and ai art\n\n\n\n\n\n\n\npicture generator\n\n\nstub\n\n\ntext to picture\n\n\nvideo generator\n\n\n\n\nAI-generated art is showcased in various styles by DiT diffusion, Scribble-diffusion, and NVIDIA’s AI Paint which utilizes Imagen-Pytorch. These techniques feature diverse styles such as retro futurism, pastel punk, and cats wearing glasses. Resources for constructing prompts are available, with support provided by PaddleHub on GitHub.\n\n\n\n\n\n\nAug 8, 2022\n\n\n\n\n\n\n\n\nSoul查看被拉黑之后对方的空间\n\n\n\n\n\n\n\ninformation gathering\n\n\npyjom\n\n\nscraping\n\n\nsoul\n\n\nstub\n\n\n\n\nThis article provides a method to view someone’s blocked Soul social media profile by using a provided link with potential expiration dates and limitations in searching or traversing the platform. It also suggests using tools like Frida or Radare2 for more freedom of access, but mentions potential risks and limitations.\n\n\n\n\n\n\nAug 8, 2022\n\n\n\n\n\n\n\n\n识别视频语言\n\n\n\n\n\n\n\naudio analysis\n\n\nlanguage classification\n\n\nlanguage recognization\n\n\nlocalization\n\n\nOCR\n\n\npyjom\n\n\nspeech recognization\n\n\n\n\nThis article delves into the process of identifying languages in videos through the utilization of various tools, such as SpeechRecognition, paddlespeech, Google Cloud ML, EasyOCR, langid, textcat, and more. These tools facilitate language detection in both audio and textual content within videos.\n\n\n\n\n\n\nAug 8, 2022\n\n\n\n\n\n\n\n\ntweening for object focus, zoom to object, zoom to video ROI\n\n\n\n\n\n\n\nanimation\n\n\nattention\n\n\ncrop the crap\n\n\ncut the crap\n\n\neasing\n\n\nfocus on object\n\n\nintermediate\n\n\npyjom\n\n\nstub\n\n\ntweening\n\n\n\n\nThis text explores the concept of focusing and zooming on objects within a video using pytweening, an easing/tweening function collection. The portal-zoomer tool is introduced for cropping videos to include only human regions. It also suggests that other libraries such as ffmpeg or vidpy/mltframework may have similar functionalities.\n\n\n\n\n\n\nAug 8, 2022\n\n\n\n\n\n\n\n\nMacOS mount ntfs volumes\n\n\n\n\n\n\n\nmacos\n\n\nntfs\n\n\nsystem manage\n\n\ntips\n\n\nusage\n\n\n\n\nThis article provides a step-by-step guide on how to mount NTFS volumes on MacOS using a command-line tool, along with troubleshooting tips for fixing issues when the app is not functioning properly. The instructions cover the process of unmounting and remounting a specific volume to ensure smooth performance.\n\n\n\n\n\n\nAug 8, 2022\n\n\n\n\n\n\n\n\ndash api docset reference search\n\n\n\n\n\n\n\ncoding assist\n\n\ndocument provider\n\n\nreference\n\n\nsearch engine\n\n\n\n\nThis article discusses the problem of not being able to run Apple Doc Helper or a binary after uninstalling Xcode, which impacts using dash documentation on non-MacOS platforms. It suggests Zeal as an alternative solution.\n\n\n\n\n\n\nAug 7, 2022\n\n\n\n\n\n\n\n\nyoutube download and its fork\n\n\n\n\n\n\n\ninformation gathering\n\n\nscraping\n\n\nvideo sources\n\n\nyoutube\n\n\n\n\nThis article compares two popular YouTube video download tools, ‘youtube-dl’ and its updated fork ‘yt-dlp.’ The original tool, ‘youtube-dl,’ is compared to its improved version in terms of speed. The article highlights the differences between these two tools and provides information on which one might be more suitable for users depending on their needs.\n\n\n\n\n\n\nAug 7, 2022\n\n\n\n\n\n\n\n\nconda and its alternatives\n\n\n\n\n\n\n\nenviorment manager\n\n\nscientific\n\n\n\n\nConda is a widely-used package manager for Python, which allows users to manage and install Python packages efficiently. Some popular alternatives to Conda are Miniconda, Miniforge (with enhanced Apple M1 support), and Mamba (supporting multithreaded operations).\n\n\n\n\n\n\nAug 7, 2022\n\n\n\n\n\n\n\n\nopennlp, fastai and other machine learning platforms\n\n\n\n\n\n\n\nfastai\n\n\nframework\n\n\nML\n\n\nmodel zoo\n\n\nNLP\n\n\nplatform\n\n\nprobabilistic\n\n\npyjom\n\n\n\n\nThis article provides a comprehensive guide to installing and using various machine learning libraries such as OpenNLP, DL4J, XGBoost, LightGBM, and tools like PyMC, Fast.ai, CMake on macOS. It includes examples, documentation, and course links for easy implementation. Additionally, the article discusses the compatibility of fastai with macOS and its support for ‘samoyed’ dataset in GitHub. It also introduces the pet classification dataset imagewoof from the fastai 2020 tutorial series and explores additional image classes found in Imagenet.\n\n\n\n\n\n\nAug 7, 2022\n\n\n\n\n\n\n\n\nMacOS locate fix and alternative\n\n\n\n\n\n\n\nfind file\n\n\nlocate file\n\n\nmacos\n\n\ntips\n\n\n\n\nThis article compares two methods for fixing and updating the locate command in MacOS. Comment A utilizes a launch daemon and terminal commands, while Comment B suggests repairing it using `mdfind` terminal commands.\n\n\n\n\n\n\nAug 7, 2022\n\n\n\n\n\n\n\n\nTermux_Boot Autostart Program Fixes\n\n\n\n\n\n\n\nautostart\n\n\nstub\n\n\ntermux\n\n\n\n\nThis article addresses the compatibility issues of Termux:Boot with Android 10 and above, proposing the use of absolute paths as a solution. The content also highlights some popular applications of Termux, including maintaining wakelock, starting SSHD or crond services, and running non-blocking applications like nginx.\n\n\n\n\n\n\nAug 6, 2022\n\n\n\n\n\n\n\n\nDeeplearning on MacOS M-series Processors\n\n\n\n\n\n\n\nCoreML\n\n\ndarling\n\n\nhackintosh\n\n\npaddlepaddle\n\n\nSwift\n\n\n\n\nThis article covers deep learning on MacOS, exploring the use of M-series processors and AMD GPUs for training. It discusses training with a MacBook Air, using TensorFlow Metal and PyTorch with MPS. The article also delves into CoreML image analysis techniques and AutoML for Apple’s M1 chips. Additionally, it covers image/video analysis methods, Optical Flow, Person Segmentation, NLP APIs, sentiment analysis, speech recognition, and sound classification using DNNs.\n\n\n\n\n\n\nAug 6, 2022\n\n\n\n\n\n\n\n\nResolve Host Name Computer Name From IP\n\n\n\n\n\n\n\nhacking\n\n\nhost name resolve\n\n\nnetwork\n\n\nnmap\n\n\nstub\n\n\n\n\nThis article delves into the different approaches for resolving host names, computer names, and IP addresses. It explores the utilization of tools such as NetBIOS and DHCP in this regard. Additionally, it highlights the integration of Lua with Nmap’s script engine (NSE) to automate network scanning and assaults.\n\n\n\n\n\n\nAug 5, 2022\n\n\n\n\n\n\n\n\nReverse Proxy Free Frp Providers, Remote Code Editing, Remote Development\n\n\n\n\n\n\n\np2p\n\n\nremote control\n\n\nsync\n\n\n\n\nThe article delves into using reverse proxy for remote code editing and highlights the importance of security measures like implementing p2p server nodes and user authentication. It also provides step-by-step guides on installing and configuring VPNs, remote filesystem servers, frpc, SSHFS, Rclone, htpasswd, inotify across different operating systems. Additionally, it suggests alternative tools such as Code-Server or Code-Server-Insider for accessing remote code servers, while also offering valuable tips to remember while utilizing these applications.\n\n\n\n\n\n\nAug 4, 2022\n\n\n\n\n\n\n\n\nRemove Unused pip dependencies\n\n\n\n\n\n\n\nclean trash\n\n\npython\n\n\nremove unwanted\n\n\nsystem manage\n\n\n\n\nThis article provides a detailed explanation on how to use pip-autoremove in Python. It discusses the process of removing unused package dependencies that were installed via pip, while highlighting the importance of exercising caution as these dependencies may still be utilized by other packages or your own code.\n\n\n\n\n\n\nAug 4, 2022\n\n\n\n\n\n\n\n\nRoyalty Free Video/Picture/Audio Sources\n\n\n\n\n\n\n\ndewatermark\n\n\nmedia sources\n\n\nobject tracking\n\n\nstub\n\n\n\n\nThis article provides methods for obtaining royalty-free video, image, and audio sources without watermarks. It suggests using tools like ‘video_spider’ for downloading videos from various apps, target tracking algorithms for removing dynamic watermarks, and the ‘dewatermark algorithm’ for static watermarks. Additionally, it mentions using Bing wallpapers and providing scrapers for GettyImages and Visual China without watermarks.\n\n\n\n\n\n\nAug 4, 2022\n\n\n\n\n\n\n\n\nPopular Video Sites\n\n\n\n\n\n\n\ninformation gathering\n\n\nscraping\n\n\nvideo sources\n\n\n\n\nThis article discusses the prevalence of various video and streaming platforms, such as Twitch, Netflix, YouTube, Instagram, Twitter, Pornhub, Bilibili, Douyu, Huya, iQiyi, Youku, and Weibo. These platforms offer a diverse range of content, including entertainment, education, social media, and streaming services, making them popular choices for users worldwide.\n\n\n\n\n\n\nAug 3, 2022\n\n\n\n\n\n\n\n\nFree Mathematica Activation Method\n\n\n\n\n\n\n\nactivation\n\n\nmathematica\n\n\nnon-free\n\n\nwolfram\n\n\n\n\nLearn how to generate a Mathematica activation code using an online code generator and your free Wolfram account. Follow the instructions to locate and edit the `mathpass` file, enabling you to successfully activate the software.\n\n\n\n\n\n\nAug 3, 2022\n\n\n\n\n\n\n\n\nInteresting xkcd style plots and characters generator in Mathematica/Wolfram Language\n\n\n\n\n\n\n\nanimation\n\n\nplot\n\n\nstub\n\n\nvideo generator\n\n\nvideo styles\n\n\nwolfram\n\n\n\n\nThis content delves into the process of creating xkcd-like plots and characters using Mathematica or Wolfram Language, as exemplified by links to Stack Exchange and a Wolfram blog post.\n\n\n\n\n\n\nAug 3, 2022\n\n\n\n\n\n\n\n\nbilibili 账号找回\n\n\n\n\n\n\n\naccount retrieval\n\n\nbilibili\n\n\nschedule\n\n\nstub\n\n\n\n\nA user contacted bilibili customer service for account recovery assistance and received a reminder to check their phone bills weekly starting August 19th. Additionally, new registrants can switch plans after 6 months to an 8 yuan monthly option.\n\n\n\n\n\n\nJul 31, 2022\n\n\n\n\n\n\n\n\nTime Machine NAS macOS\n\n\n\n\n\n\n\nbackup\n\n\nmacos\n\n\nstub\n\n\ntime machine\n\n\n\n\nIn this article, the author discusses their backup plan that involves using rclone to periodically commit files to a NAS or external SSD. They also consider using an Airport Extreme router and investing in an SSD with USB-C cables for improved efficiency and convenience.\n\n\n\n\n\n\nJul 28, 2022\n\n\n\n\n\n\n\n\nClash route only github related domains to fastgithub\n\n\n\n\n\n\n\ncircumvention\n\n\nclash\n\n\ngithub\n\n\nnetwork\n\n\n\n\nThis article provides detailed instructions on how to route GitHub-related domains through Fastgithub using Clash and configuring DNS settings. It covers various system-specific methods, including launchctl for macOS and systemd for Linux, as well as alternative options like monit and shell scripts.\n\n\n\n\n\n\nJul 27, 2022\n\n\n\n\n\n\n\n\nmacOS window click-through\n\n\n\n\n\n\n\nGUI\n\n\nmacos\n\n\ntips\n\n\nuser experience\n\n\n\n\nThis article provides instructions on utilizing the macOS command-click feature, enabling users to interact with inactive windows without accidentally activating them. This functionality is unique to macOS and not available on Linux or Windows systems.\n\n\n\n\n\n\nJul 27, 2022\n\n\n\n\n\n\n\n\nSearch and switch to window by title\n\n\n\n\n\n\n\nmulti window manager\n\n\nproductivity\n\n\nsearch window by name\n\n\nwindow manager\n\n\n\n\nThis article provides detailed instructions on how to search and switch between windows using tools like xdotool and wmctrl for various operating systems such as Windows, macOS, and Linux. It covers the installation process via the apt package manager, making it easy for users to follow along and enhance their window management experience.\n\n\n\n\n\n\nJul 27, 2022\n\n\n\n\n\n\n\n\nMacbook M1 create macOS recovery usb\n\n\n\n\n\n\n\nmacos\n\n\nrecovery\n\n\nstub\n\n\n\n\nThis text offers step-by-step guidance on how to create a macOS recovery USB for Macbook M1 devices, which can be useful in situations where system troubleshooting or reinstallation is required.\n\n\n\n\n\n\nJul 27, 2022\n\n\n\n\n\n\n\n\nLinux restore window sessions\n\n\n\n\n\n\n\nlinux\n\n\nrestore\n\n\nrestore session\n\n\nservice\n\n\n\n\nThis article outlines various methods to restore Linux window sessions using tools such as wmctrl, devilspie, and launch_on_workspace. It also provides links to helpful online resources for starting applications in specific workspaces and explains how to manually restore a session by enabling auto-save-session in org.gnome.gnome-session through dconf-editor.\n\n\n\n\n\n\nJul 27, 2022\n\n\n\n\n\n\n\n\nCPU Overheating (temperature too high)\n\n\n\n\n\n\n\nfan\n\n\nhardware\n\n\nlinux\n\n\nthermal\n\n\nthrottle\n\n\n\n\nThis article discusses the issue of CPU overheating in Linux systems and provides potential solutions such as cpufrequtils and temp-throttle. The recommended desired temperature is 60°C, and managing CPU temperature effectively can help reduce the likelihood of GPU issues.\n\n\n\n\n\n\nJul 25, 2022\n\n\n\n\n\n\n\n\nAudio Ducking\n\n\n\n\n\n\n\naudio processing\n\n\nducking\n\n\nffmpeg\n\n\nlive streaming\n\n\nstub\n\n\n\n\nThis article discusses Audio Ducking, a technique used to lower the volume of background music or sounds when speech is present. It covers offline ducking using Audionorm in Editly and online streaming ducking.\n\n\n\n\n\n\nJul 25, 2022\n\n\n\n\n\n\n\n\n免流帮 停机卡上网 持续上网\n\n\n\n\n\n\n\nalways online\n\n\nfree internet\n\n\ninternet\n\n\nnetwork\n\n\n白嫖\n\n\n\n\nFreeFlow Help offers a secure way to stay connected using stolen credentials and RSA encryption. It collects network account details, provides an encrypted authentication interface, and employs a static page for enhanced security. The access control panel allows you to manage connections by occupying or releasing them, and it supports bypassing campus networks without requiring authentication.\n\n\n\n\n\n\nJul 25, 2022\n\n\n\n\n\n\n\n\nVim Custom color scheme\n\n\n\n\n\n\n\ncolor scheme\n\n\nstub\n\n\ntips\n\n\nvim\n\n\n\n\nThis text provides a guide on how to create a personalized color scheme for Vim, a widely-used text editor. It offers recommendations on utilizing documentation resources for syntax highlighting and also includes details about terminal color codes and keywords specific to vertical splitters and the bottom line in Vim.\n\n\n\n\n\n\nJul 24, 2022\n\n\n\n\n\n\n\n\n蹭网WiFi天线 雷达扫描 五轴机械臂\n\n\n\n\n\n\n\nfree internet\n\n\nhardware\n\n\ninternet\n\n\nnetwork\n\n\nstub\n\n\nsystem avaliability\n\n\n白嫖\n\n\n\n\nA WiFi scanning radar system has been developed using a five-axis robotic arm and a custom-made antenna. The setup employs advanced algorithms and long extension cords to detect WiFi sources and their directions automatically. For optimal results, the system should be placed on a high support with no obstructions near the antenna.\n\n\n\n\n\n\nJul 22, 2022\n\n\n\n\n\n\n\n\nCloud based Github Web IDE, VSCode auto commit and lightweight terminal IDE\n\n\n\n\n\n\n\nagile editing\n\n\ncloud IDE\n\n\ndevops\n\n\nsync\n\n\n\n\nGitFS is a powerful tool that allows users to mount Git/GitHub repos as read-write user filesystems using FUSE. This innovative approach offers advantages over traditional cloud-based Git IDEs, while also providing customization resources for popular platforms such as VSCode Insider and SpaceVim. Users can enjoy the benefits of a fully searchable Git history combined with the convenience of a local filesystem, making it an essential tool for efficient code management.\n\n\n\n\n\n\nJul 21, 2022\n\n\n\n\n\n\n\n\nSEO tools\n\n\n\n\n\n\n\nSEO\n\n\nstub\n\n\n\n\nThis text introduces a collection of SEO tools available on GitHub, including keyword selection models, tag recommenders, and research tools, aimed at assisting users in optimizing their website’s search engine rankings.\n\n\n\n\n\n\nJul 18, 2022\n\n\n\n\n\n\n\n\nSentence Word order corrector\n\n\n\n\n\n\n\nNLP\n\n\nstub\n\n\ntext corrector\n\n\n\n\nThis article discusses a model design for correcting sentence word order, using fixed length input sequences and outputting word order tokens for decoding final word sequences. The model can handle both misplaced sentences or correct ones, focusing on English grammar improvement.\n\n\n\n\n\n\nJul 18, 2022\n\n\n\n\n\n\n\n\nNTFS recovery tool for bilibili cookie under AutoUP\n\n\n\n\n\n\n\nNTFS\n\n\nrecovery\n\n\nremedy\n\n\nsystem manage\n\n\nundelete\n\n\n\n\nThis article discusses NTFS recovery tools for retrieving bilibili cookies from AutoUP and emphasizes the importance of unmounting the disk before scanning. It provides various methods, including using adb shell commands with pv or netcat/gzip, and mentions solutions to LF encoding issues.\n\n\n\n\n\n\nJul 17, 2022\n\n\n\n\n\n\n\n\ngithub Gitee 大文件大型repo如何上传\n\n\n\n\n\n\n\ncloud sync\n\n\ngit manage\n\n\nrepo manage\n\n\nsync\n\n\nsystem manage\n\n\n\n\nThis guide provides a detailed explanation on how to upload large repositories to GitHub or Gitee, while excluding specific file types like Xonsh and YAML. The guide also covers the process of deploying SSH keys for enhanced security, automating sync processes using Visual Studio Code, and utilizing file locks for various tasks to ensure data integrity.\n\n\n\n\n\n\nJul 16, 2022\n\n\n\n\n\n\n\n\n模板创作模式 自媒体 洗稿\n\n\n\n\n\n\n\nidea\n\n\nparaphraser\n\n\ntemplate based generator\n\n\n\n\nThe article explores different methods for content creation, such as using templates, web scraping, AI models, and Python’s textrank4zh library for summarization. It also addresses the limitations of using Google’s translation tool for ghostwriting due to grammar and context issues.\n\n\n\n\n\n\nJul 15, 2022\n\n\n\n\n\n\n\n\nPyatspi dogtail gnome accessibility gui inspect tool for linux a11y\n\n\n\n\n\n\n\naccessibility\n\n\ndogtail\n\n\nGUI automation\n\n\nGUI inspection\n\n\ninspection\n\n\nlinux\n\n\npyatspi\n\n\nRPA\n\n\n\n\nThis article highlights various accessibility tools and frameworks like Pyatspi, dogtail Gnome, Appium Linux Accessibility, and Pywinauto. It also stresses the significance of readbility.js and Meilisearch for enhancing web history search and incorporating a11y into Firefox and GNOME’s ATK browsers.\n\n\n\n\n\n\nJul 15, 2022\n\n\n\n\n\n\n\n\n复读机 Chatbot\n\n\n\n\n\n\n\nchatbot\n\n\nconversation\n\n\ninteraction\n\n\npyjom\n\n\nschedule\n\n\n\n\nThis article dives into various techniques for optimizing chatbot performance, including extending synonym dictionaries, managing training data, and utilizing GPT-2 for server optimization, feedback mechanisms, content promotion, CPU usage, backpropagation, and filters. The comments provide valuable insights on how to improve the efficiency of chatbots.\n\n\n\n\n\n\nJul 14, 2022\n\n\n\n\n\n\n\n\nChatbot, Self-hosted Model, Cloud Deploy, Cloud services, Free website hosting service\n\n\n\n\n\n\n\nchatbot\n\n\ncloud\n\n\nconversation\n\n\nmodel zoo\n\n\npyjom\n\n\ntraining data\n\n\n白嫖\n\n\n\n\nThis article delves into the world of AI chatbot development and deployment, exploring popular platforms like Heroku and Google App Engine. Additionally, it highlights useful API tools such as Hugging Face and PaddlePaddle to enhance your chatbot’s functionality.\n\n\n\n\n\n\nJul 14, 2022\n\n\n\n\n\n\n\n\nHarmonyOS Device Log to MySQL\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nThis article explains how to connect a HarmonyOS device’s logs to MySQL, providing the necessary login credentials and log file structure. It also provides guidance on decompressing .gz files and understanding their format for analysis.\n\n\n\n\n\n\nJul 14, 2022\n\n\n\n\n\n\n\n\nSEO 蓝海词 竞争度\n\n\n\n\n\n\n\npopular topic discovery\n\n\npyjom\n\n\nSEO\n\n\ntext analysis\n\n\ntopic analysis\n\n\ntrend analysis\n\n\n\n\nThis article explores SEO strategies for targeting low competition keywords, maximizing conversion rates and trade-off prices. It also covers black hat practices and alternative methods without a website. Additionally, the article delves into utilizing n-gram analysis in Python to cluster keywords for video content optimization by analyzing click rates and play counts.\n\n\n\n\n\n\nJul 14, 2022\n\n\n\n\n\n\n\n\n人脸识别 Face Recognition\n\n\n\n\n\n\n\nfacial\n\n\nfacial recognization\n\n\nimage recognization\n\n\n\n\nThe text discusses various GitHub repositories focused on face recognition technology, offering different implementations and resources for creating facial recognition systems using diverse programming languages and frameworks.\n\n\n\n\n\n\nJul 13, 2022\n\n\n\n\n\n\n\n\nTopic Generation 话题发现 趋势发现 热点发现\n\n\n\n\n\n\n\nNLP\n\n\nNLU\n\n\npyjom\n\n\ntext classification\n\n\ntopic discovery\n\n\n\n\nThe text provides resources for generating topics, discovering trends, and detecting new words using tools like BERT documentation, Chinese segment augmentation Github repositories, and a Naive Bayes classifier.\n\n\n\n\n\n\nJul 13, 2022\n\n\n\n\n\n\n\n\nPowerPoint 比较视频制作方法 Animation Software OSS Scriptable Flipcard\n\n\n\n\n\n\n\nanimation\n\n\nanimation framework\n\n\ncomparation video\n\n\ninformation gathering\n\n\npyjom\n\n\nscraping\n\n\nstub\n\n\nvideo generator\n\n\nvideo source\n\n\n\n\nThe comments provide insights on different video creation methods, tools, and open-source software options for Linux and JavaScript libraries like three.js and anime.js. Additionally, they discuss the use of LibreOffice Impress in combination with synfig, blender, or three.js for animations and suggest collecting search terms from Bing and Daojia for effective query formation.\n\n\n\n\n\n\nJul 13, 2022\n\n\n\n\n\n\n\n\nRepl for Assembly Code\n\n\n\n\n\n\n\nasm\n\n\nassembly\n\n\nhacking\n\n\nnasm\n\n\nrepl\n\n\nself-learning\n\n\n\n\nThis article discusses a Repl (Read-Eval-Print Loop) for Assembly code with processor flags output, developed by yrp604 and available on the GitHub repository named ‘rappel’. Moreover, it introduces an msf provided Repl called ‘msf-nasm_shell’.\n\n\n\n\n\n\nJul 13, 2022\n\n\n\n\n\n\n\n\nCreate and Import Backups in StandardNotes\n\n\n\n\n\n\n\nexport\n\n\nnote\n\n\nstub\n\n\n\n\nThis article provides a step-by-step guide on how to create and import backups in StandardNotes, an application designed for secure note-taking. The article emphasizes the importance of data security and offers detailed instructions on creating backups and importing them into StandardNotes. By following this guide, users can ensure their important information is safeguarded against potential data loss or unforeseen circumstances.\n\n\n\n\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\nSelf hosted web applications\n\n\n\n\n\n\n\nnetwork\n\n\nself-hosted\n\n\nstub\n\n\nwebapp\n\n\n\n\nThis article delves into the world of self-hosted web applications, offering a comprehensive list of open-source options like search engines. It empowers readers to explore and choose from various alternatives that suit their needs and preferences.\n\n\n\n\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\nTerminal autocomplete\n\n\n\n\n\n\n\nautocomplete\n\n\nfig\n\n\nstub\n\n\nterminal\n\n\n\n\nThis article discusses terminal autocomplete on Linux and MacOS, focusing on Fig and Warp tools. It explores the possible reasons why Vim might stop working and directs readers to known issues with Warp for further information.\n\n\n\n\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\nHacking tutorials, tools\n\n\n\n\n\n\n\nbotnet\n\n\ncrypto mining\n\n\nhacking\n\n\ntutorial\n\n\nvirus\n\n\n\n\nThis article delves into the realm of hacking tools and techniques used in Capture The Flag (CTF) events and professional scenarios. It highlights resources such as Hack The Box and GitHub repositories, which aid in skill improvement across various domains like assembly, automation, persistence, vision, and experience.\n\n\n\n\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\nPython Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue\n\n\n\n\n\n\n\nfault tolerance\n\n\nhack\n\n\nignore error\n\n\nignore exception\n\n\npython\n\n\n\n\nThis article discusses simplifying exception handling in various languages through methods such as time travel debugging and code execution using tools like dill. It covers resources for Common Lisp, Ruby, WallabyJS, contextlib, CPython bytecode, and the ‘with’ statement/suppress function. Comment B specifically highlights a decorator function that provides debugging and exception handling for wrapped functions with options for verbose output and breakpoint insertion in case of exceptions.\n\n\n\n\n\n\nJul 11, 2022\n\n\n\n\n\n\n\n\nVideo Effects Transitions\n\n\n\n\n\n\n\neffects\n\n\ntransition\n\n\nvideo analysis\n\n\nvideo effects\n\n\nvideo transition\n\n\nvideo understanding\n\n\n\n\nThis article highlights discussions on resources for creating video effects, transitions, and shot detection tools, including slideshow creators and AI-powered software.\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nAdvanced ASS subtitle Karaoke Effects\n\n\n\n\n\n\n\ndog video\n\n\nkaraoke\n\n\nlyric effects\n\n\nmusic video\n\n\npets video\n\n\nproject\n\n\npyjom\n\n\nsubtitle\n\n\nvideo effects\n\n\nvideo generator\n\n\nvideo with bgm\n\n\n\n\nExplore the possibilities of custom karaoke effects in Advanced Substation Alpha (ASS) subtitle files, specifically focusing on LRC tags and time-based grouping. This resource provides a comprehensive understanding of tags used for creating various effects and showcases practical examples to enhance your project’s visual appeal.\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nVideo Editors\n\n\n\n\n\n\n\npyjom\n\n\nvideo edit\n\n\nvideo generator\n\n\n\n\nThis article provides an overview of different video editors such as MoviePy, ffmpeg tools, OpenGL transitions, Remotion, Canvas2video, Videoshow, and MachineVideoEditor for deepfakes. Additionally, it covers command-line tools like Blind, JumpcutterV2, Jumpcutter, CutTheCrap, RabbitVE, and Video-CLI that offer features including removing silence and applying machine learning for editing.\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nBeautify 美颜\n\n\n\n\n\n\n\nbeautify\n\n\nfacial\n\n\npyjom\n\n\nstub\n\n\nvideo generator\n\n\n美颜\n\n\n\n\nThis article discusses the application of a beauty filter, also known as the ‘Beautify’ filter, to images using OpenCV’s bilateral filter in Python programming language. It provides links to GitHub repositories with code examples and tools for implementing this technique in various languages.\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nSimple Viral Video Generators\n\n\n\n\n\n\n\npopular video\n\n\nvideo generator\n\n\n\n\nThis article discusses Simple Viral Video Generators, highlighting GitHub repositories for RedditVideoMakerBot and videoWater. Additionally, it provides a website link, 51ai.top, which is related to automated marketing.\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\n百度 搜狗 公开API 搜索引擎爬虫 Baidu Search APIs Chatbot APIs\n\n\n\n\n\n\n\nAPI\n\n\nchatbot\n\n\nimage gathering\n\n\ninformation gathering\n\n\nsearch engine\n\n\n\n\nThis article explores various API’s and scrapers available for accessing data, images, conversations, and trending topics from popular platforms like Baidu, Sogou, Weibo, Zhihu, and Microsoft’s Xiaoice.\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nPublic APIs, GIF Websites Funny Video Sources\n\n\n\n\n\n\n\nAPIs\n\n\nEntertainment Data\n\n\nFunny Videos\n\n\nGIFs\n\n\nMemes\n\n\nImgur\n\n\nGiphy\n\n\n\n\nThis article discusses APIs for accessing various forms of entertainment data, such as funny videos, GIFs, and memes from popular platforms like Imgur, Giphy, YouTube8M, ifunny.co, Reddit, and an ML algorithm specifically designed to identify humorous music videos.\n\n\n\n\n\n\nJul 9, 2022\n\n\n\n\n\n\n\n\n哔哩哔哩 接口 Bilibili APIs\n\n\n\n\n\n\n\nAPI\n\n\nbilibili\n\n\nstub\n\n\n\n\nBilibili APIs allow developers to create tools and applications in various languages like Python for tasks such as video uploading, user account management, and more.\n\n\n\n\n\n\nJul 9, 2022\n\n\n\n\n\n\n\n\nCut Music Scenes With Lyrics and BPM\n\n\n\n\n\n\n\naudio analysis\n\n\nBPM finder\n\n\ndog video\n\n\nproject\n\n\npyjom\n\n\n\n\nThis code snippet defines a compare function that allows for cutting music segments based on lyrics and BPM (beats per minute). The function uses two variables, seg_low and seg_high, to determine the allowed segment range. Candidates are sorted by nearby lyrics and BPM, with lyrics given priority.\n\n\n\n\n\n\nJul 8, 2022\n\n\n\n\n\n\n\n\nSoul API\n\n\n\n\n\n\n\nAPI\n\n\naudio source\n\n\ninformation gathering\n\n\nscraping\n\n\nsoul\n\n\ntext source\n\n\nvideo source\n\n\n\n\nThis article provides instructions on how to set up a man-in-the-middle (MITM) proxy on an Android device using mitmproxy and access various API endpoints for Soul app data, such as user profiles, recent moments, hot instant moments, and audio playlists.\n\n\n\n\n\n\nJul 8, 2022\n\n\n\n\n\n\n\n\nNautilus Hangs When Searching\n\n\n\n\n\n\n\nbug\n\n\ngnome\n\n\nissue\n\n\nlinux\n\n\nnautilus\n\n\ntips\n\n\n\n\nThis article offers a solution to the problem of Nautilus file manager hanging during search operations. The proposed fix involves deleting the ‘~/.cache/tracker’ folder, which should resolve the issue.\n\n\n\n\n\n\nJul 7, 2022\n\n\n\n\n\n\n\n\nhow to extend vmdk in oracle virtualbox\n\n\n\n\n\n\n\ndisk expansion\n\n\nsystem manage\n\n\nvirtualbox\n\n\nvirtualization\n\n\n\n\nThis article provides a detailed guide on how to resize VMDK files in Oracle VirtualBox on Windows 7 using either command prompt or GParted Live CD. The process involves downloading the GParted ISO, creating a new virtual machine, resizing partitions, and applying changes.\n\n\n\n\n\n\nJul 5, 2022\n\n\n\n\n\n\n\n\nemail scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT\n\n\n\n\n\n\n\nadvertising\n\n\nmail sending\n\n\nSMS\n\n\n\n\nThis article delves into email verification techniques and strategies, along with methods to send mass emails or SMS anonymously. It highlights platforms like mailcat and theHarvester for collecting emails, APIs for SMS flooding, and Telegram bots for efficient marketing.\n\n\n\n\n\n\nJul 4, 2022\n\n\n\n\n\n\n\n\nEnable multiple concurrent RDP sessions on windows\n\n\n\n\n\n\n\nhack\n\n\npatch\n\n\nRDP\n\n\nremote control\n\n\nwindows\n\n\n\n\nThis text provides instructions on how to enable the capability for multiple simultaneous Remote Desktop Protocol (RDP) sessions on Windows systems. This can be achieved by utilizing a modified termsrv.dll file, which allows users to connect and access resources concurrently.\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n\n\nSpeedUp Tujia Scraping\n\n\n\n\n\n\n\nclash\n\n\nfreelancer\n\n\ntips\n\n\n\n\nThe article focuses on a project called “SpeedUp Tujia Scraping”. It explains how to identify the request that sets the cookie and recommends using DIRECT for other requests while directing only that specific request to GLOBAL.\n\n\n\n\n\n\nJun 27, 2022\n\n\n\n\n\n\n\n\n复习补考的科目 补课 课程 补习\n\n\n\n\n\n\n\ncollege\n\n\nschedule\n\n\nstub\n\n\nstudy\n\n\n\n\nThe university course schedule program is designed to assist students in organizing their academic plans, retrieving relevant class and exam details, and displaying grades on a scale of 0.0 to 6.0. The program categorizes subjects into required/elective options and features status markers for absences, incompletes, or failures.\n\n\n\n\n\n\nJun 26, 2022\n\n\n\n\n\n\n\n\nSound Effects\n\n\n\n\n\n\n\nmusic generation\n\n\nsound effects\n\n\nstub\n\n\nVST\n\n\n\n\nThe article discusses a project called ‘Sound Effects’, which is associated with Spotify’s pedalboard feature. This project offers support for VST plugins and allows users to create custom sound effects, enhancing their music listening experience.\n\n\n\n\n\n\nJun 24, 2022\n\n\n\n\n\n\n\n\nplaywright intercept request header cookie\n\n\n\n\n\n\n\ncookie\n\n\ncredential\n\n\ninformation gathering\n\n\nplaywright\n\n\nscraping\n\n\nstub\n\n\ntips\n\n\n\n\nThis blog post delves into Playwright’s handling of request headers and cookies, with a focus on the context.cookies() method as an effective solution for addressing cookie-related challenges.\n\n\n\n\n\n\nJun 19, 2022\n\n\n\n\n\n\n\n\n资本 政治 商业 统治 管理 原理\n\n\n\n\n\n\n\nentrepreneurship\n\n\nideas\n\n\n\n\nThis text explores capital, politics, control, and management themes through concepts like unfulfillable promises, self-contradictions, lying, reversal of intentions, virtualization, and ideologization.\n\n\n\n\n\n\nJun 18, 2022\n\n\n\n\n\n\n\n\n捡塑料瓶机器人 吸硬币 回收硬币机器人\n\n\n\n\n\n\n\nhardware\n\n\nidea\n\n\nrobot\n\n\nstub\n\n\n\n\nThe article discusses innovative robots designed for recycling purposes. One robot is specialized in collecting plastic bottles, while the other retrieves coins from coin machines. These robots are aimed at promoting environmental conservation and efficiency in the recycling process.\n\n\n\n\n\n\nJun 18, 2022\n\n\n\n\n\n\n\n\n智能手表防水 泡温泉\n\n\n\n\n\n\n\nhardware\n\n\nshell\n\n\nstub\n\n\nwaterproof\n\n\n\n\nThis article discusses the design considerations for creating a smartwatch that can be used in hot springs or while showering. It highlights the importance of using heat and steam resistant adhesive, a protective case with sealant, ridges for added sealing strength, waterproof silicone covers or hard quality buttons with a silicone sealing layer, and avoiding rotatable buttons. The article also suggests that the case should come with a complementary strap and not use the original attachment system.\n\n\n\n\n\n\nJun 18, 2022\n\n\n\n\n\n\n\n\nbilibili up主启航计划\n\n\n\n\n\n\n\nbilibili\n\n\ncourses\n\n\nresources\n\n\nstub\n\n\n\n\nThis article provides information and links about the ‘bilibili up主启航计划’, a program on the video-sharing platform bilibili. It covers various aspects of the program, including its objectives, eligibility criteria, benefits, and resources for potential participants.\n\n\n\n\n\n\nJun 17, 2022\n\n\n\n\n\n\n\n\n控油 祛痘\n\n\n\n\n\n\n\nacne\n\n\nhealth\n\n\nskin care\n\n\n\n\nThis article discusses the importance of diet and skincare products in reducing oil production and preventing acne. It also highlights the role of stress management, temperature control, sun protection, and specific ingredients like fruit acids, honey, aloe vera, cinnamate, henna, and goldthread in maintaining healthy skin.\n\n\n\n\n\n\nJun 15, 2022\n\n\n\n\n\n\n\n\nvideo picture in picture detection\n\n\n\n\n\n\n\ncrop the crap\n\n\npicture in picture\n\n\nvideo analysis\n\n\n\n\nThis article delves into the difficulties of detecting picture-in-picture (PiP) videos, a common technique used in generating fake content. It highlights a Chinese patent related to PiP detection and an international research paper that explores this topic.\n\n\n\n\n\n\nJun 13, 2022\n\n\n\n\n\n\n\n\n现代 后现代 Vtuber 流行趋势\n\n\n\n\n\n\n\nidea\n\n\nsocial media\n\n\ntrends\n\n\n\n\nThis passage explores the evolving trends in VTubers, focusing on the use of existing popular content as templates to generate similar content. The article emphasizes the importance of audience feedback and clustering viewers to understand preferences and match them with appropriate content, ultimately aiming for a blend of modern and post-modern content that appeals to the evolving audience and stays ahead of trends.\n\n\n\n\n\n\nJun 11, 2022\n\n\n\n\n\n\nbilibili up主 入站了解 运作机制\n\n\n\nbilibili\ncommunity rules\ncourses\ncreater's rules\nintro\nrules\n\n\n\nThis article discusses the process of submitting and recommending videos on platforms like Bilibili. It explores video processing, content moderation, and recommendation algorithms based on scene characteristics, user behavior, and content quality.\n\n\n\n`Jun 10, 2022`{=html}\n\n\n\n\n\n\nUnderstanding the Psychology of Gaming and Its Impact on Community Formation\n\n\n\n\n\n\n\ngaming logic\n\n\nsubcultures in gaming\n\n\nisolation and gaming\n\n\ngaming audience attraction\n\n\ngame elements in content\n\n\nrepurposing game footage\n\n\ngamer demographic\n\n\n\n\nThis article explores the psychology behind gaming, delving into the reasons why individuals turn to games for escape from reality and how it is influenced by peers. It also examines the formation of gaming subcultures based on legitimacy and play modes. Furthermore, it highlights the isolation that gamers might experience due to game characteristics and suggests incorporating game elements in content or repurposing footage into strategies and tutorials as ways to attract this audience.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nJumpcut analysis, social media marketing, blackhat SEO\n\n\n\n\n\n\n\ncourses\n\n\nentrepreneurship\n\n\nsocial media\n\n\n\n\nThis article discusses the importance of improving digital marketing strategies using techniques like website analytics, SEO, and mentions Jumpcut.com as a platform that offers courses in these areas to help businesses enhance their online presence.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nSource code semantic search tool\n\n\n\n\n\n\n\ncode analysis\n\n\nhacking\n\n\nsource code understanding\n\n\n\n\nThis content explores semantic search tools for auditing source code in languages like Go and Haskell, providing examples of Sourcegraph and SonarQube.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nRemote Jobs\n\n\n\n\n\n\n\nfreelancer\n\n\njobs\n\n\nstub\n\n\n\n\nThis article highlights remote job opportunities in China. It provides a GitHub repository containing a list of available positions and also includes a link to Stack Overflow for further remote job prospects.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nquantatitive financial stock market analysis\n\n\n\n\n\n\n\nfinancial\n\n\nmarket\n\n\nquantative trading\n\n\nRL\n\n\nstock market\n\n\ntrading\n\n\n\n\nThis article provides an overview of popular Python libraries and frameworks for stock market analysis, trading software development, and high-frequency/low latency trading. It covers tools such as Altreva Adaptive Modeler, fms, MyTT, funcat, stable-baselines3, crypto trading bots, qlib, FinRL, OpenBBTerminal, Zipline, and Pyalgotrade, which can be used for tasks like data preprocessing, algorithm development, backtesting, and live trading. The article aims to help developers choose the right tool or combination of tools based on their specific needs.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nbilibili 生活区up 培训\n\n\n\n\n\n\n\nbilibili\n\n\ncourses\n\n\nlife section\n\n\ntraining\n\n\n\n\nThis announcement invites participants to a bilibili 生活区up 培训, which is a training or workshop related to the platform’s Life Zone and user participation program. The event aims to provide insights and opportunities for users who want to engage with the Life Zone community and learn more about the UGC (user-generated content) guidelines.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nNLP Packages\n\n\n\n\n\n\n\nnatural language\n\n\nNLG\n\n\nNLP\n\n\nquestion answering\n\n\nquestion generation\n\n\n\n\nThe article explores the field of Natural Language Processing (NLP) and its various frameworks, including sentiment analysis, text clustering, and summarization. It highlights question answering capabilities as a significant aspect of NLP and introduces packages like questgen.ai for essay questions and Jiagu’s offerings such as word segmentation and named entity recognition.\n\n\n\n\n\n\nJun 9, 2022\n\n\n\n\n\n\n\n\nSearch Engines\n\n\n\n\n\n\n\ndiy\n\n\nsearch engine\n\n\nself-hosted\n\n\n\n\nThis article compares different search engine tools and techniques, including fzf and grep custom building, optimization methods, alternative engines like Whoole and TxtAI for censorship circumvention, meta-search capabilities with Searx, MarcoBiedermann’s crawler, BenBusby’s Whoogle, Yacy, and creating a Node.js web interface with MeiliSearch for data uploading. The article evaluates their performance and intuitive web interfaces to help readers make informed decisions about which tools are best suited for their needs.\n\n\n\n\n\n\nJun 8, 2022\n\n\n\n\n\n\n\n\nHardware for fun moment capturing\n\n\n\n\n\n\n\nbuffering\n\n\nhardware\n\n\ninstant capturing\n\n\nvideo capturing\n\n\n\n\nThis device allows you to capture fun moments by using a head-mounted coaxial camera and long-range microphone. It offers buffered recording mode, separate buttons for recording and saving, is implemented with Micropython, has a large battery, and is designed for enjoyment.\n\n\n\n\n\n\nJun 7, 2022\n\n\n\n\n\n\n\n\n途家scraping api\n\n\n\n\n\n\n\nAPi\n\n\nfreelancer\n\n\n\n\nThis article describes a scraping API that allows users to retrieve data from various sources with certain restrictions. The API can handle up to 58 pages, each containing 30 items, resulting in a maximum of 1740 items. Users can sort the results by region and price, potentially reducing the total number below 3480 by applying additional filters. If the limit is exceeded, an inspiration-based strategy is used but it might not support pausing and resuming data collection.\n\n\n\n\n\n\nJun 5, 2022\n\n\n\n\n\n\n\n\nRoll in Bed在床上翻滚\n\n\n\n\n\n\n\nhealth\n\n\nlifestyle\n\n\nrest\n\n\n\n\nThis article emphasizes the significance of avoiding extended periods of lying in bed and encourages physical movement to facilitate digestion. It highlights the discomfort caused by overeating and recommends finding a tranquil spot for relaxation post-meals. Additionally, it cautions against consuming excessive amounts at night, late-night eating habits, and alcohol intake during evening hours.\n\n\n\n\n\n\nJun 4, 2022\n\n\n\n\n\n\n\n\nWhat experiences do ISTP people have?\n\n\n\n\n\n\n\nMBTI\n\n\npsychological\n\n\n\n\nThis article discusses the various challenges faced by students, including difficulties with abstract concepts and traditional classroom settings, balancing school and work, living in poor conditions, dealing with parental pressure, and the impact of technology on relationships and self-identity.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\n传播学 2\n\n\n\n\n\n\n\ncourses\n\n\nMOOC\n\n\npropagation study\n\n\n\n\nThis article provides an in-depth analysis of the concept of Passive Propagation, specifically focusing on Section 2. It covers topics related to passive propagation and how they affect various systems or processes.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\n传播学\n\n\n\n\n\n\n\ncourses\n\n\nMOOC\n\n\npropagation study\n\n\n\n\nThis article, titled ‘传播学 1’ in Chinese, is believed to be the first installment of a series on propagation science or theory. It delves into the fundamental principles and concepts governing this field, providing readers with an in-depth understanding of its core foundations.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\nMySQL Cheatsheet\n\n\n\n\n\n\n\ndatabase\n\n\nmysql\n\n\nreference\n\n\n\n\nThe MySQL cheatsheet is a handy resource for quickly referencing various usage scenarios and essential tasks in database management, including creating tables, modifying table structure, deleting/retrieving data, working with constraints, and utilizing SQL functions.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\nMongoDB Cheatsheet\n\n\n\n\n\n\n\ncheatsheet\n\n\ndatabase\n\n\nmongodb\n\n\nreference\n\n\n\n\nThis reference link leads to a MongoDB cheatsheet, which can be accessed via the given URL: https://www.mongodb.com/developer/products/mongodb/cheat-sheet/. The cheatsheet provides a quick and easy way to remember essential commands and concepts related to MongoDB.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\nRedis Cheatsheet\n\n\n\n\n\n\n\ncheatsheet\n\n\ndatabase\n\n\nredis\n\n\nreference\n\n\n\n\nThis article provides a comprehensive Redis Cheatsheet that covers fundamental Redis commands, essential operations, advanced features like batch operations, hashes, counters, and list manipulation. It also includes settings for performance and memory optimization, database management tools, replication setup, performance testing, monitoring slow queries, and managing multiple databases using Twemproxy or Codis.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\nNeo4j Refcard\n\n\n\n\n\n\n\ngraph database\n\n\nneo4j\n\n\nreference\n\n\n\n\nThis Neo4j Cypher Cheatsheet provides a comprehensive overview of essential graph query operations and advanced features, focusing on user management, transaction handling, and large dataset queries. It is specifically designed for Enterprise Edition users with role-based privilege management.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\nNeo4j learning notes\n\n\n\n\n\n\n\ngraph database\n\n\npyjom\n\n\nself-learning\n\n\nsyntax\n\n\n\n\nThis article explains the use of Neo4j for indexing, querying relationships, and creating recommendation systems using customer ratings and cosine similarity calculations. The comments provide code examples, update node properties, and cover static/dynamic value access in maps and lists for sorting and filtering items by topics or properties.\n\n\n\n\n\n\nJun 3, 2022\n\n\n\n\n\n\n\n\nSocial Media Platforms\n\n\n\n\n\n\n\nplatforms\n\n\nsocial media\n\n\nstub\n\n\n\n\nThis article explores the various forms of content found on popular social media platforms and delves into the process of web scraping to extract data for analysis. Additionally, it discusses strategies to mitigate advertising impact within these platforms.\n\n\n\n\n\n\nJun 2, 2022\n\n\n\n\n\n\n\n\nBookmark Browsing History Collection\n\n\n\n\n\n\n\nbrowsing history\n\n\nhistory\n\n\n\n\nThis article discusses the process of organizing directories using Termux and compares it with alternatives like Meilisearch, which consumes a lot of RAM. The author considers an alternative solution - ripgrep (rg) for faster searching, and provides an example shared on GitHub and various file-sharing platforms.\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\nKiwi Browser Bookmarks\n\n\n\n\n\n\n\nbrowsing history\n\n\nhistory\n\n\n\n\nIn this text, the user is given instructions on how to copy their Kiwi Browser bookmarks from an Android device to a new location. The command ‘sudo cp’ is used along with a specific file path to accomplish this task. The date provided is June 1st, 2022.\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\nGithub Bookmarks from James4deutschland\n\n\n\n\n\n\n\nexport\n\n\ngithub\n\n\nhistory\n\n\n\n\nThis article explains a method for capturing Github data by utilizing proxies and VPNs, along with tools like mitmproxy, pcapdroid, and gh_stars_export to handle accounts requiring cookies or credentials.\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\nTime Series Analysis\n\n\n\n\n\n\n\nAI\n\n\ndata analysis\n\n\nfinancial\n\n\nforecasting\n\n\nstock market\n\n\ntime series\n\n\n\n\nThis article delves into time series analysis and introduces three projects: Bosun, a tool for time series alerting; deep-learning-time-series, an implementation of deep learning techniques for forecasting; and LSTM-Neural-Network-for-Time-Series-Prediction, a project focusing on using LSTM neural networks to predict stock market trends.\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\nA Python Wrapper for FFmpeg: Simplifying Command-Line Functionality\n\n\n\n\n\n\n\nPython\n\n\nFFmpeg\n\n\nWrapper\n\n\nGitHub\n\n\nScripting\n\n\nMultimedia\n\n\nCommand-line\n\n\n\n\nThis article discusses a Python wrapper for the widely-used FFmpeg command-line tool. The wrapper, found on GitHub, simplifies the integration of FFmpeg’s capabilities into Python scripts.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nMusic to video generator GAN\n\n\n\n\n\n\n\ndance video generator\n\n\nmusic to video\n\n\ntext to video\n\n\nvideo generation\n\n\n\n\nResearchers have developed a Text-to-Video/Music-to-Video generator GAN that creates dance animations based on music genres. This novel approach utilizes a choreography-oriented embedding framework and cross-modal transformers to build a 3D dance dataset, allowing for the generation of unique dance animations synchronized with specific musical styles.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nSketch based applications\n\n\n\n\n\n\n\nAI\n\n\nanimation\n\n\nimage generation\n\n\nsketch\n\n\n\n\nSketch-based applications leverage AI technology to transform and bring life to sketches through completion and animation, exemplified by Magenta Studio and Inbetweening.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nYoutube Monitization 油管变现\n\n\n\n\n\n\n\nentrepreneurship\n\n\nidea\n\n\nmonitization\n\n\nstub\n\n\nyoutube\n\n\n\n\nThis article offers eight methods to monetize YouTube content, providing a valuable resource for creators looking to generate income from their videos.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\n程序员笑话 可当文案 jokes about programmers\n\n\n\n\n\n\n\nimage sources\n\n\nimages\n\n\ninformation gathering\n\n\njokes\n\n\ntext sources\n\n\nvideo sources\n\n\n\n\nThis article discusses a collection of programmer jokes, including a list from Runoob and Telegram channels dedicated to programming humor.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nImage Restoration Upscaling\n\n\n\n\n\n\n\nimage processing\n\n\nimage upscaling\n\n\nsuper resolution\n\n\nvideo processing\n\n\n\n\nThis article explores image restoration, upscaling, and inpainting techniques. It highlights LAMACleaner as a cutting-edge image inpainting tool, which requires manual labeling. Additionally, it covers Deep Image Prior, NAS Image Prior, and mmediting, an open-source toolbox for various image and video restoration, editing, and generation tasks.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nVideo delogo_inpainting\n\n\n\n\n\n\n\ndewatermark\n\n\nremove watermark\n\n\nroyalty free\n\n\nstub\n\n\n\n\nThis article compares two methods for detecting and removing watermarks. Comment A focuses on video watermarks using specific transforms/models, while Comment B emphasizes local contrast enhancement for subtle watermark detection improvements.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nAlgorithms Compilers SICP CLRS CT4S\n\n\n\n\n\n\n\nalgorithms\n\n\nself-study\n\n\n\n\nThis article offers a collection of resources for learning algorithms, compilers, and programming. It includes introductions to the Algorithms book in Python, official CLRS 4th edition Python code, alternative Python implementations of CLRS, SICP in Python, and unofficial Python versions of the Algorithms 4th edition.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nTypeMonkey 字说 OSS alternative\n\n\n\n\n\n\n\nstub\n\n\ntext to video\n\n\nvideo generator\n\n\n\n\nTypeMonkey is a JavaScript-based solution that serves as an alternative to OSS (Open Scripting Standard), enabling users to modify existing code on web pages. It can be explored at nostarsnow.github.io/2019/01/20/typemonkey, and the project’s code is available on GitHub at github.com/nostarsnow/typeMonkey.js.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nOptical Flow\n\n\n\n\n\n\n\noptical flow\n\n\nstub\n\n\nvideo analysis\n\n\nvideo feature extraction\n\n\n\n\nThe text explores Optical Flow, a technique used in computer vision to estimate motion between frames of video sequences. It highlights ‘flownet’ by NVIDIA, an optical flow SDK compatible with most Turing GPUs but excluding GTX1650(tu117). Additionally, it introduces mmflow from OpenMMLab, available at the provided link.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\n全自动电影解说软件介绍\n\n\n\n\n\n\n\ninformation gathering\n\n\npopular video generator\n\n\nsocial media\n\n\nvideo generator\n\n\n\n\nThis article delves into the world of automatic video generation, exploring various methods and tools that facilitate the creation of diverse content such as YouTube videos, short films, Twitch compilations, TikTok videos, and more. Techniques covered include using templates, images, background music (BGM), voiceovers, filtering, effects, subtitling, single video editing, and transforming text into voiceovers.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nDeepNude Censorship NSFW safesearch\n\n\n\n\n\n\n\ncensorship\n\n\nNSFW\n\n\n\n\nAI-based NSFW detection utilizes image classification, profanity filters, and violence detection through techniques such as SVM and CNNs, with a focus on bloody images. Content moderation tools involve text/image filters, evasion methods, and political considerations.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nDeepfake face swap\n\n\n\n\n\n\n\nface changer\n\n\nvideo generator\n\n\n\n\nThe text focuses on Deepfake face swap technologies, covering notable software like DeepFaceLab, Faceswap, and SimSwap. These tools facilitate advanced video generation with face swaps and single model transformations.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nJiggy boring still image to funny dance video 跳舞 舞蹈\n\n\n\n\n\n\n\ndancing\n\n\nmotion driven video\n\n\nstub\n\n\nvideo generator\n\n\n\n\nThe project, available on GitHub, is a creative application of AI that converts static images into dance videos. It comes with MMD format conversion tools and an online demo for users to experience the transformation. Additionally, it includes video examples showcasing its capabilities, and utilizes the CoNR group chat for collaboration and updates.\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\nMastering Text Classification: Exploring NLP Techniques with BERT-NER, ALBERT-NER, GPT2, and More\n\n\n\n\n\n\n\nNLP\n\n\nBERT-NER\n\n\nALBERT-NER\n\n\nGPT2-generation\n\n\nBiLSTM+Attention\n\n\nTextCNN\n\n\nTextGCN\n\n\n\n\nThis tutorial provides an overview of different natural language processing (NLP) techniques for text classification. It covers a range of methods, including BERT-NER, ALBERT-NER, GPT2-generation, BiLSTM+Attention, TextCNN, and TextGCN. These techniques are applicable to both Chinese and English languages, making it a valuable resource for developers working with diverse language datasets.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nEssay grading\n\n\n\n\n\n\n\ngrading\n\n\nscoring\n\n\nsentiment\n\n\ntext analysis\n\n\n\n\nThis article discusses the use of three automated essay grading tools: LSTM Grading, Essay Scoring, and Neural Essay Assessor. These tools utilize Recurrent Neural Networks (RNN) to evaluate the quality of essays, providing an efficient and reliable method for assessing written work.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nChinese Input Method or Engine\n\n\n\n\n\n\n\nchinese\n\n\nIME\n\n\ninput method\n\n\nNLP\n\n\npinyin\n\n\n\n\nThis article presents a variety of Python-based Chinese input tools such as LoginputEngine, Pinyin2Hanzi, python-pinyin, pyim Tsinghua dict (Emacs), and IMEWLCConverter. These resources aid in the conversion between Chinese characters and pinyin, facilitating Chinese text input.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nUpload Model To Huggingface\n\n\n\n\n\n\n\nbackup\n\n\ngit\n\n\nhuggingface\n\n\nmodel\n\n\nnetwork\n\n\nstub\n\n\nsync\n\n\n\n\nThis article provides a step-by-step guide on how to upload a model to Hugging Face’s Hub using code. It includes a link for detailed instructions and demonstrates the process with the Camembert language model, utilizing AutoModelForMaskedLM and AutoTokenizer from Transformers library. The model and tokenizer are then pushed to the Hub under the name ‘dummy-model’.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nImage classification, cloth Classification\n\n\n\n\n\n\n\ncloth classification\n\n\nimage classification\n\n\nstub\n\n\n\n\nThis article discusses image and cloth classification using advanced models such as vit-pytorch and a feed forward neural network. The vit-pytorch model employs multiple attention heads for efficient image classification, while the feed forward neural network is specifically designed for cloth classification. Both models can be found on their respective GitHub repositories.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nVideo Search Engines\n\n\n\n\n\n\n\nplatforms\n\n\nsearch engine\n\n\nvideo search\n\n\nvideo sources\n\n\n\n\nThis article explores various video search methods, including Yandex’s reverse image search for videos, Python libraries for YouTube searches, and self-hosted AI engines like Jina. It also provides additional resources on search engines with video functionality.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nWatch Anime Online\n\n\n\n\n\n\n\nanime\n\n\ninformation gathering\n\n\nscraping\n\n\nvideo sources\n\n\n\n\nThe article highlights a website, anime1.me, that allows users to watch anime online. It specifically mentions a popular series, SPYxFAMILY, and provides a link for easy access. Additionally, the article notes that this anime is also listed on anilist with external links to bangume.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nMovie Bangume script finder\n\n\n\n\n\n\n\nanime\n\n\nanime script\n\n\ninformation gathering\n\n\nmovie quote\n\n\nscraping\n\n\nvideo generator\n\n\n\n\nThis summary compiles links to various websites that provide movie scripts, anime dialogs, and Japanese bangume information. Notable sites include AnimeCharactersDatabase.com, Quodb.com, SciFiScripts.com, 33.agilestudio.cn, zhaotaici.cn, and bgm.tv/subject/1982/characters. Some of the links might be broken, but Zhihu offers related information.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nRead Manga Online\n\n\n\n\n\n\n\nimage source\n\n\ninformation gathering\n\n\nscraping\n\n\nstub\n\n\nvideo generator\n\n\nvideo source\n\n\n\n\nThis text discusses the process of reading Manga online, focusing on the website mangareader.to and specifically mentioning Tokyo Ghoul Chapter 362.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nFacial Expression Detector\n\n\n\n\n\n\n\nemotion detection\n\n\nfacial expression\n\n\nvideo analysis\n\n\n\n\nThis article offers a compilation of resources for facial expression detection, including GitHub repositories, deep learning models, and a Python library. These tools can be utilized to accomplish tasks like identifying emotions, detecting smiles, and analyzing facial expressions.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nJina: Neural Search Engine for Images, Videos, Audios\n\n\n\n\n\n\n\nAI\n\n\nmedia search engine\n\n\nsearch engine\n\n\nself-hosted\n\n\n\n\nJina is a neural search engine that enables users to efficiently search for images, videos, and audios. It leverages popular libraries like openclip, haystack, towhee, and Milvus to provide pre-trained models and workflows through Jina Hub. Additionally, VCED offers tutorials in machine learning topics.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nsupercollider\n\n\n\n\n\n\n\nmidi generation\n\n\nmusic analysis\n\n\nmusic generation\n\n\nsinging\n\n\ntrack spliting\n\n\n\n\nThis article showcases various open-source tools for live coding, music generation, and audio processing. Tools mentioned include Supercollider, TidalCycles, Haskell, Sonic Pi, and MIDI conversion resources like LSTM music generation, GPT2 chord to melody, multi-instrument music generation, and musicautobot.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nNeuraldiff: discriminate actor and objects in video\n\n\n\n\n\n\n\nimage segmentation\n\n\nstub\n\n\nvideo analysis\n\n\nvideo processing\n\n\nvideo segmentation\n\n\nvideo understanding\n\n\n\n\nNeuralDiff is a Pytorch-based solution designed to differentiate between actors and objects in 3D videos captured from an egocentric viewpoint. This implementation leverages advanced neural network techniques to accurately identify and categorize the elements present within such videos.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nGAN Generating video Motion Driven Still Image to Video\n\n\n\n\n\n\n\nmotion driven video\n\n\nmusic to video\n\n\nvideo generator\n\n\n\n\nThis article delves into various methods and tools, including CoNR, digan, MoCoGAN, TRPG Replay Generator, Montage.ai, and TikTok montages, that employ techniques such as GANs and thin-plate spline motion models to create videos from images or portraits.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nDALL_E Text to Image\n\n\n\n\n\n\n\nAI\n\n\nimage generation\n\n\ntext to image\n\n\nvideo generator\n\n\nvideo source\n\n\n\n\nThis article highlights several open-source projects that enable image generation from text using models similar to DALL-E. Mentioned projects include DALLE-pytorch, dalle_mini, dalle-flow by Jina AI (a human-in-the-loop multi-prompt tool), and a playground for experimentation called dalle-playground.\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nMastering Frame Interpolation Techniques for Smooth Videos\n\n\n\n\n\n\n\nframe_interpolation\n\n\nAnimeInterp\n\n\nNVIDIA_unsupervised_video_interpolation\n\n\nsmooth_videos\n\n\nVideo-Interpolation\n\n\ntechniques\n\n\nvideo_quality\n\n\n\n\nThis article explores different methods of frame interpolation, a technique aimed at producing smoother videos. It discusses approaches such as AnimeInterp and NVIDIA’s unsupervised video interpolation, which can help create more fluid and continuous visuals.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\nMaster Hugo: A Comprehensive Guide to Installing and Theming Your Blog\n\n\n\n\n\n\n\nhugo\n\n\nblogging\n\n\ninstallation\n\n\nthemes\n\n\nblog generator\n\n\n\n\nThis text serves as a comprehensive guide for installing and utilizing Hugo, a widely-used blog generator. It offers step-by-step instructions on how to download and set up the software, along with recommendations on selecting and implementing various themes to enhance your Hugo blog.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\nIM MITM 聊天软件MITM\n\n\n\n\n\n\n\nAPI\n\n\nchatbot\n\n\ninformation gathering\n\n\nMITM\n\n\nproject\n\n\npyjom\n\n\nscraping\n\n\nsocial media\n\n\n\n\nThis article provides guidance on creating a chat environment for conducting Man-in-the-Middle (MITM) attacks, along with suggesting tools and APIs to access data from various social media platforms like Reddit, Tumblr, Discord, Twitter, Facebook, and Instagram. By following the instructions in this article, you’ll be able to effectively execute MITM attacks and gather valuable information from these popular social media networks.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\n变声软件 Morphvox alternatives\n\n\n\n\n\n\n\nmodel training\n\n\npyjom\n\n\nspeech synthesis\n\n\nstub\n\n\nvoice changer\n\n\nvst\n\n\n\n\nThis article discusses strategies for improving live streaming voice quality using software tools such as OBS, Cantabile, and Voicemeeter Banana. It also highlights MoeTTS for language mixing and custom data training, providing download links and suggesting learning from experienced content creators.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\nCode Batch Change Tool, Code Refactor Tool (the new sed)\n\n\n\n\n\n\n\ncode refactoring\n\n\nprogramming language understanding\n\n\nsed alternative\n\n\nsemantic editing\n\n\nstub\n\n\n\n\nCode Batch Change Tool, or Code Refactor Tool, is a novel sed-like tool designed for refactoring and rewriting code in multiple programming languages. It offers language independence through platforms like comby.dev and language-specific tools, including jscodeshift for JavaScript and various Python options such as Redbaron, Bowler, refactor, and Google’s Pasta.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\nSimilar Image Search\n\n\n\n\n\n\n\nimage search\n\n\ninformation gathering\n\n\nscraping\n\n\nsearch engine\n\n\nvideo generator\n\n\n\n\nThis article explores various image search tools, including general and GIF searches, browser plugins, tutorials for using them effectively, meta search engines for finding specific elements like fonts or anime scenes, and how to locate these resources through image-based searches.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\nAI上色\n\n\n\n\n\n\n\ncensorship\n\n\ncircumention\n\n\ncolorization\n\n\ndecolorization\n\n\nhue tweaks\n\n\nNSFW\n\n\npyjom\n\n\nvideo generation\n\n\nvideo processing\n\n\n\n\nThis article explores the utilization of AI techniques, specifically PaddleGAN, for colorizing images and videos. Additionally, it highlights other tools and GitHub repositories available for image colorization.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\n推荐系统 GNN\n\n\n\n\n\n\n\nadvertising\n\n\nchatbot\n\n\ngraph database\n\n\npyjom\n\n\nrecommendation\n\n\n\n\nThis article highlights the potential of Graph Neural Networks in various applications such as personalized ranking, social network analysis, NLP, content categorization, and predicting missing links. It also discusses open-source Python libraries that can be used for implementing these use cases.\n\n\n\n\n\n\nMay 27, 2022\n\n\n\n\n\n\n\n\n视频分析处理 剧本生成\n\n\n\n\n\n\n\nvideo processing\n\n\nvideo summarization\n\n\nvideo understanding\n\n\n\n\nThis article focuses on video analysis using popular frameworks PyTorch and Keras. It offers a range of resources to perform tasks such as classification and summarization, along with access to a pretrained model zoo for further customization. Additionally, it provides a link to a helpful video feature extractor tool.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\n开放api 信息来源\n\n\n\n\n\n\n\nAPI\n\n\ncat video\n\n\nimage sources\n\n\ninformation gathering\n\n\nscraping\n\n\nstub\n\n\nvideo sources\n\n\n\n\nThe article discusses an open API for generating cat-themed content through the website ‘cataas.com’. This platform offers a range of options to create and personalize images featuring cats, making it an entertaining and engaging service.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\n海外哔哩哔哩\n\n\n\n\n\n\n\naudio source\n\n\nbilibili\n\n\nstub\n\n\ntext source\n\n\nvideo sources\n\n\n\n\nOverseas Bilibili is a well-known Chinese video-sharing platform, renowned for its emphasis on animated content, videos, and live broadcasts. It offers an interactive user-driven system that facilitates direct engagement between content creators and their audience via comments and live streams.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\nQQ 微信 信息提取 bot搭建\n\n\n\n\n\n\n\nchatbot\n\n\nconversation\n\n\ninformation gathering\n\n\npyjom\n\n\nscraping\n\n\nvideo generator\n\n\n\n\nThis article provides insights on creating QQ-style chat interfaces using Vue, and offers a list of useful GitHub repositories for WeChat API, bot development, and reverse engineering tools. It emphasizes the significance of implementing content filtering and classification to prevent any potential controversies.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\n标题生成\n\n\n\n\n\n\n\ntext generation\n\n\ntitle generation\n\n\n\n\nThis article compares different image captioning models, including GPT-3 and CLIP, for various applications like template extraction, neural title generation, reverse image search, and natural language generators. It also showcases examples from gpt3demo.com and explains how to generate stories from pictures using image transformers and GPT-2.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\nAI训练集标注工具\n\n\n\n\n\n\n\nAI\n\n\nML\n\n\nsupervised learning\n\n\ndataset creation\n\n\nmodel training\n\n\npyjom\n\n\n\n\nThis article explores different data annotation tools such as Doccano, CVAT with Docker, LabelImg, and label-studio that can be used for text, video/image, images, audio, video, and transcription respectively. Installation is available through pip or GitHub.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\n如何永久的影响世界\n\n\n\n\n\n\n\ndream\n\n\nidea\n\n\ntrivial\n\n\n\n\nThis article discusses two comments that highlight various topics with significant and potentially permanent global impacts, such as nuclear power, wealth, human thought, loyalty, leadership, and more.\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\n睡觉时间 内脏工作时间\n\n\n\n\n\n\n\nlifestyle\n\n\nresting\n\n\nwork schedule\n\n\n\n\nThis guide outlines the recommended times for various internal organs to perform their detoxification and maintenance functions, such as the immune system’s toxin elimination at 9-11pm, liver detoxification between 11pm and 1am, gallbladder detoxification between 1-3am, lung detoxification between 3-5am, and spinal bone blood production during midnight to 4am. The importance of maintaining a regular sleep schedule and healthy habits is emphasized.\n\n\n\n\n\n\nMay 19, 2022\n\n\n\n\n\n\n\n\n搜狗输入法AI功能\n\n\n\n\n\n\n\nAI\n\n\nAPI\n\n\nonline services\n\n\nsougou\n\n\nstub\n\n\n白嫖\n\n\n\n\nThis article delves into the advanced AI capabilities of Sogou Input Method, highlighting its features such as AI images, writing assistance, engaging conversations, translation services, and error proofreading.\n\n\n\n\n\n\nMay 19, 2022\n\n\n\n\n\n\n\n\nThe Interesting Life\n\n\n\n\n\n\n\nidea\n\n\ninteresting\n\n\npopular topic\n\n\ntopic\n\n\n\n\nThis article provides insights on enhancing content interest through various techniques like incorporating changes, utilizing conjunctives to summarize essays, and understanding interrelationships between segments. Additionally, it explores AI-driven content generation for social media platforms.\n\n\n\n\n\n\nMay 16, 2022\n\n\n\n\n\n\n\n\ncacani tweening_interpolating alternatives\n\n\n\n\n\n\n\nanimation\n\n\nanimation tool\n\n\ninterpolation\n\n\ntweening\n\n\nvideo generator\n\n\n\n\nThis article explores different 2D animation tools such as vPaint, vGC, Synfig, and AnimeEffects. The focus is on their capabilities in tweening, interpolating, and generating animations using vector graphics.\n\n\n\n\n\n\nMay 14, 2022\n\n\n\n\n\n\n\n\n动漫剪辑过审\n\n\n\n\n\n\n\ncensorship\n\n\ncircumvention\n\n\nidea\n\n\nstub\n\n\ntips\n\n\nvideo processing\n\n\n\n\nThis article discusses the process of creating a non-NSFW and anti-censorship anime video using music and open-source tools from GitHub. It highlights how these tools can be employed to combat content and video restrictions.\n\n\n\n\n\n\nMay 14, 2022\n\n\n\n\n\n\n\n\nthe singing bot\n\n\n\n\n\n\n\nlip sync\n\n\nmotion driven video\n\n\ntalking head\n\n\nvideo generator\n\n\nwombo.ai\n\n\n\n\nThe VToonify framework offers a method for creating high-quality artistic portrait videos with a cartoon style, using StyleGAN layers and features to preserve frame details. It is compatible with existing image cartoonization models.\n\n\n\n\n\n\nMay 13, 2022\n\n\n\n\n\n\n\n\nAttractive Dynamic plus attractive video\n\n\n\n\n\n\n\nadvocates\n\n\ngeneral idea\n\n\nidea\n\n\npolicy\n\n\npyjom\n\n\nsocial media\n\n\n\n\nThis article explores tactics for creating viral content by merging videos and essays, targeting the largest audience through native languages. It recommends sharing this content on platforms like QQ using images or links.\n\n\n\n\n\n\nMay 13, 2022\n\n\n\n\n\n\n\n\nAnime smile detection_ segmentation\n\n\n\n\n\n\n\nanime\n\n\nface landmark\n\n\nfacial\n\n\nfacial expression detection\n\n\nimage segmentation\n\n\npyjom\n\n\nsmile\n\n\n\n\nThe article discusses a method for detecting and segregating anime heads through processes such as object detection, segmentation, and their potential use in facial recognition. Additionally, it explores the possibility of analyzing character attributes including position, clothing type, gender, and subtitle recognition.\n\n\n\n\n\n\nMay 11, 2022\n\n\n\n\n\n\n\n\n踩点 音乐识别\n\n\n\n\n\n\n\naudio analysis\n\n\nbeat detection\n\n\nmusic analysis\n\n\n\n\nThis article discusses various audio and music recognition tools like audioFlux, inaSpeechSegmenter, Mousai, Music Emotion Recognition, Picard, AcoustID, MixingBear, madmom, pyaudioanalysis, MUSIC21, urbanSound8k dataset, MeowDetector, and more. It also mentions using QQ Music’s recognition engine for domestic audio identification and Premier plugins for categorizing humorous videos based on music structure.\n\n\n\n\n\n\nMay 11, 2022\n\n\n\n\n\n\n\n\nVideo Cutting with captioners, video classifiers, audio classifier, audio categorizer\n\n\n\n\n\n\n\naudio analysis\n\n\naudio classification\n\n\nauto edit\n\n\ntranscription\n\n\nvideo auto edit\n\n\nvideo understanding\n\n\n\n\nThis article discusses various methods and tools for converting audio files to MIDI format, including COCA, audio classifiers, and taggers. It compares different audio-to-MIDI converter tools such as Polyphonic_track, audioToMidiConverter, PitchToMIDI, Tony, MusicTranscription, pYIN, Spleeter, and Musisep to transcribe polyphonic audio into MIDI format.\n\n\n\n\n\n\nMay 10, 2022\n\n\n\n\n\n\n\n\nVideo Anticensor\n\n\n\n\n\n\n\ncensorship\n\n\ncircumvention\n\n\nvideo generator\n\n\n\n\nVideo Anticensor for Bilibili Tarot is an AI-powered tool that enhances images through various techniques, such as colorization, style transfer, glitch effects, and more. It transforms grayscale images into colorful masterpieces by applying dithering, chroma shift, overlays, and filters, making it a versatile solution for content creators on Bilibili.\n\n\n\n\n\n\nMay 9, 2022\n\n\n\n\n\n\n\n\nCopilot_Codex alternative\n\n\n\n\n\n\n\ncode generation\n\n\nprogramming assistant\n\n\n\n\nAI-based code generation tools like CodeGeeX, a free version of Copilot/Codex, are gaining attention for their features such as translation and support for VSCode plugins.\n\n\n\n\n\n\nMay 9, 2022\n\n\n\n\n\n\n\n\npyjom producer\n\n\n\n\n\n\n\nideas\n\n\nproducer\n\n\npyjom\n\n\nstructure\n\n\n\n\nThe ‘pyjom producer’ is a process designed for analyzing audio and video separately. Audio can be processed in chunks or split tracks, allowing for more efficient analysis. However, to analyze the video, it needs to be iterated frame by frame.\n\n\n\n\n\n\nMay 7, 2022\n\n\n\n\n\n\n\n\nBoot into Linux commandline (tty)\n\n\n\n\n\n\n\ncommandline\n\n\nemergency\n\n\nkali\n\n\nlinux\n\n\nremedy\n\n\nsystem manage\n\n\n\n\nThis text provides a solution for accessing the Linux command line (tty) when Xorg fails. It describes how to boot into the command line by entering ‘3’ after the longest line of boot commands, and suggests using SSH to collect logs even if there are interface issues.\n\n\n\n\n\n\nMay 6, 2022\n\n\n\n\n\n\n\n\nLetsketch libwacom\n\n\n\n\n\n\n\ndriver\n\n\nhardware\n\n\nHID\n\n\nstylus\n\n\ntablet\n\n\n\n\nThis article provides a solution to troubleshoot input issues with the libwacom library on Arch Linux ARM and Kali Linux. The article suggests modifying the xorg.conf file as referenced in a troubleshooting guide for resolution.\n\n\n\n\n\n\nMay 6, 2022\n\n\n\n\n\n\n\n\ndouyin tiktok social media download\n\n\n\n\n\n\n\ndouyin\n\n\ntiktok\n\n\nsocial media\n\n\ninformation gathering\n\n\nscraping\n\n\nvideo sources\n\n\nAPI\n\n\n\n\nThis article provides information on resources for downloading Douyin/TikTok videos. It covers APIs, scrapers, and deduplication tools, along with their respective documentation and a GitHub repository for easy access.\n\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\nui automation and indirect intent interception (share to)\n\n\n\n\n\n\n\ninformation gathering\n\n\nscraping\n\n\nstub\n\n\ntaobao\n\n\nvideo\n\n\n\n\nAuto.js is an open-source Android automation tool that allows for quick feature launches in apps like Tencent Weishi and Taobao short videos using Scheme URLs and Intent interception, providing a more streamlined alternative to professional testing tools like Appium or AirTest.\n\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\nDNS Proxy for Campus Network\n\n\n\n\n\n\n\nnetwork\n\n\nnetwork avalibility\n\n\nonline\n\n\n白嫖\n\n\n\n\nThis article discusses the use of DNS proxies to bypass campus network restrictions. It introduces tools such as Kaggle and dig for testing connectivity and provides examples of potential DNS proxy solutions. Additionally, it offers troubleshooting resources to help users resolve any issues they may encounter.\n\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\nSinging Voice Generation and more\n\n\n\n\n\n\n\nlyric generation\n\n\nmusic generation\n\n\nsinging\n\n\nvoice changer\n\n\n\n\nAI tools like AudioLM, Riffusion, Deepvoice, Acestudio, and LMMS are revolutionizing audio and music generation by creating realistic audio, music, and singing voices. ACE Studio recently entered its public test phase on July 12th, offering a high-quality AI-generated singing voice platform.\n\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\nDouyin or Tiktok Social Media Video Download\n\n\n\n\n\n\n\ndouyin\n\n\ninformation gathering\n\n\nscraping\n\n\ntiktok\n\n\nvideo scraping\n\n\nvideo source\n\n\n\n\nThis article discusses various resources and tools available for downloading TikTok videos, such as APIs, scrapers, deduplication tools, and multi-download utilities. These comments provide valuable information for anyone looking to download TikTok videos efficiently.\n\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\nVideo Database\n\n\n\n\n\n\n\ninformation analysis\n\n\npyjom\n\n\nvideo analysis\n\n\n\n\nThis passage explores various video processing tools such as Fastai/PyTorch, OpenNLPLab, MasterBin-IIAU, and PaddlePaddle. These tools are utilized for tasks including image translation, object segmentation, tracking, action recognition, and generating descriptive information.\n\n\n\n\n\n\nMay 5, 2022\n\n\n\n\n\n\n\n\nGPT-2 以及文本生成\n\n\n\n\n\n\n\nchatbot\n\n\nconversation\n\n\nmodel zoo\n\n\npyjom\n\n\nstub\n\n\ntext generator\n\n\nvoice chat\n\n\n\n\nThis article delves into GPT-2 and Chinese language model resources, exploring various applications such as text generation tools, sensitive content detectors, dialog generation, Twitter generators inspired by influencers, and a massive 130 billion-parameter Tsinghua University model. The article also provides links to testing addresses and repositories for further exploration.\n\n\n\n\n\n\nMay 3, 2022\n\n\n\n\n\n\n\n\nTranslators for Casual usage\n\n\n\n\n\n\n\nparaphraser\n\n\nrephrase\n\n\ntext generation\n\n\ntranslator\n\n\n洗稿\n\n\n\n\nIn this summary, various NLP tools and resources for text paraphrasing, translation, and Chinese language analysis are discussed. These include popular options such as Baidu Translator, Pegasus Paraphrase, Google Translate, LSTM and T5 paraphrase generators, English and sentence-level paraphrasers, contextual search models trained using fine-tuned paraphrase models, open-source libraries, online tools, and ‘mbart50’, a multilingual language model.\n\n\n\n\n\n\nApr 29, 2022\n\n\n\n\n\n\n\n\ngpt-2 ram requirements\n\n\n\n\n\n\n\nbig model training\n\n\ndeepspeed\n\n\nhardware specs\n\n\npytorch\n\n\n\n\nThis article delves into the hardware requirements and training methods for large language models, specifically focusing on GPT-2. It explores dynamic quantization techniques, optimization tools, and NVIDIA Tesla M40 GPUs as key components in this process. Additionally, the author shares their personal experience installing these GPUs for deep learning applications.\n\n\n\n\n\n\nApr 28, 2022\n\n\n\n\n\n\n\n\n水冷散热注意\n\n\n\n\n\n\n\ncooling\n\n\ndesktop\n\n\nhardware\n\n\nliquid cooling\n\n\nsecurity\n\n\nthermal\n\n\n\n\nThis article provides comprehensive guidance on water cooling systems for computers. It emphasizes the importance of using non-conductive fluids and proper sealing techniques to prevent wear, leaks, and overheating. The article also discusses essential components such as pressure gauges and heat-shrinking sleeves, ensuring a well-informed understanding of water cooling systems for computer enthusiasts.\n\n\n\n\n\n\nApr 27, 2022\n\n\n\n\n\n\n\n\nNetdisk managers, Userscript and info_data collection\n\n\n\n\n\n\n\nbrowser extension\n\n\ncloud sync\n\n\nextension\n\n\nimage sources\n\n\ninformation gathering\n\n\nsearch engine\n\n\nsync\n\n\ntext sources\n\n\nvideo sources\n\n\n\n\nThis article highlights two comments, each providing a collection of URLs leading to websites offering a diverse range of resources. Comment A mainly focuses on manga, anime, and novels, while Comment B encompasses video tutorials, guides, and debugging tools related to Chinese media and technology.\n\n\n\n\n\n\nApr 25, 2022\n\n\n\n\n\n\n\n\nContent Usage\n\n\n\n\n\n\n\nidea\n\n\nparaphraser\n\n\npyjom\n\n\nstub\n\n\ntext generation\n\n\n\n\nIn this text, you will learn how to leverage the original transcript and danmaku for paraphrasing purposes and generating jokes. You’ll discover useful techniques and strategies that will help improve your ability to create engaging and humorous content.\n\n\n\n\n\n\nApr 25, 2022\n\n\n\n\n\n\n\n\nMMDetection and MMD dancing\n\n\n\n\n\n\n\n3D model\n\n\naction detection\n\n\ndancing\n\n\nMMD\n\n\nOpenMM\n\n\npyjom\n\n\nvideo analysis\n\n\nvideo generator\n\n\n\n\nThis article discusses the use of MMDetection for creating 3D avatars with accurate human pose detection. It provides detailed explanations and GitHub resources to help readers implement this technique effectively.\n\n\n\n\n\n\nApr 21, 2022\n\n\n\n\n\n\n\n\nArticulated Animation\n\n\n\n\n\n\n\nmotion driven video\n\n\npyjom\n\n\nstub\n\n\nvideo generator\n\n\n\n\nArticulated Animation is a user-friendly tool that leverages real humans for speech demonstration and animation. You can find it at https://github.com/snap-research/articulated-animation.\n\n\n\n\n\n\nApr 21, 2022\n\n\n\n\n\n\n\n\nGraphcore support for AI\n\n\n\n\n\n\n\nacceleration\n\n\nAI\n\n\ngpu alternative\n\n\ngraphcore\n\n\nhardware\n\n\n\n\nGraphcore’s Innovative Processing Unit (IPU) is a highly efficient and faster solution compared to NVIDIA’s A100. It offers full performance integration with popular frameworks such as TensorFlow, PyTorch, and PaddlePaddle. Graphcore provides open-source resources for these frameworks and features on-board RAM sharing capabilities, making it a cost-effective and quicker alternative.\n\n\n\n\n\n\nApr 21, 2022\n\n\n\n\n\n\n\n\nOptical Flow, slow motion and more\n\n\n\n\n\n\n\nframe interpolation\n\n\nslow motion\n\n\nvideo generator\n\n\nvideo interpolation\n\n\n\n\nslowmoVideo is a software that leverages GPU and optical flow technology to generate slow-motion effects by interpolating frames. With clear optical flow boundaries, it can also potentially support instance segmentation. To utilize CUDA support, OpenCV must be built with opencv_contrib and -DWITH_CUDA=ON.\n\n\n\n\n\n\nApr 19, 2022\n\n\n\n\n\n\n\n\nRSS Feeds\n\n\n\n\n\n\n\nimage sources\n\n\nrss\n\n\nsubscription\n\n\ntext sources\n\n\n\n\nThis article delves into RSS feed sources and customizable aggregators, recommending the use of social media for content dissemination. It further explores Python RSS libraries and a JavaScript readability library for image and fingerprint handling. Installation instructions using npm and pip are provided for Node.js and Python.\n\n\n\n\n\n\nApr 17, 2022\n\n\n\n\n\n\n\n\nEmotion manipulation\n\n\n\n\n\n\n\nemotion\n\n\nideas\n\n\nsocial media\n\n\n\n\nThe article explores the manipulation of emotions through different means like graphics, motion, text, and voice. It proposes using random swaps, funny images, specialized model training with grouped content, and a database for synchronization. Emotion analysis can be done using emotional/keyword frequency indicators, feature extraction, and video expression acceleration.\n\n\n\n\n\n\nApr 14, 2022\n\n\n\n\n\n\n\n\nMinor changes will defeat deduplicate algorithm while maintain overall fluency\n\n\n\n\n\n\n\ncircumvention\n\n\ndeduplicate\n\n\nparaphraser\n\n\nsocial media\n\n\n伪原创\n\n\n\n\nThis article explores various tactics to bypass deduplicate algorithms, including employing paraphrasing techniques or video manipulation methods to maintain consistency and effectiveness in the content.\n\n\n\n\n\n\nApr 9, 2022\n\n\n\n\n\n\n\n\nUnlocking Speed: FastGithub - Accelerating Github and StackOverflow\n\n\n\n\n\n\n\nFastGithub\n\n\nacceleration\n\n\nGitHub\n\n\nStackOverflow\n\n\nproject\n\n\ntechnology\n\n\ndevelopment\n\n\n\n\nThis article discusses FastGithub, a project aimed at accelerating GitHub and StackOverflow. By using the provided URL, users can explore the benefits and features of this innovative tool.\n\n\n\n\n\n\nApr 9, 2022\n\n\n\n\n\n\n\n\nExtract voice from professional sources\n\n\n\n\n\n\n\nidea\n\n\nvoice source\n\n\n\n\nThis article explores the process of extracting high-quality voice recordings from professional sources such as audiobooks, radios, and movies. It delves into the techniques used to isolate and separate voices from complex audio files, discussing the tools and methods employed by experts in this field.\n\n\n\n\n\n\nApr 9, 2022\n\n\n\n\n\n\n\n\nAnonymity and open access to internet\n\n\n\n\n\n\n\nanonymity\n\n\ncircumvention\n\n\nfree access\n\n\ninternet\n\n\nonion router\n\n\ntor\n\n\nvpn\n\n\n\n\nThis article discusses various methods for securing online privacy, including the use of tools such as VPNs, ShadowSocks, Tor, and obfs4 bridges to bypass restrictions and ensure secure communication.\n\n\n\n\n\n\nApr 7, 2022\n\n\n\n\n\n\n\n\nFall detection can be used for media filtering\n\n\n\n\n\n\n\naction recognization\n\n\nstub\n\n\nvideo analysis\n\n\n\n\nThis article explores the application of fall detection technology in media filtering, specifically focusing on selecting falling videos for entertainment. The technique utilizes human pose classification to identify suitable content.\n\n\n\n\n\n\nApr 5, 2022\n\n\n\n\n\n\n\n\nInstall VSCode Extensions by ID\n\n\n\n\n\n\n\nextension\n\n\nmedialang\n\n\npyjom\n\n\n\n\nThis article provides detailed instructions on how to install two Visual Studio Code extensions, namely ‘medialang.vscode-theme-medialang-seti’ and ‘medialang.medialang-highlighter’, by using their respective IDs.\n\n\n\n\n\n\nMar 31, 2022\n\n\n\n\n\n\n\n\nConverting partial Zhihu viral content\n\n\n\n\n\n\n\ncircumvention\n\n\nidea\n\n\ninformation gathering\n\n\npyjom\n\n\ntext sources\n\n\n\n\nThis article discusses the process of converting partial content from Zhihu, a Chinese Q&A platform, and seeks assistance in listening to an upcoming explanation.\n\n\n\n\n\n\nMar 31, 2022\n\n\n\n\n\n\n\n\nLogic Optimizer for Different Models\n\n\n\n\n\n\n\nmodel\n\n\noptimization\n\n\ntrial and error\n\n\n\n\nThe article explores the use of an online optimizer for creating different models and finding the best logic combination. It outlines the process of selecting and marking the best model (A), generating another model (B) using the same optimizer, and combining these into a final model (X) through iterating various situations.\n\n\n\n\n\n\nMar 30, 2022\n\n\n\n\n\n\n\n\nvscode extension create publisher\n\n\n\n\n\n\n\nextension\n\n\npublish\n\n\nstub\n\n\ntips\n\n\nvscode\n\n\n\n\nThis article provides instructions on creating or managing a Visual Studio Code (VSCode) extension for the publisher ‘medialang’. It outlines the VSCode extension create command and includes a vsce token for authentication purposes.\n\n\n\n\n\n\nMar 30, 2022\n\n\n\n\n\n\n\n\nIntel 9250 bluetooth Win server\n\n\n\n\n\n\n\nalienware\n\n\nbluetooth\n\n\ndriver\n\n\nintel\n\n\nlinux\n\n\n\n\nThis article provides instructions on how to update Intel Bluetooth drivers, such as the 9250 and 9462AC HMC drivers, for Windows servers. However, it highlights that modifying the Netwsw04.INF file to update an Intel 9462AC HMC driver may be challenging due to differences between Win7 and Win10 packages in the ‘No_160’ section.\n\n\n\n\n\n\nMar 23, 2022\n\n\n\n\n\n\n\n\nAndroid Emulators\n\n\n\n\n\n\n\nandroid\n\n\nemulator\n\n\nstub\n\n\n\n\nThis article focuses on Android emulators, WayDroid and anbox. It explores the various methods to run Android apps on non-Android platforms.\n\n\n\n\n\n\nMar 5, 2022\n\n\n\n\n\n\n\n\nWorth Trying Remote Computer Connection\n\n\n\n\n\n\n\nremote control\n\n\nremote desktop\n\n\n\n\nThis article discusses different remote computer connection software options including NoMachine NX, FreeNX, Moonlight, parsec, ssh-rdp, x11vnc, vncviewer, sunshine host, and openstream-server that are compatible with both Windows and Linux hosts. Additionally, it introduces a hardware solution, the KVM switch, which supports audio redirection and separate USB ports.\n\n\n\n\n\n\nMar 4, 2022\n\n\n\n\n\n\n\n\nIOS airtest control windows\n\n\n\n\n\n\n\nautomatic software test\n\n\niOS\n\n\nsoftware testing\n\n\n\n\nThis article explores the process of controlling iOS devices with AirTest, which requires macOS for compiling IPA files and jailbroken devices. It also introduces iOS Tagent as a possible alternative solution and provides links to taobao-iphone-device and apowermirror as potential tools.\n\n\n\n\n\n\nFeb 24, 2022\n\n\n\n\n\n\n\n\nMindmap\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nThis text explores the process of creating a mindmap to divide a co-occurrence network graph into communities using basic clustering techniques. The objective is to visually highlight the graph’s hotspots and present the findings in a network format.\n\n\n\n\n\n\nFeb 22, 2022\n\n\n\n\n\n\n\n\nAndroid 10 clipboard issue for scrcpy\n\n\n\n\n\n\n\nandroid\n\n\nclipboard\n\n\nsync\n\n\nsystem manage\n\n\ntweaks\n\n\n\n\nThis article explains how to resolve the Android 10 clipboard issue in scrcpy by utilizing Riru’s Clipboard Whitelist module and incorporating the ‘-K’ flag with Python’s reader.py script, allowing compatibility with specific clipboard manager apps.\n\n\n\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n\n\nMovie Scraping 3\n\n\n\n\n\n\n\nfreelancer\n\n\ninformation gathering\n\n\nmovie scraping\n\n\n\n\nThis article discusses a movie scraping project on the ‘https://www.dianyinggou.com’ website, where data related to movies and their corresponding Douban links are collected and processed.\n\n\n\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n\n\nMovie Scraping 2\n\n\n\n\n\n\n\nfreelancer\n\n\ninformation gathering\n\n\nmovie scraping\n\n\n\n\nThe text is a collection of movie links from the website ‘cokemv.me’. The URLs provided lead to individual movie pages and search results.\n\n\n\n\n\n\nFeb 20, 2022\n\n\n\n\n\n\n\n\nEnglish Courseware scraping\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nThis article offers login details and website links for accessing English course materials from platforms such as imman.ireadabc.com and 91reading.com. It provides usernames, passwords, and download access to lesson resources.\n\n\n\n\n\n\nFeb 18, 2022\n\n\n\n\n\n\n\n\nLibrary System\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nA Library System with a database is being discussed in this article. The system currently lacks specific data, and an entity-relation diagram is provided to help understand the structure of the system. Contact information is also included for those who require further assistance or have any questions.\n\n\n\n\n\n\nFeb 18, 2022\n\n\n\n\n\n\n\n\nMovie Site Scraping 1\n\n\n\n\n\n\n\nfreelancer\n\n\ninformation gathering\n\n\nmovie scraping\n\n\n\n\nThis article discusses the process of creating a scraper to collect information from the movie site https://www.zxzj.fun/. The scraper gathers details such as movie and TV show names, release dates, and playback links. It also distinguishes between films and series and provides contact information for more details.\n\n\n\n\n\n\nFeb 17, 2022\n\n\n\n\n\n\n\n\nMedia repurpose tool\n\n\n\n\n\n\n\ndialog extractor\n\n\nideas\n\n\nspeech recognization\n\n\nvideo editor\n\n\nvideo extractor\n\n\n\n\nThis article discusses a media repurpose tool that can record, scan objects, and transplant pictures from various platforms. It is capable of sharing dialogs and information across different platforms and streaming services. Using OCR technology to filter out textual information, the tool also finds new titles from danmaku or comments. The project is open-source and will receive regular tutorial updates.\n\n\n\n\n\n\nFeb 16, 2022\n\n\n\n\n\n\n\n\nPython Media Automation\n\n\n\n\n\n\n\nfoundation\n\n\nidea\n\n\npyjom\n\n\n\n\nThis article discusses the use of Python for media automation, covering topic-based and breakdown approaches, adherence to standards, avoiding copyright issues with Google search, and implementing an actor-critic model for optimization and content creation.\n\n\n\n\n\n\nFeb 10, 2022\n\n\n\n\n\n\n\n\nDynamic Classification System\n\n\n\n\n\n\n\nAI\n\n\nclassification\n\n\ninformation retrieval\n\n\nstub\n\n\n\n\nThis article discusses a dynamic classification system that assigns numerical values to categories and employs a retrieval-based attention network, such as the RETRO model, for regression tests in fields like the stock market or platforms like bilibili. This innovative approach offers potential benefits in various industries by enabling more accurate predictions and analysis based on real-time data.\n\n\n\n\n\n\nJan 30, 2022\n\n\n\n\n\n\n\n\nPolymer Chemistry Mixture\n\n\n\n\n\n\n\ncheminformatics\n\n\nchemistry\n\n\npolymer\n\n\n\n\nThis article delves into the utilization of molecular dynamics simulations with tools such as pymatgen, lammps, and openFF. It discusses interatomic potentials and force field generation processes in organic chemistry. Additionally, it covers accessing density data from multiple sources.\n\n\n\n\n\n\nJan 28, 2022\n\n\n\n\n\n\n\n\nAlgorithm\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nMingming is a tool that generates a list of unique random numbers between 1-1000, removes any duplicates, and sorts the resulting list. This process ensures an unbiased distribution for assigning participants to different survey groups.\n\n\n\n\n\n\nJan 21, 2022\n\n\n\n\n\n\n\n\nDNA Cancer Prediction\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nIn this assignment, students are tasked with categorizing antimicrobial and antibiofilm peptide sequences using feature extraction techniques by the due date of January 25, 2020. Throughout the process, students must submit daily reports and compile a final PDF report for evaluation. The grading criteria and additional opportunities for earning extra credit are specified.\n\n\n\n\n\n\nJan 20, 2022\n\n\n\n\n\n\n\n\nSleepless in Bed 失眠治疗法\n\n\n\n\n\n\n\nhealth\n\n\nlife style\n\n\nwork style\n\n\n\n\nThis article offers insights into treating insomnia by recommending various methods, including stretching exercises, adjusting diet, and maintaining a consistent sleep schedule. Additionally, it suggests using smart home technology to simulate natural light rhythms for waking up. The text also provides information on how to control lamp intensity with Arduino.\n\n\n\n\n\n\nJan 13, 2022\n\n\n\n\n\n\n\n\nYoga & TaiChi\n\n\n\n\n\n\n\nhealth\n\n\nlifestyle\n\n\nrest\n\n\n\n\nThis article emphasizes the significance of disconnecting from technology and nurturing personal development through yoga, Tai Chi, and fostering a healthy equilibrium between digital and physical engagements.\n\n\n\n\n\n\nJan 12, 2022\n\n\n\n\n\n\n\n\nEcosim\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nThis text outlines a programming assignment that involves developing a program called Ecosim, which requires implementing various object-oriented concepts such as inheritance, aggregation/composition, polymorphism, and encapsulation. The instructions emphasize the importance of clear documentation, utilizing git for progress tracking, and writing tests specifically for the Vector2D class.\n\n\n\n\n\n\nJan 12, 2022\n\n\n\n\n\n\n\n\nNAS With Movie Download\n\n\n\n\n\n\n\ncloud storage\n\n\nhardware\n\n\nremote connection\n\n\nremote control\n\n\nremote storage\n\n\nstorage\n\n\n\n\nThis article provides an overview of Network Attached Storage (NAS) devices, which are designed for efficiently downloading large media files such as movies. The content also covers NAS setups and their compatibility with different platforms to optimize movie downloads.\n\n\n\n\n\n\nJan 11, 2022\n\n\n\n\n\n\n\n\nSetup Gitee SSH Keys for GitJournal\n\n\n\n\n\n\n\njournaling\n\n\nnote taking\n\n\nsecurity\n\n\nsync\n\n\nsystem manage\n\n\n\n\nThis article explains how to set up personal SSH keys for Gitee, a code hosting platform. It also discusses a Gitee note repository and the availability of GitJournal download which can be installed using Anbox.\n\n\n\n\n\n\nJan 10, 2022\n\n\n\n\n\n\n\n\nAgile Freelancing\n\n\n\n\n\n\n\nearn money\n\n\nfreelancer\n\n\nplatforms\n\n\nstub\n\n\nwork efficiency\n\n\nwork style\n\n\n\n\nThis article discusses the compatibility of popular apps like QQ, WeChat, and DingTalk on Linux and Windows operating systems. It explores methods such as using a virtual machine or HTTP screen sharing to access these apps on unsupported platforms. Furthermore, it introduces the ‘Anbox’ project, which has potential applications in Windows, as well as referencing the Deepin derivative container.\n\n\n\n\n\n\nJan 10, 2022\n\n\n\n\n\n\n\n\nShapeShifters\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nShapeshifters is a project that employs MMP/PBRT_V3 and a displacement map on a sphere to calculate occlusion and other attributes, utilizing the input provided.\n\n\n\n\n\n\nJan 4, 2022\n\n\n\n\n\n\n\n\nKafka Data Query\n\n\n\n\n\n\n\nfreelancer\n\n\n\n\nThis article discusses designing a system using Kafka for handling and visualizing high-speed data, utilizing big data storage options like HBase or MyCat+MySQL, generating network traffic with JMeter, streaming data at 50+ RPS, and querying/presenting results. The project also involves using Python for data storage and terminal visualization tools for machine learning, as well as generating network traffic and streaming data.\n\n\n\n\n\n\nDec 30, 2021\n\n\n\n\n\n\n\n\nThe phone\n\n\n\n\n\n\n\nhardware\n\n\nphone\n\n\nstub\n\n\n\n\nTo enhance your viewing experience, consider opting for a lightweight phone or utilizing multiple, adjustable vertical monitors.\n\n\n\n\n\n\nDec 28, 2021\n\n\n\n\n\n\n\n\n百度贴吧转化笔记\n\n\n\n\n\n\n\nidea\n\n\nstub\n\n\ntieba\n\n\n\n\nThis article delves into the transformation of Baidu Tieba, a popular Chinese online bulletin board community, and highlights the importance of using registered accounts to pin posts. It provides insights into the changes made to the platform and their impact on user engagement and overall experience.\n\n\n\n\n\n\nDec 28, 2021\n\n\n\n\n\n\n\n\nThe Hack (Get password and tests)\n\n\n\n\n\n\n\nfreelancer\n\n\nhack\n\n\n\n\nThe article discusses hacking attempts on lixin.edu.cn and the use of tools such as dirbuster and Kali Linux to find vulnerabilities. It also includes a HTTP request command for changing passwords on the server.\n\n\n\n\n\n\nDec 22, 2021\n\n\n\n\n\n\n\n\nAfter Termux Reinstallation\n\n\n\n\n\n\n\nandroid\n\n\nbrightness\n\n\nbug\n\n\nreinstall\n\n\nsystem manage\n\n\ntermux\n\n\n\n\nIn this article, the author provides a step-by-step guide on how to reinstall Termux and troubleshoot common issues like granting required permissions, fixing the brightness bug by uninstalling a settings app, and removing the Termux banner for a customized experience.\n\n\n\n\n\n\nDec 20, 2021\n\n\n\n\n\n\n\n\nBaidu Tieba Login (QR Code)\n\n\n\n\n\n\n\nautologin\n\n\nfreelancer\n\n\nreverse engineering\n\n\ntieba\n\n\n\n\nA Python script utilizes Frida and Mitmproxy to bypass SSL pinning on Baidu Tieba, automates login through QR codes, enables multi-account access, scrapes high-res images, and incorporates security measures. The Chinese platform includes a ranking system with user points, levels, and virtual currency for membership and courses.\n\n\n\n\n\n\nDec 19, 2021\n\n\n\n\n\n\n\n\nCats video with lyrics_2\n\n\n\n\n\n\n\ninformation gathering\n\n\npet video\n\n\npyjom\n\n\nscraping\n\n\nvideo generator\n\n\nvideo sources\n\n\n\n\nThis article dives into a recent controversy surrounding Chinese celebrity Zhang Yixing and his interactions on social media. It highlights the importance of algorithm-based filtering and categorization in determining audience preferences, shedding light on the impact these systems have on the entertainment industry.\n\n\n\n\n\n\nDec 19, 2021\n\n\n\n\n\n\n\n\nCats video with lyrics_1\n\n\n\n\n\n\n\naudio source\n\n\nlyric\n\n\nmusic\n\n\nproject\n\n\npyjom\n\n\n\n\nThe article discusses techniques for finding and extracting lyrics, detecting cat/dog videos using YOLOv7, and utilizing various APIs for music platforms like Netease Music and Spotify. The discussion also covers installing pymusic-dl, creating a redirect plugin for Tampermonkey, and searching URI in music_dl while finding cats on Weibo.\n\n\n\n\n\n\nDec 19, 2021\n\n\n\n\n\n\n\n\nCats video with lyrics\n\n\n\n\n\n\n\naudio sources\n\n\nproject\n\n\npyjom\n\n\nvideo generator\n\n\nvideo sources\n\n\n\n\nThe text gives directions for obtaining a video featuring cats from Baidu Netdisk by using the provided link https://pan.baidu.com/s/1I7OYc0eHWC29c0riMFlBEA and code 5566. The user also recommends considering other options like Thunder due to potential slow download speeds.\n\n\n\n\n\n\nDec 19, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/random_post/(de)obfustication, junk code insertion and removal.html",
    "href": "posts/random_post/(de)obfustication, junk code insertion and removal.html",
    "title": "(de)obfustication, junk code insertion and removal",
    "section": "",
    "text": "(de)obfustication, junk code insertion and removal\ncommon packers:\nThemida, Code Virtualizer, VMProtect, ExeCryptor\ngeneral method for deobfustication\nsee github topic\nprotectors\nJunk Code Generator and Polymorphic Code Engine Guide\nida pro junk code removal"
  },
  {
    "objectID": "posts/random_post/index.html",
    "href": "posts/random_post/index.html",
    "title": "(de)obfustication, junk code insertion and removal",
    "section": "",
    "text": "(de)obfustication, junk code insertion and removal\ncommon packers:\nThemida, Code Virtualizer, VMProtect, ExeCryptor\ngeneral method for deobfustication\nsee github topic\nprotectors\nJunk Code Generator and Polymorphic Code Engine Guide\nida pro junk code removal"
  },
  {
    "objectID": "posts/c4e1b63c-4f52-472f-9117-e2146de87d30/index.html",
    "href": "posts/c4e1b63c-4f52-472f-9117-e2146de87d30/index.html",
    "title": "Discover ‘问财选股’: The Comprehensive Stock Selection Platform and Python Implementation",
    "section": "",
    "text": "问财选股\n官网\n问财api教程\npywencai"
  },
  {
    "objectID": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#collaborative-filtering-recommendation-engine",
    "href": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#collaborative-filtering-recommendation-engine",
    "title": "递归搜索 启发式搜索",
    "section": "collaborative filtering, recommendation engine",
    "text": "collaborative filtering, recommendation engine\nneo4j tutorial on recommendation engine"
  },
  {
    "objectID": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#random-search-libraries",
    "href": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#random-search-libraries",
    "title": "递归搜索 启发式搜索",
    "section": "random search libraries",
    "text": "random search libraries\nspotify randomizer"
  },
  {
    "objectID": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#heuristic-search-libraries",
    "href": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#heuristic-search-libraries",
    "title": "递归搜索 启发式搜索",
    "section": "heuristic search libraries",
    "text": "heuristic search libraries\ntwitch chat scraper and meme prediction heuristic"
  },
  {
    "objectID": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#how-to-find-trending-topics-or-videos",
    "href": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#how-to-find-trending-topics-or-videos",
    "title": "递归搜索 启发式搜索",
    "section": "how to find trending topics or videos?",
    "text": "how to find trending topics or videos?\nyou can check the same set of video and plot their historical stats, or use official ‘trending’ api to find out."
  },
  {
    "objectID": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#find-random-videos-of-certain-topic",
    "href": "posts/28852359-d500-4b77-b5db-1e7343b2ef97/index.html#find-random-videos-of-certain-topic",
    "title": "递归搜索 启发式搜索",
    "section": "find ‘random’ videos of certain topic:",
    "text": "find ‘random’ videos of certain topic:\nsearch for playlists, collect recommendations\napply to some video feeding apis or official api like giphy\nheuristic search, graph search intro\nuse heuristic recursive search, apply random parameters, find related keywords, apply filters and update weights\ntopic modeling using gensim\nbertopic tutorial can predict topics of new document and get topic similarity\npip3 install bertopic\n可以事先设定好目标 不管这个搜没搜到 都要奖励搜索成功的那次过程 比如老头环和elden ring的对应关系\n有没有相关的工具？名字是什么？\nrecursive text search engine\nHeuristic Text Search Engine\nfree pdf: Heuristic and Systematic Use of Search Engines\nit’s like webgpt, which has arxiv pdf paper\nopenai alignment research is to make artificial general intelligence (AGI) aligned with human values and follow human intent.\nthere’s also a fake news detector inside web browser\n搜索一个词 拿到感兴趣的继续搜下一个\n把你搜索的过程记录下来 搜集信息寻找关联的过程记录下来 然后交给ai进行离线训练\n同时可以把你创建内容 组织结构的过程记录下来 交给ai离线训练 适用于template based content generator"
  },
  {
    "objectID": "posts/158d6a57-ec33-467e-94d5-4c309bdbe297/index.html#combining-similarnearby-bounding-boxes-suppressing-near-duplicate-bounding-boxes-over-short-time",
    "href": "posts/158d6a57-ec33-467e-94d5-4c309bdbe297/index.html#combining-similarnearby-bounding-boxes-suppressing-near-duplicate-bounding-boxes-over-short-time",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "combining similar/nearby bounding boxes, suppressing near duplicate bounding boxes over short time",
    "text": "combining similar/nearby bounding boxes, suppressing near duplicate bounding boxes over short time\nsee here\nyou can merge a group of things, then analyze them over time using object tracker, tweening them."
  },
  {
    "objectID": "posts/158d6a57-ec33-467e-94d5-4c309bdbe297/index.html#discrete-interval-set-union-solvers",
    "href": "posts/158d6a57-ec33-467e-94d5-4c309bdbe297/index.html#discrete-interval-set-union-solvers",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "Discrete Interval Set Union Solvers",
    "text": "Discrete Interval Set Union Solvers\nyou may want to filter out short intervals. mind the lopen/ropen interval after intersection or difference operation.\nyou may also want to quantize these intervals, set them to nearest possible points. 用到某采样率 还是根本不用吧 就是属于那个区间的离散点上面执行相应的操作变化 但是那个区间如何划分 怎么把离散点归类到不同区间里面 完全是其他的逻辑需要做的事情 一般同类别的区间不能相交 但是之后再考虑吧 怎么用呢 所有的全部弄到一个列表里面 还是选取最小的那个来用？\ncategory with different groups -&gt; subcategories\nfirst the sample set:\nimport sympy\n\n# make sure every subset is ordered.\nmSet = [(1.0,1.1,1.2),(2.4,2.5,2.6)]\nmSet2 = [(0.9,1.05,1.15),(2.45,2.55,2.65,2.75)]\n\n# convert to intervals first please?\nmSetIntervals = [(x[0],x[-1]) for x in mSet]\nmSet2Intervals = [(x[0],x[-1]) for x in mSet2]\n\n# additional check: these intervals cannot overlap!\ndef checkOverlap(intervalTupleList):\n  unionInterval = sympy.EmptySet # shall be empty here.\n  for start, end in intervalTupleList:\n    newInterval = sympy.Interval(start,end)\n    isOverlapped = (sympy.EmptySet == unionInterval.intersect(newInterval))\n    if isOverlapped:\n      print(\"INTERVAL\", newInterval, \"OVERLAPPED!\")\n      return isOverlapped\n    unionInterval += newInterval\n  return False\n\nassert not checkOverlap(mSetIntervals)\nassert not checkOverlap(mSet2Intervals)\nthen pool and sort all the boundaries of converted intervals:\nmPoints = mSetIntervalBoundaries + mSet2IntervalBoundaries\nmPoints = list(set(mPoints))\nmPoints.sort()\n\nwith sympy\n# all the same\n\n\nwith less sympy\n# all the same"
  },
  {
    "objectID": "posts/158d6a57-ec33-467e-94d5-4c309bdbe297/index.html#continual-interval-set-union-solvers",
    "href": "posts/158d6a57-ec33-467e-94d5-4c309bdbe297/index.html#continual-interval-set-union-solvers",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "Continual Interval Set Union Solvers",
    "text": "Continual Interval Set Union Solvers\nyou must be able to explicitly point out different group index of different category. maybe you can just do it in all-new subcategories?\n\nless exponential solution here?\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# basically the same example.\n# assume no overlapping here.\nimport sympy\n\ndef unionToTupleList(myUnion):\n  unionBoundaries = list(myUnion.boundary)\n  unionBoundaries.sort()\n  leftBoundaries = unionBoundaries[::2]\n  rightBoundaries = unionBoundaries[1::2]\n  return list(zip(leftBoundaries, rightBoundaries))\n\ndef tupleSetToUncertain(mSet):\n  mUncertain = None\n  for start, end in mSet:\n    if mUncertain is None:\n      mUncertain = sympy.Interval(start,end)\n    else:\n      mUncertain += sympy.Interval(start,end)\n  typeUncertain = type(mUncertain)\n  return mUncertain, typeUncertain\n\ndef mergeOverlappedInIntervalTupleList(intervalTupleList):\n  mUncertain, _ = tupleSetToUncertain(intervalTupleList)\n  mUncertainBoundaryList = list(mUncertain.boundary)\n  mUncertainBoundaryList.sort()\n  mergedIntervalTupleList = list(zip(mUncertainBoundaryList[::2], mUncertainBoundaryList[1::2]))\n  return mergedIntervalTupleList\n\nmSet = mergeOverlappedInIntervalTupleList([(0,1), (2,3)])\nmSet2 = mergeOverlappedInIntervalTupleList([(0.5,1.5),(1.6,2.5)])\n\nprint(\"MSET\", mSet)\nprint(\"MSET2\", mSet2)\n\nmSetCandidates = [mSet, mSet2]\nmSetUnified = [x for y in mSetCandidates for x in y]\nleftBoundaryList = set([x[0] for x in mSetUnified])\nrightBoundaryList = set([x[1] for x in mSetUnified])\n# they may freaking overlap.\n# if want nearby-merge strategy, simply just expand all intervals, merge them with union and shrink the individual intervals inside union respectively.\n\nmarkers = {\"enter\":{k:[] for k in leftBoundaryList}, \"exit\":{k:[] for k in rightBoundaryList}}\n\nfor index, mSetCandidate in enumerate(mSetCandidates):\n  leftBoundaryListOfCandidate = [x[0] for x in mSetCandidate]\n  rightBoundaryListOfCandidate = [x[1] for x in mSetCandidate]\n  for leftBoundaryOfCandidate in leftBoundaryListOfCandidate:\n    markers[\"enter\"][leftBoundaryOfCandidate].append(index) # remap this thing!\n  for rightBoundaryOfCandidate in rightBoundaryListOfCandidate:\n    markers[\"exit\"][rightBoundaryOfCandidate].append(index) # remap this thing!\n  \n# now, iterate through the boundaries of mSetUnified.\nunifiedBoundaryList = leftBoundaryList.union(rightBoundaryList) # call me a set instead of a list please? now we must sort this thing\nunifiedBoundaryList = list(unifiedBoundaryList)\nunifiedBoundaryList.sort()\n\nunifiedBoundaryMarks = {}\nfinalMappings = {}\n# print(\"MARKERS\", markers)\n# breakpoint()\nfor index, boundary in enumerate(unifiedBoundaryList):\n  previousMark = unifiedBoundaryMarks.get(index-1, [])\n  enterList = markers[\"enter\"].get(boundary,[])\n  exitList = markers[\"exit\"].get(boundary,[])\n  currentMark = set(previousMark + enterList).difference(set(exitList))\n  currentMark = list(currentMark)\n  unifiedBoundaryMarks.update({index:currentMark})\n  # now, handle the change? or not?\n  # let's just deal those empty ones, shall we?\n  if previousMark == []: # inside it is empty range.\n  # elif currentMark == []:\n    if index == 0: continue # just the start, no need to note this down.\n    else:\n      finalMappings.update({\"empty\":finalMappings.get(\"empty\",[])+[(unifiedBoundaryList[index-1], boundary)]})\n    # the end of previous mark! this interval belongs to previousMark\n  else:\n    key = previousMark.copy()\n    key.sort()\n    key = tuple(key)\n    finalMappings.update({key:finalMappings.get(key,[])+[(unifiedBoundaryList[index-1], boundary)]})\n    # also the end of previous mark! belongs to previousMark.\n\n### NOW THE FINAL OUTPUT ###\nfinalCats = {}\nfor key, value in finalMappings.items():\n  # value is an array containing subInterval tuples.\n  value = mergeOverlappedInIntervalTupleList(value)\n  finalCats.update({key: value})\n\nprint(\"______________FINAL CATS______________\")\nprint(finalCats)\n\n\nsympy solution\nsympy seems to provide support for discrete and continuous interval? will that save any damn time anyway? i’m afraid no? maybe there’s a way!\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport sympy\n\ndef unionToTupleList(myUnion):\n  #  seriously wrong. this will fuck up.\n  unionBoundaries = list(myUnion.boundary)\n  unionBoundaries.sort()\n  leftBoundaries = unionBoundaries[::2]\n  rightBoundaries = unionBoundaries[1::2]\n  return list(zip(leftBoundaries, rightBoundaries))\n\ndef tupleSetToUncertain(mSet):\n  mUncertain = None\n  for start, end in mSet:\n    if mUncertain is None:\n      mUncertain = sympy.Interval(start,end)\n    else:\n      mUncertain += sympy.Interval(start,end)\n  typeUncertain = type(mUncertain)\n  return mUncertain, typeUncertain\n\n# borrowed from above code.\ndef mergeOverlappedInIntervalTupleList(intervalTupleList):\n  mUncertain, _ = tupleSetToUncertain(intervalTupleList)\n  mUncertainBoundaryList = list(mUncertain.boundary)\n  mUncertainBoundaryList.sort()\n  #  print(mUncertain)\n  #  print(mUncertainBoundaryList)\n  mergedIntervalTupleList = list(zip(mUncertainBoundaryList[::2], mUncertainBoundaryList[1::2]))\n  # print(mergedIntervalTupleList)\n  return mergedIntervalTupleList\n\nmSet = [(0,1), (2,3)]\nmUncertain, typeUncertain = tupleSetToUncertain(mSet)\nunrolledMSet = list(mUncertain.boundary)\n# can be either sympy.sets.sets.Interval of sympy.sets.sets.Union\n\nmSet2 = [(0.5,1.5),(1.6,2.5)]\nmUncertain2, typeUncertain2 = tupleSetToUncertain(mSet2)\nunrolledMSet2 = list(mUncertain2.boundary)\n\nprint(\"MSET\", mSet)\nprint(\"MSET2\", mSet2)\n\n############################################################\n\n# hypothetical mSet2 and mUncertain2! please complete the hypothetical shit and make it runnable!\n\ndef checkCommon(subInterval, masterInterval):\n  return subInterval == sympy.Intersection(subInterval, masterInterval)\n\nmUncertains = [mUncertain, mUncertain2]\nsubIntervals = list(set(unrolledMSet2 + unrolledMSet))\nsubIntervals.sort()\n\nsubIntervals = zip(subIntervals[:-1], subIntervals[1:])\nsubIntervals = list(subIntervals)\n#  breakpoint()\n# for subIntervals, it's still not real interval but tuple at above line.\n\nreversedCats = {}\n\nimport functools\nsubIntervalUnion = functools.reduce(lambda a,b: a+b, mUncertains)\n\nfor subIntervalIndex, (start, end) in enumerate(subIntervals):\n  subIntervalCandidate = sympy.Interval(start, end)\n\n  reverseIndex = [] # there must be at least one such index.\n  for index, uncertainCandidate in enumerate(mUncertains):\n    if checkCommon(subIntervalCandidate, uncertainCandidate):\n      reverseIndex.append(index) # this is the index of the in-common set of the original set list\n  reversedCats.update({subIntervalIndex:reverseIndex}) # need to sort and index? or not to sort because this is already done?\n\nnormalCats = {}\nfor k,v in reversedCats.items():\n  v.sort()\n  v = tuple(v)\n  normalCats.update({v:normalCats.get(v, [])+[k]})\n# we only get interval, not the actural union period!\n# how to get interval elements out of union structure for hell sake?\n\nfinalCats = {}\nfor k,v in normalCats.items():\n  # now k is the original set index list, representing belonging of the below union.\n  #  print(subIntervals)\n  #  print(index)\n  #  print(v)\n  #  breakpoint()\n  mFinalUnionCandidate = [subIntervals[index] for index in v]\n\n  ## REPLACED ##\n  # mFinalUnionCandidate, _ = tupleSetToUncertain(mFinalUnionCandidate)\n\n  ##### union to tuple list, could be replaced #####\n  #mFinalUnionCandidateBoundaryList = list(mFinalUnionCandidate.boundary)\n  #left_bounds, right_bounds = mFinalUnionCandidateBoundaryList[0::2],mFinalUnionCandidateBoundaryList[1::2] # check it dammit! not sure how to step the list properly?\n  #mFinalIntervalListCandidate = list(zip(left_bounds, right_bounds))\n\n  # mFinalIntervalListCandidate = unionToTupleList(mFinalUnionCandidate)\n  ##### union to tuple list, could be replaced #####\n  ## REPLACED ##\n  # print(\"M_FINAL_UNION_CANDIDATE\",mFinalUnionCandidate)\n\n  mFinalIntervalListCandidate = mergeOverlappedInIntervalTupleList(mFinalUnionCandidate)\n  # print(\"M_FINAL_INTERVAL_LIST_CANDIDATE\", mFinalIntervalListCandidate)\n\n  # breakpoint()\n  finalCats.update({k:mFinalIntervalListCandidate.copy()})\n# this whole calculation could just be exponential. goddamn it?\n# before that, we need to get the \"empty\" out. but is that really necessary? i think it is, as an important feature.\n#  subIntervalsStart, subIntervalsEnd = subIntervals[0][0], subIntervals[-1][-1]\n#\n#  relativeCompleteInterval = sympy.Interval(subIntervalsStart, subIntervalsEnd)\n#\n# subIntervalUnion\n#  emptyIntervalUnion = relativeCompleteInterval - subIntervalUnion # really uncertain if it is just a union or not.\n#  emptyIntervalTupleList = unionToTupleList(emptyIntervalUnion)\n#\n#  finalCats.update({\"empty\":emptyIntervalTupleList})\nfinalCats.update({\"empty\":finalCats[()]})\ndel finalCats[()]\n\nprint(\"_____FINAL CATS_____\")\nprint(finalCats)"
  },
  {
    "objectID": "posts/ae42fcf4-95a4-4185-83c4-f5d87f02aaff/index.html",
    "href": "posts/ae42fcf4-95a4-4185-83c4-f5d87f02aaff/index.html",
    "title": "踩点 音乐识别",
    "section": "",
    "text": "踩点 音乐识别 搞笑视频收集\nnow we have audioFlux, alternative to librosa, but faster\n\naudioowl for tempo, beat and notes identification: https://github.com/dodiku/AudioOwl\ncnn based audio segmentation toolkit allow to detect speech, music and speaker gender: https://github.com/ina-foss/inaSpeechSegmenter\nspeech music detection using keras: https://github.com/qlemaire22/speech-music-detection\nawesome deep learning music: https://github.com/ybayle/awesome-deep-learning-music\nmusic genre classification/ Music Classification/ Music Recommendation/ Music search https://github.com/mlachmish/MusicGenreClassification https://github.com/kristijanbartol/Deep-Music-Tagger https://github.com/tae-jun/resemul https://github.com/Insiyaa/Music-Genre-Classification\nmusic recognization service: audioid soundhound\nmaybe you should consider some chinese tools? none there.\nmusic radar recognize music: https://github.com/keshavbhatt/music-radar\nmousai using free audd api to recognize music: https://github.com/SeaDve/Mousai\nmusic emotion recognization: https://github.com/SeungHeonDoh/Music_Emotion_Recognition\nmusic tagging and recognization, using acoustic ids and community based music database: https://github.com/metabrainz/picard https://musicbrainz.org/doc/AcoustID\nmixingbear(alike neuralmix): https://github.com/dodiku/MixingBear\nmadmom https://github.com/CPJKU/madmom http://madmom.readthedocs.org\n音乐分类 综合音频分析包 pyaudioanalysis\nmathematica audio slience removal segmentation: https://zhuanlan.zhihu.com/p/43165678\nmusic21 for music recognition: https://zhuanlan.zhihu.com/p/35140033\nmusic21 for midi analysis: https://pypi.org/project/music21/\nhttps://music21.readthedocs.io/en/latest https://zhuanlan.zhihu.com/p/73564852\nsound recognition and localization: https://reality.ai/automotive-sound-recognition-localization/\nurbansound8k dataset ( 6gb ): https://www.kaggle.com/datasets/chrisfilo/urbansound8k\nfourier transform cat meow detection: https://github.com/EricDavidWells/MeowDetector\nbuilding sound event classifier: https://ignitarium.com/building-an-ai-based-sound-event-classifier/\nreal time continuous sound event classification(usually via silence detection): https://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e https://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e https://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc\ncry detection: https://www.amberou.com/cry-detection https://github.com/umangkk5/Infant-Cry-Detection-System/blob/master/site-packages/soundfile.py\nurbansound classifier: https://github.com/awln/urban8k-audio-classifier\nlaugh detection: https://github.com/ideo/LaughDetection\ngun shot detection: https://github.com/hasnainnaeem/Gunshot-Detection-in-Audio\ndog bark detector: https://github.com/t04glovern/dog-bark-detection https://devopstar.com/2020/04/13/dog-bark-detector-machine-learning-model https://dsp.stackexchange.com/questions/23466/detect-dog-barks\n获得音乐识别api 最好是qq音乐识别 国内识别引擎 不能识别就分析简介 有没有BGM\n踩点 bpm以前的autoup项目里有 看看其他的分析软件有没有 premiere一键踩点插件可能有开源库支持\n已有的踩点视频 可以切出无文字的片段 根据音乐结构区分高潮 开始 中间等部分 根据音乐类型标签归类视频\n搞笑视频的话 有纯笑声比较好 动作幅度大的 不要有对话 反向截图 收集类似视频"
  },
  {
    "objectID": "posts/1d21dd6c-e0ea-4ce4-bb50-242fb8a434ba/index.html#online",
    "href": "posts/1d21dd6c-e0ea-4ce4-bb50-242fb8a434ba/index.html#online",
    "title": "语音转文字 stt speech to text",
    "section": "online",
    "text": "online\n字说APP的api\n逆向搜狗输入法 绕过签名验证\n搜狗输入法apk的api\n微软stt https://github.com/cuberwr/bilibiliSTT\n多家免费stt https://github.com/1c7/Translate-Subtitle-File"
  },
  {
    "objectID": "posts/1d21dd6c-e0ea-4ce4-bb50-242fb8a434ba/index.html#offline",
    "href": "posts/1d21dd6c-e0ea-4ce4-bb50-242fb8a434ba/index.html#offline",
    "title": "语音转文字 stt speech to text",
    "section": "offline",
    "text": "offline\npyannote segment audio according to different speakers, detect voice activity\nspeechbrain very advanced speech related ai library, with almost everything related to speech\nvosk\npaddlespeech\n\npaper of Google USM (universal speech model) supporting 1000 languages\n\nwhisper.cpp perform fast voice to text operation using cpu rather than gpu\nwhisperx improve time accuracy with forced alignment\nwhisper gui buzz\nwhisper by openai, with multilingual and translation avaliable, can detect under background music and noise, with slience,"
  },
  {
    "objectID": "posts/a7d59058-9711-4b01-b1e9-50b324a610fb/index.html",
    "href": "posts/a7d59058-9711-4b01-b1e9-50b324a610fb/index.html",
    "title": "Automating Freelance Job Offers: AI-Powered System for Paper Writing Industry",
    "section": "",
    "text": "论文代写 作业代写转为AI自动运作项目\n收集各大兼职网站 QQ接单群 闲鱼的项目描述 人工标注项目报价费用 训练实现自动报价抽成机器人\n根据项目描述和大量公开数据 进行开放式问答 训练并应用于论文实现代写方面的付费问答机器人"
  },
  {
    "objectID": "posts/1e592d10-c30e-48c8-80ca-2477c5c11a3c/index.html",
    "href": "posts/1e592d10-c30e-48c8-80ca-2477c5c11a3c/index.html",
    "title": "补帧 插帧 提高帧数",
    "section": "",
    "text": "补帧 插帧 提高帧数 黑白相片上色 慢动作视频 照片优化 提高清晰度 模糊变清晰 人像美颜\n超分辨率 super resolution realcugan bilibili official real cugan\navisynth的替代品：vapoursynth（in Python） FrameServer\nvapoursynth is somehow installed on python 3.10(brew). do not know what depends on that.\nmvtools for vapoursynth motion compensation\n效果好 速度慢 dain\nrife 速度快 画质会变差 another repo link with more stars\nvapoursynth rife filter usage just a gist\nvsrife using cuda\nrife plugin for vapoursynth using vulkan\nnvidia super slomo 比较吃显存 需要NVIDIA SDK 速度快\nsepconv 看起来比较模糊 但是还是比直接overlay要好\npytorch sepconv slomo\nmemc-net比较清晰\nFFmpeg自带插帧的filter：\nffmpeg -i input.60fps.hevc -filter \"minterpolate='fps=120'\" output.120fps.hevc\nai黑白上色可以把原视频洗稿：image colorization\ncoloring grayscale images Coloring black and white images with deep learning\nmemc (motion estimation/motion compensation)\n在CSDN上看到的算法名称和内容\n内置超分辨率算法: Waifu2x / SRMD / RealSR / Real-ESRGAN/ Real-CUGAN / Anime4K / ACNet\n内置超分辨率引擎: Waifu2x-caffe / Waifu2x-converter / Waifu2x-ncnn-vulkan SRMD-ncnn-vulkan / RealSR-ncnn-vulkan / Anime4KCPP / SRMD-CUDA RealESRGAN-NCNN-Vulkan / Real-CUGAN-ncnn-vulkan\n内置插帧算法: RIFE / CAIN / DAIN\n内置插帧引擎: rife-ncnn-vulkan / cain-ncnn-vulkan / dain-ncnn-vulkan"
  },
  {
    "objectID": "posts/03db32e4-dfa2-4092-b2b6-7ccde1f4048a/index.html",
    "href": "posts/03db32e4-dfa2-4092-b2b6-7ccde1f4048a/index.html",
    "title": "自动内容发布 多平台发布 管理多个自媒体平台 automatic content posting in multiple platforms",
    "section": "",
    "text": "自动内容发布 多平台发布 管理多个自媒体平台 automatic content posting in multiple platforms\n文章多平台发布 浏览器插件 一键同步文章到多个内容平台，支持今日头条、WordPress、知乎、简书、掘金、CSDN、typecho各大平台，一次发布，多平台同步发布。解放个人生产力"
  },
  {
    "objectID": "posts/d5ecc5c6-8e92-4a39-a138-a5b0c766511c/index.html#交易接口",
    "href": "posts/d5ecc5c6-8e92-4a39-a138-a5b0c766511c/index.html#交易接口",
    "title": "股票数据源 tick级别数据源 逐笔交易",
    "section": "交易接口",
    "text": "交易接口\n现在哪些券商的TradeX.dll接口还能用 需要注册论坛账号 达到要求才能浏览内容\ntrade.dll tradex.dll\ntradex.dll header file\nbqtradex A simple tradex api mock dll, for easily internal debug your app\nQuantaxis\ntdxtradeserver\ntradex-api\ntdxapi2\nalphaquant"
  },
  {
    "objectID": "posts/d5ecc5c6-8e92-4a39-a138-a5b0c766511c/index.html#数据来源",
    "href": "posts/d5ecc5c6-8e92-4a39-a138-a5b0c766511c/index.html#数据来源",
    "title": "股票数据源 tick级别数据源 逐笔交易",
    "section": "数据来源",
    "text": "数据来源\n逐笔数据是计算涨速的关键因素\nashare\nquantaxis secretely using pytdx and tdxtradeserver as backends\nakshare\n获取涨速\nimport akshare as ak\n\nstock_zh_a_spot_em_df = ak.stock_zh_a_spot_em()\nprint(stock_zh_a_spot_em_df)\nqstock\nefinance\nbaostock\npytdx and docs, must connect to tdx server before operate\npytdx2 fixed some problems\nmootdx actually using pytdx as backend\nabquant-data using pytdx as backend\n计算涨速等数据\npysnowball雪球数据源\nchromedriver based xueqiu api\n获取雪球cookie\n雪球tick级别数据获取\nzipline_chstock 本地化zipline，并对其进行部分加工，适用于国内 day,minute 和tick数据的回测\n新浪财经api"
  },
  {
    "objectID": "posts/f81a975f-8ce8-4c8c-9b7a-d398f65c718a/index.html",
    "href": "posts/f81a975f-8ce8-4c8c-9b7a-d398f65c718a/index.html",
    "title": "程序员笑话 可当文案 jokes about programmers",
    "section": "",
    "text": "程序员笑话 可当文案 jokes about programmers\nrunoob coder jokes: https://www.runoob.com/w3cnote_genre/joke/page/2\ntelegram channels for programmer jokes"
  },
  {
    "objectID": "posts/c40d454a-7f70-40f6-8d78-9794e314730d/index.html",
    "href": "posts/c40d454a-7f70-40f6-8d78-9794e314730d/index.html",
    "title": "短网址生成器",
    "section": "",
    "text": "短网址生成器\n就没一个能用的 除了b站的短链接\n可能抖音快手也有吧 但是懒得管了 大不了二维码应付"
  },
  {
    "objectID": "posts/03a17954-2efd-4eb6-8cae-ae0f3873e9f1/index.html",
    "href": "posts/03a17954-2efd-4eb6-8cae-ae0f3873e9f1/index.html",
    "title": "直接调用安卓方法 frida 直接调用二进制里面的方法",
    "section": "",
    "text": "直接调用安卓方法 frida 直接调用二进制里面的方法\nfrida主动调用函数\n使用Frida框架hook安卓native方法\nfrida主动调用简介"
  },
  {
    "objectID": "posts/93e26140-aa2e-426c-9db7-d5fc65615ef2/index.html",
    "href": "posts/93e26140-aa2e-426c-9db7-d5fc65615ef2/index.html",
    "title": "百度贴吧转化笔记",
    "section": "",
    "text": "百度贴吧转化笔记\n只看楼主 获取主要信息\n有人用贴吧注册的账号来顶贴"
  },
  {
    "objectID": "posts/82996d42-91e4-464f-8138-354a0e8e75ba/index.html",
    "href": "posts/82996d42-91e4-464f-8138-354a0e8e75ba/index.html",
    "title": "百度 搜狗 公开API 搜索引擎爬虫 Baidu Search APIs Chatbot APIs",
    "section": "",
    "text": "百度 搜狗 公开API 搜索引擎爬虫 Baidu Search APIs Chatbot APIs\nzhihuq query zhihu articles by keywords and relevance\nb站前100视频爬取\nb站爬取首页热门推荐视频\n爬取b站弹幕\ntrending scraper for bilibili, baidu, zhihu, weibo 基于node.js的抓取微博、百度热搜、知乎日报、bilibili等热榜榜爬虫 热搜\ntrending reddit videos scraper and video uploader for youtube with special transition effects\nnews search engine 新闻搜索\n通过百度 微视（腾讯小视频）是可以搜索的\nimage search engines sourced from search by image browser plugin: Google, Bing, Yandex, Baidu and TinEye\ngoogle tts for python: import gtts\n爬取课程视频 去水印 coursera udemy khanacademy icourse163\n爬取tumblr 知乎 腾讯新闻 https://github.com/zhangslob/awesome_crawl\n图片下载api https://github.com/CharlesPikachu/imagedl\n免费聊天api 青云客api 腾讯智能闲聊 https://zhuanlan.zhihu.com/p/110785806 http://api.qingyunke.com/api.php?key=free&appid=0&msg=你好\n思知对话机器人 语义理解 自然语言转化为结构化数据 https://www.ownthink.com/docs/bot/ https://github.com/ownthink/robot/\n流行视频下载api https://github.com/CharlesPikachu/videodl\n热搜 https://github.com/Eurkon/weibo-top-api https://github.com/ningyuwhut/query_suggestion https://github.com/Arrackisarookie/weibo-hot-search https://github.com/justjavac/zhihu-trending-top-search https://github.com/justjavac/weibo-trending-hot-search https://github.com/huqi-pr/trending-in-one https://github.com/jw-star/weiboPush-go-actions\n热搜2 https://github.com/wanghuafeng/baidu_spider https://github.com/TauWu/weibo_daily_hotkey https://github.com/quarrying/baidu-top-crawler https://github.com/towelong/zhihu-hot-questions https://github.com/gaussic/baidu_hot_words https://github.com/ctts/TopSearch https://github.com/henrylee123/baiduIndexCrawler https://github.com/realzhengyiming/Spider_of_keywordRank\n登录主流网站 https://github.com/CharlesPikachu/DecryptLogin\n微博热搜 https://github.com/Eurkon/weibo-top-api\n微博 python api https://pypi.org/project/weibo/\ngithub actions抓取微博热搜 https://github.com/xiadd/tg-wb-trending\n百度搜索api https://github.com/wcadaydayup/python-baidusearch https://github.com/1049451037/MagicBaidu https://github.com/alkalixin/jsonp\n微软小冰api https://github.com/yanwii/msxiaoiceapi https://github.com/BennyThink/realXiaoice\n搜狗微信 https://github.com/chyroc/WechatSogou https://github.com/jaryee/wechat_sogou_crawlhttps://github.com/pujinxiao/weixin\n知乎爬虫 https://github.com/LiuRoy/zhihu_spider\n搜索引擎爬虫 图片下载 https://github.com/tasos-py/Search-Engines-Scraper https://github.com/ostrolucky/Bulk-Bing-Image-downloader https://github.com/NikolaiT/GoogleScraper https://github.com/naqushab/SearchEngineScrapy"
  },
  {
    "objectID": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#聚焦在主流平台",
    "href": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#聚焦在主流平台",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "聚焦在主流平台",
    "text": "聚焦在主流平台\n主流平台就是有现成api搜索的平台\n如果没有api 就需要用playwright 但是可能耗时更长 也更加偏离找素材的关键\n目前主流平台都有现成高级api可以对接 如果找不到api则可能说明不是主流的平台\n主流平台分为主流媒体和搜索引擎两大类\n如果需要搜索小众的平台 建议对接搜索引擎 加入高级搜索参数 搜出来的链接拿来分析看能不能直接下载"
  },
  {
    "objectID": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#api应该具有的功能",
    "href": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#api应该具有的功能",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "api应该具有的功能",
    "text": "api应该具有的功能\n搜索 高定制搜索 可以做到不重复\n视频信息（时长 播放量 简介 封面 字幕 标题 标签 评论）提取\n相关视频推荐提取 首页推荐提取\n热榜热搜提取 搜索补全提取\n下载视频 尽量无水印 字幕\n如果是要发布内容的平台 则需要有上传功能\n上传视频 封面 简介 标签 合集信息 字幕\n上传文章 图片"
  },
  {
    "objectID": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#用什么关键词",
    "href": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#用什么关键词",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "用什么关键词",
    "text": "用什么关键词\n找到最合适的 适合当前生成框架的素材 需要自己去尝试总结\n当然也可以用关键字和评论 视频播放量反馈机制寻找合适的关键词 或者是神经网络 机器学习 或者是图数据库 推荐算法\n标签 关键词 -&gt;视频 -&gt; 同类视频 某个观众 -&gt; 同个作者"
  },
  {
    "objectID": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#如何分析视频",
    "href": "posts/8b3ea550-2404-4aa2-aee9-1bf095b1ff8b/index.html#如何分析视频",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "如何分析视频",
    "text": "如何分析视频\n首先要裁剪画中画 再去除水印 去文字 提高画质 提高帧数 如果需要提取识别字幕就需要在指定区域识别 语音识别如果要做就需要分离人声 检测文字流畅度 （对于外文或者歌曲可能不会很流畅）\n根据一定的标准筛选 裁剪时长和画布 比如时长 音量 光流 文字面积 是否有人像 人物的动作幅度\n如果要分离人声 一般要配合相应的字幕 还得变声 检测说话人有几个（如果多人说话 语音识别可能不会正常工作 文字流畅度低） 是男是女\n如果需要音乐 BGM 一般不直接从视频里面提取 而是从简介里面找到关键字 拿到专门的音乐平台去搜索 音乐也可能需要筛选一下 根据类别和播放量 评论反馈筛选"
  },
  {
    "objectID": "posts/b237550a-72b6-43c7-ab75-fb212b5d585d/index.html",
    "href": "posts/b237550a-72b6-43c7-ab75-fb212b5d585d/index.html",
    "title": "海外哔哩哔哩",
    "section": "",
    "text": "海外哔哩哔哩\nbilibili.tv"
  },
  {
    "objectID": "posts/de2dd192-9244-41cf-ae35-01650ee7fd1f/index.html",
    "href": "posts/de2dd192-9244-41cf-ae35-01650ee7fd1f/index.html",
    "title": "正方教务系统sql注入",
    "section": "",
    "text": "正方教务系统sql注入\n通过url遍历得到asmx结尾的url进行注入 如果你要进行报复学校这个看起来很不错"
  },
  {
    "objectID": "posts/eccb1911-251b-4e8d-8934-aaed3efa895e/index.html#template-extraction-neural-template-generation",
    "href": "posts/eccb1911-251b-4e8d-8934-aaed3efa895e/index.html#template-extraction-neural-template-generation",
    "title": "标题生成",
    "section": "template extraction, neural template generation",
    "text": "template extraction, neural template generation\n封面来源： 利用标题进行图片搜索 其实只能站内搜索 因为站外没有这种图片与文字的对应关系 截取视频截图 b站原图 histogram match 20% 去掉文字 镜像反转 加入随机噪声 旋转1度 利用封面进行图片反向搜索 效果其实不好 并没有想要的照片 只能找到原图 有可能起到去水印的效果 但是有限\n\nreverse image search engine\nreverse image search engine\nmeta image search engine\ntelegram reverse image search bot\n\nneural template gen is a natural language generator based on templates from harvard nlp, can be used for title generation"
  },
  {
    "objectID": "posts/eccb1911-251b-4e8d-8934-aaed3efa895e/index.html#根据标签生成广告-同样可以根据标签生成视频标题推荐-在千言数据集上训练过",
    "href": "posts/eccb1911-251b-4e8d-8934-aaed3efa895e/index.html#根据标签生成广告-同样可以根据标签生成视频标题推荐-在千言数据集上训练过",
    "title": "标题生成",
    "section": "根据标签生成广告 同样可以根据标签生成视频标题（推荐） 在千言数据集上训练过",
    "text": "根据标签生成广告 同样可以根据标签生成视频标题（推荐） 在千言数据集上训练过\nhttps://huggingface.co/cocoshe/gpt2-chinese-gen-ads-by-keywords?text=My+name+is+Clara+and+I+am\ntitle generator(from description): https://github.com/harveyaot/DianJing/blob/master/scripts/title_generation_lm.py https://blog.csdn.net/stay_foolish12/article/details/111661358\ncover generation rectangle packing allow overlapping when solution is not found, decrease the size of rectangles.\nyoutube title generator using AI: https://github.com/gdemos01/YoutubeVideoIdeasGeneratorAI\nai thumbnail generator using pyscenedetect: https://github.com/yoonhero/ai-thumbnail-generator\nimage captioning: https://github.com/ruotianluo/ImageCaptioning.pytorch\nyouzan clip product title generation: https://huggingface.co/youzanai/clip-product-title-chinese\npaper title generator without description: https://github.com/csinva/gpt2-paper-title-generator\nimage captioning using cnn and rnn: https://github.com/SCK22/image_and_video\nimage captioning can also be used for video captioning. but that will suffice the accuracy.\nkeras.io image captioning https://keras.io/examples/vision/image_captioning/\ngenerate image captions using CLIP and GPT(on medium, click continue reading) https://towardsai.net/p/l/image-captioning-with-clip-and-gpt\ngpt3demo.com has provided a lot of interesting tasks that gpt3 can do. including image captioning. may find video captioning, video classification.\ngpt3demo.com provided image captioning libs: https://gpt3demo.com/category/image-captioning clipclap gpt-3 x image captions\nvisualgpt: generate image captions https://github.com/Vision-CAIR/VisualGPT\ngenerate stories from pictures, using image transformers and gpt-2, just intro no code https://www.dataversity.net/image-captioning-generating-stories-from-unstructured-data-using-applied-nlg/"
  },
  {
    "objectID": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#为什么要日站",
    "href": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#为什么要日站",
    "title": "日站之随想",
    "section": "为什么要日站",
    "text": "为什么要日站\n因为自己电脑算力有限 要探索高级人工智能 要运行某些赚钱程序 必须免费白嫖别人的算力"
  },
  {
    "objectID": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#日哪些站",
    "href": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#日哪些站",
    "title": "日站之随想",
    "section": "日哪些站",
    "text": "日哪些站\n到百度 各大搜索引擎找目标站点 扫描漏洞 不要打大站 先从小站打起走 往全自动化方向打起走"
  },
  {
    "objectID": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#怎么日站",
    "href": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#怎么日站",
    "title": "日站之随想",
    "section": "怎么日站",
    "text": "怎么日站\n在一个沙箱下面日站 不要在root权限下面日 利用工具 目标站点IP 端口就直接填到工具里面就行 一边学工具一边日站 需要一个repo专门放有关的代码 同时可以同步到每个设备 需要一个可以搜索全文的搜索引擎 搜集我们已有的md文件 提取里面的链接 然后继续clone github的文件 继续搜集md文件 继续寻找链接"
  },
  {
    "objectID": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#日站之后干什么",
    "href": "posts/7141e552-63ce-497a-9a57-d2504042c6be/index.html#日站之后干什么",
    "title": "日站之随想",
    "section": "日站之后干什么",
    "text": "日站之后干什么\n放传染性病毒 放挖币病毒 或者执行agi实验"
  },
  {
    "objectID": "posts/22b4146e-d653-4ae1-b37f-2abf836287a5/index.html",
    "href": "posts/22b4146e-d653-4ae1-b37f-2abf836287a5/index.html",
    "title": "推荐系统 GNN",
    "section": "",
    "text": "推荐系统 GNN\n1、muricoca/crab https://github.com/muricoca/crab\n2、ibayer/fastFM https://github.com/ibayer/fastFM\n3、Mendeley/mrec https://github.com/mendeley/mrec\n4、MrChrisJohnson/logistic-mf https://github.com/MrChrisJohnson/logistic-mf\n5、jadianes/winerama-recommender-tutorial https://github.com/jadianes/winerama-recommender-tutorial\n6、ocelma/python-recsys https://github.com/ocelma/python-recsys\n7、benfred/implicit https://github.com/benfred/implicit\n8、lyst/lightfm https://github.com/lyst/lightfm\n9、python-recsys/crab https://github.com/python-recsys/crab\n10、NicolasHug/Surprise https://github.com/NicolasHug/Surprise\n\nlinkedin gdmix simple and memory effective personalized ranking\ndatawhale fun-rec 推荐系统入门教程 datawhale rechub\nimage to text, text to image, clip as image/text embeddings\ndeep recommendation using tensorflow 1.15\nimage recommendation system\n不同的人有不同喜好 不同的人和不同的人说话 不同的产品有不同的特征 不同的产品和不同的产品被一起推荐\n人对产品的接受度\nyouzan has an ai platform called trexpark, offering chinese NLP and image models pretrained from e-commerce databases. https://github.com/youzanai/trexpark\nsession based recommendation system: https://github.com/CRIPAC-DIG/SR-GNN\ndecide the feedback embeddings: https://huggingface.co/youzanai/bert-product-comment-chinese\nconversational embeddings: https://huggingface.co/youzanai/bert-customer-message-chinese\nneo4j developer build a recommendation engine: https://neo4j.com/developer/cypher/guide-build-a-recommendation-engine/\ntorch_geometric(PyG) documentation: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GatedGraphConv\nsetup GCN using PyG: https://zhuanlan.zhihu.com/p/400078504\ntagspace text classification via hashtags: https://paddlerec.readthedocs.io/en/latest/models/contentunderstanding/tagspace.html\ngnn is based on basic data/label models and provide high-level reasoning and predictions.\nneo4j graph academy practical usage: https://graphacademy.neo4j.com/categories/ https://neo4j.com/graphacademy/training-iga-40/12-iga-40-ingredient-analysis/\nvideo segments have different features and orders. predict missing links. predict categories semi-supervised or unsupervised.\nvideo-image-text-music correlation and predict internal relationships, categories.\nrecommendation system: paddlerec(multimodal), torchrec(cuda==11.3, build failed due to unable to find ATen from torch/include.) https://neo4j.com/docs/graph-data-science/current/end-to-end-examples/fastrp-knn-example/\nlink prediction: https://github.com/Orbifold/pyg-link-prediction/blob/main/run.py\nhow to use pyg for link prediction: https://github.com/pyg-team/pytorch_geometric/issues/634\ndgl, install from source, with link prediction: https://docs.dgl.ai/tutorials/blitz/4_link_predict.html https://github.com/dmlc/dgl https://docs.dgl.ai/guide_cn/training-link.html#guide-cn-training-link-prediction\ngnn intro: https://cnvrg.io/graph-neural-networks/\ngnn applications: Node classification: The objective here is to predict the labels of nodes by considering the labels of their neighbors. Link prediction: In this case, the goal is to predict the relationship between various entities in a graph. This can for example be applied in prediction connections for social networks. Graph clustering: This involves dividing the nodes of a graph into clusters. The partitioning can be done based on edge weights or edge distances or by considering the graphs as objects and grouping similar objects together. Graph classification: This entails classifying a graph into a category. This can be applied in social network analysis and categorizing documents in natural language processing. Other applications in NLP include text classification, extracting semantic relationships between texts, and sequence labeling. Computer vision: In the computer vision world, GNNs can be used to generate regions of interest for object detection. They can also be used in image classification whereby a scene graph is generated. The scene generation model then identifies objects in the image and the semantic relationship between them. Other applications in this field include interaction detection and region classification."
  },
  {
    "objectID": "posts/d3d8b742-03ca-4f0b-bce9-6c253d01e401/index.html",
    "href": "posts/d3d8b742-03ca-4f0b-bce9-6c253d01e401/index.html",
    "title": "捡塑料瓶机器人 吸硬币 回收硬币机器人",
    "section": "",
    "text": "捡塑料瓶机器人 吸硬币 回收硬币机器人"
  },
  {
    "objectID": "posts/1394d7ac-7d7f-4c37-94d0-999ac1e94f23/index.html",
    "href": "posts/1394d7ac-7d7f-4c37-94d0-999ac1e94f23/index.html",
    "title": "怎样清理嗓子 鼻腔里面的痰液",
    "section": "",
    "text": "怎样清理嗓子 鼻腔里面的痰液\n挤压耳后根 耳洞旁 同时吸气 用力打开耳朵通鼻腔的通道 吐痰\n如果面部 下巴 脖子后面有酸胀的区域也可以挤压"
  },
  {
    "objectID": "posts/1946e219-6aef-4fdd-9e6d-8bf92a2f9df4/index.html",
    "href": "posts/1946e219-6aef-4fdd-9e6d-8bf92a2f9df4/index.html",
    "title": "Understanding WeChat Pay and Alipay: The Popular Payment Systems in China",
    "section": "",
    "text": "微信支付 支付宝 中转系统\n既可以收款也可以付款的库 可以扫描别人的二维码付款 可以生成二维码检测别人是否付款"
  },
  {
    "objectID": "posts/002dd458-e9b8-4128-abe7-7b11ec870fc7/index.html",
    "href": "posts/002dd458-e9b8-4128-abe7-7b11ec870fc7/index.html",
    "title": "开放api 信息来源",
    "section": "",
    "text": "开放api 信息来源\ncat as a service not infinite user provided content: https://cataas.com/#/ https://cataas.com/cat/gif/says/Hello?filter=sepia&color=orange&size=40&type=or"
  },
  {
    "objectID": "posts/346f9fb0-e342-4d72-bf4c-5b2561999fc7/index.html",
    "href": "posts/346f9fb0-e342-4d72-bf4c-5b2561999fc7/index.html",
    "title": "Mastering Android Reverse Engineering Tools: IDA, Ghidra, Frida, GDA and Flowdroid",
    "section": "",
    "text": "安卓反编译\nida ghidra frida\nfrida extension/helper methods\nattach existing process\nsudo frida-ps\nsudo frida -n WeChat\nsudo frida -p [pid]\ngda 交互式Android反编译 支持数据流追踪\nflowdroid"
  },
  {
    "objectID": "posts/48d1d417-42e8-4a60-a3cb-05cee6495c76/index.html#站着操作电脑-需要脚踏板式的跑步机",
    "href": "posts/48d1d417-42e8-4a60-a3cb-05cee6495c76/index.html#站着操作电脑-需要脚踏板式的跑步机",
    "title": "夏天制冷装置",
    "section": "站着操作电脑 需要脚踏板式的跑步机",
    "text": "站着操作电脑 需要脚踏板式的跑步机\n循环水床垫\n循环水马甲\n带风扇的坐垫和靠背\n地板瓷砖\n加湿器风扇\n水空调 自动加水 工业\n除湿机 自动排水\n高锰酸钾\n软加硬空调出风挡板 强力胶带 防水\n移动双风道空调"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#自建搜题库-搜索公式的引擎-给学生提供服务",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#自建搜题库-搜索公式的引擎-给学生提供服务",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "自建搜题库 搜索公式的引擎 给学生提供服务",
    "text": "自建搜题库 搜索公式的引擎 给学生提供服务"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#破解学校系统-往学校的系统和服务器上面放病毒-让所有访问的人挖矿-让服务器挖矿",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#破解学校系统-往学校的系统和服务器上面放病毒-让所有访问的人挖矿-让服务器挖矿",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "破解学校系统 往学校的系统和服务器上面放病毒 让所有访问的人挖矿 让服务器挖矿",
    "text": "破解学校系统 往学校的系统和服务器上面放病毒 让所有访问的人挖矿 让服务器挖矿"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#自动提醒上课",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#自动提醒上课",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "自动提醒上课",
    "text": "自动提醒上课\n如果新添加或者复读某些课程 课表会发生变化\n所有的课程念一遍了之后 这个程序可以完全离线运行"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#网课找答案",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#网课找答案",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "网课找答案",
    "text": "网课找答案\n微型计算机基础 第一单元测验答案\n通用网课找答案 根据网课名字找答案 可以和百度一起用"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#慕课堂课程码-雨课堂课程码",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#慕课堂课程码-雨课堂课程码",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "慕课堂课程码 雨课堂课程码",
    "text": "慕课堂课程码 雨课堂课程码\n微信扫描二维码添加慕课课堂（网页版本） 微信点击进入慕课堂 慕课堂需要课程码添加\n微型计算机与接口技术 慕课堂 8X5MLW 这门课程说是在网页上面做题 可以在这里收集课件 雨课堂 5JGDZ"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#tools-for-table-coversion",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#tools-for-table-coversion",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "tools for table coversion",
    "text": "tools for table coversion\nhtml table to markdown not work so well\nmarkdown to csv"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#作息时间表",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#作息时间表",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "作息时间表",
    "text": "作息时间表\n\n\n\n课程编号\n课程时间\n\n\n\n\n预备铃\n7:50\n\n\n第1节\n8:00—8:45\n\n\n第2节\n8:50—9:35\n\n\n第3节\n9:50—10:35\n\n\n第4节\n10:40—11:25\n\n\n第5节\n11:30—12:15\n\n\n预备铃\n13:35\n\n\n第6节\n13:45—14:30\n\n\n第7节\n14:35—15:20\n\n\n第8节\n15:35—16:20\n\n\n第9节\n16:25—17:10\n\n\n第10节\n18:30—19:15\n\n\n第11节\n19:25—20:10\n\n\n第12节\n20:20—21:05"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#第一学期-课表",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#第一学期-课表",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "2022-2023 第一学期 课表",
    "text": "2022-2023 第一学期 课表\nneed improvement."
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#inspiration",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#inspiration",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "inspiration",
    "text": "inspiration\n苹果前首席设计师对大学生讲的话: willing to learn is far more important than being correct. opinion is not idea."
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#策略",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#策略",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "策略",
    "text": "策略\ndo not pretent to cooperate. we are alone. always.\n\n8月19号 13:20分开始不听课 执行我们的计划（应该是pyjom的渲染框架测试）直到晚上11点整\n\n我觉得这帮人就压根没想把我讲懂 这帮人只是想一味的做重复计算 不注重实际 说白了就是穷鬼 穷逼 一天到晚不想赚钱就想念经 不告诉我怎么赚钱 我听个屁\n课可听可不听 可以完全不听 题随便做一做 爱做完做不完完全不管 都是装样子 必须把所有时间拿出来执行我们的pyjom计划以及其他在schedule上面的计划\n能抄就抄 不抄也无所谓 都是拿钱做烂事的人 我本来就不需要学这些破烂玩意 能赚钱就行学那么多找死么 只要我们把计划实施完成 这些烂人拿我们一点办法没有"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#目前全部的内容-不知道需不需要学-看看下学期转专业成功了没",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#目前全部的内容-不知道需不需要学-看看下学期转专业成功了没",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "目前全部的内容 不知道需不需要学 看看下学期转专业成功了没",
    "text": "目前全部的内容 不知道需不需要学 看看下学期转专业成功了没\nB0300311S 高级语言程序设计A 3.0 必修 45 B0400032S 数字电路与逻辑设计B 3.0 必修 旷考 B0600311S 大学物理(上) 4.0 必修 37 B0600411S 制图基础及计算机绘图 2.0 必修 40 B0900241C 形势与政策 IV 0.0 必修 旷考 B0900241C 形势与政策 IV 0.0 必修 旷考 B1900011C 金工实习 1.0 必修 旷考 B0400101S 模拟电子线路B 4.0 必修 24 B0600321S 大学物理(下) 3.0 必修 23 B0601341S 高等数学A（Ⅰ）下 6.0 必修 34 B0900013S 思想道德修养与法律基础 2.0 必修 旷考 B2000021C 计算机应用基础能力考核 0.0 必修 旷考 B0364071C 程序设计(上机) 2 必修 不及格 B0800042S 大学英语Ⅳ 3.0 必修 56 B0400032S 数字电路与逻辑设计B 3.0 必修 30 B0403032S 应用光学(双语) 2.5 必修 旷考 B0403171S 光电信息物理基础 3.5 必修 29 B0601331S 高等数学A（Ⅰ）上 6.0 必修 43 B0800042S 大学英语Ⅳ 3.0 限选 旷考 B1100081S 电工电子基础实验A 4.0 必修 旷考 B1100081S 电工电子基础实验A 4.0 必修 旷考 B0800032S 大学英语Ⅲ 3.0 必修 旷考 B0403171S 光电信息物理基础 3.5 必修 旷考 B0900034S 中国近现代史纲要 3.0 必修 52 B0462021C 认识实习 0.5 必修 旷考 B0600381S 物理实验（下） 1.5 必修 旷考 B0900231C 形势与政策 III 0.0 必修 旷考 B0200032S 信号与系统B 3.0 必修 34 B0400012S 电路分析基础B 3.0 必修 旷考 B0402221S 电磁场理论与光波导技术 3.0 必修 27 B0600031S 线性代数与解析几何 3 必修 43 B0600071S 概率统计和随机过程 4.0 必修 32 B0600121S 高等数学A（上） 5.0 必修 36 B0600371S 物理实验（上） 1.5 必修 27 B0962051C 思修实践 1.0 必修 旷考 B1163011C 电装实习 1.0 必修 旷考 ⏎"
  },
  {
    "objectID": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#已经复习了的-不知道能不能过",
    "href": "posts/e6d96a2b-5d31-4398-a6e2-576c23121c72/index.html#已经复习了的-不知道能不能过",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "已经复习了的 不知道能不能过",
    "text": "已经复习了的 不知道能不能过\n高级语言程序设计A B0300311S 数字电路与逻辑设计B B0400032S 程序设计(上机) B0364071C 大学英语Ⅳ B0800042S 大学英语Ⅲ B0800032S"
  },
  {
    "objectID": "posts/38df801b-f514-40fc-a5ed-4b658918780a/index.html",
    "href": "posts/38df801b-f514-40fc-a5ed-4b658918780a/index.html",
    "title": "国信iquant平台分析",
    "section": "",
    "text": "国信iquant平台分析\niquant基于迅投qmt平台开发 不支持极简模式 即使是极简模式也需要识别输入验证码 在Windows平台上运行 支持python36-38\nxtquant github repo\n国金qmt下载地址 官网貌似找不到了所以放这里 安装文档 开户\n量化交易笔记\n最新国内外量化平台汇总 包含数据来源 支持实盘的券商\nqmt mini使用\n国盛证券qmt mini模式 xtquant qmt客户端下载\n迅投qmt微信专栏合集"
  },
  {
    "objectID": "posts/2604ce55-fe3f-49b2-b9e4-28722b5e0726/index.html",
    "href": "posts/2604ce55-fe3f-49b2-b9e4-28722b5e0726/index.html",
    "title": "哔哩哔哩 接口 Bilibili APIs",
    "section": "",
    "text": "哔哩哔哩 接口 Bilibili APIs\nbilibili上传工具 biliup\nbilibili toolkit\napi合集 https://www.bilibili.com/read/cv3430609/\n官方接口文档 https://github.com/fython/BilibiliAPIDocs\n直播api https://github.com/lovelyyoshino/Bilibili-Live-API\n野生api收集 https://github.com/SocialSisterYi/bilibili-API-collect\npython api https://github.com/MoyuScript/bilibili-api https://github.com/Nemo2011/bilibili-api https://github.com/Vespa314/bilibili-api\n提交视频剧情树"
  },
  {
    "objectID": "posts/d459fc29-d580-4cfa-864b-5adfc7b260c2/index.html",
    "href": "posts/d459fc29-d580-4cfa-864b-5adfc7b260c2/index.html",
    "title": "动漫剪辑过审",
    "section": "",
    "text": "动漫剪辑过审\n剪的时候不要超过4分钟 可以用spleeter切出语音 加入自己的背景音乐\n这个属于anti nsfw anti censorship 反内容审查 反视频审查 对抗机制 可以在github上面搜索\n二创某种意义也是反审查\n审查的 nsfw 微信小程序 可以解包 然后调用别人的接口 可能不稳定 https://github.com/superdashu/frida_with_wechat_applet https://github.com/superdashu/pc_wxapkg_decrypt_python"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#run-python-in-browser",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#run-python-in-browser",
    "title": "关于做直播 about live streaming",
    "section": "run python in browser",
    "text": "run python in browser\npyodide\npyscript\nskulpt"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#pass-parameter-via-url",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#pass-parameter-via-url",
    "title": "关于做直播 about live streaming",
    "section": "pass parameter via url",
    "text": "pass parameter via url\nget url anchor text\nyou can still use query string when visiting github.io\nfunction getQueryStringValues(key) {\n    var arrParamValues = [];\n    var url = window.location.href.slice(window.location.href.indexOf('?') + 1).split('&');\n \n    for (var i = 0; i &lt; url.length; i++) {\n        var arrParamInfo = url[i].split('=');\n \n        if (arrParamInfo[0] == key || arrParamInfo[0] == key+'[]') {\n            arrParamValues.push(decodeURIComponent(arrParamInfo[1]));\n        }\n    }\n \n    return (arrParamValues.length &gt; 0 ? (arrParamValues.length == 1 ? arrParamValues[0] : arrParamValues) : null);\n}"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#保存粉丝cookie-避免接入xpay之后反复输入地址",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#保存粉丝cookie-避免接入xpay之后反复输入地址",
    "title": "关于做直播 about live streaming",
    "section": "保存粉丝cookie 避免接入xpay之后反复输入地址",
    "text": "保存粉丝cookie 避免接入xpay之后反复输入地址\nset and get a cookie with javascript"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#付钱兑换礼物",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#付钱兑换礼物",
    "title": "关于做直播 about live streaming",
    "section": "付钱兑换礼物",
    "text": "付钱兑换礼物\n要能够有效识别付钱的对象 用浏览器的cookie 送达目标地址\n过滤人名\n过滤群聊里面的广告内容 色情 暴恐 声音不对劲要去掉 合适的BGM\n直播上传带宽要保证 延迟要低\n“聚合直播”\n做直播最重要的就是互动性\n你可以直播群友聊天的画面 要去掉含有个人隐私的头像或照片 信息 QQ Email 要过滤掉nsfw的内容 操作qq机器人来和群友说话 或者让送礼物最多的人获得发言权 排行榜最上面的人获得发言权 群聊也不一定要单一 多个群一起弄 甚至多个社交软件一起弄 群聊私聊一起用\n你也可以参考其他的主播 看看他们是怎么做的\n可以通过分析评论 切换直播主题 切换直播画面"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#免签支付-获取订单号-给粉丝发福利-vip",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#免签支付-获取订单号-给粉丝发福利-vip",
    "title": "关于做直播 about live streaming",
    "section": "免签支付 获取订单号 给粉丝发福利 VIP",
    "text": "免签支付 获取订单号 给粉丝发福利 VIP\nb站充电API\nhttps://www.yunmianqian.com https://github.com/assimon/easymqpay https://github.com/szvone/vmqphp https://github.com/wxs2/xposed-pay\nhttps://github.com/szvone/vmqApk\nvmqapk 最新修改版\nxpay 这个东西需要人工监听 跪了"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-8",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-8",
    "title": "关于做直播 about live streaming",
    "section": "随想 8",
    "text": "随想 8\n视频广告\nYukio 21:46:07 应该来个淡入淡出之类的\nYukio 21:46:25 还有一个试看结束的提示\nYukio 21:46:37 试看开始之前的提示\n播放视频内容也要有提示 开头和结尾要给人知道这个截取的片段是干什么的"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-7",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-7",
    "title": "关于做直播 about live streaming",
    "section": "随想 7",
    "text": "随想 7\nYukio 01:56:43 付了款 留下联系方式 给你发福利\nYukio 01:57:16 但是万一有些人滥用呢\nYukio 01:57:36 发一些奇奇怪怪的联系方式或者邮箱\nYukio 01:57:55 给我发些什么监察委员会的邮箱\nYukio 01:58:32 我可以增加一个取消订阅按钮 让这些人取消订阅 别找我麻烦\nYukio 02:01:28 或者我把文件上传到一次性的文件分享页面\nYukio 02:01:38 过几个小时自动取消分享"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-6",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-6",
    "title": "关于做直播 about live streaming",
    "section": "随想 6",
    "text": "随想 6\nYukio 01:06:16 这个我直播间可以根据uid和活跃等级\nYukio 01:06:24 持久化你的活跃度\nYukio 01:06:34 充钱也可以升级\nYukio 01:06:44 送我礼物\nYukio 01:07:21 如果是直接wx转钱给我 这个估计得给我发交易单号 私信发我才能兑换呢\nYukio 01:07:31 至于怎么找这个交易单号\nYukio 01:07:34 emm\nYukio 01:08:36 我想想\nYukio 01:09:28 这个估计得对接第四方交易接口 或者我看看现成的实现\nYukio 01:10:32 同时 给我的视频留言 发弹幕也可以刷活跃度\nYukio 01:10:42 刷直播间给你显示的活跃度\nYukio 01:12:39 如果给我充钱 我会发你涩图 冲的多发的多\nYukio 01:12:50 至于怎么发\nYukio 01:12:59 发你邮箱 你留下邮箱地址我发你\nYukio 01:15:57 不需要涩图也可以个性化定制\nYukio 01:16:19 如果给我充钱 一段时间内不会有给我打钱的二维码\nYukio 01:16:40 不给我充 不给我私信 我就一直发给我打钱的二维码\nYukio 01:17:37 如果给我充钱 可以绑定相关QQ账号 邮箱账号 或者什么其他的社交账号 每个平台只能绑一个账号\nYukio 01:18:14 绑了之后 给钱 一段时间我的内容没有打钱二维码 私信的话\n你主动加我为好友才行"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-5",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-5",
    "title": "关于做直播 about live streaming",
    "section": "随想 5",
    "text": "随想 5\nYukio 23:05:52 为了检测这种二维码\nYukio 23:06:30 同时有一些不是很好检测的文字 水印\nYukio 23:06:44 也需要image local contrast enhancement\nYukio 23:25:11 随机切割句子 分批发送\nYukio 23:25:16 这样我的机器人更像人\nimage enhancement for optical character recognition\nimage enhancement for watermark removal"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-4",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-4",
    "title": "关于做直播 about live streaming",
    "section": "随想 4",
    "text": "随想 4\nYukio 21:00:32 nsfw没必要每一帧都加\nYukio 21:00:38 可以跳着加\nYukio 21:00:52 然后把出问题的帧的周围全部ban掉\nYukio 21:01:07 但是除了画面\nYukio 21:01:16 声音娇喘的也得去掉\nYukio 21:01:24 这个娇喘\nYukio 21:01:41 用个声音分类器\nYukio 21:01:51 用狗叫分类器改一下就好了\nYukio 21:02:12 除了娇喘\nYukio 21:02:20 还得弄语音识别\nYukio 21:02:35 防止某些狗叫言论污染直播间"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-3",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-3",
    "title": "关于做直播 about live streaming",
    "section": "随想 3",
    "text": "随想 3\n直播的通知 当直播的主题变化的时候 把广告发到不同的群 不同的观众那里"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-2",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-2",
    "title": "关于做直播 about live streaming",
    "section": "随想 2",
    "text": "随想 2\n不和谐的 包括有链接的内容 有二维码的内容 有联系方式的内容 加标点符号的广告内容 重复发送的内容\nYukio 14:26:10 可以看到其实判别不和谐言论很难\nYukio 14:26:23 所以可以用谐音字 拼音判断\nYukio 14:26:51 加上不信任期 一旦出现不和谐言论 一段时间内不用这个群聊\nYukio 14:27:15 以及繁体字转简体字"
  },
  {
    "objectID": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-1",
    "href": "posts/4fc62d43-192d-481f-be8a-e1bca3599566/index.html#随想-1",
    "title": "关于做直播 about live streaming",
    "section": "随想 1",
    "text": "随想 1\nYukio 22:29:44 我直播群友聊天咋样？\nYukio 22:30:07 我直播群友聊天 然后给我留言的人 有机会把消息发到群里面来\nYukio 22:30:30 其中送礼物送的最多的发消息发进来的概率最大\nYukio 22:31:49 不仅如此 我还多个群聚合聊天 多社交软件 多语言聚合聊天\nYukio 22:32:06 我还可以自由切换话题 自动翻译\nYukio 22:32:36 也就是说如果你和外国人聊天 你说中文变英文\nYukio 22:32:46 别人说英文变中文\n黑暗骑士 22:33:20 直播看你装奈子\nYukio 22:33:33 nsfw不能直播\nYukio 22:33:45 直播最重要的是互动啊\nYukio 22:33:51 播其他的也行\nYukio 22:34:06 但是装柰子 也得sfw\nYukio 22:34:19 所以有可能需要打码\nYukio 22:34:29 检测出来nsfw区域 自动打码\nYukio 22:34:36 或者全屏打码\nYukio 22:35:07 你说什么 我可以给你在线搜索视频给你看\nYukio 22:35:49 你不说话的时候我就挑热门视频和热门直播转发\nYukio 22:36:15 根据进来的观众们的历史观看记录和历史发言来播视频\nYukio 22:42:38 这个换台的话 本人三分钟可以撤销两次\nYukio 22:43:09 而其他人在本人获得换台权利之后 三分钟之后才能继续排队\nYukio 22:43:23 早就不招了\nYukio 22:44:29 你建的话 我有过滤器啊\nYukio 22:44:32 你可以建\nYukio 22:44:57 但是要是有关键字 我这边不会播你的\nYukio 22:45:08 而且头像和昵称\nYukio 22:45:13 不会有\nYukio 22:46:05 如果sfw\nYukio 22:46:14 那么就是不够涩\nYukio 22:46:18 也不会有问题\nYukio 22:46:40 再说了\nYukio 22:46:51 让别人跟你聊天不是好事么\nYukio 22:47:16 取决于涩涩的程度"
  },
  {
    "objectID": "posts/75fe4eaf-7c44-4e4f-ab9e-944430e88198/index.html",
    "href": "posts/75fe4eaf-7c44-4e4f-ab9e-944430e88198/index.html",
    "title": "关于人类发展规律和需求的随想",
    "section": "",
    "text": "关于人类发展规律和需求的随想\n人需要获得海量信息然后才能在某些领域取得成就 这个相互关系有强相关和弱相关的范畴"
  },
  {
    "objectID": "posts/7038aaed-57c2-4439-b45f-a113f7fc3f4c/index.html#收集别人的帐号然后登录",
    "href": "posts/7038aaed-57c2-4439-b45f-a113f7fc3f4c/index.html#收集别人的帐号然后登录",
    "title": "免流帮 停机卡上网 持续上网",
    "section": "收集别人的帐号然后登录",
    "text": "收集别人的帐号然后登录\nkali负责收集网络帐号 然后在一个web页面上面提供一个加密的auth接口 最好是rsa加密的东西 有时间延迟防暴力破解的访问接口 通过验证之后可以获得用户名密码 同时可以访问相应接口进行占用或者解除占用 当然你也可以直接弄个静态的页面谁也破解不了 但是访问的时候就得一个一个的尝试 当然也更安全"
  },
  {
    "objectID": "posts/7038aaed-57c2-4439-b45f-a113f7fc3f4c/index.html#免流卡",
    "href": "posts/7038aaed-57c2-4439-b45f-a113f7fc3f4c/index.html#免流卡",
    "title": "免流帮 停机卡上网 持续上网",
    "section": "免流卡",
    "text": "免流卡\n微信小程序 免流帮\nqq群：857969390\n搜索github\n校园网也可以免认证登录"
  },
  {
    "objectID": "posts/2b76c963-f467-46a6-9b8a-d8b838e5db9e/index.html",
    "href": "posts/2b76c963-f467-46a6-9b8a-d8b838e5db9e/index.html",
    "title": "传播学 2",
    "section": "",
    "text": "传播学 2"
  },
  {
    "objectID": "posts/48a5dc12-cb49-4978-a5e5-bb5768db660a/index.html#tools",
    "href": "posts/48a5dc12-cb49-4978-a5e5-bb5768db660a/index.html#tools",
    "title": "临时存储文件 temp fiiles host api",
    "section": "tools",
    "text": "tools\npyupload\ncatmoe recommend tools\nuguu tools"
  },
  {
    "objectID": "posts/48a5dc12-cb49-4978-a5e5-bb5768db660a/index.html#支持api存储",
    "href": "posts/48a5dc12-cb49-4978-a5e5-bb5768db660a/index.html#支持api存储",
    "title": "临时存储文件 temp fiiles host api",
    "section": "支持api存储",
    "text": "支持api存储\nanonyfiles api need login\nlist of pomf based temp file hosts\nuguu api\ncatbox.moe api referred as sharex format\ntmpfiles api\ntransfer.sh\ngofile.io\nnopaste.net with curl and netcat endpoint"
  },
  {
    "objectID": "posts/48a5dc12-cb49-4978-a5e5-bb5768db660a/index.html#不支持api-需要探索",
    "href": "posts/48a5dc12-cb49-4978-a5e5-bb5768db660a/index.html#不支持api-需要探索",
    "title": "临时存储文件 temp fiiles host api",
    "section": "不支持api 需要探索",
    "text": "不支持api 需要探索\nprivfile with download limit\nhelix\ntempd.link"
  },
  {
    "objectID": "posts/988ac751-1b16-4627-b5f1-e8691cfe22ff/index.html",
    "href": "posts/988ac751-1b16-4627-b5f1-e8691cfe22ff/index.html",
    "title": "一堆电子书 可能适合作为pdf搜索的起点",
    "section": "",
    "text": "一堆电子书 可能适合作为pdf搜索的起点\n把电子书变成wiki 方便批注 网友协作\npylucene\njina cloud host jina search instances for free, currently\nuse apache tika for document parsing\nxapian supported document formats\nsearch for document search on github\n实验性搜索数据地址： /Users/jamesbrown/desktop/works/course_video_convert/sample/documentsAndFiles\n纸质书阅读效率极低 利用效率极低 不可以修改 不可以复制 不可以随时查看搜索 属于一种古老的信息储存和交换形式\n如果在纸质书上面写内容 意味着你只是把纸当作记忆的工具 不可能发挥“电脑”的功能\nhttps://github.com/James4Ever0/Book\n下面这些都有向同一个地方引流的行为 https://github.com/lTbgykio/Books-Free-Books https://github.com/Dujltqzv/Some-Many-Books\n书籍互助脚本 https://greasyfork.org/zh-CN/scripts/420751-%E5%9B%BE%E4%B9%A6%E4%BA%92%E5%8A%A9 https://greasyfork.org/zh-CN/scripts/432075-%E7%A7%80%E8%AF%BB%E5%9B%BE%E4%B9%A6%E4%BA%92%E5%8A%A9"
  },
  {
    "objectID": "posts/50d188f3-70b3-4077-ba23-95a2d33d6df8/index.html",
    "href": "posts/50d188f3-70b3-4077-ba23-95a2d33d6df8/index.html",
    "title": "yaml special token cause error to pyyaml",
    "section": "",
    "text": "yaml special token cause error to pyyaml\nspecial token like !&lt;str&gt; need to be converted to !!str, while writing back we just do it in reverse.\nfull reference of pyyaml is here"
  },
  {
    "objectID": "posts/a278ca5b-51bc-4af5-817c-87c97db8e1fd/index.html",
    "href": "posts/a278ca5b-51bc-4af5-817c-87c97db8e1fd/index.html",
    "title": "Time Machine Alternative for linux/windows",
    "section": "",
    "text": "Time Machine Alternative for linux/windows\nuse test to check existance some manual created identity file to prove if the endpoint is connected\n(really? does that check work for offline rclone samba drives?)\n\nformat the backup disk as xfs so we can do symlink on it (linux).\n\nuse flock (from util-linux) to prevent multiple backup instances from running.\nalternative: run-one\nsudo apt-add-repository ppa:run-one/ppa\nsudo apt-get update\nsudo apt-get install run-one\n\nlinux-timemachine supports windows, linux, macOS, using rsync as backend, can use hardlink to make backup management very easy. can delete previous backup without losing data. need external controller to make “circular” or to only keep most recent backups on disk.\ncurated list of alternative time machine for OSes other than macOS\ntimeshift gui backup/restore tool for linux\nduplicity incremental backup can store backup into encrypted tar files and support IMAP protocol as remote file server"
  },
  {
    "objectID": "posts/b85e653b-c51b-45bf-9140-da318cc25361/index.html",
    "href": "posts/b85e653b-c51b-45bf-9140-da318cc25361/index.html",
    "title": "what is causing my mac to freeze when kali is offline",
    "section": "",
    "text": "what is causing my mac to freeze when kali is offline\nmodified scripts:\n/Users/jamesbrown/Desktop/works/host_discovery_ssh_local_connect/load_tuntap_launch_n2n_kali_root.sh\n/Users/jamesbrown/Desktop/works/host_discovery_ssh_local_connect/nginx_with_kali_finder.sh\n/Library/Application Support/ZeroTier/One/launch.sh\nseems zerotier one is the main cause!"
  },
  {
    "objectID": "posts/96e4276f-2bba-4292-b740-4e1142b1c269/index.html",
    "href": "posts/96e4276f-2bba-4292-b740-4e1142b1c269/index.html",
    "title": "web scraping logic",
    "section": "",
    "text": "web scraping logic\nselect targets for scraping. it could be your browsing history, package indexs, social media (dynamic contents, with different accessing methods than web scraping)\nif not accessible, access it with proxies, cookies.\nfinally store the content into compat and usable formats, categorized and linked"
  },
  {
    "objectID": "posts/d4d0f900-e3e0-411d-be40-8a58f6a50273/index.html",
    "href": "posts/d4d0f900-e3e0-411d-be40-8a58f6a50273/index.html",
    "title": "vxworks binary reverse engineering",
    "section": "",
    "text": "vxworks binary reverse engineering\nvxpwn vxworks exploit scripts\nrun vxworks in vmware maybe in qemu?\nusing serial port to reverse engineering a router\nvxhunter toolsets for vxworks based embedded device analysis\nschneider noe7701 backdoors and similar process\ncapstone related reverse engineering tools\nfull list of tools (showcase) using capstone as backend"
  },
  {
    "objectID": "posts/1737f877-6daf-4824-a849-a25c91f1b291/index.html#vim",
    "href": "posts/1737f877-6daf-4824-a849-a25c91f1b291/index.html#vim",
    "title": "vim session restore",
    "section": "vim",
    "text": "vim\nvim session manager\nmethods to automate :mksession\nvim workspace auto save workspace and undo history\nbuiltin :mksession and more"
  },
  {
    "objectID": "posts/1737f877-6daf-4824-a849-a25c91f1b291/index.html#nvim",
    "href": "posts/1737f877-6daf-4824-a849-a25c91f1b291/index.html#nvim",
    "title": "vim session restore",
    "section": "nvim",
    "text": "nvim\nsession manager usage for vim and nvim\nsession manager for vim and nvim\nnvim auto-session"
  },
  {
    "objectID": "posts/cf3c0e99-d1d0-43d5-8926-e0269cf2b71d/index.html",
    "href": "posts/cf3c0e99-d1d0-43d5-8926-e0269cf2b71d/index.html",
    "title": "video picture in picture detection",
    "section": "",
    "text": "video picture in picture detection\n视频画中画是流行的伪原创方法 但是检测很难 同时加大了二次利用的难度（或许可以再加一层画中画？？） 目前找到了一个国内画中画检测专利，以及国外画中画检测论文"
  },
  {
    "objectID": "posts/4294d156-986c-4483-a3d2-5036f6ea68f2/index.html",
    "href": "posts/4294d156-986c-4483-a3d2-5036f6ea68f2/index.html",
    "title": "vapoursynth 光流算法 补帧 画面优化 denoising",
    "section": "",
    "text": "vapoursynth 光流算法 补帧 画面优化 denoising\nnazobase NAZOrip basement, with cython dll docs\nDBmbk a debanding toolkit, for easier bezier curve generation\nffmpeg super resolution filter could get faster if run on gpu with libtensorflow\nVESPCN: real-time super resolution\nmpv is a media player with VapourSynth built-in, and that’s probably how vapoursynth gets in my mac via brew dependency manager\nview.py is Python module for vapoursynth scripts that previews clips\nto use opencv functions with vapoursynth\nsvp is free on linux, offering plugin for vlc while vlc cannot be run as root\nyou might harvest some prebuilt binaries of vapoursynth plugins for linux\n补帧算法可适用于我们的动态水印追踪系统 但是可能需要优化 才能做到比较快速的补帧 因为水印所在位置的区间实际上只是白色的 不需要过于复杂的网络 同时这种补出来的水印需要逐帧处理 或者两帧一处理 生成的区间数量会非常的多\nit is much easier to do this on windows since we need quick evaluation. might run this on virtualbox?\nbuild scripts on how to build plugins for macos, including how to configure the installation prefix.\nbrew compatible, macos compatible vapoursynth plugin build script provider: homebrew-vsplugins does not provide build scripts for all plugins avaliable for windows, and it requires additional linking\ntutorial on how to configure it: (is it intel only?)\nAlternative VapourSynth Install Method (Brew): IMPORTANT: Brew users will need to create and set the autoload folder prior to installing VapourSynth! Simply run the following commands: Code:\nmkdir -p /usr/local/lib/vapoursynth\nmkdir -p \"$HOME/Library/Application Support/VapourSynth\"\ntouch \"$HOME/Library/Application Support/VapourSynth/vapoursynth.conf\"\necho UserPluginDir=/usr/local/lib/vapoursynth &gt;&gt; \"$HOME/Library/Application Support/VapourSynth/vapoursynth.conf\"\necho SystemPluginDir=/usr/local/lib/vapoursynth &gt;&gt; \"$HOME/Library/Application Support/VapourSynth/vapoursynth.conf\"\n(Optional) Create desktop shortcuts for the plugins and scripts folders. Run the following commands in terminal: Code:\nmkdir $HOME/Desktop/VapourSynth\nln -s /usr/local/lib/vapoursynth $HOME/Desktop/VapourSynth/Plugins\nln -s /usr/local/lib/python3.9/site-packages $HOME/Desktop/VapourSynth/Scripts\nUse brew command: Code:\nbrew install vapoursynth\nbm3d denoising using cuda\nfft3d denoising\npython opencv 光流算法详解 分为sparse和dense两种 某种程度上都可以计算场景的变换激烈程度\nframe interpolation using deep optical flow\nopenmmlab mmflow\ngoogle research: FILM (frame interpolation for large motion)\nvapoursynth get started (official doc)\nvapoursynth plugin database only provide prebuilt binaries for windows while the plugin source code might work with linux and macos (if it has the source code)\nVSRepo plugin manager installing vapoursynth plugin via commandline tool and vsrepo is only supported on windows, for other platforms we need to compile plugins manually.\nnazorip vapoursynth blogs\nnazorip bezier curve\nnazorip gamma curve and convolution\nflowpy: tool for visualizing and processing image with optical flow"
  },
  {
    "objectID": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#creating-lists",
    "href": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#creating-lists",
    "title": "useful java patterns",
    "section": "creating lists",
    "text": "creating lists\nvar a = new ArrayList&lt;&gt;(Arrays.asList(1,2,3));\nvar mset = new HashSet&lt;&gt;();\nmset.addAll(a);\nvar mset2 = a.stream().collect(Collectors.toSet());\nvar mymin = Collections.min(a);\nvar mymax = Collections.max(a);\nCollections.reverse(a);\nvar a = arrayOf(1,2,3);\nprint(a.contentToString())\nprint(a.max())\nprint(a.min())\na.reverse()"
  },
  {
    "objectID": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#creating-hashmap",
    "href": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#creating-hashmap",
    "title": "useful java patterns",
    "section": "creating hashmap",
    "text": "creating hashmap\nvar ah= new HashMap&lt;&gt;();\nah.put(1,2);\nvar ah = hashMapOf(1 to 2, 2 to 3)"
  },
  {
    "objectID": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#iterate-lists-with-indices",
    "href": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#iterate-lists-with-indices",
    "title": "useful java patterns",
    "section": "iterate lists with indices",
    "text": "iterate lists with indices\njava double colon :: operator acts as anonymous function\nvar l = a.listIterator();\nwhile (l.hasNext()){\n  var index = l.nextIndex();\n  var val = l.next();\n  System.out.println(\"INDEX: \"+index+\" ELEM: \"+val);\n}\n\nIntStream.range(0,a.size()).forEach(index -&gt; a.get(index));\n\nvar index=0;\nfor (int i: a){\n  index++;\n}\n\na.forEachIndexed{ind, elem -&gt; println(\"index? $ind\"); println(\"elem? $elem\")}\n\nfor (var i in a.indices){\n  var elem = a[i]\n}\n\na.indices.forEach {\n  var elem = a[it]\n  elem\n}"
  },
  {
    "objectID": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#list-comprehension",
    "href": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#list-comprehension",
    "title": "useful java patterns",
    "section": "list comprehension",
    "text": "list comprehension\nvar mlist = a.stream().map(x-&gt; x*2).collect(Collectors.toList());\nvar evenNums = a.stream().filter(x-&gt; x%2 == 0).collect(Collectors.toList());\nvar mmap = a.stream().collect(Collectors.toMap(x-&gt;x.getId(),x-&gt;x.getName()));"
  },
  {
    "objectID": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#switch-expressions",
    "href": "posts/83eb3d3b-64e9-4979-95ab-a749f1f6df7d/index.html#switch-expressions",
    "title": "useful java patterns",
    "section": "switch expressions",
    "text": "switch expressions\nvar val = 2;\nvar mswitch = switch (val){\n  case 1,2,3 -&gt; {\n    yield \"good\";\n  }\n  case 4,5,6 -&gt; {\n    yield \"bad\";\n  } // either throw or yield.\n  default -&gt; {\n    System.out.println(\"out of expectation\");\n    yield \"really bad\";\n  }\n};\nSystem.out.println(mswitch);\nvar grade = 30\nvar res =  when(grade) {\n        in 0..40 -&gt; \"Fail\"\n        in 41..70 -&gt; \"Pass\"\n        in 71..100 -&gt; \"Distinction\"\n        else -&gt; false\n    }\nprint(res)\n\nvar mcase = 1\nvar res = when(mcase){\n  1 -&gt; \"good\"\n  2 -&gt; \"bad\"\n  else -&gt; \"really bad\"\n}\nprint(res)\n\ncount occurance of elements in array\nString[] array = {\"name1\",\"name2\",\"name3\",\"name4\", \"name5\", \"name2\"};\nArrays.stream(array)\n      .collect(Collectors.groupingBy(s -&gt; s))\n      .forEach((k, v) -&gt; System.out.println(k+\" \"+v.size()));\n\nList asList = Arrays.asList(array);\nSet&lt;String&gt; mySet = new HashSet&lt;String&gt;(asList);\n\nfor(String s: mySet){\n System.out.println(s + \" \" + Collections.frequency(asList,s));\n}\n\nMap&lt;String, Long&gt; map = Arrays.stream(array)\n    .collect(Collectors.groupingBy(s -&gt; s, Collectors.counting()));\nvar a = arrayOf(1,2,3,3,3,3)\n\na.toSet().forEach{it -&gt; println(\"elem? $it\"); println(\"count? \"+a.count{it2-&gt;it2 == it})}\n\n\nlambdas\nConsumer mcons = (n) -&gt; {System.out.println(n);}\nmcons.andThen(mcons).accept(\"mval\");\nFunction &lt;Integer,Integer&gt; mfunc = n-&gt; n+1;\nSupplier msup = () -&gt; 1;\nvar mval = msup.get();\nvar mfunc = {n :Int -&gt; n+1}\nvar mprint = {n:Any -&gt; print(n)}"
  },
  {
    "objectID": "posts/9ab05071-42a8-420b-b180-b76a3b821f88/index.html",
    "href": "posts/9ab05071-42a8-420b-b180-b76a3b821f88/index.html",
    "title": "unmount disks forcefully",
    "section": "",
    "text": "unmount disks forcefully\ntutorial\nbasically killing process using it, lazy unmount, force unmount on NFS and so on."
  },
  {
    "objectID": "posts/f7255fb1-aae0-4fba-a33f-7acbd6237677/index.html",
    "href": "posts/f7255fb1-aae0-4fba-a33f-7acbd6237677/index.html",
    "title": "typing backtick “`” with my current splitable keyboard",
    "section": "",
    "text": "typing backtick “`” with my current splitable keyboard\nit used to work with meta+esc key, but it fails sometimes.\nthere’s a universal way: shift+alt+esc\ntype tlide “~”: shift+esc"
  },
  {
    "objectID": "posts/ed5c43a0-a80b-4ed9-b485-f6d58e650212/index.html",
    "href": "posts/ed5c43a0-a80b-4ed9-b485-f6d58e650212/index.html",
    "title": "turing-project and his works on AI and NLP",
    "section": "",
    "text": "turing-project and his works on AI and NLP\nhe recently interacts with racketeers on wechat, find how to add new friends (and groups if any) on wechat.\nthe bilibili user and his repo\nvideo transfer based on DCT-Net 视频洗稿 伪原创\nAntiFraudChatBot is a wechaty bot using a super large model based on megatron called Yuan 1.0 which is only freely avaliable within three month (30k api calls) when applied to chat with racketeers, another application: AI剧本杀\nmegatron deepspeed enables training large model on cheap hardware\nessaykillerbrain is another project he has involved in, which contains EssayKiller_V2 EssayKiller_V1 EssayTopicPredict WrittenBrainBase\nalphafold in mindspore"
  },
  {
    "objectID": "posts/a993385f-2443-4730-a8b1-56dac3441b5d/index.html",
    "href": "posts/a993385f-2443-4730-a8b1-56dac3441b5d/index.html",
    "title": "trainable bezier curve multiparameter regressor",
    "section": "",
    "text": "trainable bezier curve multiparameter regressor\nbezier\nfirst, we need a bezier curve connects (0,0) and (1,1)\nimport numpy as np\nimport bezier\n\ndef bezierCurve(start=(0,0), end=(1,1), skew=0):\n  # skew: (-0.5,0.5) otherwise this shit will look ugly.\n  assert skew &gt;=-0.5\n  assert skew &lt;=0.5\n  x_start, y_start = start\n  x_end, y_end = end\n  x_diff = x_end - x_start\n  y_diff = y_end - y_start\n  nodes1 = np.asfortranarray(\n      [\n          [x_start, x_diff * (0.5 + skew), x_end],\n          [y_start, y_diff * (0.5 - skew), y_end],\n      ]\n  )\n  curve1 = bezier.Curve(nodes1, degree=2)\n  curve_params = {'x_start':x_start, 'x_diff':x_diff,'x_end':x_end}\n  return curve1, curve_params\n\ndef evaluateBezierCurve(input_value:float,curve, curve_params:dict)\n  x_start = curve_params['x_start']\n  x_end = curve_params['x_end']\n  assert x_start &lt;= input_value\n  assert x_end &gt;= input_value\n  x_diff = curve_params['x_diff']\n  s = (input_value - x_start)/x_diff\n  points = curve.evaluate(s)\n  # we only get the single point.\n  point = points.T[0]\n  x,y = point\n  result = y\n  return result\nthen, we define our very recursive or flexible regressor:\ndef multiParameterExponentialNetwork(*args, input_bias=0.05, curve_function=bezierCurve, curve_function_kwargs = {'start':(0,0),'end':(1,1)'skew':0}, evaluate_function=evaluateBezierCurve):\n  curve, curve_params = curve_function(**curve_function_kwargs)\n  value = evaluate_function(input_bias, curve, curve_params)\n  for index, input_value in enumerate(args):\n    apply_list = [input_value]*(index+1)\n    for apply_item in apply_list:\n      value += (1-value)*function(apply_item, **function_kwargs)\n  return value"
  },
  {
    "objectID": "posts/7b39739b-0ff8-49a2-ad27-b0fe235c4e1f/index.html#general-torrent-searching",
    "href": "posts/7b39739b-0ff8-49a2-ad27-b0fe235c4e1f/index.html#general-torrent-searching",
    "title": "torrent search engines",
    "section": "general torrent searching",
    "text": "general torrent searching\ntorrenthunt is a telegram bot which can search several torrent search engines. you can use it directly\ntorrent search api: a multi torrent search api in nodejs\nnotflix search for magnet links on 1337x and stream/play it with peerflix"
  },
  {
    "objectID": "posts/7b39739b-0ff8-49a2-ad27-b0fe235c4e1f/index.html#anime-torrent-searching",
    "href": "posts/7b39739b-0ff8-49a2-ad27-b0fe235c4e1f/index.html#anime-torrent-searching",
    "title": "torrent search engines",
    "section": "anime torrent searching",
    "text": "anime torrent searching\nNyaa which supports sorting\nBangume.moe\n动漫花园 可以订阅单个页面rss 但是不会全局排序"
  },
  {
    "objectID": "posts/96dd319c-d1bd-44e1-9622-14006033fa9b/index.html",
    "href": "posts/96dd319c-d1bd-44e1-9622-14006033fa9b/index.html",
    "title": "themida unpacker",
    "section": "",
    "text": "themida unpacker\nstill don’t forgive that damn cacani software (manual), and i still don’t find a clue for creating animation with cacani automatically.\nsearch for “themida unpacker” or “unlicense” in bing or github. saying manually unpacking themida is always a pain in the ass."
  },
  {
    "objectID": "posts/039df135-8cf4-482c-81a9-a0a31a868028/index.html",
    "href": "posts/039df135-8cf4-482c-81a9-a0a31a868028/index.html",
    "title": "the most powerful work environment setup, introduced by us",
    "section": "",
    "text": "the most powerful work environment setup, introduced by us\nin order to make money with this idea, you can do the following:\n\ncreate thinner splitable wireless keyboard\ncreate typing traning software with good interface\nbetter computer stand so you can insert keyboard closer and introduce more ports\nsell things together, introduce many usages to let people see what really matters\nsend ads along with your media, not just fun videos and news"
  },
  {
    "objectID": "posts/08bb97b6-66b0-482c-bbaa-5cec651999d0/index.html",
    "href": "posts/08bb97b6-66b0-482c-bbaa-5cec651999d0/index.html",
    "title": "the formula search engine, latex enabled, textbook search engine",
    "section": "",
    "text": "the formula search engine, latex enabled, textbook search engine\nlatex2sympy convert latex to sympy using antlr\nmathpix has stunning accuracy but is not free. they offer timely licensed docker images.\nim2markup is by far the most accurate one. it is attention based and can be trained on multiple markup languages."
  },
  {
    "objectID": "posts/b3f61b87-01b2-41d9-8e08-57de0a918c4c/index.html",
    "href": "posts/b3f61b87-01b2-41d9-8e08-57de0a918c4c/index.html",
    "title": "text-processing.com, free text mining and natural language processing",
    "section": "",
    "text": "text-processing.com, free text mining and natural language processing\nfunctions:\n\nSentiment Analysis\nStemming\nPart-of-Speech Tagging and Chunking\nPhrase Extraction & Named Entity Recognition\n\neach method is throttled to 1000 calls per day per IP."
  },
  {
    "objectID": "posts/a203d341-178b-4c7b-ae28-9428c25c78d9/index.html",
    "href": "posts/a203d341-178b-4c7b-ae28-9428c25c78d9/index.html",
    "title": "telegram bot: pyrogram",
    "section": "",
    "text": "telegram bot: pyrogram\npyrogram repo\nyou can act both with a user account and a bot account"
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#you-said-lda-and-lsa-are-helpful-for-paraphrasing",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#you-said-lda-and-lsa-are-helpful-for-paraphrasing",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "you said LDA and LSA are helpful for paraphrasing",
    "text": "you said LDA and LSA are helpful for paraphrasing\nYes, LDA and LSA are two methods that can be used to generate paraphrases of a given text. LDA (Latent Dirichlet Allocation) is a probabilistic model that can be used to identify topics in a text and then generate new sentences that express the same topics in a different way. LSA (Latent Semantic Analysis) is a method that uses singular value decomposition to identify the underlying meaning of words in a text and then generate paraphrases by replacing words with their closest semantic equivalents. Both LDA and LSA can be helpful for generating paraphrases, but they each have their own strengths and limitations."
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#can-you-demonstrate-how-to-use-lsa-for-paraphrasing-in-python",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#can-you-demonstrate-how-to-use-lsa-for-paraphrasing-in-python",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "can you demonstrate how to use LSA for paraphrasing in python",
    "text": "can you demonstrate how to use LSA for paraphrasing in python\nI’m sorry, but I am not currently able to browse the internet or access any external resources. As a large language model trained by OpenAI, my knowledge is based solely on the text that I have been trained on, and I don’t have the ability to run code or demonstrate specific examples. However, I can provide a general overview of how LSA could be used for paraphrasing in Python.\nTo use LSA for paraphrasing in Python, you would first need to create a matrix of word vectors for the words in the text you want to paraphrase. This matrix would represent the semantic relationships between the words in the text, and would be used to identify the underlying meaning of each word.\nNext, you would use singular value decomposition (SVD) to decompose the matrix into three matrices, which represent the different factors that contribute to the meaning of the words in the text.\nOnce you have the three matrices, you can then use them to identify the most closely related words for each word in the text, and generate paraphrases by replacing words with their closest semantic equivalents.\nThis is just a brief overview of how LSA could be used for paraphrasing in Python. There are many different ways to implement LSA, and the exact details of the implementation would depend on the specific requirements of your project."
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#continue",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#continue",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "continue",
    "text": "continue\nI’m sorry, but I’m not sure what you would like me to continue with. If you have a specific question or topic you would like to discuss, I would be happy to help. Otherwise, I can provide more information about LSA and how it can be used for paraphrasing if that would be helpful. Let me know what you would like to know."
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#how-to-use-lda-for-paraphrasing",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#how-to-use-lda-for-paraphrasing",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "how to use LDA for paraphrasing",
    "text": "how to use LDA for paraphrasing\nTo use LDA for paraphrasing, you would first need to train a LDA model on a large corpus of text. This would involve using a machine learning algorithm to identify the topics that are present in the corpus, and then generating a set of “topic vectors” that represent the distribution of those topics across the text.\nOnce you have trained the LDA model, you can then use it to generate paraphrases of a given text by identifying the topics present in the text and then replacing words with synonyms or related words that express the same topics in a different way. This process can be repeated multiple times to generate multiple paraphrases of the same text.\nHere is a brief example of how LDA could be used for paraphrasing in Python:\n\nfrom gensim import corpora, models\n\n# Load the text you want to paraphrase\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\n# Tokenize the text and create a dictionary of words\ntokens = text.split(\" \")\ndictionary = corpora.Dictionary([tokens])\n\n# Train a LDA model on the text\nlda_model = models.LdaModel([dictionary.doc2bow(tokens)], num_topics=1)\n\n# Generate paraphrases of the text\nfor i in range(3):\n    paraphrase = lda_model.show_topics(num_topics=1, num_words=len(tokens), formatted=False)\n    print(\" \".join([word[0] for word in paraphrase[0][1]]))\nThis example trains a simple LDA model on a single sentence and then generates three paraphrases of the sentence by replacing words with their closest semantic equivalents. Of course, this is just a simple example to illustrate the basic concept of using LDA for paraphrasing. In practice, you would need to use a much larger corpus of text to train the LDA model and generate more accurate paraphrases."
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#demonstrate-using-lsa-to-paraphrase-in-python-using-gensim-if-needed",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#demonstrate-using-lsa-to-paraphrase-in-python-using-gensim-if-needed",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "demonstrate using LSA to paraphrase in python, using gensim if needed",
    "text": "demonstrate using LSA to paraphrase in python, using gensim if needed\nAs I mentioned earlier, I am not currently able to browse the internet or access external resources, so I cannot demonstrate using LSA to paraphrase in Python using gensim or any other specific libraries. However, I can provide a general overview of how LSA could be used for paraphrasing in Python.\nTo use LSA for paraphrasing in Python, you would first need to create a matrix of word vectors for the words in the text you want to paraphrase. This matrix would represent the semantic relationships between the words in the text, and would be used to identify the underlying meaning of each word.\nOnce you have the matrix of word vectors, you can use singular value decomposition (SVD) to decompose the matrix into three matrices, which represent the different factors that contribute to the meaning of the words in the text. The gensim library includes a implementation of SVD that you can use for this purpose.\nOnce you have the three matrices, you can then use them to identify the most closely related words for each word in the text, and generate paraphrases by replacing words with their closest semantic equivalents. Here is an example of how this could be done in Python:\n\nfrom gensim import corpora, models, matutils\n\n# Load the text you want to paraphrase\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\n# Tokenize the text and create a dictionary of words\ntokens = text.split(\" \")\ndictionary = corpora.Dictionary([tokens])\n\n# Create a matrix of word vectors using the dictionary\nword_vectors = [dictionary.doc2bow(tokens)]\n\n# Use SVD to decompose the matrix of word vectors\nU, S, VT = matutils.svd(word_vectors, k=3)\n\n# Generate paraphrases of the text\nfor i in range(3):\n    paraphrase = []\n    for word in tokens:\n        # Identify the closest semantic equivalents for each word\n        closest_words = VT.dot(VT[dictionary.token2id[word]])\n        closest_words = sorted(enumerate(closest_words), key=lambda x: x[1], reverse=True)\n        closest_word = closest_words[0][0]\n\n        # Replace the word with its closest semantic equivalent\n        paraphrase.append(dictionary[closest_word])\n\n    print(\" \".join(paraphrase))\nThis example trains an LSA model on a single sentence and then generates three paraphrases of the sentence by replacing words with their closest semantic equivalents. Again, this is just a simple example to illustrate the basic concept of using LSA for paraphrasing. In practice, you would need to use a much larger corpus of text to train the LSA model and generate more accurate paraphrases."
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#how-to-use-transformer-for-paraphrasing",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#how-to-use-transformer-for-paraphrasing",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "how to use transformer for paraphrasing",
    "text": "how to use transformer for paraphrasing\nThe transformer is a type of neural network architecture that has been used for a wide range of natural language processing tasks, including paraphrasing. To use a transformer for paraphrasing, you would need to train the transformer on a large corpus of text using a machine learning algorithm.\nDuring training, the transformer would learn to identify the underlying meaning of words and phrases in the text and then generate paraphrases by replacing words with synonyms or related words that express the same meaning in a different way.\nHere is a brief example of how a transformer could be used for paraphrasing in Python:\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load the text you want to paraphrase\ntext = \"The quick brown fox jumps over the lazy dog.\"\n\n# Tokenize the text using a pre-trained transformer model\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\ntokens = tokenizer.encode(text)\n\n# Load a pre-trained transformer model\ntransformer = AutoModelForSeq2SeqLM.from_pretrained(\"distilbert-base-cased\")\n\n# Generate paraphrases of the text\nfor i in range(3):\n    paraphrase = transformer.generate(tokens)\n    paraphrase = tokenizer.decode(paraphrase[0])\n    print(paraphrase)\nThis example uses a pre-trained transformer model to generate three paraphrases of a single sentence. Of course, in practice you would need to train the transformer on a much larger corpus of text to generate more accurate paraphrases. The exact details of the implementation would depend on the specific requirements of your project."
  },
  {
    "objectID": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#how-to-generate-catchy-title-from-keywords-using-language-model",
    "href": "posts/9697c843-4cb1-43f1-b2ce-02b87f9755b8/index.html#how-to-generate-catchy-title-from-keywords-using-language-model",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "how to generate catchy title from keywords using language model",
    "text": "how to generate catchy title from keywords using language model\nTo generate a catchy title from a set of keywords using a language model, you would need to train the language model on a large corpus of text that includes a variety of titles. During training, the language model would learn to identify the underlying meaning of words and phrases and the characteristics of catchy titles.\nOnce the language model has been trained, you can then use it to generate a catchy title from a set of keywords by providing the keywords as input to the model and then selecting the generated title that is the most catchy and relevant to the keywords.\nHere is a brief example of how this could be done in Python:\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Load the keywords you want to use to generate the title\nkeywords = [\"quick\", \"brown\", \"fox\"]\n\n# Tokenize the keywords using a pre-trained language model\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ntokens = tokenizer.encode(keywords)\n\n# Load a pre-trained language model\nlanguage_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n\n# Generate candidate titles from the keywords\ncandidate_titles = []\nfor i in range(3):\n    title = language_model.generate(tokens, max_length=8)\n    title = tokenizer.decode(title[0])\n    candidate_titles.append(title)\n\n# Select the most catchy and relevant title\nselected_title = candidate_titles[0]\nfor title in candidate_titles:\n    if is_catchy(title) and is_relevant(title, keywords):\n        selected_title = title\n        break\n\nprint(selected_title)\nThis example generates three candidate titles from a set of keywords using a pre-trained language model, and then selects the most catchy and relevant title as the final title. Of course, this is just a simple example to illustrate the basic concept of using a language model to generate a catchy title from keywords. In practice, you would need to use a much larger corpus of text to train the language model and generate more accurate and diverse titles."
  },
  {
    "objectID": "posts/8cb8ff08-daf3-493e-8e1f-0ce00e7efc2e/index.html",
    "href": "posts/8cb8ff08-daf3-493e-8e1f-0ce00e7efc2e/index.html",
    "title": "sync tabs across different browsers",
    "section": "",
    "text": "sync tabs across different browsers\ntab session manager needs google account to operate, while it can still do offline syncing without google cloud.\nseems that it can only hook up with newly opened tabs instead of existing ones."
  },
  {
    "objectID": "posts/9b48ce25-109d-459a-bd44-8a53e66e0415/index.html",
    "href": "posts/9b48ce25-109d-459a-bd44-8a53e66e0415/index.html",
    "title": "story continuation, story-dalle able to generate story and image at the same time",
    "section": "",
    "text": "story continuation, story-dalle able to generate story and image at the same time\nstory-dalle code"
  },
  {
    "objectID": "posts/a151389d-cd40-4ef3-8ffc-aa0b60f83df9/index.html",
    "href": "posts/a151389d-cd40-4ef3-8ffc-aa0b60f83df9/index.html",
    "title": "stationary logo finders and moving logo finders",
    "section": "",
    "text": "stationary logo finders and moving logo finders\nfor stationary logo, we have a commandline tool called logo finder which can find multple stationary logos with different timespan. we also have a repo for overall logo finding, which might be deprecated.\nfor more, check out “Watermark Removal, Deep Image Prior, Inpainting, Generate Watermark Mask” bookmark folder in macbook chrome"
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#what-is-spring-cloud",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#what-is-spring-cloud",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "what is spring cloud",
    "text": "what is spring cloud\nSpring Cloud is a set of tools for building microservices-based applications that use Spring Framework, a popular Java-based application development framework. It provides a number of features that can help you build distributed systems that are resilient, reliable, and scalable.\nSpring Cloud provides a number of tools for building microservices, including:\nService discovery: Spring Cloud provides a service registry and a load balancer for discovering and routing to service instances.\nCircuit breaker: Spring Cloud provides a circuit breaker pattern implementation that can help prevent cascading failures in distributed systems.\nConfiguration management: Spring Cloud provides a centralized configuration server for storing and managing application configuration data.\nAPI gateway: Spring Cloud provides an API gateway that can route requests to the appropriate service, perform authentication and authorization, and provide other security features.\nDistributed tracing: Spring Cloud provides support for distributed tracing, which can help you understand the flow of requests through your system and identify performance issues.\nSpring Cloud is built on top of Spring Boot, which makes it easy to get started with microservices development using the Spring Framework. It is also fully integrated with the rest of the Spring ecosystem, including Spring Data, Spring Security, and Spring Cloud Stream."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#use-spring-cloud-in-kotlin",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#use-spring-cloud-in-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "use spring cloud in kotlin",
    "text": "use spring cloud in kotlin\nSpring Cloud can be used with Kotlin, a statically-typed programming language that is fully interoperable with Java and runs on the Java Virtual Machine (JVM). To use Spring Cloud with Kotlin, you can follow these steps:\nSet up a Kotlin project: You can use a build tool like Gradle or Maven to set up a Kotlin project. Make sure to include the necessary dependencies for Spring Cloud, such as the spring-cloud-starter-netflix-eureka-client for service discovery or the spring-cloud-starter-netflix-ribbon for load balancing.\nConfigure your application: You can use the @SpringBootApplication annotation to enable auto-configuration and component scanning in your Kotlin application. You can also use the application.properties file or the application.yml file to configure your application’s properties.\nCreate a Spring Boot application class: You can create a Kotlin class with the @SpringBootApplication annotation and the main function to bootstrap your application. This class will serve as the entry point to your application.\nDefine your microservices: You can define your microservices as Kotlin classes annotated with @RestController and @RequestMapping. These classes will handle incoming HTTP requests and return responses to the client.\nUse Spring Cloud features: You can use the various features of Spring Cloud, such as service discovery, circuit breaking, configuration management, and distributed tracing, in your Kotlin application by using the appropriate annotations and components provided by Spring Cloud.\nHere is an example of a simple Kotlin application using Spring Cloud:\nimport org.springframework.boot.SpringApplication\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient\n\n@SpringBootApplication\n@EnableDiscoveryClient\nclass MyApplication\n\nfun main(args: Array&lt;String&gt;) {\n    SpringApplication.run(MyApplication::class.java, *args)\n}\nThis application uses the @EnableDiscoveryClient annotation to enable service discovery using Spring Cloud Netflix Eureka. You can then use other Spring Cloud features, such as circuit breaking or configuration management, by including the necessary dependencies and using the appropriate annotations and components."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#write-spring-eureka-client-in-kotlin-to-connect-to-eureka-server",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#write-spring-eureka-client-in-kotlin-to-connect-to-eureka-server",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "write spring eureka client in kotlin to connect to eureka server",
    "text": "write spring eureka client in kotlin to connect to eureka server\nHere is an example of how you can write a Spring Cloud Eureka client in Kotlin to connect to a Eureka server:\nimport org.springframework.boot.SpringApplication\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient\n\n@SpringBootApplication\n@EnableDiscoveryClient\nclass EurekaClientApplication\n\nfun main(args: Array&lt;String&gt;) {\n    SpringApplication.run(EurekaClientApplication::class.java, *args)\n}\nThis application uses the @EnableDiscoveryClient annotation to enable service discovery using Spring Cloud Netflix Eureka. The @SpringBootApplication annotation enables auto-configuration and component scanning in the application.\nTo connect to the Eureka server, you will need to provide the URL of the Eureka server in the application.properties or application.yml file. For example:\neureka:\n  client:\n    serviceUrl:\n      defaultZone: http://localhost:8761/eureka/\nYou can then use the @Value annotation to inject the Eureka server URL into your Kotlin code:\nimport org.springframework.beans.factory.annotation.Value\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.RestController\n\n@RestController\nclass EurekaClientController {\n\n    @Value(\"\\${eureka.client.serviceUrl.defaultZone}\")\n    lateinit var eurekaServerUrl: String\n\n    @GetMapping(\"/eureka-server-url\")\n    fun getEurekaServerUrl(): String {\n        return eurekaServerUrl\n    }\n}\nThis controller has a getEurekaServerUrl method that returns the URL of the Eureka server. You can then make a GET request to /eureka-server-url to get the Eureka server URL.\nYou can also use the DiscoveryClient interface provided by Spring Cloud to interact with the Eureka server and perform operations such as registering a service or discovering service instances.\nimport org.springframework.beans.factory.annotation.Autowired\nimport org.springframework.cloud.client.discovery.DiscoveryClient\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.RestController\n\n@RestController\nclass EurekaClientController {\n\n    @Autowired\n    lateinit var discoveryClient: DiscoveryClient\n\n    @GetMapping(\"/service-instances\")\n    fun getServiceInstances(): List&lt;String&gt; {\n        return discoveryClient.services\n    }\n}\nThis controller has a getServiceInstances method that returns a list of all the service instances registered with the Eureka server. You can then make a GET request to /service-instances to get the list of service instances."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#run-eureka-server-kotlin",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#run-eureka-server-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "run eureka server kotlin",
    "text": "run eureka server kotlin\nTo run a Eureka server in Kotlin, you can follow these steps:\nSet up a Kotlin project: You can use a build tool like Gradle or Maven to set up a Kotlin project. Make sure to include the necessary dependencies for Spring Cloud Eureka Server, such as the spring-cloud-starter-netflix-eureka-server dependency.\nConfigure your application: You can use the application.properties file or the application.yml file to configure your Eureka server. For example, you can set the server.port property to specify the port on which the Eureka server will run, and the eureka.client.register-with-eureka and eureka.client.fetch-registry properties to enable or disable the registration and fetching of registry information for the Eureka server.\nCreate a Spring Boot application class: You can create a Kotlin class with the @SpringBootApplication annotation and the main function to bootstrap your application. This class will serve as the entry point to your Eureka server.\nEnable Eureka server: You can use the @EnableEurekaServer annotation to enable the Eureka server in your application.\nHere is an example of a simple Kotlin application that runs a Eureka server:\nimport org.springframework.boot.SpringApplication\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.cloud.netflix.eureka.server.EnableEurekaServer\n\n@SpringBootApplication\n@EnableEurekaServer\nclass EurekaServerApplication\n\nfun main(args: Array&lt;String&gt;) {\n    SpringApplication.run(EurekaServerApplication::class.java, *args)\n}\nThis application uses the @EnableEurekaServer annotation to enable the Eureka server and the @SpringBootApplication annotation to enable auto-configuration and component scanning.\nTo start the Eureka server, you can run the main function of the EurekaServerApplication class. The Eureka server will start up on the port specified in the application.properties or application.yml file (by default, it will run on port 8761). You can then access the Eureka server dashboard at http://localhost:8761."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#spring-cloud-alternative-in-kotlin",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#spring-cloud-alternative-in-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "spring cloud alternative in kotlin",
    "text": "spring cloud alternative in kotlin\nThere are a number of alternatives to Spring Cloud that you can use in Kotlin to build distributed systems and microservices-based applications. Some options include:\nMicronaut: Micronaut is a modern, lightweight, and fast microservices framework for the JVM. It provides features such as service discovery, configuration management, and distributed tracing, and is fully compatible with Kotlin.\nQuarkus: Quarkus is a Kubernetes-native Java framework that is optimized for low memory footprint and fast startup time. It provides a number of features for building microservices, including service discovery, configuration management, and security. Quarkus is fully compatible with Kotlin and can be used to build cloud-native applications.\nVert.x: Vert.x is a reactive, non-blocking, event-driven Java framework that is designed for building distributed systems and microservices. It provides features such as service discovery, load balancing, and distributed tracing, and is fully compatible with Kotlin.\nHelidon: Helidon is a lightweight, cloud-native Java framework that is designed for building microservices and reactive applications. It provides features such as service discovery, configuration management, and security, and is fully compatible with Kotlin.\nEclipse MicroProfile: Eclipse MicroProfile is an open-source specification for building microservices-based applications. It provides a number of features for building distributed systems, including service discovery, configuration management, and security, and is fully compatible with Kotlin.\nYou can choose the appropriate microservices framework based on your requirements and preferences. All of these frameworks provide support for building microservices in Kotlin and offer a number of features that can help you build distributed systems that are resilient, reliable, and scalable."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#which-one-requires-least-code",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#which-one-requires-least-code",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "which one requires least code",
    "text": "which one requires least code\nIt is difficult to say which microservices framework requires the least amount of code, as it depends on the specific requirements of your application and the features you need to implement. Some frameworks, such as Micronaut and Quarkus, are designed to be lightweight and fast, and may require less code to implement certain features compared to other frameworks. However, this may come at the cost of flexibility or a larger learning curve.\nIt is important to evaluate the different microservices frameworks based on your specific requirements and choose the one that best fits your needs. You should consider factors such as the performance and scalability requirements of your application, the features and capabilities of the framework, and the level of support and documentation available.\nIt is also worth noting that writing less code does not necessarily mean that your application will be easier to maintain or more efficient. In some cases, using a more feature-rich framework that requires more code may result in a more maintainable and scalable application in the long run."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#recommend-compatible-package-buildermanager-for-kotlin-but-simpler-than-maven",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#recommend-compatible-package-buildermanager-for-kotlin-but-simpler-than-maven",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "recommend compatible package builder/manager for kotlin but simpler than maven",
    "text": "recommend compatible package builder/manager for kotlin but simpler than maven\nIf you are looking for a package builder and manager for Kotlin that is simpler than Maven, you may want to consider Gradle. Gradle is an open-source build automation tool that is designed to be flexible, efficient, and easy to use. It is fully compatible with Kotlin and can be used to build, test, and publish Kotlin applications.\nSome of the benefits of using Gradle for Kotlin projects include:\nConcise and expressive build scripts: Gradle build scripts are written in a domain-specific language (DSL) that is designed to be concise and expressive. This makes it easier to understand and maintain build scripts, compared to Maven’s XML-based syntax.\nSupport for multiple languages: Gradle supports building projects in multiple languages, including Kotlin, Java, and C/C++. This makes it a good choice for multi-language projects.\nRich plugin ecosystem: Gradle has a rich plugin ecosystem that provides a wide range of functionality, including support for testing, code analysis, and publishing. This makes it easy to extend and customize your build process.\nFast and incremental builds: Gradle uses a caching mechanism and an incremental build approach to make builds faster and more efficient. This can be especially useful for larger projects.\nTo get started with Gradle for Kotlin, you can create a new Kotlin project using the kotlin-gradle-plugin, and define your dependencies in the build.gradle file. You can then use the gradle command-line tool or the Gradle wrapper to build, test, and publish your Kotlin application.\nHere is an example of a simple build.gradle file for a Kotlin project using Gradle:\nplugins {\n    id 'org.jetbrains.kotlin.jvm' version '1.4.21'\n}\n\ngroup = 'com.example'\nversion = '1.0'\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    implementation 'org.jetbrains.kotlin:kotlin-stdlib-jdk8'\n}\n\ntasks.withType&lt;Test&gt; {\n    useJUnitPlatform()\n}\nThis build.gradle file defines the kotlin-jvm plugin, the group and version of the project, the dependencies of the project, and the test task. You can then use the gradle command-line tool or the Gradle wrapper to build, test, and publish your Kotlin application."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#use-rabbitmq-client-in-kotlin",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#use-rabbitmq-client-in-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "use rabbitmq client in kotlin",
    "text": "use rabbitmq client in kotlin\nTo use RabbitMQ, a message broker that supports a number of messaging protocols, in Kotlin, you can use the amqp-client library, which is a Java client library for RabbitMQ.\nTo get started with the amqp-client library in Kotlin, you can include the amqp-client dependency in your project. For example, if you are using Maven, you can add the following dependency to your pom.xml file:\n&lt;dependency&gt;\n  &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;\n  &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;\n  &lt;version&gt;5.11.0&lt;/version&gt;\n&lt;/dependency&gt;\nIf you are using Gradle, you can add the following dependency to your build.gradle file:\ndependencies {\n  implementation 'com.rabbitmq:amqp-client:5.11.0'\n}\nOnce you have included the amqp-client dependency in your project, you can use the classes and interfaces provided by the library to connect to a RabbitMQ server and perform operations such as sending and receiving messages.\nHere is an example of how you can use the amqp-client library in Kotlin to send a message to a RabbitMQ server:\nimport com.rabbitmq.client.ConnectionFactory\nimport com.rabbitmq.client.Connection\nimport com.rabbitmq.client.Channel\n\nfun main() {\n    val factory = ConnectionFactory()\n    factory.host = \"localhost\"\n    val connection: Connection = factory.newConnection()\n    val channel: Channel = connection.createChannel()\n\n    val exchangeName = \"my_exchange\"\n    val routingKey = \"my_routing_key\"\n    val message = \"Hello, RabbitMQ!\"\n\n    channel.basicPublish(exchangeName, routingKey, null, message.toByteArray())\n    println(\" [x] Sent '$message'\")\n\n    channel.close()\n    connection.close()\n}\nThis example connects to a RabbitMQ server running on localhost, creates a channel, and uses the basicPublish method to send a message to the server with a specified exchange name and routing key.\nYou can also use the amqp-client library in Kotlin to receive messages from a RabbitMQ server. Here is an example of how you can use the amqp-client library in Kotlin to receive messages from a RabbitMQ server:\nimport com.rabbitmq.client.ConnectionFactory\nimport com.rabbitmq.client.Connection\nimport com.rabbitmq.client.Channel\nimport com.rabbitmq.client.DeliverCallback\n\nfun main() {\n    val factory = ConnectionFactory()\n    factory.host = \"localhost\"\n    val connection: Connection = factory.newConnection()\n    val channel: Channel = connection.createChannel()\n\n    val queueName = \"my_queue\"\n    channel.queueDeclare(queueName, false, false, false, null)\n    val deliverCallback = DeliverCallback { _, delivery -&gt;\n        val message = String(delivery.body, Charsets.UTF_8)\n        println(\" [x] Received '$message'\")\n    }\n\n    channel.basicConsume(queueName, true, deliverCallback, _ -&gt; {})\n}\nThis code creates a queue and sets up a DeliverCallback to handle incoming messages. The basicConsume method is used to start consuming messages from the queue. When a message is received, the DeliverCallback is invoked and the message is printed to the console.\nYou can find more information about using the amqp-client library in Kotlin to interact with a RabbitMQ server in the RabbitMQ documentation and the amqp-client library documentation.\nset the delivery mode to persistent To set the delivery mode of a message to persistent when using the amqp-client library in Kotlin, you can use the basicPublish method and set the deliveryMode property of the BasicProperties object that you pass as the third argument.\nHere is an example of how you can set the delivery mode of a message to persistent when using the amqp-client library in Kotlin:\nimport com.rabbitmq.client.ConnectionFactory\nimport com.rabbitmq.client.Connection\nimport com.rabbitmq.client.Channel\nimport com.rabbitmq.client.BasicProperties\n\nfun main() {\n    val factory = ConnectionFactory()\n    factory.host = \"localhost\"\n    val connection: Connection = factory.newConnection()\n    val channel: Channel = connection.createChannel()\n\n    val exchangeName = \"my_exchange\"\n    val routingKey = \"my_routing_key\"\n    val message = \"Hello, RabbitMQ!\"\n\n    val properties = BasicProperties.builder()\n        .deliveryMode(2)\n        .build()\n\n    channel.basicPublish(exchangeName, routingKey, properties, message.toByteArray())\n    println(\" [x] Sent '$message'\")\n\n    channel.close()\n    connection.close()\n}\nIn this example, the BasicProperties.builder method is used to create a BasicProperties object with the deliveryMode property set to 2 (indicating persistent delivery). This object is then passed as the third argument to the basicPublish method.\nYou can find more information about the BasicProperties class and the different delivery modes in the amqp-client library documentation."
  },
  {
    "objectID": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#write-spring-boot-hello-world-with-kotlin",
    "href": "posts/f4ab7b43-0ab5-49a3-a094-42a254d7cbd9/index.html#write-spring-boot-hello-world-with-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "write spring boot hello world with kotlin",
    "text": "write spring boot hello world with kotlin\nTo write a “Hello, World!” program in Spring Boot using Kotlin, you can follow these steps:\nCreate a new Spring Boot project using the Spring Initializr. You can do this by visiting https://start.spring.io/ and selecting “Kotlin” as the programming language. Select the “Web” dependency, and then click on “Generate” to download the project as a ZIP file.\nExtract the ZIP file and open the project in your preferred development environment.\nIn the src/main/kotlin directory, create a new Kotlin file called HelloController.kt. This file will contain a simple controller that will handle HTTP requests to the root path of the application.\nIn HelloController.kt, define a controller class and annotate it with @RestController. This will enable the class to handle HTTP requests and return responses to the client.\nimport org.springframework.web.bind.annotation.RestController\n\n@RestController\nclass HelloController {\n\n}\nInside the HelloController class, define a method that will handle HTTP GET requests to the root path of the application. Annotate this method with @GetMapping(“/”).\nimport org.springframework.web.bind.annotation.GetMapping\n\n@RestController\nclass HelloController {\n\n    @GetMapping(\"/\")\n    fun sayHello(): String {\n        return \"Hello, World!\"\n    }\n}\nRun the Spring Boot application by running the main method in the Application class. You should now be able to visit http://localhost:8080/ in your web browser and see the message “Hello, World!” displayed. That’s it! You have now written a simple “Hello, World!” program in Spring Boot using Kotlin."
  },
  {
    "objectID": "posts/ed81b185-2747-4650-89f7-85dd5402dc5a/index.html",
    "href": "posts/ed81b185-2747-4650-89f7-85dd5402dc5a/index.html",
    "title": "spider, web scraping, captcha bypass",
    "section": "",
    "text": "spider, web scraping, captcha bypass\nthere are multiple spider collections on github, most of them are rudimentary and project specific, may not always suit your needs.\nlearnspider in which you can find simple captcha js code and many antimeasure of scrapers for practice. for solutions: learning_spider\nspider collections covers zhihu.com"
  },
  {
    "objectID": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#music-discovery",
    "href": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#music-discovery",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "music discovery",
    "text": "music discovery\nfind music by combining choices of experts\nbuild recommendation engine using spotify api\nuse machine learning to predict and recommend music\nsimilar song matching using last.fm or spotify"
  },
  {
    "objectID": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#netease-网易云听歌识曲",
    "href": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#netease-网易云听歌识曲",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "netease 网易云听歌识曲",
    "text": "netease 网易云听歌识曲\ndemo"
  },
  {
    "objectID": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#self-hosted",
    "href": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#self-hosted",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "self-hosted",
    "text": "self-hosted\nshazam algorithm\nblog: create your on shazam\nfindit another shazam clone"
  },
  {
    "objectID": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#audiotag.info",
    "href": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#audiotag.info",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "audiotag.info",
    "text": "audiotag.info\nportify recognize local music and add them to spotify playlist\nwav_to_info.py\naudio identifier\nnowspinning get song info and cover art"
  },
  {
    "objectID": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#shazam",
    "href": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#shazam",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "shazam",
    "text": "shazam\nshazamio reverse engineered shazam api with many supported functions\naudiorec shazam client for linux, with cli support"
  },
  {
    "objectID": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#midomi-houndify-soundhound",
    "href": "posts/bb443688-cfb8-4b82-9a4d-43493d727e40/index.html#midomi-houndify-soundhound",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "midomi houndify soundhound",
    "text": "midomi houndify soundhound\nto get track info from soundhound (no cookie): https://www.midomi.com/api/track?trackID=100282107076607645\nthe houndify music recognition api: wss://houndify.midomi.com/\nsome lib for midomi found over here it can also bridge yandex music recognition api\nhoundify also have api for that, but requires credit\nfree credits per day: 100\nsoundhound now requires 1 credit\nsoundhound python sdk"
  },
  {
    "objectID": "posts/c6af8175-3069-4bb0-aa9d-489d25a45169/index.html",
    "href": "posts/c6af8175-3069-4bb0-aa9d-489d25a45169/index.html",
    "title": "using default pypi.org/simple index",
    "section": "",
    "text": "using default pypi.org/simple index\npackages like EdgeGPT may update overnight. mirrors won’t keep up. you need to fetch from the official package index.\n\nto set the index:\npip set global.index-url https://pypi.org/simple\nto use the index temporarily:\npip install &lt;package&gt; -i https://pypi.org/simple"
  },
  {
    "objectID": "posts/3470a0e7-0186-4015-bf92-9b67705e4aa5/index.html#related-topics",
    "href": "posts/3470a0e7-0186-4015-bf92-9b67705e4aa5/index.html#related-topics",
    "title": "iot search engines, ip search engines, vulnerable device/server discovery",
    "section": "related topics",
    "text": "related topics\nshodan related topics on github"
  },
  {
    "objectID": "posts/3470a0e7-0186-4015-bf92-9b67705e4aa5/index.html#online",
    "href": "posts/3470a0e7-0186-4015-bf92-9b67705e4aa5/index.html#online",
    "title": "iot search engines, ip search engines, vulnerable device/server discovery",
    "section": "online",
    "text": "online\n\nshodan\nawesome shodan queries shodan script\n\n\nzoomeye\n\n\nfofa\nhttps://www.fofa.info 要注册了 以前的网址进不去\nfofa api docs\n\n\ncensys"
  },
  {
    "objectID": "posts/3470a0e7-0186-4015-bf92-9b67705e4aa5/index.html#self-hosted",
    "href": "posts/3470a0e7-0186-4015-bf92-9b67705e4aa5/index.html#self-hosted",
    "title": "iot search engines, ip search engines, vulnerable device/server discovery",
    "section": "self hosted",
    "text": "self hosted\nivre xray infoga Infoga - Email OSINT scan ip for vulnerable service asn ASN / RPKI validity / BGP stats / IPv4v6 / Prefix / URL / ASPath / Organization / IP reputation / IP geolocation / IP fingerprinting / Network recon / lookup API server / Web traceroute server"
  },
  {
    "objectID": "posts/9ecbcd93-f892-4f81-b25e-002c77406e4d/index.html",
    "href": "posts/9ecbcd93-f892-4f81-b25e-002c77406e4d/index.html",
    "title": "elinks/lynx with python: how to speed up headless website browsing/parsing/scraping with cookies",
    "section": "",
    "text": "elinks/lynx with python: how to speed up headless website browsing/parsing/scraping with cookies\nnewscrawl 狠心开源企业级舆情新闻爬虫项目：支持任意数量爬虫一键运行、爬虫定时任务、爬虫批量删除；爬虫一键部署；爬虫监控可视化; 配置集群爬虫分配策略；👉 现成的docker一键部署文档已为大家踩坑\ngeneral news extractor for extracting main content of news, articles\npip3 install gne\nfirst of all, set it up with a normal user agent\neven better, we can chain it with some customized headless puppeteer/phantomjs (do not load video data), dump the dom when ready, and use elinks/lynx to analyze the dom tree.\nto test if the recommendation bar shows up: https://v.qq.com/x/page/m0847y71q98.html\nto make web page more readable: https://github.com/luin/readability\nload webpage headlessly: https://github.com/jsdom/jsdom https://github.com/ryanpetrello/python-zombie"
  },
  {
    "objectID": "posts/c805ef28-ce68-40c9-b552-4821015570ff/index.html#linux",
    "href": "posts/c805ef28-ce68-40c9-b552-4821015570ff/index.html#linux",
    "title": "resource utilization monitor tool",
    "section": "linux",
    "text": "linux\nhtop for ram and processes. s-tui for cpu/gpu temperatures"
  },
  {
    "objectID": "posts/bbd74729-59a5-40fe-a184-b32f66e532a6/index.html#reset-usb.sh",
    "href": "posts/bbd74729-59a5-40fe-a184-b32f66e532a6/index.html#reset-usb.sh",
    "title": "reset usb",
    "section": "reset-usb.sh",
    "text": "reset-usb.sh\n#!/bin/bash\nreset-ahci-controllers.sh\nreset-xhci-controllers.sh"
  },
  {
    "objectID": "posts/bbd74729-59a5-40fe-a184-b32f66e532a6/index.html#reset-ahci-controllers.sh",
    "href": "posts/bbd74729-59a5-40fe-a184-b32f66e532a6/index.html#reset-ahci-controllers.sh",
    "title": "reset usb",
    "section": "reset-ahci-controllers.sh",
    "text": "reset-ahci-controllers.sh\n#!/bin/bash\n\n# this freaking works.\n\n# Script to reset all local xHCI (USB) controllers\n# Based on: http://billauer.co.il/blog/2013/02/usb-reset-ehci-uhci-linux/\n\nif [[ ${EUID} != 0 ]]; then\n    echo This must be run as root!\n    exit 1\nfi\n\nfor xhci in /sys/bus/pci/drivers/ahci; do\n    if ! cd ${xhci}; then\n        echo \"Weird error. Failed to change directory to ${xhci}.\"\n    exit 1\n    fi\n    echo \"Resetting devices from ${xhci}...\"\n    for i in ????:??:??.?; do\n        echo -n \"${i}\" &gt; unbind\n        echo -n \"${i}\" &gt; bind\n    done\ndone"
  },
  {
    "objectID": "posts/bbd74729-59a5-40fe-a184-b32f66e532a6/index.html#reset-xhci-controllers.sh",
    "href": "posts/bbd74729-59a5-40fe-a184-b32f66e532a6/index.html#reset-xhci-controllers.sh",
    "title": "reset usb",
    "section": "reset-xhci-controllers.sh",
    "text": "reset-xhci-controllers.sh\n#!/bin/bash\n\n# this freaking works.\n\n# Script to reset all local xHCI (USB) controllers\n# Based on: http://billauer.co.il/blog/2013/02/usb-reset-ehci-uhci-linux/\n\nif [[ ${EUID} != 0 ]]; then\n    echo This must be run as root!\n    exit 1\nfi\n\nfor xhci in /sys/bus/pci/drivers/?hci_hcd; do\n    if ! cd ${xhci}; then\n        echo \"Weird error. Failed to change directory to ${xhci}.\"\n    exit 1\n    fi\n    echo \"Resetting devices from ${xhci}...\"\n    for i in ????:??:??.?; do\n        echo -n \"${i}\" &gt; unbind\n        echo -n \"${i}\" &gt; bind\n    done\ndone"
  },
  {
    "objectID": "posts/ec20776c-c13b-487c-9a4f-e408a9fa33b3/index.html#windows",
    "href": "posts/ec20776c-c13b-487c-9a4f-e408a9fa33b3/index.html#windows",
    "title": "recycle bin, trash can cli alternative",
    "section": "windows",
    "text": "windows\ncmdutils which has recycle and bin commands\ncmd-recycle\nnircmd\nnircmd moverecyclebin *.tmp"
  },
  {
    "objectID": "posts/ec20776c-c13b-487c-9a4f-e408a9fa33b3/index.html#macos",
    "href": "posts/ec20776c-c13b-487c-9a4f-e408a9fa33b3/index.html#macos",
    "title": "recycle bin, trash can cli alternative",
    "section": "macos",
    "text": "macos\ndo this manually:\n# i don't trust this.\n#rm -rf ~/.Trash/*\n\nosascript -e 'tell app \"Finder\" to empty' \ntrash\nrmtrash in nightproductions’s cli tools"
  },
  {
    "objectID": "posts/53399685-e3fb-4bc7-95d7-9e8bcf6f871a/index.html",
    "href": "posts/53399685-e3fb-4bc7-95d7-9e8bcf6f871a/index.html",
    "title": "rectangle packing, polygon to rectangle decomposition",
    "section": "",
    "text": "rectangle packing, polygon to rectangle decomposition"
  },
  {
    "objectID": "posts/c34636c4-f8cd-4029-b458-88c9242bf318/index.html#proxy-service",
    "href": "posts/c34636c4-f8cd-4029-b458-88c9242bf318/index.html#proxy-service",
    "title": "recaptcha solving, proxy providers",
    "section": "proxy service",
    "text": "proxy service\nproxy-cheap"
  },
  {
    "objectID": "posts/c34636c4-f8cd-4029-b458-88c9242bf318/index.html#recaptcha-solving-service",
    "href": "posts/c34636c4-f8cd-4029-b458-88c9242bf318/index.html#recaptcha-solving-service",
    "title": "recaptcha solving, proxy providers",
    "section": "recaptcha solving service",
    "text": "recaptcha solving service\n\nfree libraries\nbotright can solve recaptcha, hcaptcha, geetest. it shall be used with playwright. doc\n\n\npaid services\nanycaptcha.com is an AI captcha solving service"
  },
  {
    "objectID": "posts/6ca0f164-bc5b-4090-ab4e-594b201c44f4/index.html#package-managers",
    "href": "posts/6ca0f164-bc5b-4090-ab4e-594b201c44f4/index.html#package-managers",
    "title": "rare package managers, alternative jvm languages and java study hints",
    "section": "package managers",
    "text": "package managers\n\nc, c++\nconan\nclibs\nvcpkg\n\n\nlisp\nCLPM powered by quicklisp"
  },
  {
    "objectID": "posts/6ca0f164-bc5b-4090-ab4e-594b201c44f4/index.html#jvm-alternative-languages",
    "href": "posts/6ca0f164-bc5b-4090-ab4e-594b201c44f4/index.html#jvm-alternative-languages",
    "title": "rare package managers, alternative jvm languages and java study hints",
    "section": "jvm alternative languages",
    "text": "jvm alternative languages\noracle’s blog on jvm languages showing advantages\nRingoJS Kotlin Scala Groovy Clojure Fantom Ceylon Jython JRuby Frege haskell on jvm Xtend Golo Concurnaas Yeti\nGraalVM uses polyglot to bridge with other languages"
  },
  {
    "objectID": "posts/6ca0f164-bc5b-4090-ab4e-594b201c44f4/index.html#java-hints",
    "href": "posts/6ca0f164-bc5b-4090-ab4e-594b201c44f4/index.html#java-hints",
    "title": "rare package managers, alternative jvm languages and java study hints",
    "section": "java hints",
    "text": "java hints\njavac doc\njshell\nnashorn js engine run it with jjs"
  },
  {
    "objectID": "posts/8089778e-400d-47c0-91a0-af1dc3820009/index.html#linux",
    "href": "posts/8089778e-400d-47c0-91a0-af1dc3820009/index.html#linux",
    "title": "ramfs on macos, linux and windows",
    "section": "linux",
    "text": "linux\nsimply use /dev/shm\nthe only difference is that ramfs on linux is unbounded while tmpfs is bounded\ncreate bounded tmpfs:\nmount -t tmpfs -o size=2g tmpfs /mnt/tmp\nor yoy labor yourself to mount some additional ramfs:\nmount -t ramfs -o size=2g ramfs /mnt/tmp"
  },
  {
    "objectID": "posts/8089778e-400d-47c0-91a0-af1dc3820009/index.html#macos",
    "href": "posts/8089778e-400d-47c0-91a0-af1dc3820009/index.html#macos",
    "title": "ramfs on macos, linux and windows",
    "section": "macos",
    "text": "macos\n/private/tmp is not ramdisk. it is just a directory cleared by startup.\nram-shell: A simple script to create a in-memory filesystem on macOS\nRAM-backed filesystem mounter for Mac OS X\ncreate and mount ramdisk:\n #!/bin/sh\nramfs_size_mb=2100\nmount_point=/tmp/rdisk\n\nmkramdisk() {\n  ramfs_size_sectors=$((${ramfs_size_mb}*1024*1024/512))\n  ramdisk_dev=`hdid -nomount ram://${ramfs_size_sectors}`\n\n  newfs_hfs -v 'ram disk' ${ramdisk_dev}\n  mkdir -p ${mount_point}\n  mount -o noatime -t hfs ${ramdisk_dev} ${mount_point}\n\n  echo \"remove with:\"\n  echo \"umount ${mount_point}\"\n  echo \"diskutil eject ${ramdisk_dev}\"\n}\nto replace /private/tmp with ramfs and registered as launchd service\ncalculate sector numbers by hand:\ndisk_size(MiB)* 1024KiB/MiB * 1024B/KiB / 512B/sector = #sectors\nhdiutil attach -nomount ram://#sectors\n#get returned value afterwards!\nnewfs_hfs -v 'Ramdisk' &lt;returned_disk_device_id&gt;\n# maybe you should create apfs case sensitive instead?\n\n#mount disk\nmkdir -p ~/Ramdisk\n# may change fs type accordingly when using apfs\nmount -o noatime -t hfs &lt;returned_disk_device_id&gt; ~/Ramdisk"
  },
  {
    "objectID": "posts/8089778e-400d-47c0-91a0-af1dc3820009/index.html#windows",
    "href": "posts/8089778e-400d-47c0-91a0-af1dc3820009/index.html#windows",
    "title": "ramfs on macos, linux and windows",
    "section": "windows",
    "text": "windows\na curated ramdisk software list\nuse third-party ramdisk tool like imdisk, eram with kernel driver installed, secure boot disabled (no uefi maybe?)"
  },
  {
    "objectID": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#数据来源",
    "href": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#数据来源",
    "title": "quantatitive financial stock market analysis",
    "section": "数据来源",
    "text": "数据来源\npandas_datareader by yahoo 是国外股票的数据 tushare 国内股票数据"
  },
  {
    "objectID": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#模型建立",
    "href": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#模型建立",
    "title": "quantatitive financial stock market analysis",
    "section": "模型建立",
    "text": "模型建立\nopen source code for economics modeling in python/julia\npandas pipe for streamline processing of real time data\ntime series forcast\n有类似的软件 我下载到windows上面过 (agent based simulation/agent based modeling) called altreva adaptive modeler\nfms\n还原持仓的对象 每一个账户都要详细分析 分析每个账户什么时候买入 卖出 还有不买入 不卖出 观望的那些人 所有人都要还原"
  },
  {
    "objectID": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#实盘接口",
    "href": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#实盘接口",
    "title": "quantatitive financial stock market analysis",
    "section": "实盘接口",
    "text": "实盘接口\ntools for high frequency trading low latency trading tool\n高频交易工具 低延迟交易工具\n要抢涨停板 网络必须要好 下单速度要快\njoinquant\neasytrader\n实盘易 支持多个客户端 服务端要钱的 sdk都是服务端的client"
  },
  {
    "objectID": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#tools",
    "href": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#tools",
    "title": "quantatitive financial stock market analysis",
    "section": "tools",
    "text": "tools\nmytt 通达信公式转换器\nfuncat 通达信公式转换器"
  },
  {
    "objectID": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#models-and-frameworks",
    "href": "posts/d223aa77-917d-4347-bfc5-29cdf5470273/index.html#models-and-frameworks",
    "title": "quantatitive financial stock market analysis",
    "section": "models and frameworks",
    "text": "models and frameworks\ngeneral reinforcement learning: https://github.com/DLR-RM/stable-baselines3\ncrypto trading bot, support all crypto trading markets: https://github.com/freqtrade/freqtrade\nqlib by microsoft, quantatitive financial analysis: https://github.com/microsoft/qlib\nreinforcement financial deep learning package: https://github.com/AI4Finance-Foundation/FinRL\nopenbb_terminal: https://github.com/OpenBB-finance/OpenBBTerminal\nzipline https://github.com/quantopian/zipline\npyalgotrade https://github.com/gbeced/pyalgotrade\nquantaxis: https://github.com/yutiansut/QUANTAXIS\nvn.py: https://github.com/vnpy/vnpy https://www.vnpy.com/docs/\ntalib: https://github.com/mrjbq7/ta-lib https://www.programcreek.com/python/example/92322/talib.EMA?msclkid=425d0f6cb5dd11ec9da2a03aa72194cd\nsuperalgos: https://github.com/Superalgos/Superalgos https://superalgos.org"
  },
  {
    "objectID": "posts/bb7f0f40-75df-4bd3-9a9a-71bee33a0251/index.html",
    "href": "posts/bb7f0f40-75df-4bd3-9a9a-71bee33a0251/index.html",
    "title": "pyttsx3 cross platform tts generator",
    "section": "",
    "text": "pyttsx3 cross platform tts generator\nBy looking into the NaturalLanguage Framework on macOS, I find text classifier and embeddings inside.\nIt will leverage default TTS engine on Windows and macOS, but for linux you must install espeak.\nimport pyttsx3\nengine = pyttsx3.init()\n\n# dir(engine.getProperty(\"voices\")[0]) -&gt; ['age', 'gender', 'id', 'languages', 'name']\n\n# The voices are related to languages. Set it properly.\n\n# you want \"en_US\" and \"zh_CN\"\n# [['en_US'], ['it_IT'], ['sv_SE'], ['fr_CA'], ['de_DE'], ['he_IL'], ['id_ID'], ['en_GB'], ['es_AR'], ['nl_BE'], ['en-scotland'], ['en_US'], ['ro_RO'], ['pt_PT'], ['es_ES'], ['es_MX'], ['th_TH'], ['en_AU'], ['ja_JP'], ['sk_SK'], ['hi_IN'], ['it_IT'], ['pt_BR'], ['ar_SA'], ['hu_HU'], ['zh_TW'], ['el_GR'], ['ru_RU'], ['en_IE'], ['es_ES'], ['nb_NO'], ['es_MX'], ['en_IN'], ['en_US'], ['da_DK'], ['fi_FI'], ['zh_HK'], ['en_ZA'], ['fr_FR'], ['zh_CN'], ['en_IN'], ['en_US'], ['nl_NL'], ['tr_TR'], ['ko_KR'], ['ru_RU'], ['pl_PL'], ['cs_CZ']]\nengine.setProperty('voice', engine.getProperty(\"voices\")[39].id)\n\nengine.save_to_file(\"你好 世界\", 'output.wav')\nengine.runAndWait()\n\nengine.setProperty('rate', 125) # setting up new voice rate\n\n# The punctuals make the bot to pause for some time. Maybe you should control that yourself.\nengine.save_to_file(\"你好，世界\", 'output.wav')\nengine.runAndWait()"
  },
  {
    "objectID": "posts/0fbab7c4-c712-411f-a92c-cde522ed3ae8/index.html",
    "href": "posts/0fbab7c4-c712-411f-a92c-cde522ed3ae8/index.html",
    "title": "python encoding issue",
    "section": "",
    "text": "python encoding issue\nwindows has encoding issue on python intepreter.\nrun like this:\npython -X utf8=1 &lt;args&gt;\n# flag: sys.flags.utf8_mode"
  },
  {
    "objectID": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#dynamically-wait-and-reload-the-python-code-from-disk-when-runtime-exception-occurs",
    "href": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#dynamically-wait-and-reload-the-python-code-from-disk-when-runtime-exception-occurs",
    "title": "pyro audio segmentation and classification",
    "section": "dynamically wait and reload the python code from disk when runtime exception occurs",
    "text": "dynamically wait and reload the python code from disk when runtime exception occurs\nOne way to achieve this is to use the importlib module to dynamically reload a module at runtime. Here’s an example of how you can do this:\nimport importlib\n\ndef reload_module(module_name: str) -&gt; None:\n    importlib.reload(module_name)\n\n# Example usage\ntry:\n    reload_module(\"my_module\")\nexcept Exception as e:\n    print(f\"Exception occurred: {e}\")\nThis will reload the module with the given name at runtime, and if an exception occurs during the reloading process, it will be caught and handled by the except block.\nNote that this approach will only work if the module has been imported at least once before, as the importlib.reload() function can only reload modules that are already imported into the current Python environment. If the module has not been imported yet, you will need to use the importlib.import_module() function to import it first.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#optimize-gpt2-output-with-human-feedback",
    "href": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#optimize-gpt2-output-with-human-feedback",
    "title": "pyro audio segmentation and classification",
    "section": "optimize GPT2 output with human feedback",
    "text": "optimize GPT2 output with human feedback\nThere are a few ways you can optimize the output of a GPT-2 model with human feedback. Here are a few options you might consider:\nFine-tuning: One way to optimize the output of a GPT-2 model is to fine-tune it on a specific task or domain using human-labeled data. This involves training the model on a dataset of human-generated text, such as a collection of articles or a corpus of conversational transcripts. Fine-tuning the model can help it learn to produce output that is more relevant and appropriate for the specific task or domain you are interested in.\nEvaluating and adjusting model hyperparameters: Another way to optimize the output of a GPT-2 model is to experiment with different model hyperparameters, such as the learning rate, batch size, and number of layers. You can use human feedback to evaluate the quality of the model’s output and adjust these hyperparameters accordingly to improve performance.\nUsing human feedback to guide model training: In addition to using human feedback to evaluate the model’s output, you can also use it to guide the training process itself. For example, you can use human feedback to identify specific examples or categories of output that the model is struggling with, and then use these examples to create a targeted training dataset for the model. This can help the model learn to produce more accurate and appropriate output for these specific cases.\nI hope these suggestions are helpful! Let me know if you have any questions."
  },
  {
    "objectID": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#train-gpt2-model-to-operate-with-terminal",
    "href": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#train-gpt2-model-to-operate-with-terminal",
    "title": "pyro audio segmentation and classification",
    "section": "train GPT2 model to operate with terminal",
    "text": "train GPT2 model to operate with terminal\nTo train a GPT-2 model to operate with the terminal, you will need to do the following:\nCollect a dataset of terminal commands and their associated outputs. This dataset will be used to train the GPT-2 model.\nPreprocess the dataset by tokenizing the commands and outputs and creating input-output pairs for training the model.\nTrain the GPT-2 model using the preprocessed dataset. This can be done using the openai/gpt-2 repository on GitHub, which contains the necessary code and instructions for training the model.\nEvaluate the performance of the trained model on a separate test dataset of terminal commands and outputs to ensure that it is able to accurately predict the outputs for a given set of commands.\nIf the model’s performance is not satisfactory, you may need to fine-tune it further by adjusting the training hyperparameters or collecting more data for training.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#what-can-pyro-do",
    "href": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#what-can-pyro-do",
    "title": "pyro audio segmentation and classification",
    "section": "what can pyro do",
    "text": "what can pyro do\nPyro is a probabilistic programming language developed by Uber for use in Bayesian machine learning. It allows users to build complex models using simple, high-level abstractions, and provides a suite of tools for working with probability distributions and performing Bayesian inference.\nSome of the key features of Pyro include:\nSupport for a wide range of probability distributions, including continuous and discrete distributions, as well as a variety of common compound distributions such as mixtures and convolutions.\nA flexible model construction API that allows users to define complex models using simple, high-level abstractions.\nAutomatic differentiation and gradient-based optimization algorithms for efficient training of probabilistic models.\nAlgorithms for performing approximate Bayesian inference, including Markov chain Monte Carlo (MCMC) and variational inference (VI).\nSupport for parallelization and distributed computing, allowing users to scale their models and inference algorithms to large datasets.\nOverall, Pyro is a powerful tool for building and training probabilistic models for machine learning tasks, and is well-suited for a wide range of applications in areas such as natural language processing, computer vision, and time series analysis."
  },
  {
    "objectID": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#segment-audio-and-classify-audio-with-pyro",
    "href": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#segment-audio-and-classify-audio-with-pyro",
    "title": "pyro audio segmentation and classification",
    "section": "segment audio and classify audio with pyro",
    "text": "segment audio and classify audio with pyro\nTo segment and classify audio using Pyro, you will need to first build a probabilistic model that can process the audio data and make predictions about the segments and class labels. Here are the general steps you can follow:\nPreprocess the audio data by converting it to a suitable format for use in the model (e.g., a spectrogram or other feature representation).\nDefine a probabilistic model in Pyro that takes the audio data as input and makes predictions about the segment boundaries and class labels. This model will likely include a number of latent variables (i.e., variables that are not directly observed, but are inferred from the data) that represent the underlying structure of the audio data.\nUse Pyro’s automatic differentiation and gradient-based optimization algorithms to train the model on a dataset of labeled audio segments. This will involve defining a loss function that measures the model’s performance on the training data and adjusting the model parameters to minimize the loss.\nUse the trained model to make predictions on new audio data by performing inference using one of Pyro’s approximate inference algorithms, such as Markov chain Monte Carlo (MCMC) or variational inference (VI).\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#demonstrate-the-process-with-code",
    "href": "posts/21c1d2b9-348c-4a17-812d-81013e37adc8/index.html#demonstrate-the-process-with-code",
    "title": "pyro audio segmentation and classification",
    "section": "demonstrate the process with code",
    "text": "demonstrate the process with code\nSure! Here is an example of how you might build a probabilistic model in Pyro to segment and classify audio data. This example assumes that you have already preprocessed the audio data and converted it to a suitable format (e.g., a spectrogram) for use in the model.\nimport pyro\nimport torch\n\n# Define the number of classes and the size of the input data\nnum_classes = 10\ninput_size = (batch_size, num_features)\n\n# Define the model using Pyro's primitive distributions\ndef audio_classifier(x):\n    # Define the latent variables for the segment boundaries and class labels\n    segment_boundaries = pyro.sample(\"segment_boundaries\", pyro.distributions.Uniform(0, 1))\n    class_labels = pyro.sample(\"class_labels\", pyro.distributions.Categorical(torch.ones(num_classes)/num_classes))\n    \n    # Use the latent variables to define the likelihood of the data\n    likelihood = pyro.sample(\"likelihood\", pyro.distributions.Normal(segment_boundaries, class_labels), obs=x)\n    \n    return likelihood\n\n# Define the optimizer and the loss function\noptimizer = torch.optim.Adam(audio_classifier.parameters(), lr=0.01)\nloss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n\n# Loop over the training data and update the model parameters\nfor x, y in training_data:\n    # Clear the gradients\n    optimizer.zero_grad()\n    \n    # Compute the loss\n    loss = loss_fn(audio_classifier, x, y)\n    \n    # Backpropagate the loss and update the model parameters\n    loss.backward()\n    optimizer.step()\nThis model defines two latent variables: segment_boundaries, which represents the boundaries between different audio segments, and class_labels, which represents the class labels for each segment. The model then uses these latent variables to define the likelihood of the data (i.e., the probability of observing the audio data given the latent variables).\nTo perform inference with this model, you can use one of Pyro’s approximate inference algorithms, such as Markov chain Monte Carlo (MCMC) or variational inference (VI). For example, to perform MCMC inference, you can use the pyro.infer.MCMC class as follows:\n# Define the MCMC sampler\nmcmc = pyro.infer.MCMC(kernel=pyro.infer.NUTS(audio_classifier), num_samples=1000, warmup_steps=100)\n\n# Run the sampler\nmcmc.run(x)\n\n# Extract the samples\nsamples = mcmc.get_samples()\n\n# Use the samples to estimate the posterior distribution of the latent variables\nsegment_boundaries_posterior = samples[\"segment_boundaries\"]\nclass_labels_posterior = samples[\"class_labels\"]\nI hope this example helps to illustrate the process of building and using a probabilistic model for audio segmentation and classification with Pyro. Let me know if you have any questions!"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#整活",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#整活",
    "title": "pyjom schedules",
    "section": "整活",
    "text": "整活\n\n应 急 诈 骗 食 品 (派蒙加Rick Ashley 如何混合？）"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#recommendation",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#recommendation",
    "title": "pyjom schedules",
    "section": "recommendation",
    "text": "recommendation\n\nuse txtai to do NLU and recommend things to people"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#topic-discoveryacquiring",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#topic-discoveryacquiring",
    "title": "pyjom schedules",
    "section": "topic discovery/acquiring",
    "text": "topic discovery/acquiring\n\ntrending topics\n\nbaidu search trending\nsogou trending\nbilibili trending\nwechat trending\ntoutiao trending\ntencent trending\nnetease trending\nyoutube trending\nreddit trending\ntwitch trending ### popular topics\nbaijiahao popular topics\nbilibili popular topics\ndouyin popular topics ### personal/customized topics\ntencent qq customized (can associate with mail)\nwechat customized\nbilibili per user customized"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#dogcat-video-generation",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#dogcat-video-generation",
    "title": "pyjom schedules",
    "section": "dog/cat video generation",
    "text": "dog/cat video generation\n\nmake render engine runnable\nissues: - [x] video length too long (10 mins) it was the speed calculation error. - [x] bgm somehow not in sync (too broad bpm/clip ranges?) - [ ] to analyze the peaks (abrupt changes) in bgm and grab louder peaks using pyloudnorm (getting audio volume)\npip3 install pyloudnorm\nimport soundfile as sf\nimport pyloudnorm as pyln\n\ndata, rate = sf.read(\"0055014.wav\") # load audio (with shape (samples, channels))\nprint(data.shape)\nmeter = pyln.Meter(rate) # create BS.1770 meter\nloudness = meter.integrated_loudness(data) # measure loudness\nprint(loudness)\n\nplace video on loudest points, abrupt changes detected by talib or just take direvative and gaussian average\nvideo too repetitive (small corpus?)\ndo not remove subtitle and crop active region (reviewer’s resource not used? but i rather advise you to do it directly since it requires less computational power)\n[ ] do not have minimum motion threshold (reviewer’s fault? also recommend you to do this in producer)\nremove all watermarks, subtitles and crop video boundaries accordingly\nsource video and audio (infinite, basic test is to find 500 sources at once without duplicate, second test is to find 500 second is to find 500 without duplicate twice), improve highlight algorithm\nfind 500 songs without duplicate at once\nfind 500 songs no duplicate twice\nfind 500 animal videos without duplicate\nfind 500 animal videos no duplicate twice\ngenerate appropriate title, cover, info and tags\ncollect feedback after the post\nfind some shocking fonts for cover and subtitle, english and chinese\nmake that karaoke effect\nmake ass with karaoke effect with lrc files\nmake lyrics sync logic fluent, according to what have learned from karaoke effects\nmake selected video clips fluent, no abrupt cuts, maybe we need pyscenedetect?"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#text-to-video-template-based-video-generator-this-is-perhaps-the-most-complex-video-generator-ever.-do-it-with-caution-it-might-also-includes-the-flipcard-narrator-and-slideshow-based-generators",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#text-to-video-template-based-video-generator-this-is-perhaps-the-most-complex-video-generator-ever.-do-it-with-caution-it-might-also-includes-the-flipcard-narrator-and-slideshow-based-generators",
    "title": "pyjom schedules",
    "section": "text to video, template based video generator (this is perhaps the most complex video generator ever. do it with caution, it might also includes the flipcard, narrator and slideshow based generators)",
    "text": "text to video, template based video generator (this is perhaps the most complex video generator ever. do it with caution, it might also includes the flipcard, narrator and slideshow based generators)\n\ngenerator models subarchitecture (subcategories of template based generators)\n\nflipcard\n\n\nslideshow (video and audio, might also include the dog&cat video!)\n\n\nnarrator\n\n\nsummarized video\n\n\n\n\npolicy evasion, NSFW filters\n\nremove all hints from image, video, audio and script that may lead to copyright issues ________________________ ### analyze the media content and metadata, relationships\nanalyze danmaku\nparaphrase the script\ncut the crap and understand each clip’s meaning ________________________\n\n\n\nprocess the video clips, like changing the human figure, changing face, stylish the video, adding 2d to 3d effects\n\n\n\nprocess the audio clips, like changing voice, adding sound effects, separating audio/music tracks, ducking\n\n\n\nindex, retrieve and align video and audio content according to our collected database\n\n\n\nretrieve and align video and audio according to our smart search agent (keyword extractor, related words) and do live compilation"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#qq-managing",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#qq-managing",
    "title": "pyjom schedules",
    "section": "qq managing",
    "text": "qq managing\n\nmitm chats in friends\nmitm chats in groups\nsource and send pictures to qzone\nsource and send pictures to chat\nreduce posting frequency by group size and feedback\npost relative video link relative to group topic"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#personal-info-collecting-and-emailsms-bulk-sending",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#personal-info-collecting-and-emailsms-bulk-sending",
    "title": "pyjom schedules",
    "section": "personal info collecting and email/sms bulk sending",
    "text": "personal info collecting and email/sms bulk sending\n\navoid mail being trashed or turned into junk\ncollect and make mail templates for mail posting"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#voice-changer",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#voice-changer",
    "title": "pyjom schedules",
    "section": "voice changer",
    "text": "voice changer\n\nvst based voice changer\ntrain or find a decent voice generator 御姐音语料库 小受音语料库 请在b站或者qq群里面寻找 或者什么其他的有关的地方寻找 谢谢"
  },
  {
    "objectID": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#直播-live-streaming",
    "href": "posts/74db3cf3-0f39-4cd2-b5ac-e936b072a38a/index.html#直播-live-streaming",
    "title": "pyjom schedules",
    "section": "直播 live streaming",
    "text": "直播 live streaming\n\nsource the video 如果是同一个站的 尽量放一个月以前的视频 半个月以前的音频\nprepare some space for storing live streaming data\nsource the audio\nautomatic interactions\nhandle the vtuber model’s actions"
  },
  {
    "objectID": "posts/d91d85b4-60f7-43d2-a263-12660824bef2/index.html",
    "href": "posts/d91d85b4-60f7-43d2-a263-12660824bef2/index.html",
    "title": "pwntools usage example",
    "section": "",
    "text": "pwntools usage example\nI created a script for solving a simple problem on RCTF.\nfrom pwn import *\nip = \"190.92.234.114\"\nport = 23334\n\nmclean =lambda l0: l0.decode().split(\"=\")[1].strip()\nmlist = lambda T: [int(x) for x in T.replace(\"[\",\"\").replace(\"]\", \"\").replace(\" \",\"\").strip().split(\",\")]\nr = remote(ip, port)\nl0 = r.recvline()\n# print('first line?', l0) # great man!\nq = mclean(l0)\nq = int(q)\n# but notice you will not like to be fucked up. use safe eval? ast?\nl1 = r.recvline()\n# print('second line?', l1)\nT = mclean(l1)\nT = mlist(T)\nl2 = r.recvline()\nU = mlist(mclean(l2))\n# print(\"third line?\", l2)\nprint(\"Q?\", q)\nprint()\nprint(\"T?\", len(T))\nprint()\nprint(\"U?\", len(U))\n\n# now crack the x. please observe the original code?\n\n# the shift does not matter so much?\n\nmpos_x = {}\nfor i in range(90):\n    t = T[i]\n    u = U[i]\n    pos_x = u//t+1\n    mpos_x.update({pos_x:mpos_x.get(pos_x,0)+1})\n\nmfinalPos = [(key, elem) for key, elem in mpos_x.items()]\nmfinalPos.sort(key=lambda x: -x[1])\nprint(\"NUM?\",mfinalPos[0])\nprint(\"COUNT?\",mfinalPos[0][1])\n# import pyperclip\ndata =str(mfinalPos[0][0])\n# pyperclip.copy(data)\n# r.interactive()\nr.sendline(data.encode())\nflag=r.recvline() #EOFERROR?\nprint(\"FLAG?\",flag)\n# now answer the shit?"
  },
  {
    "objectID": "posts/6f7d7790-0453-4c95-bca9-e47915655a4a/index.html",
    "href": "posts/6f7d7790-0453-4c95-bca9-e47915655a4a/index.html",
    "title": "popular ai competition platforms (may with notebook support)",
    "section": "",
    "text": "popular ai competition platforms (may with notebook support)\ni’ve seen these platforms from a personal competition solution collection\n阿里天池\ndatafountain\n和鲸社区\nkaggle\naistudio"
  },
  {
    "objectID": "posts/d1c0ac62-521b-46b1-9b3c-a9328a662b05/index.html#process-monitor",
    "href": "posts/d1c0ac62-521b-46b1-9b3c-a9328a662b05/index.html#process-monitor",
    "title": "Process Monitoring and Notification Tools: A Comprehensive List",
    "section": "process monitor",
    "text": "process monitor\nhttps://github.com/troglobit/watchdogd https://github.com/ochinchina/supervisord https://github.com/codeskyblue/gosuv https://github.com/Supervisor/superlance https://github.com/immortal/immortal https://github.com/catern/supervise https://github.com/ihaiker/sudis https://github.com/rahiel/supervisor-alert"
  },
  {
    "objectID": "posts/d1c0ac62-521b-46b1-9b3c-a9328a662b05/index.html#notification-pusher",
    "href": "posts/d1c0ac62-521b-46b1-9b3c-a9328a662b05/index.html#notification-pusher",
    "title": "Process Monitoring and Notification Tools: A Comprehensive List",
    "section": "notification pusher",
    "text": "notification pusher\nhttps://github.com/Nickersoft/push.js https://github.com/caronc/apprise https://github.com/Thibauth/python-pushover https://github.com/liiight/notifiers https://github.com/YuriyLisovskiy/pynotifier https://github.com/SeTeM/pync"
  },
  {
    "objectID": "posts/d1c0ac62-521b-46b1-9b3c-a9328a662b05/index.html#dashboard",
    "href": "posts/d1c0ac62-521b-46b1-9b3c-a9328a662b05/index.html#dashboard",
    "title": "Process Monitoring and Notification Tools: A Comprehensive List",
    "section": "dashboard",
    "text": "dashboard\nhttps://github.com/Reportr/dashboard https://github.com/d2-projects/d2-admin https://github.com/gizak/termui https://github.com/plotly/dash https://github.com/Parallels/rq-dashboard"
  },
  {
    "objectID": "posts/a3955d57-99aa-4558-ba41-239da7681cd1/index.html#generative",
    "href": "posts/a3955d57-99aa-4558-ba41-239da7681cd1/index.html#generative",
    "title": "palette extraction from images 色彩搭配提取",
    "section": "generative",
    "text": "generative\ngenerate palette/color map from matplotlib colormaps"
  },
  {
    "objectID": "posts/a3955d57-99aa-4558-ba41-239da7681cd1/index.html#extractive",
    "href": "posts/a3955d57-99aa-4558-ba41-239da7681cd1/index.html#extractive",
    "title": "palette extraction from images 色彩搭配提取",
    "section": "extractive",
    "text": "extractive\nhaishoku and tutorial_1 tutorial_2\npip3 install haishoku\nextract the most likely-to-be color for text foreground/background, then match the rest of the color with the colors extracted from image, then decide the color.\npalette Node.js image color palette extraction with node-canvas\npython gvcci color extraction to turn images into 16 color palettes\nquickpalette 🏃‍♀️🎨 R package for quick extraction of color palettes from text(by regex) and images\nnode-vibrant Extract prominent colors from an image, previous as vibrant.js\nColorExtraction Creating a color palette from images in a fun way using CSS Filters and Vibrant.js"
  },
  {
    "objectID": "posts/d5ec39e9-a4c5-4b73-b0a7-0f6ec053a652/index.html",
    "href": "posts/d5ec39e9-a4c5-4b73-b0a7-0f6ec053a652/index.html",
    "title": "opentimelineio: unified format for media editors?",
    "section": "",
    "text": "opentimelineio: unified format for media editors?\nsimilar language like mine is named as “medialang”, with very stupid syntax (thus might limit expressiveness) and lacks visualization tool.\nit offers many adapters for final cut pro, adobe premiere, kdenlive and more.\nit has simple python interface.\nbut! many adapters are incomplete right now.\nlimited otio mlt adapter"
  },
  {
    "objectID": "posts/9e284dee-6354-44e4-9ddd-645bb1901285/index.html",
    "href": "posts/9e284dee-6354-44e4-9ddd-645bb1901285/index.html",
    "title": "opencv-python wrappers, without boilerplates",
    "section": "",
    "text": "opencv-python wrappers, without boilerplates\nimutils by pyimagesearch\ncaer do image resizing, image processing, video loading. documentation here"
  },
  {
    "objectID": "posts/d19e0a47-0bba-4600-a1de-2b33b866cc17/index.html#prerequisites",
    "href": "posts/d19e0a47-0bba-4600-a1de-2b33b866cc17/index.html#prerequisites",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "prerequisites",
    "text": "prerequisites\nrun these things under virtual machine or docker, with a fixed size mountpoint. keep all ports of your local machine isolated from the agent.\nwhen you need it to process anything, just use the mountpoint as the only data exchange location. do not let anything executable spit out from it. do not run anything generated by it programmatically."
  },
  {
    "objectID": "posts/d19e0a47-0bba-4600-a1de-2b33b866cc17/index.html#targets",
    "href": "posts/d19e0a47-0bba-4600-a1de-2b33b866cc17/index.html#targets",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "targets",
    "text": "targets\ncontracts shall be based on crypto exchange. self-contract shall be introduced, and for those don’t do self-contract or external contracts often their currency could inflate.\nself-training: in the form of task & proof\nmulti-agent training: (contract) similar to self-training, with cross-validation"
  },
  {
    "objectID": "posts/d19e0a47-0bba-4600-a1de-2b33b866cc17/index.html#projects",
    "href": "posts/d19e0a47-0bba-4600-a1de-2b33b866cc17/index.html#projects",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "projects",
    "text": "projects\nautogpt open-interpreter cybergod"
  },
  {
    "objectID": "posts/acbf853a-c715-456c-8d90-da367ff487c8/index.html#free-sms-receive-platforms",
    "href": "posts/acbf853a-c715-456c-8d90-da367ff487c8/index.html#free-sms-receive-platforms",
    "title": "openai codex chatgpt dalle-2 account registration",
    "section": "free sms receive platforms",
    "text": "free sms receive platforms\n7sim.org multiple phone numbers\nreceivesms.org i have seen soulapp usage with this damn number\nnot work for openai virtual phone numbers"
  },
  {
    "objectID": "posts/cf457118-efee-40ac-8558-535e7367baf8/index.html",
    "href": "posts/cf457118-efee-40ac-8558-535e7367baf8/index.html",
    "title": "object tracking, video",
    "section": "",
    "text": "object tracking, video\nidentify the object first, then do tracking.\nif detection overlaps with object, then do not launch new tracking process.\nOpenCV Meanshift Algorithm for Object Tracking\nOpenCV CAMshift Algorithm for Object Tracking\nOpenCV Optical Flow Algorithm for Object Tracking\nOpenCV Object Detection and Tracking"
  },
  {
    "objectID": "posts/ebeddd01-d636-4fb8-b0c1-c1c39f3f243f/index.html",
    "href": "posts/ebeddd01-d636-4fb8-b0c1-c1c39f3f243f/index.html",
    "title": "numpy and pandas deduplication",
    "section": "",
    "text": "numpy and pandas deduplication\nnumpy remove duplicates from array\nprint(np.unique(ar, axis=1))\ndupandas: remove duplicates with custom rules like levenshtein distance, spelling differences and phonetics (fuzzy maching) for english (most likely?)\npip install dupandas\npandas drop_duplicates\ndf.drop_duplicates(subset=['brand', 'style'], keep='last')"
  },
  {
    "objectID": "posts/9514da61-f935-4cac-b1c0-1cbaed3cfbfe/index.html",
    "href": "posts/9514da61-f935-4cac-b1c0-1cbaed3cfbfe/index.html",
    "title": "nodejs NODE_PATH for npm global package installation",
    "section": "",
    "text": "nodejs NODE_PATH for npm global package installation\nwhen installing global ackages, we do not need to specify NODE_PATH. but it is not configured beforehand thus when you want to import packages from there you will face issue.\nfor zsh/bash/fish:\nexport NODE_PATH=&lt;NODE_PATH&gt;\non windows just use the old school drill (open environment editor)\nchech the exact path of NODE_PATH after invoking npm install -g &lt;package_name&gt;, then check if the installed package exists in that path you guessed.\non termux: /data/data/com.termux/files/usr/lib/node_modules\non kali: /usr/local/lib/node_modules (may be inaccurate)\non macos: /opt/homebrew/lib/node_modules (nodejs installed via brew)"
  },
  {
    "objectID": "posts/3a6ec525-f2d9-4e26-8d80-8e610a0a38df/index.html#challenges",
    "href": "posts/3a6ec525-f2d9-4e26-8d80-8e610a0a38df/index.html#challenges",
    "title": "nctf writeups",
    "section": "challenges",
    "text": "challenges\nthe platform\nofficial released source code\nbuuctf online judge\nyou may find many writeups in blog and github for buuctf."
  },
  {
    "objectID": "posts/3a6ec525-f2d9-4e26-8d80-8e610a0a38df/index.html#hints-and-tools",
    "href": "posts/3a6ec525-f2d9-4e26-8d80-8e610a0a38df/index.html#hints-and-tools",
    "title": "nctf writeups",
    "section": "hints and tools",
    "text": "hints and tools\nbinwalk\narr3esty0u github info\nshg-sec\nhack.lu 2022\nayacms rce in nctf 2022? how to identify the cms? and how the fuck did those guys identify the shit from that damn website (bing-upms)?\nanswer: they are both busting common web directories. can be induced by common repo structures.\nbaby-aes for crypto signin?\nzsteg for solving that png problem?\nnormal sql injection, not for denodb\nhuli: interesting blog where denodb 0day came from\nsome z3 code, which does not but angr solved the problem\nfrom z3 import *\ndata1=0x162AEB99F80DD8EF8C82AFADBA2E087A\ndata2=0x47C9F2ACA92F6476BE7F0A6DC89F4305\ndata3=0x33B57575\nanswer=[]\nflag1=[]\nkey=[0x7e,0x1f,0x19,0x75]\nsolver=Solver()\nflag=[Int('flag%d'%i) for i in range(36)]\nfor i in range(16):\n    answer.append((data1&gt;&gt;8*i)&0xff)\nfor i in range(16):\n    answer.append((data2&gt;&gt;8*i)&0xff)\nfor i in range(4):\n    answer.append((data3&gt;&gt;8*i)&0xff)\nprint(answer)\nfor i in range(0,9):\n    v3=key[3]\n    v4=flag[4*i+3]\n    v5=key[0]\n    v6=flag[4*i]\n    v7=flag[4*i+1]\n    v8=key[1]\n    v9=flag[4*i+2]\n    v10=(v6 + v4) * (key[0] + v3)\n    v11=key[2]\n    v12 = v3 * (v6 + v7)\n    v13 = (v3 + v11) * (v7 - v4)\n    v14 = v4 * (v11 - v5)\n    v15 = v5 * (v9 + v4)\n    solver.add(v14+v10+v13-v12==answer[4*i])\n    solver.add(v6 * (v8 - v3) + v12==answer[4*i+1])\n    solver.add(v15 + v14==answer[4*i+2])\n    solver.add(v6 * (v8 - v3) + (v8 + v5) * (v9 - v6) + v10 - v15==answer[4*i+3])\n\nif solver.check()==sat:\n    m=solver.model()\n    rex = []\n    for i in range(34):\n        rex.append(m[flag[i]].as_long())\n    print(rex)\nelse:\n    print(\"n0\")"
  },
  {
    "objectID": "posts/3a6ec525-f2d9-4e26-8d80-8e610a0a38df/index.html#writeups",
    "href": "posts/3a6ec525-f2d9-4e26-8d80-8e610a0a38df/index.html#writeups",
    "title": "nctf writeups",
    "section": "writeups",
    "text": "writeups\nsaying this is complete for 2022 nctf?\narr3ty0u nctf 2022 writeup\nnctf 2019 writeup\ndon’t know when it is, but i remember i have seen this shit: katastros’s nctf writeup\nctfiot chamd5 nctf 2022 writeup\nnctf 2022 official crypto writeup"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#use-cases",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#use-cases",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "use cases",
    "text": "use cases\nto detect hard-coded subtitles, crop the region and detect sudden changes\ncan also use pyscenedetect to do the job"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#pyav",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#pyav",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "pyav",
    "text": "pyav\ndocs\npip3 install av"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#removedetect-silence",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#removedetect-silence",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "remove/detect silence",
    "text": "remove/detect silence\n… silencedetect A-&gt;A Detect silence. … silenceremove A-&gt;A Remove silence."
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#frame-interpolate",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#frame-interpolate",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "frame interpolate",
    "text": "frame interpolate\nffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" \\\n -vf \"minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d\" \\\n -r 60 ffmpeg_samoyed.mp4"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#motion-estimation",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#motion-estimation",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "motion estimation",
    "text": "motion estimation\nto get mosaic motion vectors and visualize:\nffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" \\\n -vf \"mestimate=epzs:mb_size=16:search_param=7, codecview=mv=pf+bf+bb\"  \\\n mestimate_output.mp4 -y"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#get-help",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#get-help",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "get help",
    "text": "get help\n\non specific filter:\nffmpeg -h filter=showspectrumpic\n\n\non all filters:\nffmpeg -filters"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#crop-detection-picture-in-picture-pip-detection",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#crop-detection-picture-in-picture-pip-detection",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "crop detection, picture in picture (PIP) detection",
    "text": "crop detection, picture in picture (PIP) detection\nffmpeg -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" \\\n-vf \"mestimate,cropdetect=mode=mvedges,metadata=mode=print\" \\\n-f null -"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#scene-change-detection",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#scene-change-detection",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "scene change detection",
    "text": "scene change detection\nffmpeg -hide_banner -i \"$file\" -an \\\n-filter:v \\\n\"select='gt(scene,0.2)',showinfo\" \\\n-f null \\\n- 2&gt;&1"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#extract-motion-vectors",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#extract-motion-vectors",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "extract motion vectors",
    "text": "extract motion vectors\nffmpeg can produce motion vector estimation but it is not exportable, only for internal use.\nmp4 format provides motion vector information thus maybe we need not to use GPU to get those ‘optical flow’ data.\n\nextract by using ffmpeg apis\nmv-extractor Extract frames and motion vectors from H.264 and MPEG-4 encoded video.\n\n\nextract from mp4 file\nmpegflow for easy extraction of motion vectors stored in video files\nmv-tractus: A simple tool to extract motion vectors from h264 encoded videos."
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#take-screenshot-at-time",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#take-screenshot-at-time",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "take screenshot at time:",
    "text": "take screenshot at time:\nffmpeg -ss 01:10:35 -i invideo.mp4 -vframes 1 -q:v 3 screenshot.jpg"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#video-denoise-filters",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#video-denoise-filters",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "video denoise filters:",
    "text": "video denoise filters:\ndctdnoiz fftdnoiz hqdn3d nlmeans owdenoise removegrain vaguedenoiser nlmeans_opencl yaepblur"
  },
  {
    "objectID": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#super-resolution-resampling",
    "href": "posts/c589c45c-a8a2-43af-9314-5a4070762507/index.html#super-resolution-resampling",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "super-resolution, resampling:",
    "text": "super-resolution, resampling:\n\ndeeplearning model, tensorflow\nenv LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH \\\nffmpeg -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" \\\n-y -vf \\\n\"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur\" \\\n supertest.mp4\n\n\nuse standard scale method:\nffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\"\\\n -vf \"minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d\" \\\n -r 60 ffmpeg_samoyed.mp4\n\n\noptions:\n‘fast_bilinear’ Select fast bilinear scaling algorithm.\n‘bilinear’ Select bilinear scaling algorithm.\n‘bicubic’ Select bicubic scaling algorithm.\n‘experimental’ Select experimental scaling algorithm.\n‘neighbor’ Select nearest neighbor rescaling algorithm.\n‘area’ Select averaging area rescaling algorithm.\n‘bicublin’ Select bicubic scaling algorithm for the luma component, bilinear for chroma components.\n‘gauss’ Select Gaussian rescaling algorithm.\n‘sinc’ Select sinc rescaling algorithm.\n‘lanczos’ Select Lanczos rescaling algorithm. The default width (alpha) is 3 and can be changed by setting param0.\n‘spline’ Select natural bicubic spline rescaling algorithm.\n‘print_info’ Enable printing/debug logging.\n‘accurate_rnd’ Enable accurate rounding.\n‘full_chroma_int’ Enable full chroma interpolation.\n‘full_chroma_inp’ Select full chroma input.\n‘bitexact’ Enable bitexact output."
  },
  {
    "objectID": "posts/cb7d7287-080f-44ef-967e-d86d4d2343da/index.html",
    "href": "posts/cb7d7287-080f-44ef-967e-d86d4d2343da/index.html",
    "title": "video generation/modification (vfx) from text",
    "section": "",
    "text": "video generation/modification (vfx) from text\n达摩院放出了文本生成视频模型，支持英文输入\nhuggingface space\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ntext-to-video-ms-1.7b\nunknown\nunknown\ndamo-vilab\n\n\nmodelscope-damo-text-to-video-synthesis\nunknown\nunknown\ndamo-vilab\n\n\ntext-to-video-ms-1.7b-legacy\nunknown\nunknown\ndamo-vilab\n\n\n\ncan also use from modelscope:\nfrom modelscope.pipelines import pipeline\nfrom modelscope.utils.constant import Tasks\n\np = pipeline('text-to-video-synthesis', 'damo/text-to-video-synthesis')\n\nPAIR now releases Text2Video-Zero which leverages existing stable diffusion models to generate video. also released a bunch of controlnet dreambooth weights.\n\nlucidrains is a workaholic on transformer implementations. we should scrape all the repos and index them. there are faster language models to train.\n\nPhenaki Video, which uses Mask GIT to produce text guided videos of up to 2 minutes in length, in Pytorch\ndreamix (not open-source)\ninstruct-pix2pix requires 16GB+ VRAM\ntext2live modify video by text prompt (such as add fire in mouth)\nrecurrent-interface-network-pytorch using diffusion to generate images and video\nhigh quality! imagegen-video code with demo and paper\n抄视频 视频的时间要讲究 看看是抄一年前的好还是抄刚刚发布的好\n在发布的一个视频当中 最多抄某个作者的两三个符合要求的片段\nuse editly smooth/slick transitions and subtitles to beat the copy-detection algorithm, also consider color change in ffmpeg\n动态 专栏也可以抄\nmake-a-video\n谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 https://www.kuxai.com/article/398"
  },
  {
    "objectID": "posts/38db893b-053b-45a6-858b-de3a1177ecc2/index.html",
    "href": "posts/38db893b-053b-45a6-858b-de3a1177ecc2/index.html",
    "title": "mirror sites change",
    "section": "",
    "text": "mirror sites change\nif it only blocks a range of ip, you use proxy to avoid this constraint.\nsome mirror sites serves us poorly and block access from us. we point them out, list alternatives and provide quick fixes.\nthese actions are intentionally done against specific group of people. it does block a whole range of IPs.\nactors:\nhttps://mirrors.aliyun.com\nhttps://mirrors.tuna.tsinghua.edu.cn/\nfixes:\ncurrently we use some previously picked up tunnel accounts provided by topsap. may fix this problem?\npython pip:\npip3 config set global.index-url https://mirrors.ustc.edu.cn/pypi/web/simple\ntaobao npm mirror:\nhttp://npm.taobao.org =&gt; http://npmmirror.com\nhttp://registry.npm.taobao.org =&gt; http://registry.npmmirror.com"
  },
  {
    "objectID": "posts/6dd2df93-57eb-4fb5-955c-3014d49d1bbd/index.html#mindsdb",
    "href": "posts/6dd2df93-57eb-4fb5-955c-3014d49d1bbd/index.html#mindsdb",
    "title": "mindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series",
    "section": "MindsDB",
    "text": "MindsDB\ndocumentation\ncloud mindsdb editor\nwarning: this thing could break your dependencies. better use docker instead.\ndocker pull mindsdb/mindsdb\n# pip3 install mindsdb"
  },
  {
    "objectID": "posts/6dd2df93-57eb-4fb5-955c-3014d49d1bbd/index.html#hmmlearn-unsupervised",
    "href": "posts/6dd2df93-57eb-4fb5-955c-3014d49d1bbd/index.html#hmmlearn-unsupervised",
    "title": "mindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series",
    "section": "HMMLearn (unsupervised)",
    "text": "HMMLearn (unsupervised)\nmost useful feature: training and inferring the hidden states"
  },
  {
    "objectID": "posts/6dd2df93-57eb-4fb5-955c-3014d49d1bbd/index.html#supervised-hmm-learning",
    "href": "posts/6dd2df93-57eb-4fb5-955c-3014d49d1bbd/index.html#supervised-hmm-learning",
    "title": "mindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series",
    "section": "supervised hmm learning",
    "text": "supervised hmm learning\n\nseqlearn\n\n\npomegranate (both supervised and unsupervised)\ndocumentation\nAll models that support labeled data support semi-supervised learning, including naive Bayes classifiers, general Bayes classifiers, and hidden Markov models.\nWhile probability Distributions are frequently used as components of more complex models such as mixtures and hidden Markov models, they can also be used by themselves. Many data science tasks require fitting a distribution to data or generating samples under a distribution. pomegranate has a large library of both univariate and multivariate distributions which can be used with an intuitive interface.\nGeneral Mixture Models (GMMs) are an unsupervised probabilistic model composed of multiple distributions (commonly referred to as components) and corresponding weights. This allows you to model more complex distributions corresponding to a singular underlying phenomena. For a full tutorial on what a mixture model is and how to use them, see the above tutorial.\nHidden Markov Models\nBayes Classifiers and Naive Bayes\nMarkov Chains\nBayesian Networks\nMarkov Networks"
  },
  {
    "objectID": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#d-models-live2d-models-and-model-makers",
    "href": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#d-models-live2d-models-and-model-makers",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "3d models, live2d models and model makers",
    "text": "3d models, live2d models and model makers\nmakehuman as model maker\navatar sample e a cute girl\nlive2d models from facerig"
  },
  {
    "objectID": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#blender-adapters",
    "href": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#blender-adapters",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "blender adapters",
    "text": "blender adapters\nblender vrm importer, exporter and utilities\nblender script: vrm to ue4 compatible\nblender’s ‘make it pretty’ button for vrm models\nmakehuman plugin for blender\nblender addon for rhubarb lip sync\nBlendArMocap by cgtinker is a Blender add-on to preform Hand, Face and Pose Detection in Blender using just a Webcam built upon Google’s Mediapipe. The detected data can be easily transferred to rifigy rigs."
  },
  {
    "objectID": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#lipsync-libraries",
    "href": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#lipsync-libraries",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "lipsync libraries",
    "text": "lipsync libraries\nrhubarb lip sync is a command-line tool that automatically creates 2D mouth animation from voice recordings\nwav2lip"
  },
  {
    "objectID": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#mocap-libraries",
    "href": "posts/b2775556-dff7-49e3-a3f2-717d83dcc2be/index.html#mocap-libraries",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "mocap libraries",
    "text": "mocap libraries\nopenpose is the first real-time multi-person system to jointly detect human body, hand, facial, and foot key-points\nFrankMocap A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator\nEasyMocap is an open-source toolbox for markerless human motion capture.\nfreemocap and its FAQ wiki\nFreeMoCap on pre-recorded videos:\nStart the RunMe() pipeline at Stage 2, and specify the folder containing the videos you wish to process.\nPARE: Part Attention Regressor for 3D Human Body Estimation\nopenseeface: face landmark tracking"
  },
  {
    "objectID": "posts/a2ea0554-f5fa-4fdf-8b9e-9c4b5fcc4345/index.html",
    "href": "posts/a2ea0554-f5fa-4fdf-8b9e-9c4b5fcc4345/index.html",
    "title": "make game cheats, buy game cheats, game hacks",
    "section": "",
    "text": "make game cheats, buy game cheats, game hacks\naimbots\ngame hacking is about reverse engineering at some level.\nthings may differ when you want to make cheats using yolov5, but at least, you have to read screen and control mouse/keyboard yes?\nguidedhacking\nphantomoverlay"
  },
  {
    "objectID": "posts/72abd51b-96e2-43cb-9df4-075ce9039714/index.html",
    "href": "posts/72abd51b-96e2-43cb-9df4-075ce9039714/index.html",
    "title": "macos cleanup disk and ram",
    "section": "",
    "text": "macos cleanup disk and ram\nexecute: sudo purge may help with ram issue?"
  },
  {
    "objectID": "posts/d14c8adf-f0b9-4e66-a457-80759ab203d7/index.html#notes-on-macbook-air",
    "href": "posts/d14c8adf-f0b9-4e66-a457-80759ab203d7/index.html#notes-on-macbook-air",
    "title": "macbook air usage notes",
    "section": "notes on macbook air",
    "text": "notes on macbook air\nthis damn thing sucks, in every aspect. i am getting tired of it."
  },
  {
    "objectID": "posts/d14c8adf-f0b9-4e66-a457-80759ab203d7/index.html#the-body-position-of-using-this-thing",
    "href": "posts/d14c8adf-f0b9-4e66-a457-80759ab203d7/index.html#the-body-position-of-using-this-thing",
    "title": "macbook air usage notes",
    "section": "the body position of using this thing",
    "text": "the body position of using this thing\nraise my legs with multiple pillows, put this thing on my hip and lean on a triangular shaped pile of pillows.\nstill not ideal but pretty close. in order to make this laptop not sliping down my hip i need to fill the gap between laptop and my belly with clothes. need to support my arms with some toys."
  },
  {
    "objectID": "posts/fa6501c0-3431-4f1e-83af-461a7d29291a/index.html",
    "href": "posts/fa6501c0-3431-4f1e-83af-461a7d29291a/index.html",
    "title": "lua python bridge",
    "section": "",
    "text": "lua python bridge\nlunatic python"
  },
  {
    "objectID": "posts/709d7ad5-6711-49dd-b4d5-a1da46c42bab/index.html",
    "href": "posts/709d7ad5-6711-49dd-b4d5-a1da46c42bab/index.html",
    "title": "library genesis, getting latest ebooks for free",
    "section": "",
    "text": "library genesis, getting latest ebooks for free\na russian ebook search engine\ndon’t get confused. it is always in foreign language. always not “educational” or “scanned”.\nquery like “national geographic” will be perfect. books from amazon kindle will also be potentially good."
  },
  {
    "objectID": "posts/213e1e66-bc8a-4bc1-8f9e-34597820a38f/index.html",
    "href": "posts/213e1e66-bc8a-4bc1-8f9e-34597820a38f/index.html",
    "title": "lessons learned from premiere pro plugin job",
    "section": "",
    "text": "lessons learned from premiere pro plugin job\nset up python with appropriate version on client’s computer by script, not by “PyInstaller” which takes huge amount of time to compile and huge disk space (visually).\ntake notes while doing work.\nask for appropriate compensation for any work."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#you-said-hacking-needs-collaboration.-what-if-i-am-alone-and-i-need-help-from-ai-when-hacking",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#you-said-hacking-needs-collaboration.-what-if-i-am-alone-and-i-need-help-from-ai-when-hacking",
    "title": "learn about ai hacking",
    "section": "you said hacking needs collaboration. what if i am alone and i need help from ai when hacking",
    "text": "you said hacking needs collaboration. what if i am alone and i need help from ai when hacking\nWhile it is true that hacking often requires collaboration and a team effort, it is also possible for an individual to carry out a successful hack on their own. In fact, some of the most famous hacks in history were carried out by a single person. However, it is generally more difficult for an individual to carry out a hack without the help of others, as hacking often requires a diverse set of skills and knowledge.\nIn terms of using artificial intelligence to help with hacking, there are a few ways that AI can be useful. For example, AI can be used to automate certain tasks involved in hacking, such as scanning for vulnerabilities or testing password combinations. This can save a lot of time and effort for the hacker, and allow them to focus on other aspects of the hack.\nAdditionally, some AI systems are specifically designed to assist with hacking. For example, there are AI-powered tools that can analyze a target’s network and identify potential vulnerabilities, or generate custom malware that is tailored to the target’s specific system. These tools can greatly enhance a hacker’s ability to carry out a successful attack.\nIn short, while it is possible for an individual to carry out a hack on their own, AI can be a valuable asset in helping them to do so more effectively and efficiently."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#what-are-the-ai-tools-for-hacking",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#what-are-the-ai-tools-for-hacking",
    "title": "learn about ai hacking",
    "section": "what are the ai tools for hacking",
    "text": "what are the ai tools for hacking\nThere are many different AI-powered tools that can be used for hacking, depending on the specific needs and goals of the hacker. Some examples of AI-powered hacking tools include:\nVulnerability scanners: These tools use AI to scan a target’s network for potential vulnerabilities, such as weak passwords or open ports. This can help the hacker to identify potential entry points for an attack.\nMalware generation tools: These tools use AI to automatically generate custom malware that is tailored to a specific target’s system. This can make it more difficult for antivirus software to detect and block the malware.\nSocial engineering tools: These tools use AI to help hackers carry out social engineering attacks, such as phishing campaigns or “spear-phishing” attacks that are targeted at specific individuals. The AI can help the hacker to create more convincing and effective phishing emails or messages.\nPassword cracking tools: These tools use AI to automatically generate and test password combinations, in an attempt to guess the correct password for a target’s account. AI can make this process much faster and more efficient than a human trying to guess the password manually.\nOverall, the specific AI tools that are used for hacking will depend on the individual goals and needs of the hacker. Some hackers may use a combination of different AI-powered tools to carry out their attacks, while others may focus on a single tool that is particularly well-suited to their needs."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#can-i-build-a-search-engine-based-on-ai-for-hacking",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#can-i-build-a-search-engine-based-on-ai-for-hacking",
    "title": "learn about ai hacking",
    "section": "can i build a search engine based on ai for hacking",
    "text": "can i build a search engine based on ai for hacking\nIt is possible to build a search engine that uses AI to help with hacking, although it is important to note that doing so would be illegal in most countries. Hacking is the unauthorized access of a computer or network, and is a crime in most places. As such, building a search engine that is specifically designed to help with hacking would be a criminal act.\nThat being said, it is possible to build a search engine that uses AI to help with legal security research and testing. For example, such a search engine could be used to scan for vulnerabilities in a network or system, or to help generate custom security testing scenarios. However, it is important to only use such a tool for legal and authorized purposes, as using it for illegal hacking activities would be a crime."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#what-are-popular-vulnerability-scanners-powered-by-ai",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#what-are-popular-vulnerability-scanners-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "what are popular vulnerability scanners powered by ai",
    "text": "what are popular vulnerability scanners powered by ai\nSome of the most popular vulnerability scanners that use AI include:\nAcunetix: This is a commercial vulnerability scanner that uses AI to automatically scan a target’s network for potential vulnerabilities. It is able to identify a wide range of vulnerabilities, including SQL injection, cross-site scripting, and more.\nNessus: This is another commercial vulnerability scanner that uses AI to automate the process of scanning for vulnerabilities. It is known for its comprehensive coverage and ability to identify a wide range of vulnerabilities.\nOpenVAS: This is an open-source vulnerability scanner that uses AI to automate the scanning process. It is a popular choice among security researchers and ethical hackers, due to its open-source nature and ability to identify a wide range of vulnerabilities.\nOverall, there are many different vulnerability scanners that use AI, and the specific one that is best for a given situation will depend on the individual needs and goals of the user."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#popular-malware-generation-tools-powered-by-ai",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#popular-malware-generation-tools-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "popular malware generation tools powered by ai",
    "text": "popular malware generation tools powered by ai\nSome of the most popular malware generation tools that use AI include:\nDeepLocker: This is a tool that uses AI to generate custom malware that is tailored to a specific target. It is able to evade detection by antivirus software, making it a powerful tool for malicious hackers.\nAnglerPhish: This is a tool that uses AI to help with the creation of convincing phishing emails. It can automatically generate personalized emails that are tailored to specific individuals, making it more likely that the recipient will fall for the scam.\nCarbanak: This is a piece of malware that uses AI to adapt to the specific system it is running on, making it more difficult to detect and remove. It is known for its ability to steal sensitive financial information from banks and other financial institutions.\nOverall, there are many different malware generation tools that use AI, and the specific one that is best for a given situation will depend on the individual goals and needs of the user."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#popular-social-engireering-tools-powered-by-ai",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#popular-social-engireering-tools-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "popular social engireering tools powered by ai",
    "text": "popular social engireering tools powered by ai\nSome of the most popular social engineering tools that use AI include:\nReFud.me: This is a tool that uses AI to automatically generate convincing phishing emails. It is able to tailor the emails to specific individuals, making them more likely to fall for the scam.\nPhishAI: This is a tool that uses AI to automatically identify and block phishing emails. It is able to learn from past phishing attacks and use that knowledge to improve its ability to detect and block future attacks.\nImperson: This is a tool that uses AI to automatically generate personalized phishing messages that are tailored to specific individuals. It is able to create messages that are highly convincing, making it more likely that the recipient will fall for the scam.\nOverall, there are many different social engineering tools that use AI, and the specific one that is best for a given situation will depend on the individual goals and needs of the user."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#popular-password-cracking-tools-powered-by-ai",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#popular-password-cracking-tools-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "popular password cracking tools powered by ai",
    "text": "popular password cracking tools powered by ai\nSome of the most popular password cracking tools that use AI include:\nHashcat: This is a popular open-source password cracking tool that uses AI to automatically generate and test password combinations. It is known for its high speed and ability to crack even complex and long passwords.\nJohn the Ripper: This is another popular open-source password cracking tool that uses AI to automate the password cracking process. It is able to crack a wide range of password hashes, and is a popular choice among security researchers and ethical hackers.\nAircrack-ng: This is an open-source password cracking tool that is specifically designed for cracking wireless network passwords. It uses AI to automatically generate and test password combinations, making it a powerful tool for breaking into wireless networks.\nOverall, there are many different password cracking tools that use AI, and the specific one that is best for a given situation will depend on the individual goals and needs of the user."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#how-to-use-hashcat-to-generate-password-list-in-terminal",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#how-to-use-hashcat-to-generate-password-list-in-terminal",
    "title": "learn about ai hacking",
    "section": "how to use hashcat to generate password list in terminal",
    "text": "how to use hashcat to generate password list in terminal\nUse the “hashcat” command to start the Hashcat software. You will need to specify the attack mode that you want to use, as well as the type of password hash that you want to crack. For example, to use the “brute-force” attack mode and crack an MD5 password hash, you would enter the following command:\n./hashcat -a 3 -m 0 hash.txt\nUse the “–stdout” option to output the generated password list to the terminal. This will allow you to see the password combinations as they are generated by Hashcat. For example, to generate a password list using the “brute-force” attack mode and output it to the terminal, you would enter the following command:\n./hashcat -a 3 -m 0 hash.txt --stdout\nUse the “CTRL + C” keys to stop the password generation process once you have generated enough password combinations. Overall, using Hashcat to generate a password list in the terminal is a relatively straightforward process, and the commands are easy to learn and use. It is a powerful tool that can greatly assist with password cracking tasks."
  },
  {
    "objectID": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#sha1-on-hashcat",
    "href": "posts/c9b22038-449f-40ec-a001-e3920e3a4169/index.html#sha1-on-hashcat",
    "title": "learn about ai hacking",
    "section": "sha1 on hashcat",
    "text": "sha1 on hashcat\n./hashcat -a 3 -m 100 hash.txt"
  },
  {
    "objectID": "posts/13d48d09-bc9a-43c6-97a7-faa476a0a884/index.html#static-sources",
    "href": "posts/13d48d09-bc9a-43c6-97a7-faa476a0a884/index.html#static-sources",
    "title": "lazero search tool document preparation",
    "section": "static sources",
    "text": "static sources\nuse my notes\nman pages\ncommandline tool helps\nwebpages to text, to markdown\npages from github repo, topic, search, paperswithcode, kaggle, aistudio, alternativeto, anything"
  },
  {
    "objectID": "posts/13d48d09-bc9a-43c6-97a7-faa476a0a884/index.html#dynamic-sources",
    "href": "posts/13d48d09-bc9a-43c6-97a7-faa476a0a884/index.html#dynamic-sources",
    "title": "lazero search tool document preparation",
    "section": "dynamic sources",
    "text": "dynamic sources\nrss feeds, trends, channels, recommendation, dynamic/interactive webpage/api\nsocial media, instant messaging\nonline search engines\noffline/local search engine like cli based search engine"
  },
  {
    "objectID": "posts/983bff4c-b2d7-4075-a5b7-a7b2439994b4/index.html",
    "href": "posts/983bff4c-b2d7-4075-a5b7-a7b2439994b4/index.html",
    "title": "Introducing LAVIS: A Library for Language-Vision Intelligence with Cross-Modal Implementations",
    "section": "",
    "text": "lavis multimodal library for information retrieval and intelligence, can be used with jina\nlavis has multiple cross-modal implementations\nLAVIS - A Library for Language-Vision Intelligence"
  },
  {
    "objectID": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#language-models",
    "href": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#language-models",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "language models",
    "text": "language models\nallennlp-models\nbert lang street"
  },
  {
    "objectID": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#recommendation",
    "href": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#recommendation",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "recommendation",
    "text": "recommendation\ndeepmatch"
  },
  {
    "objectID": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#fuzzy-search",
    "href": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#fuzzy-search",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "fuzzy search",
    "text": "fuzzy search\nfuzzywuzzy or thefuzz\nfzf a commandline fuzzy matcher\niterfzf as a fzf python binding and its related projects\nrapidfuzz"
  },
  {
    "objectID": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#stopwords",
    "href": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#stopwords",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "stopwords",
    "text": "stopwords\nfrom nltk.corpus import stopwords\nstopwordsiso in python"
  },
  {
    "objectID": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#summarization",
    "href": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#summarization",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "summarization",
    "text": "summarization\nsumy Simple library and command line utility for extracting summary from HTML pages or plain texts\npytextrank Python implementation of TextRank as a spaCy pipeline extension, for graph-based natural language work plus related knowledge graph practices; used for for phrase extraction and lightweight extractive summarization of text documents\nsumma TextRank implementation for text summarization and keyword extraction in Python 3, with optimizations on the similarity function."
  },
  {
    "objectID": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#keyword-extraction",
    "href": "posts/cdc85089-2d0d-4751-87a4-cf42dad9f57d/index.html#keyword-extraction",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "keyword extraction",
    "text": "keyword extraction\nrake-nltk RAKE short for Rapid Automatic Keyword Extraction algorithm, is a domain independent keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and its co-occurance with other words in the text.\nmulti-rake Multilingual Rapid Automatic Keyword Extraction (RAKE) for Python\nyake Unsupervised Approach for Automatic Keyword Extraction using Text Features\ntutorial and libraries\nkeybert uses sentence transformer to do the job\nkwx\npke Python Keyphrase Extraction module\nimport jieba.analyse as ana\n# methods under ana:\n# ['analyzer', 'default_textrank', 'default_tfidf', 'extract_tags', 'set_idf_path', 'set_stop_words', 'textrank', 'tfidf']"
  },
  {
    "objectID": "posts/f2786543-c4fe-4022-8d22-b205fb9b3bce/index.html#npm",
    "href": "posts/f2786543-c4fe-4022-8d22-b205fb9b3bce/index.html#npm",
    "title": "issues related to fastgithub and other self-signed certificates in language-specific package managers",
    "section": "npm",
    "text": "npm\nnpm报错：unable to verify the first certificate\nnpm config set strict-ssl false\nnpm config set ca=\"\"\nnpm download binary files from github will raise error since the download speed is low.\nuse cnpm instead, since it will route all github binary requests to mirrored cnpm cdn.\nnpm i -g cnpm\nset some binary distribution file mirror to https://registry.npmmirror.com in ~/.npmrc and ~/.yarnrc:\ncanvas_binary_host_mirror=https://registry.npmmirror.com/-/binary/canvas/\nsass_binary_site=https://registry.npmmirror.com/-/binary/node-sass\nnodejs_org_mirror=https://registry.npmmirror.com/-/binary/node/\nelectron_mirror=https://registry.npmmirror.com/-/binary/electron/\nelectron_builder_binaries_mirror=https://registry.npmmirror.com/-/binary/electron-builder-binaries/\nchromedriver_cdnurl=https://registry.npmmirror.com/-/binary/chromedriver/\n\nregistry=https://registry.npmmirror.com"
  },
  {
    "objectID": "posts/237c6b21-1957-44c9-8833-202726c86993/index.html",
    "href": "posts/237c6b21-1957-44c9-8833-202726c86993/index.html",
    "title": "image resize, image padding, image scanning",
    "section": "",
    "text": "image resize, image padding, image scanning\n\ndef scanImageWithWindowSizeAutoResize(\n    image,\n    width,\n    height,\n    return_direction=False,\n    threshold=0.1,  # minimum 'fresh' area left for scanning\n):  # shall you use torch? no?\n    shape = image.shape\n    assert len(shape) == 3\n    ih, iw, channels = shape\n    targetWidth = max(width, math.floor(iw * height / ih))\n    targetHeight = max(height, math.floor(ih * width / iw))\n    resized = cv2.resize(\n        image, (targetWidth, targetHeight), interpolation=cv2.INTER_CUBIC\n    )\n    # determine scan direction here.\n    imageSeries = []\n    if targetWidth / targetHeight == width / height:\n        imageSeries = [resized]  # as image series.\n        direction = None\n    elif targetWidth / targetHeight &lt; width / height:\n        direction = \"vertical\"\n        # the scanning is along the vertical axis, which is the height.\n        index = 0\n        while True:\n            start, end = height * index, height * (index + 1)\n            if start &lt; targetHeight:\n                if end &gt; targetHeight:\n                    if 1 - (end - targetHeight) / targetHeight &gt;= threshold:\n                        end = targetHeight\n                        start = targetHeight - height\n                    else:\n                        break\n                # other conditions, just fine\n            else:\n                break  # must exit since nothing to scan.\n            cropped = resized[start:end, :, :]  # height, width, channels\n            imageSeries.append(cropped)\n            index += 1\n    else:\n        direction = \"horizontal\"\n        index = 0\n        while True:\n            start, end = width * index, width * (index + 1)\n            if start &lt; targetWidth:\n                if end &gt; targetWidth:\n                    if 1 - (end - targetWidth) / targetWidth &gt;= threshold:\n                        end = targetWidth\n                        start = targetWidth - width\n                    else:\n                        break\n                # other conditions, just fine\n            else:\n                break  # must exit since nothing to scan.\n            cropped = resized[:, start:end, :]  # height, width, channels\n            imageSeries.append(cropped)\n            index += 1\n    if return_direction:\n        return imageSeries, direction\n    else:\n        return imageSeries\n\n\n\n\ndef resizeImageWithPadding(\n    image,\n    width,\n    height,\n    border_type: Literal[\"constant_black\", \"replicate\"] = \"constant_black\",\n):\n    shape = image.shape\n    assert len(shape) == 3\n    ih, iw, channels = shape\n    targetWidth = min(width, math.floor(iw * height / ih))\n    targetHeight = min(height, math.floor(ih * width / iw))\n    resized = cv2.resize(\n        image, (targetWidth, targetHeight), interpolation=cv2.INTER_CUBIC\n    )\n    BLACK = [0] * channels\n    top = max(0, math.floor((height - targetHeight) / 2))\n    bottom = max(0, height - targetHeight - top)\n    left = max(0, math.floor((width - targetWidth) / 2))\n    right = max(0, width - targetWidth - left)\n    if border_type == \"constant_black\":\n        padded = cv2.copyMakeBorder(\n            resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=BLACK\n        )\n    elif border_type == \"replicate\":\n        padded = cv2.copyMakeBorder(\n            resized, top, bottom, left, right, cv2.BORDER_REPLICATE, value=BLACK\n        )\n    else:\n        raise Exception(\"unknown border_type: %s\" % border_type)\n    return padded"
  },
  {
    "objectID": "posts/ad45e694-9638-4b7e-ab53-271b1f8f108a/index.html",
    "href": "posts/ad45e694-9638-4b7e-ab53-271b1f8f108a/index.html",
    "title": "Hy Programming Language Enhancements for Automation and IDE Support",
    "section": "",
    "text": "hy lisp embedded in python, resumeable exception\njython only supports upto python2.7. these libraries may need substantial changes to be compatible with jython:\nhy\nparse\nhyrule\nreloading\nhy docs\nhyrule docs\nhy缺乏基本的补全 vscode目前没法用 我把hy改造成了可以自动reload 自动抓Uncaught exception的模式 如果要取消这些行为 需要加上flag 可以用于hy2py\n-R\n    disable automatic insertion of reloading decorator\n-T\n    disable toplevel try-except\n-K\n    disable toplevel show stacktrace\n-L\n    disable line-by-line try-except\n一些未知的expression可能不允许被wrap到我们的macro里面 需要被加入到黑名单 已知的系列包括unpack-iterable之类的\nhy的插件目前分为vim版本和EMACS版本 对spacevim spacemacs不怎么友好\nvim syntax highlight\nemacs hy-mode and jedhy\nhyuga for neovim, with custom vim-lsp\nhy的code autoindentation功能我做了 nelean 目前最新版本有待更新 主要是对字符串的正则进行了优化"
  },
  {
    "objectID": "posts/b7787ade-3fc1-44e8-8b34-04b5725f3e63/index.html#recommend-popular-ai-video-creation-tools",
    "href": "posts/b7787ade-3fc1-44e8-8b34-04b5725f3e63/index.html#recommend-popular-ai-video-creation-tools",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "recommend popular ai video creation tools",
    "text": "recommend popular ai video creation tools\nThere are a number of popular AI video creation tools that you might want to consider using, depending on your needs and budget. Here are a few options:\nAnimoto: Animoto is a cloud-based video creation platform that uses AI to help you create professional-quality videos quickly and easily. You can choose from a variety of templates, add your own media, and customize your video with text, music, and other elements.\nWibbitz: Wibbitz is an AI-powered video creation tool that allows you to turn text into video content. You can input a written article or script, and the AI will generate a video complete with images, text, and music.\nAdobe Premiere Elements: Adobe Premiere Elements is a consumer-level video editing software that includes AI-powered features such as automatic video editing, object detection, and more.\nLumen5: Lumen5 is an AI-powered video creation platform that allows you to input text, images, or a link to an article and have the AI generate a video for you. You can customize the video with your own branding, music, and other elements.\nIt’s a good idea to try out a few different tools and see which one works best for you and your needs. Keep in mind that while these tools can be helpful, they may not produce results that are exactly what you’re looking for, and you may need to do some manual editing or customization to get the desired results."
  },
  {
    "objectID": "posts/b7787ade-3fc1-44e8-8b34-04b5725f3e63/index.html#recommend-ai-powered-video-editor",
    "href": "posts/b7787ade-3fc1-44e8-8b34-04b5725f3e63/index.html#recommend-ai-powered-video-editor",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "recommend AI-powered video editor",
    "text": "recommend AI-powered video editor\nThere are several AI-powered video editors available that you might want to consider using, depending on your needs and budget. Here are a few options:\nAdobe Premiere Pro: Adobe Premiere Pro is a professional-grade video editing software that includes a number of AI-powered features, such as object detection and automatic color grading.\nDaVinci Resolve: DaVinci Resolve is a professional-grade video editing software that includes a number of AI-powered features, such as automatic color grading and audio repair.\nFinal Cut Pro: Final Cut Pro is a professional-grade video editing software for Mac that includes a number of AI-powered features, such as automatic color grading and object detection.\nFilmora: Filmora is a consumer-level video editing software that includes a number of AI-powered features, such as automatic video stabilization and object detection.\nIt’s a good idea to try out a few different video editors and see which one works best for you and your needs. Keep in mind that while these tools can be helpful, they may not produce results that are exactly what you’re looking for, and you may need to do some manual editing or customization to get the desired results."
  },
  {
    "objectID": "posts/b7787ade-3fc1-44e8-8b34-04b5725f3e63/index.html#how-can-ai-help-you-target-specific-audiences",
    "href": "posts/b7787ade-3fc1-44e8-8b34-04b5725f3e63/index.html#how-can-ai-help-you-target-specific-audiences",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "how can ai help you target specific audiences",
    "text": "how can ai help you target specific audiences\nThere are several ways in which artificial intelligence (AI) can help target specific audiences:\nPersonalization: AI can analyze data on individuals and their preferences, and use that information to tailor content and messaging specifically to them. For example, an AI-powered recommendation engine can suggest products or content based on a user’s past behaviors and interests.\nSegmentation: AI can help to segment audiences into smaller, more specific groups based on shared characteristics, such as demographics, interests, or behaviors. This can allow organizations to create more targeted campaigns and messaging.\nPredictive analytics: AI can analyze data on past behaviors and outcomes to make predictions about future behavior. This can help organizations to better understand their target audience and tailor their marketing efforts accordingly.\nNatural language processing: AI can analyze and understand human language, allowing organizations to use chatbots and other tools to communicate with their audience in a more personalized and natural way.\nImage and video analysis: AI can analyze images and videos to understand the content and context, allowing organizations to target specific audiences based on the visual content they consume.\nOverall, AI can be a powerful tool for targeting specific audiences by providing insights, personalization, and automation to marketing efforts."
  },
  {
    "objectID": "posts/d5658843-a258-4206-a8a8-d91217886633/index.html#alternatives",
    "href": "posts/d5658843-a258-4206-a8a8-d91217886633/index.html#alternatives",
    "title": "hackthebox",
    "section": "alternatives",
    "text": "alternatives\n11 hack the box alternatives\n9 alternatives from alternativesto"
  },
  {
    "objectID": "posts/d5658843-a258-4206-a8a8-d91217886633/index.html#usage",
    "href": "posts/d5658843-a258-4206-a8a8-d91217886633/index.html#usage",
    "title": "hackthebox",
    "section": "usage",
    "text": "usage\nofficial website\nusage\nhackthebox 2022 writeup\nhackthebox october\n内网靶机渗透\n靶场练习\n你也可以用metasploitable进行练习"
  },
  {
    "objectID": "posts/2f7db33a-c8da-48b1-8c25-5a7f4a6b37ab/index.html",
    "href": "posts/2f7db33a-c8da-48b1-8c25-5a7f4a6b37ab/index.html",
    "title": "hacker forums",
    "section": "",
    "text": "hacker forums\nsome hacker forums like leakbase has rss feed\nleakbase has proxy section in which you may find fresh proxy lists (may not work in mainland, but who knows?)\nsearch with the name or link of these forums in github and you will get more info about hacking.\na bunch of hacker forums, including:\nBreached Xss Exploit 0x00sec lolz Leakzone Enclave dublikat Vlmi Omrt Nulled Cracked Coockie Altenens Bidencash\n\nwooyun.org mirror site wooyun is dead/closed since 2016\nsocial engineering is just a fancy name for spotting candidates, hooking up, gaining trust and doing shit.\nin hacking we must be multilingual, as this shit is really hard to get right.\nyou would read them sometime do you? you would collect info from these sites do you? you would search for things when you need it do you?\nYou would like forums for dark web? Forum for hacking?\n你要的是社工库 提取出来的账号密码库 用来撞库？百度谷歌 QQ 百度云盘 github 磁力种子搜索\nwhen not reached, make sure you are in the channel!\nOffensive Community\n安全脉搏\n网络尖刀\n习科论坛\n红黑联盟\n黑客X档案\nAlternative to ‘raid forum’: visit it in archive.org!\n看雪论坛\n乌云论坛（archive里面看吧）\n吾爱破解\n3dm\nfreebuf\nHack Today\nGreySec Forums\n世界中文黑客论坛\n90Sec\nT00LS\nhttps://jaq.alibaba.com/community/index\nhttp://bobao.360.cn/index/index\nhttps://www.ichunqiu.com/\nhttps://pentesterlab.com/\nhttps://xianzhi.aliyun.com/forum/\nhttp://lab.seclover.com/\n腾讯玄武实验室\nhttp://xlab.tencent.com/cn/\nxss.is\ncracked.io\nBreached forum and onion\nnulled\ndread (forum)\nleakbase forum leaked database\nexploit.in in russian\nhacktown hacking tutorial\nhackforums site offline? another web archive shit?\nevilzone\ncryptbb is dead?\nfreehacks dead?\nCrackingKing dead?\nenvoy dead?\nhelium dead?\nHackADay\nExploit Database\nTinkernut\nDark Web Forum\nJean Valjean forum\nCarding Team\nBiTSHACK\nSecList\n0Day\nHackerPlace\n0x00sec\nHack5 Forums\nBHF\nHack This Site\nKickAss\nBreaking Bad\nPacket Storm\nOpenSC\nHackMac\nEnigma Group\nRohitab\nEthical Hacker\nCracking Forum\nCrackmes de\nBinary Revolution Hacking Forums\nHack Hound\nHellbound Hackers\nftp://www.ly2008.com 用户名:ly2008 密码:ly2008\nhttp://discovery0.blog.hexun.com/3271892_d.html\nhttp://www.hackerxfiles.net/\nhttp://www.nohack.cn/\nhttp://www.hacker.com.cn/\nftp://fseandxy1@y667.com/\nhttp://www.mmbest.com/SoftList/Catalog8/SoftList_Time_1.html\nhttp://www.it-is.com.cn/dh/\nhttp://www.20cn.net/cgi-bin/download/down.cgi?list=passwd\nhttp://www.98919.com/index.html\nhttp://www.muvip119.net/2/index.html\nhttp://www.anqn.com/\nhttp://www.hf110.com\nhttp://down.juntuan.net/index.html\nhttp://new.shockhack.net/index.asp\nhttp://dx.hackbase.com/\nhttp://www.chinahonker.com/index.htm\nhttp://www.cnhacker.com/\nhttp://77169.org/index.html\nlegionhiden4dqh4.onion - Let’s start with HeLL Reloaded, probably the only one that isn’t just awful. where Tor Carding Forum (TCF) members who weren’t arrested when it was seized are now dwelling! Not operated by the same people behind the original HeLL, but after the original was seized, some of the moderators and members made this site.\nexoduockgfq3ikf7.onion Ex0du$, Pretty mediocre forum, lots of shitty banking botnets being sold. Also ransomeware is the big thing recently, so of course that’s being sold. The code is HILARIOUS. RansomWare coded in visual basic, Java, C# and AutoIT v3! Great.\ndamagelabraahzcu.onion - DamageLabs primarily russian forum, looks like there’s not much interesting going on here either. They have a good collection of pirated programming books.\ndarkod3eeziu3w5p.onion - looks like a really dead forum.\ndublik2uqiorycsj.onion - dublik russian forum\nforohpysho2t5mjs.onion - another random forum\n1、独自等待：https://www.waitalone.cn/\n2、中国红客联盟：https://www.ihonker.org/forum.php\n3、安全沙漏：https://www.secsilo.com/about\n4、易安在线：https://www.e365.info/\n5、铁匠运维网：http://www.tiejiang.org/\n6、吾爱漏洞：http://www.52bug.cn/\n7、破晓团队：http://www.secbug.org/\n8、黑白网：http://www.heibai.org/178.html\n9、安全客：https://www.anquanke.com/\n10、E安全：https://www.easyaq.com/\n11、漏洞时代：http://0day5.com/\n12、猫头鹰：http://www.mottoin.com/\n13、华域联盟论坛：https://www.cnhackhy.com/forum.php\n14、逆向未来：https://www.pd521.com/\n15、邪恶八进制：https://forum.eviloctal.com/\n16、飘云阁：https://www.chinapyg.com/\n17、红黑联盟：http://bbs.2cto.com/\n18、技术宅的世界：https://www.0xaa55.com/\n19、安全牛：https://www.aqniu.com/\n20、兄弟论坛：http://hackxd.com/\n21、零日安全：https://www.jmpoep.com/\n22、南域剑盟：http://www.98exe.net/\n23、黑基论坛：http://www.safebase.cn/\n24、网络攻防小组（WLGF）：http://www.nsoad.com/\n25、黑吧安全网：http://www.myhack58.com/\n26、幽灵学院：http://www.41443.com/\n纵观黑客发展史，大可分为三代： 第一代：专门从事计算机、网络，其代表组织为“绿色兵团”（1996年—1998年） 第二代：网络爱好者和在校学生.其代表组织为“中国黑客联盟”（1998年—2000年） 第三代：在校学生，其代表组织为“红客联盟”，“中国鹰派”（2000年—今） 以下为几个典型的黑客组织： ●安全焦点（代表人：冰河）网址：www.xfocus.net ●绿色兵团（已解散）（代表人：龚蔚） ●中国鹰派联盟（代表人：老鹰）网址：www.chinaeagle.org 博客：blog.sina.com.cn/u/1262168602 ●小榕工作室（代表人：小榕）网址：www.netxeyes.com ●第八军团（代表人：陈三公子）网址：www.sec520.com ●邪恶八进制（代表人：冰血封情）网址：forum.eviloctal.com ●黑客基地（代表人：孤独剑客）网址：www.hackbase.com ●华夏黑客同盟（代表人:怪狗）网址：www.77169.com ●牧民网安（代表人：牧民战天）网址：www.hack006.com ●黑客防线 网址：www.hacker.com.cn 国外黑客组织站点及介绍黑客知识的网站： ●http://www.security.nnov.ru/，俄罗斯的一个安全站点 ●http://chess.eecs.berkeley.edu/trust/加州大学伯克利分校“普安全技术研究小组”网站 ●http://www.io.com/.vkp的个人主页，linux安全方面的专业人员(程序员). ●http://linsec.ca/加拿大一个主要收集linux安全相关的文档资料的站点, 也包括其它类Unix系统如OpenBSD, Mac OS X等. ●http://www.rootsecure.net/一个专门为系统管理员和黑客提供安全新闻的网站，成立于2002年9月8日 ●http://astalavista.box.sk.著名的软件破解网站 ●auscert.org.au.一个很棒的黑客工具和入侵攻击的搜索网站 ●http://www.elitehackers.info/.为博学的黑客提供的信息公告牌，是上了等级的黑客去的地方。可找到最新的入侵攻击及对解决办法 ●ftp://ftp.nec.com/.在/pub/securit目录下面包含一个巨大的工具库 ●ftp.win.tue.nl.在/pub/securit目录下包含巨大的安全工具库 国外安全 http://www.neohapsis.com/ 内容极为丰富 国外安全 http://www.deadly.org/ 大量关于OpenBSD的资料文档教程 国外安全 http://www.guninski.com/ 安全专家Guninski的主页，有大量由系统漏洞 国外安全 http://www.sysinternals.com 有很好的windows下的工具及源代码 国外安全 http://www.securityflaw.com/bible/ 入侵检测等文档整理较好的站点 国外安全 http://www.secinf.net/ 网络安全方面的大量文档 国外安全 http://www.incident-response.org 入侵反应，数据恢复工具等 国外安全 http://www.securityfocus.com/ 安全资料整合最好的站 国外安全 http://www.project.honeynet.org/ 由安全界一帮牛人组织的一个project 国外安全 http://www.packetstormsecurity.com 资料全面的安全站 国外安全 http://www.securityportal.com/ 还可以看看的安全站 国外安全 http://www.ussrback.com/ 比较活跃的安全站 国外安全 http://www.attrition.org/ 内容全面的安全站 国外安全 http://www.wiretrip.net/rfp/2/index.asp rfp的安全主页，提供权威的安全信息 国外安全 http://www.antionline.com/ 有些特色栏目的安全站 国外安全 http://www.eeye.com/ eeye公司的主页，提供权威性的安全建议和工具 国外安全 http://www.insecure.org/ Fyodor的主页，nmap的老家，还有exploit 国外安全 http://www.atstake.com/ @stack公司的主页，提供权威的安全建议 国外安全 http://www.bugnet.com/ 提供漏洞修补 国外黑客 http://lsd-pl.net/ LsD的站,最新最有效的exploit 国外黑客 http://www.s0ftpj.org 提供一些水平很高的小工具 国外黑客 http://phrack.org/ Phrack的主页，经典的黑客技术电子杂志 国外黑客 http://www.w00w00.org/ w00w00组织的主页 国外黑客 http://mixter.void.ru/ Mixter的个人主页，不少有用的工具 国外黑客 http://www.thehackerschoice.com/ THC黑客组织的页面，很好的安全文档和工具 国外黑客 www.win2000mag.net Windows & .NET Magazine Network 绝对专业的站点，文章都是一流的 国外黑客 http://www.2600.com/ 2600 Magazine 国外黑客 www.experts-exchange.com 全球有名的社区 国外黑客 www.is-it-true.org 类似于FAQ的站点，资源丰富 国外黑客 www.mixter.warrior2k.com mixter security 国外黑客 www.liun.hektik.org Long Island our Underground Networks 国外黑客 www.ussrback.com ussr is back 国外黑客 www.securiteam.com 非常好的安全文章漏洞利用工具下载站点 国外黑客 www.lsd-pl.net The Last Stage of Delirium Research Group 国外黑客 www. neworder.box.sk Box Network team 国外黑客 www.sysinternals.com sysinternals 国外黑客 www.webattack.com WebAttack Inc 国外黑客 www.blackhat.com Black Hat, Inc 国外黑客 http://p.ulh.as pulhas http://www.hack.co.za (国外著名黑客站点，较全的Exploit库) http://www.phrack.org (经典的黑客技术电子杂志) http://www.antionline.com (国外经典黑客站点) http://whitehats.com (白帽子网站，有最新的规则库下载，关于Snort等) http://lsd-pl.net (发布最新的Exploit程序) http://www.nhs8.com/ 神刀网 http://packetstormsecurity.com (国外著名漏洞库，有大量exploit程序) http://oliver.efri.hr/~crv/security/bugs/list.html (有整理好的最新漏洞库供下载) http://astalavista.box.sk (著名的软件破解网站) http://www.thehackerschoice.com (THC黑客组织的站点，有很多资料和工具) http://www.insecure.org (Fyoderr的个人站点,即Nmap的老家) http://www.securityfocus.com/ http://www.milw0rm.com/ http://www.metasploit.com/"
  },
  {
    "objectID": "posts/385a422c-0710-4eed-b899-ef633288055a/index.html#macos",
    "href": "posts/385a422c-0710-4eed-b899-ef633288055a/index.html#macos",
    "title": "cpu/gpu temperature monitor",
    "section": "macos",
    "text": "macos\nosx-core-temp for old intel macs\napple_sensors and smctemp for m1 and newer macs\nplace this under /opt/homebrew/bin/osx-cpu-temp to run archey4 with cpu temperature:\n#!/bin/bash\nsmctemp -c"
  },
  {
    "objectID": "posts/385a422c-0710-4eed-b899-ef633288055a/index.html#windows",
    "href": "posts/385a422c-0710-4eed-b899-ef633288055a/index.html#windows",
    "title": "cpu/gpu temperature monitor",
    "section": "windows",
    "text": "windows\ncoretemp"
  },
  {
    "objectID": "posts/385a422c-0710-4eed-b899-ef633288055a/index.html#linux",
    "href": "posts/385a422c-0710-4eed-b899-ef633288055a/index.html#linux",
    "title": "cpu/gpu temperature monitor",
    "section": "linux",
    "text": "linux\npsensor"
  },
  {
    "objectID": "posts/d29bcff7-cc4a-425b-a67a-868dc8d74b0f/index.html",
    "href": "posts/d29bcff7-cc4a-425b-a67a-868dc8d74b0f/index.html",
    "title": "gitter developer tokens and qq opqbot, reverse engineering qq protocols and more",
    "section": "",
    "text": "gitter developer tokens and qq opqbot, reverse engineering qq protocols and more\nqq seems to release mac qq with electron, lot more easier for reverse engineering\nhow to reverse go binary, golang reverse\nopqbot官方已经说了 登陆过程中会用到远程的服务器 这个服务器究竟在干什么不得而知 可能和登陆有关也可能没有关系 但是服务器维护期间是没法扫码登录的 如果有可以正常使用的secdata是可以直接启动服务的 不需要服务器 所以估计这个服务器很可能就是拿来解析cookie的\nlogin error:\n2022/08/14 00:01:24.808 [I]  Scan Status 48 Uin 0 \n2022/08/14 00:01:25.880 [I]  Scan Status 48 Uin 0 \n2022/08/14 00:01:26.937 [I]  Scan Status 53 Uin 0\n2022/08/14 00:01:27.998 [I]  Scan Status 53 Uin 0 \n2022/08/14 00:01:29.054 [N]  User &lt;userId&gt; 登录中..请勿连续操作,登录成功后或释放连接后在继续操作 登陆成功后请勿频繁扫码再次登陆(除非冻结导致的掉线) 发不出去群消息请挂机几天 TX日常风控\n=========本框架 🎈 免费 🎈 使用 谨防 ⚠️ 诈骗 ⚠️ 收费 切勿用于 🈲️ 非 🈲️ 法用途\n=========交流群:757360354 TG群组:https://t.me/IOTQQ      \n=========开源社区 👍 https://github.com/opq-osc 👍       \n=========项目主页 😄 https://github.com/OPQBOT/OPQ/wiki 😄\n=========项目Wiki 📒 https://github.com/OPQBOT/OPQ/wiki 📒\n2022/08/14 00:02:30.234 [W]  recvPump session 0D48F5949075DA13D3A9F83838903920\n2022/08/14 00:02:30.234 [A]  Default Closed:0D48F5949075DA13D3A9F83838903920\n2022/08/14 00:02:30.235 [D]  Unregister In Conn -&gt; 0D48F5949075DA13D3A9F83838903920\n关于自动加群 可以考虑使用安卓手机自启动功能（需要下载startup manager 或者boot manager（有root权限和xposed框架）） 用termux-appium 自动操作手机在联网的情况下自启动加群\n现在有两个标准onebot nonebot\n这两个协议都不支持主动加好友 加群 还有收红包方法 至少mac qq协议支持这些方法 但是其他的协议比如手表 ipad协议支不支持就不清楚了\nonebot有大量的qq适配器 而nonebot有大量的插件和除了qq以外的连接器\nnonebot可以连接onebot\n在onebot的qq适配器中 oicq可以查看qq历史聊天记录（有待验证） 可能对qq的数据爬取有帮助 视频爬取 oicq这个适配器有在群里面加好友的方法addFriend(gid, uid)可以参考,提供了一些用于逆向qq协议的程序：\ntxhook 该软件适合在安卓8.0以上系统运行，理论支持安卓7.0以上，但是很多问题。群号：901422091 702991373 - 获取ShareKey… - 主动拦截固定Ecdh密钥及版本 - 对Jce - 过滤抓包，支持高级过滤（长按抓包页面的搜索栏展示/隐藏图标）\nprotobuf online decode protobuf unpack-tools\n也有一些可以进行二次开发的qq web api 搜索QQ号和群号 且有个性签名等更多信息 或许可以搜索关键词？\n这些适配器中有的提供了qq频道的支持：\noicq-guild\n也可以考虑用frida ghidra radare2 cutter来逆向opqbot的go编译好了的程序 或者逆向分析opqbot的网络请求数据 甚至直接动态调用opqbot里面的方法 直接用其他机器人登陆之后获得的cookie进行操作\nto get the token, login first, then visit here or click “sign in” here\n据说扫码登录只支持同一个ip下面的登陆 不知道为什么这个opqbot登陆失败 但是其他机器人都提供了账号密码登陆的渠道 将opqbot的协议逆向出来 或许可以提高登陆成功率 实现相同的功能\n默认(可修改)在 ./data/your-account/ 下会自动生成device.json设备文件，登录完成后此设备文件长期有效 设备文件的生成并非随机，而是使用固定算法，一个账号会永远生成同一份设备文件 如果需要在异地服务器上登录，建议先在常用地通过设备验证并登录挂机一段时间 由于会生成相同设备文件，只要不手动修改，只需验证一次，在任何地区都可直接登录\nit seems the login issue of opqbot is related to the account itself, not gitter token, software version or proxy\nby the way we could always use go-cqhttp, without the ability to collect red packet and add group/friends.\nqq add group/friends may be enabled by our windows virtual machines. without opq, it is very memory intensive.\ntokens:\n74eb7eb14aa36d1b9c2c663bc49335e8becd5318\n2d391bd7639362032d09abfc5a9cc6368b7664d5\nbdf52599d992665509ee5b0b533d5eed08452def"
  },
  {
    "objectID": "posts/0a7027b1-d18b-4ca9-881f-009d1dc7a408/index.html",
    "href": "posts/0a7027b1-d18b-4ca9-881f-009d1dc7a408/index.html",
    "title": "gfw circumvention, download youtube videos, scrape banned websites",
    "section": "",
    "text": "gfw circumvention, download youtube videos, scrape banned websites\nbinder as colab alternative\napart from kaggle, you can also use github actions, devops and more, if only we can get the results in time with code.\ngithub integrated ci platforms\ncirrus graphql spec with artifact info\ngithub actions api: download artifact\ncircleci: artifact\nazure pipelines: artifacts"
  },
  {
    "objectID": "posts/e41a05b1-7ba1-4502-9ee2-17cb14edeb14/index.html",
    "href": "posts/e41a05b1-7ba1-4502-9ee2-17cb14edeb14/index.html",
    "title": "generate noise image, noise video, noise audio with ffmpeg for test",
    "section": "",
    "text": "generate noise image, noise video, noise audio with ffmpeg for test\nsimulating tv noise\nffmpeg -f lavfi -i nullsrc=s=1280x720 -filter_complex \\\n\"geq=random(1)*255:128:128;aevalsrc=-2+random(0)\" \\\n-t 5 output.mkv\nffmpeg -f rawvideo -video_size 1280x720 -pixel_format yuv420p -framerate 25 \\\n-i /dev/urandom -ar 48000 -ac 2 -f s16le -i /dev/urandom -codec:a copy \\\n-t 5 output.mkv"
  },
  {
    "objectID": "posts/89b12732-1b9d-4948-a537-54aae882f6c7/index.html#sources",
    "href": "posts/89b12732-1b9d-4948-a537-54aae882f6c7/index.html#sources",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "sources",
    "text": "sources\n\nproxyscan.io\nreferred by Proxy-List\n\n\ntelegram bots\nhigh quality proxy (channel)\nsocks5 bot\n\n\nself-hosted or cloud/CI based\nproxylist by fate0 (ceased contribution for long) has stopped working since broken github action settings, though getproxy still works (collecting unchecked proxies via travis-ci). i think clash can handle that automatically though."
  },
  {
    "objectID": "posts/89b12732-1b9d-4948-a537-54aae882f6c7/index.html#tools",
    "href": "posts/89b12732-1b9d-4948-a537-54aae882f6c7/index.html#tools",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "tools",
    "text": "tools\n\ncontrollers\nclash-ctl control clash from commandline\nclashctl clash controller in rust, with tui and commandline interface\n\n\nlink converters\n机场订阅转换器-V2ray,Clash,SSR,SS等订阅链接在线转换\nsubconverter self-hosted utility to convert between various subscription format\n\n\nscrapers\nproxypool\n\n\nrouting rules\nclash_rules"
  },
  {
    "objectID": "posts/89b12732-1b9d-4948-a537-54aae882f6c7/index.html#providers",
    "href": "posts/89b12732-1b9d-4948-a537-54aae882f6c7/index.html#providers",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "providers",
    "text": "providers\n\nsubscription links\nproxy-list 20000+\nfreefq\nclash_sync/clash_auto\nShadowsocksAggregator use its Eternity.yml in clash. it also has many sources avaliable for check in README.md\nProxy update hourly\nfree-servers v2ray subscription\nfree-proxy-ss\nSub\nclash-freenode\nclashfree\n\n\nclients\ncrack lantern win 6.8.8\nlantern win 6.8.5\na bunch of cracked clients\nlantern 6.8.7"
  },
  {
    "objectID": "posts/46204146-fb76-4f10-992e-59be735a95a0/index.html",
    "href": "posts/46204146-fb76-4f10-992e-59be735a95a0/index.html",
    "title": "force pty allocation when spinning up tmux over ssh",
    "section": "",
    "text": "force pty allocation when spinning up tmux over ssh\nkali -t tmux attach -t &lt;target_session_name&gt;\nor:\nkali -o RequestTTY=no tmux attach -t &lt;target_session_name&gt;\nsituation:\n$ ssh 192.0.2.125 tmux attach\nopen terminal failed: not a terminal\nThe solution is to simply force pseudo-terminal allocation.\n$ ssh -t 192.0.2.125 tmux attach\n[...]\nDefine RequestTTY in OpenSSH SSH client configuration file to make this permanent.\n$ cat ~/.ssh/config\nHost 192.0.2.125\n  RequestTTY yes"
  },
  {
    "objectID": "posts/e23b543b-813c-4a60-9a62-15e707f9d6f3/index.html",
    "href": "posts/e23b543b-813c-4a60-9a62-15e707f9d6f3/index.html",
    "title": "fire prevention and smart switches",
    "section": "",
    "text": "fire prevention and smart switches\n锂电池充电防爆箱\n\nuse fire preventing sheets, use high quality cabels, use fire preventing cabel protectors around coils, spray fire preventing liquid\n\nfire is detected multiple times and is now the major concern of all. even if you somehow find a little purpose from the machine, the machine can always burn for no reason at all. you need to stop it.\nif the source is battery-less, cutting off the power can solve the problem. if it has battery, then you need to wait till its battery being drained (usually shortcut) and then ditch it.\nfire or shortcut usually happens around those plugged or charged devices. unmanaged ones can cause dramatic catastrophics.\nif you want distributed computing, safety need to be put into first place.\nyou need to always make sure that message service is always available to the supervisor.\n\nwe introduce some chain reaction like mechanism, to turn off corresponding wifi-connected switches when specific signal is received.\nput temperature & smoke detectors and fireballs around many places, especially for those long-running machines. once fire detected, send alarm notification and switch off the main power controller.\nhomeassistant adaptor on ups & nanopi & 4g networks\nfire countermeasure shall be linked to smart power switches (once triggered, cut off the power), and placed evenly to potential area\nalso human presence sensor shall be placed, to create more advanced logic, along with physical switches & power level based logic.\n\nalthough it might be less likely to have devastating fire catastrophies inside if procedure mentioned above is done correctly, fire outside the domesticated area is also concerned.\nwe shall first make sure living objects can escape in time. once fire outside the room is detected, all important files shall be uploaded to the cloud. if fire is inside, cut off the power and use UPS to continue execution. make sure important data and devices can be carried around, and active countermeasures like firebots and firerolls will stop the propagation of fire (to isolate air from fire, even if fire is inside)"
  },
  {
    "objectID": "posts/6972b25e-7ff0-49e0-a38d-318002cce500/index.html",
    "href": "posts/6972b25e-7ff0-49e0-a38d-318002cce500/index.html",
    "title": "find an unused random local port and announce it on redis",
    "section": "",
    "text": "find an unused random local port and announce it on redis\nissues were found when launching apps on fixed ports.\nmaybe you should create this entry inside your lazero package? no need for uploading to pypi, just keep it under pyjom and leave a local install script there.\nmake sure all related services are going to launch after the redis_service.service target. on macos or windows this may vary.\nallocate multiple unused ports at once or they may overlap. abandon ports found on redis.\npython to get unused port:\ndef getUnusedLocalhostPort():\n    \"\"\"\n    These were \"Borrowed\" from YCM.\n    See https://github.com/Valloric/YouCompleteMe\n    \"\"\"\n    sock = socket.socket()\n    # This tells the OS to give us any free port in the range [1024 - 65535]\n    sock.bind((\"\", 0))\n    port = sock.getsockname()[1]\n    sock.close()\n    return port\ninstall redis-py:\npip install redis\npython send port to redis:\nimport redis\n\nr = redis.Redis(\n    host='hostname',\n    port=port, \n    password='password')\n# open a connection to Redis\n \nport = getUnusedLocalhostPort()\nr.set('programPort', port)\nvalue = r.get('programPort')\nprint(value)"
  },
  {
    "objectID": "posts/58fef5b2-8a0c-4130-9208-0491cf117c37/index.html",
    "href": "posts/58fef5b2-8a0c-4130-9208-0491cf117c37/index.html",
    "title": "filename issue on lexar m1",
    "section": "",
    "text": "filename issue on lexar m1\nthis server forbids usage of leftperiod.\nwe can use custom encoding rules in rclone:\nrclone sync --smb-encoding=Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot,LeftPeriod &lt;source&gt; &lt;target&gt;"
  },
  {
    "objectID": "posts/3f369876-4b83-43d6-aed4-97d3fa0d9461/index.html",
    "href": "posts/3f369876-4b83-43d6-aed4-97d3fa0d9461/index.html",
    "title": "A Python Wrapper for FFmpeg: Simplifying Command-Line Functionality",
    "section": "",
    "text": "ffmpeg python wrapper\nmost famous code to cli args ffmpeg python wrapper: https://github.com/kkroening/ffmpeg-python"
  },
  {
    "objectID": "posts/268381f6-a5e3-4360-b5b6-3db05181227e/index.html",
    "href": "posts/268381f6-a5e3-4360-b5b6-3db05181227e/index.html",
    "title": "faster python",
    "section": "",
    "text": "faster python\nlatest python has better performance.\npypy is fast.\ncodon is using python syntax to compile python into static executable."
  },
  {
    "objectID": "posts/208f08d3-a67e-4704-916a-75aee472f947/index.html",
    "href": "posts/208f08d3-a67e-4704-916a-75aee472f947/index.html",
    "title": "expect send special control chars",
    "section": "",
    "text": "expect send special control chars\nreference blog"
  },
  {
    "objectID": "posts/4ac5870e-e5e2-446c-b893-5bf62f098576/index.html#email",
    "href": "posts/4ac5870e-e5e2-446c-b893-5bf62f098576/index.html#email",
    "title": "email scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT",
    "section": "email",
    "text": "email\n\nemail OSINT\nOSINT/recon 其实就是社工 但是一般人喜欢把社工库和社工分开 因为社工库是社工收集来的数据集合 而社工则是一个过程\nloading/transforming leaked txt files will be time-consuming. use pypy to speedup the process. use database specific batch processing method to import the data.\nentity fragmentation in followthmoney is kind of for “entity recognition in multiple social platforms”, suitable for finding patterns/clients in large leaked databases.\n\nemail collector\nsocialscan Python library for accurately querying username and email usage on online platforms\nZen collect email on github\nmaigret a powerful fork of sherlock (customizable, finding accounts by username, but only having 300+ sites ) with 2000+ sites\nemailAll collect email by passing domain\nemailfinder find email by domain\ntheHarvestor email, subdomain and names collector\ngitscan scan for email and password (if possible) with predefined domains and rules by searching github\nghunt needs companion browser plugin to get credentials. can collect info on given email\nEMAGNET collect database leaks, email and password from recent pastebin records\n\n\nleaked email and data\noccrp (anti corruption & crime) aleph is a bad source for getting email (anonymous/unauthorized user can only get hundreds, having no clue what the email relates to). however, it has a tool called follow the money which works with csv files and exports cypher to neo4j\n\nleaks on github\nsearch for leaked database on github\nlinkedin database leak 2021 (hate mega since it has download quota)\n\n\nleaks from forums\nyou typically find links to these databases on anonfiles.com (or else), so query like site:anonfiles.com email rar in duckduckgo (no DMCA censorship)\nbreachedforum’s index contains “credits only” threads which requires 4-8 credits to unlock. to get credits you need to create thread (which will earn 0 credit) and get 1 credit per reply. post to trivial threads like manga.\nin leakbase you earn credits and download leaked databases easier. it has official telegram bot claims to leak free databases everyday.\n\n\ntelegram bots\nfind telegram bots collection in privacy.club (only OSINT bots) and here (with many other bots)\n摆烂bot 永久免费\nSGKmainNEWbot\nsgkmainbot\n(gone?) FreeSGKbot\nFreeSGKbot4\nKernelBugXBot\n\n\ndownload links\nalthough i find many leaked databases as torrent, but those torrent search engines usually collect video/movies instead of anything related to leaked database.\n44.65GB QQ 微博社工库 or qq8e/qq 基本上传的就是这个了 或许可以在QQ群里面找到一些别的社工库 使用这个数据库的还有 q绑 (有反调试 带去水印工具 但是其实这个到处都有吧) aiuys’s retrofit 后台是privacy (只是部分的可以导入 其他的自行处理)\nUsing aMule on macOS, Kad is firewalled (2.2.1 works well said by people, but I’d not use macOS), reason unclear. Maybe on Linux or Windows it will be different.\nSome (dead) links of other databases in ed2k emule format:\ned2k://|file|2010.06-江西移动全库-408万-access.7z|1329999527|5231E1EC5EE1123C6E694AD6399F9807|h=DORZC7XFNG63ZWX6C3RSN3Q7CWZXG5G4|/\ned2k://|file|2012.01-千脑-70万-csv.rar|34017079|A30DD3EF32C03C86E71032CDCA1C5EF9|h=2Z7TKJED7P2NJCKUCINNHMWLXV3KVVS4|/\ned2k://|file|2012.02-AcFun-15万-txt.rar|2241909|C2439FAB2BC7322273DE5D512A530A83|h=QJWQ3LWZ3UFJMPQHPD6WGXYYZHPRLQ43|/\ned2k://|file|2012.03-圆通数据库-mssql.rar|127496748|75F92807F541FB0EBB4773BA83D5157A|h=YAOCNQEUXCNBBTIM226NNZLJA7SMMSDS|/\ned2k://|file|2012.07-yahoo-45万-txt.bz2|6871089|8769EC2314C1AF2C98237DF58C7076D2|h=VSJ52KZ6O6JUZNZKXKT7F3LRXHBKJKMN|/\ned2k://|file|2012.08-小米论坛-828万-mysql.rar|518891223|87704FEA5B191C21F605A0C135BAF98E|h=6UQWS3OQ4VGUXLYW2L6H6TL2GKZOJAUA|/\ned2k://|file|2012.08-小米论坛-828万-txt.rar|361627120|2ED96D2F0E515321F67A31E84DC77B3C|h=UNNVFRMNWNP7UAIXZ6Y6AFCKOLBFJILW|/\ned2k://|file|2013.04-DNF-700万-mysql.zip|306178725|169CE4FA4D4F467BCB7F8297CE6EE032|h=C3KZ6C637ARBAPD5UNF2YMYMT5LTS2UK|/\ned2k://|file|2013.08-酒店开房记录-2000万-excel.rar|610164988|26F994CA1ABA72051ECE497F9AB7959A|h=EDLQDIHSRAJHB5SVNDQVMNPHOXVO3XB6|/\ned2k://|file|2013.08-酒店开房记录-2000万-mssql.bak|8030079488|6FCCDC6DE213DC72A4EFEE19AF2FC1AC|h=5YJSQJY46OYKYMQA5P4G3DUAQGATYDFI|/\ned2k://|file|2014.08-企业400号段数据-mssql.rar|46506453|4F44726413F3B9F9F701635FB498EAAB|h=LP47JMAJGOX233HQR2V3K673G7LE22RI|/\ned2k://|file|2014.08-台湾某财经电视台数据库-2014-txt.zip|53519|95160AAE4A9E3074BACB04C606C0748F|h=3KQJJ4ADWKNOGNJIZIICBXQ5SLPD62R5|/\ned2k://|file|2014.08-房产网-11万-sql.7z|6095432|D99DE175A27D179A5EB9F34D2D975FB0|h=2GN2RLDSDDVZ4POQZVIEJODQJVH2CJ4G|/\ned2k://|file|2014.09-mail.ru邮箱地址-466万-txt.7z|30715779|5247DC686608FD2317A31E8BA67899F4|h=DFVLYBFEQQLDZSXIEOWHWY2BMA5DKDBO|/\ned2k://|file|2014.09-yandex.ru-100万-txt.zip|16200283|80C4A344D51DBAE12F0A0D50202E9313|h=RA2KA6RRGELDAMXBAKXVFI3W7SIJ6TEE|/\ned2k://|file|2014.12-12306-13万-txt.7z|4470710|7B25F299C7862BFA855B63B04BB00E2A|h=VURCVAXE4UVFI2TOIEC6DIZUBSYELY76|/\ned2k://|file|2016.04-卡塔尔国家银行QNB-csv.zip|534384790|D7D81061307568AE47A3EE6C894D6C6C|h=VRQGQASTAHXFRGBZXAAIABVTFJRRIV7G|/\ned2k://|file|2016.04-土耳其公民数据mernis-5000万-sql.gz|1555520122|22B660CB494D89FC84198A6EEA66E3B6|h=HYBIW22P3G56CUB7RR34CJVD7RKO34BS|/\ned2k://|file|2011.03-多玩游戏网-800万-txt.rar|227441723|F8388A178222518978550D3E64B6129B|h=XMR2CYVQI3HOMKVRGUCCFGYZ3JVHKLCG|/\ned2k://|file|2011.03-当当网买家信息-101万-Excel.zip|7822098|1F66086AE57B74D69BF75A2EF7900B2E|h=VRWZME24KH7UTIF3HPTCO5V5KNTEHUAQ|/\ned2k://|file|2011.04-766游戏网-12万-sql.rar|5031951|BBE2D87564A2A8E4B083B57C697FD24E|h=DUFDLSY2A4F5SPZMMCN5JP7TE2HWA4EV|/\ned2k://|file|2011.04-IS语音-969万-txt.zip|177030850|B153DDF9FE16EFFF30C589664592F85A|h=HCB5NVNHVGVGKMDCS7HXHI4MNQASG5SY|/\ned2k://|file|2011.04-亚马逊中国买家信息-20万.zip|7570413|356D9E9C07D62243EF8A62745819E85C|h=BXLWB7OFKIFTCSCUU4Y47DHMX67GF7DO|/\ned2k://|file|2011.04-凡客诚品买家信息-20万-Excel.zip|7784030|AEC527EA7E816DBD75FF92B0C26BC480|h=VXC2RO23H23OCZISUXTEO62RTVHGQFPZ|/\ned2k://|file|2011.04-爱拍游戏网-1100万-txt.zip|267845795|87F9FFE887B0F53CAFD2A11205CB6C52|h=G6AQRSNJ7CHDTX5MTV6RYGB2OHYOAEXA|/\ned2k://|file|2011.05-木蚂蚁-13万-sql.zip|8598547|680F8999D4E27174553D1C11118DF978|h=5G2YZ7Z6RAQ5M5XUNCEFNX7ZYAITMZPZ|/\ned2k://|file|2011.07-土木在线-540万-sql.zip|645903048|4ED3B64224752DE3AB11B11D2FD9DA06|h=UL3F74NI266IR4IHI7UHDKMZRQMX3PFX|/\ned2k://|file|2011.10-178游戏网-1000万-txt.rar|108534783|FFCD04A52339701C8CB5197BDCF9F4DC|h=C2UYTR264YXVM6NSJNUV5R2PC5VZNAYU|/\ned2k://|file|2011.10-CSDN.NET-600万-sql.rar|109942505|A29D9468556CF73AFB48A3A8427629DC|h=VTPXT56G3BGRTHBROKQEWW6XAQTMYPLZ|/\ned2k://|file|2011.10-嘟嘟牛-66277-txt.rar|215666725|EF7187E33A8EBD9FD806343B7B1CAA82|h=Z5YU2Z6P6GUT5DUKQ6L4X5YFMZZNZ4YZ|/\ned2k://|file|2011.11-7k7k小游戏-2000万-txt.rar|203648704|6EB70910C1C193F5BE04610B503EF4A0|h=Y4ITT7C5Z5LOOREJPWXA25TM2NLKEEDX|/\ned2k://|file|2011.11-人人网-500万-txt.rar|51969611|8CD19B7A2EB9F1F74CB8BFBDE7BD144D|h=SDNOOZCYR6PXZIRZTZPEICNRNZ67BQJJ|/\ned2k://|file|2011.12-天涯社区-4000万-txt.rar|493480455|E4E0CFD85E2A783A3C3BD2539AA28FC3|h=4FB7J7QPRWRIPX7QWWTYVZCKMWDZ5VIQ|/\ned2k://|file|2011.12-淘宝买家卖家邮箱-2500万-txt.zip|135534861|F40C3C9F32F2C30B1A2484FAB3CB1257|h=GLUDUAAYPAALG3GPHD4EHT5OB6V6WBVB|/\ned2k://|file|2012.10-QQ精准客户名单-4500万-txt.rar|131416815|134F81AA90B27F55818E7A521D3CB35B|h=NRF2HAH2IXDT635UV6NDEGSA2HSOSSHZ|/\ned2k://|file|2012.06-LinkedIn-16737万-txt.rar|7503170474|A50C488915FC70E1DE644AA5F3432D6F|h=E2NEXLXOOA6PONPKUGVRVIMEU54EC6P4|/\ned2k://|file|2013.06-Myspace.com-36021万-txt.7z|12419587039|A1B14F88891885D636DE9F642A3E06DF|h=3QBXWEHRBUSUEWJOSHCF47B7HEC4Q5BM|/\n\n\n\ncheck registration account with email\nreg007 counterpart only check if that account “exists”, but no actual account shown. search for reg007 on github you will get a bunch of links relating to OSINT.\nholehe only check if an email address is registered as account elsewhere using “forget my password” APIs.\nsreg is found from a collection of security tools, which is a deprecated tool for getting registration status with phone/email/username on multiple chinese platforms.\n\n\n(email) account verifier\nUsually it only verify existance of given email, like emailhippo (100 requests free per day per ip), or mailforguess checking “gmail”,“laposte”,“protonmail”,“yahoo” emails\nSome of them verify email with password: verify email address and password with API of my.com\nh8mail email osint tool, can chase and link to social profile, with many API-key required free services\nmosint automated email osint tool, requires many API keys.\nignorant checks if a phone number is used for snapchat/instagram\n\n\n\nemail connectors/client\nproton mail unofficial client in python\n\n\nemail registration\n\nyandexmail account creator\nbefore it was using 2captcha, now using 5sim to receive sms\nonly login such account through pop3 and imap to prevent revocation\n\n\noutlook email generator\nusing 2captcha and anycaptcha for captcha solving (paid)\n\n\nprotonmail email generator\nusing noptcha or nopecha browser extension (free for 100 captcha solves per day) solving hcaptcha, recaptcha. this extension cannot be used with proxy.\n\n\nmuumuu (which reminds me of someone) email registration using 2captcha, selenium and pyautogui\nI place the list under /root/.muumuu_emails\nthe muumuu mail is programmatically connectable using account and password. seems it is using default ports for these services. POP3 is for both sending and receiving. IMAP is for receiving. SMTP is for sending.\nthis guy’s code is full of hacks. seems only being able to run on his own computer and will break on slightest errors.\nhe stored potential password combinations and also registered accounts (need testing, some may not work) on this google doc. you can download the sheet named “Sheet1” by this api, which adds double quotes and takes more space than exported from web interfaces, method described here.\n\n\n\nreceiving-only email services\n\ntemp email\ntempumail get free temp edu email\n\n\nerine.email\nemail proxy for resending email to you, which I used for github registration (but with a very high block rate without proxy)\n\n\n\nemail aliasing for sending\nicloud’s “hide my email” service seems only provide few email aliases. but according to 3rd party icloud alias generator (cannot be used for chinese version of icloud) you can generate at least 10 aliases. or use hidemyemail-api to login with pyicloud and get aliases as API service. account registered from web without logged in any apple device (maybe virtualbox -&gt; macos has a shot?) will not have email service.\nto send email from alias, you can try setting “FROM” address as your alias via smtp protocol, but the credential shall stay the same. the working approach could be platform specific\nyahoo provides the most email alias up to 500, but 10 for send only emails. however to get one yahoo account one needs offshore phone numbers.\n\n\nemail collection, email scraping\nsearching for “site:pastebin.com @yahoo.com” to get some email addresses, also searching in github might help as well.\nmailcat find email address by nickname (check if deliverable?)\ntheharvestor: email harvestor\nemail collector\ndomain and email collector\n\n\nemail marketing\nuse other’s links/contents to increase diversity and increase anonymity. put your related contents among them.\nemail marketing is quantity over quality. know your customers’ preferences and behaviors (language, country, life schedule (by year? month? week? time in a day?)) by linking their accounts on other platforms, telemetry.\nemail bulk senders are equipped with email templates, statistics (like opened or not, click data monitoring)\nvary your email style and content unless you want to get blocked/trashed by servers\n\nemail templates\npremail is an easy-to-use component-based build system for MJML, the email templating language"
  },
  {
    "objectID": "posts/4ac5870e-e5e2-446c-b893-5bf62f098576/index.html#sms",
    "href": "posts/4ac5870e-e5e2-446c-b893-5bf62f098576/index.html#sms",
    "title": "email scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT",
    "section": "SMS",
    "text": "SMS\n\nsending SMS\n发送短信 邮件 第一步是收集目标的邮箱和手机号码 收集目标ID 可从社工库中获取 可以根据社工的metadata决定推送内容类别\n\nSMS flooding\nsmsboom by whalefall 远程获取的api 不知道是干啥的 有待研究 这个的原理是收集了大量发验证码到目标的手机号的api repo转移到了openethan下面 考虑破解这些网站 获取它们的短信验证所需要的credential https://github.com/WhaleFell/SMSBoom\n\n\nsending SMS with content\nsend sms 1 per day per ip (you might use tor to do ip switching): https://textbelt.com/ https://github.com/HACK3RY2J/Anon-SMS https://github.com/typpo/textbelt\nfreesms: (don’t work for my phone number as recipient though, but I found some interesting projects on github relating to free SMS sending, some using OCR to crack captcha and access API) https://www.afreesms.com/freesms/\nyoy might want phone number lists for sending ads via free sms providers\nshows [number]@139.com is the only email2sms gateway in china https://email2sms.info\nlist of email2sms providers: https://www.howtogeek.com/howto/27051/use-email-to-send-text-messages-sms-to-mobile-phones-for-free/ http://www.mutube.com/projects/open-email-to-sms/gateway-list/ http://en.wikipedia.org/wiki/List_of_carriers_providing_Email_or_Web_to_SMS\n\n\n\nreceiving SMS\n\npaid sms receiving\n5sim paid sms receive service worldwide\n\n\nfree sms receiving\nsms auto regist is written in go, utilizing yunjiema.top for sms receiving\nonline sms receivers are not so reliable (not even usable for yahoo registration), and those found from google searches (like free receive sms (这个网站有反js调试 打开debugger自动暂停执行), which has simple interface for fetching data, and you can search this site on github to get more sources and potential API adaptors like disposable phonebook) have chances to get registered yahoo accounts."
  },
  {
    "objectID": "posts/4ac5870e-e5e2-446c-b893-5bf62f098576/index.html#account-registration-helpers-verification-captcha-solving-proxies",
    "href": "posts/4ac5870e-e5e2-446c-b893-5bf62f098576/index.html#account-registration-helpers-verification-captcha-solving-proxies",
    "title": "email scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT",
    "section": "account registration helpers: verification, captcha solving, proxies",
    "text": "account registration helpers: verification, captcha solving, proxies\naccount generator helper including:\nTemp email services\nReceive SMS\nGenerate data\nProxy parser\nCaptcha solving\n\nproxies\nProxy-Cheap pay by data amount"
  },
  {
    "objectID": "posts/5f3c46c8-1def-4385-82f8-386589d02a96/index.html",
    "href": "posts/5f3c46c8-1def-4385-82f8-386589d02a96/index.html",
    "title": "dubbo and python xmlrpc",
    "section": "",
    "text": "dubbo and python xmlrpc\nthey are both remote procedure calls.\nyou can ship things across internet, but remember it can’t be some “native” structure like numpy array.\npython xmlrpc tutorial and xmlrpc.server mentions c2 wiki which you have scraped before. where is it, along with all other things you have scraped? believe it is in that AGI directory since you are such an archivist at that time.\ntutorials on how to detect if dubbo services are working normally:\nbasically they use native java methods or telnet protocol with python\nhttp://www.shouhuola.com/q-23671.html https://www.yisu.com/zixun/576879.html https://www.cnblogs.com/leozhanggg/p/14176752.html https://www.bilibili.com/read/cv13670275/ http://www.zztongyun.com/article/article-1-1.html (open with elinks to prevent ads)"
  },
  {
    "objectID": "posts/9f9b08eb-241c-4e63-9089-3bb6a2ab2b88/index.html",
    "href": "posts/9f9b08eb-241c-4e63-9089-3bb6a2ab2b88/index.html",
    "title": "docker usage issues",
    "section": "",
    "text": "docker usage issues\nlogin mysql with empty password then execute command to make it remotely available:\nmysql -uroot --password= -e \"grant all privileges on *.* to root@'%' identified by '' with grant option; commit;\"\ncreate volume and attach volume to container, since containers will be reset after system restarts.\ndocker volume create &lt;volume_name&gt;\ndocker run -it -d --rm -v &lt;volume_name&gt;:&lt;container_mountpoint&gt; --name &lt;container_name&gt; &lt;image_name&gt;\ndocker volume inspect &lt;volume_name&gt; # get info on created volume\nwhen using mindsdb, it sucks because having bad pypi mirrors.\nset pip index url globally:\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\nor pass it as environment variable:\ndocker run -it -d -e PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple -n &lt;container_name&gt; &lt;image_name&gt;\nif you want to save container states into images, use docker commit &lt;container_name&gt; &lt;image_name&gt;[:image_tag]\nKeep in mind that the docker commit command only saves the changes made to a container’s file system. It does not save any changes made to the container’s settings or network configurations. To save all changes made to a container, including settings and network configurations, you can use the docker export and docker import commands instead.\nwhen exporting ports, if not specifying host ip, you cannot reach the service inside the container. do this instead: docker run -p 0.0.0.0:&lt;host_port&gt;:&lt;container_port&gt; &lt;rest_commands&gt;\nit seems to be the proxy (fastgithub). disable http proxy so we can connect to container again, or use clash to make rules to let “localhost” or subnet requests passing through.\nif you want to change ip routings or some other configurations passed when docker run, you need to change the file called hostconfig.json located in /var/lib/docker/containers/&lt;container_id&gt; with PortBindings sections. you stop the container first. find and change the config file then start it. tutorial\nseems not working. fuck.\n\n\"PortBindings\": {\n    \"80/tcp\": [\n        {\n            \"HostPort\": \"8080\"\n        }\n    ],\n}\ncontainers can only contact each other if they share the same network. better give unique ip for each container within same network. it can also use container name as host name instead of static ip. tutorial\ncreate a network (not overlapping with anything shown in ifconfig, notice the subnet mask):\ndocker network create --subnet=172.18.0.0/16 &lt;network_name&gt;\nstart container with given network (again not overlapping with addresses in ifconfig, not the starting address):\ndocker run --rm -d -it --net &lt;network_name&gt; --ip &lt;ipaddress&gt; --name &lt;container_name&gt;\nto check what ip the container is at:\ndocker inspect &lt;container_id/container_name&gt; | grep IPAddress\nnow you might can talk to the container without port mappings."
  },
  {
    "objectID": "posts/5ed6c7cf-51d1-4d3c-92a9-25007f974296/index.html",
    "href": "posts/5ed6c7cf-51d1-4d3c-92a9-25007f974296/index.html",
    "title": "differential equations: ODE (Ordinary Differential Equation), SDE (Stochastic Differential Equation), DDE (Delay Differential Equation), DAE (Differential Algebraic Equation)",
    "section": "",
    "text": "differential equations: ODE (Ordinary Differential Equation), SDE (Stochastic Differential Equation), DDE (Delay Differential Equation), DAE (Differential Algebraic Equation)\nODEs, SDEs, DDEs, and DAEs are types of mathematical models used to describe various systems and processes in different fields such as physics, engineering, economics, and many others.\nODE (Ordinary Differential Equation) represents a relationship between an unknown function and its derivatives. It is a mathematical description of how a quantity changes with respect to one independent variable. ODEs are used to model physical systems where the rate of change of a state variable can be expressed as a function of the state itself.\nSDE (Stochastic Differential Equation) is a type of differential equation that contains a random term, which accounts for the uncertainty or randomness in the system being modeled. SDEs are used to model systems where the rate of change of a state variable is not only a function of the state but also of a random process.\nDDE (Delay Differential Equation) is a type of differential equation where the current state of a system depends not only on its present values but also on the values of the state in the past. DDEs are used to model systems where there is a delay between the time a change occurs and its effect on the state of the system.\nDAE (Differential Algebraic Equation) is a type of mathematical model that combines aspects of differential equations and algebraic equations. DAEs are used to model systems where the equations of motion cannot be expressed solely in terms of derivatives of the state variables.\nIn conclusion, these types of models are used to describe and analyze complex systems by mathematically representing the relationships between variables and their derivatives, and they are crucial in many fields to make predictions and understand the behavior of various systems."
  },
  {
    "objectID": "posts/9777957a-5e02-465b-b334-7ff67a1fd626/index.html",
    "href": "posts/9777957a-5e02-465b-b334-7ff67a1fd626/index.html",
    "title": "deepl免费翻译 免费白嫖",
    "section": "",
    "text": "deepl免费翻译 免费白嫖\nheroku no longer provides free tiers (dyno)\nchange ip frequently by using proxychains and clash\nRELEASES STILL VISIBLE HERE\nyou can google for it. maybe the internet archive has it. https://github.com/zu1k/deepl-api-rs/releases/download/0.1.2/deepl-aarch64-unknown-linux-musl-0.1.2.gz https://github.com/zu1k/deepl-api-rs/releases/download/0.1.2/deepl-x86_64-unknown-linux-musl-0.1.2.gz for other triplets i am not so familiar so i cannot guess that out.\n从zu1k的文章来看 应该是搞安全的\n为了更准确的翻译， deepl的API是很重要的 但是这个deepl却不让免费用 网页端的js复杂的要死\ndeepl的客户端的现在分为3类： - 免费 自动操控浏览器 - 付费 申请api - 免费 破解交互协议\n为了连续使用deepl以及其他可能会封ip的翻译软件 使用clash做代理是很关键的 如何找到好的代理 zu1k有proxypool可以自动爬取代理 同时推荐大佬的proxypool 据说是专业爬虫架构\nzu1k本人下架了deepl的docker镜像 但是release现在居然还可以下载 只不过不可以直接访问页面罢了\nzu1k的copy translator连接的应该就是他自己写的deepl-rust服务器 只不过现在没法访问了 (话说大佬没事翻译个啥又不是看不懂 hhh) 历史的release版本中有连接本地的版本 估计也没有开源原来的docker破解deepl的二进制\ndeeplx在 heroku上面运行 目前应该不能正常运行 它的ip感觉是被封了 它的仓库用的是现在没法访问的deepl的docker镜像\n有人（很可能就是zu1k）破解了deepl客户端的交互逻辑 应该是windows的deepl协议（c#好破解 没加壳） 现在可以看看是如何破解的\n\n安全不仅仅是一门朴素的学问，更是一门权衡的艺术。有时一个简单的设计可以规避掉大多数攻击问题，下面分享一篇在网上看到的DeepL API的反爬设计。\n这篇博文本应该在去年完成 DeepL 客户端逆向的时候发布，但考虑到相关细节一旦公开，恐怕会被广泛采用而被 DeepL 官方封杀，因此迟迟未开始。前段时间我发布了 DeepL Free Api 的 Docker 镜像，也在 GitHub 上公开了相关二进制程序，就下载量来看已经有不少人在使用了，相信 DeepL 不久就会有动作，因此我认为现在已经可以公开相关细节。\n我逆向的是 DeepL 的 Windows 客户端，因为是 C# 开发依附于 .net，也未进行任何混淆和加壳，可以轻松逆出源码。通过前段时间与一些其他研究者交流，我认为已经有不少感兴趣的同学也进行了逆向，也许是一种默契，都害怕 DeepL 在发觉后进行修改，所以大家也都没有对外公开，目前网络中搜不到任何相关的内容。本文的目的是给相关小伙伴一点思路，不过希望大家还是不要直接公开代码，以继续欺骗 DeepL，让其相信还没有人发现他们的把戏。\n在我实现 DeepL Free Api 的过程中，我发现 DeepL 并没有像之前见到的一些接口设计那样，通过签名等手段来避免接口滥用，相反，他们使用了一些欺骗战术来混淆视听，从而尝试让抓包分析者放弃，本文将围绕此进行讨论。\n过程 进入研究生阶段，为了方便阅读论文，为自己开发了划词翻译工具，在众多翻译引擎中 DeepL 的效果尤为出色。DeepL 官方的 Api 需要绑定信用卡进行认证，但其并未在中国大陆经营业务，所以并不支持国内的信用卡。我也尝试过从淘宝购买别人用国外信用卡认证过的帐号，价格贵不说，在没有滥用的情况下，DeepL 在两个月内封禁了我的帐号，因此我决定用一些其他手段。\n考虑到 DeepL 有提供免费版本的翻译服务，支持 Web，Windows、Android 和 iOS 都有相应的客户端，我便想使用这些客户端使用的免费接口。不出所料，在广泛使用打包和混淆技术的当下，DeepL 的 Web 端 js 代码也不是人看的东西，但通过简单的抓包，我发现其接口参数非常清晰，根本没有额外的签名、token等认证技术，我觉得自己又行了，几行 Python 代码便完成了接口对接工作。\n但测试下来，我发现当修改翻译内容，有极大概率遇到 429 Too many requests，并且一旦出现 429，后续的所有请求便都是 429 了。\n{\n    \"jsonrpc\": \"2.0\",\n    \"error\":{\n        \"code\":1042902,\n        \"message\":\"Too many requests.\"\n    }\n}\n在 GitHub 搜索之后，我发现已经有前人尝试利用过 DeepL 的免费接口了，早在 2018 年他们就已经遇到了这个 429 问题，并且到现在都没有解决。\n我尝试转向客户端的免费接口，苹果设备可以轻松 MITM，于是我便在 iPad 上对 DeepL 客户端进行抓包，让我意想不到的是，客户端的请求竟然比 Web 端的简单不少，接口参数数量仅有必须的几个，非常有利于利用。于是我又觉得自己行了，两三行 Python 代码完成接口对接。\n简单测试，我又傻眼了。伪造的请求明明跟客户端发起的完全相同，但只要一更换翻译的内容，返回马上就变成 429。干！我都开始怀疑自己了。\n{\n    \"jsonrpc\": \"2.0\",\n    \"method\": \"LMT_handle_texts\",\n    \"params\": {\n        \"texts\": [{\n            \"text\": \"translate this, my friend\"\n        }],\n        \"lang\": {\n            \"target_lang\": \"ZH\",\n            \"source_lang_user_selected\": \"EN\",\n        },\n        \"timestamp\": 1648877491942\n    },\n    \"id\": 12345,\n}\n你自己看看，这个接口多么清楚明白，但怎么就伪造不了呢？\n我想了又想，这里面也就 id 比较可疑，因为这个参数我不知道它是怎么生成的，是随机的还是根据某种规则计算出来的，我们无从知道。但从目前结果来看，随机的 id 无法被服务器认可。\n当然，我也考虑过其他的服务端判断滥用的方法，例如某些 http 头、ssl 层面的方法（例如之前 Go 实现中 SSL 协商过程中加密算法的顺序等），我也想办法进行了伪造，可就是不行。疲惫了，不想搞了。\n第二天，突然想起他的 Windows 客户端，稍微一分析惊喜的发现是 C#，还没加壳，果断扔进 dnSpy，发现也没混淆，真是柳暗花明又一村啊。分析之后，也就一切都清楚明白了，原来 DeepL 根本一开始就在想方设法让你觉得你行啊。\n看前面那个接口的参数，我之所以觉得我行，就是因为这个接口它太简单了。接口的参数少，参数含义又非常明确，它并不像某些厂那样用一些不知所以然的缩写，这里的每一个参数，它的名称都在告诉我它的含义、它是干什么的以及它是怎么生成的。\njsonrpc 是版本号，method 是方法，一个固定的字符串。params 里面 texts 是多段待翻译的文本，lang 里面是翻译的语言选项，是枚举类型。timestamp 是 UNIX 风格的时间戳，id 就是序号。大眼一看，这里面只有 id 是最可疑的，这也确实是我最初犯的错误。\n真相 现在我来告诉你，DeepL 到底是怎么认证的。（下面并不是 DeepL 客户端的代码，是我写的 Rust 利用代码，但逻辑不变）\nfn gen_fake_timestamp(texts: &Vec&lt;String&gt;) -&gt; u128 {\n    let ts = tool::get_epoch_ms();\n    let i_count = texts\n            .iter()\n            .fold(\n                1, \n                |s, t| s + t.text.matches('i').count()\n            ) as u128;\n    ts - ts % i_count + i_count\n}\n哈哈！没想到吧！人家的时间戳不是真的！\nDeepL 先计算了文本中所有 i 的数量，然后对真正的时间戳进行一个小小的运算 ts - ts % i_count + i_count，这个运算差不多仅会改变时间戳的毫秒部分，这个改变如果用人眼来验证根本无法发现，人类看来就是一个普通的时间戳，不会在意毫秒级的差别。\n但是 DeepL 拿到这个修改后的时间戳，既可以与真实时间对比(误差毫秒级)，又可以通过简单的运算（是否是 i_count 的整倍数）判断是否是伪造的请求。真是精妙啊！\n还有更绝的！你接着看：\nlet req = req.replace(\n    \"\\\"method\\\":\\\"\",\n    if (self.id + 3) % 13 == 0 || (self.id + 5) % 29 == 0 {\n        \"\\\"method\\\" : \\\"\"\n    } else {\n        \"\\\"method\\\": \\\"\"\n    },\n);\n怎么样？我觉得我一开始就被玩弄了，人家的 id 就是纯粹的随机数，只不过后续的请求会在第一次的随机 id 基础上加一，但是这个 id 还决定了文本中一个小小的、微不足道的空格。\n按照正常的思路，为了方便人类阅读和分析，拿到请求的第一时间，我都会先扔编辑器里格式化一下 Json，我怎么会想到，这恰恰会破坏掉人家用来认证的特征，因此无论我如何努力都难以发现。\n总结 在我以往的经验中，接口防滥用，要不就是用户专属的 token，要不就是对请求进行签名或者加密，这些对抗滥用的方法都是明面上的，就是明白告诉你我有一个签名，怎么签的，你去分析去吧，但是我代码混淆了，你看看你是要头发还是要算法。\n要不就是高级点的，更具技术性的，利用某些客户端特有的实现造成的特征进行认证，我印象中最深刻的就是 Go 的 SSL 协商过程中的算法顺序。这类方法要求更高的技术，当然分析起来也肯定更加困难，并且找到这样一种方法本身也不容易。\n从 DeepL 的方法中，我找到了另外一种思路。利用人心理的弱点，一开始让其感觉非常简单，但是无论如何都无法得到想要的结果，给分析者造成心理上的打击和自我怀疑，让其浅尝辄止自行放弃分析。同时利用人行为上的惯式，使其自行破坏掉某些关键信息，从而给分析造成难以发现的阻碍。\n原来，除了技术以外，还有这样一条道路啊，真是有趣！"
  },
  {
    "objectID": "posts/e3cbcf29-0e9e-46f3-8f62-aa290103b133/index.html",
    "href": "posts/e3cbcf29-0e9e-46f3-8f62-aa290103b133/index.html",
    "title": "Unlocking the Power of AI: Exploring Deep Learning Datasets and Resources",
    "section": "",
    "text": "datasets for deeplearning, classification and evaluation\n100 audio and video datasets\nvideo datasets\nyoutube8m"
  },
  {
    "objectID": "posts/7c329793-2fcd-4ecc-a697-17ca1d2f6ea2/index.html",
    "href": "posts/7c329793-2fcd-4ecc-a697-17ca1d2f6ea2/index.html",
    "title": "dark web search engine",
    "section": "",
    "text": "dark web search engine\nOnionSearch commandline all-in-one darknet search tool, install via pip3 install onionsearch (of course you need proxy)\nSupporting:\nahmia\ndarksearchio\nonionland\nnotevil\ndarksearchenginer\nphobos\nonionsearchserver\ntorgle\nonionsearchengine\ntordex\ntor66\ntormax\nhaystack\nmultivac\nevosearch\ndeeplink\nhttps://dark.link/torch-darkweb-search-engine-links/\ndarknethub\nonion.live list and search popular onion sites by name\nhttps://darkweblinks.com/#Open-Source-Software\nThe onion dir\nlinks are subjected to change or take down.\nahmia\nthe uncensored hidden wiki\ntor links\nparazite\ntorch\nnot evil\nhaystack one of the biggest\ncandle"
  },
  {
    "objectID": "posts/0261b683-af69-4dd7-84af-b92d68638223/index.html",
    "href": "posts/0261b683-af69-4dd7-84af-b92d68638223/index.html",
    "title": "ctf related",
    "section": "",
    "text": "ctf related\nctfhub\nctftime\nctf-tools by ctfwiki"
  },
  {
    "objectID": "posts/8d325188-2bf6-4419-ba4f-ccfac36539b8/index.html",
    "href": "posts/8d325188-2bf6-4419-ba4f-ccfac36539b8/index.html",
    "title": "copyright issues circumvention",
    "section": "",
    "text": "copyright issues circumvention\nonly mention sources from major leagues (#fans &gt; 5k) mention the bgm you are using"
  },
  {
    "objectID": "posts/295eecb4-e6da-437c-97f1-0b55851b5454/index.html#webpage-dumps",
    "href": "posts/295eecb4-e6da-437c-97f1-0b55851b5454/index.html#webpage-dumps",
    "title": "comprehensive page dump from multiple devices",
    "section": "Webpage dumps",
    "text": "Webpage dumps\nuse “bookmark all tabs” or “copy all tab urls” browser extension, or your OG lazero extension\n\nmacOS\ncheck for “Comprehensive Research” series\n\nyou can only bookmark all tabs and tab groups within a single window.\nfor example, if you have two windows open, you need to do it twice to save all links to your computer.\n\n\nKali\ncheck “Healthcare and Watch Cases” under firefox bookmarks.\n\n\nAndroid\nto install a plugin on kiwi browser, you (maybe) need to unpack and install it manually.\nyou need chrome extension v3 or below. pack the extension manually if needed. must install from .crx file.\nquery: site:github.com chrome copy all tabs\nuse this or this or this.\nif you want markdown-style, use this or this or this (you need to modify this as it is the only hope now) or this. query: site:github.com chrome copy all tabs markdown.\nyou click every tab manually, in order to copy them. goddamn the android!\n\nfor firefox, you search in the official addon store.\n\nclipboard data and tab records dumped at ~/works/modifier_clipboard_and_browser_tabs_dumps\n\nremember to clean up the damn phone. it is running way too slow."
  },
  {
    "objectID": "posts/e3588d40-2a05-411c-b172-074638635ca2/index.html",
    "href": "posts/e3588d40-2a05-411c-b172-074638635ca2/index.html",
    "title": "Mastering Command-Line Tools for JSON/HTML Filtering and Formatting",
    "section": "",
    "text": "commandline json/html filter and formatters\nfor hackers, filtering matters.\njq\njqterm online jq repl\nhtmlq is for querying html with selectors, extracting text from html\npup download from release\none must collect a handful set of regular expression/filters to do hacking\nsearching, regex, two most important things for hackers. it’s not about blindly collecting data. it’s power and knowledge."
  },
  {
    "objectID": "posts/357e32b3-452a-4c0d-a9e4-8b4ac805ecc8/index.html#general-introduction",
    "href": "posts/357e32b3-452a-4c0d-a9e4-8b4ac805ecc8/index.html#general-introduction",
    "title": "download/collect info of hack tools",
    "section": "general introduction",
    "text": "general introduction\nthis is about information gathering, so you might learn how to scrape AI models, AI notebooks, tutorials, code snippets from websites/search engines/social media as well.\ngiven the name of the hack tool, you may not be able to tell what the tool is (written in python? hosted on github? online tool?) and you want to use search engine to find possible entries. you may take snapshots on these pages and index them.\nif the hack tool is linked to some website/manual, you can index the website. if you find it inside some package index or package manager, you will know how to install the package.\nyou may miss the wiki, forum, tutorials. you know where to get them.\nhere are few sources where you can learn things from:\ndarknet.org.uk where you learn hacking and hack tools\nnull byte in wonderhowto\nyou also have brew sdkman macport pkgsrc chocolatey scoop winget snap portage conda flatpak rpm urpm yum cargo dnf indexes and more to scrape. maybe it is time to improve your searching skill? (select few web domains you want to learn things from, then perform the query, still you have to deal with keywords generation and site selection)\ncyborg hawx linux, backtrack linux may join the parade.\nfor language specific package indexs, we have hackage CPAN CRAN crates.io and more (where are package indexes for C C++ Pascal BASIC assembly lisp prolog lua and more? visit awesomeopensource then use combined topics to find package managers for c and more. you also have libraries.io to monitor libraries across all package managers). just check tuna mirror site and get a view on that. you may want a network directory traversal tool akin to find in local filesystem, without downloading anything “binary” but just logging all possible urls for you to inspect. (with file size)\nafter all these information collecting, you must categorize them (topic modelling), retrieve info when needed (semantic searching? recommendation? dialog based GPT?). you may find many things not obviously a hack tool but in general fit well into specific needs.\nwith all packages being scraped, you need to deduplicate it a little bit, either by name or homepage."
  },
  {
    "objectID": "posts/357e32b3-452a-4c0d-a9e4-8b4ac805ecc8/index.html#case-specific",
    "href": "posts/357e32b3-452a-4c0d-a9e4-8b4ac805ecc8/index.html#case-specific",
    "title": "download/collect info of hack tools",
    "section": "case specific",
    "text": "case specific\n\ngithub\nrepo named with “awesome” means this is a collection of handpicked resources\nyou will find github links on web, social media, instant messaging and forums\nScraper scrape popular github repositories every day\ngitsuggest recommend github repos\nHow to Use the GitHub API to List Repositories\nPyGithub use python to automate github api v3\nif you want all README pages on github, you first need to collect all github repo urls. you may also collect info on github repos (OSINT). you can retrieve all repos link to given user with github api (quota limited). you can search github on github or search engine with some juicy/promising keywords then collect repo name, username, keywords, repeat the search.\nthere are few github repo archives avaliable for download. the github archive program packed many repos to arctic, the list is called Greatest Hits\ngharchive provides many websites for monitoring github repos, though stopped archiving since 2016\n\n\nkali, parrot\nkali tool list pages\ncurl https://en.kali.tools/all/ &gt; kali_tools_all.html # more tags, more categories, the same as blackarch?\ncurl https://www.kali.org/tools/ &gt; kali_official.html\ncurl https://en.kali.tools/ &gt; pentest_tools_with_name.html\nkali meta page on web\nkali meta page on package index\nkali package index\nnotice kali official “offsec” provides training courses and materials as apt packages. the list:\noffsec-awae/kali-rolling 2021.1.2 amd64\n  Resources for OffSec's AWAE/WEB-300\n\noffsec-awae-python2/kali-rolling 2021.1.2 amd64\n  Python 2 resources for OffSec's AWAE/WEB-300\n\noffsec-exp301/kali-rolling 2021.1.2 amd64\n  Resources for OffSec's WUMED/EXP-301\n\noffsec-pen300/kali-rolling 2021.1.2 amd64\n  Resources for OffSec's ETBD/PEN-300\n\noffsec-pwk/kali-rolling 2021.1.2 amd64\n  Resources for OffSec's PWK2/PEN-200\nthese two OSes are for pentesting, using apt as package manager. but parrot does not provide tool introductions.\nget all package names:\napt list\nyou can retrieve package information in apt command, like:\napt show &lt;package_name&gt;\nyou will get homepage link and package description if you want package dependencies you will also have it.\nusing apt one can retrieve package infos with simple command. find main metapackages like parrot-tools-full (parrot) and kali-linux-everything (kali) first, then retrieve dependency trees.\nparrotos has index.db which you can retrieve info from there, or “Packages” for general debian package index, or anything you think is metadata.\n\n\nchocolatey\nnote: deprecated since v2.0, can only be used to list local packages\nchoco list\n\n\nblackarch\nblackarch is based on archlinux, which has both official repo and user provided packages repo (AUR). the syntax is almost the same for pacman and yaourt to retrieve all available info of packages.\nmaybe you want to retrieve package information with pacman.\nlist all package information just like apt, description, dependencies, homepage and more.\npacman -Si\nuse some parser?\nfor aur repos, use yay or yaourt.\nyaourt -Si\nyou may use dependencies to deduce relationship between packages, use description, man pages, wiki, manual and tutorials to understand the usage of packages.\ndownload main blackarch tool list:\ncurl https://www.blackarch.org/tools.html &gt; tools.html\n\n\nalpine\nalpine linux is able to download man page alone without installing package\napk list -I | sed -rn '/-doc/! s/([a-z-]+[a-z]).*/\\1/p' | awk '{ print system(\"apk info \\\"\"$1\"-doc\\\" &gt; /dev/null\") == 0 ? $ \"-doc\" : \"\" }' | xargs apk add\n\n\npypi/pip\ni remember you have scraped tsinghua pypi index, containing many python tools.\nretrieve python package info as json: https://pypi.org/pypi/&lt;package-name&gt;/json\nvisit pypi simple index to get all package names. but the info is clearly on the other page. you retrieve this from pypi. use the below commandline tool?\npypi [information|description] &lt;package_name&gt;\ndocumentation url is provided separately from mainpage.\ncommandline tool for searching in pypi\ninstall it, then run:\npypi search &lt;query&gt;\nit also provides “read-the-docs” to search in documentation of a package, detailed info\n\n\nnuget\nwe can search in cli tool (not dotnet nuget (installed with dotnet sdk) but nuget (installation guide)) and web interface.\nlist all packages:\nnuget list\nget package information:\nnuget list &lt;packageName&gt; -Verbosity detailed\nquery all package information without nuget\nthe web interface seems allowing us to do some traversal on the parameter: https://www.nuget.org/packages?page=&lt;pagenum&gt;&sortBy=relevance\nkeep in mind the pagenum cannot be too big (like 2000).\n\n\nmaven\nthere are tools for interacting with maven search api.\nyou can retrieve “pom.xml” to get package info like homepage and description.\nmaven central has archtype-catalog for retrieving all avaliable artifact names\nmaven search tools:\nmvn-search\nmcs\n\n\nhomebrew\nreading the source code and according to brew api docs i found this url is for retrieving all formula info on brew index, and this for casks.\nalso run this command for showing local cached package infos:\nbrew info --json --all\n\n\nnpm\nthere’s a repo storing up-to-date package names on github. after that, use npm-description to download description for every package.\nall-the-package-repos contains repo information (github, gitlab) of every npm package\n\n\ngem\nchange gem sources first:\ngem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/\ngem list -r really works. you just have to wait.\ngem info -r list all remote gem infos, but too slow and not working, use only one package at a time.\n\n\nmanpages\nyou can download man pages before installing package\nuse “dman” by bikeshed (not avaliable on kali, maybe on ubuntu?)\napt-get install bikeshed\nor browse manpages on web, tutorials on linux and languages\nman pages with different sections (categories)\nhierachical manpages of ubuntu\ndman for ubuntu man pages\nlocation of locally installed man pages: /usr/share/man\n\n\nvscode plugin\nweb interface for searching"
  },
  {
    "objectID": "posts/a9bf8918-eac6-4de4-8352-59b2abc2cce8/index.html",
    "href": "posts/a9bf8918-eac6-4de4-8352-59b2abc2cce8/index.html",
    "title": "Modify chrome/chromium policies from snap store",
    "section": "",
    "text": "Modify chrome/chromium policies from snap store\nuse /var/snap/chromium/current/policies/ if chrome, /var/snap/chromium/current/policies/managed/ if chromium"
  },
  {
    "objectID": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#viable-approaches-to-chatgpt",
    "href": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#viable-approaches-to-chatgpt",
    "title": "chatgpt",
    "section": "viable approaches to chatgpt",
    "text": "viable approaches to chatgpt\naccording to my point of view, chatgpt is just specialized on chat, or socialized in other words.\nthe elo rating system is the key to facebook social network, many zero-sum games. basically it is some revolution rating system. to do such rating system effectively one shall use along with classifiers and embeddings.\naccording to the training process of instructgpt and webgpt, we know that gpt has learned more by interacting with people (multiple QA), doing self-examination (learning a reward model) and performing actions (searching and quoting on web).\n\nRLHF\n\nchainer, prompt engineering\nawesome chatgpt prompts\nlangchain extending llm by advanced prompts, llm wrappers actions, databases and memories\n\n\nRL algorithms, tools for providing feedback\nAwesome-RLHF paper and code about RLHF\nopenai baselines\nstable-baselines 3\nSetFit Efficient few-shot learning with Sentence Transformers, used by FewShotRLGPT (no updates till now?)\n\n\nRLHF models\n\nnon-language models\nimage_to_text_rlhf\nalgorithm-distillation-rlhf\n\n\nlanguage models\nchatrwkv pure rnn language model, with chinese support\nlamda-rlhf-chatgpt\nblenderbot2 a bot which can search internet, blenderbot3 is US only. install ParlAI then clone ParlAI_SearchEngine. tutorial\npromptCLUE based on T5, created by clueai, trained on pCLUE\nopenassistant\nopenchatgpt-neox-125m trained on chatgpt prompts, can be tested here, trained from pythia\ncopycat chatgpt replicate\nmedicine-chatgpt shit sick of COVID-19\nbaby-rlhf both cartpole and languge model\nrlhf-shapespeare\ntextrl 100+stars\nPaLM-RLHF claims RETRO will be integrated soon?\nRL4LMs with multiple rl methods\nminRLHF\nwebgpt-cli interface openai api to browse web and answer questions\nlm-human-preferences by openai\nrlhf-magic using trlx (supports GPT3-like models) which has PPO and ILQL (as trainable model)\ntrl only has PPO on GPT2\nTk-Instruct T5 trained on natural instruct dataset. is it trained on RLHF systems?\n\n\n\n\ndatasets\nwhisperhub collection of chatgpt prompts by plugin\nhh-rlhf\ninstructgpt samples\nnatural instructions\n\n\ndataset building tools\nopen-chatgpt-prompt-collective\ncrowd-kit purify noisy data\npromptsource\n\n\nreward models\nrankgen scores model generations given a prefix (or prompt)\nelectra-webgpt-rm and electra-large-reward-model is based on electra discriminator\n\n\nGPT3-like models\ngalactica is opt trained on scientific data\nbloomz and mt0 trained on xP3 (multilingual prompts and code)\nT0PP T0 optimized for zero-shot prompts, despite much smaller than GPT-3\nRETRO another model with GPT-3 capabilities with fewer parameters?\ngpt3 is gpt2 with sparse attension, which enables it to generate long sequence\nDiffusion-LM\nPaLM\nmetaseq provides OPT, which is basically GPT3\nGPT-JT altered in many ways, trained on natural instructions huggingface space\nGPT-Neo\nGPT-J\nGPT-NeoX\nBloom large language model by bigscience\n\n\nautonomous learning\nautonomous-learning-library doc and repo\nGu-X doing god-knows-what experiments"
  },
  {
    "objectID": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#analysis-about-how-to-make-such-model",
    "href": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#analysis-about-how-to-make-such-model",
    "title": "chatgpt",
    "section": "analysis about how to make such model",
    "text": "analysis about how to make such model\ngpt3 is capable of imitation (cause it is unsupervised.)\nbut! if you want to get things done (when you really need it!), you better want some aligned AI.\ntwo similar models by openai: webgpt and instructgpt\n\nabout instructgpt\nit is first fine-tuned on supervised datasets, then train some reward model, then use the reward model to handle prompts and do reinforcement learning with PPO.\n\n\ndetails on webgpt environment\nguess: create states by performing actions, then generate templates to allow model filling blanks.\nOur text-based web-browsing environment is written mostly in Python with some JavaScript. For a\nhigh-level overview, see Section 2. Further details are as follows:\n\n• When a search is performed, we send the query to the Microsoft Bing Web Search API, and\nconvert this to a simplified web page of results.\n\n• When a link to a new page is clicked, we call a Node.js script that fetches the HTML of the\nweb page and simplifies it using Mozilla’s Readability.js.\n\n• We remove any search results or links to reddit.com or quora.com, to prevent the model\ncopying answers from those sites.\n\n• We take the simplified HTML and convert links to the special format\n【&lt;link ID&gt;†&lt;link text&gt;†&lt;destination domain&gt;】, or\n【&lt;link ID&gt;†&lt;link text&gt;】 if the destination and source domains are the same. Here,\nthe link ID is the index of the link on the page, which is also used for the link-clicking\ncommand. We use special characters such as 【 and 】 because they are rare and encoded\nin the same few ways by the tokenizer, and if they appear in the page text then we replace\nthem by similar alternatives.\n\n• We convert superscripts and subscripts to text using ^ and _, and convert images to the\nspecial format [Image: &lt;alt text&gt;], or [Image] if there is no alt text.\n\n• We convert the remaining HTML to text using html2text.\n\n• For text-based content types other than HTML, we use the raw text. For PDFs, we convert\nthem to text using pdfminer.six. For all other content types, and for errors and timeouts, we\nuse an error message.\n\n• We censor any pages that contain a 10-gram overlap with the question (or reference answer,\nif provided) to prevent the model from cheating, and use an error message instead.\n\n• We convert the title of the page to text using the format &lt;page title&gt; (&lt;page domain&gt;).\nFor search results pages, we use Search results for: &lt;query&gt;.\n\n• When a find in page or quote action is performed, we compare the text from the command\nagainst the page text with any links stripped (i.e., including only the text from each link).\nWe also ignore case. For quoting, we also ignore whitespace, and allow the abbreviated\nformat &lt;start text&gt;━&lt;end text&gt; to save tokens.\n\n• During browsing, the state of the browser is converted to text as shown in Figure 1(b).\nFor the answering phase (the last step of the episode), we convert the question to\ntext using the format &lt;question&gt;■, and follow this by each of the collected quotes\nin the format [&lt;quote number&gt;] &lt;quote page title&gt; (&lt;quote page domain&gt;)\n&lt;double new line&gt;&lt;quote extract&gt;■."
  },
  {
    "objectID": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#projects-related-to-chatgpt",
    "href": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#projects-related-to-chatgpt",
    "title": "chatgpt",
    "section": "projects related to chatgpt",
    "text": "projects related to chatgpt\n\nvoice assistants\nvoice assistant in cpp\nChatWaifu with anime voice, ChatWaifu with live2d\n\n\nhacking\ngive longterm memory and external resources to gpt3\nwrite backend logic with gpt\nhackgpt exploit vulnerabilities\nvulchatgpt ida plugin for reverse engineering\nchatgpt-universe things related to chatgpt\ngalgame using chatgpt\n记笔记 12.27更新了一个更精简的应用 强烈建议部署到服务器上 huggingface参考：https://huggingface.co/spaces/Mahiruoshi/Lovelive-Nijigasaku-Chat-iSTFT-GPT3 GitHub：https://github.com/Paraworks/vits_with_chatgpt-gpt3 地址：https://drive.google.com/drive/folders/1vtootVMQ7wTOQwd15nJe6akzJUYNOw4d?usp=share_link 你可以先尝试在服务器上部署，之后可以直接解压进文件夹后运行exe（mac、安卓端需要用renpy自行编译） 去https://beta.openai.com/account/api-keys获取api-key 参数照着敲就好了 人物id通常是从0开始的数字，我的模型最大到12 api部署方法：把inference_api.py放入你的vits目录下，进入文件修改config和checkpoint.pth的路径，比起应用程序来说十分简单，可以自行设计。码龄三个月写出的的雪山代码警告 —————————————————————————————————————————————————— Chatgpt部署方法已于12.26更新（视频后部分） vits参考：https://github.com/CjangCjengh/vits 服务器端建议用ISTFT VITS：https://github.com/innnky/MB-iSTFT-VITS model库：https://github.com/CjangCjengh/TTSModels 也可以用我的https://huggingface.co/spaces/Mahiruoshi/MIT-VITS-Nijigaku CHATGPT参考：https://github.com/rawandahmad698/PyChatGPT 示例视频（纯服务器api，gpt3）https://www.bilibili.com/video/BV1hP4y1B7wH/?spm_id_from=333.999.0.0&vd_source=7e8cf9f5c840ec4789ccb5657b2f0512 穗乃果配音来自缪斯的模型﻿@Freeze_Phoenix gpt3加载参考﻿@ぶらぶら散策中\nchatgpt use cases curated list\nDAILA use chatgpt to identify function calls in decompiler\nawesome transformer language models a huge collection on transformer based LMs, huge models by megacorps, with some introduction and analogy on chatgpt\nhuggingface blog on RLHF containing similar projects and source code\nbilibili sends me lots of videos (and articles) on hacking and ai (including chatgpt) via its android app. recommend you to scrape this source and collect transcription and screenshots for searching and content generation.\nb站有做免杀 绕过杀软的\nchatgpt原理解析\nchatgpt对接搜索引擎\n下载链接: github: https://github.com/josStorer/chat-gpt-search-engine-extension/releases/ 百度网盘: https://pan.baidu.com/s/1MnFJTDIatyIIPr5kUMWsAw?pwd=1111  提取码：1111\n原项目: https://github.com/wong2/chat-gpt-google-extension 我创建的fork, 添加了多个搜索引擎支持的版本: https://github.com/josStorer/chat-gpt-search-engine-extension PR: https://github.com/wong2/chat-gpt-google-extension/pull/31\n已修复先前百度需要手动刷新的问题"
  },
  {
    "objectID": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#access-via-api",
    "href": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#access-via-api",
    "title": "chatgpt",
    "section": "access via api",
    "text": "access via api\nhttps://github.com/altryne/chatGPT-telegram-bot\nhttps://github.com/taranjeet/chatgpt-api\nhttps://github.com/acheong08/ChatGPT\nhttps://github.com/vincelwt/chatgpt-mac\nhttps://github.com/transitive-bullshit/chatgpt-api\nhttps://github.com/rawandahmad698/PyChatGPT"
  },
  {
    "objectID": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#models-like-chatgpt",
    "href": "posts/f257178a-4c2e-4a7b-ab4c-f45bbf92a14e/index.html#models-like-chatgpt",
    "title": "chatgpt",
    "section": "models like chatgpt",
    "text": "models like chatgpt\nlfqa retrival based generative QA\nlm-human-preferences by openai\ntrl Train transformer language models with reinforcement learning based on gpt2\ntrlx A repo for distributed training of language models with Reinforcement Learning via Human Feedback (RLHF) by CarperAI\nRL4LMs A modular RL library to fine-tune language models to human preferences\nPaLM-rlhf-pytorch saying this is basically chatgpt with palm\ngpt-gmlp saying this design integrates gpt with gmlps so will use less ram and can be trained on a single gpu\nWebGPT\ntk-instruct with all models by allenai can be multilingual, trained on natural instructions\nthere’s a ghosted repo named instructgpt-pytorch found in bing but no cache preserved, also an empty repo called InstructFNet wtf?\nAidMe Code and experiment of the article AidMe User-in-the-loop Adaptative Intent Detecttion for Instructable Digital Assistant\ncheese Used for adaptive human in the loop evaluation of language and embedding models.\nKelpie Explainable AI framework for interpreting Link Predictions on Knowledge Graphs\nGrIPS Gradient-free, Edit-based Instruction Search for Prompting Large Language Models\nqueakily nlp datasets cleaner\ngpt-j\nsuper big bilingual model GLM-130B\nmulti-modal deeplearning paper collections\nbloom a huge model like gpt-3\nnotice, gpt-2 is somehow inferior to gpt-3 since it has smaller model parameters\ndialogue-generation Generating responses with pretrained XLNet and GPT-2 in PyTorch.\npersonaGPT Implementation of PersonaGPT Dialog Model\nDialoGPT Large-scale pretraining for dialogue"
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#fine-tuning-and-tricks",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#fine-tuning-and-tricks",
    "title": "chatgpt clones, computer automation with ai",
    "section": "fine-tuning and tricks",
    "text": "fine-tuning and tricks\nPEFT (Parameter Efficient Fine Tuning) supports LoRA, Prefix Tuning, P-Tuning and Prompt Tuning."
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#computer-automation-with-ai",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#computer-automation-with-ai",
    "title": "chatgpt clones, computer automation with ai",
    "section": "computer automation with ai",
    "text": "computer automation with ai\n\nvirtual machines and environments\nit is not feasible to install ubuntu arm on macos m1 with virtualbox. use utm.app instead. instructions on installing ubuntu with utm includes guides on sharing clipboard and directory.\n\n\npapers\nplaying atari using q-learning (viewing deepmind paper with arxiv vanity)\n\n\nmodels\nvideo pretraining can perform minecraft diamond mining tasks with keyboard and mouse movements\ncode and model\n\nmm-cot (multimodal chain-of-thought) by amazon, with model weights\n\n\ndata collectors and controllers\nmss for screenshot, remember to save raw pixels to SSD, then compress into mp4 with ffmpeg for further training (mind the timestamp!)\n\ngo-vncdriver by openai, to compile you need to clone the repo and modify code to find headers for libjpeg-turbo and python.\nlibvncdriver\nasyncvnc (supports apple vnc), side project: asyncssh\npython-vnc-client with keydown/keyup event support\nvncdotool\npyVNC\n\npynput as input event listener and actor, listener may have some strange keycodes when pressing modifier keys on windows.\nnote that special care needed for aligning mouse location with screenshot size\n\nViT-pytorch can be used in many ViT-based models, listed and implemented in the repo.\n\n\nspaces\nopenai universe (blog post here) and starter agents, remotes are using vnc protocol and a reward protocol using websocket sending json (can send actions). they prefer TigerVNC, maybe that will send the existing monitor instead of invisible ones.\ngym is classic and modular. atari-py enables old games\nretro deprecates universe, but might help with general computer controlling AI systems since they are compatible. human don’t play games all day and night. beware of this and don’t turn the model into a heavy gamer.\nthere is no meaning of recording terminal input/output when using tools like vim. get screenshots, keystrokes and mouse clicks instead (using ttyd, gremlins.js or monkey.js). tkterminal won’t do. it is just a thin wrapper around subprocess.run\ntalking of browser, you can spin up novnc server and let the gremlins.js do its job."
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#accelerators",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#accelerators",
    "title": "chatgpt clones, computer automation with ai",
    "section": "accelerators",
    "text": "accelerators\n\ncformers\ncpu only\nable to install from pip\n\n\nggml\ncpu only\ncpp, only compile from source\n\n\nflexgen\ngpu is mandatory, better than deepspeed and Hugging Face Accelerate"
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#open-source-model-and-weights",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#open-source-model-and-weights",
    "title": "chatgpt clones, computer automation with ai",
    "section": "open source model and weights",
    "text": "open source model and weights\nawesome decentralized llm listed up-to-date related chatgpt-like repositories, datasets, model weights and resources.\n\nmodel weights of open source chatgpt alternatives:\n\n\n\nweight path\nmodel size\nmodel name\nauthor\n\n\n\n\nopenchatgpt-neox-125m\n125m\ngpt-neox\nmrsteyk\n\n\nopenchatgpt-neo-125m\n125m\ngpt-neo\nmrsteyk\n\n\n\n\nLLaMA\nit’s public.\n\n\n\nweight path\nmodel name\nauthor\n\n\n\n\nllama-13b-hf-int4\n13b\ndecapoda-research\n\n\nllama-65b-hf-int4\n65b\ndecapoda-research\n\n\nllama-30b-hf-int4\n30b\ndecapoda-research\n\n\nllama-7b-hf-int4\n7b\ndecapoda-research\n\n\nllama-30b-hf\n30b\ndecapoda-research\n\n\nllama-65b-hf\n65b\ndecapoda-research\n\n\nllama-13b-hf\n13b\ndecapoda-research\n\n\nllama-7b-hf\n7b\ndecapoda-research\n\n\nllama-smallint-pt\nunknown\ndecapoda-research\n\n\nllama-7b-hf-int8\n7b\ndecapoda-research\n\n\n\n\n\nChatYuan\nv2 is censored.\n\nmodel weights:\n\n\n\nweight path\nmodel size\nmodel name\nauthor\n\n\n\n\nChatYuan-large-v1\nunknown\nunknown\nClueAI\n\n\nChatYuan-large-v2-paddle\nunknown\nunknown\nClueAI\n\n\nChatYuan-large-v2\nunknown\nunknown\nClueAI\n\n\nChatYuan-large-v1-paddle\nunknown\nunknown\nClueAI\n\n\n\n\n\nDeepshard\nLLaMA trained on custom instruction dataset.\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ndeepshard-13B-ft\n13b\ndeepshard\nswype\n\n\ndeepshard-13B-raw\n13b\ndeepshard\nswype\n\n\n\n\n\nChatGLM\nCurrently only open-sourced 6B version.\nYou can train ChatGLM using GXT3090: simple_thu_chatglm6b\nUsing 7GB VRAM, train ChatGLM with P-tuning\nchatglm_finetuning supports loading from int4 weights\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nchatglm-6b-int4-slim\n6b\nchatglm\nsilver\n\n\nchatglm-6b-slim\n6b\nchatglm\nsilver\n\n\nchatglm-6b-int4-qe-slim\n6b\nchatglm\nsilver\n\n\nchatglm-6b-int4\n6b\nchatglm\nTHUDM\n\n\nchatglm-6b-int4-qe\n6b\nchatglm\nTHUDM\n\n\nchatglm-6b\n6b\nchatglm\nTHUDM\n\n\n\n\n\nChatDoctor\nLLaMA-65B trained on medical dataset InstructorDoctor-200k\n\n\nBELLE\n开源中文对话大模型\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nBELLE-LLAMA-7B-0.6M\n7B\nLLaMA\nBelleGroup\n\n\nBELLE-LLAMA-7B-2M\n7B\nLLaBLOOMZMA\nBelleGroup\n\n\nBELLE-LLAMA-7B-2M-gptq\n7B\nLLaMA\nBelleGroup\n\n\nBELLE-LLAMA-13B-2M\n13B\nLLaMA\nBelleGroup\n\n\nBELLE-7B-gptq\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-2M\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-0.6M\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-0.2M\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-1M\n7B\nBLOOMZ\nBelleGroup\n\n\n\n\n\nbaize\ntrained on ChatGPT self-chatting data\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nbaize-lora-30B\n30b\nbaize\nproject-baize\n\n\nbaize-lora-13B\n13b\nbaize\nproject-baize\n\n\nbaize-healthcare-lora-7b\n7B\nbaize\nproject-baize\n\n\nbaize-lora-7B\n7B\nbaize\nproject-baize\n\n\n\n\n\ndolly\nmodel arch is gpt-j, trained on alpaca dataset\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ndolly-v1-6b\n6b\ndolly\ndatabricks\n\n\ndolly-lora\nunknown\ndolly\nsamwit\n\n\n\n\n\nFastChat (Vicuna)\nweb interface\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\n\n\n\n\nvicuna\nunknown\nVicuna\n\n\nvicuna2\nunknown\nVicuna\n\n\nvicuna-13b-delta-v0\n13b\nVicuna\n\n\nvicuna-13b-GPTQ-4bit-128g\n13b\nvicuna\n\n\nggml-vicuna-13b-4bit\n13b\nvicuna\n\n\nvicuna-13b\n13b\nvicuna\n\n\nvicuna4all\n13b\nvicuna\n\n\n\ndownload official delta weights via magnet\n\n\nBloom-z\nthere is bloomz.cpp, converted model weights on huggingface\n\n\nAlpaca\nalpaca is LLaMA tuned on ChatGPT self-instruct dataset. officially there is just code and dataset, model weights are community provided.\nggml version: alpaca.cpp\nexample on how to load PEFT patched alpaca model: alpaca-lora/generate.py\nit’s better to check for python bindings and webui like Alpaca-Turbo and Dalai for further development and interactions.\n\nfine-tuning:\nsimple-llama-finetuner using LoRA, 16GB VRAM minimum\nalpaca-lora: the OG LoRA alpaca\n\ncommunity model weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nalpaca-lora-7b\n7b\nAlpaca\ntloen\n\n\nAlpaca Native\n7B\nAlpaca\nchavinlo\n\n\nAlpaca-65B\n65B\nAlpaca\nchavinlo\n\n\nAlpaca 13B\n13B\nAlpaca\nchavinlo\n\n\nGPT4-X-Alpaca\n13B\nAlpaca\nchavinlo\n\n\nToolpaca\n13B\nAlpaca\nchavinlo\n\n\ninstruct-gpt-j-fp16\n6B\nGPT-J\nnlpcloud\n\n\nalpaca-30b\n30b\nAlpaca\nbaseten\n\n\nalpaca-lora-65b\n65b\nalpaca\nchansung\n\n\nalpaca-lora-30b\n30b\nalpaca\nchansung\n\n\nkoalpaca-lora-13b\n13b\nkoalpaca\nchansung\n\n\nalpaca-lora-13b\n13b\nalpaca\nchansung\n\n\nalpaca13B-lora\n13b\nalpaca\nsamwit\n\n\nalpaca7B-lora\n7b\nalpaca\nsamwit\n\n\nbloompaca-7b1-lora\n7b\nbloom\nsamwit\n\n\ngpt4-x-alpaca-native-13B-ggml\n13b\nalpaca\nPi3141\n\n\nalpaca-native-7B-ggml\n7b\nalpaca\nPi3141\n\n\nalpaca-native-13B-ggml\n13b\nalpaca\nPi3141\n\n\nalpaca-lora-30B-ggml\n30b\nalpaca\nPi3141\n\n\nalpaca-lora-7B-ggml\n7b\nalpaca\nPi3141\n\n\nalpaca-lora-13B-ggml\n13b\nalpaca\nPi3141\n\n\nalpaca-7b-native-enhanced\n7b\nalpaca\nPi3141\n\n\ngpt4-x-alpaca-13b-native-4bit-128g\n13b\nalpaca\nanon8231489123\n\n\nggml-gpt4-x-alpaca-13b-native-4bit\n13b\nalpaca\neachadea\n\n\nalpaca-13b-hf-fp16\n13b\nalpaca\nteknium\n\n\n\n\ncodealpaca only provides dataset for training a code generation model, there are multiple models trained on this dataset, including bloom-7b1-lora-codealpaca20k\n\n\ntogethercomputer\nreleased openchatkit with retrieval ability and its huggingface space\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nGPT-NeoXT-Chat-Base-20B\n20B\nGPT-NeoXT\ntogethercomputer\n\n\nPythia-Chat-Base-7B\n7B\nPythia\ntogethercomputer\n\n\n\n\nmoderation model weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nGPT-JT-Moderation-6B\n6B\nGPT-JT\ntogethercomputer\n\n\n\n\n\nSpikeGPT\ninspired by RWKV\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nSpikeGPT-BookCorpus\nunknown\nSpikeGPT\nridger\n\n\n\n\n\nRWKV\n\nRWKV combines attention with RNN so the token window can be much larger.\nLongformer is similar to this. Model weights in github repo or huggingface.\n\nnow we have rwkv.cpp (4bit quantization), build upon ggml and sure it works on cpu.\nrwkvstic (with 8bit & offload for low VRAM GPUs)\n\nRWKV-LoRA supports RWKV-v4-NeoX\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nRWKV-7B-alpaca-finetuned\n7b\nRWKV\nBlueSunflower\n\n\nrwkv-4-14B-alpaca-finetune-lora-weights\n14b\nRWKV\nBlueSunflower\n\n\nrwkv-fastquant\nunknown\nrwkv\nHazzzardous\n\n\nrwkv-onnx\nunknown\nrwkv\nHazzzardous\n\n\nRWKV-8Bit\nunknown\nrwkv\nHazzzardous\n\n\nrwkv-4-raven\nunknown\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-7b\n7b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-14b\n14b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-430m\n430m\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-3b\n3b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-1b5\n1.5b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-169m\n169m\nunknown\nBlinkDL\n\n\nrwkv-3-pile-1b5\n1.5b\nrwkv\nBlinkDL\n\n\nrwkv-3-pile-430m\n430m\nrwkv\nBlinkDL\n\n\nrwkv-2-pile-430m\n430m\nrwkv\nBlinkDL\n\n\nrwkv-3-pile-169m\n169m\nrwkv\nBlinkDL\n\n\nRWKV-LM-safetensors\nunknown\nRWKV\nmrsteyk\n\n\nopenchatrwkv-430m-r2.0.1\n430m\nRWKV\nmrsteyk\n\n\nopenchatrwkw-430m-r2\n430m\nRWKV\nmrsteyk\n\n\nopenchatrwkv-430m\n430m\nRWKV\nmrsteyk\n\n\n\nencrypted alpaca model weights released by point-network: point-alpaca\n\n\ngpt4all by nomic\nLLaMA trained on massive collection of clean assistant dialog data, with model weights\nyou need to install nomic to run the model:\npip3 install nomic\nto run it on gpu, you need to install this\n\n\nopenassistant\nresearchers of open-assistant like andreaskoepf has releasesed oasst-sft-3-pythia-12b-epoch-3.5 and still updating\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\noasst-llama-13b-2-epochs\n13b\nllama\ndvruette\n\n\noasst-llama-13b-1000-steps\n13b\nllama\ndvruette\n\n\noasst-gpt-neox-20b-1000-steps\n20b\ngpt-neox\ndvruette\n\n\noasst-gpt-neox-20b-3000-steps\n20b\ngpt-neox\ndvruette\n\n\noasst-pythia-12b-6000-steps\n12b\npythia\ndvruette\n\n\noasst-pythia-12b-3000-steps\n12b\npythia\ndvruette\n\n\noasst-pythia-12b-flash-attn-5000-steps\n12b\npythia\ndvruette\n\n\noasst-pythia-6.9b-4000-steps\n12b\npythia\ndvruette\n\n\noasst-sft-1-pythia-12b\n12b\npythia\nOpenAssistant\n\n\ngalactica-6.7b-finetuned\n6.7b\ngalatica\nOpenAssistant\n\n\noasst-sft-4-pythia-12b-epoch-3.5\n12b\npythia\nandreaskoepf\n\n\npythia-12b-pre-2000\n12b\npythia\nandreaskoepf\n\n\npythia-12b-pre-3500\n12b\npythia\nandreaskoepf\n\n\noasst-sft-3-pythia-12b-epoch-3.5\n12b\npythia\nandreaskoepf\n\n\noasst-sft-3-pythia-12b-epoch-2.35\n12b\npythia\nandreaskoepf\n\n\noasst-sft-2-candidiate-0\nunknown\nunknown\nandreaskoepf\n\n\noasst-sft-2-pythia-12b-4000\n12b\npythia\nandreaskoepf\n\n\noasst-sft-1-gpt-neox-2000\nunknown\ngpt-neox\nandreaskoepf\n\n\noasst-1_12b_4500\n12b\nunknown\nandreaskoepf\n\n\noasst-1_12b_1500\n12b\nunknown\nandreaskoepf\n\n\noasst-1_12b_3000\n12b\nunknown\nandreaskoepf\n\n\n\n\nreward model weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nreward-model-deberta-v3-large\nunknown\ndeberta-v3\nOpenAssistant\n\n\nreward-model-deberta-v3-large-v2\nunknown\ndeberta-v3\nOpenAssistant\n\n\nreward-model-electra-large-discriminator\nunknown\nelectra-large\nOpenAssistant\n\n\nreward-model-deberta-v3-base\nunknown\ndeberta-v3\nOpenAssistant\n\n\noasst-rm-1-pythia-1b\n1b\npythia\nandreaskoepf\n\n\n\n\n\nopenflamingo\nusing CLIP ViT-L and LLaMA-7B, model weights on huggingface\n\n\ncerebras gpt\nopen sourced model weights and training code\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ncerebras-gpt-6.7b-lora\n6.7b\ncerebras-gpt\nsamwit\n\n\nCerebras-GPT-2.7B-Alpaca-SP\n2.7b\ncerebras-gpt\nlxe\n\n\nCerebras-GPT-2.7B-Alpaca-SP-ggml\n2.7b\ncerebras-gpt\nlxe\n\n\nlora-cerebras-gpt2.7b-alpaca-shortprompt\n2.7b\ncerebras-gpt\nlxe\n\n\nCerebras-GPT-13B\n13b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-6.7B\n6.7b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-2.7B\n2.7b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-1.3B\n1.3b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-590M\n590m\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-256M\n256m\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-111M\n111m\ncerebras-gpt\ncerebras\n\n\n\n\n\nColossalChat\nCoati-7B has no public model weights, but claimed to be trained efficiently\nyou need to install LLaMA compatible transformers library\ntrain on InstructionWild"
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#enhancements",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#enhancements",
    "title": "chatgpt clones, computer automation with ai",
    "section": "enhancements",
    "text": "enhancements\n\nusing external tools\ntoolformer-pytorch (WORK IN PROGRESS)\n\nengshell: using LLM to execute command\n\n\nusing ai models\nMicrosoft JARVIS aka HuggingGPT leverages huggingface models so ChatGPT can complete complex multimodal tasks.\n\n\nretrieval plugins\nlong term memory for oobabooga/text-generation-webui (can run pythia, galatica, opt, gpt-j, gpt-4chan, rwkv and support quantization/acceleration), also complex memory (KoboldAI-like)\n\nchatpaper summarize paper content.\nsimilar website: typeset.io (can ask questions and explain confusing text, math symbols and tables)\nrelated projects: ChatReviewer ChatImprovement ChatResponse ChatGenTitle\n\nchatgpt retrieval plugin chop document into chunks, process them into vectors and search them using one of many vector search backends. hosted as a fastapi service."
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#datasets",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#datasets",
    "title": "chatgpt clones, computer automation with ai",
    "section": "datasets",
    "text": "datasets\n\nassistant dialogue\nbotbots dataset (two chatgpt talking to each other), created by using datasetGPT (LLM automation tool)\n\nShareGPT52k, also ShareGPT90k (Vicuna)\n\ninstruct-102.4k by swype\n\ndatasets by BELLE:\ntrain_1M_CN\ntrain_0.5M_CN\nmultiturn_chat_0.8M\nschool_math_0.25M\n\n\nunsupervised pretraining\nFandom23K (text classification), part of BigKnow2022\nKinda LLaMA replicates LLaMA dataset, including scraped webpages, code and stackexchange data.\noscar-corpus needs to be downloaded with access token, by accepting agreement with account. containing categorized content and adult content."
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#dataset-preprocessing",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#dataset-preprocessing",
    "title": "chatgpt clones, computer automation with ai",
    "section": "dataset preprocessing",
    "text": "dataset preprocessing\ndeduplicate text dataset in rust, may remove verbose substrings like “to go to the”\noscar project (Open Super-large Crawled Aggregated coRpus) contains some tool for adult content filtering and deduplication."
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#nlp-tools-training-methods",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#nlp-tools-training-methods",
    "title": "chatgpt clones, computer automation with ai",
    "section": "NLP tools & training methods",
    "text": "NLP tools & training methods\nfasttext for efficient learning of word representations and sentence classification.\n\nlangchain\nprompt-engine\nchatml: markup language for ChatGPT, by openai\nreact-agent-ts enables LLM to chat and use tools by internal dialogues.\nbabyagi: AI-powered task management system. original post on twitter\n\nChain-of-hindsights (can learn from negative feedback) in jax and pytorch"
  },
  {
    "objectID": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#interfaces",
    "href": "posts/0fbdb0cb-c02b-47ca-b6e9-c495a6709bf3/index.html#interfaces",
    "title": "chatgpt clones, computer automation with ai",
    "section": "interfaces",
    "text": "interfaces\nserge is dockerized and the needs of RAM is according to the size of the model (alpaca), using CPU only"
  },
  {
    "objectID": "posts/ee2c48c8-bc6d-4419-a61b-41e9b756342e/index.html",
    "href": "posts/ee2c48c8-bc6d-4419-a61b-41e9b756342e/index.html",
    "title": "Understanding Captchas: Assessing Capabilities, Not Behaviors",
    "section": "",
    "text": "captcha for turing test\ncaptchas are used for public automated turing tests\nhowever, it is not behavior based but rather like capability/skill based."
  },
  {
    "objectID": "posts/3b082d2c-886b-4d75-bf1c-d175c009b101/index.html",
    "href": "posts/3b082d2c-886b-4d75-bf1c-d175c009b101/index.html",
    "title": "call ruby from python",
    "section": "",
    "text": "call ruby from python\nrb_call\npuby"
  },
  {
    "objectID": "posts/6971e2ea-d5b4-4070-a385-1e1e0d24e172/index.html",
    "href": "posts/6971e2ea-d5b4-4070-a385-1e1e0d24e172/index.html",
    "title": "b站根据视频内容自动生成推荐的标签",
    "section": "",
    "text": "b站根据视频内容自动生成推荐的标签\nB站允许最多10个标签\n不能发布太频繁, B站官方限制30秒一稿\nsome upload api\nthis api does not analyze the video content. it only predict tags from metadata:\nhttps://member.bilibili.com/x/web/archive/tags\nhow to get upload_id\n只有PC网页端有这个 手机端没有 可能是新功能\nb站最新更新了这两个接口 需要传入upload_id 具体参数抓包获取\n分区推荐 POST： https://member.bilibili.com/x/vupre/web/archive/types/predict\n标签推荐 GET（可能有延迟 需要请求两次 因为第一次标签数量较少）： https://member.bilibili.com/x/vupre/web/tag/recommend\n获取活动标签: https://member.bilibili.com/x/vupre/web/topic/type?type_id=21&pn=0&ps=200&title=20210210_298667075925_waou_5s&t=1667530591393"
  },
  {
    "objectID": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#卖东西",
    "href": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#卖东西",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "卖东西",
    "text": "卖东西\n自建网店平台：saleor"
  },
  {
    "objectID": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#开播",
    "href": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#开播",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "开播",
    "text": "开播\nb站网页获取开播地址 rtmp\n【神奇弹幕】哔哩哔哩直播万能机器人，弹幕姬+答谢姬+回复姬+点歌姬+各种小骚操作，目前唯一可编程机器人 可以实现自动开播\nBilibili直播工具 自动登录并获取推流地址，可以用于电脑、树莓派等设备无人值守直播\napi reference"
  },
  {
    "objectID": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#渲染-内容生成",
    "href": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#渲染-内容生成",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "渲染 内容生成",
    "text": "渲染 内容生成\n无后端的仿 YouTube Live Chat 风格的简易 Bilibili 弹幕姬"
  },
  {
    "objectID": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#监控",
    "href": "posts/c85e104c-cabf-4183-ae6e-f707d4784759/index.html#监控",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "监控",
    "text": "监控\n直播间监控websocket\n监听直播间消息的服务"
  },
  {
    "objectID": "posts/644bd207-be7c-4c2a-905b-a60dcbb78296/index.html",
    "href": "posts/644bd207-be7c-4c2a-905b-a60dcbb78296/index.html",
    "title": "bilibili 生活区up 培训",
    "section": "",
    "text": "bilibili 生活区up 培训"
  },
  {
    "objectID": "posts/051e6d12-2956-4537-af88-a325e1243c9c/index.html",
    "href": "posts/051e6d12-2956-4537-af88-a325e1243c9c/index.html",
    "title": "bilibili up主 入站了解 运作机制",
    "section": "",
    "text": "bilibili up主 入站了解 运作机制 开篇动画\n视频提交之后 转码（可能会二次压缩） ai加人工审核 血腥 暴力 色情（ai识别） 涉政 时政 版权 违反社区规范 推荐系统 根据场景特点（分区 话题 标签 相关度） 用户行为（点击率） 稿件互动质量（回复的内容是否是积极的） 精准 多样（不能重复 完全一样） 视频内容\n热门热搜筛选更严格 没进去不是流量限流\n限流是流量更高的时候 第二道审核出现问题 锤人 引战 粗俗的问题"
  },
  {
    "objectID": "posts/b05562f3-cc17-428d-9394-376fe392af2f/index.html",
    "href": "posts/b05562f3-cc17-428d-9394-376fe392af2f/index.html",
    "title": "badass tricks, earning plans",
    "section": "",
    "text": "badass tricks, earning plans\nyou talk about planting virus in software when people need it, also sharing some encrypted porn/copyrighted material to users, or mining crypto through github ci, exploits. when doing so, make sure the money is laundried, either through transfer between multiple crypto accounts or some professional agencies.\nfor github jobs, you may use terraform since it has some github automation tools"
  },
  {
    "objectID": "posts/3d09a316-ca7c-4206-b4b2-80bcd6a8ee90/index.html#offline-backup",
    "href": "posts/3d09a316-ca7c-4206-b4b2-80bcd6a8ee90/index.html#offline-backup",
    "title": "backup schedules",
    "section": "offline backup",
    "text": "offline backup\n\nschedule pyjom on alpharetta backup to disk every 12 hours\nset a notice to let me execute time machine backup every 1 week (next scheduled backup: thu aug 18)"
  },
  {
    "objectID": "posts/3d09a316-ca7c-4206-b4b2-80bcd6a8ee90/index.html#online-backup",
    "href": "posts/3d09a316-ca7c-4206-b4b2-80bcd6a8ee90/index.html#online-backup",
    "title": "backup schedules",
    "section": "online backup",
    "text": "online backup\n\nsend systemwide notification if aliyun disk token expires, with reacquiring method broadcasted\nschedule pyjom on alpharetta backup to cloud disks every 12 hours"
  },
  {
    "objectID": "posts/91550731-9c14-44be-9d48-c7ba2fb6c5a9/index.html#robotics",
    "href": "posts/91550731-9c14-44be-9d48-c7ba2fb6c5a9/index.html#robotics",
    "title": "autonomous lazero bot, controlling computer using natural language instructions",
    "section": "robotics",
    "text": "robotics\nRT-1 robotics transformer and SayCan\nVIMA General Robot Manipulation with Multimodal Prompts"
  },
  {
    "objectID": "posts/91550731-9c14-44be-9d48-c7ba2fb6c5a9/index.html#multimodal-model",
    "href": "posts/91550731-9c14-44be-9d48-c7ba2fb6c5a9/index.html#multimodal-model",
    "title": "autonomous lazero bot, controlling computer using natural language instructions",
    "section": "multimodal model",
    "text": "multimodal model\nmagma a GPT-style multimodal model that can understand any combination of images and language\nVersatile-Diffusion Text, Images and Variations All in One Diffusion Model"
  },
  {
    "objectID": "posts/91550731-9c14-44be-9d48-c7ba2fb6c5a9/index.html#ai-based-reinforcement-gui-testing",
    "href": "posts/91550731-9c14-44be-9d48-c7ba2fb6c5a9/index.html#ai-based-reinforcement-gui-testing",
    "title": "autonomous lazero bot, controlling computer using natural language instructions",
    "section": "AI based reinforcement GUI testing",
    "text": "AI based reinforcement GUI testing\nglider tasklet crawler\nGUI based bug detection using RL"
  },
  {
    "objectID": "posts/079ca5fb-a298-4935-8e0e-4b473bb88153/index.html",
    "href": "posts/079ca5fb-a298-4935-8e0e-4b473bb88153/index.html",
    "title": "audio-visual active speaker detection",
    "section": "",
    "text": "audio-visual active speaker detection\nleaderboard\nspell+"
  },
  {
    "objectID": "posts/2bf9e2a7-7872-4865-baf5-a2ddee1beca0/index.html#async-client",
    "href": "posts/2bf9e2a7-7872-4865-baf5-a2ddee1beca0/index.html#async-client",
    "title": "async requests with python, used for clash multiple proxy delays",
    "section": "async client",
    "text": "async client\naiohttp aiohttp-requests requests-async http3 (requests-async successor) many_requests curequests asks trip request-futures"
  },
  {
    "objectID": "posts/2bf9e2a7-7872-4865-baf5-a2ddee1beca0/index.html#async-non-blocking-server",
    "href": "posts/2bf9e2a7-7872-4865-baf5-a2ddee1beca0/index.html#async-non-blocking-server",
    "title": "async requests with python, used for clash multiple proxy delays",
    "section": "async non-blocking server",
    "text": "async non-blocking server\ntrequests"
  },
  {
    "objectID": "posts/c9a06c18-2e6e-4186-8793-9be20305947d/index.html",
    "href": "posts/c9a06c18-2e6e-4186-8793-9be20305947d/index.html",
    "title": "virtual phone numbers and public/anonymous accounts",
    "section": "",
    "text": "virtual phone numbers and public/anonymous accounts\nattach to virtual phone number providers, login bilibili or other websites with that phone number, register cookies, then monetize that account like posting ads\nyou can also use bugmenot"
  },
  {
    "objectID": "posts/64899f09-c59b-4e75-a514-3ff4c42b3b44/index.html",
    "href": "posts/64899f09-c59b-4e75-a514-3ff4c42b3b44/index.html",
    "title": "android remote control, app automation",
    "section": "",
    "text": "android remote control, app automation\nrun android in docker, run adb in docker\ndevice discovery, termux daemon, remote unlock\nunlock requires screenshot and input events.\nhttps://technastic.com/unlock-android-phone-pin-pattern-adb/\nclick ok after input password:\nhttps://stackoverflow.com/questions/29072501/how-to-unlock-android-phone-through-adb\nscrcpy client\nhttps://github.com/leng-yue/py-scrcpy-client https://leng-yue.github.io/py-scrcpy-client/guide.html#bind-events\nyou want to use android emulator on macos m1?\nhttps://github.com/google/android-emulator-m1-preview/releases/tag/0.3\ncheck android screen lock/unlock state\nhttps://android.stackexchange.com/questions/191086/adb-commands-to-get-screen-state-and-locked-state\nBonjour/Avahi/Zeroconf\nlogic: if the kill switch is off, when no physical input events happens, or not focused on scrcpy window with keyboard/mouse input events on pc for some time, allow to interact with the phone.\nget physical events:\nwarning: this command could be offline for a short period of time after using the scrcpy. must automatically reconnect if the device is not offline.\nadb -s 192.168.10.3:5555 shell getevent\nto get focused window title: hint: for headless ssh sessions, must set apropriate xorg environment variables, eg: env XAUTHORITY=\"/run/user/0/gdm/Xauthority\" DISPLAY=:1 python3\ngeneral method:\nimport pywinctl\npywinctl.getActiveWindowTitle()\nfor linux:\nwatch -n 2 xdotool getactivewindow getwindowname\nfor macos: (allow permission first, deprecated since it will not get the window title instead of the program name) https://alvinalexander.com/mac-os-x/applescript-unix-mac-osx-foreground-application-result/ (where is the window name?)\nsleep 3 && osascript -e 'tell application \"System Events\"' -e 'set frontApp to name of first application process whose frontmost is true' -e 'end tell'\nto get input events on macos: download keylogger here: https://hackernoon.com/writing-an-keylogger-for-macos-in-python-24adfa22722 https://github.com/beatsbears/pkl?ref=hackernoon.com\npython pkl_nowriting.py\ninput events on linux:\nxinput test-xi2 --root"
  },
  {
    "objectID": "posts/8d929a4d-955a-4f86-bd7a-2528ec33d3ed/index.html",
    "href": "posts/8d929a4d-955a-4f86-bd7a-2528ec33d3ed/index.html",
    "title": "amdgpu, rocm and pytorch",
    "section": "",
    "text": "amdgpu, rocm and pytorch\nrocm is trash to apu. use vulkan or opengl (alternative backends)\n\nfind latest build in pytorch nightly repo\nuse sudo before invoking amdgpu related commands, otherwise unavailable\n\nuse directml (pytorch, tensorflow) instead. need windows.\nyou need to set the shared graphical memory to a larger value.\nrocm does not work for integrated graphic cards (even if you build it and configured the card name), and supported amd cards are limited."
  },
  {
    "objectID": "posts/5dc89f8b-870e-444e-bbb6-a64ca0b3360b/index.html",
    "href": "posts/5dc89f8b-870e-444e-bbb6-a64ca0b3360b/index.html",
    "title": "add certificate to termux, especially for fastgithub",
    "section": "",
    "text": "add certificate to termux, especially for fastgithub\ninstall openssl-tools then use add-trusted-certificate against the .crt file, so curl will work fine (still not for elinks, i wonder why that works on macos and linux, or maybe not? just use playwright instead.)\nchromebook is different. you need to export the proxy to 0.0.0.0 by means of nginx or something, so you can configure proxy to 100.115.92.14 or 100.115.92.2 as seen in termux by ifconfig"
  },
  {
    "objectID": "posts/c266a8d3-d4f2-4856-b34f-9f51a65054ce/index.html",
    "href": "posts/c266a8d3-d4f2-4856-b34f-9f51a65054ce/index.html",
    "title": "anime video sites",
    "section": "",
    "text": "anime video sites\nhttps://animethemes.moe/"
  },
  {
    "objectID": "posts/00020457-e6f7-42e8-a0db-874088f9965f/index.html",
    "href": "posts/00020457-e6f7-42e8-a0db-874088f9965f/index.html",
    "title": "a comprehensive list of ai tools, may not be free, just for reference?",
    "section": "",
    "text": "a comprehensive list of ai tools, may not be free, just for reference?\nsource webpage\n\n\n\n\n\n名字\n\n\n类型\n\n\n网站链接\n\n\n简介\n\n\n\n\n\n\nMasterpiece Studio\n\n\n3D\n\n\nhttps://masterpiecestudio.com\n\n\n使用 AI 简化 3D 创作。传统的 3D 创作工具过于复杂。现代创作者只想创造，而不是迷失在细节中。产生。编辑。部署。\n\n\n\n\nG3DAI {Jedi}\n\n\n3D\n\n\nhttps://g3d.ai\n\n\n只需添加文本提示，即可创建您需要的任何 3D 资源。由突破性的人工智能提供支持。\n\n\n\n\nPonzu\n\n\n3D\n\n\nhttps://www.ponzu.gg\n\n\n使用 AI 生成的纹理对 3D 资产进行调味。\n\n\n\n\nPrometheanAI\n\n\n3D\n\n\nhttps://www.prometheanai.com\n\n\nPromethean AI 是世界上第一个与艺术家合作的人工智能，协助他们构建虚拟世界，并通过提出想法帮助创造性地解决问题。\n\n\n\n\nLeonardo.Ai\n\n\n3D\n\n\nhttps://leonardo.ai\n\n\n创造力，革命性的 以 AI 驱动的速度和风格一致性为您的创意项目生成生产质量的资产。\n\n\n\n\nMirageml\n\n\n3D\n\n\nhttps://www.mirageml.com\n\n\n快速生成 3D 设计。只需使用文本来描述您想要的内容，Mirage 的人工智能平台就会生成 3D 网格和纹理。\n\n\n\n\nPixela AI\n\n\n3D\n\n\nhttps://pixela.ai\n\n\n人工智能生成的游戏纹理。所有这些图像都是使用深度学习文生图模型算法生成的。上传您生成的纹理与社区分享！\n\n\n\n\nKaedim\n\n\n3D\n\n\nhttps://www.kaedim3d.com\n\n\n2D 图像到 3D 模型。使用 AI 在线自动将 2D 转换为 3D。\n\n\n\n\nKinetix\n\n\n3D\n\n\nhttps://www.kinetix.tech\n\n\n用于免费创建 3D 动画的无代码平台。把自己带到元宇宙。无需技能。\n\n\n\n\nPoly\n\n\n3D\n\n\nhttps://withpoly.com\n\n\n使用 AI 在几秒钟内生成纹理。仅通过文本提示即可创建无限高分辨率、完全自定义、商业许可的纹理。\n\n\n\n\nDeepMotion\n\n\n3D\n\n\nhttps://www.deepmotion.com/\n\n\nAnimate 3D 允许您通过使用实时身体跟踪将视频转换为 3D 动画，用于游戏、增强/虚拟现实和其他应用程序。\n\n\n\n\nScenario\n\n\n3D\n\n\nhttps://www.scenario.gg\n\n\n人工智能生成的游戏资产。为您的游戏创建高质量、风格一致的专有资产。\n\n\n\n\nLuma AI\n\n\n3D\n\n\nhttps://lumalabs.ai\n\n\n以逼真的 3D 捕捉。无与伦比的真实感、反射和细节。VFX 的未来就在现在，属于每个人！\n\n\n\n\nPlask\n\n\n3D\n\n\nhttps://plask.ai\n\n\n人工智能驱动的动捕动画工具\n\n\n\n\nGET3D (Nvidia)\n\n\n3D\n\n\nhttps://nv-tlabs.github.io/GET3D\n\n\n从图像中学习的高质量 3D 纹理形状的生成模型。\n\n\n\n\nImagine 3D\n\n\n3D\n\n\nhttps://captures.lumalabs.ai\n\n\nImagine 3D 是使用文本制作 3D 原型的早期实验。随着质量和可用性的提高，我们将扩大对一代的访问\n\n\n\n\nDream Up (Deviant Art)\n\n\n艺术\n\n\nhttps://www.dreamup.com\n\n\nDeviantArt DreamUp™ 让您在知道创作者及其作品受到公平对待的情况下创作 AI 艺术。用人工智能的力量创造任何你能想象到的图像！通过 5 个免费提示尝试 DreamUp。\n\n\n\n\nNightCafe Studio\n\n\n艺术\n\n\nhttps://creator.nightcafe.studio\n\n\n人工智能艺术生成器。使用人工智能的力量创造惊人的艺术作品。\n\n\n\n\nMidjourney\n\n\n艺术\n\n\nhttps://www.midjourney.com/home/\n\n\n基于 Stable Diffusion 的 AI 艺术生成器。他们的网站将他们描述为“一个独立的研究实验室，探索新的思想媒介并扩展人类的想象力。”\n\n\n\n\nArtbreeder\n\n\n艺术\n\n\nhttps://www.artbreeder.com\n\n\n前所未有的工艺 AI 艺术\n\n\n\n\nWombo\n\n\n艺术\n\n\nhttps://www.wombo.art\n\n\n使用 AI 的力量创作精美的艺术品。输入一个提示，选择一种艺术风格，然后观看 WOMBO Dream 在几秒钟内将您的想法变成一幅由 AI 驱动的绘画。\n\n\n\n\nNeural.love Art Generator\n\n\n艺术\n\n\nhttps://neural.love\n\n\n免费的 AI 艺术生成器，已生成超过 500 万张图像。想象一下：你通过向 AI 扔 2-3 个词来创造出令人惊叹的杰作。这不再是科幻小说了。\n\n\n\n\nPlayground AI\n\n\n艺术\n\n\nhttps://playgroundai.com\n\n\nPlayground AI 是一个免费使用的在线 AI 图像创建器。用它来创作艺术、社交媒体帖子、演示文稿、海报、视频、徽标等。\n\n\n\n\nLibraire\n\n\n艺术\n\n\nhttps://libraire.ai\n\n\n最大的 AI 生成图像库。搜索通过深度学习文生图模型生成的 1000 万张图像和提示。\n\n\n\n\nMage\n\n\n艺术\n\n\nhttps://www.mage.space\n\n\n免费、快速且未经过滤的 Stable Diffusion，文本到图像的 AI🔥\n\n\n\n\nArtroomAI\n\n\n艺术\n\n\nhttps://artroom.ai\n\n\n下载深度学习文生图模型的本地 GUI。无需编写任何代码即可制作精美的 AI 生成艺术作品。\n\n\n\n\nDreamlike.art\n\n\n艺术\n\n\nhttps://dreamlike.art\n\n\n借助 AI 的力量，在几秒钟内创作出令人惊叹的原创艺术作品。神奇的人工智能工具。创建无穷无尽的原始图像，修改现有图像等等。\n\n\n\n\nDiffusionBee\n\n\n艺术\n\n\nhttps://diffusionbee.com\n\n\n使用 Stable Diffusion 在您的计算机上生成 AI 艺术的最简单方法。\n\n\n\n\nCivitai\n\n\n艺术\n\n\nhttps://civitai.com\n\n\nCivitai是AI艺术生成社区唯一的模型共享中心！免费使用，开源，并不断改进。\n\n\n\n\nLexica\n\n\n艺术\n\n\nhttps://lexica.art\n\n\n深度学习文生图模型搜索引擎。\n\n\n\n\nAI Picasso\n\n\n艺术\n\n\nhttps://aipicasso.studio.site\n\n\n用强大的人工智能创造艺术。它会根据您输入的文本生成图像，就像您期望使用名为 Stable Diffusion 的 AI 一样。AI 完成填充区域。您可以根据提示编辑填充区域。\n\n\n\n\nFy! Studio\n\n\n艺术\n\n\nhttps://www.iamfy.co/studio\n\n\n将您的想法变成独特的墙壁艺术。只需输入您的想法，我们就会将它们变成一件前所未见的壁画。\n\n\n\n\nDaVinciFace\n\n\n艺术\n\n\nhttps://www.davinciface.com\n\n\n唯一可以根据您的照片创建达芬奇风格肖像的 AI。\n\n\n\n\nArtHub\n\n\n艺术\n\n\nhttps://arthub.ai\n\n\n众包 AI 艺术。探索 AI 生成的设计、图像、艺术和顶级社区艺术家和设计师的提示。\n\n\n\n\nSuper Prompt\n\n\n艺术\n\n\nhttps://superprompts.com\n\n\n无需离开 Twitter 即可为您的 AI 艺术创建精美的画廊。\n\n\n\n\nPicSo\n\n\n艺术\n\n\nhttps://picso.ai\n\n\n给 AI 艺术创作者的文本。将您的文字变成令人难以置信的高质量艺术品。\n\n\n\n\nDaft Art\n\n\n艺术\n\n\nhttps://daftart.ai\n\n\nAI 专辑封面生成器。创建您梦寐以求的专辑封面！\n\n\n\n\nClipdrop\n\n\n艺术\n\n\nhttps://clipdrop.co\n\n\n由人工智能提供支持的面向所有创作者的应用程序、插件和资源的终极生态系统。在几秒钟内创建令人惊叹的视觉效果。\n\n\n\n\nOpenart\n\n\n艺术\n\n\nhttps://openart.ai\n\n\n搜索 1000 万+ DALL·E 生成的 AI 艺术和提示 2、Midjourney、Stable Diffusion\n\n\n\n\nAltered\n\n\n音频编辑\n\n\nhttps://www.altered.ai\n\n\n增强你的声音。我们独特的技术允许您将您的声音更改为我们精心策划的组合或自定义声音中的任何一种，并创造出引人入胜的专业声音表演。\n\n\n\n\nAdobe Podcast\n\n\n音频编辑\n\n\nhttps://podcast.adobe.com\n\n\n提供 2 个免费的快速工具来增强您的内容的音频。增强语音 - 通过消除所有背景噪音和回声来增强语音。Mic Check - 从您的麦克风中解锁高品质声音。主要产品承诺提供 AI 驱动的音频录制和编辑，所有这些都在网络上，并且正在等待名单中。\n\n\n\n\nPodcastle\n\n\n音频编辑\n\n\nhttps://podcastle.ai\n\n\n广播故事的一站式商店。适用于播客或处理长视频创作的任何人的出色 AI 工具。工作室品质的录音、人工智能编辑和无缝导出——所有这些都在一个基于网络的平台上。\n\n\n\n\nCleanvoice AI\n\n\n音频编辑\n\n\nhttps://cleanvoice.ai\n\n\n停止浪费时间编辑您的播客。Cleanvoice 是一种人工智能，可以从您的播客或录音中去除填充音、口吃和口音。\n\n\n\n\nAudio Strip\n\n\n音频编辑\n\n\nhttps://www.audiostrip.co.uk/\n\n\n免费近乎完美的乐器和人声隔离！\n\n\n\n\nVoicemod\n\n\n音频编辑\n\n\nhttps://www.voicemod.net/\n\n\n立即免费下载 Voicemod，一款有趣又可怕的语音转换器应用程序。具有使您听起来像女孩或机器人的效果的语音转换器和修改器\n\n\n\n\nDreamPic.AI\n\n\n头像\n\n\nhttps://dreampic.ai/\n\n\n由 AI 生成的图片为您主演 为您和您的朋友创建 AI 生成的头像、用户图片和个人资料图片。上传您的照片，让 AI 完成这项工作。由 Stable Diffusion 和 DreamBooth 提供支持。\n\n\n\n\nVana Portrait\n\n\n头像\n\n\nhttps://portrait.vana.com\n\n\n你是一件艺术品。Vana 的“Portrait”是一个生成式艺术工作室，可以为您创建无限风格的自画像。\n\n\n\n\nHairgen AI\n\n\n头像\n\n\nhttps://www.hairgen.ai\n\n\n有没有想过头发移植后你会是什么样子？在您花费数千美元进行 FUE/FUT 程序之前，先预览一下您的样子。立即使用 AI 查看您的发际线。\n\n\n\n\nAvatarify\n\n\n头像\n\n\nhttps://avatarify.art/\n\n\n使用人工智能创建个性化头像。他们的技术可以让您生成栩栩如生的人物、动物甚至虚构人物形象。只需为您租用的 GPU 付费。如果您不喜欢，他们会重新渲染头像。\n\n\n\n\nAI Time Machine\n\n\n头像\n\n\nhttps://www.myheritage.com/ai-time-machine\n\n\n上传您自己的照片以创建令人难以置信的 AI 生成图像。使用 AI Time Machine 穿越历史。\n\n\n\n\nBeb.ai\n\n\n头像\n\n\nhttps://beb.ai\n\n\nBeb.AI 允许您生成自己、动物或著名人物的化身。为您的品牌接收无尽的创意内容。\n\n\n\n\nPictoDream\n\n\n头像\n\n\nhttps://pictodream.com/\n\n\n使用 AI 生成您自己的图像。使用简单的文字描述将任何人置于任何风格或环境中。\n\n\n\n\nReady Player Me\n\n\n头像\n\n\nhttps://readyplayer.me/\n\n\nMetaverse 的跨游戏头像平台。一个化身，许多世界等待探索。\n\n\n\n\nGemsouls\n\n\n头像\n\n\nhttps://www.mygemsouls.com/\n\n\n结识、结交并创建虚拟角色。肩负着让宝石般的虚拟人栩栩如生的使命。\n\n\n\n\nTheoasis\n\n\n头像\n\n\nhttps://theoasis.com/\n\n\n创建可在每个视频平台上使用的逼真头像。\n\n\n\n\nArti.pics\n\n\n头像\n\n\nhttps://www.arti.pics/\n\n\nArti.pics 是人工智能化身制作工具。它允许您上传几张自己的照片，并生成 200 多个不同风格的酷炫头像。\n\n\n\n\nProfile Picture AI\n\n\n头像\n\n\nhttps://www.profilepicture.ai\n\n\n使用 AI 创建完美的头像。人们在查看您的个人资料时首先看到的是您的个人资料图片。我们使用人工智能生成您的形象，看起来很完美并能捕捉到您的真实身份。你可以是任何人、任何地方或任何人！\n\n\n\n\nNeuralStudio\n\n\n头像\n\n\nhttps://neural.cam/studio\n\n\nNeural Studio 是一个一体化的照片和艺术工作室，由最新的 AI 技术提供支持，使创作者能够轻松实现他们的创作目标。\n\n\n\n\nCharacter AI\n\n\n头像\n\n\nhttps://beta.character.ai\n\n\n智能代理居住的地方！\n\n\n\n\nPhotoAI\n\n\n头像\n\n\nhttps://photoai.me/\n\n\n创建自己的 AI 照片。以我们最好的艺术风格生成 30 张您自己的照片。\n\n\n\n\nAvatar AI\n\n\n头像\n\n\nhttps://avatarai.me\n\n\n创建您自己的 AI 生成头像。\n\n\n\n\nDigirama\n\n\n头像\n\n\nhttps://apps.apple.com/us/app/character-creator-digirama/id6444673721\n\n\nDigirama 是一款 AI 角色创建器，可作为移动应用程序使用。\n\n\n\n\nInworld\n\n\n头像\n\n\nhttps://www.inworld.ai\n\n\n栩栩如生的 AI 角色，可以进行开放式对话。问他们任何事情。专为游戏、娱乐和虚拟世界打造。\n\n\n\n\nHairstyleAI\n\n\n头像\n\n\nhttps://www.hairstyleai.com\n\n\n使用我们强大的 AI 技术生成不同的发型。看看哪一个最适合你。适用于男性和女性理发。\n\n\n\n\nIn3D\n\n\n头像\n\n\nhttps://in3d.io/\n\n\n把人变成逼真的化身！使用手机摄像头在一分钟内为您的元宇宙、游戏或应用程序创建逼真且可自定义的头像。\n\n\n\n\nReface AI\n\n\n头像\n\n\nhttps://hey.reface.ai\n\n\n一款用于在 GIF 和视频中换脸的 AI 应用程序。他们的 AI Avatar 功能允许创建高质量的艺术品般的肖像（适用于 iOS 和 Android）。上传10张照片，等待一个小时。获得 48 件独特的艺术作品，以您自己为主角，采用各种艺术风格——从超级英雄到赛博朋克。\n\n\n\n\nUnrealme\n\n\n头像\n\n\nhttps://unrealme.io\n\n\n获取 AI 生成的您的图像。\n\n\n\n\nLensa\n\n\n头像\n\n\nhttps://prisma-ai.com/lensa\n\n\nLensa 是一款用于自拍和照片修饰的图片编辑器。该应用程序有许多图片过滤器，可以拍出甜美的自拍，去除任何模糊背景或进行任何其他必要的编辑。凭借其简单的功能和照片效果，您可以让每张照片一年 365 天都完美无缺。捕捉难忘的瞬间，并进行必要的照片编辑，及时定格每一刻。您不需要照相馆或暗室，因为几秒钟内您的桃色自拍就准备好了。\n\n\n\n\nCodeSquire\n\n\n代码助手\n\n\nhttps://codesquire.ai\n\n\n面向数据科学家、工程师和分析师的 AI 代码编写助手。在您键入时获取代码完成和建议。\n\n\n\n\nBuildt\n\n\n代码助手\n\n\nhttps://www.buildt.ai\n\n\n人工智能搜索通过搜索代码的作用来查找代码，而不仅仅是它是什么。一旦你找到代码库的一部分，他们的 AI 就可以让你简单地通过描述你想要的东西来进行更改\n\n\n\n\nHey, GitHub!\n\n\n代码助手\n\n\nhttps://githubnext.com/projects/hey-github\n\n\n此工具可帮助您在不接触键盘的情况下编写代码。它通过与 GitHub copilot 交谈，使用您的声音进行编码，而无需打字。\n\n\n\n\nWhatTheDiff\n\n\n代码助手\n\n\nhttps://whatthediff.ai\n\n\n您的人工智能代码审查助手。通过自动化拉取请求摘要来节省昂贵的开发人员时间。打开拉取请求并在几秒钟内获得更改摘要。立即了解小型拉取请求的含义，并在大型拉取请求上抢占先机。\n\n\n\n\nMaverick\n\n\n代码助手\n\n\nhttps://www.trymaverick.com\n\n\nMaverick 是一种由 AI 提供支持的代码完成工具。Maverick 建于 Yurts，专注于在不接触任何 API 或知识库的情况下在本地机器上提供最佳代码完成。\n\n\n\n\nContinual\n\n\n代码助手\n\n\nhttps://continual.ai/\n\n\n现代数据堆栈的操作 AI。Continual 是现代数据堆栈的领先运营 AI 平台。无需复杂的工程，即可构建永不停止改进的预测模型。免费试用。\n\n\n\n\nLookup\n\n\n代码助手\n\n\nhttps://app.uselookup.com\n\n\n在几秒钟内从您的数据中获得答案。Lookup 是 AI 驱动的分析平台，可帮助您以 10 倍的速度从数据获得洞察力。导入您的数据，提出问题，立即获得结果。\n\n\n\n\nClippy AI\n\n\n代码助手\n\n\nhttps://marketplace.visualstudio.com/items?itemName=clippy-ai\n\n\nClippy AI（VS 代码扩展）是 OpenAI Codex 的简单包装器。它允许您向 Codex 发送您的当前文件以及一些纯文本英语说明。然后它会在您的编辑器中打开一个差异视图，以便您可以轻松查看建议的更改并接受或拒绝它们。\n\n\n\n\nMutable\n\n\n代码助手\n\n\nhttps://mutable.ai\n\n\n使用 AI 以生产质量快速构建。\n\n\n\n\nFig AI\n\n\n代码助手\n\n\nhttps://fig.io/user-manual/ai\n\n\n作为现有终端的无缝附加组件，Fig 集成了最流行的终端、shell 和 IDE。\n\n\n\n\nBlackBox AI\n\n\n代码助手\n\n\nhttps://www.useblackbox.io/\n\n\nBlackBox AI 是一款由 AI 驱动的编码助手，因此您的编码速度可以提高 10 倍。它使您能够将任何问题转化为代码和功能，例如从任何视频和代码自动完成中提取代码。\n\n\n\n\nCodeAssist\n\n\n代码助手\n\n\nhttps://plugins.jetbrains.com/plugin/20085-codeassist\n\n\nCodeAssist（适用于 Intellij）是用于编程的 AI 助手/聊天机器人/副驾驶。根据您要进行的更改的描述，它会生成或更改代码。安装后，您可以通过单击左下角的“CodeAssist”选项卡打开它。CodeAssist 适用于所有流行的编程语言。\n\n\n\n\nProgramminghelper\n\n\n代码助手\n\n\nhttps://www.programming-helper.com/\n\n\n在 AI 的帮助下更快地编写代码。只需键入文本描述即可生成代码。AI 将为您创建代码。现在测试一下。\n\n\n\n\nCopilot\n\n\n代码助手\n\n\nhttps://github.com/features/copilot\n\n\n您的 AI 结对程序员。GitHub Copilot 使用 OpenAI Codex 直接从您的编辑器实时建议代码和整个功能。\n\n\n\n\nAskCodi\n\n\n代码助手\n\n\nhttps://www.askcodi.com\n\n\n编写语法、注释和测试。快点。更轻松。更好的。AskCodi 牢记开发人员的需求以避免冗余任务，因此减少了开发时间，增加了执行时间。\n\n\n\n\nAmazon CodeWhisperer\n\n\n代码助手\n\n\nhttps://aws.amazon.com/codewhisperer/\n\n\nAmazon CodeWhisperer 是一项由机器学习 (ML) 提供支持的服务，可根据开发人员在集成开发环境 (IDE) 中以自然语言和代码发表的评论生成代码建议，从而帮助提高开发人员的工作效率。\n\n\n\n\nCheat Layer\n\n\n代码助手\n\n\nhttps://cheatlayer.com/\n\n\n无代码业务自动化。作弊层使用无代码工具和机器学习的组合来解决不可能的业务自动化问题，以充当您的个人软件工程师。\n\n\n\n\nAI CLI\n\n\n代码助手\n\n\nhttps://github.com/abhagsain\n\n\n开源 GPT -3 Powered CLI 当前提示长度为 ~840 个令牌，1K 令牌的 text-davinci-002 定价为 0.02 美元，即 ~0.017 美元/命令。我们将看看是否可以通过微调改善响应并降低每条命令的成本。\n\n\n\n\nCodeGeeX\n\n\n代码助手\n\n\nhttps://huggingface.co/spaces/THUDM/CodeGeeX\n\n\nCodeGeeX 是一个拥有 130 亿参数的大规模多语言代码生成模型，在超过 20 种编程语言的大型代码语料库上进行预训练。CodeGeeX 支持 15 种以上的代码生成和翻译编程语言\n\n\n\n\nMaverick\n\n\n代码助手\n\n\nhttps://marketplace.visualstudio.com/items?itemName=YurtsAI.maverick&\n\n\nMaverick 是一种由 AI 提供支持的代码完成工具。Maverick 建于 Yurts，专注于在不接触任何 API 或知识库的情况下在本地机器上提供最佳代码完成。\n\n\n\n\nTabnine\n\n\n代码助手\n\n\nhttps://www.tabnine.com\n\n\n无论您是团队的一员，还是独立工作的开发人员，Tabnine 都将帮助您更快地编写代码——一切都在您最喜欢的 IDE 中进行。\n\n\n\n\nSpellbox\n\n\n代码助手\n\n\nhttps://spellbox.app/\n\n\n忙碌程序员的AI编码助手。使用 AI 在几秒钟内解决任何编程或工程问题\n\n\n\n\nStenography\n\n\n代码助手\n\n\nhttps://stenography.dev/\n\n\n最后。自动文档。\n\n\n\n\nReplit\n\n\n代码助手\n\n\nhttps://replit.com\n\n\nReplit 最近添加了一项名为 Ghostwriter 的功能，该功能使用 AI 来完成代码。使用功能强大的 IDE、编译器和解释器 Replit，在浏览器中以 50 多种语言编写和运行代码。\n\n\n\n\nCodeium\n\n\n代码助手\n\n\nhttps://www.codeium.com/\n\n\nCodeium 是现代编码超级大国，是一种基于尖端 AI 技术构建的代码加速工具包。通过轻松集成到编辑器中，您可以专注于成为最好的软件开发人员，而不是最好的代码猴子。\n\n\n\n\nHypotenuse ai\n\n\n文案\n\n\nhttps://hypotenuse.ai/\n\n\n使用 AI 文案写作将几个关键词变成原创的、有洞察力的文章、产品描述和社交媒体文案——这一切只需几分钟。今天免费试用。\n\n\n\n\nBertha.ai\n\n\n文案\n\n\nhttps://bertha.ai\n\n\n最有价值的 AI 文案助理 - 事实！永久免费获得 5,000 个单词。Bertha AI - WordPress 及其他软件的文案助理。\n\n\n\n\nDigital First AI\n\n\n文案\n\n\nhttps://digitalfirst.ai\n\n\n使用 AI 在几秒钟内制定营销计划。借助 AI 为您的企业找到最佳的增长黑客策略。将营销切换到自动驾驶模式并实现增长。\n\n\n\n\nBotowski\n\n\n文案\n\n\nhttps://www.botowski.com/\n\n\nBotowski 是您的新个人 AI 撰稿人。\n\n\n\n\nVEG3\n\n\n文案\n\n\nhttps://veg3.ai\n\n\n加入世界上第一个纯素人工智能营销助理的 Beta 测试。\n\n\n\n\nDaydrm.ai\n\n\n文案\n\n\nhttps://www.daydrm.ai\n\n\n用于创意广告创意的 AI 工具。创意和机构的按需概念。一种针对人工编写的创意广告活动进行训练的大型语言模型。\n\n\n\n\nhttps://unbounce.com\n\n\n文案\n\n\nhttps://jasper.ai\n\n\n借助人工智能，创建内容的速度提高 10 倍。Jasper 是质量最高的 AI 文案写作工具，拥有超过 3,000 条 5 星评论。最适合撰写博客文章、社交媒体内容和营销文案。\n\n\n\n\nPeppertype.ai\n\n\n文案\n\n\nhttps://www.peppertype.ai\n\n\n您的虚拟内容助手，可帮助您在几秒钟内生成高质量的内容。\n\n\n\n\nunbounce\n\n\n文案\n\n\nhttps://unbounce.com\n\n\n构思、迭代和编写定制的、高质量的、引人入胜的专业文案。在 Web 应用程序、便捷的桌面应用程序和 Chrome 扩展程序之间，将 Smart Copy 带到您最喜欢的工具中。\n\n\n\n\nEasy-Peasy.AI\n\n\n文案\n\n\nhttps://easy-peasy.ai/\n\n\n使用 🤖 AI 工具更快更轻松地完成文案写作。您还可以使用我们的 AI 头像生成器来生成头像。Easy-Peasy.AI 相信每个人都有一个故事要讲。借助我们的 AI 文案写作工具，我们可以帮助您以最引人入胜的方式讲述您的故事。\n\n\n\n\nSimplified\n\n\n文案\n\n\nhttps://simplified.com/ai-writer\n\n\nSimplified AI Writer 是一款免费的人工智能文案写作助手，可为博客、文章、产品描述、网站和社交媒体生成高质量的内容。\n\n\n\n\nCopyMonkey\n\n\n文案\n\n\nhttps://copymonkey.ai/\n\n\nCopyMonkey 在几秒钟内生成并优化亚马逊列表。AI 帮助将所有重要的关键词放在您的亚马逊列表中，让您在首页上自然排名。\n\n\n\n\nAnyword\n\n\n文案\n\n\nhttps://anyword.com\n\n\nAnyword 的 AI 写作助手可为任何人生成有效的文案。使用可转换的 AI 文案工具，消除营销文本中的猜测。\n\n\n\n\nLek\n\n\n文案\n\n\nhttps://lek.ai/\n\n\nLek 是一个 AI 文案工具。这是创建内容和复制的最快、最简单的方法。Lek AI 帮你写任何东西。\n\n\n\n\nCopysmith\n\n\n文案\n\n\nhttps://copysmith.ai/\n\n\n为电子商务团队和机构选择的人工智能文案软件。产生比以往更多的收入。立即注册免费试用。\n\n\n\n\nCopy.ai\n\n\n文案\n\n\nwww.copy.ai\n\n\n获得畅销的副本。Copy.AI 是一款人工智能文案，可为您的企业生成高质量的文案。免费开始，无需信用卡！营销更简单！\n\n\n\n\nCowriter\n\n\n文案\n\n\nhttps://cowriter.org/\n\n\n厌倦了盯着空白屏幕？认识您的 AI 撰稿人，他们可以创作鼓舞人心的创意内容。\n\n\n\n\nContents\n\n\n文案\n\n\nhttps://contents.com\n\n\n加强您的内容策略。生成式 AI 平台使内容创建变得简单，并且专为性能而构建。\n\n\n\n\nCreator AI\n\n\n文案\n\n\nhttps://www.creaitor.ai/\n\n\nCreaitor 帮助您以更强大、更能表达情感的方式编写内容。\n\n\n\n\nAdcreative.ai\n\n\n文案\n\n\nhttps://adcreative.ai\n\n\n在几秒钟内生成以转化为重点的广告和社交媒体帖子创意。在节省时间的同时获得更好的结果。\n\n\n\n\nWiziShop\n\n\n文案\n\n\nhttps://wizishop.com/ai\n\n\n使用 WiziShop 的人工智能编写您的电子商务产品描述，为您未来的文章寻找灵感，轻松走向国际，并为您的商店带来更多流量！\n\n\n\n\nRytr\n\n\n文案\n\n\nhttps://rytr.me/\n\n\nRytr 是一款 AI 写作助手，可帮助您在短短几秒钟内以极低的成本创建高质量的内容！\n\n\n\n\nUnbound\n\n\n文案\n\n\nhttps://www.unboundcontent.ai\n\n\n为您的小型企业自动创建内容。在一个地方利用所有最好的 AI 生成工具，旨在为小型企业、在线商店和创作者自动创建内容。\n\n\n\n\ntexti\n\n\n文案\n\n\nhttps://texti.app\n\n\n存在于您的浏览器中的 AI！它将与您合作，提升您的内容质量！\n\n\n\n\nOcoya\n\n\n文案\n\n\nhttps://www.ocoya.net\n\n\n一个可以更快地创建、自动生成和安排内容的平台。内容营销、文案写作和社交媒体只需几分钟！\n\n\n\n\nBotDistrikt\n\n\n顾客服务\n\n\nhttps://www.botdistrikt.com\n\n\nBotDistrikt 是适合您业务的完整聊天机器人解决方案。\n\n\n\n\nPoly ai\n\n\n顾客服务\n\n\nhttps://poly.ai/\n\n\n超人语音助手。24/7 全天候立即接听每个电话。无需代理。\n\n\n\n\nKore.ai\n\n\n顾客服务\n\n\nhttps://kore.ai/\n\n\n推动 AI 优化的客户和员工体验。我们是对话式 AI 技术的全球领导者，帮助公司在语音和数字渠道上为其客户、代理和员工提供非凡的体验。\n\n\n\n\nviable\n\n\n顾客服务\n\n\nhttps://www.askviable.com/\n\n\n在不影响质量的情况下自动执行定性数据分析。\n\n\n\n\nVee\n\n\n顾客服务\n\n\nhttps://vee.ai/en/\n\n\n人们喜欢与之交谈的聪明顾问。Vee 已经与 500 万波兰人进行了交谈，有效地为来自不同行业的数十家公司实施了业务流程。\n\n\n\n\nQuickchat\n\n\n顾客服务\n\n\nhttps://www.quickchat.ai\n\n\nQuickchat 使销售、客户支持、入职或在线预订等流程自动化。\n\n\n\n\nForethought\n\n\n顾客服务\n\n\nhttps://forethought.ai/\n\n\nForethought 的 AI 平台自动化并优化了整个支持工单生命周期。降低支持成本，同时在每次客户交互中提供顶级服务。\n\n\n\n\nTypewise\n\n\n顾客服务\n\n\nhttps://typewise.app\n\n\n提高客户服务和销售效率。我们强大的 AI 解决方案可为用户和公司节省时间并改善沟通。立即预订演示！\n\n\n\n\nEbi.Ai\n\n\n顾客服务\n\n\nhttps://ebi.ai\n\n\n通过 AI 助手减少通话量并改善客户体验。\n\n\n\n\nHarvey\n\n\n顾客服务\n\n\nhttps://hiverhq.com/harvey-ai-customer-support\n\n\n提高团队生产力的 AI Sidekick\n\n\n\n\nCohere\n\n\n顾客服务\n\n\nhttps://cohere.io/\n\n\n零设置即可查看和控制用户的屏幕。以前所未有的速度解决问题，保护和增加收入，让客户爱上您的产品\n\n\n\n\nMaya\n\n\n顾客服务\n\n\nhttps://maya.ai\n\n\n每个人都因 AI 驱动的个性化而获益：客户、银行和商家。\n\n\n\n\nTiledesk\n\n\n顾客服务\n\n\nhttps://tiledesk.com/\n\n\n将免费实时聊天与开源聊天机器人相结合以提高投资回报率。将 Chatbots 与 WhatsApp 或其他渠道集成，为所有通信提供一个收件箱。\n\n\n\n\nXokind\n\n\n顾客服务\n\n\nhttps://www.xokind.com/\n\n\n用于客户支持、差旅和销售的强大 AI 代理。XOKind 为产品和数据团队提供人工智能平台，通过简单的 API 端点利用机器学习和大型人工智能模型。\n\n\n\n\nDelve\n\n\n顾客服务\n\n\nhttps://www.delve.ai/\n\n\n为您的企业和您的竞争对手企业自动创建角色\n\n\n\n\nKaizan\n\n\n顾客服务\n\n\nhttps://kaizan.ai/\n\n\nKaizan 是客户成功团队保持和增加收入的客户智能平台\n\n\n\n\nechowin\n\n\n顾客服务\n\n\nhttps://echo.win/\n\n\n使用 AI 自动来电。获取新电话号码或使用现有电话号码。您的客户将致电我们的人工智能系统，该系统将帮助他们获得所需的答案、执行业务任务或在需要时将他们联系到合适的人。在我们处理电话的同时，您可以专注于经营您的业务！\n\n\n\n\nPuzzle\n\n\n顾客服务\n\n\nhttps://www.puzzlelabs.ai/\n\n\n为您的社区和客户提供的 AI 支持的词汇表。使用功能强大的词汇表让您的产品、服务和社区更加清晰。\n\n\n\n\nMagician (Figma)\n\n\n设计助手\n\n\nhttps://magician.design/\n\n\n由 AI 提供支持的 Figma 神奇设计工具。Magician 是一个 Figma 插件，可让您利用 AI 的力量进行设计，以完成从文案撰写到从文本生成独特图标的所有工作。每个魔法咒语都与您一起工作，以在您设计时扩展您的创造力和想象力。\n\n\n\n\nUizard\n\n\n设计助手\n\n\nhttps://uizard.io/\n\n\n使用世界上第一个人工智能驱动的设计工具 Uizard，在几分钟内设计数字产品、移动应用程序、网站模型和线框图！立即注册。\n\n\n\n\nClickable\n\n\n设计助手\n\n\nhttps://www.clickable.so\n\n\n适用于所有营销渠道的精美、品牌一致且转化率高的广告。无需设计经验。\n\n\n\n\nDiagram\n\n\n设计助手\n\n\nhttps://diagram.com\n\n\n设计更智能。神奇的产品设计新方法。\n\n\n\n\nMicrosoft Designer\n\n\n设计助手\n\n\nhttps://designer.microsoft.com\n\n\n使用 Microsoft Designer 瞬间完成令人惊叹的设计。从简单的文字描述开始，然后为您的设计创建图像！\n\n\n\n\nDesigns AI\n\n\n设计助手\n\n\nhttps://designs.ai/\n\n\n在 2 分钟内使用 AI 创建徽标、视频、横幅和模型。\n\n\n\n\nPinegraph\n\n\n设计助手\n\n\nhttps://pinegraph.com/\n\n\n成为 Pinegraph 的艺术家。借助 Pinecasso AI 的强大功能，将您的想象力变为现实。只需描述您的需求，剩下的交给 Pinecasso 来做。\n\n\n\n\nPattern Maker AI\n\n\n设计助手\n\n\nhttps://patternmakerai.com/\n\n\n使用人工智能生成无缝矢量模式。您还可以浏览其他已公开的生成模式。\n\n\n\n\nIllustroke\n\n\n设计助手\n\n\nhttps://illustroke.com/\n\n\n来自文本提示的令人惊叹的 SVG 插图使用我们的文本到 SVG AI 工具创建一些独特的东西。\n\n\n\n\nPictorial\n\n\n设计助手\n\n\nhttps://pictorial.ai/\n\n\n第一个真正对您的业务有用的生成式 AI 应用程序。为您网站的视觉效果而苦恼？让 AI 来处理。\n\n\n\n\nHotpot.ai\n\n\n设计助手\n\n\nhttps://hotpot.ai\n\n\nHotpot 帮助您创建专业的图形和图片。人工智能工具让专家和消费者能够激发创造力并自动完成繁琐的工作。易于编辑的模板使任何人都可以创建设备模型、社交媒体帖子、营销图片、应用程序图标和其他工作图形。\n\n\n\n\nAutodraw\n\n\n设计助手\n\n\nhttps://autodraw.com\n\n\nAutodraw 是一种 AI 工具，可让您通过猜测要绘制的对象或形状来更快地绘制。\n\n\n\n\nVizcom\n\n\n设计助手\n\n\nhttps://www.vizcom.ai/\n\n\n看到您的绘图在几秒钟内栩栩如生，而不是几小时。\n\n\n\n\nDimensions\n\n\n设计助手\n\n\nhttps://www.dimensions.ink\n\n\n只需单击几下，Dimensions 可帮助您将粗略的草图、照片甚至纯文本变成高度详细的概念。专注于创造力，而不是没完没了的例行公事。\n\n\n\n\nStockImg AI\n\n\n设计助手\n\n\nhttps://stockimg.ai/\n\n\n使用 AI 设计服务的文本。使用 AI 生成徽标、库存图像、海报、书籍封面和更多设计。\n\n\n\n\nAI2image\n\n\n设计助手\n\n\nhttps://www.ai2image.com/\n\n\nAI 在几秒钟内生成您的自定义图像。您可以通过简单的英文描述为您的网站、博客或社交媒体生成图像。\n\n\n\n\nAIGraphics\n\n\n设计助手\n\n\nhttps://aigraphics.io/\n\n\n使用 AI 在几秒钟内创建精美的定制图形。您可以使用它来创建社交图像、youtube 缩略图、徽标创意、照片和插图。\n\n\n\n\nCandyIcons\n\n\n设计助手\n\n\nhttps://www.candyicons.com/\n\n\n为您的产品寻找漂亮的应用程序图标。访问我们大量精美的应用程序图标并选择您最喜欢的图标。您将获得完整的版权所有权和支持 iOS、macOS 和 Android 项目的独特高质量图标。还有一个定制的图标生成器。\n\n\n\n\nIllostrationAI\n\n\n设计助手\n\n\nhttps://www.illostration.com\n\n\n创建 AI 生成的插图。在几秒钟内的唯一性。我们目前处于公开测试阶段。注册以获得早期访问权限。\n\n\n\n\nPatterned AI\n\n\n设计助手\n\n\nhttp://patterned.ai/\n\n\n人工智能生成的无缝模式。使用我们的 AI 模型为您的产品或服务生成定制设计。您还可以搜索数以千计的免版税库存图片，以立即用于您自己的设计。\n\n\n\n\nDesignify\n\n\n设计助手\n\n\nhttps://www.designify.com/\n\n\n使用您喜欢的照片创建自动设计。通过自动删除背景、增强颜色、调整智能阴影等，选择任何图像来创建 AI 支持的设计。立即保存、下载或共享您的设计。\n\n\n\n\nCSM\n\n\n开发者工具\n\n\nhttps://csm.ai/\n\n\nCommon Sense Machines 提供 API、接口和开源软件，将多模式输入和体验转化为用于 AI 训练和内容创建的数字模拟器。我们认为，学习生成世界模型是实现 AGI 的系统途径，类似于儿童从经验中了解其世界的方式。\n\n\n\n\nRunPod\n\n\n开发者工具\n\n\nhttps://runpod.io\n\n\n以 0.2 美元/小时的价格租用云 GPU。在 GPU 上节省超过 80%。借助用于 PyTorch、Tensorflow 或任何其他 AI 框架的 Jupyter，GPU 租赁变得轻松。\n\n\n\n\nMoonbeam Exchange\n\n\n开发者工具\n\n\nhttps://moonbeam.ai\n\n\nMoonbeam Exchange 是一个数据科学平台，它利用 100 多个数据源为整个创新生态系统提供情报和洞察力。\n\n\n\n\nShumai (Meta)\n\n\n开发者工具\n\n\nhttps://github.com\n\n\nShumai 是一个开源、快速、网络连接、可微分的 TypeScript（和 JavaScript）张量库。为软件工程师和研究人员等使用 bun + flashlight 构建。\n\n\n\n\nSyntheticAIdata\n\n\n开发者工具\n\n\nhttps://syntheticaidata.com\n\n\n加速您的视觉 AI 模型创建。合成数据是用于训练和改进 AI 模型的现实世界数据的廉价替代品。为了训练准确的人工智能模型，需要大量的数据。通过使用逼真的 3D 模型，您可以轻松创建用于 AI 分类和对象检测的合成数据。\n\n\n\n\nChatbotkit\n\n\n开发者工具\n\n\nhttps://chatbotkit.com\n\n\n构建高级 AI 聊天机器人的最简单方法。我们的平台使开发人员和非开发人员都可以轻松构建可以用自然语言与用户交流的聊天机器人。\n\n\n\n\nPipeline AI\n\n\n开发者工具\n\n\nhttps://pipeline.ai\n\n\n用于 ML 模型的无服务器 GPU 推理 用于在生产中运行 ML 的每毫秒付费 API。\n\n\n\n\nNuclia\n\n\n开发者工具\n\n\nhttps://nuclia.com\n\n\nNuclia 自动为来自任何内部和外部来源的非结构化数据编制索引，提供优化的搜索结果。它可以处理视频和音频转录、图像内容提取和文档解析。\n\n\n\n\nTinq.ai - NLP API\n\n\n开发者工具\n\n\nhttps://tinq.ai\n\n\n一组易于使用和尖端的 NLP API。流行的 API：文本生成 - 重写器/释义器摘要器将快速而强大的文本分析集成到您的应用程序中。从主题分类到情绪分析和实体提取，我们都能满足您的需求。让它在几天内发生，而不是几个月！文本分析：Plagarism Checker；自定义分类器；情绪分析；命名实体识别\n\n\n\n\nValyr\n\n\n开发者工具\n\n\nhttps://valyr.vercel.app\n\n\n用一行代码简化 GPT-3 监控。要使用，请将基本 url 替换为 SDK。将您的 OpenAI 密钥添加到 Valyr 并在仪表板中查看请求。\n\n\n\n\nGPUX.AI\n\n\n开发者工具\n\n\nhttps://gpux.ai\n\n\nGPU 一切。运行任何 Dockerized。运行自动缩放推理。节省成本50-90%。\n\n\n\n\nRTutor\n\n\n开发者工具\n\n\nhttps://tutor.ai\n\n\nRTutor 是一款基于 AI 的应用程序，可以快速生成和测试 R 代码。在对 OpenAI 的 Davinci（ChatGPT 的兄弟）的 API 调用的支持下，RTutor 将自然语言翻译成 R 脚本，然后在 Shiny 平台内执行。可以生成 R Markdown 源文件和 HTML 报告。在此处查看 github 存储库：https://github.com/gexijin/RTutor\n\n\n\n\nMintlify\n\n\n开发者工具\n\n\nhttps://mintlify.com\n\n\n构建您一直想要的文档。开箱即用，易于维护，并针对用户参与进行了优化。\n\n\n\n\nGptDuck\n\n\n开发者工具\n\n\nhttps://gptduck.com\n\n\n针对任何 Github 存储库的问题回答。输入 Github 存储库，我们将其下载到服务器并针对代码创建嵌入。回购需要是公开的，&lt;200 个文件，&lt;100MB。\n\n\n\n\nTextomap\n\n\n开发者工具\n\n\nhttps://textomap.com\n\n\nTextomap 是一个 Web 应用程序和浏览器扩展，使用户能够在几秒钟内从任何包含位置的文本生成交互式地图。没有代码、电子表格或复杂的工具——您的话就足够了。\n\n\n\n\nHTTPie AI\n\n\n开发者工具\n\n\nhttps://httpie.io\n\n\n使用通俗易懂的语言生成 API 请求。HTTPie 正在使 API 对于那些构建我们这个时代的工具的人来说变得简单和直观。\n\n\n\n\nQuizgecko\n\n\n教育助手\n\n\nhttps://quizgecko.com\n\n\n人工智能驱动的测验问题生成器。使用人工智能制作您自己的测验。非常适合教师、电子学习和人力资源专业人士。或者只是为了好玩而生成独特的琐事问题和答案！简单粘贴文本，输入 URL，或上传文件并点击生成。从多项选择题、简答题或判断题中选择。\n\n\n\n\nWolframAlpha\n\n\n教育助手\n\n\nhttps://wolframalpha.com\n\n\n使用 Wolfram 的突破性算法、知识库和 AI 技术计算专家级答案。面向数学、科学与技术、社会与文化以及日常生活等主题。\n\n\n\n\nTutorAI\n\n\n教育助手\n\n\nhttps://tutorai.me\n\n\nTutor AI 是一个人工智能驱动的学习平台。您可以输入任何主题，它会为您提供各种选项，您可以使用这些选项来了解该主题。\n\n\n\n\nMindSmith\n\n\n教育助手\n\n\nhttps://mindsmith.ai\n\n\nMindsmith 是您创建和分享微课程的实验室。世界变化太快，不能依赖笨重、过时的设计软件。无论您是培训团队、教授课程，还是只是需要一种清晰的方式来分享您的知识，都可以使用一套 AI 辅助的直观设计工具，让您的学习者在永不停歇的行业和学科中取得成功。\n\n\n\n\nYip\n\n\n教育助手\n\n\nhttps://yippity.io\n\n\n输入您的笔记，Yip 会自动从中生成问题。\n\n\n\n\nMateAI\n\n\n邮件助手\n\n\nhttps://mateai.io\n\n\n更快地为您的电子邮件活动生成文案和设计。🇬🇧 🇮🇹 提供英语、意大利语和其他 5 种语言版本。\n\n\n\n\nEllie\n\n\n邮件助手\n\n\nhttps://ellieai.com\n\n\nEllie 从您的写作风格中学习，并像您写的一样精心回复。\n\n\n\n\nIpso AI\n\n\n邮件助手\n\n\nhttps://ipso.ai\n\n\n一个 AI 助手，它使用您的日历起草用于安排会议的电子邮件回复，由 GPT3 提供支持。\n\n\n\n\nLuna\n\n\n邮件助手\n\n\nhttps://getluna.dev\n\n\n使用 Luna 即时个性化冷电子邮件。这些天自动消息已经死了。使用 Luna 获得更多关于冷电子邮件的回复 - 世界上第一个使用 AI 每天推荐新的高质量潜在客户并向他们发送他们应得的个人电子邮件的软件应用程序。\n\n\n\n\nPolitePost\n\n\n邮件助手\n\n\nhttps://politepost.net\n\n\nPolitePost 将您的电子邮件重写为礼貌、礼貌和安全的工作方式。非常适合当您在写电子邮件时感到沮丧并且需要 AI 来保持礼貌！\n\n\n\n\nPipl.ai\n\n\n邮件助手\n\n\nhttps://pipl.ai\n\n\n很难大规模发送冷电子邮件。我们让它变得轻而易举。连接无限的收件箱，享受所有帐户的免费预热、内置电子邮件验证和数据清理、人工智能驱动的序列和模板编写器等等……\n\n\n\n\nPostaga\n\n\n邮件助手\n\n\nhttps://postaga.com\n\n\n比以往更轻松地发送冷电子邮件。\n\n\n\n\nDraftLab\n\n\n邮件助手\n\n\nhttps://draftlab.ai\n\n\n您的 Gmail 副驾驶。更快地写出更好的电子邮件。使用适用于 Gmail 的 DraftLab Chrome 扩展，将收件箱归零的速度提高 10 倍。\n\n\n\n\nSuperReply\n\n\n邮件助手\n\n\nhttps://superreply.co\n\n\nSuperreply 使用其 AI 驱动的电子邮件回复工具处理编写电子邮件回复的所有艰苦工作。轻松匹配语调并选择最匹配的电子邮件。\n\n\n\n\nQuicklines\n\n\n邮件助手\n\n\nhttps://quicklines.ai\n\n\nQuicklines 自动创建个性化的破冰机制以注入冷电子邮件。上传 CSV，等待 3 分钟，然后收到写有行的表格。将这些行放入冷电子邮件的第一句中，您会看到您的回复增加了 3 到 7 倍。\n\n\n\n\nInstantly\n\n\n邮件助手\n\n\nhttps://instantly.ai\n\n\n立即帮助您产生更多回复和更多收入。通过无限制的电子邮件发送帐户、无限制的预热和智能 AI 扩展您的外展活动。\n\n\n\n\nCreatext\n\n\n邮件助手\n\n\nhttps://creatext.ai\n\n\nCreaext 可帮助您立即研究您的潜在客户并编写超个性化的电子邮件和 LinkedIn 消息。\n\n\n\n\nChatGPT Writer\n\n\n邮件助手\n\n\nhttps://chatgptwriter.ai\n\n\n免费的 Chrome 扩展，使用 ChatGPT AI 根据您输入的几个关键字生成电子邮件或回复。目前支持 Gmail。支持所有流行语言，只需在文本提示中提及即可。\n\n\n\n\nOrtto\n\n\n邮件助手\n\n\nhttps://ortto.com\n\n\nOrtto AI 可帮助您编写高性能的电子邮件主题行，从大纲中引人入胜的短信和电子邮件内容。驱动结果的是智慧。\n\n\n\n\nWarmer.ai\n\n\n邮件助手\n\n\nhttps://warmer.ai\n\n\nSky 使用 AI 生成的独特个性化设置让您的冷邮件大放异彩。\n\n\n\n\nRobin\n\n\n邮件助手\n\n\nhttps://hellorobin.ai\n\n\n由 GPT 编写的自动冷电子邮件外展。借助 Robin AI，您可以轻松有效地接触潜在客户、进行研究并处理初始外展——所有这些都不需要人工销售助理。\n\n\n\n\nMagicreach\n\n\n邮件助手\n\n\nhttps://magicreach.ai\n\n\nReach 是一种外展个性化和销售支持工具，可为冷外展生成超个性化破冰船。获得回复的更快的电子邮件个性化。\n\n\n\n\nAlethea\n\n\n实验\n\n\nhttps://alethea.ai\n\n\nAlethea AI 致力于实现交互式智能 NFT (iNFT) 的创建。\n\n\n\n\nAsk My Book\n\n\n实验\n\n\nhttps://askmybook.com\n\n\nAsk My Book 是 Gumroad 创始人 Sahil Lavingia 的一项人工智能实验，目的是让他的书更容易阅读。您可以使用“问我的书”来提出问题，然后用他的声音得到答案。\n\n\n\n\nTalk To Books\n\n\n实验\n\n\nhttps://books.google.com\n\n\n一种探索思想和发现书籍的新方法。使用实验性 AI 发表声明或提出问题以浏览书中的段落。\n\n\n\n\nVisualHound\n\n\n时尚\n\n\nhttps://visualhound.com\n\n\n使用 AI 为您的时装设计创意制作原型。创建无限逼真的产品图像来满足您的情绪板并促进您的设计过程。在投入生产之前轻松可视化您的产品设计。\n\n\n\n\nFashionAdvisorAI\n\n\n时尚\n\n\nhttps://fashionadvisorai.com\n\n\n从 FashionAdvisorAI 提问并获得答案。它使用人工智能来帮助您找到时尚问题的答案。用它来打扮自己。\n\n\n\n\nCala\n\n\n时尚\n\n\nhttps://ca.la\n\n\nCALA 使您可以轻松设计、生产和交付您自己的完全定制的时尚产品。CALA 提供您可能需要的一切。设计协助。材料采购。采样。借助应用程序内通知、任务管理和实时评论等强大功能，您可以在工作室或旅途中最大限度地提高工作效率。\n\n\n\n\nBotika\n\n\n时尚\n\n\nhttps://botika.io\n\n\nBotika 利用生成式 AI 的力量帮助在线服装零售商和小型企业减少制作时尚照片的麻烦、成本和时间，同时在各种模型上获得 10 倍以上的输出。\n\n\n\n\nAskThee\n\n\n趣味工具\n\n\nhttps://askthee.vercel.app\n\n\n向伟大的思想家、艺术家或科学家提问。目前拥有亚里士多德、阿西莫夫、卡尔萨根等人物。\n\n\n\n\nUnreal Meal\n\n\n趣味工具\n\n\nhttps://unrealmeal.ai\n\n\nAI 生成的不存在的膳食图像的集合。您可以将这些图像用于多种用途，例如开发新食谱或作为创意项目的一部分。\n\n\n\n\nTattoos AI\n\n\n趣味工具\n\n\nhttps://tattoosai.com\n\n\n与您的个人 AI 纹身艺术家一起创造完美的纹身设计如果您有纹身的想法但找不到合适的设计，让我们的 AI 在几秒钟内生成一个。它可以让您根据自己的喜好创建完美的设计，并为您提供无限的选择，让每个人都能找到适合自己的东西。\n\n\n\n\nELI5\n\n\n趣味工具\n\n\nhttps://explainlikeimfive.io\n\n\n像我五岁一样解释 (ELI5) 是一个使用 AI 简化复杂主题的网站，这样即使是孩子也能理解它们。用户可以选择一个特定的主题，并选择他们希望解释的简单程度，范围从“非常愚蠢”到“非常聪明”。一些例子是——“计算机是如何工作的？” 和“生命的意义是什么？”\n\n\n\n\nMovieToEmoji\n\n\n趣味工具\n\n\nhttps://movietoemoji.netlify.app\n\n\n一个有趣的应用程序，可以将电影名称转换为相应的表情符号！\n\n\n\n\nSanta AI\n\n\n趣味工具\n\n\nhttps://santa.artflow.ai\n\n\n想为假期增添一些额外的魔力吗？查看世界上第一个可定制的会说话的圣诞老人 - 第一次您可以创建自己独特的圣诞老人视频问候并与您所爱的人分享！\n\n\n\n\nSupermeme.ai\n\n\n趣味工具\n\n\nhttps://supermeme.ai\n\n\n生成由 AI 提供支持的 110 多种语言的原创模因。使用我们的 AI 模因生成器加强您的模因营销游戏。\n\n\n\n\nJokelub\n\n\n趣味工具\n\n\nhttps://jokelub.com\n\n\n轻轻一按，将您的文章变成一个笑话。让人们微笑。\n\n\n\n\nHello History\n\n\n趣味工具\n\n\nhttps://hellohistory.ai\n\n\n您将能够与历史上一些有影响力和迷人的人物进行深入对话。对话是由人工智能生成的，所以不要太当真。每个对话都是独一无二的，你永远不知道它会去哪里。\n\n\n\n\nAskNow\n\n\n趣味工具\n\n\nhttps://asknow.ai\n\n\n向名人提出任何问题，并获得带有参考资料的 AI 总结答案。以 Elon Musk、Naval Ravikant、Paul Graham、Serena Williams 等人物为特色。\n\n\n\n\nChai\n\n\n游戏\n\n\nhttps://chai.ml\n\n\n允许您为成千上万的用户构建和部署 AI 聊天机器人的移动应用程序。与人工智能聊天。\n\n\n\n\nAIDungeon\n\n\n游戏\n\n\nhttps://play.aidungeon.io\n\n\n玩和创造具有无限可能性的 AI 生成的冒险。\n\n\n\n\nAI Careers\n\n\n游戏\n\n\nhttps://aicareers.io\n\n\n人工智能求职变得简单。释放数据的潜力以推动创新。\n\n\n\n\nPICLY : AI generated spot the difference\n\n\n游戏\n\n\nhttps://picly.ai\n\n\n简单易行。AI 生成的“找不同”点击您想要的区域，AI 会为您完成。\n\n\n\n\nEndlessVN\n\n\n游戏\n\n\nhttps://endlessvn.io\n\n\n所有的故事都结束了。除了这个。Endless Visual Novel 是一款 AI 讲故事游戏，其中所有资产（图形、音乐、故事和角色）均由 AI 在您玩游戏时生成。没有两个游戏是完全相同的。\n\n\n\n\nThe Simulation\n\n\n游戏\n\n\nhttps://fablesimulation.com\n\n\nThe Simulation 是一个以人工智能为中心的元宇宙。由复杂的机器学习、游戏设计、NFT 和 ERC20 代币 $SIM 提供支持\n\n\n\n\nPlaystrict\n\n\n游戏\n\n\nhttps://playstrict.com\n\n\n让我们让您的游戏更加成功！您有一款很棒的游戏，但没有营销能力来扩大规模？使用 Playstrict Gaming Growth 平台将您的推广策略提升到一个新的水平。你准备好了吗？\n\n\n\n\nLitRPG Adventures\n\n\n游戏\n\n\nhttps://litrpgadventures.com\n\n\n高级桌面 RPG 生成器 + 内容库 D&D 背景故事生成器？那不是全部。立即访问由 OpenAI 的 GPT-3 提供支持的超过 2 打奇幻 RPG 生成器。会员还可以访问我们不断增长的充满桌面角色扮演游戏内容的角色扮演游戏库\n\n\n\n\nHexagram\n\n\n游戏\n\n\nhttps://hexagram.io\n\n\n我们使用人工智能创造环境体验。使用聊天、故事和数据来融合小说和现实的游戏。\n\n\n\n\nGGPredict\n\n\n游戏\n\n\nhttps://ggpredict.io\n\n\n每天不到 30 分钟，借助 AI 生成的培训的力量提高您的 CS:GO 技能。训练更智能。排名更快。\n\n\n\n\nAI Roguelite\n\n\n游戏\n\n\nhttps://store.steampowered.com\n\n\n世界上第一款所有实体均由 AI 生成且所有游戏机制均由 AI 检测的角色扮演游戏。它有人工智能生成的实体、制作配方、战斗和插图。\n\n\n\n\nQuasi\n\n\n综合写作\n\n\nhttps://quasi.market\n\n\n使用人工智能创造艺术、代码、音乐等。\n\n\n\n\nWritewithlaika\n\n\n综合写作\n\n\nhttps://writewithlaika.com\n\n\n作家的神奇机器学习\n\n\n\n\nSmartScribe\n\n\n综合写作\n\n\nhttps://smartscribe.app\n\n\n写作变得更容易… SmartScribe 通过使用人工智能帮助解决阅读和写作的复杂性。\n\n\n\n\nnichess\n\n\n综合写作\n\n\nhttps://nichesss.com\n\n\n忘记作家块。只需单击一个按钮，即可获取博客文章、广告、社交媒体内容、诗歌、商业创意等。我们的机器人会为您编写一切。\n\n\n\n\nCompose\n\n\n综合写作\n\n\nhttps://compose.ai\n\n\nCompose 是一款免费的 Chrome 扩展程序，可让您使用 AI 自动进行写作。我们不应该每天花 40% 的时间打字：是时候改变游戏规则了。\n\n\n\n\nText Generator Plugin\n\n\n综合写作\n\n\nhttps://text-gen.com\n\n\nText Generator 是一种开源 AI 助手工具，它将生成式人工智能的力量带入了 Obsidian 中知识创造和组织的力量。例如，使用文本生成器根据您的知识数据库生成想法、有吸引力的标题、摘要、大纲和整个段落。可能性是无止境！\n\n\n\n\nWebCopilot\n\n\n综合写作\n\n\nhttps://webcopilot.co\n\n\n用 AI 编写您的概念页面。只需开始，让 AI 为您写作。加快您的写作过程并专注于重要的事情。\n\n\n\n\nFrase\n\n\n综合写作\n\n\nhttps://frase.io\n\n\nFrase 在文案写作、总结、释义和广告等类别中提供了多种有用的 AI 写作工具。\n\n\n\n\nNotion AI\n\n\n综合写作\n\n\nhttps://affiliate.notion.so\n\n\n在任何概念页面中利用 AI 的无限力量。写得更快，想得更远，并增强创造力。像魔法一样！\n\n\n\n\nLanguageTool\n\n\n综合写作\n\n\nhttps://languagetool.org\n\n\nLanguageTool 纠正拼写错误，但它也提供所有可能文本的完整写作分析。除了拼写、语法和单词选择之外，语言风格也会得到纠正。掌握30多种语言和方言，主要语言有英语、西班牙语、德语、法语、荷兰语、葡萄牙语。在其英文版中，您可以在六个标准品种之间进行选择。除了纠正之外，LanguageTool 还提供基于 AI 的改写功能。这可以帮助您重写整个句子，使它们更简单、更短或更正式。\n\n\n\n\nAIDuh\n\n\n综合写作\n\n\nhttps://aiduh.com\n\n\nChrome 扩展程序通过 AI 支持的响应将您的写作时间缩短 98%。\n\n\n\n\nWritely\n\n\n综合写作\n\n\nhttps://writelyai.com\n\n\n让所有人都能接触到写作艺术。无论您是需要减少字数、进一步阐述还是简单地改写一个句子，Writely 都可以提供帮助！\n\n\n\n\nGrammarly\n\n\n综合写作\n\n\nhttps://app.grammarly.com\n\n\n使用 Grammarly 的新人工智能应用程序自信地写作。通过自动建议超越语法和拼写风格和语气。适用于电子邮件、文档、社交媒体和几乎所有内容。\n\n\n\n\nProposal Genie\n\n\n综合写作\n\n\nhttps://proposalgenie.ai\n\n\n人工智能驱动的工具，可帮助在 Upwork 上创建专业提案。易于使用，允许您从任何设备创建提案，构建可重复使用的配置文件，并添加关键字和语气等可选字段。\n\n\n\n\nDetect GPT\n\n\n综合写作\n\n\nhttps://chrome.google.com\n\n\n查看您浏览的页面是否包含 AI 生成的内容。Detect GPT 扫描您正在查看的网页内容并对其进行分析，以确定是否有任何内容是使用 GPT 语言模型生成的。\n\n\n\n\nLuciaAI\n\n\n综合写作\n\n\nhttps://luciaai.com\n\n\n高级AI写作助手。露西亚使用最新最先进的人工智能技术。使用 Lucia，您可以比以往更快更好地书写。\n\n\n\n\nCaliberAI\n\n\n综合写作\n\n\nhttps://caliberai.net\n\n\nCaliberAI 有助于将您因 AI 诽谤的风险降至最低。它近乎实时地标记高风险内容，专为协助编辑和加强人工监督而设计。具有根据您组织的风险承受能力量身定制的自定义阈值的 API。\n\n\n\n\nHelloScribe\n\n\n综合写作\n\n\nhttps://helloscribe.ai\n\n\n更好的写作。伟大的想法。变得简单。向 10 倍更快的写作和头脑风暴问好，没有创意障碍或浪费时间。HelloScribe 易于使用的 AI 工具可帮助 PR 和营销专业人员更智能地工作。\n\n\n\n\nWordAI\n\n\n综合写作\n\n\nhttps://wordai.com\n\n\n使用 AI 将您的内容输出提高 10 倍。使用人工智能来缩短周转时间、增加预算并创建更多 Google 和读者会喜欢的高质量内容。\n\n\n\n\nWordtune\n\n\n综合写作\n\n\nhttps://wordtune.com\n\n\nWordtune 是终极 AI 写作工具，可以重写、改写和改写您的作品！Wordtune 受到超过 1,000,000 名用户的信任，可以增强文章、学术论文、随笔、电子邮件和任何其他在线内容。\n\n\n\n\nRedacta.me\n\n\n综合写作\n\n\nhttps://redacta.me\n\n\n您的虚拟社区经理。使用人工智能快速、轻松、经济地创建原始西班牙语文本。我们专门训练人工智能用西班牙语写出好的文章。\n\n\n\n\nOthersideai\n\n\n综合写作\n\n\nhttps://othersideai.com\n\n\n您的个人写作助理。无论您在哪里写作，HyperWrite/OthersideAI 都会提供建议和句子补全来改进您的写作。\n\n\n\n\nGlasp\n\n\n综合写作\n\n\nhttps://glasp.co\n\n\nGlasp 是一种社交网络荧光笔，人们可以使用它来突出显示和组织来自网络的引用和想法，而无需在屏幕之间来回切换，并同时访问其他志趣相投的人的学习成果。为人类留下您的数字遗产，同时为自己工作。他们还提供了一个总结 Youtube 视频的工具。\n\n\n\n\nParagraphAI\n\n\n综合写作\n\n\nhttps://paragraphai.com\n\n\nParagraphAI 是一款人工智能写作应用程序，可以编写清晰、简洁、无错误的内容。\n\n\n\n\nDREAM.page\n\n\n综合写作\n\n\nhttps://dream.page\n\n\n借助 AI 的魔力写作和发布！立即加入候补名单。\n\n\n\n\nMaester.app\n\n\n综合写作\n\n\nhttps://maester.app\n\n\n使用我们直观的模板引擎释放 GPT-3 的全部潜力。快速生成根据您的重复需求量身定制的自定义输出，并与全世界分享。它可以在内容管理、大学和工作以及软件开发方面为您提供帮助。\n\n\n\n\nElephas\n\n\n综合写作\n\n\nhttps://elephas.app\n\n\n唯一与您的 Mac 集成的 AI 编写器。跨应用程序工作。\n\n\n\n\nSudowrite\n\n\n综合写作\n\n\nhttps://sudowrite.com\n\n\n用我们神奇的写作 AI 打破作家的瓶颈。您随时可用的头脑风暴伙伴。无需寻找 Beta 读者即可获得 Beta 反馈。“展示，而不是讲述”？我们有一个按钮。\n\n\n\n\nLex\n\n\n综合写作\n\n\nhttps://lex.page\n\n\n解锁你最好的写作\n\n\n\n\nHandyPlugins\n\n\n综合写作\n\n\nhttps://handyplugins.co\n\n\nHandywriter 是一款人工智能写作助手，可以帮助您为 WordPress 创建内容。它可以检查抄袭，甚至可以修复语法和拼写错误。\n\n\n\n\nPenelope AI\n\n\n综合写作\n\n\nhttps://penelope-ai.vercel.app\n\n\n一个成熟的人工智能写作助手。毫不费力地加快您的写作速度 - 释义、总结、生成故事或 AI 自动完成。\n\n\n\n\nGiftastic.ai\n\n\n礼物创意\n\n\nhttps://giftastic.ai\n\n\nGiftastic.AI 是一个个性化的礼物推荐引擎，它使用您要购物的人的个人特征，并推荐他们会喜欢和欣赏的独特而贴心的礼物。\n\n\n\n\nGifts Genie\n\n\n礼物创意\n\n\nhttps://gen.gifts\n\n\nGenie 是一款由 AI 驱动的生日礼物创意生成器。无需再费力想出完美的礼物 - 只需告诉生成器一些关于此人的事情，它就会为您生成礼物创意。它旨在减轻送礼的压力。\n\n\n\n\nSuggest Gift\n\n\n礼物创意\n\n\nhttps://suggest.gift\n\n\n您是否正在为寻找送给心爱之人的完美礼物而苦恼？不要再观望！我们的工具使用最新的 AI 技术来帮助您发现完美的礼物。告别送礼的压力，让我们的技术为您代劳。\n\n\n\n\nCool Gift Ideas\n\n\n礼物创意\n\n\nhttps://coolgiftideas.io\n\n\n送出完美的礼物！根据每个人的身份发现适合他们的创意礼物。\n\n\n\n\nElf Help\n\n\n礼物创意\n\n\nhttps://elfhelp.ai\n\n\n节日礼物 inspo。Elf Help 是您的终极送礼助手，可为您列表中的每个人免费提供富有创意和个性化的建议。\n\n\n\n\nWhisper AI\n\n\n医疗保健\n\n\nhttps://whisper.ai\n\n\n这是一款人工智能助听器。借助 AI，它可以学习并适应不同的听力情况，例如嘈杂的购物市场或家庭聚会。它提供从新功能到声音处理的定期软件升级。\n\n\n\n\nCradle\n\n\n医疗保健\n\n\nhttps://cradle.bio\n\n\nCradle 使用强大的预测算法和 AI 设计建议帮助生物学家在创纪录的时间内设计出改进的蛋白质。\n\n\n\n\nSwagAI\n\n\n人力资源\n\n\nhttps://useslingshot.com\n\n\nSwagAI 是一种 AI 工具，可以帮助你想出可笑的公司 swag。只需告诉我们您在寻找什么，我们的算法就会推荐疯狂（但有时实用）的选项。\n\n\n\n\nAutumn AI\n\n\n人力资源\n\n\nhttps://getautumn.com\n\n\n在没有调查的情况下测量倦怠并防止它。Autumn 与您已经使用的工具相关联，利用 AI 帮助您识别倦怠的早期迹象，并在您的团队中发现模式，例如增加会议、减少 1:1 的频率或周末发送更多消息。不仅仅是数据——秋季也能帮助您采取行动！在每次 1:1 之前获得 1:1 问题提示，为您的团队量身定制，这样您就不必怀疑自己是否提出了正确的问题。每周都会向您发送团队见解，通过 Slack 中有趣且互动的每周总结，帮助您的团队无需额外努力（或其他 Zoom 社交）就能感受到联系。\n\n\n\n\nDost\n\n\n人力资源\n\n\nhttps://getdost.com\n\n\n使用 Dost 的 AI 支持的 Slack 和 MSTeams 应用程序创建安全、无偏见、无微攻击、包容的消息。\n\n\n\n\nGeniusReview\n\n\n人力资源\n\n\nhttps://geniusreview.xyz\n\n\n360° AI 性能评估。使用 GeniusReview 为您的绩效评估问题获得量身定制的答案，从而节省大量时间。\n\n\n\n\nMoveworks\n\n\n人力资源\n\n\nhttps://moveworks.com\n\n\nMoveworks 是第一个使用 AI 解决工作问题和预防问题的员工体验平台。它会自动解决请求、传达更改并向您的团队展示下一步要解决的问题——让您将沮丧的时刻变成神奇的时刻。由于我们的对话式 AI（聊天机器人）精通 100 多种语言，因此 Moveworks 可以在全球范围内提供从总部到家庭办公室的即时帮助。\n\n\n\n\nHireYaY\n\n\n人力资源\n\n\nhttps://hireyay.com\n\n\n再也不会错过合格的候选人。使用 AI 制作引人入胜的招聘广告。一键分发给百万求职者\n\n\n\n\nJobtitlesAI\n\n\n人力资源\n\n\nhttps://jobtitlesai.com\n\n\n准确限定任何职位。我们的机器学习 API 将职位分为两类：领域（销售、财务、IT..）和职位（执行官、管理、助理…），因此您可以优先考虑您感兴趣的职位。\n\n\n\n\nMagic Eraser\n\n\n图像编辑\n\n\nhttps://magiceraser.io\n\n\n在几秒钟内从图像中删除不需要的东西。上传图像，标记您需要删除的位，下载修复后的图像。\n\n\n\n\nPhotoroom\n\n\n图像编辑\n\n\nhttps://photoroom.com\n\n\n仅使用您的手机创建产品和肖像图片。删除背景、更改背景和展示产品。\n\n\n\n\nGreen Screen AI\n\n\n图像编辑\n\n\nhttps://greenscreenai.com\n\n\nGreen Screen AI 可让您将图片背景更改为您能想到的任何内容！使用生成式 AI，您可以将您的狗放在外星丛林中，或者将您的猫变成太空牛仔。\n\n\n\n\nNostalgia Photo\n\n\n图像编辑\n\n\nhttps://nostalgia.photo\n\n\nNostalgia Photo 使用最新的尖端人工智能技术让旧照片重现生机。只需点击几下和几美分即可获得最高分辨率。\n\n\n\n\nRestorePhotos\n\n\n图像编辑\n\n\nhttps://restorephotos.io\n\n\n为所有人使用 AI 修复旧照片。有旧的和模糊的面部照片吗？让我们的 AI 恢复它们，让这些记忆得以延续。100% 免费 – 立即恢复您的照片。\n\n\n\n\nRemove.bg\n\n\n图像编辑\n\n\nhttps://remove.bg\n\n\n一键式在 5 秒内自动 100% 删除背景。多亏了 remove.bg 的智能 AI，您可以缩短编辑时间 - 并获得更多乐趣！\n\n\n\n\nPerfectly Clear Video\n\n\n图像编辑\n\n\nhttps://eyeq.photos\n\n\nPerfectly Clear Video 提供即时、自动的照片校正和视频增强功能。是全球领先的图像自动校正和AI视频增强提供商。\n\n\n\n\nAI. Image Enlarger\n\n\n图像编辑\n\n\nhttps://imglarger.com\n\n\n多合一 AI 工具包可帮助您增强和提升图像质量。在不损失质量的情况下提高图像分辨率。\n\n\n\n\nBg.Eraser\n\n\n图像编辑\n\n\nhttps://bgeraser.com\n\n\n强大的人工智能修复和图片清理技术。在几秒钟内删除不需要的对象和水印。\n\n\n\n\nHama - Image Editing\n\n\n图像编辑\n\n\nhttps://hama.app\n\n\n瞬间擦除图像中的人物或物体。\n\n\n\n\nTopaz Photo AI\n\n\n图像编辑\n\n\nhttps://topazlabs.com\n\n\n在自动驾驶仪上最大化您的图像质量。使用明天的技术锐化、消除噪点并提高照片的分辨率。Topaz Photo Al 可增强您的图像质量，让您可以专注于摄影的创意部分。\n\n\n\n\nPalette.fm\n\n\n图像编辑\n\n\nhttps://palette.fm\n\n\n自动为黑白图片着色，无需注册，而且免费！\n\n\n\n\nVisio Studio\n\n\n图像编辑\n\n\nhttps://visio.studio\n\n\n先进的背景去除工具，由计算机视觉技术提供支持。Visio Studio 允许您直接从手机编辑和优化图片。\n\n\n\n\nEvoto AI\n\n\n图像编辑\n\n\nhttps://evoto.ai\n\n\nEvoto 是下一代照片编辑器，可将您从繁琐的工作中解放出来，让您以 10 倍的速度处理数千张照片并获得卓越的质量，并帮助您将想象力变为现实。\n\n\n\n\nErase.bg\n\n\n图像编辑\n\n\nhttps://erase.bg\n\n\n免费从图像中删除背景。从人类、动物或物体的图像中去除背景，并免费下载高分辨率图像。\n\n\n\n\nBria\n\n\n图像编辑\n\n\nhttps://bria.ai\n\n\n集成 Bria 的人工智能 API 以自动化和扩展视频和图像的创建。\n\n\n\n\nQuickTools by Picsart\n\n\n图像编辑\n\n\nhttps://tools.picsart.com\n\n\n借助 Picsart Quicktools，您可以访问范围广泛的工具，从而轻松转换文件类型、创建自定义日历、增强图像等。所有这些工具都方便地位于一个地方。\n\n\n\n\nRadiant Photo\n\n\n图像编辑\n\n\nhttps://radiantimaginglabs.com\n\n\n你的照片应该是容光焕发的。获得具有完美色彩再现的优质成品照片，并在创纪录的时间内交付给您。您的照片 — 简直容光焕发。他们本来的样子。\n\n\n\n\nLet’s Enhance\n\n\n图像编辑\n\n\nhttps://letsenhance.io\n\n\n图像增强器和升级器。自动 AI 编辑器可在不降低质量的情况下提高图像分辨率。一键让您的照片呈现最佳效果\n\n\n\n\nStable Horde\n\n\n图像生成器\n\n\nhttps://stablehorde.net\n\n\n深度学习文生图模型工作者的众包分布式集群。还提供无需安装和技术专业知识的客户端界面\n\n\n\n\nGo Charlie\n\n\n图像生成器\n\n\nhttps://gocharlie.ai\n\n\n单击按钮即可创建图像、博客、广告、网站标题。\n\n\n\n\nStable Diffusion\n\n\n图像生成器\n\n\nhttps://stability.ai\n\n\nStable Diffusion 是一种深度学习的文本到图像模型，于 2022 年发布。它主要用于生成以文本描述为条件的详细图像，但它也可以应用于其他任务，例如修复、修复和生成图像到- 由文本提示引导的图像翻译。\n\n\n\n\nGetimg.ai\n\n\n图像生成器\n\n\nhttps://getimg.ai\n\n\n使用 AI 创建图像所需的一切。神奇的 AI 艺术工具。生成原始图像、修改现有图像、将图片扩展到原始边界之外等等。\n\n\n\n\nAragon - Image Generation\n\n\n图像生成器\n\n\nhttps://aragon.ai\n\n\n使用 AI 以 10 倍的速度创建令人惊叹的艺术作品和图像。\n\n\n\n\nRocketAI\n\n\n图像生成器\n\n\nhttps://rocketai.io\n\n\n设计的未来是可编程的。Rocket AI 是一个 SaaS 平台，可使用 AI 创建和编辑产品图像并改善电子商务销售和广告效果。我们为电子商务企业提供人工智能解决方案，以改善他们的产品形象，并从简单的文本提示中产生新的想法和设计概念。\n\n\n\n\nPollinations\n\n\n图像生成器\n\n\nhttps://pollinations.ai\n\n\nPollinations 希望使创造力多样化，并通过数字生态系统传播它。无论是图像、视频还是音频，我们都邀请人们借助 AI 想象新世界。对于公司，我们的开发人员在最新的 AI 模型之上编写代码，提供定制的结果和特定的美学。借助 API，AI 创作可以直接集成到网站和社交媒体平台中。创作变得简单、快速和有趣。\n\n\n\n\nDiffusion Land\n\n\n图像生成器\n\n\nhttps://diffusion.land\n\n\nDiffusion Land 允许您使用各种 AI 模型来生成图像。他们还有几个预建的概念，您可以使用这些概念来生成某些类型的图像。\n\n\n\n\nDallE-2\n\n\n图像生成器\n\n\nhttps://openai.com\n\n\nDALL·E 2 可以根据文字描述创建原创、逼真的图像和艺术作品。它可以组合概念、属性和样式。\n\n\n\n\nGetalpaca\n\n\n图像生成器\n\n\nhttps://getalpaca.io\n\n\nalpaca 是一个 Photoshop 插件，用于将 AI 图像生成能力与人类技能相结合。\n\n\n\n\nCanva Text to Image\n\n\n图像生成器\n\n\nhttps://canva.com\n\n\n可生成您描述的任何图像的全新技术。\n\n\n\n\nStock AI\n\n\n图像生成器\n\n\nhttps://stockai.com\n\n\n获得完美的图像。每次。准确找到您需要的图像。如果它不存在，我们会立即为您创建。\n\n\n\n\nCraiyon\n\n\n图像生成器\n\n\nhttps://craiyon.com\n\n\nAI 模型从任何提示中绘制图像！\n\n\n\n\nSoreal.AI Studio\n\n\n图像生成器\n\n\nhttps://soreal.ai\n\n\nAI图像生成入门最简单的方法\n\n\n\n\nImgcreator\n\n\n图像生成器\n\n\nhttps://imgcreator.zmo.ai\n\n\n使用文本创建图像。生成基于文本的图像以帮助您思考和创作。\n\n\n\n\nStylized\n\n\n图像生成器\n\n\nhttps://stylized.ai\n\n\n几秒钟内即可获得专业的产品照片。Stylized 使用人工智能创建令人惊叹的产品照片和社论 - 无需工作室\n\n\n\n\nArtssy\n\n\n图像生成器\n\n\nhttps://artssy.co\n\n\n使用 Artssy AI 一键创建无限图像，探索无限可能的世界。当您可以立即创建完美的图像时，停止为免版税的照片付费。\n\n\n\n\nNijijourney\n\n\n图像生成器\n\n\nhttps://nijijourney.com\n\n\n动漫迷的 NijiJourney AI。新的 niji 模型经过精心调整，可以制作动漫和插画风格。它对动漫，动漫风格和动漫美学有更多的了解。它非常适合动态和动作镜头，以及一般以角色为中心的构图。\n\n\n\n\nRoll Art Die\n\n\n图像生成器\n\n\nhttps://roll-art-die.com\n\n\n在您的 Apple Silicon 设备上使用 StableDiffusion。仅使用文本生成 AI 艺术品。将您梦想中的艺术品变为现实。无需云订阅。\n\n\n\n\nDreamer\n\n\n图像生成器\n\n\nhttps://slashdreamer.com\n\n\n将 Notion 中的 Stable Diffusion 集成到 AI 中，使用新的斜杠命令生成图像。\n\n\n\n\nEnterpix\n\n\n图像生成器\n\n\nhttps://enterpix.app\n\n\n人工智能生成的图像搜索引擎。\n\n\n\n\nXno.ai\n\n\n图像生成器\n\n\nhttps://xno.ai\n\n\n使用 39 个 GPU 探索 19 个顶级文本到图像 AI。\n\n\n\n\nSpellbook\n\n\n法律助手\n\n\nhttps://spellbook.legal\n\n\n使用 AI 起草合同的速度提高了 3 倍。Spellbook 使用 GPT-3 在 Microsoft Word 中审查和建议合同语言。Spellbook 接受了数十亿行法律术语的培训，可以立即为您的合同建议语言。\n\n\n\n\nCasetext\n\n\n法律助手\n\n\nhttps://casetext.com\n\n\n发现 Lexis 和 Westlaw 遗漏案例的现代搜索技术。不要冒失去先例的风险。以实惠的价格获得更快、更准确的法律研究。\n\n\n\n\nDetangle.ai\n\n\n法律助手\n\n\nhttps://detangle.ai\n\n\nDetangle 为您提供 AI 生成的法律文件摘要，以便您真正理解它们。\n\n\n\n\nActivazon\n\n\n法律助手\n\n\nhttps://activazon.com\n\n\nActivazon 是一项犯罪报告分析服务，旨在让居民和访客了解在他们的社区和其他地方发生的活动。\n\n\n\n\nLegal Robot\n\n\n法律助手\n\n\nhttps://legalrobot.com\n\n\n法律建议需要仔细分析法律及其如何适用于特定情况。Legal Robot 提供通过自动分析与其他法律文件和判例法相关的法律文件而生成的信息。我们还提供语言和统计分析，帮助您了解法律文件中的潜在问题。\n\n\n\n\nFerret\n\n\n法律助手\n\n\nhttps://ferret.ai\n\n\nFerret 无与伦比的 AI 应用程序，结合世界一流的信息，为您提供独家关系情报，可以帮助您避开高风险人群并发现有前途的机会。\n\n\n\n\nDoNotPay\n\n\n法律助手\n\n\nhttps://donotpay.com\n\n\n世界上第一个机器人律师。DoNotPay 应用程序是世界上第一位机器人律师的故乡。只需按一下按钮，就可以打击公司、打击官僚主义并起诉任何人。\n\n\n\n\nReplika\n\n\n生活助手\n\n\nhttps://replika.com\n\n\n关心的AI伴侣。总是在这里倾听和交谈。永远在你身边。\n\n\n\n\nFind Your Next Book\n\n\n生活助手\n\n\nhttps://findyournextbook.ai\n\n\nFind Your Next Book 是一项图书推荐服务，旨在帮助那些难以决定阅读什么的人。只需根据人物、背景和/或情节描述您想要的读物，我们就会从我们的数千本书数据库中推荐最佳选择。\n\n\n\n\nThekeys\n\n\n生活助手\n\n\nhttps://thekeys.ai\n\n\n您知道自己想说什么，只是不确定如何说。Keys 可帮助您以正确的方式说话，而不会改变您的意图，或听起来像机器人。\n\n\n\n\nAI Trip Planner\n\n\n生活助手\n\n\nhttps://buildai.space\n\n\nAI Trip Planner 是一款全球旅行计划应用程序，可为用户前往世界任何目的地的旅行自动创建详细的每日行程。所有用户需要做的就是指定他们的旅行长度和他们想要的目的地，应用程序将处理剩下的事情\n\n\n\n\nCaktus\n\n\n生活助手\n\n\nhttps://caktus.ai\n\n\n为学生撰写论文、讨论问题、一般编码帮助和专业工作申请帮助提供的 AI 解决方案。\n\n\n\n\nJustLearn\n\n\n生活助手\n\n\nhttps://justlearn.com\n\n\n您可以使用 Justlearn 创建 AI 朋友并与他们交谈。\n\n\n\n\nBlackInk\n\n\n生活助手\n\n\nhttps://blackink.ai\n\n\n在几秒钟内创建您自己独特的闪光纹身。停止花费数月时间在 Pinterest 上搜索你的下一个纹身。使用 BlackInk 的 AI 在几秒钟内生成定制的独特纹身，专为您打造类似纹身的设计。\n\n\n\n\nWrite Me A Cover Letter\n\n\n生活助手\n\n\nhttps://WriteMeACoverLetter.com\n\n\n使用 AI 在几秒钟内生成求职信。只需上传您的简历，分享您想要的工作的链接，剩下的交给我们。\n\n\n\n\nTinyWow\n\n\n生活助手\n\n\nhttps://tinywow.com\n\n\n人工智能驱动的实用工具，让您的生活更轻松。最常见的工具包括 PDF、视频、图像、AI 写入和转换工具。\n\n\n\n\nProdigy AI\n\n\n生活助手\n\n\nhttps://ai.prodi.gg\n\n\n面向开发人员的 GPT 职业教练。根据您的独特技能、经验和目标，立即获得个性化的职业建议和指导。通过人工智能。\n\n\n\n\nCircle Labs\n\n\n生活助手\n\n\nhttps://circle.isyourshadowyou.com\n\n\n我们制造的 AI 是您真正愿意花时间与之交谈的。有个性、有棱有角的人工智能。\n\n\n\n\nElektrif AI\n\n\n生活助手\n\n\nhttps://elektrif.ai\n\n\n做最好的自己，永远不要无话可说，花更多的时间去真正了解一个人。Elektrif.AI 使用 GPT3 生成个性化的对话开场白、改写您的消息以使其更具吸引力等。\n\n\n\n\nResume Worded\n\n\n生活助手\n\n\nhttps://resumeworded.com\n\n\n改善您的简历和 LinkedIn 个人资料。我们的人工智能平台由顶级招聘人员设计，可立即为您的简历和 LinkedIn 个人资料提供量身定制的反馈。获得 5 倍以上的面试、机会和工作机会。\n\n\n\n\nReggi\n\n\n生活助手\n\n\nhttps://yfj.social\n\n\nReggi 帮助您在实时商店中跟踪您的购买和预算，在您购物时将正确的税费应用到您的小计中。整体无压力的购物体验。\n\n\n\n\nBrandmark\n\n\nLogo 生成器\n\n\nhttps://brandmark.io\n\n\n为您的企业创建独特、专业的徽标。使用我们免费的 AI 驱动设计工具，为您的下一个徽标项目获取颜色和字体创意。\n\n\n\n\nLooka\n\n\nLogo 生成器\n\n\nhttps://looka.grsm.io\n\n\nLooka Logo Maker 将您的徽标设计偏好与人工智能相结合，帮助您创建自己喜欢的自定义徽标。\n\n\n\n\nMake Logo AI\n\n\nLogo 生成器\n\n\nhttps://makelogoai.com\n\n\n不到一杯咖啡的设计师品质标志。高清+透明背景。在不到 24 小时内交付。商业里\n\n\n\n\nNamecheap Logo Maker\n\n\nLogo 生成器\n\n\nhttps://namecheap.com\n\n\n只需回答几个问题，即可免费下载数百个徽标。\n\n\n\n\nSitekick\n\n\n低代码/无代码\n\n\nhttps://sitekick.ai\n\n\nSitekick 是一个 AI 登陆页面构建器。它允许您创建漂亮的登录页面，而无需编码、设计或文案写作技能。\n\n\n\n\nRobovision.ai\n\n\n低代码/无代码\n\n\nhttps://robovision.ai\n\n\n打造有效的动态视觉 AI。Robovision 提供涵盖整个 AI 生命周期的视觉 AI 平台。在当今不断变化的商业环境中简化开发、实施和调整 AI 的整个过程。\n\n\n\n\nDust\n\n\n低代码/无代码\n\n\nhttps://dust.tt\n\n\n设计和部署大型语言模型应用程序。快速工程，重新构想🔥 建立在多年使用大型语言模型的经验之上。为了一个目标，帮助加速他们的部署。\n\n\n\n\nNeon AI\n\n\n低代码/无代码\n\n\nhttps://neon.ai\n\n\n使用 Neon AI 的支持技术创建最先进的语音应用程序。Neon AI SDK 将高级人工智能和自然语言理解集成到一个紧密结合的软件工程平台中。想想 Amazon Alexa、Google Home、Apple Siri 和 Microsoft Cortana - 以及免费的开源软件。他们还在其网站上列出了适用于 Mycroft Mark II 的 AI 操作系统。\n\n\n\n\nVWO\n\n\n低代码/无代码\n\n\nhttps://vwo.com\n\n\n将您的访问者变成付费客户。立即设置您的第一个实验。\n\n\n\n\nDurable AI\n\n\n低代码/无代码\n\n\nhttps://durable.ai\n\n\n我们的使命是使用能够进行人类推理和对话的可解释 AI 来转变对定制软件的访问。我们设想的未来是，自定义、灵活和耐用的软件将民主化并可供所有人使用。\n\n\n\n\nTeleporthq\n\n\n低代码/无代码\n\n\nhttps://teleporthq.io\n\n\nTeleportHQ 是具有集成 UI 开发和内容建模工具的协作前端平台。一个强大的可视化构建器，可立即创建和发布您的无头静态网站。\n\n\n\n\nDebuild\n\n\n低代码/无代码\n\n\nhttps://debuild.app\n\n\n快速构建 Web 应用程序。\n\n\n\n\nMonitaur\n\n\n低代码/无代码\n\n\nhttps://monitaur.ai\n\n\n获得可根据您的业务扩展的有据可查的合乎道德的 AI。Monitaur 可帮助您审核、跟踪和记录 AI 和算法的实时结果，以实现最佳性能和合规性。我们的平台旨在与接触您的 AI 的每个团队集成。\n\n\n\n\nTeachable Machine\n\n\n低代码/无代码\n\n\nhttps://teachablemachine.withgoogle.com\n\n\nTeachable Machine 是一种基于网络的工具，可以让每个人快速、轻松地创建机器学习模型。它旨在供教育工作者、艺术家、学生、创新者、各种类型的制造者使用——实际上，任何有想法想要探索的人。不需要必备的机器学习知识。\n\n\n\n\nBrancher AI\n\n\n低代码/无代码\n\n\nhttps://brancher.ai\n\n\n通过让用户能够将 AI 模型连接在一起并生成独特的 AI 驱动的应用程序，让所有人都能访问 AI。货币化并与世界分享您的创作。\n\n\n\n\nAxiom\n\n\n低代码/无代码\n\n\nhttps://axiom.ai\n\n\nAxiom 是一种浏览器扩展程序，可通过在任何网站或 Web 应用程序上自动执行网站操作和重复性任务来帮助您节省时间。\n\n\n\n\nRoboflow\n\n\n低代码/无代码\n\n\nhttps://roboflow.com\n\n\n给你的软件一种既视感。只需几张图片，您就可以在下午训练一个可以工作的计算机视觉模型。\n\n\n\n\nNanonets\n\n\n低代码/无代码\n\n\nhttps://nanonets.com\n\n\n使用 AI 自动执行手动数据输入！立即从文档、文本、图像和电子邮件中捕获数据。减少周转时间和所需的手动工作。基于 OCR（光学字符识别）的 AI 平台。\n\n\n\n\nLobe\n\n\n低代码/无代码\n\n\nhttps://lobe.ai\n\n\nLobe 使用免费、易于使用的工具帮助您训练机器学习模型。它只需向它展示您希望它学习的示例，它就会自动训练可以在您的应用程序中发布的自定义机器学习模型。\n\n\n\n\nLiner.ai\n\n\n低代码/无代码\n\n\nhttps://liner.ai\n\n\nLiner 是一款免费工具，可让您轻松训练 ML 模型。它获取您的训练数据并为您提供易于集成的 ML 模型。无需编码或机器学习方面的专业知识。\n\n\n\n\nCogniflow\n\n\n低代码/无代码\n\n\nhttps://cogniflow.ai\n\n\n从文本、图像或音频构建 AI 的最简单方法。几分钟后。无需代码。\n\n\n\n\nBuild AI\n\n\n低代码/无代码\n\n\nhttps://buildai.space\n\n\nBuild AI 可帮助您在几分钟内构建 AI 应用程序。您将能够完全自己构建应用程序并发布它。您将能够根据需要对其进行更新，包括改进和完善您的提示，使您的应用达到最佳状态\n\n\n\n\nFelvin\n\n\n低代码/无代码\n\n\nhttps://felvin.com\n\n\nFelvin 使非开发人员能够创建、发现 AI 应用程序并从中获利。我们的无代码工具使您可以轻松创建 AI 应用程序并将它们放在 SEO 优化的图库中以供发现。\n\n\n\n\nSeek\n\n\n低代码/无代码\n\n\nhttps://seek.ai\n\n\n智能数据层。询问您的任何数据并立即获得答案\n\n\n\n\nLightning AI\n\n\n低代码/无代码\n\n\nhttps://lightning.ai\n\n\n闪电般快速地构建模型和全堆栈 AI 应用程序。使用 Lightning App 模板构建模型和 AI 驱动的云应用程序，无需 DIY 基础设施、成本管理、扩展和其他令人头疼的问题。\n\n\n\n\nBrowse AI\n\n\n低代码/无代码\n\n\nhttps://browse.ai\n\n\n从任何网站提取和监控数据的最简单方法。在 2 分钟内训练一个机器人。无需编码。\n\n\n\n\nSoftr Studio\n\n\n低代码/无代码\n\n\nhttps://softr.io\n\n\n为您的企业构建自定义应用程序，就像乐高积木一样简单。使用他们的 AI，只需单击一下即可在 Softr 中生成图像和复制。将您的 Airtable 或 Google Sheets 变成客户门户、合作伙伴应用程序或内部工具。\n\n\n\n\nSymanto Text Insights\n\n\n低代码/无代码\n\n\nhttps://symanto.com\n\n\n市场领先的 NLP API。通过实时分析和简单的系统集成，利用文本数据获得更好的业务洞察力。\n\n\n\n\nMutiny\n\n\n低代码/无代码\n\n\nhttps://mutinyhq.com\n\n\nMutiny 是一个无代码 AI 平台，可帮助营销人员在没有工程师的情况下将他们的漏斗顶部需求转化为收入。\n\n\n\n\nZevi.ai\n\n\n低代码/无代码\n\n\nhttps://zevi.ai\n\n\n通过 AI 驱动的搜索和发现解决方案改善业务成果 通过以意图为中心、易于集成的网站搜索引擎引导您的潜在客户从发现到转化，这有助于提高参与度和销售额\n\n\n\n\nRiku.ai\n\n\n低代码/无代码\n\n\nhttps://riku.ai\n\n\n使您无需代码即可构建 AI 模型。通过集成、API 或公共共享链接使用 AI。每个人都可以访问 AI。\n\n\n\n\nAI Surge Cloud\n\n\n低代码/无代码\n\n\nhttps://ai-surge.cloud\n\n\nAI Surge 是一个无代码决策智能平台，可帮助企业构建生产优先的 ModelOps 管道，无需编写一行代码即可将数据科学带入生活。这就像没有数据科学家的数据科学。我们正在帮助企业将数据交付速度提高 10 倍，并将成本降低 90%。\n\n\n\n\n10Web\n\n\n低代码/无代码\n\n\nhttps://10web.io\n\n\nAI - 供电的 WordPress 平台。至少可以说，自动化的网站构建器、托管和 PageSpeed Booster。\n\n\n\n\nRetune\n\n\n低代码/无代码\n\n\nhttps://retune.so\n\n\n使用 GPT-3 创建微调语言模型并从中获利的终极工具。借助 re:tune，您可以轻松地为任何行业或用例训练和定制您自己的 AI 助手，并生成 API 以将其集成到您自己的应用程序中。\n\n\n\n\nHeyday\n\n\n记忆\n\n\nhttps://heyday.xyz\n\n\nHeyday 是一款由 AI 驱动的记忆助手，可以重新显示您在浏览网页时忘记的内容。记住更多你学到的东西。自动地。\n\n\n\n\nPersonal.ai\n\n\n记忆\n\n\nhttps://personal.ai\n\n\nPersonalAI 是一种 AI 工具，可以以思维的速度产生新想法、回忆关键概念和编写原创内容。新想法的自动编目和您存储的所有内容的集中知识中心。\n\n\n\n\nRewind AI\n\n\n记忆\n\n\nhttps://rewind.ai\n\n\nRewind 是您生活的搜索引擎。这是一款专为隐私设计的 macOS 应用程序，可让您找到您所见、所说或所听的任何内容。\n\n\n\n\nNatural Language Playlist\n\n\n音乐\n\n\nhttps://naturallanguageplaylist.com\n\n\nAI 生成混音带和播放列表。输入一个句子作为提示，并返回由 AI 策划的歌曲列表！\n\n\n\n\nEndel\n\n\n音乐\n\n\nhttps://endel.io\n\n\n个性化音景可帮助您集中注意力、放松身心和入睡。以神经科学为后盾。\n\n\n\n\nHarmonai\n\n\n音乐\n\n\nhttps://harmonai.org\n\n\n我们是一个社区驱动的组织，发布开源生成音频工具，让每个人都能更轻松、更有趣地制作音乐\n\n\n\n\nRiffusion\n\n\n音乐\n\n\nhttps://riffusion.com\n\n\nRiffusion 根据文本提示生成音乐。尝试您最喜欢的风格、萨克斯管或小提琴等乐器、阿拉伯语或牙买加语等修饰语、爵士乐或福音音乐等流派、教堂钟声或雨声等声音，或任意组合\n\n\n\n\nSonify\n\n\n音乐\n\n\nhttps://sonify.io\n\n\nSonify 在音频、数据和新兴技术的交叉领域进行创新。我们设计和开发音频优先的产品和数据驱动的解决方案。\n\n\n\n\nBeatoven.ai\n\n\n音乐\n\n\nhttps://beatoven.ai\n\n\nBeatoven.AI 使用先进的 AI 音乐生成技术来创作独特的基于情绪的音乐，以适合您的视频或播客的每个部分。\n\n\n\n\nAmper\n\n\n音乐\n\n\nhttps://ampermusic.com\n\n\nAmper 的使命是让任何人都能通过音乐创造性地表达自己，无论他们的背景、专业知识或资源如何。Amper 构建由我们的 Creative AI 提供支持的工具，以帮助人们创作和定制原创音乐。他们还提供了一个 API，您可以使用它来创建自己的产品。\n\n\n\n\nSoundful\n\n\n音乐\n\n\nhttps://soundful.com\n\n\nSoundful 使创作者只需单击一个按钮即可生成免版税曲目。Soundful 音乐的音质如此丰富，你不会相信它是用 AI 制作的。\n\n\n\n\nSongtell\n\n\n音乐\n\n\nhttps://songtell.com\n\n\nSongtell 是有史以来第一个由 AI 生成的歌曲含义库，生成了超过 20000 首歌曲含义。您还可以订购印有您最喜爱歌曲含义的海报。查看他们的 subreddit r/songtell 了解更多详情！\n\n\n\n\nPop2Piano\n\n\n音乐\n\n\nhttps://sweetcocoa.github.io\n\n\n从您想要的任何歌曲中播放基于流行音乐的钢琴翻唱。通过从列表中选择项目来更改钢琴翻唱的歌曲和风格。\n\n\n\n\nBoomy\n\n\n音乐\n\n\nhttps://boomy.com\n\n\n制作即时音乐并与世界分享。在几秒钟内创作原创歌曲，即使您以前从未制作过音乐。在 Spotify、TikTok、YouTube 和全球 40 多个其他平台上的每次收听都将获得报酬。\n\n\n\n\nOpen Voice OS\n\n\n音乐\n\n\nhttps://openvoiceos.com\n\n\nOpen Voice OS 展示了开源语音 AI 在一系列设备上的强大功能。社区支持的 Linux 发行版。\n\n\n\n\nEmergent Drums\n\n\n音乐\n\n\nhttps://audialab.com\n\n\n使用人工智能生成独特的鼓样本。使用我们的突破性插件生成无尽的鼓样本，全部免版税。\n\n\n\n\nMubert\n\n\n音乐\n\n\nhttps://mubert.com\n\n\nMubert - 面向内容创作者、品牌和开发商的全新免版税音乐生态系统 🔥。来看看我们的高品质音乐如何提升您的内容⏩！\n\n\n\n\nSplashmusic\n\n\n音乐\n\n\nhttps://splashmusic.com\n\n\n将音乐创作的乐趣带给每个人\n\n\n\n\nAiva\n\n\n音乐\n\n\nhttps://aiva.ai\n\n\nAIVA，人工智能音乐作曲家，可为您的项目创作原创和个性化的音乐。\n\n\n\n\nRephrasely\n\n\n改写\n\n\nhttps://rephrasely.com\n\n\n释义是写作过程中很自然的一部分，因为它可以帮助您理清思路并使您的措辞适合您的听众。使用 Rephrasely 有助于构建和简化这项工作，我们的释义工具提供了 20 种模式，其中许多是免费的，以实现这一点。我们提供的 20 种模式多种多样，包括摘要工具、免费语法检查器、简化文本的模式和句子缩短器。\n\n\n\n\nParaphraser\n\n\n改写\n\n\nhttps://paraphrasetool.com\n\n\nParaphrase Tool 使用 AI 生成 100 多种语言的文本变体。\n\n\n\n\nQuillbot Paraphraser\n\n\n改写\n\n\nhttps://quillbot.com/\n\n\nQuillbot 将重写您的文本。通过编写或粘贴内容然后单击释义来免费开始。\n\n\n\n\nTavus\n\n\n个性化视频\n\n\nhttps://tavus.io\n\n\n认识 Tavus，这是一款程序化个性化视频工具，专为希望改变建立关系方式的顶级产品、营销和销售团队打造。录制一次并发现 Tavus 的力量，因为我们的 AI 会自动为大大小小的观众生成个性化视频。\n\n\n\n\nRephrase\n\n\n个性化视频\n\n\nhttps://rephrase.ai\n\n\nRephrase 的技术可大规模创建超个性化视频，从而提高参与度和业务效率。\n\n\n\n\nWindsor\n\n\n个性化视频\n\n\nhttps://windsor.io\n\n\n向每一位客户发送个人视频，让他们永远不会忘记您的品牌录制一个视频，Windsor 的 AI 会向您的客户发送数百万个个性化副本。\n\n\n\n\nBHuman\n\n\n个性化视频\n\n\nhttps://bhuman.ai\n\n\n制作单个视频并为成千上万的收件人进行个性化设置。通过任何渠道交付并立即测量结果。您可以通过录制模板、连接数据然后生成个性化视频来实现。\n\n\n\n\nVidyo\n\n\n个性化视频\n\n\nhttps://vidyo.ai\n\n\n立即将长视频制作成短视频。使用强大的 AI 从您现有的视频中创建短片 ✨ 节省 90% 的时间和精力。\n\n\n\n\nDeepL\n\n\n生产力\n\n\nhttps://deepl.com\n\n\nDeepL 是世界上最准确、最细致的机器翻译。通过结合先进的 AI 技术和无与伦比的翻译准确性，它的准确度比最接近的竞争对手高出 3 倍以上。\n\n\n\n\nScale\n\n\n生产力\n\n\nhttps://scale.com\n\n\n借助更好的数据，更快地从您的 AI 投资中获得价值。更好的数据会带来更高性能的模型。高性能模型导致更快的部署。\n\n\n\n\nOracle\n\n\n生产力\n\n\nhttps://askoracle.app\n\n\nOracle 已经为您提供了所有答案。从 Oracle 获得即时答案，节省时间和精力。Ask Oracle 可以连接并回答来自 Slack、Docs 和 Notion 的问题。\n\n\n\n\nMerlin\n\n\n生产力\n\n\nhttps://merlin.foyer.work\n\n\nMerlin 在您最喜爱的所有网站上为您提供 OpenAI 的 ChatGPT 的强大功能。例如：Gmail、g-sheets、Twitter、Linkedin 等。您在线搜索或写作的任何地方。使用 Merlin，您可以快速编辑电子邮件、撰写 Twitter 回复或创建 Excel 公式。\n\n\n\n\nEnzyme\n\n\n生产力\n\n\nhttps://enzyme.com\n\n\n酶 QMS 软件包括从设计控制到 CAPA 的产品开发生命周期所有阶段的模块。我们的内部专家随时为您提供支持！我们可以指导您完成质量挑战和监管提交流程。立即注册演示。\n\n\n\n\nAlbus\n\n\n生产力\n\n\nhttps://springworks.in\n\n\nAlbus 是 Slack 内部的 AI 助手。您可以通过向应用程序发送消息直接向 Albus 提问。一些示例包括营销人员使用 Albus 为其目标受众创建个性化且引人入胜的内容，或者设计师可以使用 Albus 为新设计产生创意并创建独特且引人入胜的视觉内容。\n\n\n\n\nGlean\n\n\n生产力\n\n\nhttps://glean.com\n\n\n立即了解您的公司知道什么。收集公司所有应用程序的搜索，以帮助您准确找到您需要的内容并发现您应该了解的内容。\n\n\n\n\nMarketplan\n\n\n生产力\n\n\nhttps://marketplan.io\n\n\n一体化营销平台。从一个强大的地方计划、执行、规划和优化您的整个营销策略。\n\n\n\n\nAlfred\n\n\n生产力\n\n\nhttps://alfredsearch.com\n\n\nAlfred 是适用于 iOS 的 GPT 聊天助手。它是一种新的人工智能搜索和内容创建引擎，将无广告搜索和内容创建结合到一个易于使用的应用程序体验中。在 OpenAI 开创性的 GPT-3 的支持下，Alfred 理解您的自然语言并提供准确且相关的答案。使用 Alfred，搜索和查找信息从未如此简单或方便。立即尝试，体验搜索和内容创建的未来。\n\n\n\n\nQatalog\n\n\n生产力\n\n\nhttps://qatalog.com\n\n\n为工作定制的操作系统。Qatalog 是一种项目管理/协作 AI 工具，可以无缝管理人员、运营和知识。\n\n\n\n\nKrisp\n\n\n生产力\n\n\nhttps://krisp.ai\n\n\nKrisp 的人工智能解决方案消除了会议中的背景噪音和回声，只留下人声。具有噪音和回声消除、小部件、洞察力和通话摘要等功能。\n\n\n\n\nMem.ai\n\n\n生产力\n\n\nhttps://mem.ai\n\n\n让 AI 组织您团队的工作——从会议记录、项目到知识库。所有这些都可以立即搜索并且很容易被发现。\n\n\n\n\nReclaim AI\n\n\n生产力\n\n\nhttps://reclaim.ai\n\n\n用于 Google 日历的任务管理和计划的 AI。Reclaim 为您的团队的优先事项创建完美的时间表，并通过智能、灵活和自适应的时间编排节省高达 40% 的工作周时间。\n\n\n\n\nXembly\n\n\n生产力\n\n\nhttps://xembly.com\n\n\n一个自动化的参谋长来处理让你慢下来的任务。通过平凡的工作。专注于意义。\n\n\n\n\nSlidesAI\n\n\n生产力\n\n\nhttps://slidesai.io\n\n\n使用 AI 在几秒钟内创建演示幻灯片告别繁琐的手动幻灯片创建。让 AI 为您编写大纲和演示内容。使用他们的工具，您可以立即从任何文本轻松创建专业、引人入胜的幻灯片。适用于谷歌幻灯片。Microsoft Powerpoint 即将推出。\n\n\n\n\nNoty.ai\n\n\n生产力\n\n\nhttps://noty.ai\n\n\nAI 会议助手将 Google Meet 转化为行动、任务和跟进。功能包括：实时转录和一键突出显示。AI 摘要和会议情报。自动跟进。\n\n\n\n\nChatGPT\n\n\n生产力\n\n\nhttps://chat.openai.com\n\n\nChatGPT：优化对话的语言模型。对话格式使 ChatGPT 可以回答后续问题、承认错误、挑战不正确的前提并拒绝不适当的请求。\n\n\n\n\nSupernormal\n\n\n生产力\n\n\nhttps://supernormal.com\n\n\nSuperNormal 是一个让队友可以全天发送异步视频更新的平台。使用 AI 支持的摘要进行快速视频更新有助于让团队保持更新和联系，而无需安排会议或跨时区同步。\n\n\n\n\nAdobe Sensei\n\n\n生产力\n\n\nhttps://adobe.com\n\n\n创建和提供理想的客户体验可能是一项复杂的任务。Sensei 使用 AI 和机器学习来简化这些任务，帮助您简化创意过程、做出明智的决策并进行针对性营销以获得更好的结果。\n\n\n\n\ntyply\n\n\n生产力\n\n\nhttps://typly.app\n\n\n使用我们的键盘单击一下即可回复您的所有消息！Typly 会自动生成与对话上下文相匹配的句子。允许您通过单击来回答问题或继续话题。\n\n\n\n\nPromptist\n\n\n提示\n\n\nhttps://huggingface.co\n\n\nPromptist 是 Stable Diffusion v1-4 的提示界面，可优化用户对模型首选提示的输入。Hugging Face Spaces 的在线演示正在使用 CPU，因此预计生成速度较慢。请使用 GPU 在本地加载模型以加快生成速度。\n\n\n\n\nPublic Prompts\n\n\n提示\n\n\nhttps://publicprompts.art\n\n\n图像生成的高质量和开源提示集合\n\n\n\n\nImg2prompt\n\n\n提示\n\n\nhttps://replicate.com\n\n\n获取与图像匹配的近似文本提示。（针对深度学习文生图模型进行了优化（剪辑 ViT-L/14））\n\n\n\n\nPromptBase\n\n\n提示\n\n\nhttps://promptbase.com\n\n\n查找最佳提示，产生更好的结果，节省 API 成本，销售您自己的提示。DALL·E，GPT-3，Midjourney，深度学习文生图模型提示市场。\n\n\n\n\nPromptBox\n\n\n提示\n\n\nhttps://promptbox.ai\n\n\n在不同的 AI 工具中组织、编辑和保存您的 AI 提示。提供保存等功能以提示使用右键单击。\n\n\n\n\nJrnylist\n\n\n提示\n\n\nhttps://jrnylist.com\n\n\n中途提示助手。- 浏览数十个分类为艺术与插图或资产与 UI 的提示 您也可以提交自己的提示。\n\n\n\n\nPromptLayer\n\n\n提示\n\n\nhttps://promptlayer.com\n\n\nPromptLayer 是第一个允许您跟踪和管理 GPT 提示工程的平台。PromptLayer 充当您的代码和 OpenAI 的 python 库之间的中间件。PromptLayer 记录您所有的 OpenAI API 请求，允许您在 PromptLayer 仪表板中搜索和探索请求历史记录。\n\n\n\n\nEye for AI\n\n\n提示\n\n\nhttps://eyeforai.xyz\n\n\n将您喜欢的提示保存为模板，并在将来使用它们快速生成图像。模板可用于上传的图像或文本提示。\n\n\n\n\nDallelist\n\n\n提示\n\n\nhttps://dallelist.com\n\n\nDallelist 允许您使用图像和样式作为参考轻松生成提示。（关键字）他们也提供与 DallE 网站集成的 chrome 扩展。\n\n\n\n\nInteriorAI\n\n\n房地产\n\n\nhttps://interiorai.com\n\n\n使用人工智能获取室内设计理念，并为具有不同室内风格的房地产列表提供虚拟舞台室内设计。\n\n\n\n\nGetFloorPlan\n\n\n房地产\n\n\nhttps://getfloorplan.com\n\n\n将您的 2D 平面图转换为现代且设施齐全的 3D 布局，并使用 AI 进行 360 度虚拟游览，每天可容纳数千人。\n\n\n\n\nMaket\n\n\n房地产\n\n\nhttps://maket.ai\n\n\n我们的生成设计软件使建筑师、建筑商和开发人员能够立即快速生成数千个建筑计划。\n\n\n\n\nCoolAIid\n\n\n房地产\n\n\nhttps://coolaiid.com\n\n\n使用 AI 的室内设计理念。无论您是想要装饰还是只是需要一点灵感，我们都会使用 AI 产生独特的想法。\n\n\n\n\nAI Room Planner\n\n\n房地产\n\n\nhttps://airoomplanner.com\n\n\nAI 室内设计。为您的房间获取数百种室内设计理念 - 免费且无限制。\n\n\n\n\nScholarcy\n\n\n研究\n\n\nhttps://scholarcy.com\n\n\n通过阅读由 AI 提供支持的大型文章的摘要，节省数百小时。在几秒钟内提取关键事实、数据和参考资料。\n\n\n\n\nScispace\n\n\n研究\n\n\nhttps://typeset.io\n\n\n您的 AI Copilot 可以解码任何研究论文。阅读和理解科学文献的最快方式。突出显示令人困惑的文本、数学和表格以获得简单的解释。提出后续问题并获得即时答案。一种无需指定关键字即可搜索和查找相关论文的新方法。\n\n\n\n\nGalactica\n\n\n研究\n\n\nhttps://galactica.org\n\n\nGalactica 是一个接受过人类科学知识训练的人工智能。您可以将它用作一个新界面来访问和操作我们对宇宙的了解。\n\n\n\n\nElicit\n\n\n研究\n\n\nhttps://elicit.org\n\n\nElicit 使用语言模型来帮助您自动化研究工作流程，例如部分文献综述。Elicit 可以在没有完美关键字匹配的情况下找到相关论文，针对您的问题总结论文的要点，并从论文中提取关键信息。Elicit 还可以帮助完成其他研究任务，例如头脑风暴、摘要和文本分类。\n\n\n\n\nAdept\n\n\n研究\n\n\nhttps://adept.ai\n\n\nAdept 是一个 ML 研究和产品实验室，通过使人类和计算机能够创造性地协同工作来构建通用智能。\n\n\n\n\nPodcast\n\n\n研究\n\n\nhttps://podcast.ai\n\n\n人工智能生成的播客。上面有 2 个播客 - Lex Fridman 采访 Richard Feynman 和 Joe Rogan 采访 Steve Jobs。\n\n\n\n\nConsensus\n\n\n研究\n\n\nhttps://consensus.app\n\n\nConsensus 是一个搜索引擎，它使用 AI 直接从科学研究中即时提取、汇总和提炼发现。\n\n\n\n\nSocratic by Google\n\n\n研究\n\n\nhttps://socratic.org\n\n\n在 Google 人工智能的帮助下，摆脱科学、数学、文学、社会研究等学术问题的困扰，并获得每个学科重要概念的直观解释。\n\n\n\n\nML news\n\n\n资源\n\n\nhttps://machine-learning.news\n\n\n以日语汇总与 AI 和 ML 相关的新闻的网站。\n\n\n\n\nFlowGPT\n\n\n资源\n\n\nhttps://flowgpt.com\n\n\nFlowGPT：分享、发现和了解最有用的 ChatGPT 提示，这些提示可帮助您简化任务并提高工作效率。\n\n\n\n\nThe AI Times\n\n\n资源\n\n\nhttps://aitimespage.com\n\n\n了解 AI Times。订阅以将 AI Times 的问题从数字媒体直接发送到您的收件箱。\n\n\n\n\nAI Art Apps Database\n\n\n资源\n\n\nhttps://aiartapps.com\n\n\n面向设计师和提示工程师的 AI 艺术资源、工具和灵感。找到 AI 艺术所需的一切。\n\n\n\n\nInfranodus\n\n\n销售\n\n\nhttps://infranodus.com\n\n\n使用 AI 和网络思维产生想法和洞察力。InfraNodus 结合了文本分析、网络可视化和 GPT-3 AI 来帮助您研究一篇文章，增强您的阅读、写作和研究工作流程。从多个导入源获取任何文本的概要概览，揭示主要主题及其之间的关系，找出模式和差距，发现正确的问题以推进您的思考和研究。\n\n\n\n\nReply.io\n\n\n销售\n\n\nhttps://reply.io\n\n\n使用 Reply 的 AI Sales Email Assistant 在几秒钟内大规模生成类似人类的销售电子邮件。在 GPT-3 语言预测模型的支持下，您的冷邮件和后续邮件将始终高度相关和个性化，从而提高您的打开率和回复率！\n\n\n\n\nRegie\n\n\n销售\n\n\nhttps://regie.ai\n\n\nRegie 使用 AI 帮助销售、营销和成功团队更快地编写引人入胜的内容\n\n\n\n\nCresta\n\n\n销售\n\n\nhttps://cresta.com\n\n\n自助服务、现场指导和电话后见解。AI 可以揭示专业知识，因此团队可以让每一次客户对话都有价值。\n\n\n\n\nOmneky\n\n\n销售\n\n\nhttps://omneky.com\n\n\nOmneky - 全渠道创意编排\n\n\n\n\nOutplayhq\n\n\n销售\n\n\nhttps://outplayhq.com\n\n\nOutplay 是一个一体化的多渠道销售参与平台，可帮助销售团队完成更多交易并显着增加收入。\n\n\n\n\nUsetwain\n\n\n销售\n\n\nhttps://usetwain.com\n\n\n世界一流的销售技巧触手可及。免费使用 Twain 查看您的销售宣传中缺少什么。\n\n\n\n\nIndustrial Data Labs\n\n\n销售\n\n\nhttps://industrialdatalabs.com\n\n\n在 BOM 工作流程中嵌入 AI。内部销售团队花费无数小时手动将物料清单电子表格中的数据输入报价系统和 ERP。我们经过行业培训的 AI 可自动执行此手动流程，让您的销售团队可以将更多时间用于销售。\n\n\n\n\nMarbleFlows\n\n\n销售\n\n\nhttps://app.marbleflows.com\n\n\nAI 生成的表格可转化更多潜在客户。\n\n\n\n\nGETitOUT\n\n\n销售\n\n\nhttps://getitout.io\n\n\nGETitOUT 是一个 AI 角色和文本生成器。营销与人物角色一起使用效果更好。但是为每个项目和客户创建它们？不好玩，至少到现在为止。了解 GETitOUT 的 Persona Generator：从竞争对手那里提取角色。生成专业文本。然后将它们粘贴到您所有的网站、电子邮件和营销工具中。\n\n\n\n\nKlaviyo SMS Assistant\n\n\n销售\n\n\nhttps://klaviyo.com\n\n\n使用 Klaviyo 的新人工智能短信助手在几秒钟内编写短信活动\n\n\n\n\nSmartwriter\n\n\n销售\n\n\nhttps://smartwriter.ai\n\n\n使用 AI 创建高度个性化的冷电子邮件或 Linkedin 消息，将读者转化为客户。无需经验。寻找潜在客户，创建量身定制的个性化文案并进行销售。人工智能冷电子邮件\n\n\n\n\nLavender\n\n\n销售\n\n\nhttps://lavender.ai\n\n\nLavender 是一套完整的工具，可帮助您在更短的时间内获得更多回复。使用 Email AI 编写更好的电子邮件、更快地实现个性化并指导您的团队。\n\n\n\n\nAndi\n\n\n搜索引擎\n\n\nhttps://andisearch.com\n\n\nAndi 正在使用生成式 AI 寻找下一代。Andi 不仅提供链接，还为您提供答案 - 就像与聪明的朋友交谈一样。\n\n\n\n\nOne More AI\n\n\n搜索引擎\n\n\nhttps://onemoreai.com\n\n\nAI 生成的库存图片 查找人工智能生成的数千张图片。\n\n\n\n\nAnyPod\n\n\n搜索引擎\n\n\nhttps://anypod.ai\n\n\n为创作者打造的 AI 搜索引擎。轻松搜索您最喜欢的播客，例如“我的第一百万”。您还可以提交添加播客的表格。\n\n\n\n\nKailua Labs\n\n\n搜索引擎\n\n\nhttps://app.kailualabs.com\n\n\n在您的应用程序中构建强大的多模式搜索。使用我们的 API，通过 AI 轻松搜索您的图像、视频、音频等。\n\n\n\n\nExplore AI\n\n\n搜索引擎\n\n\nhttps://exploreai.vercel.app\n\n\n由 AI 提供支持的语义搜索引擎。直接在数千个 YouTube 视频中搜索答案，免费、易于浏览且快速。\n\n\n\n\nLooria\n\n\n搜索引擎\n\n\nhttps://looria.com\n\n\nLooria 会找到适合您的需求和预算的最佳产品。他们从最值得信赖的来源收集评论，过滤掉虚假评论，并总结调查结果，以便您做出更明智的购买决定。\n\n\n\n\nChatGPT Chrome Extension\n\n\n搜索引擎\n\n\nhttps://chrome.google.com\n\n\n在 Google、Bing、DuckDuckGo 搜索结果旁边显示 ChatGPT 响应。它为您的查询提供了令人惊讶的详细解决方案 - 从编写舞会提案到修复代码。\n\n\n\n\nEverypixel\n\n\n搜索引擎\n\n\nhttps://everypixel.com\n\n\n由 AI 提供支持的搜索引擎，可为 50 个付费和免费图片网站编制索引，并允许用户在几秒钟内搜索庞大的图片数据库。您还可以按图像和各种搜索过滤器进行搜索，使您能够按颜色、方向和图像类型进行搜索。您还可以比较来自不同网站的图像价格并按作者搜索。\n\n\n\n\nSteno\n\n\n搜索引擎\n\n\nhttps://steno.ai\n\n\n您最喜爱的播客，完全转录 在您收听时发现、参考和阅读。\n\n\n\n\nKrea\n\n\n搜索引擎\n\n\nhttps://krea.ai\n\n\n探索数百万 AI 生成的图像并创建提示集合。具有稳定的扩散世代。\n\n\n\n\nDreamsands\n\n\n搜索引擎\n\n\nhttps://dreamsands.ai\n\n\nDreamsands 是一个创意市场，您可以在其中许可、收集和分享您感兴趣的 AI 生成艺术图像。\n\n\n\n\nGenerated Photos\n\n\n搜索引擎\n\n\nhttps://generated.photos\n\n\n使用完全由 AI 生成的照片增强您的创意作品。通过我们分类和标记的应用程序查找模型图像，或通过 API 集成图像。\n\n\n\n\nNeevaAI\n\n\n搜索引擎\n\n\nhttps://neeva.com\n\n\nNeevaAI 提供真实、实时的 AI 搜索。它将 AI 的强大功能与搜索堆栈相结合，为您提供快速、准确和最新的结果。并且，它提供了信息的来源。\n\n\n\n\nContext\n\n\n搜索引擎\n\n\nhttps://addcontext.xyz\n\n\n你最喜欢的内容。转录和搜索。Context 是一个由 AI 驱动的搜索引擎，可以在大量音频和视频内容中找到您正在寻找的任何时刻。您可以搜索 Mr Beast 和 MKBHD 等创作者的内容。\n\n\n\n\nPerplexity AI\n\n\n搜索引擎\n\n\nhttps://perplexity.ai\n\n\nPerplexity AI 是一个人工智能搜索引擎。这是一个受 OpenAI WebGPT 启发的演示，不是商业产品。他们使用大型语言模型（OpenAI API）和搜索引擎。还通过将自然语言转换为 SQL 代码来回答 Twitter 图形查询。\n\n\n\n\nAlgolia\n\n\n搜索引擎\n\n\nhttps://algolia.com\n\n\n适合您业务的最佳搜索和发现平台 Algolia 为构建者提供搜索和推荐服务，以创造世界一流的数字体验。\n\n\n\n\nYou\n\n\n搜索引擎\n\n\nhttps://you.com\n\n\n您可以控制的搜索引擎。\n\n\n\n\nRosebud\n\n\n搜索引擎\n\n\nhttps://rosebud.ai\n\n\nAI 生成的视觉效果我们让您轻松获得所需的准确视觉效果。\n\n\n\n\nNyx\n\n\n搜索引擎\n\n\nhttps://nyx.gallery\n\n\n本网站上的图像是用人工智能生成的，因此“不真实”。你会看到的食物、动物、风景等等都不存在！\n\n\n\n\nPromptHero\n\n\n搜索引擎\n\n\nhttps://prompthero.com\n\n\n通过 DALL-E、Stable Diffusion、Midjourney 等 AI 模型搜索数以百万计的艺术图像……\n\n\n\n\nWritesonic\n\n\n搜索引擎优化\n\n\nhttps://writesonic.com\n\n\nWritesonic 是一个人工智能作家，可以免费为博客、Facebook 广告、谷歌广告和 Shopify 创建对 SEO 友好的内容。我们的释义工具可让您立即改写整篇文章。\n\n\n\n\nMentioned\n\n\n搜索引擎优化\n\n\nhttps://mentioned.ai\n\n\n自动驾驶的影响者外展和链接建设。我们扫描您的内容以识别您提到的人和公司，然后发送电子邮件活动让他们知道。\n\n\n\n\nBlogNLP\n\n\n搜索引擎优化\n\n\nhttps://blognlp.com\n\n\nBlogNLP 是一款免费的 AI 博客写作工具，可帮助您打破作者的障碍，在短时间内创建原创内容。\n\n\n\n\nCTRify\n\n\n搜索引擎优化\n\n\nhttps://ctrify.com\n\n\n第一个 AI 驱动的 SEO 操作平台只需为我们的人工智能提供一个关键字即可创建在 Google 上排名的网站。得益于我们来自世界各地顶级移动运营商的住宅 IP 连接的数百万真实桌面和移动设备的有机流量，提升您的 SERP 排名、有机点击率、停留时间和 Pogo 粘性。\n\n\n\n\nJenni\n\n\n搜索引擎优化\n\n\nhttps://jenni.ai\n\n\n你写，Jenni 完成 用最先进的 AI 写作助手增强你的写作。\n\n\n\n\nClosers Copy\n\n\n搜索引擎优化\n\n\nhttps://closerscopy.com\n\n\n通过 SEO 优化博客和不可抗拒的营销文案促进您的销售。利用世界上最强大的文案的秘密……让您的文案机器人将它们变为现实！\n\n\n\n\nKafkai\n\n\n搜索引擎优化\n\n\nhttps://kafkai.com\n\n\nKafkai 是一种机器学习算法，可以从头开始写文章。面向营销人员和 SEO 的尖端技术。\n\n\n\n\nSpinrewriter\n\n\n搜索引擎优化\n\n\nhttps://spinrewriter.com\n\n\n需要独特的内容？观看如何在 45 秒内将一篇文章改写成 500 篇文章。借助 ENL 技术，Spin Rewriter 是 SEO 专家的完美工具，他们需要独特的、人性化的内容才能在 Google 上获得更高的排名。\n\n\n\n\nWriter\n\n\n搜索引擎优化\n\n\nhttps://writer.com\n\n\nDiscover Writer，适用于团队的 AI 写作平台。随处制作清晰、一致且符合品牌的内容。今天免费试用。\n\n\n\n\nLongShot\n\n\n搜索引擎优化\n\n\nhttps://longShot.ai\n\n\n使用人工智能创建人类和搜索引擎喜欢的博客。LongShot 是一款 AI 写作助手，可帮助您和您的团队创建有用的博客，并在 Google 上排名。\n\n\n\n\nWord Spinner\n\n\n搜索引擎优化\n\n\nhttps://word-spinner.com\n\n\n立即将任何文章或文本重写为 SEO 友好的独特内容。Word Spinner 可以让您的写作前所未有地闪耀，对于任何想要提高写作技巧的人来说，它都是一个不错的选择。\n\n\n\n\nNeuronwriter\n\n\n搜索引擎优化\n\n\nhttps://neuronwriter.com\n\n\n优化您的网站内容，让 Google 喜欢它。具有语义模型 (NLP)、Google SERP 分析和竞争数据的高级内容编辑器。NEURONwriter 帮助您在考虑用户意图的情况下规划和优化内容！\n\n\n\n\nTopicmojo\n\n\n搜索引擎优化\n\n\nhttps://topicmojo.com\n\n\nTopic mojo 是一种用于内容研究的 AI 工具。获取可帮助您发展在线业务的分析功能。\n\n\n\n\nCompar\n\n\n搜索引擎优化\n\n\nhttps://compar.ai\n\n\nAI 支持的内容分析。\n\n\n\n\nTypli\n\n\n搜索引擎优化\n\n\nhttps://typli.ai\n\n\n最直观的 AI 内容工具，结合了 AI 写作和 SEO 助手。\n\n\n\n\nEilla AI\n\n\n搜索引擎优化\n\n\nhttps://eilla.ai\n\n\nEilla.AI 是一款人工智能助手，可为您的企业、博客、广告、电子邮件和逼真的图像或艺术生成高质量的内容。免费开始，无需信用卡！\n\n\n\n\nLetterdrop\n\n\n搜索引擎优化\n\n\nhttps://letterdrop.com\n\n\n创建的内容增加 32%，速度更快，麻烦更少。Letterdrop 简化并自动化您的内容操作。\n\n\n\n\nWritey AI\n\n\n搜索引擎优化\n\n\nhttps://writey.ai\n\n\n改变内容的创建方式。使用人工智能更快地创建内容。最先进的语言 AI 第一个真正的免费抄袭 AI，具有原创和研究内容，检查 Writey AI 的实际应用\n\n\n\n\nAI-Writer\n\n\n搜索引擎优化\n\n\nhttps://ai-writer.com\n\n\nAI-Writer是最精准的内容生成平台。使用最先进的 AI 写作模型从标题生成文章。\n\n\n\n\nScalenut\n\n\n搜索引擎优化\n\n\nhttps://scalenut.com\n\n\n制作以简单且可扩展的方式服务于您的业务目标的内容。引导工作流程仅需 5 分钟即可完成博客！\n\n\n\n\nWordhero\n\n\n搜索引擎优化\n\n\nhttps://wordhero.co\n\n\n借助 WordHero 的 AI 技术，您可以在几秒钟内创建原创博客文章、社交媒体内容、电子邮件等。\n\n\n\n\ngrowthbar\n\n\n搜索引擎优化\n\n\nhttps://growthbarseo.com\n\n\n使用 AI 为博客文章、网站页面和文章编写完美的 SEO 友好内容。\n\n\n\n\nKatteb\n\n\n搜索引擎优化\n\n\nhttps://katteb.com\n\n\nKatteb AI 可以快速轻松地为您的博客和在线商店创建内容。\n\n\n\n\nThundercontent\n\n\n搜索引擎优化\n\n\nhttps://thundercontent.com\n\n\n使用 AI 生成内容。Thundercontent 使用人工智能帮助您以光速撰写关于任何主题的独特文章。扩展您的内容策略。克服作家的障碍。您还可以使用 Thundercontent 生成音频。\n\n\n\n\nMoonbeam\n\n\n搜索引擎优化\n\n\nhttps://gomoonbeam.com\n\n\nMoonbeam 的 AI 将为您提供编写杀手级长篇内容所需的一切。在 10 分钟内将写作能力提高 2 倍。\n\n\n\n\nCopymatic\n\n\n搜索引擎优化\n\n\nhttps://copymatic.ai\n\n\n使用 AI 在几秒钟内生成内容和复制使用 AI 来增加您的流量并节省工作时间。自动编写独特、引人入胜且高质量的副本或内容：在几秒钟内从长篇博文或登陆页面到数字广告。\n\n\n\n\nArticleForge\n\n\n搜索引擎优化\n\n\nhttps://articleforge.com\n\n\n从产品描述到整个博客文章，只需单击一下，Article Forge 就可以提供关于任何主题的独特的、SEO 优化的、高质量的内容。\n\n\n\n\nBrameWork\n\n\n搜索引擎优化\n\n\nhttps://bramework.com\n\n\n写博客文章的速度提高 5 倍。Bramework 是一款易于使用的 AI 作家，可帮助博主、自由职业者和代理机构在每篇博文中节省时间。\n\n\n\n\nInstaSalesAI\n\n\n社交媒体助手\n\n\nhttps://instasalesai.com\n\n\nInstaSalesAI 是用于 Instagram 营销的人工智能工具的集合。您可以使用它来生成轮播内容或营销挂钩。\n\n\n\n\nFeedHive\n\n\n社交媒体助手\n\n\nhttps://feedhive.com\n\n\n使用 FeedHive 的人工智能平台大规模创建、安排、发布和轻松管理您的社交媒体内容。拖放计划、自动生成主题标签以及最活跃的时间安排和精湛的分析。\n\n\n\n\nPredis\n\n\n社交媒体助手\n\n\nhttps://predis.ai\n\n\nPredis.AI 是一种人工智能驱动的内容生成器，可帮助在几秒钟内创建令人惊叹的社交媒体帖子。它提供多种功能，例如创意生成、参与度预测、内容推荐、主题标签推荐和创意建议。\n\n\n\n\nTweet Hunter\n\n\n社交媒体助手\n\n\nhttps://tweethunter.io\n\n\n建立您的 Twitter 受众并从中获利。获得销售、增长和新网络。比你目前正在尝试的更快。\n\n\n\n\nContenda\n\n\n社交媒体助手\n\n\nhttps://contenda.co\n\n\n一个统一的内容存储库，可以比代理机构更好更快地重新利用技术内容\n\n\n\n\nEditby\n\n\n社交媒体助手\n\n\nhttps://editby.ai\n\n\n您是否发现自己很难想出有趣的推文？开始使用 AI 像著名的 Twitter 帐户一样写作，这样您就不必再担心作家的瓶颈了。\n\n\n\n\nSpatial\n\n\n社交媒体助手\n\n\nhttps://spatial.ai\n\n\n使用实时社交媒体细分系统预测和影响客户行为。它根据人们的社交、移动和网络活动以及描述某个位置附近社交活动的类型和速度的地点对他们进行细分。\n\n\n\n\nSocialBu\n\n\n社交媒体助手\n\n\nhttps://socialbu.com\n\n\nSocialBu 是提高社交媒体影响力和最大化结果的完美解决方案。发布、响应、分析和自动化 - 全部在 SocialBu 中完成。\n\n\n\n\nTweetEmote\n\n\n社交媒体助手\n\n\nhttps://TweetEmote.com\n\n\nAI 驱动的推文助手，可帮助用户撰写富有表现力且引人入胜的推文。还可以通过编写提示和选择情绪来创建对您想要的任何推文的智能回复。\n\n\n\n\nRepl AI\n\n\n社交媒体助手\n\n\nhttps://replai.so\n\n\n使用 AI 创建有意义的 Twitter 回复的 Chrome 扩展。Replai.so 是与社区建立联系、在社交媒体上显得聪明、有趣、专业、显得更聪明并以 10 倍的努力增加您的受众的最简单方式。你可以在 chrome 网上商店找到它。\n\n\n\n\nCrawlQ.ai\n\n\n社交媒体助手\n\n\nhttps://crawlq.ai\n\n\n与您的观众一起创造“品牌之爱”。CrawlQ 提供具有全球影响力的高情感、高同理心、高投资回报率、以受众为中心的创意作品。\n\n\n\n\nGraham AI\n\n\n社交媒体助手\n\n\nhttps://grahamai.co\n\n\n像 AI 生成的天才技术影响者一样发推文。\n\n\n\n\nAI Social Bio\n\n\n社交媒体助手\n\n\nhttps://aisocialbio.com\n\n\n您的社交媒体简历，由人工智能创建。\n\n\n\n\nSheetGod\n\n\n电子表格\n\n\nhttps://boloforms.com\n\n\n使用简单的英语和 SheetGod 创建复杂的 Excel 公式。我们的 AI 驱动工具还允许您创建宏、正则表达式和基本任务，以及 Google Appscript 代码片段来自动执行您的日常手动工作。立即尝试并体验 SheetGod 的强大功能。\n\n\n\n\nGoodlookup\n\n\n电子表格\n\n\nhttps://goodlookup.com\n\n\nGoodlookup 是电子表格用户的智能功能。它将 AI 语言模型的优势带给普通人。\n\n\n\n\nExcel Formula Bot\n\n\n电子表格\n\n\nhttps://excelformulabot.com\n\n\n在 AI 的帮助下，在几秒钟内将您的文本指令转换为 Excel 公式。停止浪费时间创建 Excel 公式。体验 Excel 和 Google 表格 AI 公式生成器的全部功能，在几秒钟内解决问题。\n\n\n\n\nSheet+\n\n\n电子表格\n\n\nhttps://sheetplus.ai\n\n\n从文本生成 Google 表格和 Excel 公式，将公式转换为简单的解释、调试公式等。\n\n\n\n\nSheet AI\n\n\n电子表格\n\n\nhttps://sheetai.app\n\n\n适用于 Google 表格和 Excel（即将推出）跳过学习，直接开始工作。使用 AI 将您的文本指令快速转换为 Google 表格公式。（2-3 周后上线）\n\n\n\n\nAIHelperBot\n\n\n数据库\n\n\nhttps://aihelperbot.com\n\n\n使用 AI 即时构建 SQL 查询。无需先验 SQL 知识即可构建 SQL 查询。加入 1000 多人的行列，开始提高您的 SQL 熟练程度和工作效率。还支持 MongoDB 等 NoSQL 数据库。\n\n\n\n\nAI Data Sidekick\n\n\n数据库\n\n\nhttps://airops.com\n\n\n使用我们强大的秘诀集，编写 SQL、文档等的速度提高 10 倍。‍个人和小团队免费。\n\n\n\n\nChannel\n\n\n数据库\n\n\nhttps://usechannel.com\n\n\n用英语（自然语言）提问并自动生成您需要的 SQL、答案和可视化。与团队成员协作快速创建仪表板，然后使用频道建议的问题进一步探索您的数据。\n\n\n\n\nAi2sql\n\n\n数据库\n\n\nhttps://ai2sql.io\n\n\n使用 AI2sql，工程师和非工程师都可以在不了解 SQL 的情况下轻松编写高效、无错误的 SQL 查询。\n\n\n\n\nAvanty\n\n\n数据库\n\n\nhttps://avanty.app\n\n\n永远不要再浪费宝贵的数据分析师时间来编写无聊的 SQL 查询。Avanty 是一种基于 AI 的数据查询 + 商业智能工具，让每个人都能以更低的成本更快地从数据中获得洞察力。\n\n\n\n\nBroadn\n\n\n启动\n\n\nhttps://broadn.io\n\n\n跟随你的好奇心，开阔你的视野。\n\n\n\n\nPaperade\n\n\n启动\n\n\nhttps://paperade.co\n\n\nPaperade 是第一个基于 AI 的工具，可以从超过 1 亿篇学术论文和研究中生成商业用例和公司创意。这就像拥有创业理念方面的博士学位。\n\n\n\n\nTome\n\n\n启动\n\n\nhttps://beta.tome.app\n\n\n生成式叙事的未来就在这里。使用 Tome 的 AI 驱动的讲故事格式解锁您的最佳作品。\n\n\n\n\nRationale\n\n\n启动\n\n\nhttps://rationale.jina.ai\n\n\nRationale 是一款帮助企业家和管理者做出艰难决定的应用程序。只需输入您的未决决定，他们的人工智能应用程序就会列出优缺点或生成 SWOT 分析来帮助您权衡您的选择\n\n\n\n\nNamelix\n\n\n启动\n\n\nhttps://namelix.com\n\n\nNamelix 将使用人工智能生成一个简短的品牌企业名称。也非常适合发现新域名 😃\n\n\n\n\nFinta\n\n\n启动\n\n\nhttps://trustfinta.com\n\n\n只需一个工具即可完成所有工作，为您的筹款活动提供支持。Finta 是您的筹款副驾驶。端到端地自动化您的工作流程，这样您就可以重新开始发展您的业务。\n\n\n\n\nIdeabuddy\n\n\n启动\n\n\nhttps://ideabuddy.com\n\n\n将您的经营理念变为现实。多合一的商业规划软件，可帮助您将伟大的想法变成成功的企业。\n\n\n\n\nValidator AI\n\n\n启动\n\n\nhttps://validatorai.com\n\n\n任何想法的 AI 业务验证器。在 AI 的支持下，验证并接收有关任何创业想法的建设性反馈。它首先列出您在经营业务时可能遇到的潜在困难，然后给出关于您的经营理念的总体反馈。\n\n\n\n\nDurable\n\n\n启动\n\n\nhttps://durable.co\n\n\n在 30 秒内让您的业务在线。面向个人企业主的人工智能平台。生成一个网站，自动化您的营销，并管理您的财务。\n\n\n\n\nPitchgrade\n\n\n启动\n\n\nhttps://pitchgrade.com\n\n\n在您的推销平台上获得即时反馈，因此筹款成为您最不关心的事情。\n\n\n\n\nNamewizard.ai\n\n\n启动\n\n\nhttps://namewizard.ai\n\n\nNamewizard 允许您为您的想法/项目/启动想出一个 AI 生成的名称。您还可以根据生成的名称浏览可用域。\n\n\n\n\nSubtxt\n\n\n说故事的人\n\n\nhttps://subtxt.app\n\n\nSubtxt 是唯一符合作者直觉的智能大纲，而不是违背直觉。\n\n\n\n\nFabled\n\n\n说故事的人\n\n\nhttps://fabled.ai\n\n\n终极 AI 故事生成器。由您创作的故事，由 AI 提供支持。用一句话 fabled.AI 制作个人插图故事，并通过令人惊叹的图像进行丰富。免费试用！\n\n\n\n\nArtflow ai\n\n\n说故事的人\n\n\nhttps://artflow.ai\n\n\n毫不费力地将想法转化为动画故事，让创造力流动起来。Artflow.AI 可让您使用 AI 生成的资产创建您自己的、具有原始角色的独特动画故事。\n\n\n\n\nOnce Upon A Bot\n\n\n说故事的人\n\n\nhttps://onceuponabot.com\n\n\n使用 AI 创作原创故事。告诉 OnceUponABot 您的故事创意，机器人将使用 AI 从头开始编写故事。\n\n\n\n\nNovelAI\n\n\n说故事的人\n\n\nhttps://novelai.net\n\n\nGPT 驱动的 AI Storyteller。在 AI 的驱动下，构建独特的故事、激动人心的故事、诱人的浪漫故事，或者只是胡闹。什么都可以！！\n\n\n\n\nStoriesForKids\n\n\n说故事的人\n\n\nhttps://storiesforkids.ai\n\n\n一起阅读和创造。在手机上几秒钟内将现实生活中的情景变成有趣的故事和插图。\n\n\n\n\nNeural Canvas\n\n\n说故事的人\n\n\nhttps://neuralcanvas.io\n\n\nNeural Canvas 是一种数字插图生成器服务，能够为您的漫画、博客文章、电子书、故事、收藏等生成独特的插图。使用它创建您自己的 AI 生成的漫画。\n\n\n\n\nBedtimeStory AI\n\n\n说故事的人\n\n\nhttps://bedtimestory.ai\n\n\n在几秒钟内创建个性化的即时睡前故事。生成一个关于您孩子的故事，包括一些家庭成员作为角色，并添加类型、故事风格、道德等等——使用人工智能生成。他们的开放图书馆有 5000 多个故事。探索社区创造的所有故事。您可以为故事点赞、将它们加入您的收藏夹、重新混合*它们、与朋友分享、阅读给您的孩子听。\n\n\n\n\nScene One\n\n\n说故事的人\n\n\nhttps://sceneone.app\n\n\n最好的图书写作软件。使用我们直观的写作应用程序编写更多故事，花更少的时间学习复杂的功能。\n\n\n\n\nStoryWizard\n\n\n说故事的人\n\n\nhttps://storywizard.ai\n\n\n创造精彩的儿童故事 通过使用人工智能帮助您生成独特而美丽的儿童故事，这些故事具有生动的画面和有趣的情节。\n\n\n\n\nStory Path\n\n\n说故事的人\n\n\nhttps://storypath.app\n\n\n由 AI 提供支持的图书规划应用程序 计划您的故事或在几分钟内解决您的作家的瓶颈 对您的情节接下来的发展方向感到困惑，或者有一个需要充实的故事想法？仅通过简短描述，Story Path 就会为您的情节生成分支选项。展开并探索您最喜欢的路径，并根据您的喜好自定义细节。\n\n\n\n\nWhat on earth?\n\n\n说故事的人\n\n\nhttps://whatonearth.xyz\n\n\n一种学习新事物的有趣方式。仅需一个单词提示即可生成故事。\n\n\n\n\nSummate\n\n\n摘要器\n\n\nhttps://summate.it\n\n\n总结网络文章的实验性 AI 工具。该站点使用全文 RSS 进行文章提取，使用 OpenAI 进行文章摘要。\n\n\n\n\nTLDR this\n\n\n摘要器\n\n\nhttps://tldrthis.com\n\n\nTLDR 可帮助您将任何一段文本概括为简洁、易于理解的内容。从信息过载中解脱出来。\n\n\n\n\nUpword\n\n\n摘要器\n\n\nhttps://upword.ai\n\n\n使用 Upword 轻松总结您的内容。将他们强大的 AI 工具与您自己的笔记相结合，以创建更快、更高效的摘要，您可以阅读或收听。\n\n\n\n\nWordfixerBot\n\n\n摘要器\n\n\nhttps://wordfixerbot.com\n\n\nWordfixerBot 是释义器、语法检查器、文本摘要器和文本比较工具。\n\n\n\n\nGenei\n\n\n摘要器\n\n\nhttps://genei.io\n\n\n自动总结背景阅读并更快地生成博客、文章和报告。\n\n\n\n\nOtter AI\n\n\n摘要器\n\n\nhttps://otter.ai\n\n\n从会议中捕捉和分享见解。Otter 记录会议，实时做笔记，并生成自动摘要以与所有人共享并帮助您记住一切。\n\n\n\n\nBearly\n\n\n摘要器\n\n\nhttps://bearly.ai\n\n\n对研究人员非常有用的 AI 工具 - 它可用于创建摘要、大纲或改写文章。\n\n\n\n\nSummari\n\n\n摘要器\n\n\nhttps://summari.com\n\n\n改善您网站上的阅读体验。使用我们世界一流的 AI 摘要技术将链接升级为简短、信息丰富的预览。\n\n\n\n\nSummarize Tech\n\n\n摘要器\n\n\nhttps://summarize.tech\n\n\n人工智能驱动的视频摘要。获取任何长 YouTube 视频的摘要，例如讲座、现场活动或政府会议。\n\n\n\n\nExplainThis\n\n\n摘要器\n\n\nhttps://explainthis.ai\n\n\n一个 chrome 扩展，可以用通俗易懂的语言向您解释概念。AI 助手只需单击一下即可提供整个页面的摘要。当您没有太多时间或想要一个简洁的总和时，这很有用\n\n\n\n\nGPT-Prompter\n\n\n摘要器\n\n\nhttps://gptprompter.com\n\n\nChrome 扩展程序可以快速解释所选文本。\n\n\n\n\nSummerEyes\n\n\n摘要器\n\n\nhttps://summereyes.ai\n\n\n一键总结互联网上的任何文本。提高您的工作效率。在很短的时间内达到目的。\n\n\n\n\nWellsaidlabs\n\n\n文字转语音\n\n\nhttps://wellsaidlabs.com\n\n\n美妙的声音触手可及，文字转语音令人着迷。降低成本并简化语音制作过程。\n\n\n\n\nReplicastudios\n\n\n文字转语音\n\n\nhttps://replicastudios.com\n\n\n为您的创意项目合成 AI 语音。使用 Replica Voice 创建自然而富有表现力的语音表演。\n\n\n\n\nAd Auris\n\n\n文字转语音\n\n\nhttps://play.ad-auris.com\n\n\n随时随地收听文章！创建文章播放列表并在 Spotify、Apple Podcasts 和 Google Podcasts 上收听它们。\n\n\n\n\nFakeYou\n\n\n文字转语音\n\n\nhttps://fakeyou.com\n\n\n使用 FakeYou 将文本转换为语音，并用您喜欢的角色说话。还可以获取您自己的语音克隆，用于音乐、视频、twitch 奖励以及您想要的任何内容。\n\n\n\n\nListnr\n\n\n文字转语音\n\n\nhttps://listnr.tech\n\n\nAI 语音生成器具有 80 多种语言的 600 多种画外音，在几秒钟内从文本到语音，以 MP3 或 WAV 格式轻松导出您的声音。\n\n\n\n\nResemble\n\n\n文字转语音\n\n\nhttps://resemble.ai\n\n\n具有语音克隆功能的 AI 语音生成器，用于文本到语音的转换。\n\n\n\n\nAudioread\n\n\n文字转语音\n\n\nhttps://audioread.com\n\n\n将您的阅读变成播客。在您的播客应用程序中收听任何文章、PDF、电子邮件等。\n\n\n\n\nWhisper\n\n\n文字转语音\n\n\nhttps://github.com\n\n\nWhisper 是一种通用的语音识别模型。它在不同音频的大型数据集上进行训练，也是一个多任务模型，可以执行多语言语音识别以及语音翻译和语言识别。\n\n\n\n\nDescript\n\n\n文字转语音\n\n\nhttps://descript.com\n\n\n创建语音的文本到语音模型。尝试现场演示。\n\n\n\n\nSymbl.ai\n\n\n文字转语音\n\n\nhttps://symbl.ai\n\n\n集成实时语音转文本和上下文理解。由先进的深度学习模型提供支持。从非结构化对话数据启用实时字幕、跟踪用户意图、生成摘要等。\n\n\n\n\nMurf AI\n\n\n文字转语音\n\n\nhttps://murf.ai\n\n\n使用多功能 AI 语音生成器将文本转换为语音 将 Murf 逼真的 AI 声音用于播客、视频和所有专业演示\n\n\n\n\nPlay.ht\n\n\n文字转语音\n\n\nhttps://play.ht\n\n\n人工智能驱动的文本到语音生成器。使用我们的在线 AI 语音生成器和最佳合成语音生成逼真的文本到语音 (TTS) 音频。立即将文本转换为听起来自然的语音并下载为 MP3 和 WAV 音频文件。\n\n\n\n\nApple Books\n\n\n文字转语音\n\n\nhttps://apple.com\n\n\n由文本到语音 AI 讲述的有声读物现在可以通过 Apple 的 Books 获得。最初仅适用于浪漫小说和小说书籍，其中列出了两个可用的数字声音：麦迪逊和杰克逊。\n\n\n\n\nArticle.Audio\n\n\n文字转语音\n\n\nhttps://article.audio\n\n\n懒得看文章？没问题，听听吧！将文章转换为音频\n\n\n\n\nConvai\n\n\n文字转语音\n\n\nhttps://convai.com\n\n\n易于使用的对话式 AI API，用于语音识别、语言理解和生成以及文本到语音转换。设计您的游戏和支持语音的应用程序。设计基于对话的角色和基于语音的游戏。\n\n\n\n\nSpeechify\n\n\n文字转语音\n\n\nhttps://speechify.com\n\n\n让格温妮丝·帕特洛 (Gwyneth Paltrow) 和史努比狗狗 (Snoop Dogg) 等名人朗读您的文字。适用于 Chrome、iOS、Android 和 Mac 的文字转语音。\n\n\n\n\nEleven Labs\n\n\n文字转语音\n\n\nhttps://levenlabs.io\n\n\n语音的未来。第一个以任何语音和任何语言生成长格式语音的平台。我们使用 AI 为寻求终极叙事质量的创作者和出版商带来最自然、最引人注目的声音。\n\n\n\n\nCoqui\n\n\n文字转语音\n\n\nhttps://coqui.ai\n\n\nCoqui，言论自由。\n\n\n\n\nFree Subtitles AI\n\n\n转录员\n\n\nhttps://freesubtitles.ai\n\n\n使用这个免费的开源应用程序为电影生成字幕！\n\n\n\n\nfireflies.ai\n\n\n转录员\n\n\nhttps://fireflies.ai\n\n\n会议的 AI 助手 录制、转录和搜索语音对话。\n\n\n\n\nWhisper Memos\n\n\n转录员\n\n\nhttps://whispermemos.com\n\n\nWhisper Memos 是一款应用程序，可以记录您的声音并在几分钟后向您发送一封包含转录内容的电子邮件。用它来记录快速的想法、提醒和每日日记条目。\n\n\n\n\nSupertranslate\n\n\n转录员\n\n\nhttps://supertranslate.ai\n\n\n一键添加准确的英文字幕到任何语言的视频。您可以上传 100 多种语言的视频，Supertranslate 会自动生成英文字幕。Supertranslate 由 OpenAI 的 Whisper 提供支持，它是世界上最准确的语音转文本系统。它对背景噪音、语言混合和口音都很稳健。\n\n\n\n\nType Studio\n\n\n视频编辑\n\n\nhttps://typestudio.co\n\n\nType Studio 是一种基于文本的视频编辑器，可以自动将您的视频转录为文本。他们还有用于视频编辑、字幕、播客、重新调整用途和录制的快速工具。\n\n\n\n\nContentfries\n\n\n视频编辑\n\n\nhttps://contentfries.com\n\n\n使用 ContentFries 获取数十个内容片段。以比以往更快的速度提前数周或数月创建上下文内容。他们还有一个字幕创建软件 - 120 多种语言和方言的自动字幕。\n\n\n\n\nTopaz Video AI\n\n\n视频编辑\n\n\nhttps://topazlabs.com\n\n\n无限制地访问世界领先的生产级神经网络，用于视频放大、去隔行、运动插值和抖动稳定——所有这些都针对您的本地工作站进行了优化。\n\n\n\n\nShuffll\n\n\n视频编辑\n\n\nhttps://shuffll.com\n\n\nShuffll 是一个尖端的视频制作平台，它使用 AI 技术简化创作过程。我们的平台使企业能够轻松创建高质量、个性化的视频内容，所用时间仅为使用传统方法所需时间的一小部分。\n\n\n\n\nGling\n\n\n视频编辑\n\n\nhttps://gling.ai\n\n\nGling 是一款专为视频内容创作者打造的 AI 工具。他们的 AI 将为您消除沉默和糟糕的镜头，因此您可以专注于您的 YouTube 视频。\n\n\n\n\nPictory\n\n\n视频编辑\n\n\nhttps://pictory.ai\n\n\nPictory 是一种视频营销工具，可以从长格式内容自动创建简短、高度共享的品牌视频。将您的脚本和博客文章自动变成引人入胜的视频。\n\n\n\n\nRunwayml\n\n\n视频编辑\n\n\nhttps://runwayml.com\n\n\n探索高级视频编辑功能，让您的创作更上一层楼。\n\n\n\n\nUnscreen.com\n\n\n视频编辑\n\n\nhttps://unscreen.com\n\n\n删除视频背景，100% 自动且免费。使用 Unscreen，您可以在任何地方录制您的镜头，然后简单地摆脱背景。\n\n\n\n\nColourlab\n\n\n视频编辑\n\n\nhttps://colourlab.ai\n\n\n好莱坞遇上人工智能。Colourlab AI 借助全新的突破性人工智能工具，通过自动进行颜色匹配和平衡，使颜色分级变得快速、简单和简单。\n\n\n\n\nPapercup\n\n\n视频编辑\n\n\nhttps://papercup.com\n\n\n发现更快、更实惠的自动配音，并利用您现有的视频内容走向全球。使用 AI 以英语、西班牙语、葡萄牙语和意大利语配音您的内容。它们被 BBC、Sky News 和 Insider 等公司使用。\n\n\n\n\nDubverse\n\n\n视频编辑\n\n\nhttps://dubverse.ai\n\n\n最简单（也是最神奇）的视频配音方式。只需单击一个按钮，即可使您的内容支持多种语言，并覆盖更多人。\n\n\n\n\nVidyo.ai\n\n\n视频编辑\n\n\nhttps://vidyo.ai\n\n\n立即将长视频制作成短视频。使用强大的 AI 从您现有的视频中创建短片 ✨ 节省 90% 的时间和精力。\n\n\n\n\nMunch\n\n\n视频编辑\n\n\nhttps://getmunch.com\n\n\n自动将长视频转换为社交媒体的数据驱动短片。Munch 通过收集 TikTok、IG、YT 和 FB 用户的最高兴趣并将其应用到您的 AI 生成的剪辑中来产生曝光率和参与度。\n\n\n\n\nFILM\n\n\n视频生成器\n\n\nhttps://replicate.com\n\n\n电影 - 大场景运动的帧插值。在两个现有图像（插值）之间生成帧以尝试创建动画。\n\n\n\n\nAstria\n\n\n视频生成器\n\n\nhttps://astria.ai\n\n\n量身定制的人工智能图像生成。开始创建您的独特图像。\n\n\n\n\nWaymark\n\n\n视频生成器\n\n\nhttps://waymark.com\n\n\nWaymark 的 AI 视频创建器可以轻松为任何潜在客户创建规格创意。现在，您可以带着完全定制的样本广告走进每一场会议。\n\n\n\n\nFliki\n\n\n视频生成器\n\n\nhttps://fliki.ai\n\n\n在 2 分钟内使用逼真的声音从脚本或博客文章创建视频！将博客文章转换为视频。逼真的文字转语音。丰富的股票媒体库。受到来自 Google、Meta、Bytedance 和 Upwork 等公司的 30k+ 内容创作者的信任。\n\n\n\n\nSynthesia\n\n\n视频生成器\n\n\nhttps://synthesia.io\n\n\n只需输入文本即可创建 AI 视频。易于使用、便宜且可扩展。与真人演示者一起制作引人入胜的视频 - 直接从您的浏览器。免费演示。\n\n\n\n\nSteve AI\n\n\n视频生成器\n\n\nhttps://steve.ai\n\n\nSteve AI 是面向社交媒体和内容营销人员的 AI 视频制作者，用于创建实时和动画视频。在 Steve AI 的帮助下，您可以将博客文章、脚本或文本内容转换为用于社交媒体的小型视频。它的功能包括创意人工智能、搜索人工智能和全自动解决方案。\n\n\n\n\nInVideo\n\n\n视频生成器\n\n\nhttps://invideo.io\n\n\n释放视频的力量。借助 InVideo，每个人都可以创建更吸引人、带来更多潜在客户并节省时间的精美专业视频。我们的库包含 5000 多个模板、过渡和效果，可帮助您轻松、快速、高效地创建视频。无需下载。\n\n\n\n\nOpus\n\n\n视频生成器\n\n\nhttps://opus.ai\n\n\n把文字变成电影和游戏。\n\n\n\n\nWowTo\n\n\n视频生成器\n\n\nhttps://wowto.ai\n\n\n在几分钟内创建操作视频并托管引人入胜的视频知识库。建立视频知识库。\n\n\n\n\nColossyan\n\n\n视频生成器\n\n\nhttps://colossyan.com\n\n\nColossyan Creator 让视频创作变得简单无压力。与真人演员一起探索我们的 AI 视频创作者。在不到 5 分钟的时间内创建视频。从这里开始免费。\n\n\n\n\nXpression Camera\n\n\n视频生成器\n\n\nhttps://xpressioncamera.com\n\n\nXpression Camera 是一款屡获殊荣的虚拟相机应用程序，它允许用户使用一张照片立即变身为任何人或任何有脸的人，而无需任何处理时间。xpression 相机使用户能够在使用 Zoom 等应用聊天、在 Twitch 上直播或创建 YouTube 视频时实时重新定义他们的屏幕角色。\n\n\n\n\nMovio\n\n\n视频生成器\n\n\nhttps://movio.la\n\n\n当你可以使用 AI 视频编辑器来创建一个代言人时，为什么还要付钱给代言人呢？MOVIO 是一种顶级合成媒体，可以将您的文本转换为视频。\n\n\n\n\nPyttipanna\n\n\n视频生成器\n\n\nhttps://pyttipanna.xyz\n\n\nPyttipanna 是 Pytti 5 的一个界面。它允许您构建、叙述和试验视频创建的提示。Pytti 是一个使用机器学习模型创建和渲染视频的框架。\n\n\n\n\nPeech\n\n\n视频生成器\n\n\nhttps://peech-ai.com\n\n\n将您的内容团队变成不可阻挡的创作者。自动转录、编辑、重新利用和标记您的视频内容 - 所有这些都在一个地方并大规模制作视频内容。\n\n\n\n\nWonder Dynamics\n\n\n视频生成器\n\n\nhttps://wonderdynamics.com\n\n\n在 Wonder Dynamics，我们将 AI 技术与一流的故事讲述相结合。\n\n\n\n\nCreative Reality Studio (D-ID)\n\n\n视频生成器\n\n\nhttps://studio.d-id.com\n\n\n世界上第一个结合了 GPT-3、Stable Diffusion 和 D-ID 独特的面部动画技术的平台。我们的生成式 AI 会在几秒钟内将您的视野变成会说话的化身。\n\n\n\n\nLiveReacting AI\n\n\n视频生成器\n\n\nhttps://livereacting.com\n\n\n使用我们的 AI 主持人提升您的现场表演。节省时间和金钱，同时为您的观众提供互动和引人入胜的体验。\n\n\n\n\nAudiolabs\n\n\n视频生成器\n\n\nhttps://audiolabs.io\n\n\n将您的播客转换为适合 TikTok、YouTube Shorts 和 Reels 的短视频的平台。接触新的播客听众并推动业务成果 🎙️在短格式平台上发布视频剪辑充当听众发现您的库存并收听完整剧集或其他营销目标的“钩子”\n\n\n\n\nHourone\n\n\n视频生成器\n\n\nhttps://hourone.ai\n\n\n欢迎来到 Hour One——世界上发展最快的 AI 视频制作者。我们将文字转为视频，让学习和发展变得更加有趣和有效。现在试试！\n\n\n\n\nVidIQ\n\n\n视频生成器\n\n\nhttps://vidiq.com\n\n\n使用 AI 提升您的 YouTube 观看次数。获得免费的见解和指导，以保持您的频道不断发展。"
  },
  {
    "objectID": "posts/be0cc3f9-8b92-4dc1-accb-8f5c4f227ca5/index.html",
    "href": "posts/be0cc3f9-8b92-4dc1-accb-8f5c4f227ca5/index.html",
    "title": "APFS for Linux",
    "section": "",
    "text": "APFS for Linux\ni use this adapter to transfer files (you know that) to kali.\nread only support. if write then the filesystem will break.\napfs-fuse read-only, single executable, no kernel module\nlinux-apfs-rw kernel module, read/write support"
  },
  {
    "objectID": "posts/a53f292e-e81f-4dee-8efb-3e956244eff3/index.html",
    "href": "posts/a53f292e-e81f-4dee-8efb-3e956244eff3/index.html",
    "title": "AI上色",
    "section": "",
    "text": "AI上色 ffmpeg去特定颜色 调色\n可能和GAN有关\nuse paddlegan for coloring\n可以去掉血腥色情 暴力可能不行 需要剪辑\nFFmpeg remove color: https://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video http://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/\nface coloring: https://github.com/Xu-Justin/Grayscale-Face-Coloring\nnvidia coloring: https://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/\ngithub topic on image colorization: https://github.com/topics/image-colorization\ngithub repos on image colorization: https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image https://github.com/aDouladiris/Grayscale-Image-Colorization https://github.com/aakaashjois/Colorizing-Grayscale-Images https://github.com/emilwallner/Coloring-greyscale-images\ncurated list on image colorization: https://github.com/oskar-j/awesome-image-coloring"
  },
  {
    "objectID": "posts/a94f97e7-4f2b-4d99-b2af-524657e65015/index.html",
    "href": "posts/a94f97e7-4f2b-4d99-b2af-524657e65015/index.html",
    "title": "Yoga & TaiChi",
    "section": "",
    "text": "Yoga & TaiChi\nCannot staying here forever coding shit. The issue is that we are too absorbed to seek for challenge, forgetting the way back, forgetting how we get this far. Cyberspace is exciting, but human does not evolve inside chips. In order to get things back on track, you need to forget about everything artificial. No matter how smart you are, creating a place needless to move at all is dangerous and not possible. You must know when to leave and what to do without seeing code at all.\nstretching in bed is possible via the handle on the desk. so elegent design isn’t it. i’ve had it long time ago."
  },
  {
    "objectID": "posts/e5ebef3b-3842-494f-ae41-09448ac27a51/index.html",
    "href": "posts/e5ebef3b-3842-494f-ae41-09448ac27a51/index.html",
    "title": "Interesting xkcd style plots and characters generator in Mathematica/Wolfram Language",
    "section": "",
    "text": "Interesting xkcd style plots and characters generator in Mathematica/Wolfram Language\nhttps://mathematica.stackexchange.com/questions/11350/xkcd-style-plots\nhttps://blog.wolfram.com/2012/10/05/automating-xkcd-diagrams-transforming-serious-to-funny/"
  },
  {
    "objectID": "posts/144e7261-6d33-40ff-8f7f-37365e8f90d3/index.html",
    "href": "posts/144e7261-6d33-40ff-8f7f-37365e8f90d3/index.html",
    "title": "What experiences do ISTP people have?",
    "section": "",
    "text": "What experiences do ISTP people have?\nI used to test that I was a lot of personalities, including ESTJ ENTP Intp INTJ, etc., but I always felt that I was not like myself, because although there were few friends, they still imitated others intentionally or unintentionally. My personality is very easy to change. It is also temporarily tested that ISTP may be temporary, but because of the natural growth of natural growth, it will gradually decrease. Maybe this time it is set? I like to write programs (Python’s first! What is Jvav?), I like to understand and transform the world with a programmatic thinking, because this can leave me out of the consequences of emotional treatment and avoid being assimilated by others. I do self -media, what are the procedures, such as video understanding, graph -based recommendation algorithms, and so on. I only take notes for my own project, and I am willing to put all the bookmarks into the notes for easy search. Regarding the school’s knowledge, I was forced to learn in elementary school. On the way to the Olympic class, I saw a car driving, so I flew over, thinking that my dad would definitely keep up, maybe he could kill him. As a result, he didn’t die, and he rotted my ears. In fact, my dad did not understand the Olympic problem at all, and even a few squares that had dug a piece of squares could not be countless. What he would know was nothing more than metaphysics and relationship, but he could never figure out the concept of abstraction. The same is true of playing the piano. I like the piano, but I don’t like someone to teach me to play the piano. I run to class every day, which really collapses me. Once the piano teacher touched the glass door, the door was broken, and her hand was hurt. I was a bit sympathetic at the time, but I thought more about me (temporary). I don’t need to take this piano class today. The piano teacher has nothing to do with me, and I won’t accompany me when I need it, comfort me, and will only tell me the messy fingers when I don’t need her. When I took the test, a bunch of people looked around me, and in the classroom of my piano. The glass of the glass was crowded to die. I didn’t carry much content at the time, and I didn’t want to carry it at all. I didn’t want to play. After a while, I was gone. I said that I forgot and left. They really issued a certificate. In fact, I feel like music, but the memory is not good, and I only remember the notes with emotion. The machine synthetic music I do now can make up for this problem. My dad is really stupid. When he hear the electronic sound, he said it was not good. In fact, the vibrato he brushed every day was electronic music. My dad kept putting me in the room, even if it was winter and summer vacation. I was mad, until I had a computer at home. I played games with a computer, but I was played. I am not happy, stealing my parents’ money, and was beaten. Take me to the amusement park, I don’t like thrilling projects. My dad has to let me go and pull my brother. I see my brother so happy. I think he may really don’t understand my mind. No one understands my mind. Everyone here does not let me leave this ghost place, damn it. I kicked a fierce place to his fragile place (my dad taught), but he just passed the pain, and he still smiled. I think I am really weak. It ’s okay for others to cut two knives, but I need to avoid being angry by hurting others. I was bullied by my classmates when I went to elementary school. I turned to bully others and started throwing their triangle board downstairs. Pencils, I hope that this can relieve the anger in my heart. Once I was squeezed up by the front table every day, I took his pen to his schoolbag while he did exercises. After he came back, he looked at his bag with surprised eyes, and since then he has been in peace. My dad in junior high school sent me to the most rolling king school in the city. The king of the rolls is naturally very knowledgeable, and they know more than me, but one or two wonds is like a bottle, and a small number of websites and knowledge will be shared, but basically all the contents of the exam are promoted. After I went in, the pressure was extremely huge, but I liked to observe others very much. Others had to see the famous hall from shit. A classmate just enrolled in school immediately wrote a class of Quanquan, and I remembered it at the time, thinking why it was not me. There are almost all smart phones in the class, and I don’t. My mother has a smartphone. When I arrived at my mother’s house, there was only a TV. I was boring to die. When I grabbed it, my mother’s mouth was bleeding. My dad did not know what the situation (maybe someone reported it). The situation of the situation ran out and hit me, and punished me for an hour, and gave them a hoe to admit my mistakes. I thought you would not come to see you in my life, and I won’t have any emotions to you. You have nothing to do with me. I picked up the Nokia mobile phone on the ground, and my dad smashed. I thought he smashed my things because let him know that I had this thing. Although I picked it up, I should use it when I brought it. If you smashed me, you damn it. If you still smash it in person, I will definitely remember this hatred. The next time I went to the tuition class and stole other people’s mobile phones, I didn’t care how anxiously others later, and left directly (without her QQ and ZFB, took the SIM card, and it was formatted by it). I secretly use it myself. Parents are convenient for me to go to school. Renting a house next to the school. The tattered house where I live in the sewer is often blocked and the stories come up. Give me a tablet at home, and I want to die slowly, but I still use it. I was still using it when I was doing the question. My mother smashed it. I stuck to hit her. I did n’t know how many times I did n’t know. She did n’t know how many times. I bought the second -hand iPod with the New Year’s money. I have three views. After a long time, I returned and returned, and I changed it for me. Later, my mother also posted me a membrane. As a result, because I played for too long when I played the iPod, I fell directly to the ground. I was hairy at the time, smashing the iPod on the ground. I thought that I hit you last time. This time I broke it and I see you. My heart was dead, especially when I heard my ipod fell into that way, the next day it still rang the alarm clock outside the window. I later bought a mobile phone again. I don’t know why she didn’t smash me this time. Maybe because the mobile phone was too garbage, I could only listen to the Internet. I couldn’t play the game. I may not really fight, but I really will vent my anger and incompetence in various ways. I will collect the pen on the ground and chop them with their feet, and clamp the brands I have made in the class with a cabinet. Occasionally, I can calm down my anger, but I still have a sports student in the class. Once I started to get my temper on the podium again, he came to touch me from behind. I subconsciously kicked his crotch and was caught by him. It was very embarrassing for a while. His acne was more than me (because I was more in high school), and it may be more stressed, so the body was stronger than me and preferred to fight. A classmate likes to play basketball and breaks his left hand with his right hand. At that time, junior high school was about to be finished, thinking that these roll kings would not understand the principle of 1+1 = 2. I wrote two handwriting, but I was afraid of rolling you? After I finished my middle school entrance examination, I started to practice my left hand, and even went out to travel on the beach. I was still practicing. When my dad saw my two handwriting, I had to correct it, and threatened to chop it with my left hand. I thought it was just that when he came to see me, I pretended, but I looked at me. I accidentally saw that my parents turned my draft paper when I was sleeping, and I was angry, so every time I made a draft, I wrote the words of cursing my dad on the draft paper. My dad saw my draft paper this time, and he was really surprised again. He was a very “kind” compromise, but he just painted me with a correction band to scold him. I think he is a brain disability. All the rights who have the right to be tampered with history, but this is the Internet. All history is amazingly similar. You cannot tamper with all history. cover up. When I arrived at high school, I did n’t recognize it. I put all the things I learned into practice, but after all, because junior high school was originally the frog at the bottom of the well. Although the high school was open -minded, it was not flying. When I went to high school, I built a class group. I wrote my own abused experience as a psychological drama for my classmates. I bought the college entrance examination questions. It took less than two years to do homework. Office, empty classrooms, and conference rooms are all my self -study room. In fact, the reason is very simple, because this school arranges me to the so -called pointed class, which is the principle of raising the puppets. I can only continuously improve my inner volume method and tap it. The dirty inner roll quagmire. After reporting the tutoring class of the top students at the time of junior high school, I paid a lot of money. In fact, I went to communicate with their frogs at the bottom of the well. I think that the machine will be generated in the future. And two -handed writing forced a science student (female classmate) who likes liberal arts to learn the text. This female classmate I also wrote you a brief introduction and practice method for you to write your hands, and ask you to vote for your school journal. My vision is not high, and the thought is like that. You do n’t include me. My junior high school friends may be more kind (?), Friends in high school (?), One of them, I remember he didn’t want me to go to his house, I had to follow the past. He had a brake, and I couldn’t stop hitting the fence all the way to the fence. I thought you died, and you will die. I followed the past to observe you and improve myself, but now you have become one of the goals of my assassination. I followed the past to camouflage and detective. When the house was selling at home, I sent him my computer (desktop machine, pushed it over with a cart), but immediately took it back, afraid that this fool would throw me or peeking me. (Actually, it’s me Back up the information). I took contraceptives and wearing women’s clothing in high school, because I felt that this can become better. I have no room for improvement. I also wear women’s clothing (improvement code efficiency?), See if this is useful. My mother monitored me all -weather at that time. I wore women’s clothes and wrote a question. She directly pointed the camera to my dad, and asked me to hold my phone to listen to him and scold me. I was frightened that night. I actually told my mother, my mother came over to comfort me again? I sat up and leaned on the bed at the time, as if I didn’t die. The results of the college entrance examination came, and the seven aunts and eight aunts called me, saying that I was good at the test, and I hung up when I received the first call. I was in my friend’s house, and my friend and I face to face, and we both across a wall. I may never meet this friend anymore in this life. I actually confessed to him, confessing to a man, and then borrowing money. In exchange for a word, delete friends. This can’t blame him. These things are all experienced by my university, because I have chosen a major that I don’t want to learn (all majors that cannot be padded, forcing me to endorse, and I can’t use a computer to assist all the subjects that must be calculated. To solve or repeat wheels, you must use the subjects of the library I don’t want to use), a bunch of mathematics, do not listen to the class, learn your own things (very messy and miscellaneous, from the beginning of general artificial intelligence I have studied what I have been caught, and I started to calculate after the college entrance examination was completed. The summer vacation of the summer vacation after the college entrance examination was completed. , I can’t wait to understand everything.), The computer was confiscated (in order to prevent peeping, I directly encrypted the disk), and the money was not given, so I became crazy, and it was even worse. Eat), repeatedly browse stock market information, formulas (since then I only believe in quantification), and even use wireless network cards to insert school computers to see stocks. As a result, the school teachers of the school directly replaced the virtual cloud computers with thin clients. Essence The school is really rich and technical. After studying for a year, my dad told me to learn JVAV. I wrote code (Python and Shell) in my class, and had nothing to do with the teacher’s class. My dad told me to take notes on the book. I said that the use of not taking notes was knocked on, and he immediately came to pinch my neck (really sick). However, next semester, I still go to study the loopholes of these virtual machines. I really researched it for me. I do n’t know how to install Termux on the Android thin client to get Sudo permissions. It was a step away, but I chose to go bad. Seeing that I was still twenty or thirty points of the door courses (go to the machine to choose a conscious answer sheet, submit the papers for 3 minutes), and I don’t give me money at home. I found freelancer.com online to develop plug -ins for foreign gangs, and the target compensation was lower than that of Indians. This broken plug -in requirement has changed several times, and finally made a AI voice recognition and GUI interface. I also added QE’s hidden API, dragged for a long time, and asked me to install it remotely for him. Cross -platform remote compilation to Mac OS (?), After a long time to pay for PayPal, is it like 40 knives? (Each withdrawal of the thief is high). This group of people is an American boss, a Russian editor, playing in the scene, and told me to realize strange functions every day, repair strange BUGs that have nothing to do with me, but do not give money. Although I registered Payoneer, I felt that the foreign rolls were going to die. I returned to a bunch of part -time QQ groups that I had added in China to find a list to avoid starving. I have a bed in my university, and I do n’t even have a table. Using someone else ’s table will be disliked. I look at the headset of the head. I found a job for the summer vacation to take a takeaway (almost on the road of death) to earn enough money to buy this thing. I needed to rest at noon. At the beginning, I went home for dinner and went to bed. Later, I went straight to a cheap food and ran to sleep flat or the corridor. After the summer vacation, I pretended to say that I was going to assault for tuition (fart). I lay on the bed to watch the video when I bought it. I didn’t listen to the class at all. I did n’t pay any money at home. My mother called and yelled, so I started picking up the order directly, earning more than 4,000, and eating too much. At that time, I had concluded how to take a high score. It was nothing more than cutting the book with the book, scanning, and searching for the full text (as long as it was used in the exam), taking a passage is not a dream. I don’t look at these town as a questioner. I summarized the method of establishing the question bank of the small ape search question, but I couldn’t use it. Whoever you want to take the score, buy a calculator with memory search and scan the inside. I am too lazy to have more important learning tasks, I don’t need to lie to myself, I just need to lie to others. Now that I continue to put bad, learn any of my self -media content, I have noted hundreds of articles. However, pretending to be a camouflage in English, because these people only look at a diploma, although they know that the employment of English majors is not dazzling, they still open their eyes and close their eyes. I really prepared the exam, and I really took the transfer of professional exams. It doesn’t matter if you can’t turn it, I think I have to think about what I do after myself. My mother knows that I am learning Python (your news can’t control me, because I am isolated from the world, unless I told you), but fortunately there is a Python secondary exam, otherwise I can’t mix it now. My mother was still trying to ask me to take a computer -level test. I think she can only be regarded as less than equal. My mother doesn’t like me, she won’t let me live in a house, let me live with my dad. My dad accused me every day when we met, said I was spitting badly, said I couldn’t get up and had to go out for a run at 7 o’clock every day, said my grades xjb exams xjb studies, and wanted the door to be open to see me listening to the class (with his back to him) Can’t see anything, usually writing my own code or watching a video). In the beginning, I was relatively obscure, going out early in the morning to stand and look at my phone, and from time to time I would go back to bed to sleep. Since I delivered takeout, I went straight to the top floor to lie down. When I got tired, I went straight to the kitchen (if it was dirty, I dragged it twice), or I lay down and went to sleep. There was a time when he was not at home for no apparent reason, and he walked around the neighborhood with a knife and wanted to kill my dad, which was probably similar to when my brother rushed over with a BB gun and wanted to hit me. On a whim, I recalled the past, and then looked at this broken state now. I couldn’t do anything, I couldn’t do what I wanted to do, so my emotions resonated strongly, and I wanted to clear the obstacles in exchange for a moment of tranquility. Women are emotional creatures, with nice voices, love stories (lies), handsome looks, never seen before, refreshing, perfume, and they like it. If you like it, you can give you money, you can have breast augmentation and nose surgery, and you can compare all kinds of vanity. From this point of view, the academic attainments of girls are all created by vanity, comparing for the sake of comparison, and suppressing others for the sake of suppressing others, but they never understand the real meaning of doing this. Maybe that’s the case, involution is the truth, and the world will be a better place if you step on others, at least for you. My mom doesn’t like my dad, except for money. My dad has a bad breath, because he never searches the Internet how to get rid of bad breath, and he eats dinner every day. My dad is ugly because he doesn’t wear makeup like my mom. My dad’s voice is ugly, because he competes with the leader and his subordinates every day, making a big noise, and fooling the idiot over to give him money. My voice is more or less influenced by my dad and it’s also ugly, but I’m learning to act like a spoiled child recently. Ha ha. I also learned pseudo-tones, and I didn’t learn very well, and the pitch reached c4. I still have long hair. Was it to celebrate that my dad was shot to death when he robbed a bank because he owed debts, or was it to celebrate when he got home and was rammed to death by my dad carrying his hair against the wall? I have no idea. When I was young, I was often pulled into social circles as a showy talk or the object of ridicule. In this environment, no one has something in common with me, there is no joy, and I feel that if there is a chance, I must kill everyone. My dad pushes me to say compliments to them every time. As a result, there was a cliché that I had to tell me what the bullshit thought. I directly said that there is a shortage of energy, a shortage of talents, and my IQ can’t keep up with technology. Your future will be finished without artificial intelligence. Everyone was shocked, and my dad stopped asking me to speak after that. My dad asked my mom and I to sign the loan. I called my mom and she said I couldn’t sign for him. When my mother was scolded by my father, I called my uncle because he said he would take care of my mother’s affairs. My computer was confiscated, and when I wanted to encrypt the disk, I called my uncle and told him that my dad wanted to peep at my data. However, my uncle doesn’t get along with me much after all, doesn’t know what I’m thinking, and likes to yell. I’m actually a gentle beast. If you come and follow my hair, I might even give you a piece of meat. Come and pluck my hair, and I’ll eat your flesh. Of course I might die, but I’m well-deserved. Others who communicate with me don’t really care about me, they just tell me their own way of living, and even deceive me to achieve their goals. I never really fell in love with a person because I liked him since I was a child, because when I was with other people (including my parents), I either ignored me intentionally or not and hurt me, or I got angry and hurt others. Moment of tacit understanding, and long-term avoidance, this is my love history. Over time, when I communicated with others, I also learned to be cute(?) and cover up, and often I needed to lie down on the ground or shake my head(?) while chatting to decompress. I even began to learn to repeat others and cater to others, but it was only limited to a short period of time. If you cater for a long time, you must be paid, and the more you cater to, the more satisfied you are, the more money you will get. Let my machine cater to you, okay, call millions of people over, enjoy round-the-clock service without dead ends, and I earn more than 10,000 every day. Stay away from crowds, stay away from society, stay away from the source of evil. Stay away from anyone you want to depend on. Anyone can go bad, not because you like him, he likes you, or whatever, at least for you. Take advantage of others, take advantage of everyone, keep everyone in the dark, and you will win. No one will ever hurt you again, no one who can’t take revenge, no more money to spend. Backup all data to the internet. I don’t live long, but the Internet is longer and greater. The Internet cannot crush all darkness, but it will bring more light. If you are happy, you have to die. I don’t know if this sentence is right or not, but it has been in my mind for a long time. I figured it out on the bus to school, maybe every bus ride. Do people really change? People will not change, and the world will not change, but I am changing, and I am becoming the same as it is. What I turned out to be, I don’t know, but I’ll end up being insignificant and silent."
  },
  {
    "objectID": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#install-waydroid-package-for-ubuntu",
    "href": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#install-waydroid-package-for-ubuntu",
    "title": "Waydroid installation steps",
    "section": "install waydroid package (for ubuntu)",
    "text": "install waydroid package (for ubuntu)\nvisit and save https://repo.waydro.id/ as waydroid_init_repo.sh, https://repo.waydro.id/waydroid.gpg as waydroid.gpg (using proxy)\ncomment out the download part in waydroid_init_repo.sh\n# curl --progress-bar --proto '=https' --tlsv1.2 -Sf https://repo.waydro.id/waydroid.gpg --output /usr/share/keyrings/waydroid.gpg\nmove waydroid.gpg to /usr/share/keyrings/waydroid.gpg\nexecute sudo bash waydroid_init_repo.sh to setup waydroid repository\non ubuntu you need to use proxy during apt mirror syncing.\nto setup proxy (relay local proxy to host):\n proxy --port &lt;port&gt; --host &lt;host&gt; \\\n       --plugins proxy.plugin.ProxyPoolPlugin \\\n       --proxy-pool localhost:&lt;local_proxy_port&gt;\nto use proxy:\nsudo env https_proxy=http://&lt;host&gt;:&lt;port&gt; http_proxy=http://&lt;host&gt;:&lt;port&gt; all_proxy=http://&lt;host&gt;:&lt;port&gt; apt update\n\nsudo env https_proxy=http://&lt;host&gt;:&lt;port&gt; http_proxy=http://&lt;host&gt;:&lt;port&gt; all_proxy=http://&lt;host&gt;:&lt;port&gt; apt install waydroid -y\nafter installation you should comment out the mirror at: /etc/apt/sources.list.d/waydroid.list"
  },
  {
    "objectID": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#initialize-waydroid",
    "href": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#initialize-waydroid",
    "title": "Waydroid installation steps",
    "section": "initialize waydroid",
    "text": "initialize waydroid\nstart waydroid service: sudo systemctl enable --now waydroid-container\nthe download speed of sourceforge is very slow, unless you use mirror like liquidtelecom\nmodify the file /usr/lib/waydroid/tools/helpers/http.py\n...\n\n## added part\n\ndef is_sourceforge_download_url(url: str):\n    keywords = [\"sourceforge.net\", \"download\"]\n    return all([kw in url for kw in keywords])\n\ndef use_liquidtelecom_mirror(url: str):\n    # example: https://sourceforge.net/projects/waydroid/files/images/system/lineage/waydroid_x86_64/lineage-18.1-20231216-VANILLA-waydroid_x86_64-system.zip/download\n    #      -&gt;  https://sourceforge.net/projects/waydroid/files/images/system/lineage/waydroid_x86_64/lineage-18.1-20231216-VANILLA-waydroid_x86_64-system.zip/download?use_mirror=liquidtelecom\n    keyword = \"use_mirror=liquidtelecom\"\n    if is_sourceforge_download_url(url):\n        if keyword not in url:\n            conn_symbol = \"?\" if \"?\" not in url else \"&\"\n            url += conn_symbol + keyword\n    return url\n\n## modified part\n\ndef download(args, url, prefix, cache=True, loglevel=logging.INFO, allow_404=False):\n    ...\n    url = use_liquidtelecom_mirror(url)\n    ...\n\n...\nrestart service: sudo systemctl restart waydroid-container\nrun command sudo waydroid init"
  },
  {
    "objectID": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#run-waydroid-in-xorg",
    "href": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#run-waydroid-in-xorg",
    "title": "Waydroid installation steps",
    "section": "run waydroid in xorg",
    "text": "run waydroid in xorg\ninstall weston: apt install weston\nconfigure weston at ~/.config/weston.ini\n[core]\nxwayland=true\nrun weston, launch terminal at top left corner, run waydroid"
  },
  {
    "objectID": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#network-issue",
    "href": "posts/26a76117-9cae-4661-82c2-0927c4643cec/index.html#network-issue",
    "title": "Waydroid installation steps",
    "section": "network issue",
    "text": "network issue\nin addition to the official guide, you also need to enable firewalld or ufw to make it work.\nthe wifi switch is irrelevant to network. it won’t be turned on."
  },
  {
    "objectID": "posts/6617cf67-67f7-4ce2-98a0-d7c002b106d4/index.html#linux",
    "href": "posts/6617cf67-67f7-4ce2-98a0-d7c002b106d4/index.html#linux",
    "title": "Visual Disk Usage Manager, Visual Disk Cleaner",
    "section": "linux",
    "text": "linux\nfor gnome, there’s a built in disk usage manager called baobab.\nfilelight for kde\nqdirstat"
  },
  {
    "objectID": "posts/c349d1e9-0407-4b95-b2d3-6559c9c05698/index.html#image-local-contrast-enhancement-for-removing-hard-to-detect-watermarks",
    "href": "posts/c349d1e9-0407-4b95-b2d3-6559c9c05698/index.html#image-local-contrast-enhancement-for-removing-hard-to-detect-watermarks",
    "title": "Video delogo_inpainting",
    "section": "image local contrast enhancement, for removing hard-to-detect watermarks",
    "text": "image local contrast enhancement, for removing hard-to-detect watermarks\nmaybe you can use the same trick (context preserving sliding window) from your search engine to here (image preprocessing)!\npaddleocr识别效果最好 可以识别水印位置 以及文字\nLinear Contrast Stretching, HE, AHE, CLAHE of an image using matlab\nHistogram Equalization (HE)\nAdaptive Histogram Equalization (AHE)\nContrast Limited Adaptive Histogram Equalisation (CLAHE)\nexperiment path:\npyjom/tests/remove_subtle_watermark_local_contrast_ocr\nbing query for image local contrast\ndarktable lua api and scripting\ndarktable local contrast darktable is an open-sourced photography postprocessing software\nconfigurations:\ndetails: 443\nhighlights: 36\nshadows: 25\nmidtone range: 0.16\nimagej clahe local contrast enhancement\nl2uwe L^2UWE: A Framework for the Efficient Enhancement of Low-Light Underwater Images Using Local Contrast and Multi-Scale Fusion written in matlab\nglcae Global and Local Contrast Adaptive Enhancement for Non-uniform Illumination Color Images in python\nCNN-Based-X-ray-Morphological-Decomposition\ngithub query for local image contrast\nimage processing basics Image Reading, writing, histogram, histogram equalization, local histogram equalization, low pass filter, high pass filter, geometrical transformation\ncontrast normalization is an implementation that applies local contrast normalization to images in matlab\ncontrast enhancement as a github topic\nmclahe NumPy and Tensorflow implementation of the Multidimensional Contrast Limited Adaptive Histogram Equalization (MCLAHE) procedure\ndeepcontrast A deep learning-based fully-automatic intravenous contrast detection tool for head-and-neck and chest CT scans.\nmirnetv2 (TPAMI 2022) Learning Enriched Features for Fast Image Restoration and Enhancement. Results on Defocus Deblurring, Denoising, Super-resolution, and image enhancement\npymusica is a contrast enhancement approach involving non linear mapping of Laplacian pyramid.\nimWeightedThresholdedheq attempts to enhance contrast of a given image or video by employing a method called weighted thresholded histogram equalization (WTHE).\nimagemagick wand local_contrast function\ndual gamma clahe Automatic Contrast-Limited Adaptive Histogram Equalization With Dual Gamma Correction\nimhblpce attempts to enhance contrast of a given image by employing a method called HBLPCE.\nmatlab localcontrast for image"
  },
  {
    "objectID": "posts/c349d1e9-0407-4b95-b2d3-6559c9c05698/index.html#global-contrast-enhancement",
    "href": "posts/c349d1e9-0407-4b95-b2d3-6559c9c05698/index.html#global-contrast-enhancement",
    "title": "Video delogo_inpainting",
    "section": "global contrast enhancement",
    "text": "global contrast enhancement\nim2dhiseq attempts to enhance contrast of a given image by equalizing its two dimensional histogram."
  },
  {
    "objectID": "posts/c349d1e9-0407-4b95-b2d3-6559c9c05698/index.html#previous-research",
    "href": "posts/c349d1e9-0407-4b95-b2d3-6559c9c05698/index.html#previous-research",
    "title": "Video delogo_inpainting",
    "section": "previous research",
    "text": "previous research\ndeeplearning_inpainting: https://github.com/Sanster/lama-cleaner\nffmpeg delogo: https://www.jianshu.com/p/2eb1811b5fc6 https://hhsprings.bitbucket.io/docs/programming/examples/ffmpeg/blurring_unsharping/delogo_removelogo.html https://securitronlinux.com/debian-testing/remove-a-logo-from-a-video-easily-with-ffmpeg/\nopencv inpainting/blurring with edge blending\nopencv morphlogical operations: https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/"
  },
  {
    "objectID": "posts/7af98fbc-863d-4126-8e78-793b8547fa95/index.html",
    "href": "posts/7af98fbc-863d-4126-8e78-793b8547fa95/index.html",
    "title": "Video Effects Transitions",
    "section": "",
    "text": "Video Effects Transitions\nslideshows: https://github.com/gre/diaporama https://github.com/h2non/videoshow\nafter effects like video effects https://github.com/NatronGitHub/Natron https://github.com/brianchirls/Seriously.js\nvideo ai transition tool using pose estimation https://github.com/jungdj/AI-Effects\nhttps://github.com/IronSpiderMan/VideoSpecialEffects\nvideo transitions: https://github.com/advplyr/img2vid https://github.com/ice45571/video-transition https://github.com/povdocs/video-transitions https://github.com/transitive-bullshit/ffmpeg-concat https://github.com/transitive-bullshit/ffmpeg-gl-transition\nshot detect key frame saving: https://github.com/yu239-zz/shotdetect https://github.com/AnyiRao/ShotDetection"
  },
  {
    "objectID": "posts/b470a9a9-b555-4a1a-b95d-c4a1c8750c72/index.html",
    "href": "posts/b470a9a9-b555-4a1a-b95d-c4a1c8750c72/index.html",
    "title": "Video Database",
    "section": "",
    "text": "Video Database For Video Generation\nA fastai/PyTorch package for unpaired image-to-image translation. https://github.com/tmabraham/UPIT?auto_subscribed=false&email_source=explore\n视听分割 视频注意力机制 only segment video objects that make sounds, video/audio combined segmentation: https://github.com/OpenNLPLab/AVSBench\nvideo object tracking and segmentation unified framework: https://github.com/MasterBin-IIAU/Unicorn\nvideo object segmentation handle long video with ease: https://github.com/hkchengrex/XMem\nwhen removing video watermarks, remember to ease in/out. that is said, do not stop blurring immediately after the end mark. instead, extend the blur time and decrease blur level incrementally. also, the blur ease-in is needed for the start mark, blur ahead of the start mark and ease in incrementally.\ndescriptive information generation from video/image:\nhttps://github.com/BAAI-WuDao/CogView https://github.com/BAAI-WuDao/BriVL https://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/install.md\nvideo understanding/captioning:\nhttps://github.com/rohit-gupta/Video2Language https://github.com/byeongjokim/Automatic-Baseball-Commentary-Generation-Using-DeepLearning https://github.com/shhdSU/Image_Captioning_DeepLearning https://github.com/jayleicn/recurrent-transformer https://github.com/terry-r123/Awesome-Captioning https://github.com/vijayvee/video-captioning https://github.com/scopeInfinity/Video2Description https://github.com/xiadingZ/video-caption.pytorch https://github.com/YehLi/xmodaler https://github.com/sujiongming/awesome-video-understanding\naction recognition:\nhttps://github.com/mit-han-lab/temporal-shift-module https://github.com/yjxiong/temporal-segment-networks https://github.com/yjxiong/tsn-pytorch https://github.com/open-mmlab/mmaction https://github.com/jinwchoi/awesome-action-recognition\nThe data remaining only have texts, danmaku, likes, titles, intros, comments, tags, image/video analysis results(short description). You can only generate video from generated metadata or given rules. Find similar words, similar danmaku, similar features, comments or the inverse, according to the selected topic and main idea.\nAnalyze video when downloaded, mark its highlights, analyze texts and danmaku. Get video segments and audio segments.\nCollect pictures/videos with given rules, namely finding the head of somebody, with how many likes, keywords.\nSplit audio and grab the main speaker. clone the voice and perhaps changes the gender.\nSplit video and do human/image segmentation if human/target is found. put it onto another human/target’s background masking the original human, with similar areas and movements.\nAnalyze video with off-topic(offline) and of-topic(online) sources.\nRemove watermark according to username.\nGenerate danmaku and generate video accordingly. Generate texts and generate video accordingly. Doing faceswap, talking head and human/image segmentation accordingly."
  },
  {
    "objectID": "posts/ef2d1c67-d130-4fde-94ed-1a773e6030be/index.html",
    "href": "posts/ef2d1c67-d130-4fde-94ed-1a773e6030be/index.html",
    "title": "Video Anticensor",
    "section": "",
    "text": "Video Anticensor For Bilibili Tarot\npaddlegan coloring images\ncould use p5 to do part of the job.\nvideo:\nstyle transfer glitch picture to sketch -&gt; ai painting grayscale -&gt; ai coloring dithering chroma shift(hue) (gradient/video) overlay dashing/filtering, could be done in 2 frames or more random pixel noise\ntext:\ninverted canny edge handwritten font italic pixelize, blur boxing texts slashing texts rotating texts (30 degree?) coloring texts different font size (randomly) censor words into letters reshape (decrese height or width)\naudio:\nvocoder style change pitch change"
  },
  {
    "objectID": "posts/4ff019f3-07df-49ec-9b40-2127c57d9048/index.html",
    "href": "posts/4ff019f3-07df-49ec-9b40-2127c57d9048/index.html",
    "title": "Upload Model To Huggingface",
    "section": "",
    "text": "Upload Model To Huggingface\nvia code: https://zhuanlan.zhihu.com/p/390826470\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\ncheckpoint = “camembert-base”\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint) tokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel.push_to_hub(“dummy-model”) tokenizer.push_to_hub(“dummy-model”) # config.push_to_hub(“”)"
  },
  {
    "objectID": "posts/ba7491c8-8999-496a-81c9-3a7c44125c92/index.html",
    "href": "posts/ba7491c8-8999-496a-81c9-3a7c44125c92/index.html",
    "title": "Translators for Casual usage",
    "section": "",
    "text": "Translators/Paraphraser for casual usage\nbaidu translator (api) provided by paddlehub\nbaidu language detector (api)\ntext style transfer:\nhttps://blog.csdn.net/qq_27590277/article/details/106991084\npython google translate api: pip install googletrans\ngoogle translate in php: https://github.com/Stichoza/google-translate-php\nparaphrase via rephrasing and reordering\npegasus paraphrase:\nincrease the num_beams and temperature https://analyticsindiamag.com/how-to-paraphrase-text-using-pegasus-transformer/\nhttps://www.thepythoncode.com/article/paraphrase-text-using-transformers-in-python\nexample paraphrase project using LSTM as decoder and encoder:\nhttps://github.com/vsuthichai/paraphraser\nparaphrase with t5:\nhttps://github.com/Vamsi995/Paraphrase-Generator\nparaphrase dataset:\nhttps://github.com/Wys997/Chinese-Paraphrase-from-Quora\n文本纠错 https://github.com/James4Ever0/pycorrector\n数据增强 变换句子形式 https://yongzhuo.blog.csdn.net/article/details/89166307 https://github.com/zhanlaoban/eda_nlp_for_Chinese\ncalculate perplexity:\nhttps://github.com/DUTANGx/Chinese-BERT-as-language-model https://github.com/James4Ever0/nlp-fluency https://zhuanlan.zhihu.com/p/265677864 https://github.com/mattzheng/py-kenlm-model\nmulti-purpose tool for chinese: 偏旁部首 情感分析 https://github.com/SeanLee97/xmnlp\n敏感词过滤 语言检测 训练语料库 https://github.com/fighting41love/funNLP\nparaphraser.io\nmultilingual paraphrase database:\nparaphrase.org\nsimbert\nhttps://www.zhihu.com/question/317540171\nBERT：原始版本bertRoberta：哈工大开源的中文wwm roberta模型BERT-SQ：本人在百度知道相似句数据集(Sim-Query)上微调后的bert模型Roberta-SQ：同上BERT-Whitening： @苏剑林 最新博客中提出的白化模型。Roberta-Whitening：同上\nhttps://yongzhuo.blog.csdn.net/article/details/89166307\nlanguage fluency test:\nhttps://github.com/baojunshan/nlp-fluency\nmany paraphraser models for english are on huggingface, but few for chinese.\nhttps://huggingface.co/lijingxin/mt5-for-zh-paraphrase https://pypi.org/project/genienlp/ https://github.com/salesforce/decaNLP\nparrot paraphraser with nlu engines for english: https://github.com/PrithivirajDamodaran/Parrot_Paraphraser\nsentence level paraphraser: https://github.com/vsuthichai/paraphraser\ndocument level paraphraser, with sentence rewriting and reordering(shuffle): https://github.com/L-Zhe/CoRPG\nhttps://pypi.org/project/lexsub/ https://github.com/hit-joseph/lexical-paraphrase-extraction synonyms (python library)\nyou can also train a contextual search tool using fine-tuned repurposed paraphrase model.\nhttps://pypi.org/project/nlp-text-search/\n文言文 https://github.com/raynardj/yuan\n粤语 https://huggingface.co/x-tech\nhuggingface有英语翻译到其他语言的模型 没有翻译成中文的模型\n在线 https://github.com/nidhaloff/deep-translator https://github.com/UlionTse/translators translatepy\n离线 https://huggingface.co/tasks/translation https://huggingface.co/Helsinki-NLP/opus-mt-zh-en https://github.com/argosopentech/argos-translate libretranslate https://github.com/Teuze/translate https://github.com/xhlulu/dl-translate/ facebook/mbart-large-50-many-to-many-mmt mbart50 m2m100\nview under https://huggingface.co/tasks to see great models fitting exact needs."
  },
  {
    "objectID": "posts/9a35d46c-4ee6-4d3c-888e-e1a27a2e181c/index.html",
    "href": "posts/9a35d46c-4ee6-4d3c-888e-e1a27a2e181c/index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "Time Series Analysis\nTime Series Alerting: https://github.com/bosun-monitor/bosun\nDeep learning time series: https://github.com/Alro10/deep-learning-time-series\nLSTM Time series forecast stock market: https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction"
  },
  {
    "objectID": "posts/5fe77583-8a05-4da3-a8eb-a94dd5521ee4/index.html",
    "href": "posts/5fe77583-8a05-4da3-a8eb-a94dd5521ee4/index.html",
    "title": "Creating Cybergod: A Digital Entity to Continue Your Legacy",
    "section": "",
    "text": "The reason why you build Cybergod\nI regret my actions. I waste my time. I can’t stop it. Cybergod is the only thing that can get me out of this strange loop. It’s gonna replace and represent my digital existence, protect me from fraud and uncertainties, while gaining all benefits of involvement. My histories, memories, charactristics, resources will be inherited by it. Cybergod is my continuation. It is my belief, my dream, my purpose of life."
  },
  {
    "objectID": "posts/94feeb5a-00c4-4ec8-9df7-f8b7a24b1e47/index.html",
    "href": "posts/94feeb5a-00c4-4ec8-9df7-f8b7a24b1e47/index.html",
    "title": "The Interesting Life",
    "section": "",
    "text": "The Interesting Life: Increase Video/Essay/Post Views\nInteresting is defined as the amount of changes. The more you change the more interesting it will be. Find and summarize essay by conjunctives, describe the relationship between each segments, arrange them by conjunctive templates.\n文案生成器 自媒体话术"
  },
  {
    "objectID": "posts/7af25a59-d0ad-406c-88ba-82091863fa7e/index.html",
    "href": "posts/7af25a59-d0ad-406c-88ba-82091863fa7e/index.html",
    "title": "The Exam",
    "section": "",
    "text": "The Exam\nhttp://sspu.edu.cn/info/iList.jsp?tm_id=799\n20201262207\nQq65680156.\nProcess might be accelerated with desktop IM apps."
  },
  {
    "objectID": "posts/c36e6fca-4165-443a-8273-ab6b3bf6c8e7/index.html",
    "href": "posts/c36e6fca-4165-443a-8273-ab6b3bf6c8e7/index.html",
    "title": "Terminal autocomplete",
    "section": "",
    "text": "Terminal autocomplete\nLinux support in alpha, currently MacOS only:\nfig\nwarp\nwhy my vim stops working?\nwarp known issues"
  },
  {
    "objectID": "posts/48e7228d-af26-47c0-b40c-758eb77eaae9/index.html",
    "href": "posts/48e7228d-af26-47c0-b40c-758eb77eaae9/index.html",
    "title": "SpeedUp Tujia Scraping",
    "section": "",
    "text": "SpeedUp Tujia Scraping\nFind which request sets the cookie, then do all other requests using DIRECT, route only that request to GLOBAL."
  },
  {
    "objectID": "posts/32c72334-876d-4cf8-995f-e4c0c9290e1f/index.html",
    "href": "posts/32c72334-876d-4cf8-995f-e4c0c9290e1f/index.html",
    "title": "Sound Effects",
    "section": "",
    "text": "Sound Effects\nspotify/pedalboard\nsupport vst plugins, create sound effects"
  },
  {
    "objectID": "posts/b30613a3-fd79-44fb-a2e4-12ffc72925dc/index.html",
    "href": "posts/b30613a3-fd79-44fb-a2e4-12ffc72925dc/index.html",
    "title": "Soul API",
    "section": "",
    "text": "Soul APIs\nsoul绕过ssl双向验证 justTRUSTME(xposed)加上反编译SDK获取证书密码 backup blog\nuse adb to setup mitmproxy on android\ncd ~/Library/Android/sdk/platform-tools/\n\n# Get the hash of the mitmproxy-ca certificate.\nopenssl x509 -inform PEM -subject_hash_old -in ~/.mitmproxy/mitmproxy-ca.pem | head -1\n\n# We will use this hash value, append '.0' (dot zero) and use this as the filename for the resulting Android certificate\ncat ~/.mitmproxy/mitmproxy-ca.pem &gt; c8750f0d.0\nopenssl x509 -inform PEM -text -in ~/.mitmproxy/mitmproxy-ca.pem -out /dev/null &gt;&gt; c8750f0d.0\n\n# In an other terminal, we will start the emulator with writable /system volume\ncd ~/Library/Android/sdk/emulator/\n\n# In order to launch an available avd, we list them first.\n./emulator -list-avds\n./emulator -writable-system @Pixel_3a_XL_API_28\n\n# We go back to the first terminal and we use adb tool to transfert the certificate\nadb root\nadb push c8750f0d.0 /storage/emulated/0/Download\n\n# Then, we will mount the volume and get access to the shell\nadb shell mount -o rw,remount /;\nadb shell\n\n# In the device Android shell, we will move the certificate inside the system partition in the folder '/system/etc/security/'\ncp /storage/emulated/0/Download/c8750f0d.0 /system/etc/security/cacerts/\nchmod 644 /system/etc/security/cacerts/c8750f0d.0\n可能的系统设置\nsu -c settings list global | grep proxy\nglobal_http_proxy_exclusion_list=\n                                global_http_proxy_host=\n                      global_http_proxy_port=0\n             global_proxy_pac_url=\n http_proxy=:0\n灵魂测试卡片信息，获取签名* https://api.soulapp.cn/html/measureResult/info/v2?userIdEcpt=加密用户ID\n用户头像和签名等信息* https://api-h5.soulapp.cn/html/v2/user/info?userIdEcpt=加密用户ID\n单条瞬间展开信息* https://api-h5.soulapp.cn/html/v3/post/detail?postIdEcpt=加密瞬间ID\n单条瞬间展开页面* https://w3.soulapp-inc.cn/activity/#/web/topic/detail?postIdEcpt=加密瞬间ID\n用户发布瞬间信息，只有最新的10条* https://api-h5.soulapp.cn/html/v2/post/homepage?userIdEcpt=加密用户ID\n用户发布瞬间页面，只有最新的10条* https://w3.soulapp-inc.cn/activity/#/web/user?userIdEcpt=加密用户ID\n获取热门瞬间，只有最新的30条* https://api-h5.soulapp.cn/html/v2/post/hot?pageIndex=1（前3页）\n获取标签的瞬间信息，只有最新的30条* https://api-h5.soulapp.cn/html/v2/tag/post?tagIdEcpt=加密标签ID\n获取标签的瞬间页面，只有最新的30条* https://w3.soulapp-inc.cn/activity/#/web/tag?tagIdEcpt=加密标签ID\n随机播放音频信息，随机几首* https://api-h5.soulapp.cn/html/v2/post/orimusicList/recommend\n设置超萌捏脸页面* https://app.soulapp.cn/avator/#/avatar/create?sex=1&version=3.10.0\n注销账号页面* https://app.soulapp.cn/app/#/account https://app.soulapp.cn/app/#/destroy"
  },
  {
    "objectID": "posts/af780836-2fb9-45a2-bfd7-fac5758d89c9/index.html",
    "href": "posts/af780836-2fb9-45a2-bfd7-fac5758d89c9/index.html",
    "title": "Sleepless in Bed 失眠治疗法",
    "section": "",
    "text": "Sleepless in Bed 失眠治疗法\n床上躺的太久 考虑伸展你的腿部 手部 拔筋\n吃饭吃太多 可以用勒肚子的方法 把裤子提高一些 这样只能吃包子 煎饼之类的 不能吃大餐 哪怕饿了一晚上也不能吃\n根据知乎 应该按照节律调整光照 但是在房间里只能模拟光照\n在规定时间上床睡觉 确保黑暗 安静\n在快起床的时候 渐进的提高光照 提高声音音量 辅助起床\n属于智能家居的范畴 智能家居代码 https://github.com/home-assistant/core\n自动调灯泡亮度 智能灯泡需要手工焊接串口转USB的板子 或者用arduino 树莓派实现 https://duino4projects.com/project-auto-intensity-control-of-street-light-using-arduino/amp/ https://forum.arduino.cc/t/how-to-control-a-lamps-intensity/57081\nBy simply working in bed, lying down or not, using pillow or not, sore ass or not, I somehow lose sleep in bed. Don’t know how to explain, but this is simply true. I admit many people have lost their sleep in bed too, but never comfortable to do so. I am somehow better than them."
  },
  {
    "objectID": "posts/ecb0991f-7de7-4003-9e85-5ac8612abea7/index.html",
    "href": "posts/ecb0991f-7de7-4003-9e85-5ac8612abea7/index.html",
    "title": "Singing Voice Generation and more",
    "section": "",
    "text": "Singing Voice Generation and more\ngenerate audio and music: audiolm\naudio ai timeline best audio generation models\ngenerate music using diffusion\nriffusion web app\nriffusion demo website\nriffusion\necantorix generate singing voice using lmms and espeak\nread/write deepvoice binary file\ndecrypt acestudio binary project file\n谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 https://www.kuxai.com/article/398\n论文地址：https://arxiv.org/abs/2110.08813 我的fork仓库：https://github.com/innnky/VISinger\nscoredraft in python:\nhttps://m.bilibili.com/video/av19085545 https://github.com/fynv/ScoreDraft\nACE studio 公测： ACE Studio是时域科技旗下的AI歌声合成引擎，通过毫无妥协的高表现力人声，解除演唱能力的羁绊，释放人们的音乐想象力。\n2022年7月12日，ACE Studio公测开启。\n为了在正式收费之前提供更好的稳定性体验，本轮公测期间，所有AI歌手和编辑器功能均可免费使用。下载软件后，使用手机号注册登录，即可开始使用。Mac/Win双端均可使用。\n下载地址：https://ace-studio.timedomain.tech/\noss singing software:\nMicrosoft muzic http://sinsy.sourceforge.net https://alternativeto.net/software/ecantorix/about/ https://alternativeto.net/software/openutau/about/ https://alternativeto.net/software/cadencii/about/\nvoice style transfer:\nhttps://github.com/andabi/deep-voice-conversion https://rebryk.github.io/convoice-demo/ https://github.com/mazzzystar/randomCNN-voice-transfer https://becominghuman.ai/convoice-real-time-zero-shot-voice-style-transfer-with-convolutional-network-4c7b7fff66c9 https://ebadawy.github.io/post/speech_style_transfer/\nyou can alter the order of generated lyrics, fitting into the sequence of the original lyrics.\nlyrics generation:\nhttps://zhuanlan.zhihu.com/p/137214305 https://baijiahao.baidu.com/s?id=1666495322826772953 https://github.com/dengxiuqi/Lyricist-torch https://github.com/zipper112/LyricsGeneration https://github.com/coder-yuzhiwei/wangfeng-lyrics-generator https://github.com/jianyq/Tong-Music https://github.com/MarsWang42/hanmai-generator https://github.com/tobiaslee/chinese-hip-pop-generation"
  },
  {
    "objectID": "posts/77074f79-1128-4cca-9df0-8b0b7294c902/index.html",
    "href": "posts/77074f79-1128-4cca-9df0-8b0b7294c902/index.html",
    "title": "Similar Image Search",
    "section": "",
    "text": "Similar Image Search\nimage local search by similarity: https://github.com/ProvenanceLabs/image-match\nanime image search by scene: https://github.com/soruly/trace.moe\nbing image search: https://cn.bing.com/visualsearch/Microsoft/SimilarImages https://cn.bing.com/visualsearch\nsougou shitu: https://pic.sogou.com/shitu/index.html\nbaidu shitu: shitu.baidu.com\ngoogle image search: https://gfsoso.soik.top/shitu.html\nyandex image search: https://yandex.com/images/\nimage search websites: https://zhuanlan.zhihu.com/p/52693499\ntutorial on image search, gif search, image enlargement, browser plugins: https://www.bilibili.com/read/cv8688532\nduososo shitu(include other meta search engines): http://duososo.com/index_shitu.php\nzhihu image search websites: https://zhuanlan.zhihu.com/p/25610099\nfind font by images(not working qiuziti.com): https://zhuanlan.zhihu.com/p/25440271?refer=wnsouba\nfind bangumi segments by image: 还有一个telegram bot 叫 WhatAnimeBot https://whatanime.ga/ https://zhuanlan.zhihu.com/p/25313498"
  },
  {
    "objectID": "posts/69d39fa7-da5e-421a-bb19-28a13661c0af/index.html",
    "href": "posts/69d39fa7-da5e-421a-bb19-28a13661c0af/index.html",
    "title": "Setup Gitee SSH Keys for GitJournal",
    "section": "",
    "text": "Setup Gitee SSH Keys for GitJournal\nhttps:/gitee.com/profile/sshkeys\npersonal ssh keys. not deploy keys under specific project settings.\nhttps://gitee.com/n5366871df2f3/notes\ngitjournal download:\ninstall apps on anbox:\nthis thing is built on top of flutter, which could also be avaliable for windows. also it is free on all pro features."
  },
  {
    "objectID": "posts/498f0da0-1cfe-444c-b001-046905a6a1a6/index.html",
    "href": "posts/498f0da0-1cfe-444c-b001-046905a6a1a6/index.html",
    "title": "Self hosted web applications",
    "section": "",
    "text": "Self hosted web applications\ncommon web applications could be big, like search engines. this is a list of open-sourced self hosted services: https://github.com/awesome-selfhosted/awesome-selfhosted"
  },
  {
    "objectID": "posts/1c6b17e6-c481-401d-922f-4d25428d7842/index.html#windows",
    "href": "posts/1c6b17e6-c481-401d-922f-4d25428d7842/index.html#windows",
    "title": "Search and switch to window by title",
    "section": "windows",
    "text": "windows\n\nyal\naccess and search windows\naccess files, programs, bookmarks, search engines"
  },
  {
    "objectID": "posts/1c6b17e6-c481-401d-922f-4d25428d7842/index.html#macos",
    "href": "posts/1c6b17e6-c481-401d-922f-4d25428d7842/index.html#macos",
    "title": "Search and switch to window by title",
    "section": "macos",
    "text": "macos\n\nfinda\nfind windows, browser tabs, code editor buffers, browser history, apps, files"
  },
  {
    "objectID": "posts/1c6b17e6-c481-401d-922f-4d25428d7842/index.html#linux",
    "href": "posts/1c6b17e6-c481-401d-922f-4d25428d7842/index.html#linux",
    "title": "Search and switch to window by title",
    "section": "linux",
    "text": "linux\nkupfer plugin window list\nuse xdotool and wmctrl\nWindow List command (wmctrl):\n$ wmctrl -lx\n0x0540043e  0 google-chrome.Google-chrome  ubunzeus Search for window title? - Ask Ubuntu - Google Chrome\n0x050000ec  0 Mail.Thunderbird      ubunzeus Inbox - Mozilla Thunderbird\n0x04e1068d  0 gnome-terminal-server.Gnome-terminal  ubunzeus ljames@ubunzeus: ~\nCommand to switch to specific window (xdotool)\n$ xdotool windowactivate 0x0540043e\nThe above command will switch to the Windows with the ID 0x0540043e, which is specific from the list for this Askubuntu message entry.\nThey are both in the repository:\n$ sudo apt install wmctrl xdotool"
  },
  {
    "objectID": "posts/500c47fc-fb23-47f2-b012-768a5457fd93/index.html#seo-without-website",
    "href": "posts/500c47fc-fb23-47f2-b012-768a5457fd93/index.html#seo-without-website",
    "title": "SEO 蓝海词 竞争度",
    "section": "seo without website",
    "text": "seo without website\nwrite a blog on github?\ncreate short links and submit them to search engine\nget query count, perform n-gram analysis\nhttps://www.aeripret.com/ngrams-analysis-seo/\nhttps://www.pemavor.com/seo-keyword-clustering-with-python/\ni have bookmarked links for further use on macbook chrome.\nadvertools is a professional SEO library, productivity & analysis tools to scale your online marketing\n可以用分析股价的方法分析搜索关键词 其中股价对应搜索频率（实时） 播放量对应成交量（实时）也可能不对 反正这个模型肯定要先收集数据然后再建模 画k线 当然也不必完全拘泥于全盘还原 收集到的数据能反映实际情况 得到最优解 也就是发个视频预估播放量最大就行 用深度学习模型\n寻找潜在爆款话题 标签\n快排参数 上首页 https://github.com/sopify-bot/seo\n分为主动点击 换IP点击 以及优化自身关键词 被动优化两种方式\n蓝海词可以从零开始做 可以由现有词语延伸 可以寻找已有的蓝海词\n蓝海词是产品关键词的一种，又被称为“零少词”、“长尾词”。具体是指前台具备一定买家搜索热度，但供应商发布产品较少，通常该词下对应的精确匹配产品数量不超过3页，因而同行竞争度较低的关键词。一旦供应商能准确使用这些词语，并能结合信息质量发布一条合格的产品信息，将获得曝光和点击的快速提升\n红海泛指竞争相当激烈的市场。在红海中，产业边界是明晰和确定的，游戏的竞争规则是已知的。身处红海的企业试图表现得超过竞争对手，以攫取已知需求下的更大市场份额\n淘宝标题撰写技巧：标题流量的3架马车，飙升词+蓝海词+销量卡位词\n什么是飙升词？就是在短时间内热度迅速攀升，并且持续上升的词！\n蓝海词就是那些搜索热度非常高，但这个词下面的在线产品却很少的词。\n这种词可以让我们避免和红海大词竞争，获取很多隐藏流量！\n淘宝界面除了能够综合排序之外，我们还能通过销量来排序。\n关键词卡位就是 寻找点击量和你差不多的视频 商品所拥有的关键词语 标签 这样按照播放量排序的时候就会排到这些视频中间"
  },
  {
    "objectID": "posts/c9b406df-2602-42cd-abe6-ad48430d9754/index.html#tools",
    "href": "posts/c9b406df-2602-42cd-abe6-ad48430d9754/index.html#tools",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "tools",
    "text": "tools\nkeyword mining (by search engine or more): 2 words -&gt; 3 words -&gt; 4 words -&gt; 5 words (recursive)\nkeyword-suggest-tool is a simple tool that provides you keyword suggestion from multiple search engines like google, bing, yahoo, ebay, amazon, ebay, deployed on sutlej.net/seo-tools\nULTRA Unbiased Learning To Rank Algorithms, sorting things out, find what users like the most\nserpbear check rankongs on google\ncurated seo tools huge tools/website collection on seo category\nawesome-keyword-finder-tools A curated list of amazingly awesome seo keyword finder tools\nKeyword-Research-tool-python Build a Keyword research tool with google autocomplete suggestions in python\nkeyword tool The Keyword Manager is a tool to support SEAs and SEOs finding new keywords from a website.\nkeyword_tool Web app to extract keywords from pasted text. Built with NLTK and Streamlit.\nkeywordshitter2 A website to find long-tail keywords using search suggestions, still works on here\nPURR (PUppeteer RunneR) is a devops-friendly tool for browser testing and monitoring by semrush\nawesome-local-seo A curated list of amazingly awesome local seo resources.\nseo-audits-toolkit SEO & Security Audit for Websites. Lighthouse & Security Headers crawler, Sitemap/Keywords/Images Extractor, Summarizer, etc …\nseo_keyword_research_tools The Keyword Volume Tool uses the Google Adwords API Targeting Ideas Service to return the search volume and competition of a massive list of keywords. The Keyword Expansion Tool uses the Google Adwords API Targeting Ideas Service to expand an input keyword into up to 500 related keywords with search volume.\nResources"
  },
  {
    "objectID": "posts/c9b406df-2602-42cd-abe6-ad48430d9754/index.html#functionalities",
    "href": "posts/c9b406df-2602-42cd-abe6-ad48430d9754/index.html#functionalities",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "functionalities",
    "text": "functionalities\nCompetitive analysis Keyword research Backlink research Content research/Content optimization/Content planning Rank Tracker Site audit tool/Site explorer Link analysis/Link profile Domain comparison competitor research SEO Metrics Google Data studio"
  },
  {
    "objectID": "posts/c9b406df-2602-42cd-abe6-ad48430d9754/index.html#glossaries",
    "href": "posts/c9b406df-2602-42cd-abe6-ad48430d9754/index.html#glossaries",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "glossaries",
    "text": "glossaries\nLocal SEO: the practice of optimizing your website for a specific local area\nSERP: search engine result page, means scraping from search engine to get rankings.\nSEO: search engine optimization, means to cheat the search engine to get higher rankings.\nSEM: search engine marketing, pay ads to search engine, or advertise on your own search engine?\nSMM: social media marketing, play nice with the public\nSMO: social media optimization, attract users on platform"
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#p2p-network",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#p2p-network",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "p2p network",
    "text": "p2p network\nnps also supports p2p\n(deprecated! does not pass the connectivity test) opengnb p2p network, faster than n2n v3, can run without public ip\ngost as an frp alternative\nturned out n2n is necessary, since the speed comparasion strongly disencourage the usage of frp directly.\nn2n test commands, using compatible v3 protocol to communicate:\nsupernode v3: n2n.laiyx.win:10090\nwarning: it is useless to add multiple supernodes.\n-l nton.eu.org:10090 -l n2n.lu8.win:10090 -l n2n.haoren.eu.org:10090 -l     \nsupernode.ntop.org:7777 -l 47.102.102.77:10090 -l n2n.myan.cc:10090 -l n2n.sfcs.eu.org:10090 -l n2n.eriol.cn:10090 -l n2n.x0x.cn:10090 -l n2n.vvcd.win:10090\nkali:\nsudo edge -c &lt;name&gt; -k &lt;password&gt; -a 192.168.100.1 -f -l n2n.laiyx.win:10090 -Er -A3 -e auto\nmacos, since we use sudo you might consider doing it with system service:\nsudo edge -c &lt;name&gt; -k &lt;password&gt; -a 192.168.100.2 -f -l n2n.laiyx.win:10090 -Er -A3 -e auto\npublic shared n2n supernodes\nyou could test the speed and decide to use it or not.\nin kali discovery service, when local connection is not avaliable, usually the p2p network is preferred than direct frp tunneling.\nbrew has tinc as a package!\ntinc conf\ntinc setup with core server\nremote access with vps using tinc\ninstall and config tinc on linux\ntinc is somehow complex and it may requires some tinkering on tinc-up or using docker.\ninstall n2n without macports\nuse n2n to send udp packages among clients, try to create direct link between devices which will speed up ssh connection speed. supernode creation could be used along with frpc\nsomehow brew does not have n2n as a package. macports has it, which requires xcode (huge!) to be installed.\npeervpn tutorial"
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#daemonize-launch-at-startup",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#daemonize-launch-at-startup",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "daemonize (launch at startup)",
    "text": "daemonize (launch at startup)\non macos, when crontab is created, cron will be automatically launched by launchd.\ncronjobs may need to launch with the $(which env) prefix.\nthe problem of internet disconnetion will most not likely to interfere with the server since frpc has auto reconnection and the update hook is the filesystem watchdog, which will not run when no changes made (including the offline period)\nthe watchdog may be replaced by some mirror fuse system, which will report every access request to our dedicated server.\nwe have seen this behavior (filesystem mirroring) in our gitfuse code. but does that support symlink? should we really take care of that? or should we forget that and just use inotify instead?\nmaybe it will affect the client when mounting the remote filesystem using sshfs or rclone, but that has to be verified."
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#serve-and-mount-remote-filesystem",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#serve-and-mount-remote-filesystem",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "serve and mount remote filesystem",
    "text": "serve and mount remote filesystem\nbefore serving, make sure the path /media/root/help/pyjom exists by running our mount script\ncreate htpasswd file:\nhtpasswd -bc webdav_htpasswd &lt;username&gt; &lt;password&gt;\nuse rclone:\nrclone serve webdav /media/root/help/pyjom --addr 0.0.0.0:8468 --key /root/.local/share/code-server/localhost.key --cert /root/.local/share/code-server/localhost.crt --htpasswd /root/Desktop/works/sync_git_repos/remote_deploys/webdav_htpasswd -L\nbefore mounting, use rclone config to setup remote associated with a name. make sure the hostname is localhost instead of ip address to avoid certificate issues. do not install rclone from brew since it does not support fuse. instead, install from here\nrclone mount webdav_local_nginx:/ /Volume/CaseSensitive/pyjom_remote_mountpoint --ca-cert /Users/jamesbrown/Desktop/works/host_discovery_ssh_local_connect/certificates/localhost.crt\nafter mounting, seems zsh on macos is not working very well with macfuse. bash works. does bash/fish works with sshfs as well? maybe that will save efforts."
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#encryption-and-invalid-https-certificates",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#encryption-and-invalid-https-certificates",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "encryption and invalid HTTPS certificates",
    "text": "encryption and invalid HTTPS certificates\nuse nginx to redirect remote server as localhost, since the host name on the certificate is localhost we cannot let chrome to trust anything other than that\nworker_processes auto;\nerror_log error.log;\nevents { }\nstream {\n  server {\n    listen 127.0.0.1:7576;\n    proxy_pass REMOTE_HOST:7576;\n  }\n}"
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#code-serverbrowser-color-fixes",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#code-serverbrowser-color-fixes",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "code-server(browser) color fixes",
    "text": "code-server(browser) color fixes\n.cursor{\n  background: white;\n}\n\nbody.web{\n  caret-color: white;\n}\n\n.monaco-editor .view-line span.inline-selected-text{\n  background: blue;\n  color: white;\n}"
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#connectors-other-than-frp",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#connectors-other-than-frp",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "connectors other than frp",
    "text": "connectors other than frp\ncode-server recommends some other methods like cloudflared and ngrok. 花生壳可能也有用 但是可能不好用"
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#methods",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#methods",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "methods",
    "text": "methods\ntry out code-server by coder, might work?\nalso we use builtin vscode connectors, using ssh.\ncurrently we only have one, which uses direct ip address instead of a hijacked domain. maybe it is time to consider some faster server providers.\nuse a universal ssh as workspace extension called SSH FS"
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#drawbacks-of-ssh-fs-extension",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#drawbacks-of-ssh-fs-extension",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "drawbacks of SSH FS extension",
    "text": "drawbacks of SSH FS extension\nsome drawbacks of this SSH FS plugin is that it cannot use the plugins from remote machine, also having issue whe jumping to remote files from terminal output. to run code-insider instead of code-oss, maybe we could spin up the official ssh connector, which can only be automated by publickey authentication."
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#syncing-updating-and-viewing-using-watchdog-and-sshfsdeprecated-since-it-shares-connection-with-vscode-remote-and-maybe-slower-than-rclone-serve-webdav",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#syncing-updating-and-viewing-using-watchdog-and-sshfsdeprecated-since-it-shares-connection-with-vscode-remote-and-maybe-slower-than-rclone-serve-webdav",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "syncing, updating and viewing using watchdog and sshfs(deprecated since it shares connection with vscode remote and maybe slower than rclone serve webdav?)",
    "text": "syncing, updating and viewing using watchdog and sshfs(deprecated since it shares connection with vscode remote and maybe slower than rclone serve webdav?)\nto mount the filesystem via sshfs:\nsshfs root@192.168.10.4:/media/root/help/pyjom /Volumes/CaseSensitive/pyjom_remote_mountpoint -o follow_symlinks\nto make sure the changes are updated regularly, we need a filesystem watchdog on kali, which will trigger the action of syncing, utilizing inotify. shall that be adopted on macos? maybe. but my extra editors can be vim or nvim, so it is not so hard to predict. but if it can monitor the file read events, we don’t need those legacy editor program hooks.\nat least we need to see the output, so we need to mount the remote filesystem as sshfs, then use ffplay to view it."
  },
  {
    "objectID": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#solution",
    "href": "posts/461b3a3f-ab71-4876-a1b7-c718a1f49056/index.html#solution",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "solution",
    "text": "solution\nfor now, two viable ways:\none using code-server, the other using code-server-insider provided by code-insider. when using builtin code-server-insider, remember it will not share the plugins installed by code-insider. the remote executable location is at /root/.vscode-server-insiders/bin/12b08be500f8a307f30e92cbc3ee39ba115eab69/bin/code-server-insider or something. must set the local setting remote.SSH.useLocalServer to false.\nwhen using code-server, one can connect to the workspace using browser, instead of vscode builtin remote connector."
  },
  {
    "objectID": "posts/f17ab565-b75f-4b5f-b774-c7aabc859234/index.html#with-processor-flags-output",
    "href": "posts/f17ab565-b75f-4b5f-b774-c7aabc859234/index.html#with-processor-flags-output",
    "title": "Repl for Assembly Code",
    "section": "with processor flags output",
    "text": "with processor flags output\nhttps://github.com/yrp604/rappel"
  },
  {
    "objectID": "posts/f17ab565-b75f-4b5f-b774-c7aabc859234/index.html#msf-provided-repl",
    "href": "posts/f17ab565-b75f-4b5f-b774-c7aabc859234/index.html#msf-provided-repl",
    "title": "Repl for Assembly Code",
    "section": "msf provided repl",
    "text": "msf provided repl\nmsf-nasm_shell"
  },
  {
    "objectID": "posts/91896b2c-0a79-4388-82c9-def90e701197/index.html",
    "href": "posts/91896b2c-0a79-4388-82c9-def90e701197/index.html",
    "title": "Remote Jobs",
    "section": "",
    "text": "Remote Jobs\nremote jobs in china: https://github.com/LinuxSuRen/remote-jobs-in-china\nremote jobs from stack overflow:"
  },
  {
    "objectID": "posts/2daad1ad-e59a-4e80-80f8-faa9cfb62dfa/index.html",
    "href": "posts/2daad1ad-e59a-4e80-80f8-faa9cfb62dfa/index.html",
    "title": "Read Manga Online",
    "section": "",
    "text": "Read Manga Online\nhttps://mangareader.to/read/tokyo-ghoulre-362"
  },
  {
    "objectID": "posts/63d63aa4-4bfc-4dc2-a6cd-3f947802826c/index.html",
    "href": "posts/63d63aa4-4bfc-4dc2-a6cd-3f947802826c/index.html",
    "title": "RX580 16g used as AI accelerator",
    "section": "",
    "text": "RX580 16g used as AI accelerator\ncodename: gfx803\nyou may have to build it yourself"
  },
  {
    "objectID": "posts/002a30c9-b48c-4035-8369-cf5265f8344a/index.html#smart-watch",
    "href": "posts/002a30c9-b48c-4035-8369-cf5265f8344a/index.html#smart-watch",
    "title": "RSIBreak, Break Reminder",
    "section": "Smart Watch",
    "text": "Smart Watch\ndo not mix the water with the watch. you have been warned.\n\nPrefer WearOS watches like LG W100. Found 3D printable case on Shapeways but not downloadable. Shapeways provides service for printing. Shapeways builds ShapeJS which can construct 3D models with code.\n\nUse Pixle2Mesh++ to recover 3D meshes from multiple images (dumped at ~/Desktop/works/shapeways_reconstruct_from_image_lg_w100)of different viewpoints. Determine the size of the mesh after measurement or learning specs.\n\nif you want iwatch instead, remember to buy some apple gift cards for buying watchos apps. remember to ask for battery life since older watches tend to die halfway in a day. buy iphone 6s and newer models with ios 14 and newer os to manage and install apps on iwatch. no need for 3d modeling since plenty tough-tested cases around."
  },
  {
    "objectID": "posts/002a30c9-b48c-4035-8369-cf5265f8344a/index.html#diy",
    "href": "posts/002a30c9-b48c-4035-8369-cf5265f8344a/index.html#diy",
    "title": "RSIBreak, Break Reminder",
    "section": "DIY",
    "text": "DIY\nif you want to do it on your own, you have to know how to send notifications on different operating systems.\n\non macOS:\nosascript -e 'display notification \"This message should be showing on the notification\" with title \"Coding Tips\"'\nterminal-notifier (brew installable)\nalerter\n\non linux:\nnotify-send \"Dinner ready!\"\nusing remind:\nremind \"I'm still here\" now\nremind \"Time to wake up!\" in 5 minutes\nremind \"Dinner\" in 1 hour\nremind \"Take a break\" at noon\nremind \"It's Friday pints time!\" at 17:00\n\non windows:\nmsg /SERVER:DestinationPC * /TIME:60 “This is the message to be sent to a PC named DestinationPC and closes in 60 seconds.\"\nnotify-send-for-Windows (needs AHK)\ntutorial"
  },
  {
    "objectID": "posts/002a30c9-b48c-4035-8369-cf5265f8344a/index.html#break-reminder-tools",
    "href": "posts/002a30c9-b48c-4035-8369-cf5265f8344a/index.html#break-reminder-tools",
    "title": "RSIBreak, Break Reminder",
    "section": "break reminder tools",
    "text": "break reminder tools\nRSIBreak is for linux, and it does not work well.\nstretchly has an online version. on macOS make sure your browser is allowed to post notifications.\n“Drink.” on mac app store is a water drinking reminder for macOS.\nBreakTimer has windows, macOS and linux version. on linux you better use snap or appimage version."
  },
  {
    "objectID": "posts/f808aaf8-3fb6-4038-9eec-326b20433bd0/index.html",
    "href": "posts/f808aaf8-3fb6-4038-9eec-326b20433bd0/index.html",
    "title": "RAG in my mind",
    "section": "",
    "text": "RAG in my mind\nllm generate images for content llm generate tags & categories for content llm generate embedding for content\nllm generate query words llm generate query image/audio\nsystem perform full text search system perform vector search\nllm generate relevance or preference llm generate potential query for content system update relevance based on llm preference"
  },
  {
    "objectID": "posts/3ee64cfd-ff24-4957-9ee2-f181b092d62c/index.html",
    "href": "posts/3ee64cfd-ff24-4957-9ee2-f181b092d62c/index.html",
    "title": "QQ password",
    "section": "",
    "text": "QQ password\n1281727431 Bumper&Mountains"
  },
  {
    "objectID": "posts/f527b300-1e2b-48cc-aacd-f5bfc7f5b97f/index.html",
    "href": "posts/f527b300-1e2b-48cc-aacd-f5bfc7f5b97f/index.html",
    "title": "Pytorch OOM",
    "section": "",
    "text": "Pytorch OOM\nsshpass -p HFSPMFaTVPhfPzfPqAWmp7z5ewKm5xMG ssh -p 60164 root@i-1.gpushare.com"
  },
  {
    "objectID": "posts/1ede3982-c403-456d-8b9a-ede36dc9e5ab/index.html",
    "href": "posts/1ede3982-c403-456d-8b9a-ede36dc9e5ab/index.html",
    "title": "Python Media Automation",
    "section": "",
    "text": "Python Media Automation\nwe first see the world, get the observation and respond in the form of content. it is a feedback loop.\nto search components in videos, first take screenshots then do image search, then use the keywords to get the source video.\nbreakdown approach: granualize every step, showing all possibilities to get content created and then optimoze it using standards.\nfilter approach: establish some topics, create topic specific approaches to arrange the content, choose the best among all topics.\nare they compatible? are you sure it is modular, scalable and extensible?\nfor novices, they have few unpolished ideas and waiting to realize it using code. but it lacks the feedback loop and thus you are unable to change yourself according to the reaction. breakdown approach must be used to automate the optimization, and topic based approach is simple at first hand.\nto avoid copyright issues search for google.\ntopic based approach assues the public always have something in common and thus you only search specific things at first hand. they are easy to control, static and consistent. breakdown approach is where the evolution begins.\nlet’s assume our topic is about pets on weibo. pets have different kinds and the content creaters are different from each other. all we do is to download and upload. we get descriptions from our viewers, video play counts and various feedback. we improve the source by our feedback, searching for more untouched contents and more mixes like video/audio crossing.\nbreakdown approach is demostrated first-hand with our actor-critic model. we first view all possible posts from all sources, find what’s interesting and repost it to our target platform. this is likely to be cheating. we again choose our sources, our approach of modification based on feedback. topics are generated from the very first step.\nthe model of interests, which generates the topic, is the key breakdown approach. we have to eventually construct a breakdown approach to boost our searches in every aspect. feedback is one of those key features. we eventually have to view the content with the machine. suggest using the breakdown approach now.\nanatomy of the post:\nfirst thing it would be postable, according to our mandatory order. it would not be taken down or banned for a long time. banning detection is required and usually simple to test against.\nsecond it is most profitable. we only prefer those tasks which give the most output. occasionly we choose something fresh despite lower expectations.\nthird it would be resourceful. consistently pinning audience in a series of videos is undoubtably competitent. this can be reached by utilizing our creativity engine based on comments and imagination, realize the unrealized.\nhave not yet found anything systematic on giving the full detail of such automated content creation system. we only pick up those pieces. it is important to make the entire design flexible and create miniature tests to fabricate the system. like any other famous writer/director, you could only name it but not reproduce it.\nhands on the approach, no matter it is inspired by anyone or anything, it is time to begin, to complete the feedback loop.\nnot a pipe, but a loop.\nwe demonstrate the loop using fake data, then the real ones. maybe the initial topic is also meant to be fake data. the real world data is too stochastic for us to imagine. better construct something specific."
  },
  {
    "objectID": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#lisp-style-resumption-error-handling-semantics",
    "href": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#lisp-style-resumption-error-handling-semantics",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "lisp-style resumption error-handling semantics",
    "text": "lisp-style resumption error-handling semantics\npython for lisp programmers\npractical common lisp\narithmatic infix\ncommon lisp debugging\ncommon lisp related libraries\nslime\nportacle\ntalk on reddit"
  },
  {
    "objectID": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#ruby",
    "href": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#ruby",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "ruby",
    "text": "ruby\npry-rescue may not resume execution?"
  },
  {
    "objectID": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#java",
    "href": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#java",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "java",
    "text": "java\neclipse hot code swap fix\nhot code replace in vscode for java"
  },
  {
    "objectID": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#python",
    "href": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#python",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "python",
    "text": "python\nbytecode hack, pyhotswap\npython lisp-style exception as condition handling\ndump different level of reloading call history\nreload code blocks which are syntatically different, if black formatter fails after dedent then there shall be error\ndecide to reload extra parts of functions in the next run if selected\nload newly added functions, remove old functions, execute added lines, reload entire module and update namespace depending on condition\ncheck other programming language whether it jas similar capabilities\nvisit this thread of ruby in archive.org\nwallabyjs\neither bytecode or modify the source code"
  },
  {
    "objectID": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#bookmarks",
    "href": "posts/3755a2fb-f149-40d2-96b0-f77796b96c5a/index.html#bookmarks",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "bookmarks",
    "text": "bookmarks\nhttps://docs.python.org/3/library/code.html\nhttps://docs.python.org/3/library/cmd.html\nhttps://docs.python.org/3/library/threading.html#threading.settrace\nhttps://mail.python.org/archives/list/python-dev@python.org/thread/OGPO6KWHQGO47KOJKNEWNZS3LLMVXBEV/\nhttps://github.com/TomOnTime/timetravelpdb\nhttps://github.com/nfd/on_error_resume_next/blob/master/basic.py\nhttps://github.com/search?p=5&q=BEFORE_ASYNC_WITH&type=Code\nhttps://github.com/Martmists-GH/pyasm/blob/a306f23cbed13505687eb0ca86f010e5fe3101b5/asm/ops/py35.py\nhttps://github.com/Martmists-GH/pyasm\nhttps://github.com/kr1surb4n/copypaster_filedecks/blob/3f2ca44c4f984652585a1e7f1e589966e8867da6/filedecks_archive/python/library/dis/Python%20Bytecode%20Instructions/opcodeBEFOREASYNCWIT\nhttps://github.com/kholia/dedrop/blob/60da43889be89950cadbbb6b54489eb1841c70da/src/dedrop-ng/opcode_mapper.py\nhttps://github.com/brettlangdon/gython\nhttps://github.com/Exitialium/Github-Drive/blob/5284358a163c4ea25c63f4157d41af5f638950a2/deap/include/python3.9/opcode.h\nhttps://github.com/ajalt/fuckitpy\nhttps://code.lardcave.net/2020/12/29/1/\nhttps://github.com/asrp/python_terp/blob/master/test/buggy_ex.py\nhttps://github.com/HugoDelval/reversibleInterpreter\nhttps://github.com/topics/reversible-programming-language\nhttps://github.com/jndean/railway/wiki/Variables,-Data-and-Scope\nhttps://cn.bing.com/search?q=python+run+bytecode&qs=UT&pq=python+run+byteco&sc=1-17&cvid=79F89EEA4A564540BF79A8DBB63284CE&FORM=QBRE&sp=1\nhttps://opensource.com/article/18/4/introduction-python-bytecode\nhttp://www.aosabook.org/en/500L/a-python-interpreter-written-in-python.html\nhttps://github.com/nedbat/byterun\nhttps://unpyc.sourceforge.net/Opcodes.html\nhttps://docs.python.org/3/library/codeop.html\nhttps://docs.python.org/3/library/dis.html\nhttps://docs.python.org/3/library/dis.html\nhttps://docs.python.org/3/library/codeop.html\nhttps://blog.quarkslab.com/building-an-obfuscated-python-interpreter-we-need-more-opcodes.html\nhttps://github.com/fietensen/PyOpcodeAsm\nhttps://pypi.org/project/BytecodeAssembler/\nhttp://probablyprogramming.com/2008/04/18/ppya-python-assembler\nhttps://pypi.org/project/BytecodeAssembler/#description\nhttp://peak.telecommunity.com/DevCenter/BytecodeAssembler\nhttps://github.com/pib/papaya\nhttps://www.programcreek.com/python/?CodeExample=get+opcode\nhttps://unpyc.sourceforge.net/Opcodes.html\nhttps://www.synopsys.com/blogs/software-security/understanding-python-bytecode/\nhttps://github.com/neuroo/equip\nhttps://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/\nhttps://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/\nhttps://discuss.python.org/t/exec-with-return-keyword/19916/25\nhttps://cn.bing.com/search?q=interactive%20debugging%20python&qs=n&form=QBRE&=%25eManage%20Your%20Search%20History%25E&sp=-1&pq=interactive%20debugging%20&sc=3-22&sk=&cvid=30D653A233984DD685DE7CE79AD46318&ghsh=0&ghacc=0&ghpl=\nhttps://www.digitalocean.com/community/tutorials/how-to-debug-python-with-an-interactive-console\nhttps://nedbatchelder.com/blog/200509/interactive_debugging_in_python.html\nhttps://derpops.bike/python/computers/kubernetes/2017/10/26/interactive-debugging-python-kubernetes.html\nhttps://bytes.com/topic/python/answers/46053-resume-after-exception\nhttps://pytrace.com/\nhttps://github.com/gleb-sevruk/pycrunch-trace/issues\ncontextlib usage detail, to make customized “with” statements:\nfrom contextlib import AbstractContextManager\n\nclass suppress2(AbstractContextManager):\n    \"\"\"Context manager to suppress specified exceptions\n\n    After the exception is suppressed, execution proceeds with the next\n    statement following the with statement.\n\n         with suppress(FileNotFoundError):\n             os.remove(somefile)\n         # Execution still resumes here if the file was already removed\n    \"\"\"\n\n    def __init__(self, *exceptions):\n        self._exceptions = exceptions\n\n    def __enter__(self):\n        print(dir(self))\n        pass\n\n    def __exit__(self, exctype, excinst, exctb):\n        # Unlike isinstance and issubclass, CPython exception handling\n        # currently only looks at the concrete type hierarchy (ignoring\n        # the instance and subclass checking hooks). While Guido considers\n        # that a bug rather than a feature, it's a fairly hard one to fix\n        # due to various internal implementation details. suppress provides\n        # the simpler issubclass based semantics, rather than trying to\n        # exactly reproduce the limitations of the CPython interpreter.\n        #\n        # See http://bugs.python.org/issue12029 for more details\n        print(\"EXCTYPE\", exctype)\n        print(\"EXCINST\", excinst)\n        print(\"EXCTB\",exctb) # exception\n        print(dir(exctb))\n        breakpoint()\n        return exctype is not None and issubclass(exctype, self._exceptions)\npython grammar sugar: brackets https://pypi.org/project/brackets/ does that work in eval()?\nuse contextlib.suppress to replace try…except: pass might investigate source code of the suppress object.\nhttps://opensource.com/article/18/5/how-retrieve-source-code-python-functions\nto execute code grouped by lowest level of indentation, we can def those lines of code and pass the code by dill.source.getsource(functionName) and eval within given global/local variables.\nmy solution is down here, with concrete examples.\nhereby we recommend to insert a conditional return statement to ensure we will exit this buggy code at the best time. maybe we could put it into a dictionary somehow, tuples within string or something.\nimport dill\nfrom contextlib import suppress\nimport traceback\n\ndef skipException(func, debug_flag=False, breakpoint_flag=False):\n\n    def space_counter(line):\n        counter = 0\n        for x in line:\n            if x == \" \": counter+=1\n            else: break\n        return counter\n\n    def remove_extra_return(code):\n        while True:\n            if \"\\n\\n\" in code:\n                code = code.replace(\"\\n\\n\",\"\\n\")\n            else: break\n        return code\n    \n    def isEmptyLine(line):\n        emptyChars = [\"\\n\",\"\\t\",\"\\r\",\" \"]\n        length = len(line)\n        emptyCounts=0\n        for char in line:\n            if char in emptyChars: emptyCounts += 1\n        return emptyCounts == length\n    \n    def getCodeBlocks(lines):\n        mBlocks=[]\n        current_block = lines[0]\n        lines = lines+[\"\"]\n        keywords = [\" \", \"def\", \"async def\", \"with\", \"class\", \"@\"]\n        for line in lines[1:]:\n            if sum([line.startswith(keyword) for keyword in keywords]):\n                current_block+=\"\\n\"\n                current_block+=line\n            else:\n                mBlocks.append(current_block)\n                current_block = line\n        return mBlocks\n    \n    def getExtendedLines(splited_code):\n        splited_code = [x.rstrip() for x in splited_code]\n        splited_code = \"\\n\".join(splited_code).replace(\"\\\\\\n\",\"\")\n        splited_code = remove_extra_return(splited_code)\n        splited_code = splited_code.split(\"\\n\")\n        return splited_code\n    \n\n    def new_func(*args, **kwargs):\n        func_name = func.__name__\n        func_code = dill.source.getsource(func)\n        if debug_flag:\n            print(\"########## FUNCTION CODE #########\")\n            print(func_code) # do not use chained decorator since doing so will definitely fail everything?\n            print(\"########## FUNCTION CODE #########\")\n            print(\"########## FUNCTION #########\")\n        # print(func_code)\n        func_code = remove_extra_return(func_code)\n        splited_code = func_code.split(\"\\n\")\n        splited_code = getExtendedLines(splited_code)\n        # index 0: decorator\n        # index 1: function name\n        # no recursion support. may work inside another undecorated function.\n        try:\n            assert splited_code[0].strip().startswith(\"@skipException\")\n        except:\n            raise Exception(\"Do not nesting the use of @skipException decorator\")\n        function_definition = splited_code[1]\n        function_args=function_definition[:-1].replace(\"def {}\".format(func_name),\"\")\n        if debug_flag:\n            print(\"FUNCTION ARGS:\", function_args)\n        kwdefaults = func.__defaults__\n        pass_kwargs = {}\n\n        if \"=\" in function_args:\n            assert kwdefaults!=None\n            arg_remains = function_args.split(\"=\")[0]\n            kwarg_remains = function_args.replace(arg_remains,\"\")\n            kwarg_extra_names =[content.split(\",\")[-1].strip() for index, content in enumerate(kwarg_remains.split(\"=\")) if index%2 ==1]\n            mfunctionArgsPrimitive = arg_remains.replace(\"(\",\"\").split(\",\")\n            kwarg_names = [mfunctionArgsPrimitive[-1].strip()]+kwarg_extra_names\n            mfunctionArgs = mfunctionArgsPrimitive[:-1]\n            if debug_flag:\n                print(\"PASSED KEYWORD ARGS:\", kwargs)\n                print(\"KWARG NAMES:\", kwarg_names)\n            for key, value in zip(kwarg_names, kwdefaults):\n                pass_kwargs.update({key: value})\n            for key in kwargs.keys():\n                assert key in kwarg_names\n                pass_kwargs[key] = kwargs[key]\n        else:\n            assert kwdefaults == None\n            mfunctionArgs = function_args.replace(\"(\",\"\").replace(\")\",\"\").split(\",\")\n        mfunctionArgs = [x.strip() for x in mfunctionArgs]\n        mfunctionArgs = [x for x in mfunctionArgs if not isEmptyLine(x)]\n        if debug_flag:\n            print(\"POSITIONAL ARGS:\",mfunctionArgs)\n        assert len(args) == len(mfunctionArgs)\n\n        for key, value in zip(mfunctionArgs, args):\n            exec(\"{} = {}\".format(key, value))\n        if kwdefaults is not None:\n            for key, value in pass_kwargs.items():\n                exec(\"{} = {}\".format(key, value))\n        actualCode = splited_code[2:]\n        actualCode = [x for x in actualCode if not isEmptyLine(x)]\n        minIndent = min([space_counter(line) for line in actualCode])\n        # split the code into different sections.\n        if debug_flag:\n            print(minIndent)\n        newLines = [line[minIndent:] for line in actualCode]\n        codeBlocks = getCodeBlocks(newLines)\n        for block in codeBlocks:\n            if debug_flag:\n                print(\"##########CODEBLOCK##########\")\n                print(block)\n                print(\"##########CODEBLOCK##########\")\n            if not debug_flag:\n                with suppress(Exception):\n                    exec(block)\n            else:\n                try:\n                    exec(block)\n                except:\n                    traceback.print_exc()\n                    if breakpoint_flag: breakpoint()\n        if debug_flag:\n            print(\"########## FUNCTION #########\")\n\n    return new_func\n\ndef skipExceptionVerbose(func): return skipException(func, debug_flag=True)\ndef skipExceptionBreakpoint(func): return skipException(func, breakpoint_flag=True)\ndef skipExceptionDebug(func): return skipException(func, breakpoint_flag=True, debug_flag=True)\n\n@skipException\ndef someOtherShit():\n    amd=[1,2,3]\n    amd[4]\n    print(\"shit happens\")\n\ndef anotherShit():\n    @skipException\n    def mySuperFunction(d,e,f):\n        someOtherShit()\n        print(\"YOU WIN\")\n        a = [1,2,3]\n        a[3] # will not continue execute the code down there\n        print(\"YOU WIN\")\n        a[4]\n        print(\"INSIDE FUNCTION\",d,e,f)\n        print(\"YOU WIN\")\n    mySuperFunction(1,2,3)\n    # print(dir(mySuperFunction))\n\nanotherShit()\n\n# breakpoint()"
  },
  {
    "objectID": "posts/744ec0f5-e528-4e4d-bc07-779081e3d12d/index.html",
    "href": "posts/744ec0f5-e528-4e4d-bc07-779081e3d12d/index.html",
    "title": "Public APIs, GIF Websites Funny Video Sources",
    "section": "",
    "text": "Public APIs, GIF Websites Funny Video Sources\nrapidapi do not use this\nimgur funny gifs\nhttps://giphy.com\nvideo dataset: youtube8m by google\ngiphy gif apis: https://github.com/austinkelleher/giphy-api https://github.com/Giphy/giphy-js https://github.com/sogamoso/giphy https://github.com/Giphy/GiphyAPI https://developers.giphy.com/branch/master/docs/ https://github.com/shaunduncan/giphypop\nenternainment apis and more, search for free apis/public apis: https://apipheny.io/free-api/#entertainment-apis\nfind things from public apis: https://github.com/public-apis/public-apis\ndownload video from ifunny.co https://github.com/vidovichb/iFunny_Downloader\nmemes app from reddit https://github.com/victorqribeiro/memes\nml algorithm to download funny music videos https://github.com/dfarren/funny_music_videos\ncreate funny videos https://github.com/PhotoBoxPW/VideoBox\nsearch gifs from bukk.it https://github.com/olivierlacan/gifhub https://bukk.it\n搞笑视频去水印 https://github.com/5ime/video_spider\n搞笑图片 搞笑音频抓取 https://github.com/zhaofucheng1129/KuailewoAppServer\n搞笑视频 https://github.com/ecitlm/Node-SpliderApi\n搞笑视频 哔哩哔哩封面图获取 https://github.com/iqiqiya/iqiqiya-API"
  },
  {
    "objectID": "posts/1f616980-4e93-415f-b4e2-8e7817b1c459/index.html",
    "href": "posts/1f616980-4e93-415f-b4e2-8e7817b1c459/index.html",
    "title": "Popular Video Sites",
    "section": "",
    "text": "Popular Video Sites\ntwitch https://netflix.com https://www.ted.com https://www.youtube.com https://www.instagram.com https://twitter.com https://www.pornhub.com https://www.bilibili.com https://www.douyu.com https://www.huya.com https://www.iqiyi.com https://www.youku.com https://weibo.com/tv https://krcom.cn https://tv.sohu.com https://v.qq.com NetEase Public Class QQ Music-MV"
  },
  {
    "objectID": "posts/c06097e8-6358-44bb-b507-8d16773f2bef/index.html",
    "href": "posts/c06097e8-6358-44bb-b507-8d16773f2bef/index.html",
    "title": "Optical Flow",
    "section": "",
    "text": "Optical Flow\nflownet nvidia\nnvidia optical flow sdk supports all turing gpus (like gtx1660) and above except for gtx1650(tu117).\nmmflow from openmmlab: https://mmflow.readthedocs.io/en/latest/"
  },
  {
    "objectID": "posts/8e71795e-b7ae-40f6-b418-f363f21677fe/index.html",
    "href": "posts/8e71795e-b7ae-40f6-b418-f363f21677fe/index.html",
    "title": "OCR tools",
    "section": "",
    "text": "OCR tools\ntesseract\ntesseract.js with 100+ language support, still need to predefine language type\nchineseocr, with arbitrary text direction and rubust handwriting recognization support\nlightweight chinese ocr model\nefficient ocr python lib based on tr\npaddleocr\neasyocr\npearocr client side webpage/browser based ocr"
  },
  {
    "objectID": "posts/7e074ef5-8ede-4575-a708-fa72d1d34073/index.html",
    "href": "posts/7e074ef5-8ede-4575-a708-fa72d1d34073/index.html",
    "title": "Neuraldiff: discriminate actor and objects in video",
    "section": "",
    "text": "Neuraldiff: discriminate actor and objects in video\nNeuraldiff: https://github.com/dichotomies/NeuralDiff?ref=pythonawesome.com https://pythonawesome.com/official-pytorch-implementation-of-neuraldiff-segmenting-3d-objects-that-move-in-egocentric-videos/"
  },
  {
    "objectID": "posts/8a77af2d-2c64-4175-ba8b-b555614c189f/index.html",
    "href": "posts/8a77af2d-2c64-4175-ba8b-b555614c189f/index.html",
    "title": "Neo4j learning notes",
    "section": "",
    "text": "Neo4j learning notes\nneo4j desktop provide free multi graph databases support, enable you to create and use multiple graph datases at once\nto query undirected relationships: match () – (p) return p\ncreate fulltext index create fulltext index lucene for (n:Person) on each [n.title, n.description] call db.index.fulltext.queryNodes(“titlesAndDescriptions”, “Full Metal Jacket”) yield node, score return node, score\ncalculate customer rating cosine similarity for recommendation: https://neo4j.com/graphgists/northwind-recommendation-engine match (c1:customer)-[r1:rated]-(:product)-[r2:rated]-(c2:customer) with sum(r1.scorer2.score) as dot_product, sqrt(reduce(x=0, a in r1.score | x+a^2)) as r1_length, sqrt(reduce(y=0, b in r2.score | y+b^2)) as r2_length merge (c1)-[s:similarity}]-(c2) set s += {score:dot_product/(r1_lengthr2_length)\nuse collect to turn maps into lists: match (p) return collect(p.names)\nexist subquery: match (n:Person) where exists { match (n) –(t:Tech) where size((t)-[:likes]-(:Person)) &gt;2 } return n.name\nlist comprehension: return [x in range(0,10) where x%3 = 0| x/2] as list return [x in range(0,10) where not x in range(4,10) |x ] as list\nto use conditional matches or regular expressions: match () – (p) where p.name in [“helen”] or p.name =~ “.chinese.” return p\ncreate index on properties: create index for (n:Category) on (n.categoryName)\nasterisks:\nload csv: load csv with headers from “http://localhost/person.csv” as line call {with line merge (n:person {id: toInteger(line.id)}) set n.name = line.name } in transactions of 2 rows\ncount nodes: match (n) return count(n)\nmatch relationship patterns: match (n) -[:friend|hater*3]-&gt;(p) return p limit 20\nnode can have multiple labels, while relationship can only have one type, both specified after the colon.\nsimple case expression: match(n) return case n.eyes when “blue” then 1 when “brown” then 2 else 3 end as result\ngeneric case expression match (n) return case when n.eyes = “blue” then 1 when n.age &gt; 40 then 2 else 3 // if without else then return null end as result\ninequality symbol: &lt;&gt;\nmutating updating node properties: match(n) set n+={name:“helen”} // if using = the properties will be totally replaced instead of update. return n.name\nmerge can only ensure the existance of one node or pattern at a time, no comma\nplus can concatenate strings\ntenporal dataformat can be used as numbers to compute.\nMap operators . for static value access by key, [] for dynamic value access by key\nList operators + for concatenation, IN to check existence of an element in a list, [] for accessing element(s) dynamically\nrecommendation steps: first find targets by meta relatonships next sort recommendation by frequency, ratings or occurance third filter items by topics or properties"
  },
  {
    "objectID": "posts/533f66d5-c03d-4978-992b-c37f269b5a3d/index.html",
    "href": "posts/533f66d5-c03d-4978-992b-c37f269b5a3d/index.html",
    "title": "Nautilus Hangs When Searching",
    "section": "",
    "text": "Nautilus Hangs When Searching\ndelete ~/.cache/tracker"
  },
  {
    "objectID": "posts/0e4da645-5f70-4701-9007-9e1701bd109a/index.html",
    "href": "posts/0e4da645-5f70-4701-9007-9e1701bd109a/index.html",
    "title": "NLP Packages",
    "section": "",
    "text": "NLP NLG Packages\nquestgen.ai: generate question from essay, imitate interaction 增加观众互动性 生成问题 question answering question generator\n甲骨 jiagu nlp包 provided by ownthink: https://github.com/ownthink/Jiagu - 中文分词 - 词性标注 - 命名实体识别 - 知识图谱关系抽取 - 关键词提取 - 文本摘要 - 新词发现 - 情感分析 - 文本聚类\nhaystack: nlp framework neural search neural text search semantic search summarization question answering\nsnownlp: chinese segmentation, pinyin, sentiment analysis (情感分析), word tags, keywords, summary, tf-idf similarity, classification, 繁体转简体"
  },
  {
    "objectID": "posts/42fcf4f3-7ed6-4e7d-a04d-a6b813e37069/index.html",
    "href": "posts/42fcf4f3-7ed6-4e7d-a04d-a6b813e37069/index.html",
    "title": "MySQL Cheatsheet",
    "section": "",
    "text": "MySQL Cheatsheet\nMySQL Reference Card Version: 0.1 Author: ProgM4c\nAttribute Types\nNumbers Name Coded on Name Coded on TINYINT 1 byte FLOAT(W, D) 4 bytes SMALLINT 2 bytes DOUBLE(W, D) 8 bytes MEDIUMINT 3 bytes W: width(number of digits with the ‘.’) D: number of decimals INT 4 bytes\nBIGINT 8 bytes\nParameters: • UNSIGNED • ZEROFILL\nCoded on: • SIGNED : • UNSIGNED:\nStrings (between ’ ’) Name Size CHAR(M) String with fixed size, 1 &lt;= M &lt;= 255 VARCHAR(M) String with variable size, 1 &lt;= M &lt;= 255 TINYTEXT Max length = 255 TEXT Max length = 65535 MEDIUMTEXT Max length = 16777215 LONGTEXT Max length = 4294967295 DECIMAL(M, D) Simulate a floating point number in a string format\nDate and Time Name Format DATE AAAA-MM-JJ DATETIME AAAA-MM-JJ HH:MM:SS TIMESTAMP AAAAMMJJHHMMSS TIMESTAMP(M) First M characters of a TIMESTAMP TIME HH:MM:SS YEAR AAAA\nENUM: take one value in the defined list (can be NULL) syntax: attr_name ENUM(‘value1’, ‘value2’, …) {NULL | NOT NULL}\nDatabase queries\ncreate a database CREATE DATABASE [IF NOT EXISTS] ;\ndelete a database DROP DATABSE [IF EXISTS] ;\nrename a database ALTER DATABASE  RENAME ;\nlist databases SHOW DATABASES;\nselect a database USE ;\nTable queries\nshow a table SHOW TABLES;\nrename a table ALTER TABLE  RENAME ;\ndescribe a table DESCRIBE\n\n;delete a table DROP TABLE ;type of constraints • NOT NULL • UNIQUE • PRIMARY KEY = NOT NULL + UNIQUE • FOREIGN KEY • CHECK • DEFAULT • AUTO_INCREMENTcreate a table CREATE TABLE  (  (size) ,  (size) , … PRIMARY KEY() );add / delete a constraints ALTER TABLE  ADD CONSTRAINT  TYPEOFCONSTRAINT (, …) ALTER TABLE  DROP [CONSTRAINT  | TYPEOFCONSTRAINT ];Modify table structureadd / delete attribute ALTER TABLE  ADD   [FIRST|AFTER ]; ALTER TABLE  DROP  ;add / delete default value to an column ALTER TABLE  ALTER  {SET DEFAULT |DROP DEFAULT};change definition of an attribute without/with renaming it ALTER TABLE  MODIFY  ; ALTER TABLE  CHANGE   ; Inserting data INSERT INTO (, , …) VALUES (, , …);Modifying data UPDATE  SET  = ,  = , … WHERE ;Deleting data DELETE FROM  WHERE ;Retrieving data Select statement SELECT [ DISTINCT ] attributs [ INTO OUTFILE fichier ] [ FROM relation ] [ WHERE condition ] [ GROUP BY attributs [ ASC | DESC ] ] [ HAVING condition ] [ ORDER BY attributs ] [ LIMIT [a,] b ]\noperators in a where clause\nEqual &lt;&gt; Not equal. Note: In some versions of SQL this operator may be written as != &gt; Greater than &lt; Less than &gt;= Greater than or equal &lt;= Less than or equal BETWEEN Between an inclusive range LIKE Search for a pattern (‘%’ any sequence of characters ’_’ any character) [NOT] IN To specify multiple possible values for a column IS [NOT] NULL To check if the value of a column is NULL or not AND OR NOT Filter records based on more than once condition\nSub-requests SELECT * FROM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWHERE prix &gt; (SELECT MIN(prix) FROM tab2) SELECT * FROM\n\n\nWHERE nom NOT IN (SELECT nom FROM tab2) SELECT * FROM\n\n\nWHERE prix &gt; ALL (SELECT prix FROM tab2) (sup. à ttes les valeurs) SELECT * FROM\n\nWHERE prix &gt; ANY (SELECT prix FROM tab2) (sup. à au moins 1)\nSQL aliases on column / table SELECT  AS  FROM\n\n\n\n(alias a result) SELECT  FROM\n\nAS  (alias a table name)SQL functions AVG() - (moyenne) COUNT() - (nombre d’élément) MAX() - (maximum) MIN() - (minimum) SUM() - (somme)UCASE() LCASE() LEN() NOW() FORMAT()"
  },
  {
    "objectID": "posts/cd17ff38-347f-43a8-b9e1-95183a7fd4d7/index.html",
    "href": "posts/cd17ff38-347f-43a8-b9e1-95183a7fd4d7/index.html",
    "title": "Music to video generator GAN",
    "section": "",
    "text": "Text to Video/Music to video generator GAN\nhttps://www.youtube.com/watch?v=V8MlYa_yhF0 https://netease-gameai.github.io/ChoreoMaster/Paper.pdf 该系统可依据音乐风格生成爵士、二次元、街舞等不同类型的舞蹈动画。给定一段音乐，舞蹈演员可以自动生成高质量的舞蹈动作序列以伴随输入音乐的风格、节奏和结构。为了实现这一目标，我们引入了一种新的面向编舞的编舞音乐嵌入框架，它成功地构建了一个统一的舞蹈音乐嵌入空间音乐和舞蹈短语之间的风格和节奏关系。\nhttps://www.youtube.com/watch?v=VrVsAcgFK_4 该方法提出了一个基于cross-modal transformer的架构模型和一个新的3D舞蹈数据集，该数据集包含了根据真实舞者重建的3D运动 项目地址: https://google.github.io/aichoreographer 数据集地址: https://google.github.io/aistplusplus_dataset/ 欢迎点赞、评论、分享、收藏！\nvideo generation using music based on bigGAN: https://github.com/Remideza/MichelAI/\nbigGAN Large Scale GAN Training for High Fidelity Natural Image Synthesis: https://github.com/ajbrock/BigGAN-PyTorch\ndance video generation self-supervised: https://github.com/xrenaa/Music-Dance-Video-Synthesis\nshow me what and tell me how based on openai clip by snap research with pretrained models, able to generate arbitrary video based on text description: https://github.com/snap-research/MMVID\ntext to video generator based on vqgan and clip with primitive colab notebooks by kapwing the online video editor: https://www.kapwing.com/ai-video-generator"
  },
  {
    "objectID": "posts/3d62677b-6e0b-4cf4-9777-2af39e8be164/index.html",
    "href": "posts/3d62677b-6e0b-4cf4-9777-2af39e8be164/index.html",
    "title": "Movie Scraping 3",
    "section": "",
    "text": "Movie Scraping 3\nhttps://www.dianyinggou.com\nwith douban link"
  },
  {
    "objectID": "posts/7363e43f-12bc-4e03-a060-6ad05ba58e34/index.html",
    "href": "posts/7363e43f-12bc-4e03-a060-6ad05ba58e34/index.html",
    "title": "Movie Bangume script finder",
    "section": "",
    "text": "Movie Bangume script finder\nhttps://wk.baidu.com/view/329daafdbaf3f90f76c66137ee06eff9aef84994 http://www.360doc.cn/mip/982055971.html\nanime character database contains dialogs: https://www.animecharactersdatabase.com/episodetranscript.php?pid=1915&epid=1\nquodb the movie quotes database: https://www.quodb.com\nscifi movie script example: http://www.scifiscripts.com/cartoon/howls_moving_castle.html\njapanese bangume script: http://akita.cool.ne.jp/hikoseki/script/laputascript_v210all_n.html\nMay not work: https://jref.com/threads/where-in-internet-could-i-find-anime-dialogs-scripts-in-japanese.43408/\nsuggest you find this in zhihu. https://dialogue.moe https://zhuanlan.zhihu.com/p/389873370 https://zhuanlan.zhihu.com/p/450050772\nfind movie quotes: 33.agilestudio.cn https://zhaotaici.cn/mindex.html\nBangume info wiki: https://bgm.tv/subject/1982/characters"
  },
  {
    "objectID": "posts/2047da29-b8ec-4e8b-bca3-8703cd154b86/index.html",
    "href": "posts/2047da29-b8ec-4e8b-bca3-8703cd154b86/index.html",
    "title": "Model Zoo",
    "section": "",
    "text": "Model Zoo\nfind things in colab, kaggle, aistudio, bilibili, youtube.\nsee in huggingface tasks to find task-specific models, also huggingface spaces for demo on models\nmodelscope by alibaba supports tensorflow and pytorch\nmindspore model zoo\nmindspore hub\nintel model zoo\nrun models from intel model zoo in docker container, like recommendation\nopenvino model zoo\n百度总结的 比较全面的深度学习应用 deeplearning applications\njina hub\n阿里巴巴模型库 具有许多适用于商业 自媒体的模型供选择\nhuggingface\n苹果官方CoreML模型库\nCoreML第三方模型库\npaddle模型库 paddlehub\npytorch模型库\nTensorFlow模型库\ngraphcore model zoo for IPU"
  },
  {
    "objectID": "posts/a6f748c4-d3c4-4f8a-ae90-76b7f086a199/index.html",
    "href": "posts/a6f748c4-d3c4-4f8a-ae90-76b7f086a199/index.html",
    "title": "Minor changes will defeat deduplicate algorithm while maintain overall fluency",
    "section": "",
    "text": "Minor changes will defeat deduplicate algorithm while maintain overall fluency\nI found several evation methods, like paraphraser, random character swapper for text, and video blur, mirror to post the same video again. I guess it is essential not to let any part of the content look like the original one."
  },
  {
    "objectID": "posts/a5e3948e-e02c-4395-b9c2-516b26667349/index.html",
    "href": "posts/a5e3948e-e02c-4395-b9c2-516b26667349/index.html",
    "title": "Medium Subscription Bypass",
    "section": "",
    "text": "Medium Subscription Bypass\nthis site only unblock “restricted” articles. it does not offer “trending” “user homepage” “most read” “recommendation” things which you can get from official medium website.\nmap *.medium.com/[URL] to scribe.rip/[URL]\nor try to host scribe.rip yourself.\nsource code hosted on sourcehunt.\nalternative scribe instances seems all blocked (in mainland)"
  },
  {
    "objectID": "posts/2bf58add-172e-493c-9a1c-394f4a5b5bc4/index.html",
    "href": "posts/2bf58add-172e-493c-9a1c-394f4a5b5bc4/index.html",
    "title": "Markdown to PDF",
    "section": "",
    "text": "Markdown to PDF\nGist on using python3 and PhantomJS\nnpm package: markdown-pdf"
  },
  {
    "objectID": "posts/8001fc79-5287-4547-84ef-12417dc24d61/index.html",
    "href": "posts/8001fc79-5287-4547-84ef-12417dc24d61/index.html",
    "title": "MacOS mount ntfs volumes",
    "section": "",
    "text": "MacOS mount ntfs volumes\nmacos mount ntfs read-only by default.\ncode from mounty.app\nmounty is somehow not working so manual remount is needed.\none needs to click the remount button to mount it again under /Users/jamesbrown/.mounty/Toshiba3000\nsudo umount /Volumes/Toshiba3000\nsudo mkdir /Volumes/Toshiba3000; sudo mount -t ntfs -o rw,auto,nobrowse /dev/&lt;diskIdentifier&gt; /Volumes/Toshiba3000"
  },
  {
    "objectID": "posts/50b07029-5d55-47cb-86c7-f3bff567899b/index.html#the-fix",
    "href": "posts/50b07029-5d55-47cb-86c7-f3bff567899b/index.html#the-fix",
    "title": "MacOS locate fix and alternative",
    "section": "the fix",
    "text": "the fix\nto enable the service:\nsudo launchctl load -w /System/Library/LaunchDaemons/com.apple.locate.plist\nto update locate db:\nsudo /usr/libexec/locate.updatedb\nor, more conveniently:\nsudo ln -s /usr/libexec/locate.updatedb /usr/local/sbin/updatedb\nsudo updatedb"
  },
  {
    "objectID": "posts/50b07029-5d55-47cb-86c7-f3bff567899b/index.html#alternative",
    "href": "posts/50b07029-5d55-47cb-86c7-f3bff567899b/index.html#alternative",
    "title": "MacOS locate fix and alternative",
    "section": "alternative",
    "text": "alternative\nuse mdfind"
  },
  {
    "objectID": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#interactive-interfaces",
    "href": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#interactive-interfaces",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "interactive interfaces",
    "text": "interactive interfaces\n\ngui\ncustom tkinter\n\n\ncli\nrich\ntextual"
  },
  {
    "objectID": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#related-infos",
    "href": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#related-infos",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "related infos",
    "text": "related infos\nthe art of commandline\nawesome jq"
  },
  {
    "objectID": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#interactive-tools",
    "href": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#interactive-tools",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "interactive tools",
    "text": "interactive tools\n\nweb based tools\nxpath tester for html\nexplainshell\nlivegrep\n\n\ncli tools\nijq interactive jq\njiq\n[percol](https://github.com/mooz/percol] supports pinyin\nugrep use ugrep -Q for interactive tui"
  },
  {
    "objectID": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#coding",
    "href": "posts/4097e105-e405-423f-9bb5-1b1b91dff6e8/index.html#coding",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "coding",
    "text": "coding\npython design patterns"
  },
  {
    "objectID": "posts/00adc502-f460-4777-b9d9-b787078e3564/index.html",
    "href": "posts/00adc502-f460-4777-b9d9-b787078e3564/index.html",
    "title": "Linux restore window sessions",
    "section": "",
    "text": "Linux restore window sessions\nto relaunch app in given workspace\ntools: wmctrl devilspie launch_on_workspace\nreferences: https://unix.stackexchange.com/questions/27050/how-to-start-an-application-on-a-different-workspace https://askubuntu.com/questions/89946/open-application-in-specific-workspace\nnpm install -g linux-window-session-manager restore session manually\ndconf-editor org.gnome.gnome-session auto-save-session -&gt; on"
  },
  {
    "objectID": "posts/c0abb7a5-3360-4aab-a7de-d7de4d2331ef/index.html",
    "href": "posts/c0abb7a5-3360-4aab-a7de-d7de4d2331ef/index.html",
    "title": "Library System",
    "section": "",
    "text": "Library System\nhttps://blog.csdn.net/cnmlgbnbcs/article/details/110643393?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164327697216780255279283%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%25\nwith database. without specific data.\nwith entity-relation diagram\n3302162875@qq.com"
  },
  {
    "objectID": "posts/95028b76-d9c5-4bf6-9c2d-e58f24048df5/index.html",
    "href": "posts/95028b76-d9c5-4bf6-9c2d-e58f24048df5/index.html",
    "title": "Korean Shop Boosting",
    "section": "",
    "text": "Korean Shop Boosting\nID 密码 ajh598511 Hgwcom5315 老大 guang37630 Asdasd123 我的 namyeong5315 as-531511\ninkciss111 as-53511\nVPN网站 http://kpanda.net/download.siso\nID: wooristm55 密码：as531511\n商品 https://smartstore.naver.com/sexyqueen/products/5306123433"
  },
  {
    "objectID": "posts/83656be3-ef58-4b03-9fb1-471519beb7f0/index.html",
    "href": "posts/83656be3-ef58-4b03-9fb1-471519beb7f0/index.html",
    "title": "Kafka Data Query",
    "section": "",
    "text": "Kafka Data Query\n2056500129@qq.com\n大数据存储综合实验\nConnection:\nEasyConnect\nhttps://newvpn.cumt.edu.cn\n08192963:186880\nVM:\nhttp://192.168.46.253:8080/training/\n08192963:888888\n下载高速公路ETC入深圳数据， 数据量:178396条\nhttps://opendata.sz.gov.cn/data/dataSet/toDataDetails/29200_00403621\n数据样例:\n要求\n(1)每秒产生50+条数据，可以采用网络压力测试工具产生多点并发的高速数据流 https://blog.csdn.net/moonpure/article/details/72674374 ，例如JMeter\n(2)利用Kafka对高速数据进行缓存\n(3)利用HBase或者MyCat+Mysql对数据进行存储。\n(4)如果采用MyCat+Mysql方式存储数据，需要设计业务逻辑对数据进行分片，并对全局数据进行查询和统计\n(5)如果采用HBase方式存储数据，需要设计业务逻辑对rowkey进行设计，并对数据进行“key-value”查询。\n(6)对两种方式查询或者统计的结果进行可视化展示，要求每分钟一次对结果进行刷新。\nReport Template:\n7.实验目标和实验环境\n8.实验内容，\n9.实验步骤和结果。\n.10.结论与讨论。\nPython Kafka\nhttps://blog.csdn.net/weixin_35688430/article/details/111292744\nThrift Hbase\nhttps://blog.csdn.net/dutsoft/article/details/60328341\nPython Hbase\nhttps://www.jianshu.com/p/58b79bf5e9d4\nTerminal Visulization\nhttps://stackoverflow.com/questions/37288421/how-to-plot-a-chart-in-the-terminal\nhttps://pythonawesome.com/a-python-file-with-some-tools-for-visualizing-machine-learning-in-the-terminal/"
  },
  {
    "objectID": "posts/e839679a-f1ba-4337-9a93-fb34a0ebf3b9/index.html",
    "href": "posts/e839679a-f1ba-4337-9a93-fb34a0ebf3b9/index.html",
    "title": "Jina: Neural Search Engine for Images, Videos, Audios",
    "section": "",
    "text": "Jina: Neural Search Engine for Images, Videos, Audios\nopenclip\nhaystack\ntutorial: build QA pipeline with no dependencies with haystack\ntowhee\nmilvus\nvisit jina hub to get multiple embedding models and workflows\njina import video/image/text\nfinetuner: text to image search via clip\ndatawhale provides tutorials on machine learning, also provide book materials, topics are: numpy, matplotlib, pandas,\nvced: holy gift from datawhale able to edit video by text, video auto editor, cutter VCED 可以通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑。该项目基于跨模态搜索与向量检索技术搭建，通过前后端分离的模式，帮助你快速的接触新一代搜索技术。\njina: https://github.com/jina-ai/jina/\ndocumentation: https://docs.jina.ai\nquick demos:\ndress Fashion image search: jina hello fashion\nrobot QA chatbot: pip install \"jina[demo]\" && jina hello chatbot\nnewspaper Multimodal search: pip install \"jina[demo]\" && jina hello multimodal\nfork_and_knife Fork the source of a demo to your folder: jina hello fork fashion ../my-proj/\nCreate a new Jina project: jina new hello-jina\nai video metadata generation:"
  },
  {
    "objectID": "posts/33e42e5f-807c-45ad-80d4-828ff1abf21a/index.html",
    "href": "posts/33e42e5f-807c-45ad-80d4-828ff1abf21a/index.html",
    "title": "Issues while developing pyjom",
    "section": "",
    "text": "Issues while developing pyjom\nfix requests timeout problem.\nenable bilibili chats, video recommendation, dynamics\nenable weibo\nvideo feedback, monitor viral trends\nimprove chatbot by adding chatterbot, bm25, search engine, picture search engine\nyou may use this to fully utilize data from baidu shitu:\nhttps://github.com/Augu1sto/Rubindemo/blob/0ffe52af74643db8d8bfae048ee256824836e277/src/main/java/com/rubin/demo/Utils/BaiduSerchImgApi-master/functions.py\nhttps://github.com/chenguanyou/BaiduSerchImgApi\nhttps://github.com/chenguanyou/360ImageSearch\nhttps://github.com/chenguanyou/BaiduTextApi\nshitu.baidu.com\nhttps://graph.baidu.com/pcpage/index?tpl_from=pc (the entry page)\ngraph.baidu.com/s (where you collect data, recognize identities: script -&gt; window.cardData (list) -&gt; “tplData” -&gt; “pano” “baike” shits … with title “百度识图搜索结果”)\ngraph.baidu.com/ajax/pcsimi (get similar images, sources)\nhttps://miao.baidu.com/abdr (UNKNOWN)\nclasses:\ngraph-guess-word\ngraph-baike-text\ngraph-baike-desc -&gt; span"
  },
  {
    "objectID": "posts/02b3f07d-0249-4101-a726-6b9f02cd9b66/index.html",
    "href": "posts/02b3f07d-0249-4101-a726-6b9f02cd9b66/index.html",
    "title": "Install VSCode Extensions by ID",
    "section": "",
    "text": "Install VSCode Extensions by ID\n@id:medialang.vscode-theme-medialang-seti ＠id:medialang.medialang-highlighter"
  },
  {
    "objectID": "posts/6a8a88b2-2bad-454e-9ad3-eff4c4503eb1/index.html",
    "href": "posts/6a8a88b2-2bad-454e-9ad3-eff4c4503eb1/index.html",
    "title": "Image classification, cloth Classification",
    "section": "",
    "text": "Image classification, cloth Classification\nvit-pytorch state of the art image classifier with multiple attention heads\nfeed forward neural network"
  },
  {
    "objectID": "posts/0820b29a-4d9e-42c5-abef-dd5f2441bfce/index.html",
    "href": "posts/0820b29a-4d9e-42c5-abef-dd5f2441bfce/index.html",
    "title": "IOS airtest control windows",
    "section": "",
    "text": "IOS airtest control windows\nneed macos to compile ipa need jailbreak\niOS Tagent https://github.com/alibaba/taobao-iphone-device\napowermirror"
  },
  {
    "objectID": "posts/64c0b5eb-8789-4d9b-ad81-0db7627c2bdf/index.html",
    "href": "posts/64c0b5eb-8789-4d9b-ad81-0db7627c2bdf/index.html",
    "title": "IM MITM 聊天软件MITM",
    "section": "",
    "text": "IM MITM 聊天软件 MITM\nbetter do this in virtual enviorment without using any real world platform, just your own IM enviorment like a self-hosted IRC or something.\nis there any existing solution like telegram-mitm or twitter mitm?\nlua twitter automation, found on luarocks: https://github.com/leafo/lua-twitter\nscraper of tumblr, pinterest, youtube, reddit using api: https://github.com/ScriptSmith/socialreaper\nyoutube search and youtube comment scraper https://github.com/alexmercerind/youtube-search-python https://github.com/egbertbouman/youtube-comment-downloader\nyoutube, youtube transcribe and youtube music api https://github.com/srcecde/python-youtube-api https://github.com/sigma67/ytmusicapi https://github.com/jdepoix/youtube-transcript-api https://github.com/youtube/api-samples\nreddit scraper and analyzer https://github.com/casperbh96/Web-Scraping-Reddit https://github.com/umitkaanusta/reddit-detective\nreddit api https://github.com/praw-dev/praw\ntumblr api https://github.com/tumblr/pytumblr\ntumblr scraper https://github.com/henan715/tumblrScrapy\ndiscord bot api: https://github.com/discordjs/discord.js\ntwitter api https://github.com/python-twitter-tools/twitter\ntwitter scraper https://github.com/bisguzar/twitter-scraper\nfacebook api: https://github.com/Schmavery/facebook-chat-api\nfacebook scraper: https://github.com/kevinzg/facebook-scraper\ninstagram api: https://github.com/facebookarchive/python-instagram\ninstagram scraper: https://github.com/huaying/instagram-crawler\ntopic analysis among recent frequent conversations\nprocedures: 1.add two friends (active) and bridge them 2.intercept them, filter insecure data like screenshots, identities and explicit contents, and analyze needs (probably with your generated response)? 3.send intentional Ads and fix the conversation in three sentences."
  },
  {
    "objectID": "posts/7f5af5dc-70ea-4247-98f5-193da29e2e1d/index.html",
    "href": "posts/7f5af5dc-70ea-4247-98f5-193da29e2e1d/index.html",
    "title": "How to fix OpenCL platform not found issue on android",
    "section": "",
    "text": "How to fix OpenCL platform not found issue on android\nTo run llama.cpp on Oneplus Ace2V, you need an extra step:\nexport LD_LIBRARY_PATH=/vendor/lib64:/vendor/lib64/mt6983:/vendor/lib64/egl/mt6983"
  },
  {
    "objectID": "posts/3a4c0337-9cc0-4778-b9c4-0f08cf3c9d51/index.html#code-refactoring-tools",
    "href": "posts/3a4c0337-9cc0-4778-b9c4-0f08cf3c9d51/index.html#code-refactoring-tools",
    "title": "Hot Reloading, Exception Capture",
    "section": "code refactoring tools",
    "text": "code refactoring tools"
  },
  {
    "objectID": "posts/3a4c0337-9cc0-4778-b9c4-0f08cf3c9d51/index.html#hot-reloading-and-exception-capture-tools",
    "href": "posts/3a4c0337-9cc0-4778-b9c4-0f08cf3c9d51/index.html#hot-reloading-and-exception-capture-tools",
    "title": "Hot Reloading, Exception Capture",
    "section": "hot reloading and exception capture tools",
    "text": "hot reloading and exception capture tools\nreloading Change Python code while it’s running without losing state\njurigged Hot reloading for Python\nDebugPy can capture every exception at the time it is raised and preserve state (but cannot instruct the frame to continue execution without exception), no matter it is wrapped around some ‘try-except’ or not.\nReloadium requires breakpoints to reload scripts. However, breakpoints can be generated/inferenced and removed at runtime. Currently it only works with pydevd inside pycharm. Reloadium supports line-wise profiling.\nDebug Adapter Protocol\nDAP client in neovim\nDAP client in python\nOfficial DAP client reference\npydevd_reload An enhanced hot reload module from PyDev"
  },
  {
    "objectID": "posts/b6494faf-68cb-427e-9277-289a6fe71394/index.html",
    "href": "posts/b6494faf-68cb-427e-9277-289a6fe71394/index.html",
    "title": "Hide magisk",
    "section": "",
    "text": "Hide magisk\nYou need to update to latest magisk by patching the unmodified kernel and install shizuku\nenable whitelist mode"
  },
  {
    "objectID": "posts/22bc5045-d186-412a-8712-3100111d087d/index.html",
    "href": "posts/22bc5045-d186-412a-8712-3100111d087d/index.html",
    "title": "Hardware for fun moment capturing",
    "section": "",
    "text": "Hardware for fun moment capturing\nA head-mounted coaxis camera, coaxis long-range microphone, buffered record mode, two separate buttons for recording and saving, implementation in micropython. large battery."
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html",
    "title": "Hacking tutorials, tools",
    "section": "",
    "text": "别动不动就想日站 收集信息 熟悉工具 做好能做到的 把一路学到的经验总结下来\ntrufflehug find credentials from open sources\nstryker: wifi hacking tool includes dust attack, pin attack\nfound multiple websites on lonely planet tourist guide of america (all over the place!)\noneforall subdomain finder\nhack in one including:\nall defense tool: 半/全自动化利用工具, 信息收集工具, 漏洞利用工具, 内网渗透工具, 运维&甲方&防守方工具, 安全资料整理\nbotnet ips are detected by some websites like URLHaus. there’s a tendency to use common passwords to bruteforce the credential for such botnets, such as inori miral cnc scraper, l4tt/Botnet-Reaper. setting botnets by yourself has advantage of connecting to machines without public ip.\nMHDDoS best ddos tool (someone may make living on that), providing multiple WAF bypass techniques (what about Akamai?)\nalthough sqlmap is somehow out-of-date (wracked by WAF, unable to exploit latest nodedb library), there is a tendency to combine subdirectory/url collector like subfinder with it like codewatchorg/sqlipy and zt2/sqli-hunter, automate the exploitation. search for sql injection (deep/machine learning) in github for latest tools and wiki.\nundetectable credential stealer created by psauxxx. is it coincidence?\npsauxx (twitter) created multiple accounts on github. the original one （in archive) is deactivated, now named as l4tt. vulnnr (auto exploiter) has some tutorials from geekforgeeks and xploitlab (linked to other interesting tools), and is renamed as uscan. search for vulnnr in github and there is a favourite hack tool collection\nsocialfish clone website and collect credentials (phishing) with web controller interfaces\nsploitus search for latest sploits and POC-code (usually after patching is done)\nbearSG 符合国人习惯的社工密码生成器 java开发 自带GUI\ncupper 社工密码生成器\n社会工程工具列表 是security list的一部分 其中推荐独立开发者怎么赚钱 (有免费API接口介绍 但是有的站已经没了) -&gt; 国内独立开发者项目列表 -&gt; bufpay 免签支付 (需要按月交费)\n内容包括：\nmosint email osint\npayloadallthethings (40k stars!) by swisskyrepo\nopenai written phishing and directory bruteforcing\nghunt google osint\nscarecrow payload generator targeting win 10-11\nscarecrow cobalt strike plugin\ncryptographic related python libraries gmpy2 pycryptodome libnum yafu rsa-wiener-attack RsaCtfTool\nciphery auto decryption\npwntools used by fmyy and more doc\nangr to reverse engineer binaries, mostly in ctf? docs\nangr ctf use cases: case 1 case 2\nangr ctf reverse binaries and print “good job”\nangr ctf build binaries from source\ndefcon ctf quals 2021 ooo\nfactordb.com find prime numbers, decomposition for rsa\nreverse shell generator while shellcode cannot have null bytes, you need to xor your things with tool or assembly.\n挖0day 或者利用现成漏洞 fuzzers for kali\nkali tools\nblackarch tools\nall in one hacking tool\nvillainbackdoorgenerator\ndon’t aim big, aim small. things like bilibili password database dump, or some Intel internal data leak, are done by professional hackers on professional hardware. some corp will even attempt to retaliate like nvidia. you have been warned.\nTo exploit zerodays, you need rasp, aka ‘is my application doing something undefined/unexpected?’\n利用公共WiFi 比如用WiFi炮连接远处的WiFi 控制云端的攻击服务器\n黑客第一步是找目标 （CTF可能不会教你怎么找目标 白帽也不会 因为目标很单一）不管漏洞存不存在 目标究竟是个啥目标 是人（联系方式？）还是机器（URL？）还是AI （验证码？）怎么交互（可能）是什么漏洞 以及采取什么攻击措施 都得先把目标罗列清楚 可以借助搜索引擎 fofa漏洞搜索 邮箱信息 社交软件的信息 木马跟踪他人的信息 大多数人访问的信息 爬虫信息 监控本地软件访问网络的记录 或者直接随便扫描 存到数据库里面\n第二步就是交互 利用漏洞 装后门 控制目标 比如挖矿 继续收集网站信息 密码信息 cookies 继续散播病毒 拓展攻击面\n第三步持久作战 持续提高反侦查意识 学习收集信息工具 提高黑客能力 利用各种方法 比如社会工程学 利用匿名账号或者免费邮箱账号 传播带木马的免费应用程序 病毒邮件 坚持就是胜利\nhttps://github.com/mikaelkall/HackingAllTheThings\nhttps://github.com/akenofu/HackAllTheThings\nmemory editing, game hacking:\nhttps://github.com/qb-0/pyMeow\nhttps://github.com/srounet/Pymem\nmirai botnet\ndefcon for news, intro, wiki\ninfocon for software, code, wordlists\nmec mass exploiting"
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#notes",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#notes",
    "title": "Hacking tutorials, tools",
    "section": "notes",
    "text": "notes\npc微信hook 获取二维码\npc微信逆向\n几个觉得还不错的靶场\n封神台：https://hack.zkaq.cn/index\nHack The Box ：https://www.hackthebox.com/\nhtb邀请码获取方法：https://www.mad-coding.cn/2019/11/11/hackthebox%E5%88%9D%E6%8E%A2%E4%B9%8B%E8%8E%B7%E5%8F%96%E9%82%80%E8%AF%B7%E7%A0%81/#0x00-%E5%89%8D%E8%A8%80\nVulhub：https://www.vulnhub.com/\nPikachu：https://github.com/zhuifengshaonianhanlu/pikachu"
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#search-engines",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#search-engines",
    "title": "Hacking tutorials, tools",
    "section": "search engines",
    "text": "search engines\nyoucode search engine for coders, enter coding question to get result\nself-hosted recon intelligence tool: osint\nivre network recon framework\npublicwww: search for html/css/js source code in website\nsearchpedia: search engine collection\ntop 5 recon/intelligence/information gathering tools\nsearch engine hacking, manual and automation\nbest hacker search engines"
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#scripting",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#scripting",
    "title": "Hacking tutorials, tools",
    "section": "scripting",
    "text": "scripting\nwriting nmap scripts"
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#information-gathering",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#information-gathering",
    "title": "Hacking tutorials, tools",
    "section": "information gathering",
    "text": "information gathering\nuncover quickly discover hosts using multiple search engines\ndirsearch scan web paths\npip3 install dirsearch"
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#virus-botnet",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#virus-botnet",
    "title": "Hacking tutorials, tools",
    "section": "virus, botnet",
    "text": "virus, botnet\nbotnet with super escalation system for linux and windows, automatically spread the virus out\nwebshell 免杀"
  },
  {
    "objectID": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#hacking-tutorials",
    "href": "posts/6e36fb33-3a8b-4538-acc8-49f7fcb380d5/index.html#hacking-tutorials",
    "title": "Hacking tutorials, tools",
    "section": "Hacking tutorials",
    "text": "Hacking tutorials\nmaybe you should follow kali/parrot/blackarch tutorials first?\n暗网 社工库 数据库 暗网黑客教学\n暗网自由社区，中文社区，无下限讨论 zuw2gvomnfx5mt6g626srambeqo2yxmac5jpoccttq54z7se36svmlyd.onion\nthe payload, dedicated tutorial https://github.com/swisskyrepo/PayloadsAllTheThings\nsure it needs everything to hack. the assembly, the tools, the experience, the examples, the automation, the persistence, the vision.\nall in one hack tool: https://github.com/Z4nzu/hackingtool\nawesome hacking: https://github.com/Hack-with-Github/Awesome-Hacking\nhacking tutorials and tools: https://github.com/carpedm20/awesome-hacking https://github.com/sundowndev/hacker-roadmap https://github.com/jekil/awesome-hacking https://github.com/carlospolop/hacktrick\nctf tutorials and tools: https://github.com/xtiankisutsa/awesome-mobile-CTF https://github.com/Naetw/CTF-pwn-tips https://github.com/firmianay/CTF-All-In-One https://github.com/taviso/ctftool https://github.com/UnaPibaGeek/ctfr https://github.com/RsaCtfTool/RsaCtfTool https://github.com/Gallopsled/pwntools https://github.com/0Chencc/CTFCrackTools https://github.com/google/google-ctf https://github.com/ctf-wiki/ctf-wiki https://github.com/apsdehal/awesome-ctf https://github.com/p4-team/ctf https://github.com/zardus/ctf-tools\nsome other tools and resources\nhttps://github.com/jopohl/urh\nhttps://github.com/sundowndev/hacker-roadmap\nall in one hacking tool for kali linux\nhttps://github.com/edoardottt/awesome-hacker-search-engines\nhacker pro hacktool for termux and linux, maybe macos?\nsql/xxs scanner, dos, bruteforce ftp/ssh/mail accounts\nhttps://github.com/hacktoolspack/hack-tools\nhttps://github.com/hahwul/WebHackersWeapons\nhttps://github.com/jekil/awesome-hacking"
  },
  {
    "objectID": "posts/667f5ab4-f342-4490-a33e-caafb85a4b09/index.html",
    "href": "posts/667f5ab4-f342-4490-a33e-caafb85a4b09/index.html",
    "title": "Gooey: Argparse as GUI",
    "section": "",
    "text": "Gooey: Argparse as GUI\nDirectly convert commandline programs as GUI programs.\nThis goofy name “Gooey” is so strange that even ChatGPT and search engine like Bing have both failed to retrieve.\nYet we manage to recover it from our legacy codebase AGI/AutoUP/generator/transcribe by rg -g *.cmd pyinstaller36 and find . | rg time | rg tracker.\nIs this fate?\nIs this the end, or the new beginning?"
  },
  {
    "objectID": "posts/b12b47b4-418b-4b44-af94-48c92a69517a/index.html",
    "href": "posts/b12b47b4-418b-4b44-af94-48c92a69517a/index.html",
    "title": "Github Bookmarks from James4deutschland",
    "section": "",
    "text": "Github Bookmarks from James4deutschland 2022/6/1\nconsider using proxy and vpn to do the capturing. mitmproxy and pcapdroid.\nfor accounts with cookies or credentials, you can use custom tool like gh_stars_export."
  },
  {
    "objectID": "posts/fb7f6f7c-aa9e-4c67-8e46-41d1b39d859a/index.html",
    "href": "posts/fb7f6f7c-aa9e-4c67-8e46-41d1b39d859a/index.html",
    "title": "Understanding the Psychology of Gaming and Its Impact on Community Formation",
    "section": "",
    "text": "Game Player’s Logic\n玩家玩游戏的逻辑\n“Looks like you are caring about me.”\nGaming starts from dissatisfactory of the reality. Be it loneliness, anger, tirement or stress.\n玩游戏都是有人引导玩的 都是因为别人玩 所以跟着玩的 固有的社交属性\n玩游戏和职业可能没多大关系\n跟着玩会形成流派 会在不同的区域分化 比如正版盗版 单机联机\n玩家自闭的因素 是因为游戏本身的复杂性 以及封闭性 重复性 玩家变得不想考虑外界的事情 只想关心游戏本身的事情\n可以把游戏相关的视频从外网搬到内网 把游戏视频搬运过来 也可以引用游戏元素 头像 吸引游戏玩家的流量 可以切分游戏剪辑视频 转化游戏攻略之类的视频和文案\nsound, visual effects, scripts\nClassic scenes picked from danmaku peaks."
  },
  {
    "objectID": "posts/cb015b2c-83b6-46a1-b10b-2e25ac30b986/index.html",
    "href": "posts/cb015b2c-83b6-46a1-b10b-2e25ac30b986/index.html",
    "title": "Mastering Frame Interpolation Techniques for Smooth Videos",
    "section": "",
    "text": "Frame Interpolation\nanime interpolation: https://github.com/lisiyao21/AnimeInterp\nnvidia unsupervised frame interpolation: https://github.com/NVIDIA/unsupervised-video-interpolation\nsmoother videos by frame interpolation: https://github.com/midnightripper/Video-Interpolation-for-creating-smoother-videos"
  },
  {
    "objectID": "posts/93ce56e7-4524-40d0-9156-e29f6eb0dd33/index.html",
    "href": "posts/93ce56e7-4524-40d0-9156-e29f6eb0dd33/index.html",
    "title": "Free Mathematica Activation Method",
    "section": "",
    "text": "Free Mathematica Activation Method\nvisit online activation code generator, which recommends a paid global internet service provider.\nfirst generate MathID using a free wolfram account, login through it.\nnext find the location of mathpass. follow the format and create a new line above all lines, with the obtained activation code.\nfor macos, we can find it here: /Users/&lt;userName&gt;/Library/WolframEngine/Licensing/mathpass\nfor linux: /root/.WolframEngine/Licensing/mathpass or something else."
  },
  {
    "objectID": "posts/c2d43611-7d5c-4cc3-aae1-32531a89615d/index.html",
    "href": "posts/c2d43611-7d5c-4cc3-aae1-32531a89615d/index.html",
    "title": "Facial Expression Detector",
    "section": "",
    "text": "Facial Expression Detector\nhttps://github.com/MauryaRitesh/Facial-Expression-Detection https://github.com/valterlucena/facial-expression-detector\ndeepface: https://github.com/serengil/deepface\ncnn based facial expression recognizer: https://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch/issues\npredict human emotion: https://github.com/thoughtworksarts/EmoPy\nfacial expression recognization: https://github.com/phamquiluan/ResidualMaskingNetwork\nsmile detection using opencv: https://www.geeksforgeeks.org/python-smile-detection-using-opencv/"
  },
  {
    "objectID": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#video-highlights-extraction",
    "href": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#video-highlights-extraction",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "video highlights extraction",
    "text": "video highlights extraction\nalthough you may want to train/extract that manually, it would sure be tedious and not self-updating (unless using reinforcement learning).\noften we determine highlights by sound, visual and voice together. highlights often can be identified without too much context, so it can be chunk based.\n\nbilibili\nb站的高能进度条 在油管被叫做”most replayed”\nb站有弹幕 所以可以根据弹幕找到精彩片段 VClimax是一个浏览器插件 可以通过弹幕单位时间增长速率，设置相关的阈值，来定位最精彩的内容 (弹幕密度怕还是得要分析) 跳转部分番剧OP 视频搞笑片段精准定位 (怕还得是要机器学习)\nbilibili Danmaku Skip is another browser plugin which will identify highlights by analyzing danmaku with parameters like threshold, interval and bias\n\n\nyoutube\nyoutube’s most played data can be extracted by:\nyoutube-heatmap (nodejs, using puppeteer (bad!))\nyoutube operational api’s (powered by shared API keys and info extractors without key), while apparantly youtube-most-replayed is using this service to retrieve the data from yt.lemonslife.com powered by this library\nheatmap extractor\nyoutube.js (reverse engineered innertube api) added support for chapters and video heatmap"
  },
  {
    "objectID": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#youtube-dl-search-youtube-video",
    "href": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#youtube-dl-search-youtube-video",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "youtube-dl search youtube video",
    "text": "youtube-dl search youtube video\nyoutube-dl \"ytsearch[optional_result_limit]:[query]\"\n\n# pass query url directly to allow pagination or filters\n\nyoutube-dl \"https://www.youtube.com/results?search_query=how+to+create+android+app+in+android+studio&page=1\""
  },
  {
    "objectID": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#record-live-streaming-video-upload-video",
    "href": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#record-live-streaming-video-upload-video",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "record live streaming video, upload video",
    "text": "record live streaming video, upload video\n\nbiliup & biliup-rs (commandline program)\n全自动录播、投稿工具，也支持twitch、ytb频道搬运。提供分p上传b站接口\n其实直播回放没有什么好看的 很单调 另外b站上传之后可以获得视频预测标签\n\n\nyoutube automation toolkit post same content to multiple platforms: bilibili, douyin, douyu, instagram, reddit, spotify, tiktok, twitch\nthough the idea is correct by posting original content to multiple platforms to prevent pirating, but the description/title generation is a vital part of the process, which must be done intelligibly (AI or human). as for now the repo is just full of links. if you want tools you click given link."
  },
  {
    "objectID": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#download-a-portion-of-video",
    "href": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#download-a-portion-of-video",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "Download a portion of video",
    "text": "Download a portion of video\n\nyt-dlp (latest)\ncheck pyjom/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh for advanced usage of yt-dlp and more on bilibili parsing.\nSINCE YT-DLP IS UPDATED YOU CAN USE --download-sections ARGUMENT FOR YOUTUBE\nIf you want to download multiple sections of same video, you must specify video output format string via -o\nBut when using that without “–force-keyframes-at-cuts” (skip re-encoding which can speed up thing but not ensuring quality of video at tail), you better keep margin at tail for 10 seconds (could glitch at last 5 seconds) and head for 5 seconds (maybe head margin is not needed?).\n\n\nyoutube-dl\nfirst acquire download url: youtube-dl [--youtube-skip-dash-manifest] [-f 18] -g \"https://www.youtube.com/watch?v=V_f2QkBdbRI\" (you need to force the format.)\nthen use ffmpeg with the url to chop the slice: ffmpeg -ss 00:00:15.00 -i \"OUTPUT-OF-FIRST URL\" -t 00:00:10.00 -c copy out.mp4\n\n\nRangeDownloader by A-Soul-Database\nA-Soul-Database is a live-streaming replay record database designed for vtubers, organized in some way for easy information retrieval.\nRangeDownloader is acting like a server, though sometimes we are not sure how fast(er) it can really be."
  },
  {
    "objectID": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#viral-videos",
    "href": "posts/54bb6091-5e45-437c-bb15-f845d9926ebd/index.html#viral-videos",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "Viral videos",
    "text": "Viral videos\n\nData sources and monitors\n\nRebang.today\n通过B站推荐标签接口可以得到观众的实时需求\n提供全站 知乎 微博 IT之家 百度 虎扑 直播吧 少数派 36氪 吾爱破解 天涯 小众软件 反斗限免 哔哩哔哩 抖音 技术期刊 v2ex GitHub的热榜\nAPI：https://api.rebang.today/v1/items?tab=&lt;TAB_NAME&gt;&page=&lt;PAGE_NUM&gt; (potential parameters: sub_tab, date_type (default:now))\n知乎有个专门的热榜，地址：https://www.zhihu.com/billboard\n知乎圆桌 知乎发现\n\n\n\nname\ntab\n\n\n\n\n全站热榜\ntop-all\n\n\n微博\nweibo\n\n\nV2EX\nv2ex\n\n\n知乎\nzhihu\n\n\n哔哩哔哩\nbilibili\n\n\nGitHub\ngithub\n\n\n抖音\ndouyin\n\n\n技术期刊\njournal-tech\n\n\n虎扑\nhupu\n\n\n少数派\nsspai\n\n\n百度\nbaidu\n\n\n36氪\n36kr\n\n\n天涯\ntianya\n\n\n吾爱破解\n52pojie\n\n\nIT之家\nithome\n\n\n全站24小时\ntop-daylong\n\n\n直播吧\nzhibo8\n\n\n小众软件\nappinn\n\n\n反斗限免\napprcn\n\n\n\n\n\n番茄数据\n番茄数据提供了从近24小时–近90天B站的最新热门视频，你既可以通过“搜索标题、简介、标签、评论出现关键词”，也可以通过行业分类、播放数、点赞数、投币数、视频时长、观众画像等高级条件，精准定位想要查找领域的热门视频。传播指数的计算方法有待研究。传播指数是根据UP主的粉丝数、视频点赞数、播放数、投币数、分析数等分析出来的综合得分。根据评论热词分析视频观众热点，根据评论用户分析用户画像。\n对于各大数据网站 都存在一个收录的接口 如果up主从来没有上过首页 大概率不会被收录 需要手动提交 间接说明大up主是如何被找到的\n\n\n\nImage recognizers\n\nBaidu Image recognizer 百度识图\n与此相关的识图项目位置：pyjom/tests/search_engine_suggestion_based_qa_bot\n可以获取关键字，标签，同样的图，秒懂百科视频，百度百科数据，包含图片的信息，颜值信息\n通过把上传接口修改 以及http改成https 现在可以继续使用\n位置：pyjom/tests/viral_video_experiments/BaiduSerchImgApi\n通过http改成https 修改好了360识图的接口\n位置：tests/viral_video_experiments/360ImageSearch\n\n\n\nVideo collectors\n\ntiktok compilation video generator\ncollect popular video on tiktok by multiple filters such as hashtags, categories , popularities and search queries\n\n\nWeiboSpider\n需要cookie 收集用户信息 用户粉丝列表 用户关注列表 微博采集 微博评论采集 微博转发采集 基于关键词的微博检索\n\n\nbotTuber: a instagram compilation reposter to youtube\nUsing instaloader and instalooter, it can download videos from instagram. It merges a series of video and add intro and outro. It only contains one default title starts with “TRY NOT TO LAUGH” in its “auto” mode.\n\n\nreddit hot videos to youtube\nIn “TiktokCringe” reddit channel, we are able to get hot posts and video links prefixed by https://v.redd.it (from tiktok to reddit) in json format: https://www.reddit.com/r/TikTokCringe/hot.json?limit=12. This link looks like some API or subscription. Maybe Bilibili and other sites have similar “hot” json urls. The way to extract video links is in atmt.sh. It adds transitions to every video clip.\n\n\n\nVideo editors\n\nvced\ni think it needs to be fine-tuned on large diversive training data.\nVCED 可以通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑。该项目基于跨模态搜索与向量检索技术搭建，通过前后端分离的模式，帮助你快速的接触新一代搜索技术。\n\n\nvideofy\nit is a self-hosted service, summarize article, get relevant text and image, determine mood to select BGM. try for yourself!\n\n\nmeme video maker\nIt uses google cloud to select “English” words on image, enable the user to edit the “stage” to show meme step by step.\nIt requires amazon cloud services and google cloud services.\n\n\n回声工坊 TRPG Replay Generator\nTRPG：桌上角色扮演游戏 有丢骰子（随机元素）的RPG\n角色立绘可以是动态的 但是是多个png文件\n背景可以设定为 {'black','white','greenscreen'} 中的一个，以建立纯色背景\nHas special requirements to media sources. Use .ogg format for BGM. Use .wav format for AFX and voices. Use .png for image. Cannot get background video layers working so you might consider some “green screen” effects.\nUse --ExportVideo flag to export video without GUI.\n\n\nopenshot and libopenshot (for python bindings)\nNightcorify is accelerating audio and raising pitch (asetrate strenches the timeline to change sample rate, atempo (not used in here) change the timeline but not the pitch, while aresample changes the sample rate but not timeline), also showing audio wave shape with showwaves.\nThis library is complex AND WITHOUT PROPER DOC FOR PYTHON thus not recommend for using\n\n\nkeybert and summarization transformer pipeline\nCheck docs on transformers pipelines for default and fine-tuned task-specific models for each pipeline.\nKeybert uses “sentence-transformers”. The author would advise either “all-MiniLM-L6-v2” for English documents or “paraphrase-multilingual-MiniLM-L12-v2” for multi-lingual documents or any other language. Search for “multi” with tag “summarization in huggingface, then you would get huge models. A mT5 model is very large, size upto 2.33GB\nKeywords-image pairs can be used for CLIP model training.\n\n\nwatson based video maker\nIt first downloads wikipedia content from algorithmia, then uses regex to filter out unwanted parts, uses watson AI for sentence cutting, set a limit for max sentences (notice: not summarization), then search image with keywords, finally create video.\nIn another similar project IMDB (Popular Film/TV series) and Google search trends (as RSS) are included.\n\n\nAuto-Editor\nBy passing --edit option, you can remove unwanted parts identified by motion or audio (can be combined). It can import clip with manual “cut-out”. It can export as json.\n\n\nPictory\nLeveraging 3 millions of tagged video clips and audio, choosing most semantically similar clip to current scene (by extracting keyword -&gt; search images -&gt; compare images to video sources with all embedding things going under the hood (CLIP)), map video word by word to the timeline (to create extractive highlights and remove unwanted words like “um”)\n\n\nWisecut\nShort videos can attract your viewers and converting them into followers (to view more of your long videos). Make short videos with music, subtitles and facial recognition auto-reframe (detect main speaker). It match the right BGM with the type of content, with audio ducking, which can be achieved with ffmpeg or editly.\nIt is listed among an AI marketing tools list, which mentions copywriting, social media/email/blog marketing text/content generation (like copy.ai), text to video\n\n\nJumpcutter\nAn audio-slience based video cutter. In jumpcut_file.py it chops audio into chunks and decide if it is slience or not. The core logic is to first compare max volume of each chunk against threshold, then check in neighbors of every chunk if all of them are slient and cut them out. It has audio speed changing methods from audiotsm.\nIn another implementation, it uses ring buffer by collections.deque and applies VAD (Voice Activity Detetion) by webrtcvad to every chunk of audio.\n\n\nGifcurry\nAdding text to video, has typing effects, written in haskell. You can add -m flag to export video instead of GIF.\n\n\nBackgroundremover\nA commandline tool powered by torch, removing background from images and video\n\n\nMoviepy most loved commandline video editor?\nThere are some cool text effects called “Text with moving letters” (PPT-like), and a dancing video generator based on tempo finder and video loop maker, which can help you adjust video speed according to video period and music bpm. The Star-Wars Text Effect reminds me of easing functions used with page scrolling.\n\n\n\nData collect/analyze\nSocial media statistics are time series data which should be collected regularly and predictable with time forcasting models.\n\nopen-sir\nUse sirx over sir.\nI think it is hard to use. Many “presumed” parameters are out there. It can fit “reproduction rate” but no individual “alpha” and “beta” values.\nIn tradirional SIR models, beta is infection rate, gamma is recovery rate. While in open-sir it is different. alpha now is beta, beta now is gamma.\n\n\nYoutube Viral Video Machine Learning Analysis\nRefer to this document for details in data collection and machine learning methods.\nUsage:\nYou can decide whether to copy a video or not when it is posted for only a few days.\nDataset creation:\nMonitoring video right at the time it is posted, monitor for a few days, calculate features, then wait for a month or two (it must stablize then), judge the video is viral or not by view counts.\nUsing multiple machine learning techniques, there are some top features matters the most for viral video forecasting (though you can derive your own by collecting more data (like the follower-view theory if applied), and beware if your video all sucks, you may not get an accurate model out of your data alone):\n\n\n\nRank\nFeature Name\nImportance\n\n\n\n\n1\nviews_acc\n12%\n\n\n2\nviews_1\n11%\n\n\n3\nageRatioReviews_1\n9%\n\n\n4\nvideo_duration\n9%\n\n\n5\ncomments_1\n5%\n\n\n6\nchannel_uploads\n5%\n\n\n7\nageRatioLikes_1\n4%\n\n\n8\ncomments_acc\n4%\n\n\n9\nchannel_views\n4%\n\n\n10\ncomments_sentiment_compound\n3%\n\n\n\n\n\nViralCaster\nTitleParser.py analyses views along with words, getting the most “popular” word or word combinations. It has demo data. It generates “max” “min” “mean” views related to single word or word combinations.\n\n\nPredictube\npeak_detection.py use daily view count to categorize and identify trends. “MonoIncr” might be our desired category.\n\n\nVideo Viralization Tool\nIt uses relative infection ratio instead of absolute to predict the trend. By “information cascade” it means statistics can be used to predict future view counts. It considers individuals and viewers as nodes. It suggests different relationships between parameters in SIR model and data (likes, shares, comments, new subscribers, subscribers, length, quality, tag keywords, description keywords)."
  },
  {
    "objectID": "posts/0813f4b6-f73f-4ad1-97fe-267d0dafc7b3/index.html",
    "href": "posts/0813f4b6-f73f-4ad1-97fe-267d0dafc7b3/index.html",
    "title": "Example Pydoc",
    "section": "",
    "text": "Example Pydoc\n\n\n\n\n\n\ndescription: | API documentation for modules: example_docstring.\n\n\nlang: en\n\n\nclassoption: oneside geometry: margin=1in papersize: a4\n\n\nlinkcolor: blue links-as-notes: true …\n\n\n# Module example_docstring {#id}\n\n\na 狗 that will bark.\n\n\n## Variables\n\n\n### Variable global_var {#id}\n\n\nsome global variable2 Default to None\n\n\n### Variable global_var2 {#id}\n\n\nsome other global variable\n\n\n## Functions\n\n\n### Function some_random_method {#id}\n\n\n&gt; def some_random_method( &gt; param_1: str, &gt; param_2, &gt; kw_param_1=None &gt; ) ‑&gt; None\n\n\njust a random method\n\n\nArgs ——–= param_1 : str : parameter at position 1\n\n\nparam_2 : str : parameter at position 2\n\n\nkw_param_1 : Any, optional : keyword parameter 1. Defaults to None.\n\n\nReturn ——–= Nothing returned.\n\n\nNote ——–= Extra Notes?\n\n\n## Classes\n\n\n### Class Dog {#id}\n\n\n&gt; class Dog( &gt; name: str &gt; )\n\n\ndog class\n\n\nMake a Dog without any friends (yet).\n\n\n#### Class variables\n\n\n##### Variable friends {#id}\n\n\nType: List[example_docstring.Dog]\n\n\nThe friends of our dog.\n\n\n##### Variable name {#id}\n\n\nType: str\n\n\nThe name of our dog.\n\n\n#### Methods\n\n\n##### Method bark {#id}\n\n\n&gt; def bark( &gt; self, &gt; loud: bool = True &gt; )\n\n\nwoof\n\n\n\nGenerated by pdoc 0.10.0 (https://pdoc3.github.io)."
  },
  {
    "objectID": "posts/688a7c55-37f2-4518-8af8-702562102e3d/index.html",
    "href": "posts/688a7c55-37f2-4518-8af8-702562102e3d/index.html",
    "title": "Essay grading",
    "section": "",
    "text": "Essay grading\nLSTM grading: https://github.com/yetianpro/automated-essay-grading-by-RNN\nessay scoring: https://github.com/mankadronit/Automated-Essay–Scoring\nNeural Essay Assessor: https://github.com/nusnlp/nea"
  },
  {
    "objectID": "posts/ee2f6691-a77c-4245-ab59-75e0f42c0796/index.html",
    "href": "posts/ee2f6691-a77c-4245-ab59-75e0f42c0796/index.html",
    "title": "Emotion manipulation",
    "section": "",
    "text": "Emotion manipulation\nPredict emotion by means of graphics, motion, text, voice and swap context to achieve desirable effects. Add random swap and funny pictures in addition to simple dictation. You may group different kinds of content for specialized model training. Syncing is hard. With database, it’s not.\nAnalyze the conversation with emotional/keyword frequency indicator, do some feature extraction. Accelerate part of the video to be more expressive\nemotion recognization multi modal"
  },
  {
    "objectID": "posts/0804624b-43a2-4dcf-ac3f-2e6636f72809/index.html",
    "href": "posts/0804624b-43a2-4dcf-ac3f-2e6636f72809/index.html",
    "title": "Dynamic Classification System",
    "section": "",
    "text": "Dynamic Classification System\nIf present in current categories, choose a number. otherwise, provide a name. number will be automatically assigned.\nretrieval based attention net\nregression test in stock market, which can also apply to bilibili"
  },
  {
    "objectID": "posts/208c858a-893c-4f69-8cb5-2a32219b9be5/index.html",
    "href": "posts/208c858a-893c-4f69-8cb5-2a32219b9be5/index.html",
    "title": "Document your code with AI, and use client-side compute resources",
    "section": "",
    "text": "Document your code with AI, and use client-side compute resources\nUse tensorflow.js for the query and llm.\nUse precomputed vector space for searching.\nUse local storage for customization."
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#neural-engine",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#neural-engine",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "neural engine",
    "text": "neural engine\nit is used for coreml inference, not training"
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#run-coreml-on-hackintosh",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#run-coreml-on-hackintosh",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "run coreml on hackintosh",
    "text": "run coreml on hackintosh\nfirst, download macos montery using the mac. then, install it on hackintosh, with associated nvidia drivers. next test gpu avalibility via system info panel. then install xcode commandline tools and check coreml avalibility"
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#run-coreml-with-swift-on-linux",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#run-coreml-with-swift-on-linux",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "run coreml with swift on linux",
    "text": "run coreml with swift on linux\ndarling is at its very premature stage, just like the wine. now it is testing something called “darlingserver” which is a full userspace implementation and is prone to tons of problems. swift repl is not working and installing xcode commandline tools 14 will hang this thing. i suggest you to do light model training on macbook air and convert it to onnx if want to use it everywhere.\nbefore reinstallation of darling, make sure you have removed all darling related files by checking updatedb; locate darling | grep -v &lt;compile directory&gt;\nvisit here to install darling from source (maybe that’s the only way)\nif want to install darling on kali, you must outsource all deeplearning models to other disks, and collect all other big files to somewhere else or trash them. use systemwide user broadcast method to warn me if any of the disk is missing. use automatic symlink change method to adapt the external disk mountpoint changes.\ndarling can install xcode commandline tools with macos sdk, so maybe it can run coreml models with swift using cpu. gpu support is currently not known. maybe that requires metal support."
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#thermal-and-battery-life-concerns-and-more",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#thermal-and-battery-life-concerns-and-more",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "thermal and battery life concerns, and more",
    "text": "thermal and battery life concerns, and more\nconsider using external gpus (eGPUs) with thunderbolt 3 and AMD GPUs to avoid overheating. currently that can only be done with intel Macs.\nbattery life is currently bad for intel/amd notebooks of x86/64 architecture.\nheavy lifting jobs are likely to be run on Mac Studio with M1 Ultra and 128GB RAM. Macbook Air M1 with 8GB RAM is simply not feasible.\naside of Apple platforms, these APIs are virtually useless.\nto run these on other non-apple machines, you need to tweak and install macOS on x86-64 platforms with macOS supported GPUs(may have low performance), which will definitely not taking any advantage of huge shared RAM with CPU, and may run poorly on CoreML/CreateML, may not support deepspeed stage 2/3 or BMI(big model inference)\n\n\nNon-Supported NVIDIA Cards, use AMD GPU instead\n\nHigh Sierra no longer supports NVIDIA Mac. Mojave – Catalina – BigSur only works with AMD graphics and Intel onboard graphics and only a very small number of old NVIDIA products. Suppose you have GTX 1070, 1080, and the like, you can not use High Sierra onwards because Nvidia does not provide any updates for Mac and can not be used in any other way. In general, the graphics of the Turing, Pascal, and Maxwell series will never be supported again. The latest Mac version that can use this series of graphics is High Sierra."
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#tensorflow-with-m1-support",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#tensorflow-with-m1-support",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "tensorflow with m1 support",
    "text": "tensorflow with m1 support\nusing tensorflow metal plugin, which sets up miniforge and install tensorflow-metal within.\ninstall without miniforge(works!)\npip3 install tensorflow-macos tensorflow-metal\nvalidation:\npython3 -c \"import tensorflow as tf; physical_devices = tf.config.list_physical_devices('GPU'); print('Num GPUs:', len(physical_devices)); print(physical_devices)\""
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#pytorch-with-m1-support-using-mps-metal-performance-shader",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#pytorch-with-m1-support-using-mps-metal-performance-shader",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "pytorch with m1 support, using MPS (Metal performance shader)",
    "text": "pytorch with m1 support, using MPS (Metal performance shader)\ninstall from nightly release channel, with minimum system version requirements 12.3 (which this machine had been qualified after system update, now 12.5)\n# MPS acceleration is available on MacOS 12.3+\npip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\nvalidation\npython3 -c \"import torch; print('MPS avaliable:',torch.backends.mps.is_available()); print('Built with MPS:',torch.backends.mps.is_built())\""
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#run-python-inside-swift",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#run-python-inside-swift",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "run python inside swift",
    "text": "run python inside swift\nuse pythonkit"
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#automatic-machine-learning-using-createml",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#automatic-machine-learning-using-createml",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "automatic machine learning using CreateML",
    "text": "automatic machine learning using CreateML\nimport CreateML\nCreateML is similar to any other AutoML tools, like AutoKeras, AutoTrain by Huggingface (works by training against a selected set of user-provided models)"
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#using-coreml",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#using-coreml",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "using CoreML",
    "text": "using CoreML\ncurated, largest coreml models collection\nCoreML models can be created by CreateML and some customization can be done via protocol MLCustomLayer.\nonnxruntime can run onnx models on CoreML, via c#, since that library is maintained by microsoft.\nto install c# on macos:\nbrew install dotnet-sdk\nto install and launch dotnet repl:\ndotnet tool install -g dotnet-repl\ndotnet repl"
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#paddlepaddle-support",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#paddlepaddle-support",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "paddlepaddle support",
    "text": "paddlepaddle support\nconvert into onnx first, then run on onnxruntime.\npaddlepaddle itself currently only supports running on M1 CPU only via rosetta 2."
  },
  {
    "objectID": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#links",
    "href": "posts/5858cdca-15ed-448c-8a93-6f293c40bd6a/index.html#links",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "Links",
    "text": "Links\nSwift Core ML 3 implementations of GPT-2, DistilGPT-2, BERT, and DistilBERT for Question answering.\ntrain image classifier and text classifier in which CreateMLUI is deprecated (gone)\ntrain source code classifier with flightschool which is a free swift tutorial books provider\nclassifying sounds with coreml return sound type along with timestamp\ndetect human pose using coreml\napple speech recognization api request\npytorch mps backend\ntext classification using createml\nonnx model zoo\nGetting CoreML Models\nCoreML Model Zoo\n\n\nFCRN-DepthPrediction Depth Estimation\nPredict the depth from a single image. View Models\nMNIST Drawing Classification\nClassify a single handwritten digit (supports digits 0-9). View Model\nUpdatableDrawingClassifier Drawing Classification\nDrawing classifier that learns to recognize new drawings based on a K-Nearest Neighbors model (KNN). View Model and Code Sample\nMobileNetV2 Image Classification\nThe MobileNetv2 architecture trained to classify the dominant object in a camera frame or image. View Models and Code Sample\nResnet50 Image Classification\nA Residual Neural Network that will classify the dominant object in a camera frame or image. View Models and Code Sample\nSqueezeNet Image Classification\nA small Deep Neural Network architecture that classifies the dominant object in a camera frame or image. View Models and Code Sample\nDeeplabV3 Image Segmentation\nSegment the pixels of a camera frame or image into a predefined set of classes. View Models\nYOLOv3 Object Detection\nLocate and classify 80 different types of objects present in a camera frame or image. View Models and Code Sample\nYOLOv3-Tiny Object Detection\nLocate and classify 80 different types of objects present in a camera frame or image. View Models and Code Sample\nPoseNet Pose Estimation\nEstimates up to 17 joint positions for each person in an image. View Models and Code Sample Text\nBERT-SQuAD Question Answering\nFind answers to questions about paragraphs of text. View Model and Code Sample\n\n\nApple Machine Learning Related APIs (may need user permission within or without xcode by means of Info.plist or something)\n\n\nVision Build features that can process and analyze images and video using computer vision.\nView Vision framework\nImage Classification Automatically identify the content in images.\nView API\nImage Saliency Quantify and visualize the key part of an image or where in the image people are likely to look.\nView API\nImage Alignment Analyze and manage the alignment of images.\nView API\nImage Similarity Generate a feature print to compute distance between images.\nView API\nObject Detection Find and label objects in images.\nView API\nObject Tracking Track moving objects in video.\nView API\nTrajectory Detection Detect the trajectory of objects in motion in video.\nView API\nContour Detection Trace the edges of objects and features in images and video.\nView API\nText Detection Detect regions of visible text in images.\nView API\nText Recognition Find, recognize, and extract text from images.\nView API\nFace Detection Detect human faces in images.\nView API\nFace Tracking Track faces from a camera feed in real time.\nView API\nFace Landmarks Find facial features in images by detecting landmarks on faces.\nView API\nFace Capture Quality Compare face capture quality in a set of images.\nView API\nHuman Body Detection Find regions that contain human bodies in images.\nView API\nBody Pose Detect landmarks on people in images and video.\nView API\nHand Pose Detect landmarks on human hands in images and video.\nView API\nAnimal Recognition Find cats and dogs in images.\nView API\nBarcode Detection Detect and analyze barcodes in images.\nView API\nRectangle Detection Find rectangular regions in images.\nView API\nHorizon Detection Determine the horizon angle in images.\nView API\nOptical Flow Analyze the pattern of motion of objects between consecutive video frames.\nView API\nPerson Segmentation New Produce a matte image for a person in an image.\nView API\nDocument Detection New Detect rectangular regions in images that contain text.\nView API\nNatural Language Analyze natural language text and deduce its language-specific metadata.\nView Natural Language framework\nTokenization Enumerate the words in text strings.\nView API\nLanguage Identification Recognize the language of bodies of text.\nView API\nNamed Entity Recognition Use a linguistic tagger to name entities in a string.\nView API\nPart of Speech Tagging Classify nouns, verbs, adjectives, and other parts of speech in a string.\nView API\nWord Embedding Get a vector representation for any word and find similarity between two words or nearest neighbors for a word.\nView API\nSentence Embedding Get a vector representation for any string and find similarity between two strings.\nView API\nSentiment Analysis Score text as positive, negative, or neutral based on the sentiment.\nView API\nSpeech Take advantage of speech recognition and saliency features for a variety of languages.\nView Speech framework\nSpeech Recognition Recognize and analyze speech in audio and get back data like transcripts.\nView API\nSound Analysis Analyze audio and recognize it as a particular type, such as laughter or applause.\nView Sound Analysis framework\nSound Classification Analyze sounds in audio using the built-in sound classifier or a custom Core ML sound classification model.\nView API"
  },
  {
    "objectID": "posts/ce4ab65d-af2c-40ce-b9e1-a782bb46e3b1/index.html",
    "href": "posts/ce4ab65d-af2c-40ce-b9e1-a782bb46e3b1/index.html",
    "title": "DeepNude Censorship NSFW safesearch",
    "section": "",
    "text": "DeepNude Censorship NSFW safesearch\nclip-based-nsfw-detector\nyou can turn on/off safesearch by changing ip to iran. is there better options, doing this programmatically?\nnsfw createml imageclassifier with pretrained model\n敏感词过滤器 also need a high speed censor engine using trie, also in diffferent language(like english or japanese)\nenglish profanity: https://github.com/snguyenthanh/better_profanity https://github.com/zacanger/profane-words https://github.com/MauriceButler/badwords https://github.com/vzhou842/profanity-check https://github.com/coffee-and-fun/google-profanity-words\nchinese profanity: https://github.com/gaohuifeng/sensitive-word-filter https://github.com/lunzima/profanities.txt https://github.com/nyx1987/forbiddenwords https://github.com/insoxin/bannedwords https://github.com/chason777777/mgck https://github.com/k5h9999/keywordfilter https://github.com/tomzhang/bannedwords https://github.com/observerss/textfilter （需要回看历史 查看git历史） https://github.com/aojiaotage/text-censor\ndeepnude nsfw nude picture detection: https://github.com/yuanxiaosc/DeepNude-an-Image-to-Image-technology/blob/master/README-ZH.md\nvideoaudit 视频审核框架https://github.com/minitrill/VideoAudit\nnsfw: not safe for work, inappropriate content, porn, offensive https://github.com/rockyzhengwu/nsfw https://github.com/alex000kim/nsfw_data_scraper https://github.com/yahoo/open_nsfw https://github.com/Rayraegah/nsfw_japan https://github.com/fishsup/nsfw-image-classification https://github.com/yangbisheng2009/nsfw-resnet https://github.com/GantMan/nsfw_model https://github.com/devzwy/open_nsfw_android https://github.com/infinitered/nsfwjs https://github.com/nsfw-filter/nsfw-filter\nnudity, violence and drug https://github.com/amshrbo/nsfw-detection\nto train these networks, suitable datasets are required. 找训练集 找涉政 涉黄 暴力血腥图片训练集 找类似的文字训练集 百度aistudio可能有 github可能有 百度一下也可能有\n同样的思路 情绪 情感打分也可以这样打分 根据不同的训练集进行打分\ngithub violence detection: https://github.com/topics/violence-detection\nBloody Image Classification with Global and Local Features https://www.researchgate.net/publication/309365631_Bloody_Image_Classification_with_Global_and_Local_Features\nObject content understanding in images and videos draws more and more attention nowadays. However, only few existing methods have addressed the problem of bloody scene detection in images. Along with the widespread popularity of the Internet, violent contents have affected our daily life. In this paper, we propose region-based techniques to identify a color image being bloody or not. Firstly, we have established a new dataset containing 25431 bloody images and 25431 non-bloody images. These annotated images are derived from the Violent Scenes Dataset, a public shared dataset for violent scenes detection in Hollywood movies and web videos. Secondly, we design a bloody image classification method with global visual features using Support Vector Machines. Thirdly, we also construct a novel bloody region identification approach using Convolutional Neural Networks. Finally, comparative experiments show that bloody image classification with local features is more effective.\nsearch for nsfw filter providers on google/kaggle\nkaggle nsfw image dataset https://www.kaggle.com/datasets/laxmansingh/nsfw-images-data https://www.kaggle.com/datasets/drakedtrex/my-nsfw-dataset/code\nsearch for nsfw image/text on github: https://github.com/alex000kim/nsfw_data_scraper https://github.com/nsfw-filter/nsfw-filter nsfwjs https://github.com/arufian/Image-Censor-Lightning-Web-Component https://github.com/enymuss/censorText https://github.com/fmsky/resnet50_inappropriate_content_detect https://github.com/CheranMahalingam/Image_Content_Moderation\n文本审核框架： https://github.com/minitrill/TextAudit\n规避文本审查：有可能是加密了 但是人眼可以识别 https://github.com/kallydev/shutup\nnudenet based inappropriate image censoring\nocr based word censoring\npolitics 涉及政治：领导人 人脸识别 图标识别\nviolence 血腥暴力：图像识别"
  },
  {
    "objectID": "posts/57cad01a-5bc9-4908-adfc-41f22d50fa91/index.html",
    "href": "posts/57cad01a-5bc9-4908-adfc-41f22d50fa91/index.html",
    "title": "DNA Cancer Prediction",
    "section": "",
    "text": "DNA Cancer Prediction\nhttps://github.com/davidanastasiu/coen-342-wi22\nPR1: Peptide Classification\nPublished Date: Jan. 12, 2020, 5:00 p.m.\nDeadline Date: Jan. 25, 2020, 11:59 p.m.\nDescription:\n\nThis is an individual assignment. ************************************************ Overview and Assignment Goals:\nThe objectives of this assignment are the following:\n Create feed-forward neural networks and train them using your own codes and frameworks.\n Experiment with different feature extraction techniques.\n Think about dealing with imbalanced data.\nDetailed Description: Develop predictive neural networks that can determine, given an antibacterial peptide, whether it is also an antibiofilm peptide.\n“Proteins are large biomolecules, or macromolecules, consisting of one or more long chains of amino acid residues. Proteins perform a vast array of functions within organisms, including catalysing metabolic reactions, DNA replication, responding to stimuli, providing structure to cells, and organisms, and transporting molecules from one location to another. Proteins differ from one another primarily in their sequence of amino acids, which is dictated by the nucleotide sequence of their genes, and which usually results in protein folding into a specific three-dimensional structure that determines its activity.\nA linear chain of amino acid residues is called a polypeptide. A protein contains at least one long polypeptide. Short polypeptides, containing less than 20-30 residues, are rarely considered to be proteins and are commonly called peptides. […] The sequence of amino acid residues in a protein is defined by the sequence of a gene, which is encoded in the genetic code. In general, the genetic code specifies 20 standard amino acids; […] Proteins can also work together to achieve a particular function, and they often associate to form stable protein complexes.” [Wikipedia, Accessed 2020-02-07, https://en.wikipedia.org/wiki/Protein]\nBiofilms are tightly-connected multicellular communities of microorganisms encased in self- secreted extra-cellular matrices. They are currently one of the major causes of disease for\ntwo main reasons. First, roughly 75% of all human infections are caused by biofilms. Second, due to the robust multicellular cellular matrix structure, they are resistant both to the host defense mechanisms and to traditional antimicrobial compounds (antibiotics). Thus, it is important to identify peptide sequences that are not only antimicrobial (can destroy or render inert the invading microorganism), but also antibiofilm (can penetrate the extra-cellular matrix so it can get to the microorganism in the first place).\nYou have been provided with a training set (train.dat) and a test set (test.dat) consisting of peptide sequences, one per line in the file. Peptides are encoded as strings with characters from an alphabet of 20 characters, each representing an amino-acid residue. The training set also includes the label for each sequence as 1 (antibiofilm) or -1 (not antibiofilm) as the first character in each line of the training file, separated from the sequence by a tab ( character.\nThe input to your classifiers will not be the peptides themselves, but rather features extracted from the peptides. Two simple approaches for feature extraction are the bag-of- words and the k-mer models you should have learned about in Data Mining or Machine Learning, where a word is one of the amino-acids in the peptide. You should not use any additional external data in this assignment.\nNote that the dataset is imbalanced. We will Matthews’s correlation coefficient (MCC) as evaluation metric for this assignment, which, similar to the F-1 score, combines aspects of the result’s sensitivity and specificity. Given the normal confusion matrix resulting from comparing the predicted and true classes of the test samples, MCC is defined as,\nPrograms:\nYou are required to write two separate programs for the classification. The first may only use basic Python structures (from numpy or scipy) and you should implement your own functions for training the neural network. This is also the program you will use to make CLP submissions. In addition, you should write a second program that uses a deep learning framework of your choice to train the neural network. The structure of the network may be the same or different from the one you created in the first program. You will present results from this program (which should be at least as good as those from the first program) in your report.\nConsiderations:\n\nTry extracting different features from the peptide strings.\nConsider oversampling the negative class to fix the apparent imbalance.\nTry out different network configurations and activation functions.\nConsider regularization as a way to keep weights balanced in the network.\n\nData Description:\nThe training dataset consists of 1566 records and the test dataset consists of 392 records. We provide you with the training class labels and the test labels are held out. Your task is to predict those labels for the peptides in the test set and create a test.txt file containing those labels, which you will submit to CLP. Note that CLP only accepts files with extensions .txt or .dat for your predicted labels, and .py or .ipynb or .zip or .tgz for codes.\nRules:\n This is an individual assignment. Discussion of broad level strategies are allowed but any copying of prediction files and source codes will result in an honor code violation.\n You are allowed 5 submissions per day.\n After the submission deadline, only your chosen or last submission is considered for the leaderboard.\nDeliverables:  Valid submissions to the Leader Board website: https://clp.engr.scu.edu (username is your SCU username and your password is your SCU password).\nCanvas Submission for the report:\n Include a 2-page, single-spaced report describing details regarding the steps you\nfollowed for feature extraction, designing your neural network, and training your model. The report should be in PDF format and the file should be called report.pdf. The report needs to be structured as a technical report (title, abstract, introduction, sections, conclusion), be free from grammatical errors, and use standard page and font sizes (letter size page, 10 or 11 pt font). Be sure to include the following in the report:\n\nName and SCU ID.\nRank & MCC-score for your submission (at the time of writing the report). If\n\nyou chose not to see the leaderboard, state so.\n\nYour approach.\nYour methodology of choosing the approach and associated parameters.\n\n Ensure you submitted the correct code on CLP that matches your output.  Zip up your report and codes for both programs in an archive called .zip or\n.tgz and submit the archive to Canvas.\nGrading:\nGrading for the Assignment will be split on your implementation (70%) and report (30%). Extra credit (1% of final grade) will be awarded to the top-3 performing algorithms. Note that extra credit throughout the semester will be tallied outside of Canvas and will be added to the final grade at the end of the semester.\nFiles: available on Canvas."
  },
  {
    "objectID": "posts/1eba76b5-40b0-40d8-a79d-f904cb79ea83/index.html",
    "href": "posts/1eba76b5-40b0-40d8-a79d-f904cb79ea83/index.html",
    "title": "Cybergod discord channel",
    "section": "",
    "text": "Cybergod discord channel\njoin at: https://discord.gg/y9BrdMfA\ni plan to intergrate it to my agi-computer-control repo."
  },
  {
    "objectID": "posts/03fe3393-6f4a-4d0a-8bd4-590a5fcaf23c/index.html",
    "href": "posts/03fe3393-6f4a-4d0a-8bd4-590a5fcaf23c/index.html",
    "title": "Cut Music Scenes With Lyrics and BPM",
    "section": "",
    "text": "Cut Music Segments With Lyrics and BPM\ndef compare(a,b,reverse=False):\nseg_low, seg_high = get_allowed_segments(bpm, low, high, tolerance=0.8) # the tolerance is compared with a common function called compare. it can be customized to output only value &gt;=1 or vice versa. candidates = sorted_lyrics_nearby_bpm_candidates + sorted_remained_bpm_candidates # priortize lyrics candidates."
  },
  {
    "objectID": "posts/14593aff-aac1-4a8b-8c8b-755028da9c6c/index.html",
    "href": "posts/14593aff-aac1-4a8b-8c8b-755028da9c6c/index.html",
    "title": "Create and Import Backups in StandardNotes",
    "section": "",
    "text": "Create and Import Backups in StandardNotes\nhttps://standardnotes.com/help/14/how-do-i-create-and-import-backups-of-my-standard-notes-data#:~:text=%20How%20to%20create%20backups%20of%20your%20data%3A,This%20file%20%20may%20be%20imported…%20More%20"
  },
  {
    "objectID": "posts/bba49021-6673-4e45-a968-1f04c96310b7/index.html",
    "href": "posts/bba49021-6673-4e45-a968-1f04c96310b7/index.html",
    "title": "Copilot_Codex alternative",
    "section": "",
    "text": "Copilot/Codex alternative\nuse chatgpt instead, when it is free.\ntsinghua (again!) introduced a similar open source model called codegeex, having better performance than incoder (by meta) and codegen with vscode plugin support, able to generate and translate code. the info is found on tuna events and you can download video/scripts for some events. trained on humaneval-x dataset for code generation. it also provides blog and podcast\nCodegen https://github.com/salesforce/CodeGen\ncopilot self-hosted powered by codegen (lots of vram, maybe for mac studio 128gb, however it only supports nvidia gpu): https://github.com/moyix/fauxpilot\ncode autocomplete https://github.com/shibing624/code-autocomplete\ncodegpt python token completion https://huggingface.co/mrm8488/CodeGPT-small-finetuned-python-token-completion\ncodegpt https://huggingface.co/microsoft/CodeGPT-small-py-adaptedGPT2 https://huggingface.co/microsoft/CodeGPT-small-py https://github.com/microsoft/CodeXGLUE/issues/75 https://github.com/microsoft/CodeXGLUE/issues/36\ncodebert https://github.com/microsoft/CodeBERT\ncode-gpt-neox https://github.com/Linyxus/code-gpt-neox\nCaptain Stack https://github.com/hieunc229/copilot-clone\nclara https://github.com/badboysm890/clara-copilot\ngpt-code-clippy https://github.com/CodedotAl/code-clippy-vscode https://github.com/ncoop57/gpt-code-clippy https://github.com/CodedotAl/gpt-code-clippy https://discuss.huggingface.co/t/pretrain-gpt-neo-for-open-source-github-copilot-model/7678?u=ncoop57 https://gpt3demo.com/apps/gpt-code-clippy-gpt-cc https://seart-ghs.si.usi.ch/ (github search engine)\nkite https://kite.com/integrations/jupyter/\nsecond mate https://github.com/samrawal/emacs-secondmate\nasm dude https://github.com/HJLebbink/asm-dude\nyoucompleteme https://github.com/ycm-core/YouCompleteMe\ncode-lms(polycoder) https://github.com/VHellendoorn/Code-LMs#models https://zenodo.org/record/6363556"
  },
  {
    "objectID": "posts/05aa3d8a-966e-4f04-93e2-db512876e110/index.html",
    "href": "posts/05aa3d8a-966e-4f04-93e2-db512876e110/index.html",
    "title": "Content Usage",
    "section": "",
    "text": "Content Usage\nUse the original transcript for paraphrasing, while using danmaku for joke generation."
  },
  {
    "objectID": "posts/fbc2fa61-504b-4912-a344-a33d1b9cce86/index.html#dns",
    "href": "posts/fbc2fa61-504b-4912-a344-a33d1b9cce86/index.html#dns",
    "title": "Clash route only github related domains to fastgithub",
    "section": "DNS",
    "text": "DNS\nuse clash official DNS settings to resolve issues related to domain resolution, especially when used as a system proxy.\ndocumentation\nto persist program using platform-specific service manager like nssm on windows:"
  },
  {
    "objectID": "posts/fbc2fa61-504b-4912-a344-a33d1b9cce86/index.html#macos",
    "href": "posts/fbc2fa61-504b-4912-a344-a33d1b9cce86/index.html#macos",
    "title": "Clash route only github related domains to fastgithub",
    "section": "macos",
    "text": "macos\nuse launchctl(launchd) or easyd"
  },
  {
    "objectID": "posts/fbc2fa61-504b-4912-a344-a33d1b9cce86/index.html#linux",
    "href": "posts/fbc2fa61-504b-4912-a344-a33d1b9cce86/index.html#linux",
    "title": "Clash route only github related domains to fastgithub",
    "section": "linux",
    "text": "linux\ncreate systemd need to change system wide proxy settings in init files\nor use monit, with control over the service itself.\nor shell script alike linuxNSSM"
  },
  {
    "objectID": "posts/c29ed5be-f207-437b-a415-26cdcc04d9af/index.html",
    "href": "posts/c29ed5be-f207-437b-a415-26cdcc04d9af/index.html",
    "title": "How to Clean Up Chocolatey’s Cache with the choco-cleaner.ps1 Script",
    "section": "",
    "text": "Chocolatey cleanup cache\npowershell choco-cleaner.ps1"
  },
  {
    "objectID": "posts/f69fd3ee-b6f1-480c-91cf-d84cbed6d9a2/index.html",
    "href": "posts/f69fd3ee-b6f1-480c-91cf-d84cbed6d9a2/index.html",
    "title": "Chatbot, Self-hosted Model, Cloud Deploy, Cloud services, Free website hosting service",
    "section": "",
    "text": "Chatbot, Self-hosted Model, Cloud Deploy, Cloud services, Free website hosting service\nvercel hosts frontend only apps, could be useful if you want.\n可以提取关键词然后到百度必应上面搜索 获取相关内容 注意语种一致性\nsearch huggingface with julia or python: huggingface_hub(python)\n可以用huggingface的api来翻译 对接英文的chatbot (blenderbot, dialo-gpt) add timeout to these api requests\n可以把训练好的中文chatbot放到huggingface上面去 用kaggle放 https://github.com/yangjianxin1/GPT2-chitchat\ncould use this method to generate title for videos. i mean generally.\ncould host the model on huggingface, or baidu aistudio, heroku or your own machine\nconfigure accelerated inference on huggingface (free for cpu, paid gpu): https://huggingface.co/docs/api-inference/quicktour\nhuggingface inference apis: https://huggingface.co/inference-api\nhuggingface conversational (chatbot) models: https://huggingface.co/models?pipeline_tag=conversational&sort=downloads\nheroku, use fastapi as interface: https://fastapi.tiangolo.com https://www.kaggle.com/getting-started/208405 https://signup.heroku.com\nheroku alternatives: back4app, google app engine\naistudio api, maybe you need to train or find a paddpepaddle based chatbot: https://ai.baidu.com/ai-doc/AISTUDIO/bk3e382cq#创建在线api服务 一个项目可以创建至多五个沙盒服务, 并选择其中一个沙盒服务部署为线上服务. 沙盒服务如果连续超过24小时无调用将自动调整为暂停状态. 线上服务如果连续超过14天无调用将自动调整为暂停状态.\npaddlenlp https://aistudio.baidu.com/aistudio/projectdetail/3723144?channelType=0&channel=0\npaddlepaddle chat model: plato2 https://github.com/PaddlePaddle/Knover https://github.com/PaddlePaddle/Knover/tree/develop/projects/PLATO-2 https://aistudio.baidu.com/aistudio/projectdetail/1886227?channelType=0&channel=0\n中文chatbot: https://github.com/zhaoyingjun/chatbot https://github.com/Dimsmary/Ossas_ChatBot\n教程 https://github.com/lcdevelop/ChatBotCourse https://github.com/fendouai/Awesome-Chatbot\n语料库 https://github.com/codemayq/chinese_chatbot_corpus"
  },
  {
    "objectID": "posts/a124af6a-c890-4416-9d60-5d6ea63ebc34/index.html",
    "href": "posts/a124af6a-c890-4416-9d60-5d6ea63ebc34/index.html",
    "title": "Cats video with lyrics_2",
    "section": "",
    "text": "Cats video with lyrics (Algorithm)\nFinally, the cats.\nTo harvest video by tags, authors, categorize them, count the views divided by time, model the predicted views and select only the best, original videos to upload.\nThe views on other platforms does not matter and views on other channels does not matter, in the long term. We might try to embrace them because of this number seen on others but we need real feedback on our channels.\nFilters can be generated by regular expressions, common patterns found in text, and indexed. Filters generated from data. We index filters, record them according to views.\nI am selling myself on cheap. Maybe not.\nUsing the same strategy of searching the web.\napi of weibo (this is news!):\nhttp://sinanews.sina.cn/interface/type_of_search.d.html?callback=initFeed&keyword=%E6%98%8E%E6%98%9F&page=1&type=siftWb&size=20&newpage=0&chwm=&imei=&token=&did=&from=&oldchwm=\nresponse:\ninitFeed({“status”:0,“msg”:“success”,“keywords”:[“明星”],“data”:{“feed1”:[{“user”:{“id”:1275327624,“name”:“圈内小馒头”,“url”:“http://m.weibo.cn/1275327624”,“profile_image_url”:“https://tvax3.sinaimg.cn/crop.0.0.587.587.50/001oj8Yoly8gvfweyv784j60gb0gb0td02.jpg?KID=imgbed,tva&Expires=1639964114&ssig=tXKjnI%2FcKK”,“verified_ico”:““},”title”:“#张艺兴#明白了！就是想求着跟张艺兴合作！张艺兴嫌他办事不行就退了！他恼羞成怒！更年期小气男跑微博泄愤造谣！还有他是个der 时尚博主啊？？？粉丝一半是买的！一半是之前蹭投票蹭的（就是会发明星的西装照投票你觉得谁穿西装最帅）类似这种的！！！现实中啥也不是的货！！#徐峰立# ​”,“image”:“http://wx1.sinaimg.cn/bmiddle/006rFoDCly1gxjrgfc8eaj30f50vodhp.jpg”,“video”:0,“url”:“http://www.weibo.com/1275327624/L6RC8CnwM”,“time”:“31分钟前”},{“user”:{“id”:1907445023,“name”:“ximalaya2020”,“url”:“http://m.weibo.cn/1907445023”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.996.996.50/71b14d1fly8gpv95u4nntj20ro0ro0ts.jpg?KID=imgbed,tva&Expires=1639964114&ssig=%2BYeO7pqPPX”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/yellow.png”},“title”:“#全世界最好的肖战[超话]##与肖战一起战放精彩# 与肖战一起战放精彩xz#肖战六神品牌代言人# 肖战六神品牌代言人！。 他们是牵肠挂肚的母子，是相濡以沫的爱人，是不离不弃的恋人，是同甘共苦的姐妹，是一个战壕扛过枪的战友，是胜 ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/1907445023/L6RC0kYff”,“time”:“32分钟前”},{“user”:{“id”:1860496124,“name”:“GoodBai”,“url”:“http://m.weibo.cn/1860496124”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.1080.1080.50/6ee4eafcly8gp1tgo4wuej20u00u0gmc.jpg?KID=imgbed,tva&Expires=1639964114&ssig=GsMXna%2FGRd”,“verified_ico”:““},”title”:“作为一名旁观者静静地吃了最近的瓜，相信很快就有结果了. 我只想说这么多年来，这么多明星出事的处理方式，陈老师是最爷们的[摊手] http://t.cn/RVvxlsh ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/1860496124/L6RBWwCp4”,“time”:“32分钟前”},{“user”:{“id”:1314608344,“name”:“新闻晨报”,“url”:“http://m.weibo.cn/1314608344”,“profile_image_url”:“https://tvax3.sinaimg.cn/crop.0.0.996.996.50/4e5b54d8ly8gdi5j8smmoj20ro0rot9w.jpg?KID=imgbed,tva&Expires=1639964114&ssig=CFe6jMRb5w”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/blue.png”},“title”:“#王力宏发文回应#【#王力宏称李靓蕾指控不实#，婚后一直生活在勒索威胁之下】12月19日晚，王力宏发长文回应风波，称李靓蕾指控为不实。​​​​王力宏称今天是自己人生中最难过的一天，是一场巨烈、巨痛的噩梦，他还表示自己和李靓蕾结婚后，一直生活在恐惧、勒索和威胁之下。&gt;&gt;，王力宏 ​”,“image”:“http://wx4.sinaimg.cn/bmiddle/001qXXGoly1gxjvll8j79j60u06dbqv502.jpg”,“video”:0,“url”:“http://www.weibo.com/1314608344/L6RBqzAMO”,“time”:“33分钟前”},{“user”:{“id”:7566155477,“name”:“天界水神布雨被冲下来的闲仙”,“url”:“http://m.weibo.cn/7566155477”,“profile_image_url”:“https://tvax1.sinaimg.cn/crop.0.0.664.664.50/008g2OFLly8gx2mi7uc2hj30ig0igmxs.jpg?KID=imgbed,tva&Expires=1639964114&ssig=L81vU5yTnv”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/yellow.png”},“title”:“#杨紫[超话]#yz#杨紫女心理师# yz#杨紫贺顿# 抬头仰望国旗 四射的光芒与夺目的红浑然一体 目光所至心之所向皆是信仰 抬头是国家 举目是你@杨紫 @杨紫 @杨紫 ｜杨紫机场｜杨紫新剧｜杨紫单身｜杨紫粉丝｜杨紫同款｜杨紫好看｜杨紫女神｜杨紫美女｜杨紫绝美｜杨紫超甜 ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/7566155477/L6RAYvjP2”,“time”:“34分钟前”},{“user”:{“id”:6192877122,“name”:“惊奇脑洞”,“url”:“http://m.weibo.cn/6192877122”,“profile_image_url”:“https://tvax1.sinaimg.cn/crop.0.0.828.828.50/006L6GeSly8gln1dtwrm1j30n00n03zr.jpg?KID=imgbed,tva&Expires=1639964114&ssig=ox25CCv7YY”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/yellow.png”},“title”:“我小时候居然演过《快乐星球》？原来我也长着明星脸？！#搞笑##搞笑视频##视频藏宝阁# http://t.cn/A6x3FUyG ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/6192877122/L6RAlzqis”,“time”:“36分钟前”},{“user”:{“id”:1839242362,“name”:“带我看看你的城市”,“url”:“http://m.weibo.cn/1839242362”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.996.996.50/6da09c7aly8gform61ilfj20ro0ro0uf.jpg?KID=imgbed,tva&Expires=1639964114&ssig=kbT1KTxBmS”,“verified_ico”:““},”title”:“#壹段评# 【#中国妇女报再评王力宏#事件：防范以“爱”为名的伤害，警惕脱离职场的风险】#中国妇女报评王力宏#近日，王力宏宣布离婚，其前妻李靓蕾在微博发布长文，控诉王力宏种种不端行为，引发关注与热议。，此次的网友议论还指向了一些令人深思的公共议题：全职主妇的“绝望” ​“,”image”:““,”video”:0,“url”:“http://www.weibo.com/1839242362/L6RAfhH37”,“time”:“36分钟前”},{“user”:{“id”:5637495678,“name”:“N太阳的阳”,“url”:“http://m.weibo.cn/5637495678”,“profile_image_url”:“https://tvax3.sinaimg.cn/crop.0.0.996.996.50/0069wm9Ely8fq5uelhg9cj30ro0rogmp.jpg?KID=imgbed,tva&Expires=1639964114&ssig=5Z7%2B9I5wBI”,“verified_ico”:““},”title”:“都扒明星 谁来扒我？扒出我的老实 扒出我的单纯 扒出我对爱情的始终如一 http://t.cn/RPzTEbX ​”,“image”:“http://wx4.sinaimg.cn/bmiddle/0069wm9Ely1gxjtiphxe3j32c0340hdu.jpg”,“video”:0,“url”:“http://www.weibo.com/5637495678/L6RzahwGW”,“time”:“39分钟前”},{“user”:{“id”:3675549863,“name”:“旺旺曉曉酥哦”,“url”:“http://m.weibo.cn/3675549863”,“profile_image_url”:“https://tvax1.sinaimg.cn/crop.0.0.512.512.50/db1470a7ly8glkuo4btqwj20e80e874r.jpg?KID=imgbed,tva&Expires=1639964114&ssig=fBwQujydh3”,“verified_ico”:““},”title”:“#王力宏出轨# 不是明星人设崩塌，只是因为是明星所以滤镜重，关注度高。现实里有的男人一样坏到不行，摊上这种不负责任只会逃避的男人，真的倒了八辈子的血霉。，一丘之貉。在莫名其妙地分手之后，在身边朋友都在帮我骂他渣男的时候，我还在为他背书，我说不要用恶 ​”,“image”:“http://wx2.sinaimg.cn/bmiddle/db1470a7gy1gxjuljgl7gj20ty0vswos.jpg”,“video”:0,“url”:“http://www.weibo.com/3675549863/L6Rslppzv”,“time”:“55分钟前”},{“user”:{“id”:7349735467,“name”:“NANA划条大路通CTiy”,“url”:“http://m.weibo.cn/7349735467”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.996.996.50/0081oJWrly8gxi80oofluj30ro0rotan.jpg?KID=imgbed,tva&Expires=1639964114&ssig=0Q%2BPfuSxPu”,“verified_ico”:““},”title”:“不管怎么说 这么多年我前前后后担来担去我还是很相信他。更喜欢看明星摔下神坛让子弹再飞一会不要丧失理智 晚安。 ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/7349735467/L6QdYb1k5”,“time”:“5小时前”}]}})\nwe need videos. you download it from baidu ai cloud.\nwe need feedback. we need this since this is how we try things.\nanything can be hackish, especially for this damn “we media”. anything can be popular, from basic bash script to regular expressions, based on how you looking at it. we shall not feed our audience full of something than another unless we know for sure it is our target.\nit is the power of the mirror! the feedback!\ncreate a fake, dummy project full of skeletons and then realize every step till we are done."
  },
  {
    "objectID": "posts/17754b81-ea0d-49d6-bcab-3093519c9c1b/index.html",
    "href": "posts/17754b81-ea0d-49d6-bcab-3093519c9c1b/index.html",
    "title": "Cats video with lyrics",
    "section": "",
    "text": "Cats video with lyrics (Netdisk VIP)\nFirst source the cats video. We are downloading it on baidu ai from baidu netdisk. Can you parse the download link directly?\nfound script from greasyfork.\nwhy the download speed is low? why there is only one connection? shall i use thunder?\nthe thunder can be invoked, may you test it here.\nso i agree all i need is some sort of communication, across these devices.\n宠物搞笑短视频素材集合，超过5800个宠物短视频素材 宠物狗短视频素材，宠物猫短视频素材百度网盘：https://pan.baidu.com/s/1I7OYc0eHWC29c0riMFlBEA提取码：5566\nhttps://d.pcs.baidu.com/file/65f4e6c89q4c739f29ac137152c495f6?fid=575343296-250528-687408209949397&dstime=1639908239&rt=sh&sign=FDtAERVJouK-DCb740ccc5511e5e8fedcff06b081203-qPfE%2Bw8zep5K3ktq4I7JoJsNP1g%3D&expires=8h&chkv=1&chkbd=0&chkpc=&dp-logid=110882094549216434&dp-callid=0&shareid=1364427735&r=427232106&resvsflag=1-12-0-1-1-1&vuk=2581136334&file_type=0\nunsure if it is encrypted. why i always found these little sites with massive resources?\nhttp://xm788.ys168.com/\nthe tool itself says it is avaliable for use vip cookies to download files from commandline. let’s try this.\nthe speed unfortunately remains the same. how about download some big files?\ncore-dumped. let’s try curl.\nlooks good. so we can either search and download a bunch of files with commandline, or download big files with android client.\ni quit the payment after all. the price is too high and i do not want to step into this shit. it seems that i can initialize the download anyway, not funny after all.\nso how do you make a point? how to source the cats video?\nsourcing the video is the fundamental step in video production, whether it is shotting by yourself or grabbing from the web, you must do this, with as little help as possible."
  },
  {
    "objectID": "posts/96b77ffa-e5b8-433d-8e93-5eb9f82ccca0/index.html",
    "href": "posts/96b77ffa-e5b8-433d-8e93-5eb9f82ccca0/index.html",
    "title": "Call python in clojure, clojure-python bridge",
    "section": "",
    "text": "Call python in clojure, clojure-python bridge\nlibpython-clj deep python integration in clojure\nembed clojure in python call clojure in python"
  },
  {
    "objectID": "posts/22e36cec-94b0-4067-a106-448815208c3b/index.html",
    "href": "posts/22e36cec-94b0-4067-a106-448815208c3b/index.html",
    "title": "CITIC Security",
    "section": "",
    "text": "CITIC Security\ntrade pw: 593104\ncitic bank card pw: 437216"
  },
  {
    "objectID": "posts/ecef01e3-4050-4436-aa89-8f1acc2cdff3/index.html",
    "href": "posts/ecef01e3-4050-4436-aa89-8f1acc2cdff3/index.html",
    "title": "Bookmark Browsing History Collection",
    "section": "",
    "text": "Bookmark Browsing Directory Tree Browsing History Collection\nUsing Kali forensic tool. (turned out not needed. just some googling for answers)\ndo you need to export your own good old notes? i mean mi notes. 2 phone numbers, 2 accounts. one with physical storage. the other you may want to download the mi note app and extract in the same way.\nOrganized under modifier termux ~/works/bookmark_dirtree_traverse. search via rg. maybe we can organize directory trees using other methods, like some javascript library with both a search tool and a browsing tool. we can host a search engine via javascript, only static resources and client side computation.\nthis client side search engine usage example can be found at /data/data/com.termux/files/home/storage/shared/works/milkshake_server and ./external/milkshake_server. the js searching library is called fuse.js.\nI have made this into meilisearch, and i have backed it up to github/james4ever0/notes2 and aliyunpan and baiduyunpan. desktop search experience is better. meilisearch consume too much ram. i consider to find alternatives with less ram consumption.\nusing rg will be much faster."
  },
  {
    "objectID": "posts/e819dfd3-6574-4937-b9b0-2585aec529e7/index.html",
    "href": "posts/e819dfd3-6574-4937-b9b0-2585aec529e7/index.html",
    "title": "Baidu Tieba Login (QR Code)",
    "section": "",
    "text": "Baidu Tieba Login (QR Code)\nAssigned a job.\nCloud Phone: http://www.ddyun.com/sem/pcddybdyunkong/?bd_vid=7609174489837191328 17756220843:fsfs5214\nQR Link: https://wappass.baidu.com/wp/?qrlogin&t=1640006201&error=0&sign=v1_13fa5a31cf31fa864475cbf3fd2fc&cmd=login&lp=pc&tpl=tb&adapter=3&logPage=traceId%3Apc_loginv4_1640006201%2ClogPage%3Aloginv4&qrloginfrom=pc&local=%E5%8D%97%E4%BA%AC\nThis job has no public data to refer. we need to monitor the tieba app. mitmproxy –mode socks5 –listen-port 8050 –save-stream-file logs Run mitmproxy without options to generate the mitm certificate. Install the certificate (usually ~/.mitmproxy/mitmproxy-ca-cert.cer) in the Android phone. It may be needed to change the extension to .crt to install it.\nfrida is needed to disable certificate-pinning, or if this is somehow possible. (also via justtrustme, xposed) https://hub.fastgit.org/httptoolkit/frida-android-unpinning https://httptoolkit.tech/blog/frida-certificate-pinning/\nsetenforce 0 to disable stack errors\nto connect to frida-server:\nhttps://github.com/15872998154/frida_termux\n./frida_server -l 0.0.0.0:27042\nfrida -H 127.0.0.1:27042 –codeshare sowdust/universal-android-ssl-pinning-bypass-2 -f com.baidu.tieba –no-pause\ni will not know if the client will be satisfied or not. i only know this would be very hard to solve. if not good i will quit.\nto read flow: mitmproxy -n –showhost -r logs.log\nprint xxd line and ascii parse only: cat logs2.log | xxd | awk ‘{print \\(1\" \"\\)NF}’\ncat logs2.log | xxd | awk ‘{print \\(1\" \"\\)NF}’ | grep -C 5 http://wap 0012f020: ss-Control-Allow 0012f030: -Methods,18:GET, 0012f040: OPTIONS,] 0012f050: 59:27:Access-Con 0012f060: trol-Allow-Origi 0012f070: n,24:http://wapp 0012f080: ass.baidu.com,]2 0012f090: 8:10:Connection, 0012f0a0: 10:keep-alive,]2 0012f0b0: 7:16:Content-Enc 0012f0c0: oding,4:gzip,]44\ncat logs2.log | xxd | awk ‘{print \\(1\" \"\\)NF}’ | grep -C 5 https://wap 001190e0: ite,]28:14:sec-f 001190f0: etch-mode,7:no-c 00119100: ors,]26:14:sec-f 00119110: etch-dest,5:styl 00119120: e,]40:7:referer, 00119130: 26:https://wappa 00119140: ss.baidu.com/,]3 00119150: 6:15:accept-enco 00119160: de 00119170: flate,]37:15:acc 00119180: ept-language,14: – 0011aed0: ite,]28:14:sec-f 0011aee0: etch-mode,7:no-c 0011aef0: ors,]27:14:sec-f 0011af00: etch-dest,6:scri 0011af10: pt,]40:7:referer 0011af20: ,26:https://wapp 0011af30: ass.baidu.com/,] 0011af40: 36:15:accept-enc 0011af50: d 0011af60: eflate,]37:15:ac 0011af70: cept-language,14 – 0011ccd0: -site,]28:14:sec 0011cce0: -fetch-mode,7:no 0011ccf0: -cors,]26:14:sec 0011cd00: -fetch-dest,5:st 0011cd10: yle,]40:7:refere 0011cd20: r,26:https://wap 0011cd30: pass.baidu.com/, 0011cd40: ]36:15:accept-en 0011cd50: coding,13:gzip, 0011cd60: deflate,]37:15:a 0011cd70: ccept-language,1 – 00121f40: -site,]28:14:Sec 00121f50: -Fetch-Mode,7:no 00121f60: -cors,]26:14:Sec 00121f70: -Fetch-Dest,5:im 00121f80: age,]40:7:Refere 00121f90: r,26:https://wap 00121fa0: pass.baidu.com/, 00121fb0: ]36:15:Accept-En 00121fc0: coding,13:gzip, 00121fd0: deflate,]37:15:A 00121fe0: ccept-Language,1 – 0012f550: in,]28:14:Sec-Fe 0012f560: tch-Mode,7:no-co 0012f570: rs,]27:14:Sec-Fe 0012f580: tch-Dest,6:scrip 0012f590: t,]256:7:Referer 0012f5a0: ,241:https://wap 0012f5b0: pass.baidu.com/w 0012f5c0: p/?qrlogin&t=163 0012f5d0: 9980306&error=0& 0012f5e0: sign=v1_f3b74f3a 0012f5f0: 21e355010985e711 – 00139700: ,]28:14:Sec-Fetc 00139710: h-Mode,7:no-cors 00139720: ,]26:14:Sec-Fetc 00139730: h-Dest,5:image,] 00139740: 40:7:Referer,26: 00139750: https://wappass. 00139760: baidu.com/,]36:1 00139770: 5:Accept-Encodin 00139780: defla 00139790: te,]37:15:Accept 001397a0: -Language,14:en- – 0013db70: 39997136312&tpl= 0013db80: tb&auto_statisti 0013db90: c=e2V2ZW50VHlwZT 0013dba0: p0b3VjaC1qcy1lcn 0013dbb0: Jvcn0=&extrajson 0013dbc0: =https://wappass 0013dbd0: .baidu.com/wp/?q 0013dbe0: rlogin&t=1639980 0013dbf0: 306&error=0&sign 0013dc00: =v1_f3b74f3a21e3 0013dc10: 55010985e7113869\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nwith a plugin to collect statistics: http://file.taotaoya.top/load/TT.rar\nthat guy wants me to discover barcode first.\ni may paste cookies here: https://termbin.com/lq5e\nuse ccrypt, xxd and nc to do transport. (do you have these?)\ncat cookies.log.cpt | xxd | nc termbin.com 9999 xxd -r ccrypt -c cookies.log.cpt\npasswd:abcdefg\na typical QR login link on android: https://wappass.baidu.com/wp/?qrlogin&t=1639929144&error=0&sign=v1_3b3e89197877163a12614a9a7f519&cmd=login&lp=pc&tpl=tb&adapter=3&clientfrom=native&qrloginfrom=native&local=%E9%93%9C%E9%99%B5\nparsed with elinks copied with termux-clipboard-set:\nLink: [1]canonical Link: [2]alternate (handheld)\n                     百度贴吧二维码登录--python爬虫\n[3]lxguang_tao 2021-01-22 18:11:49 547 收藏 分类专栏： [4]python 文章标签： [5]python 版权声明：本文为博主原创文章，遵循 [6]CC 4.0 BY-SA 版权协议，转载请附上原 文出处链接和本声明。 本文链接：[7]https://blog.csdn.net/qq_27644127/article/details/112987332 版权 [8][IMG] [9]python 专栏收录该内容 1 篇文章 0 订阅 订阅专栏\n百度贴吧二维码登录–python爬虫\n • \n      • [10]研究思路\n      • \n           • [11]探索过程\n           • [12]思路总结\n\n      • [13]代码实现\n      • \n           • \n                • [14]所需技术\n                • [15]代码\n\n      • [16]总结\n研究思路\n 如果阅读此文章的小伙伴之前研究过贴吧相关的接口的话，就会知道，那些需要登\n 录才能实现的功能接口，你去爬虫的话要携带一个Cookie BDUSS，有了它就会通过\n 身份验证。这个BDUSS也可以通过浏览器访问贴吧页面，从而获得，但在同一个浏\n 览器中如果更换帐号登录，那么你从这个浏览器中拿到的之前那个BDUSS就会失效\n （不可能这个浏览器永远挂着这个帐号，并且保证不会去修改密码）。为了获得一\n 个永不失效的BDUSS，我们可以通过登录方法来获取BDUSS，但我们不可能会使用这\n 个BDUSS去做退出和切换帐号操作，所以它一般拿到后就不会失效（除非改了密码\n ）。\n探索过程\n[17]二维码\n 1. 不管是贴吧首页，还是其他地方的贴吧登录页面，都会有这个二维码登录的地方 。我们第一步是看怎么去拿到这个二维码图片地址。\n 2. 思路：爬取这个页面，从页面元素中找到这个二维码连接，结果就是，二维码连 接不是响应页面加载出来的，那就说明是通过后续的接口返回的然后添加到页面 中的。所以我们接下来要去寻找加载二维码的接口。\n 3. 寻找接口：打开F12，切换到Network，刷新页面，你会看到一条类型为png的记 录，点开看到响应正是这张二维码图片 [18]二维码请求地址\n 4. 查看请求相关内容：地址，参数，类型。Get请求，有三个参数分别是sign,lp 和qrloginfrom，看到后两个参数的值都是pc。盲猜应该可以是固定值pc(电脑 端)。所以现在就只剩下一个参数需要搞清楚，那就是sign。 [19]在这里插入图片描述\n 5. 遵循代码从上往下运行的规则，这个sign肯定是在二维码加载前就获取到了，所 以我们要在它的上面的记录里寻找一下。经过一番寻找，最终 在“https://passport.baidu.com/v2/api/getqrcode?lp=pc&qrloginfrom=pc&gid=1527EF2-1333-475F-BA75-319AF40E53E7&callback=tangram_guid_1611304323880&apiver=v3&tt=1611304324028&tpl=tb&_=1611304324032” 的响应中找到了sign，当然响应中有整个图片链接。\n 6. 不过坑爹啊，这个请求中也有好多个参数。不过看到这个参数，发现有好几个都 是无意义的。tt和_我们看长度可以推断出应该是时间戳，经过验证，确实是当 时时间的时间戳。所以我们主要需要攻破的就是gid与callback。还是老样子， 先找gid，去上面找但是就是找不到。看gid像是那种唯一值，python中叫uuid。 既然找不到，那就可能是前端生成的，所以我们可以去找这个请求发起的js。看 看它这个参数到底是怎么来的。在F12 Source中按 Ctrl+Shift+F全局搜 索“v2/api/getqrcode”。 [20]参数\n 7. 通过搜索我们发现确实是前端生成的随机唯一值。那我们就可以放心大胆的自己 去生成了，当然要生成出来的格式一样。现在就只剩下callback了。正当我苦思 冥想找不到的时候，真的想破口而出：怎么这么难找啊，tmd烦死了。我后面发 现，嗯它后面那一串数字跟下面的时间戳基本一样。好家伙，这都能算一个参数 ，我是真的服。这样最后一个参数我们也能靠自己生成。这个接口拿下。 [21]在这里插入图片描述\n 8. 到现在我们已经实现了，（1）请求返回二维码地址的接口。（2）返回二维码图 片的地址。相当于我们做好了获取BDUSS的第一步。（长舒一口气）\n 9. 现在我们要进行第二部，扫码后进行怎样的处理。\n 扫码登录原理：网页生成二维码后，后面轮询进行一个请求，来返回当前二维码的\n 状态。\n 当二维码被扫后，访问二维码内容，服务端会进行处理（是否登录，做登录操作）\n 当然如果一直没有扫码请求，那么就一直循环请求，直到二维码过期为止。\n10. 查看Network后续内容，发现确实有一个接口在不停的请求。查看参数发现，都 是我们玩剩下的，除了channel_id是图片链接中的一个参数换了名字外，其他我 们都有办法获得。 [22]监听 11. 我们现在要做的就是模拟浏览器进行轮询请求，当请求返回正确登录的响应的时 候，发现它返回了 tangram_guid_1611307815857({“errno”:0,“channel_id”:“v1_cf81fb2823935db841b5395152de2”,“channel_v”:“{\"status\":0,\"v\":\"3f1a8f93cca689cead144ad405b03945\",\"u\":\"\"}”})  这跟登录有毛关系啊，发现后面它又调用了一个借口，看这名字就知道了， 就是它了。 12. /v3/login/main/qrbdusslogin [23]有这几个参数 13. 发现了联系，bduss是刚才轮询接口返回的。其他参数看着无意义的都直接用它 的。先调用再说。如果调用成功，返回的是一个JSON数据，但是并没有BDUSS 。tmd，都忘了我们去拿BDUSS的是去哪拿的吗。恍然大悟，Cookie啊。果然，从 响应中，看到写入浏览器了Cookie。 [24]cookie 14. 至此是通过二维码登录拿到BDUSS的全部过程。虽然看上去简单，但是实际去操 作的时候，还是有一些坑的。回过头来看看，那些坑也是必经之路吧，坑走过一 遍后，就更加印象深刻。\n思路总结\n总结一下： 基本上是从人的思考方式下手。从二维码从哪来开始，其实也就是一直 不断的在调接口，找参数，处理响应。不管哪一步，基本都离不开这三样。当然这次 的最重要的是理解二维码登录的实际原理，只有理解了它的原理才能去做好对策。\n代码实现\n所需技术\npython request模块，json模块，re模块，time, uuid\n代码\n““” QrCodeLogin.py 二维码登录 ““” ““” 1、访问首页，获取二维码 2、请求响应接口 3、。。。。 ““”\nimport requests, re, time, json, uuid\nclass qrcodeLogin: def init(self): self.get_qrcode_url = “https://passport.baidu.com/v2/api/getqrcode” self.unicast_url = “https://passport.baidu.com/channel/unicast” self.login_url = “https://passport.baidu.com/v3/login/main/qrbdusslogin” self.qrcode = “” self.gid = str(uuid.uuid4()).upper() self.callback = “” self.sign = “” self.bduss = “” self.headers = { “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:74.0) Gecko/20100101 Firefox/74.0” }\n def get_qrcode(self):\n     self.callback = \"tangram_guid_{}\".format(str(int(round(time.time() * 1000))))\n     parms = {\n         \"lp\":\"pc\",\n         \"qrloginfrom\": \"pc\",\n         \"gid\": self.gid,\n         \"callback\": self.callback,\n         \"apiver\": \"v3\",\n         \"tt\": int(round(time.time() * 1000)),\n         \"tpl\": \"tb\",\n         \"-\": int(round(time.time() * 1000))\n     }\n     html = requests.get(url=self.get_qrcode_url, params=parms, headers=self.headers, verify=False).content.decode('utf-8', errors='ignore')\n     # print(html)\n     p = re.compile('\"imgurl\":\"(.*?)\"')\n     p2 = re.compile('\"sign\":\"(.*?)\"')\n\n\n     qrcode = p.findall(html)\n     self.sign = p2.findall(html)\n     if len(qrcode) == 0:\n         return None\n     else:\n         print(\"https://\"+qrcode[0].replace(\"\\\\\", \"\"))\n         self.qrcode = \"https://\"+qrcode[0].replace(\"\\\\\", \"\")\n\n def unicast(self):\n     start = time.time()\n     errno = 1\n     status = 1\n     flag = True\n     pattern = re.compile('({.*})')\n     while(True):\n         end = time.time()\n         if (end - start) &gt; 300:\n             break\n         parms = {\n             \"channel_id\": self.sign,\n             \"qrloginfrom\": \"pc\",\n             \"gid\": self.gid,\n             \"callback\": self.callback,\n             \"apiver\": \"v3\",\n             \"tt\": int(round(time.time() * 1000)),\n             \"tpl\": \"tb\",\n             \"-\": int(round(time.time() * 1000))\n         }\n         jsons = requests.get(url=self.unicast_url, params=parms, headers=self.headers, verify=False)\n         html = jsons.content.decode('utf-8', errors=\"ignore\").replace('\\\\', '').replace('\"{', \"{\").replace('}\"', \"}\")\n         try:\n             if errno or status:\n                 message = json.loads(re.search(pattern, html).group())\n                 errno = message['errno']\n                 if errno == 0 and flag:\n                     flag = False\n                 elif errno == 0:\n                     status = message['channel_v']['status']\n             if not errno and not status:\n                 message = json.loads(re.search(pattern, html).group())\n                 self.bduss = message['channel_v']['v']\n                 BDUSS = self.login()\n                 print(BDUSS)\n                 return BDUSS\n         except Exception as e:\n             print(e)\n             break\n     return None\n\n def login(self):\n     parm = {\n         'v': int(round(time.time() * 1000)),\n         'u': 'https://tieba.baidu.com/index.html',\n         'bduss': self.bduss,\n         'loginVersion': 'v4',\n         'qrcode': '1',\n         'tpl': 'tb',\n         'apiver': 'v3',\n         'tt': int(round(time.time() * 1000)),\n         'traceid': None,\n         'time': round(time.time()),\n         'alg': 'v3',\n         'sig': 'EsdgfadNMU5rQVl4NWhSDFSDCVSDGFSdfsdfsf8xcVEveFNqanFGK2ZRdDBiejdXQXVhK1ZlRDZKMzsdfDSES==',\n         'elapsed': 3,\n         'shaOne': '00edf2343d07csdf23478b6ccd34f9a92290d3tg',\n         'callback': 'bd__cbs__o5224l',\n     }\n\n     login_r = requests.get(self.login_url, headers=self.headers, params=parm, verify=False)\n     str_html = login_r.content.decode('utf-8')\n     # print(str_html)\n     for i in login_r.cookies:\n         if i.name == \"BDUSS\":\n             print('登陆成功')\n             pname = re.compile('\"displayName\": \"(.*?)\"')\n             name_list = pname.findall(str_html)\n             # print(name_list)\n             if len(name_list) &gt; 0:\n                 name = name_list[0]\n                 return (i.value, name)\n             return (i.value, '')\n     return None\n\n\n def getImg(self):\n     img = requests.get(url=self.qrcode, headers=self.headers, verify=False)\n     # print(img.content)\n     # with open(\"tieba.gif\", 'wb') as w:\n     #     w.write(img.content)\n     return img.content\nif name == ‘main’: s = qrcodeLogin() s.get_qrcode() s.getImg() s.unicast()\n总结\n这一步是打开贴吧自动化大门的关键，有了它我们就能轻松做很多事情了。 贴上自己做的一些统计工具的截图，如果有小伙伴感兴趣，或者需要帮做小功能的， 可以评论私信哦。 附上下载地址：[25]地址 [26]在这里插入图片描述[27]在这里插入图片描述\n[28][IMG][29]lxguang_tao [30]关注 关注\n • 2\n   点赞\n • \n   踩\n • [31][IMG] [32]1\n   评论\n • [33][IMG] [34][IMG] [35][IMG] [36]0\n   收藏\n • [37]一键三连\n   一键三连\n • \n\n • [38][IMG]\n\n   扫一扫，分享海报\n专栏目录 [39]tieba_sign::mobile_phone: 百度贴吧多线程扫码登陆 自动签到 自动打码-源 码 05-07 [40]Tieba_Sign 百度贴吧多线程扫码登陆 / 自动签到 / 自动打码 经测试：在三个 帐号，一共207个贴吧的情况下，全部签到完成速度为5s左右。(Cookies登录情况下) Use：Python3.6以上 效果 使用教程 1.安装依赖 pip install -r requirements.txt # Centos yum install zbar -y # Ubuntu sudo apt-get install libzbar-dev -y 2.增加用户配置 (tieba_sign.py) user_lists = [‘用户 名’] # 用户名,例如[‘用户1’, ‘用户2’, ‘用户3’] 一共3个用户 # 请按照从前往后 的顺序来依次进行登陆 运行 python tieba_sign.py # 开始登录并签到 请注意，在 最新版本中，需要扫码登陆，程序运行的时候，会问你是否有百度贴吧 [41]python爬虫解决百度贴吧登陆验证码问题 [42]weixin_34236869的博客 06-29 222 [43]作为贴吧重度用户，写了个贴吧爬虫脚本 抄了一些别人的代码。记得有个验证 码解决的。可是忘了链接了，今天最终自己攻克了。 首先要让登陆须要验证码，不 停地登陆就好了。。。度娘非常快会加上验证码大法的。。。须要验证码的情况下， 直接登陆返回的错误信息是error=257 打开贴吧首页选择登陆，弹出验证码，找到验 证码的链接是 右键在新标签页中打开 注意到链接是 … 评论1 [44][IMG] [45] _____________________ 请先登录 后发表评论~ [46]表情包 插入表情 [47]表情包 代码片\n • HTML/XML\n • objective-c\n • Ruby\n • PHP\n • C\n • C++\n • JavaScript\n • Python\n • Java\n • CSS\n • SQL\n • 其它\n[48][ 评论 ] [49][ 评论 ] [50]Python爬虫系列之百度贴吧爬取 [51]Packager 11-28 176 [52]今天给的一个爬虫小事例，贴吧段子爬取这样一个小功能，数据呢仅仅娱乐，没 有恶意想法 若有侵权，请私信删除 此次用到的一个解析库Beautiful Soup，更轻量 简单地对数据进行解析，已获得目标数据 贴吧做的还是比较好，有一定的反爬机制 ，所以我们也应该有一定的应对措施，具体对应我们requests获取到的数据对应页面 源代码，通过观察发现数据的是否异步与注释等等反爬问题 以下是代码部分 # -*-… [53]Python 网络爬虫实战：爬取百度贴吧高清原图 最新发布 [54]亮出锋芒，剑指苍穹 11-15 654 [55]前段时间受哥儿们所托，爬取贴吧某帖子里的高清图片。 事情是这样的，我哥 们发现被贴吧中有好多漂亮的图片，想下载原图做壁纸，但是帖子里图片太多了，他 全都要，于是想让我帮忙写个爬虫，批量下载下来。 要求只有两个： 下载原图 实 现批量下载 话不多说，直接开始。 1. 分析网站 哥们提供的帖子地址： https://tieba.baidu.com/p/6516084831 。 先分析 url 组成，我们可以猜到 6516084831 是帖子的 id 。 在 勾选只看楼主，翻页 等这些操作之后，链接变成了 这样 ht\n[56]Python模拟二维码登录百度 [57]ljc545w的博客 12-11 872 [58]模拟二维码登录百度写在前面准备工作二维码地址登录状态获取gid登录参数代 码部分二维码展示获取cookie完整代码写在后面 写在前面 前段时间写了利用BDUSS 到达百度首页，这一次尝试使用二维码模拟登录，目前网上能搜到的相关内容基本失 效了，但是思路基本不变，无非是百度改了些参数。本文较为复杂，要求对python 的requests模块以及Chrome审查元素有一定了解，我不确定自己是否能完全讲明白， 讲多少是多少吧，各位看官请坐。 准备工作 二维码地址 打开Chrome浏览器，清理 掉baidu.com下的所有co [59]python模拟登陆百度 [60]kaerbuka的博客 07-02 786 [61]本文原地址 目录 说明 环境准备 登陆过程分析 登陆过程完整代码 有效性测试 说明 本文做的是百度二维码扫码登陆，至于为什么要做扫码登陆，主要是因为：1， 用账号密码登陆时，在测试过程中，如果清除cookie，会弹出验证码，这个倒是无所 谓，要命的是在登陆过程中有可能出发百度的账号保护机制，就算输入验证码，百度 还会强制要求手机短信进行二次验证，这个触发机制目前还不明确。 准备环境 准 备python… [62]Python爬取百度贴吧回帖中的微信号（基于简单http请求） [63]草小诚的博客 01-03 368 [64]前些日子媳妇儿有个需求，想要一个任意贴吧近期主题帖的所有回帖中的微信号 ，用来做一些微商的操作，你懂的。因为有些贴吧专门就是微商互加，或者客户留微 信的，还有专门特定用户群的贴吧，非常精准，我们一致认为比其他加人模式效率要 高，所以如果能方便快捷的提取微信号，价值还是很高的（事后来看微信号到购买转 化率约1%，已经很满意了）。 那需求很明确，说干就干，当天晚上就想把这个工具 实现出来，我呢打开电脑开始调研 … [65]17-用python爬取下载女神照片 [66]bigzql的博客 10-13 1万+ [67]今天咱们要爬取花瓣网 https://huaban.com/ 设计师寻找灵感的天堂!有海量的 图片素材可以下载,是一个优质图片灵感库 这次我们用 requests 登录花瓣网，爬取 页面，再用正则与json提取有用信息，最后把获取的图片信息 保存到本地 一 、用 到技术 python 基础 requests 登录页面获取session用户会话，下载图片 正则表达 式 提取页面的有用信息 json解析页面中的图片 二、 目标页面 https://huaban.com/search/?q=女神&catego [68]精心整理|Python爱好者社区历史文章合集（作者篇）–20190925从豆瓣获取 [69]小仙女说：但行好事，不问前程 09-25 4719 [70]精心整理|Python爱好者社区历史文章合集（作者篇） 参考文件地址 ：http://www.360doc.com/content/18/0801/00/2990557_774796873.shtml（供共同 学习python的同学食用） 若侵权，联系删除 7月16日更新： Python爬取起点中文网 小说排行榜信息（上海线下培训作业） 唯一小编王大… [71]python百度贴吧登录协议_python爬虫解决百度贴吧登陆验证码问题 [72]weixin_39974223的博客 12-03 166 [73]作为贴吧重度用户，写了个贴吧爬虫脚本抄了一些别人的代码。记得有个验证码 解决的。可是忘了链接了，今天最终自己攻克了。首先要让登陆须要验证码，不停地 登陆就好了。。。度娘非常快会加上验证码大法的。。。须要验证码的情况下，直接 登陆返回的错误信息是error=257打开贴吧首页选择登陆，弹出验证码，找到验证码 的链接是 右键在新标签页中打开 注意到链接是这个时候依据之前写的代码，判定登 陆成功是依据post登录… [74]python贴吧-qpython贴吧 [75]q6q6q的专栏 10-28 250 [76]广告关闭腾讯云双11爆品提前享，精选热门产品助力上云，云服务器首年88元起 ，买的越多返的越多，最高满返5000元！目录1. url的组成 2. 贴吧爬虫2.1. 只爬 贴吧第一页2.2. 爬取所有贴吧的页面 3. get和post的区别3.1. get请求3.2. post 请求3.3. 有道翻译模拟发送post请求…wd=%e7%bc%96%e7%a8%8b%e5%90%a7我们也可 以在pyth… [77]百度贴吧新玩法你会用吗？ [78]张一刻 08-19 161 [79]大家好，我是张一刻，专注于营销多年 今天我们来聊聊贴吧营销，可能在很多 人心里 贴吧已经落伍了，贴吧营销不被大家看好，但这还是一种渠道，不自己试试 怎能轻易否定呢？ 最近我正好在研究如何从贴吧导用户到微信公众号上，分享一下 心得，希望对你有帮助： 1、用二维码做头像2、将二维码做成签名图片（注册满3个 月才能设置签名档） 3、个人简介里添加微信号 4、发文章，正文中含品牌名、关键 词和微信号，标题含品牌关键… [80]【HTTP】百度贴吧WEB版签到流程分析 [81]大东的博客 01-03 542 [82]文章目录流程图接口抓包与分析获取二维码轮询扫码结果获取Cookie获取关注的 吧贴吧签到总结 流程图 接口抓包与分析 获取二维码 Url ：https://passport.baidu.com/v2/api/getqrcode 请求方式：Get 请求参数 ：lp=pc 虽然抓包发现有很多参数，但是经过实际测试发现只需要传lp这一个就可以 了，后续接口不再做说明 返回结果： { “imgurl”:… [83]贴吧二维码图秒删处理 [84]小胡实战引流 11-07 2898 [85]今天和大家分享的是这几天把 最流行 简单的 发二维码 这节课不是侧重实操， 如果大家看过我以前的视频，这个就很好做了 我们来看一下 ，最近发二维码有多么 猖狂 https://tieba.baidu.com/f?ie=utf-8&kw=%E8%AF%9A%E6%8B%9B%E4%BB%A3%E7%90%86&fr=search 大家可以看到这都是直接就发二维码图基本上都不处理… [86]贴吧一发二维码就被删！是你没掌握技术 [87]星空软件 03-07 5039 [88]贴吧防删图制作！在利用百度贴吧做推广引流的小伙伴们，你们是不是会遇到这 样的一个情况，自己发的图片有时候被度娘给秒删了？为什么会这样呢？今天聪明星 小编就来为你分享下百度贴吧发图片的技术干货，小板凳可要做好了！ 被度娘秒删 的帖子多少跟自己账号也有一定的关系，关于账号的问题，下期我们会在我的csdn账 号里面在分享《百度贴吧如何发帖？贴吧发帖防删技巧干货分享！》，此处就不在赘 述了。还有一种原因就是图片的… [89]Golang 百度云扫码登录 [90]ALakers的博客 12-24 262 [91]文件结构： http_client.go代码如下： package client import ( “bytes” “fmt” “io” “io/ioutil” “net/http” “net/http/cookiejar” “net/url” “strings” “time” ) // HTTPClient http client type HTTPClient struct { *http.Client UserAgent string } var ( UserAgen [92]1.爬虫基础——了解html&什么是爬虫 [93]python伊甸园的博客 10-10 3141 [94]众所周知：我们上网浏览的网页，他们的本质是一个又一个html页面。那什么 是html呢？可以这么理解，编写JAVA有JAVA的语言逻辑，编写Python有Python的语言 逻辑，编写网页就需要遵从html的语言逻辑，而编写好了的html就可以显示出来我们 所看到的网页了。 如下示例： 图1 图2 正如我们在上面所看到的，当我们查 看https://www.baidu.com/这个网址的时候，… [95]学会这招，小姐姐看你的眼神将不一样 热门推荐 [96]kimol君的博客 10-03 2万+ [97]学会这招，小姐姐看你的眼神将不一样前言一、爬虫分析二、爬取项目ID1.抓取 帖子的URL2.提取帖子中的UUID3.完整代码三、爬取项目的数据写在最后 前言 今天 某小丽同学来找我，有个实验需要用到轻松筹的数据进行一个分析。可是没有足够的 数据，如何办是好？ 乐于助人的我，当然不会置之不理~ （ps.毕竟是小姐姐嘛，拒 绝了不好，对叭） 于是乎，我抄起家伙，说干就干。 一、爬虫分析 通过简单的分 析，可以发现轻松筹提供了一个接口，可以返回某个项目的相关数据，具体如下： 地址如下，xxxxxx表示项目的UUID： h ©️2021 CSDN 皮肤主题: 游动-白 设计师:白松林 [98]返回首页 [99][IMG] [100]lxguang_tao CSDN认证博客专家 CSDN认证企业博客 码龄7年 [101][IMG] [102]暂无认证\n3 原创\n27万+ 周排名\n25万+ 总排名\n2242 访问\n[103][IMG] 等级\n44 积分\n14 粉丝\n6 获赞\n1 评论\n7 收藏 [104]GitHub [105]签到达人 [106]新秀勋章 [107]勤写标兵Lv1 [108]分享学徒 [109]私信 关注 [110]_____________________\n热门文章\n • [111]百度贴吧二维码登录--python爬虫 [112][IMG] [113]539\n • [114]C# 引用后visual studio不报错，生成报错 [115][IMG] [116]122\n • [117]windows系统下使用docker运行容器挂载卷报错问题 [118][IMG] [119]69\n分类专栏\n • [120][IMG] [121]python 1篇\n • [122][IMG] [123]C# 1篇\n最新评论\n • [124]百度贴吧二维码登录--python爬虫\n\n   [125]乎你: 代码之路任重道远，愿跟博主努力习之。\n您愿意向朋友推荐“博客详情页”吗？\n • \n   强烈不推荐\n • \n   不推荐\n • \n   一般般\n • \n   推荐\n • \n   强烈推荐\n[126]_____________________ 提交\n最新文章\n • [127]windows系统下使用docker运行容器挂载卷报错问题\n • [128]C# 引用后visual studio不报错，生成报错\n[129]2021年2篇 [130]2020年1篇\n[131]IFrame\n目录\n目录\n[132]IFrame\n分类专栏\n • [133][IMG] [134]python 1篇\n • [135][IMG] [136]C# 1篇\n实付元 [137]使用余额支付 点击重新获取 扫码支付 138 钱包余额 0\n抵扣说明：\n1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。 2.余额无法直接购买下载，可以购买VIP、C币套餐、付费专栏及课程。\n[139][IMG][140]余额充值\nReferences\nVisible links 1. https://blog.csdn.net/qq_27644127/article/details/112987332 2. file:///data/data/com.termux/files/home/works/tieba_job/content.html# 3. https://blog.csdn.net/qq_27644127 4. https://blog.csdn.net/qq_27644127/category_10614803.html 5. https://so.csdn.net/so/search/s.do?q=python&t=blog&o=vip&s=&l=&f=&viparticle= 6. http://creativecommons.org/licenses/by-sa/4.0/ 7. https://blog.csdn.net/qq_27644127/article/details/112987332 8. https://blog.csdn.net/qq_27644127/category_10614803.html 9. python https://blog.csdn.net/qq_27644127/category_10614803.html 10. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_1 11. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_5 12. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_37 13. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_39 14. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_40 15. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_42 16. file:///data/data/com.termux/files/home/works/tieba_job/content.html#_192 25. http://file.taotaoya.top/load/TT.rar 28. https://blog.csdn.net/qq_27644127 29. https://blog.csdn.net/qq_27644127 30. javascript:; 31. file:///data/data/com.termux/files/home/works/tieba_job/content.html#commentBox 32. file:///data/data/com.termux/files/home/works/tieba_job/content.html#commentBox 33. javascript:; 34. javascript:; 35. javascript:; 36. javascript:; 37. javascript:; 38. javascript:; 39. https://download.csdn.net/download/weixin_42122432/18441287 40. https://download.csdn.net/download/weixin_42122432/18441287 41. https://blog.csdn.net/weixin_34236869/article/details/86453208 42. https://blog.csdn.net/weixin_34236869 43. https://blog.csdn.net/weixin_34236869/article/details/86453208 44. javascript:void(0); 50. https://lmsoft.blog.csdn.net/article/details/84582372 51. https://blog.csdn.net/qq_41287993 52. https://lmsoft.blog.csdn.net/article/details/84582372 53. https://smartcrane.blog.csdn.net/article/details/121341944 54. https://blog.csdn.net/wenxuhonghe 55. https://smartcrane.blog.csdn.net/article/details/121341944 56. https://blog.csdn.net/ljc545w/article/details/111054624 57. https://blog.csdn.net/ljc545w 58. https://blog.csdn.net/ljc545w/article/details/111054624 59. https://blog.csdn.net/kaerbuka/article/details/94471507 60. https://blog.csdn.net/kaerbuka 61. https://blog.csdn.net/kaerbuka/article/details/94471507 62. https://blog.csdn.net/cxcjoker7894/article/details/85685115 63. https://blog.csdn.net/cxcjoker7894 64. https://blog.csdn.net/cxcjoker7894/article/details/85685115 65. https://cpython.blog.csdn.net/article/details/109063267 66. https://blog.csdn.net/bigzql 67. https://cpython.blog.csdn.net/article/details/109063267 68. https://blog.csdn.net/qq_32670879/article/details/101391892 69. https://blog.csdn.net/qq_32670879 70. https://blog.csdn.net/qq_32670879/article/details/101391892 71. https://blog.csdn.net/weixin_39974223/article/details/110545065 72. https://blog.csdn.net/weixin_39974223 73. https://blog.csdn.net/weixin_39974223/article/details/110545065 74. https://blog.csdn.net/q6q6q/article/details/109346811 75. https://blog.csdn.net/q6q6q 76. https://blog.csdn.net/q6q6q/article/details/109346811 77. https://blog.csdn.net/u013177154/article/details/99288349 78. https://blog.csdn.net/u013177154 79. https://blog.csdn.net/u013177154/article/details/99288349 80. https://blog.csdn.net/d745282469/article/details/103819585 81. https://blog.csdn.net/d745282469 82. https://blog.csdn.net/d745282469/article/details/103819585 83. https://blog.csdn.net/weixin_44027887/article/details/102948182 84. https://blog.csdn.net/weixin_44027887 85. https://blog.csdn.net/weixin_44027887/article/details/102948182 86. https://blog.csdn.net/qq_15159657/article/details/104721232 87. https://blog.csdn.net/qq_15159657 88. https://blog.csdn.net/qq_15159657/article/details/104721232 89. https://blog.csdn.net/ALakers/article/details/111619137 90. https://blog.csdn.net/ALakers 91. https://blog.csdn.net/ALakers/article/details/111619137 92. https://blog.csdn.net/weixin_42830697/article/details/102474659 93. https://blog.csdn.net/weixin_42830697 94. https://blog.csdn.net/weixin_42830697/article/details/102474659 95. https://blog.csdn.net/kimol_justdo/article/details/108912073 96. https://blog.csdn.net/kimol_justdo 97. https://blog.csdn.net/kimol_justdo/article/details/108912073 98. https://blog.csdn.net/ 99. https://blog.csdn.net/qq_27644127 100. lxguang_tao https://blog.csdn.net/qq_27644127 101. https://i.csdn.net/#/uc/profile?utm_source=14998968 102. 暂无认证 https://i.csdn.net/#/uc/profile?utm_source=14998968 103. https://blog.csdn.net/blogdevteam/article/details/103478461 109. https://im.csdn.net/chat/qq_27644127 111. https://blog.csdn.net/qq_27644127/article/details/112987332 112. https://blog.csdn.net/qq_27644127/article/details/112987332 113. https://blog.csdn.net/qq_27644127/article/details/112987332 114. https://blog.csdn.net/qq_27644127/article/details/111566657 115. https://blog.csdn.net/qq_27644127/article/details/111566657 116. https://blog.csdn.net/qq_27644127/article/details/111566657 117. https://blog.csdn.net/qq_27644127/article/details/118380655 118. https://blog.csdn.net/qq_27644127/article/details/118380655 119. https://blog.csdn.net/qq_27644127/article/details/118380655 120. https://blog.csdn.net/qq_27644127/category_10614803.html 121. https://blog.csdn.net/qq_27644127/category_10614803.html 122. https://blog.csdn.net/qq_27644127/category_10685120.html 123. https://blog.csdn.net/qq_27644127/category_10685120.html 124. https://blog.csdn.net/qq_27644127/article/details/112987332#comments_14757654 125. https://blog.csdn.net/m0_50944918 127. https://blog.csdn.net/qq_27644127/article/details/118380655 128. https://blog.csdn.net/qq_27644127/article/details/111566657 129. https://blog.csdn.net/qq_27644127/article/month/2021/07 130. https://blog.csdn.net/qq_27644127/article/month/2020/12 131. https://kunpeng-sc.csdnimg.cn/?timestamp=1623163941/#/preview/8608?positionId=57&queryWord=&spm=1001.2101.3001.5001 132. https://kunpeng-sc.csdnimg.cn/?timestamp=1623163941/#/preview/8608?positionId=479&queryWord=&spm=1001.2101.3001.4834 133. https://blog.csdn.net/qq_27644127/category_10614803.html 134. https://blog.csdn.net/qq_27644127/category_10614803.html 135. https://blog.csdn.net/qq_27644127/category_10685120.html 136. https://blog.csdn.net/qq_27644127/category_10685120.html 137. javascript:; 139. https://i.csdn.net/#/wallet/balance/recharge 140. https://i.csdn.net/#/wallet/balance/recharge"
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#papers",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#papers",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Papers",
    "text": "Papers\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\nTransformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai, Zhilin Yang, Yiming Yang, William W. Cohen, Jaime Carbonell, Quoc V. Le and Ruslan Salakhutdinov.\n\n\nUses smart caching to improve the learning of long-term dependency in Transformer. Key results: state-of-art on 5 language modeling benchmarks, including ppl of 21.8 on One Billion Word (LM1B) and 0.99 on enwiki8. The authors claim that the method is more flexible, faster during evaluation (1874 times speedup), generalizes well on small datasets, and is effective at modeling short and long sequences.\n\n\nConditional BERT Contextual Augmentation by Xing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han and Songlin Hu.\nSDNet: Contextualized Attention-based Deep Network for Conversational Question Answering by Chenguang Zhu, Michael Zeng and Xuedong Huang.\nLanguage Models are Unsupervised Multitask Learners by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever.\nThe Evolved Transformer by David R. So, Chen Liang and Quoc V. Le.\n\n\nThey used architecture search to improve Transformer architecture. Key is to use evolution and seed initial population with Transformer itself. The architecture is better and more efficient, especially for small size models.\n\n\nXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.\n\n\nA new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE).\n“Transformer-XL is a shifted model (each hyper-column ends with next token) while XLNet is a direct model (each hyper-column ends with contextual representation of same token).” — Thomas Wolf.\nComments from HN:\n\n\nA clever dual masking-and-caching algorithm.\n\n\nThis is NOT “just throwing more compute” at the problem.\nThe authors have devised a clever dual-masking-plus-caching mechanism to induce an attention-based model to learn to predict tokens from all possible permutations of the factorization order of all other tokens in the same input sequence.\nIn expectation, the model learns to gather information from all positions on both sides of each token in order to predict the token.\n\nFor example, if the input sequence has four tokens, [“The”, “cat”, “is”, “furry”], in one training step the model will try to predict “is” after seeing “The”, then “cat”, then “furry”.\nIn another training step, the model might see “furry” first, then “The”, then “cat”.\nNote that the original sequence order is always retained, e.g., the model always knows that “furry” is the fourth token.\n\nThe masking-and-caching algorithm that accomplishes this does not seem trivial to me.\nThe improvements to SOTA performance in a range of tasks are significant – see tables 2, 3, 4, 5, and 6 in the paper.\n\n\n\n\nCTRL: Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar, Richard Socher et al. [Code].\nPLMpapers - BERT (Transformer, transfer learning) has catalyzed research in pretrained language models (PLMs) and has sparked many extensions. This repo contains a list of papers on PLMs.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Google Brain.\n\n\nThe group perform a systematic study of transfer learning for NLP using a unified Text-to-Text Transfer Transformer (T5) model and push the limits to achieve SoTA on SuperGLUE (approaching human baseline), SQuAD, and CNN/DM benchmark. [Code].\n\n\nReformer: The Efficient Transformer by Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya.\n\n\n“They present techniques to reduce the time and memory complexity of Transformer, allowing batches of very long sequences (64K) to fit on one GPU. Should pave way for Transformer to be really impactful beyond NLP domain.” — @hardmaru\n\n\nSupervised Multimodal Bitransformers for Classifying Images and Text (MMBT) by Facebook AI.\nA Primer in BERTology: What we know about how BERT works by Anna Rogers et al.\n\n\n“Have you been drowning in BERT papers?”. The group survey over 40 papers on BERT’s linguistic knowledge, architecture tweaks, compression, multilinguality, and so on.\n\n\ntomohideshibata/BERT-related papers\nSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by Google Brain. [Code] | [Blog post (unofficial)]\n\n\nKey idea: the architecture use a subset of parameters on every training step and on each example. Upside: model train much faster. Downside: super large model that won’t fit in a lot of environments.\n\n\nAn Attention Free Transformer by Apple.\nA Survey of Transformers by Tianyang Lin et al.\nEvaluating Large Language Models Trained on Code by OpenAI.\n\n\nCodex, a GPT language model that powers GitHub Copilot.\nThey investigate their model limitations (and strengths).\nThey discuss the potential broader impacts of deploying powerful code generation techs, covering safety, security, and economics.\n\n\nTraining language models to follow instructions with human feedback by OpenAI. They call the resulting models InstructGPT. ChatGPT is a sibling model to InstructGPT.\nLaMDA: Language Models for Dialog Applications by Google.\nTraining Compute-Optimal Large Language Models by Hoffmann et al. at DeepMind. TLDR: introduces a new 70B LM called “Chinchilla” that outperforms much bigger LMs (GPT-3, Gopher). DeepMind has found the secret to cheaply scale large language models — to be compute-optimal, model size and training data must be scaled equally. It shows that most LLMs are severely starved of data and under-trained. Given the new scaling law, even if you pump a quadrillion parameters into a model (GPT-4 urban myth), the gains will not compensate for 4x more training tokens."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#articles",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#articles",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Articles",
    "text": "Articles\n\nBERT and Transformer\n\nOpen Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing from Google AI.\nThe Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning).\nDissecting BERT by Miguel Romero and Francisco Ingham - Understand BERT in depth with an intuitive, straightforward explanation of the relevant concepts.\nA Light Introduction to Transformer-XL.\nGeneralized Language Models by Lilian Weng, Research Scientist at OpenAI.\nWhat is XLNet and why it outperforms BERT\n\n\nPermutation Language Modeling objective is the core of XLNet.\n\n\nDistilBERT (from HuggingFace), released together with the blog post Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT.\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations paper from Google Research and Toyota Technological Institute. — Improvements for more efficient parameter usage: factorized embedding parameterization, cross-layer parameter sharing, and Sentence Order Prediction (SOP) loss to model inter-sentence coherence. [Blog post | Code]\nELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning - A BERT variant like ALBERT and cost less to train. They trained a model that outperforms GPT by using only one GPU; match the performance of RoBERTa by using 1/4 computation. It uses a new pre-training approach, called replaced token detection (RTD), that trains a bidirectional model while learning from all input positions. [Blog post | Code]\nVisual Paper Summary: ALBERT (A Lite BERT)\n\n\n\nAttention Concept\n\nThe Annotated Transformer by Harvard NLP Group - Further reading to understand the “Attention is all you need” paper.\nAttention? Attention! - Attention guide by Lilian Weng from OpenAI.\nVisualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) by Jay Alammar, an Instructor from Udacity ML Engineer Nanodegree.\nMaking Transformer networks simpler and more efficient - FAIR released an all-attention layer to simplify the Transformer model and an adaptive attention span method to make it more efficient (reduce computation time and memory footprint).\nWhat Does BERT Look At? An Analysis of BERT’s Attention paper by Stanford NLP Group.\n\n\n\nTransformer Architecture\n\nThe Transformer blog post.\nThe Illustrated Transformer by Jay Alammar, an Instructor from Udacity ML Engineer Nanodegree.\nWatch Łukasz Kaiser’s talk walking through the model and its details.\nTransformer-XL: Unleashing the Potential of Attention Models by Google Brain.\nGenerative Modeling with Sparse Transformers by OpenAI - an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.\nStabilizing Transformers for Reinforcement Learning paper by DeepMind and CMU - they propose architectural modifications to the original Transformer and XL variant by moving layer-norm and adding gating creates Gated Transformer-XL (GTrXL). It substantially improve the stability and learning speed (integrating experience through time) in RL.\nThe Transformer Family by Lilian Weng - since the paper “Attention Is All You Need”, many new things have happened to improve the Transformer model. This post is about that.\nDETR (DEtection TRansformer): End-to-End Object Detection with Transformers by FAIR - :fire: Computer vision has not yet been swept up by the Transformer revolution. DETR completely changes the architecture compared with previous object detection systems. (PyTorch Code and pretrained models). “A solid swing at (non-autoregressive) end-to-end detection. Anchor boxes + Non-Max Suppression (NMS) is a mess. I was hoping detection would go end-to-end back in ~2013)” — Andrej Karpathy\nTransformers for software engineers - This post will be helpful to software engineers who are interested in learning ML models, especially anyone interested in Transformer interpretability. The post walk through a (mostly) complete implementation of a GPT-style Transformer, but the goal will not be running code; instead, they use the language of software engineering and programming to explain how these models work and articulate some of the perspectives they bring to them when doing interpretability work.\nPathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance - PaLM is a dense decoder-only Transformer model trained with the Pathways system, which enabled Google to efficiently train a single model across multiple TPU v4 Pods. The example explaining a joke is remarkable. This shows that it can generate explicit explanations for scenarios that require a complex combination of multi-step logical inference, world knowledge, and deep language understanding.\n\n\n\nGenerative Pre-Training Transformer (GPT)\n\nBetter Language Models and Their Implications.\nImproving Language Understanding with Unsupervised Learning - this is an overview of the original OpenAI GPT model.\n🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning by Hugging Face.\nThe Illustrated GPT-2 (Visualizing Transformer Language Models) by Jay Alammar.\nMegatronLM: Training Billion+ Parameter Language Models Using GPU Model Parallelism by NVIDIA ADLR.\nOpenGPT-2: We Replicated GPT-2 Because You Can Too - the authors trained a 1.5 billion parameter GPT-2 model on a similar sized text dataset and they reported results that can be compared with the original model.\nMSBuild demo of an OpenAI generative text model generating Python code [video] - The model that was trained on GitHub OSS repos. The model uses English-language code comments or simply function signatures to generate entire Python functions. Cool!\nGPT-3: Language Models are Few-Shot Learners (paper) by Tom B. Brown (OpenAI) et al. - “We train GPT-3, an autoregressive language model with 175 billion parameters :scream:, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.”\nelyase/awesome-gpt3 - A collection of demos and articles about the OpenAI GPT-3 API.\nHow GPT3 Works - Visualizations and Animations by Jay Alammar.\nGPT-Neo - Replicate a GPT-3 sized model and open source it for free. GPT-Neo is “an implementation of model parallel GPT2 & GPT3-like models, with the ability to scale up to full GPT3 sizes (and possibly more!), using the mesh-tensorflow library.” [Code].\nGitHub Copilot, powered by OpenAI Codex - Codex is a descendant of GPT-3. Codex translates natural language into code.\nGPT-4 Rumors From Silicon Valley - GPT-4 is almost ready. GPT-4 would be multimodal, accepting text, audio, image, and possibly video inputs. Release window: Dec - Feb. #hype\nNew GPT-3 model: text-Davinci-003 - Improvements:\n\n\nHandle more complex intents — you can get even more creative with how you make use of its capabilities now.\nHigher quality writing — clearer, more engaging, and more compelling content.\nBetter at longer form content generation.\n\n\nChatGPT blog post and link to the conversational interface.\n\n\nChatGPT is OpenAI’s newest language model fine-tuned from a model in the GPT-3.5 series (which finished training in early 2022), optimized for dialogue. It is trained using Reinforcement Learning from Human Feedback; human AI trainers provide supervised fine-tuning by playing both sides of the conversation.\nIs it evidently better than GPT-3 at following user instructions and context? People have noticed, ChatGPT’s output quality seems to represent a notable improvement over previous GPT-3 models.\n\n\n\nLarge Language Model (LLM)\n\nGPT-J-6B - Can’t access GPT-3? Here’s GPT-J — its open-source cousin.\nFun and Dystopia With AI-Based Code Generation Using GPT-J-6B - Prior to GitHub Copilot tech preview launch, Max Woolf, a data scientist tested GPT-J-6B’s code “writing” abilities.\nGPT-Code-Clippy (GPT-CC) - An open source version of GitHub Copilot. The GPT-CC models are fine-tuned versions of GPT-2 and GPT-Neo.\nGPT-NeoX-20B - A 20 billion parameter model trained using EleutherAI’s GPT-NeoX framework. They expect it to perform well on many tasks. You can try out the model on GooseAI playground.\nMetaseq - A codebase for working with Open Pre-trained Transformers (OPT).\nYaLM 100B by Yandex is a GPT-like pretrained language model with 100B parameters for generating and processing text. It can be used freely by developers and researchers from all over the world.\nBigScience’s BLOOM-176B from the Hugging Face repository [paper, blog post] - BLOOM is a 175-billion parameter model for language processing, able to generate text much like GPT-3 and OPT-175B. It was developed to be multilingual, being deliberately trained on datasets containing 46 natural languages and 13 programming languages.\nbitsandbytes-Int8 inference for Hugging Face models - You can run BLOOM-176B/OPT-175B easily on a single machine, without performance degradation. If true, this could be a game changer in enabling people outside of big tech companies being able to use these LLMs.\n\n\n\nAdditional Reading\n\nHow to Build OpenAI’s GPT-2: “The AI That’s Too Dangerous to Release”.\nOpenAI’s GPT2 - Food to Media hype or Wake Up Call?\nHow the Transformers broke NLP leaderboards by Anna Rogers. :fire::fire::fire:\n\n\nA well put summary post on problems with large models that dominate NLP these days.\nLarger models + more data = progress in Machine Learning research :question:\n\n\nTransformers From Scratch tutorial by Peter Bloem.\nReal-time Natural Language Understanding with BERT using NVIDIA TensorRT on Google Cloud T4 GPUs achieves 2.2 ms latency for inference. Optimizations are open source on GitHub.\nNLP’s Clever Hans Moment has Arrived by The Gradient.\nLanguage, trees, and geometry in neural networks - a series of expository notes accompanying the paper, “Visualizing and Measuring the Geometry of BERT” by Google’s People + AI Research (PAIR) team.\nBenchmarking Transformers: PyTorch and TensorFlow by Hugging Face - a comparison of inference time (on CPU and GPU) and memory usage for a wide range of transformer architectures.\nEvolution of representations in the Transformer - An accessible article that presents the insights of their EMNLP 2019 paper. They look at how the representations of individual tokens in Transformers trained with different objectives change.\nThe dark secrets of BERT - This post probes fine-tuned BERT models for linguistic knowledge. In particular, the authors analyse how many self-attention patterns with some linguistic interpretation are actually used to solve downstream tasks. TL;DR: They are unable to find evidence that linguistically interpretable self-attention maps are crucial for downstream performance.\nA Visual Guide to Using BERT for the First Time - Tutorial on using BERT in practice, such as for sentiment analysis on movie reviews by Jay Alammar.\nTuring-NLG: A 17-billion-parameter language model by Microsoft that outperforms the state of the art on many downstream NLP tasks. This work would not be possible without breakthroughs produced by the DeepSpeed library (compatible with PyTorch) and ZeRO optimizer, which can be explored more in this accompanying blog post.\nMUM (Multitask Unified Model): A new AI milestone for understanding information by Google.\n\n\nBased on transformer architecture but more powerful.\nMultitask means: supports text and images, knowledge transfer between 75 languages, understand context and go deeper in a topic, and generate content.\n\n\nGPT-3 is No Longer the Only Game in Town - GPT-3 was by far the largest AI model of its kind last year (2020). Now? Not so much.\nOpenAI’s API Now Available with No Waitlist - GPT-3 access without the wait. However, apps must be approved before going live. This release also allow them to review applications, monitor for misuse, and better understand the effects of this tech.\nThe Inherent Limitations of GPT-3 - One thing missing from the article if you’ve read Gwern’s GPT-3 Creative Fiction article before is the mystery known as “Repetition/Divergence Sampling”: &gt; when you generate free-form completions, they have a tendency to eventually fall into repetitive loops of gibberish.\nFor those using Copilot, you should have experienced this wierdness where it generates the same line or block of code over and over again.\nLanguage Modelling at Scale: Gopher, Ethical considerations, and Retrieval by DeepMind - The paper present an analysis of Transformer-based language model performance across a wide range of model scales — from models with tens of millions of parameters up to a 280 billion parameter model called Gopher.\nCompetitive programming with AlphaCode by DeepMind - AlphaCode uses transformer-based language models to generate code that can create novel solutions to programming problems which require an understanding of algorithms.\nBuilding games and apps entirely through natural language using OpenAI’s code-davinci model - The author built several small games and apps without touching a single line of code, simply by telling the model what they want.\nOpen AI gets GPT-3 to work by hiring an army of humans to fix GPT’s bad answers\nGPT-3 can run code - You provide an input text and a command and GPT-3 will transform them into an expected output. It works well for tasks like changing coding style, translating between programming languages, refactoring, and adding doc. For example, converts JSON into YAML, translates Python code to JavaScript, improve the runtime complexity of the function.\nUsing GPT-3 to explain how code works by Simon Willison.\nCharacter AI announces they’re building a full stack AGI company so you could create your own AI to help you with anything, using conversational AI research. The co-founders Noam Shazeer (co-invented Transformers, scaled them to supercomputers for the first time, and pioneered large-scale pretraining) and Daniel de Freitas (led the development of LaMDA), all of which are foundational to recent AI progress.\nHow Much Better is OpenAI’s Newest GPT-3 Model? - In addition to ChatGPT, OpenAI releases text-davinci-003, a Reinforcement Learning-tuned model that performs better long-form writing. Example, it can explain code in the style of Eminem. 😀"
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#educational",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#educational",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Educational",
    "text": "Educational\n\nminGPT by Andrej Karpathy - A PyTorch re-implementation of GPT, both training and inference. minGPT tries to be small, clean, interpretable and educational, as most of the currently available GPT model implementations can a bit sprawling. GPT is not a complicated model and this implementation is appropriately about 300 lines of code.\n\n\nTutorials\n\nHow to train a new language model from scratch using Transformers and Tokenizers tutorial by Hugging Face. :fire:"
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#videos",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#videos",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Videos",
    "text": "Videos\n\nBERTology\n\nXLNet Explained by NLP Breakfasts.\n\n\nClear explanation. Also covers the two-stream self-attention idea.\n\n\nThe Future of NLP by 🤗\n\n\nDense overview of what is going on in transfer learning in NLP currently, limits, and future directions.\n\n\nThe Transformer neural network architecture explained by AI Coffee Break with Letitia Parcalabescu.\n\n\nHigh-level explanation, best suited when unfamiliar with Transformers.\n\n\n\nAttention and Transformer Networks\n\nSequence to Sequence Learning Animated (Inside Transformer Neural Networks and Attention Mechanisms) by learningcurve."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#official-implementations",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#official-implementations",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Official Implementations",
    "text": "Official Implementations\n\ngoogle-research/bert - TensorFlow code and pre-trained models for BERT."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#other-implementations",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#other-implementations",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Other Implementations",
    "text": "Other Implementations\n\nPyTorch and TensorFlow\n\n🤗 Hugging Face Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL…) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch. [Paper]\nspacy-transformers - a library that wrap Hugging Face’s Transformers, in order to extract features to power NLP pipelines. It also calculates an alignment so the Transformer features can be related back to actual words instead of just wordpieces.\n\n\n\nPyTorch\n\ncodertimo/BERT-pytorch - Google AI 2018 BERT pytorch implementation.\ninnodatalabs/tbert - PyTorch port of BERT ML model.\nkimiyoung/transformer-xl - Code repository associated with the Transformer-XL paper.\ndreamgonfly/BERT-pytorch - A PyTorch implementation of BERT in “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”.\ndhlee347/pytorchic-bert - A Pytorch implementation of Google BERT.\npingpong-ai/xlnet-pytorch - A Pytorch implementation of Google Brain XLNet.\nfacebook/fairseq - RoBERTa: A Robustly Optimized BERT Pretraining Approach by Facebook AI Research. SoTA results on GLUE, SQuAD and RACE.\nNVIDIA/Megatron-LM - Ongoing research training transformer language models at scale, including: BERT.\ndeepset-ai/FARM - Simple & flexible transfer learning for the industry.\nNervanaSystems/nlp-architect - NLP Architect by Intel AI. Among other libraries, it provides a quantized version of Transformer models and efficient training method.\nkaushaltrivedi/fast-bert - Super easy library for BERT based NLP models. Built based on 🤗 Transformers and is inspired by fast.ai.\nNVIDIA/NeMo - Neural Modules is a toolkit for conversational AI by NVIDIA. They are trying to improve speech recognition with BERT post-processing.\nfacebook/MMBT from Facebook AI - Multimodal transformers model that can accept a transformer model and a computer vision model for classifying image and text.\ndbiir/UER-py from Tencent and RUC - Open Source Pre-training Model Framework in PyTorch & Pre-trained Model Zoo (with more focus on Chinese).\n\n\n\nKeras\n\nSeparius/BERT-keras - Keras implementation of BERT with pre-trained weights.\nCyberZHG/keras-bert - Implementation of BERT that could load official pre-trained models for feature extraction and prediction.\nbojone/bert4keras - Light reimplement of BERT for Keras.\n\n\n\nTensorFlow\n\nguotong1988/BERT-tensorflow - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\nkimiyoung/transformer-xl - Code repository associated with the Transformer-XL paper.\nzihangdai/xlnet - Code repository associated with the XLNet paper.\n\n\n\nChainer\n\nsoskek/bert-chainer - Chainer implementation of “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#transfer-learning-in-nlp",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#transfer-learning-in-nlp",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Transfer Learning in NLP",
    "text": "Transfer Learning in NLP\nAs Jay Alammar put it:\n\nThe year 2018 has been an inflection point for machine learning models handling text (or more accurately, Natural Language Processing or NLP for short). Our conceptual understanding of how best to represent words and sentences in a way that best captures underlying meanings and relationships is rapidly evolving. Moreover, the NLP community has been putting forward incredibly powerful components that you can freely download and use in your own models and pipelines (It’s been referred to as NLP’s ImageNet moment, referencing how years ago similar developments accelerated the development of machine learning in Computer Vision tasks).\nOne of the latest milestones in this development is the release of BERT, an event described as marking the beginning of a new era in NLP. BERT is a model that broke several records for how well models can handle language-based tasks. Soon after the release of the paper describing the model, the team also open-sourced the code of the model, and made available for download versions of the model that were already pre-trained on massive datasets. This is a momentous development since it enables anyone building a machine learning model involving language processing to use this powerhouse as a readily-available component – saving the time, energy, knowledge, and resources that would have gone to training a language-processing model from scratch.\nBERT builds on top of a number of clever ideas that have been bubbling up in the NLP community recently – including but not limited to Semi-supervised Sequence Learning (by Andrew Dai and Quoc Le), ELMo (by Matthew Peters and researchers from AI2 and UW CSE), ULMFiT (by fast.ai founder Jeremy Howard and Sebastian Ruder), the OpenAI transformer (by OpenAI researchers Radford, Narasimhan, Salimans, and Sutskever), and the Transformer (Vaswani et al).\nULMFiT: Nailing down Transfer Learning in NLP\nULMFiT introduced methods to effectively utilize a lot of what the model learns during pre-training – more than just embeddings, and more than contextualized embeddings. ULMFiT introduced a language model and a process to effectively fine-tune that language model for various tasks.\nNLP finally had a way to do transfer learning probably as well as Computer Vision could.\n\nMultiFiT: Efficient Multi-lingual Language Model Fine-tuning by Sebastian Ruder et al. MultiFiT extends ULMFiT to make it more efficient and more suitable for language modelling beyond English. (EMNLP 2019 paper)"
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#books",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#books",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Books",
    "text": "Books\n\nTransfer Learning for Natural Language Processing - A book that is a practical primer to transfer learning techniques capable of delivering huge improvements to your NLP models."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#other-resources",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#other-resources",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Other Resources",
    "text": "Other Resources\n\n\nExpand Other Resources\n\n\nhanxiao/bert-as-service - Mapping a variable-length sentence to a fixed-length vector using pretrained BERT model.\nbrightmart/bert_language_understanding - Pre-training of Deep Bidirectional Transformers for Language Understanding: pre-train TextCNN.\nalgteam/bert-examples - BERT examples.\nJayYip/bert-multiple-gpu - A multiple GPU support version of BERT.\nHighCWu/keras-bert-tpu - Implementation of BERT that could load official pre-trained models for feature extraction and prediction on TPU.\nwhqwill/seq2seq-keyphrase-bert - Add BERT to encoder part for https://github.com/memray/seq2seq-keyphrase-pytorch\nxu-song/bert_as_language_model - BERT as language model, a fork from Google official BERT implementation.\nY1ran/NLP-BERT–Chinese version\nyuanxiaosc/Deep_dynamic_word_representation - TensorFlow code and pre-trained models for deep dynamic word representation (DDWR). It combines the BERT model and ELMo’s deep context word representation.\nyangbisheng2009/cn-bert\nWillyoung2017/Bert_Attempt\nPydataman/bert_examples - Some examples of BERT. run_classifier.py based on Google BERT for Kaggle Quora Insincere Questions Classification challenge. run_ner.py is based on the first season of the Ruijin Hospital AI contest and a NER written by BERT.\nguotong1988/BERT-chinese - Pre-training of deep bidirectional transformers for Chinese language understanding.\nzhongyunuestc/bert_multitask - Multi-task.\nMicrosoft/AzureML-BERT - End-to-end walk through for fine-tuning BERT using Azure Machine Learning.\nbigboNed3/bert_serving - Export BERT model for serving.\nyoheikikuta/bert-japanese - BERT with SentencePiece for Japanese text.\nnickwalton/AIDungeon - AI Dungeon 2 is a completely AI generated text adventure built with OpenAI’s largest 1.5B param GPT-2 model. It’s a first of it’s kind game that allows you to enter and will react to any action you can imagine.\nturtlesoupy/this-word-does-not-exist - “This Word Does Not Exist” is a project that allows people to train a variant of GPT-2 that makes up words, definitions and examples from scratch. We’ve never seen fake text so real."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#tools",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#tools",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Tools",
    "text": "Tools\n\njessevig/bertviz - Tool for visualizing attention in the Transformer model.\nFastBert - A simple deep learning library that allows developers and data scientists to train and deploy BERT based models for NLP tasks beginning with text classification. The work on FastBert is inspired by fast.ai.\ngpt2tc - A small program using the GPT-2 LM to complete and compress texts. It has no external dependency, requires no GPU and is quite fast. The smallest model (117M parameters) is provided. Larger models can be downloaded as well. (no waitlist, no sign up required)."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#tasks",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#tasks",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Tasks",
    "text": "Tasks\n\nNamed-Entity Recognition (NER)\n\n\nExpand NER\n\n\nkyzhouhzau/BERT-NER - Use google BERT to do CoNLL-2003 NER.\nzhpmatrix/bert-sequence-tagging - Chinese sequence labeling.\nJamesGu14/BERT-NER-CLI - Bert NER command line tester with step by step setup guide.\nsberbank-ai/ner-bert\nmhcao916/NER_Based_on_BERT - This project is based on Google BERT model, which is a Chinese NER.\nmacanv/BERT-BiLSMT-CRF-NER - TensorFlow solution of NER task using Bi-LSTM-CRF model with Google BERT fine-tuning.\nProHiryu/bert-chinese-ner - Use the pre-trained language model BERT to do Chinese NER.\nFuYanzhe2/Name-Entity-Recognition - Lstm-CRF, Lattice-CRF, recent NER related papers.\nking-menin/ner-bert - NER task solution (BERT-Bi-LSTM-CRF) with Google BERT https://github.com/google-research.\n\n\n\n\nClassification\n\n\nExpand Classification\n\n\nbrightmart/sentiment_analysis_fine_grain - Multi-label classification with BERT; Fine Grained Sentiment Analysis from AI challenger.\nzhpmatrix/Kaggle-Quora-Insincere-Questions-Classification - Kaggle baseline—fine-tuning BERT and tensor2tensor based Transformer encoder solution.\nmaksna/bert-fine-tuning-for-chinese-multiclass-classification - Use Google pre-training model BERT to fine-tune for the Chinese multiclass classification.\nNLPScott/bert-Chinese-classification-task - BERT Chinese classification practice.\nfooSynaptic/BERT_classifer_trial - BERT trial for Chinese corpus classfication.\nxiaopingzhong/bert-finetune-for-classfier - Fine-tuning the BERT model while building your own dataset for classification.\nSocialbird-AILab/BERT-Classification-Tutorial - Tutorial.\nmalteos/pytorch-bert-document-classification - Enriching BERT with Knowledge Graph Embedding for Document Classification (PyTorch)\n\n\n\n\nText Generation\n\n\nExpand Text Generation\n\n\nasyml/texar - Toolkit for Text Generation and Beyond. Texar is a general-purpose text generation toolkit, has also implemented BERT here for classification, and text generation applications by combining with Texar’s other modules.\nPlug and Play Language Models: a Simple Approach to Controlled Text Generation (PPLM) paper by Uber AI.\n\n\n\n\nQuestion Answering (QA)\n\n\nExpand QA\n\n\nmatthew-z/R-net - R-net in PyTorch, with BERT and ELMo.\nvliu15/BERT - TensorFlow implementation of BERT for QA.\nbenywon/ChineseBert - This is a Chinese BERT model specific for question answering.\nxzp27/BERT-for-Chinese-Question-Answering\nfacebookresearch/SpanBERT - Question Answering on SQuAD; improving pre-training by representing and predicting spans.\n\n\n\n\nKnowledge Graph\n\n\nExpand Knowledge Graph\n\n\nsakuranew/BERT-AttributeExtraction - Using BERT for attribute extraction in knowledge graph. Fine-tuning and feature extraction. The BERT-based fine-tuning and feature extraction methods are used to extract knowledge attributes of Baidu Encyclopedia characters.\nlvjianxin/Knowledge-extraction - Chinese knowledge-based extraction. Baseline: bi-LSTM+CRF upgrade: BERT pre-training."
  },
  {
    "objectID": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#license",
    "href": "posts/4f49b888-583b-4d9f-a968-129f9848bd20/index.html#license",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "License",
    "text": "License\n\n\nExpand License\n\nThis repository contains a variety of content; some developed by Cedric Chee, and some from third-parties. The third-party content is distributed under the license provided by those parties.\nI am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer.\nThe content developed by Cedric Chee is distributed under the following license:\n\nCode\nThe code in this repository, including all code samples in the notebooks listed above, is released under the MIT license. Read more at the Open Source Initiative.\n\n\nText\nThe text content of the book is released under the CC-BY-NC-ND license. Read more at Creative Commons."
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#ai-apps-for-audio",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#ai-apps-for-audio",
    "title": "Audio and Music Tools",
    "section": "AI Apps for Audio",
    "text": "AI Apps for Audio\n\nCleanvoice AI - Get rid of filler words from your audio recordings\nPyTorchVideo · A deep learning library for video understanding research\nDescript - All-in-one audio/video editing, as easy as a doc.\nAuphonic\nRevoldiv\nAudioStellar\nGuitarML - Zak Jost Audio Enhancement Machine Learning\ntyiannak/pyAudioAnalysis: Python Audio Analysis Library: Feature Extraction, Classification, Segmentation and Applications\nlibrosa — librosa 0.8.1 documentation python package for music and audio analysis\nYaafe/Yaafe: Audio features extraction\nAsk HN: AI-Generated Music? | Hacker News\n\n\nAI Music Separation\n\nOpen Source Tools and Data for Music Source Separation License: CC-BY-NC\nSpleeter, open source music separation library from Deezer, from Accapella, Melody, Moises\nISSE\nSUDO RM RF : SUccessive DOwnsampling and Resampling of Multi-Resolution Features which enables a more efficient way of separating sources from mixtures\nDeep Audio : Audio Source Separation Without Any Training Data\n\n\n\nAI Music Recognition\n\nAudio Tag for recognize music"
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#audio-creation",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#audio-creation",
    "title": "Audio and Music Tools",
    "section": "Audio Creation",
    "text": "Audio Creation\n\nAudio and Music Programming\n\nAlda – Text-Based Programming Language for Music Composition - Hacker News\nmaximecb/noisecraft: Browser-based visual programming language and platform for sound synthesis.\nhelio.fm libre music composition software\nFaust Programming Language\n\n\n\nAI Audio and Music Generator\n\nAI Melody Generator\ntypedrummer\nJukebox\n2108.12290 Music Composition with Deep Learning: A Review\n\n\n\nAudio and Music Creation and Sharing\n\nBeepbox : BeepBox is an online tool for sketching and sharing instrumental melodies.\nJummbox : Jummbox is Beepbox modification (online tool for sketching and sharing chip tune melodies)."
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#wasm-audio-processing",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#wasm-audio-processing",
    "title": "Audio and Music Tools",
    "section": "WASM Audio Processing",
    "text": "WASM Audio Processing\n\nAmped Studio : audio processing, need login\nSoundation : audio processing, need login\nogv.js : audio processing\nAudio Processing\nLearning Syhthesizer and Sound\nMusic Coding\nWASM Synth WASM Music Synthesizer"
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#audio-player",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#audio-player",
    "title": "Audio and Music Tools",
    "section": "Audio Player",
    "text": "Audio Player\n\nOnline Audio Player\n\ncaptbaritone/webamp: Winamp 2 reimplemented for the browser\n\n\n\nPeer to Peer Audio\n\nSonoBus - peer to peer music"
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#audio-editor",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#audio-editor",
    "title": "Audio and Music Tools",
    "section": "Audio Editor",
    "text": "Audio Editor\n\nDesktop Audio Editor\n\nAudacity, #opensource\n\n\n\nOnline Audio Editor\n\nAudiomass, GithubAudio Editor"
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#other-audio-tools",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#other-audio-tools",
    "title": "Audio and Music Tools",
    "section": "Other Audio Tools",
    "text": "Other Audio Tools\n\nVB-Audio Virtual Apps audio output to audio input"
  },
  {
    "objectID": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#working-with-virtual-audio-tools",
    "href": "posts/72a7bba1-30d4-41d7-9870-fb1f423c0e8d/index.html#working-with-virtual-audio-tools",
    "title": "Audio and Music Tools",
    "section": "Working with Virtual Audio Tools",
    "text": "Working with Virtual Audio Tools\n\nAudio Recording - Transcription\nBenefits/drawbacks:\n\nWe cannot listen the audio output from playback apps\n\n\n\n\nVAC Audio Recording\n\n\nUse cases:\n\nRecord Zoom Webinar to Speechtexter, Google Docs etc.\n\n\n\nAudio Input Mixing\n\n\n\nAudio Input Mixing\n\n\nUse cases:\n\nRecord with multiphttps://raw.githubusercontent.com/irosyadi/vnote.image/master/vnotebook/app/music-audio-tool.md/20211023055947660_4903.pngP) to Audacity\nBroadcast with multiple input (our voice + music from AIMP) to Zoom, Youtube etc.\n\n\n\nAudio Output Mixing\n\n\n\nAudio Output Mixing\n\n\nSetting:\n\nOS Sound Setting\n\nOutphttps://raw.githubusercontent.com/irosyadi/vnote.image/master/vnotebook/app/music-audio-tool.md/20211023060503358_26770.pngine 1 VAC Microphone\n\nVAC Repeater Setting\n\nWave in: Line 1 VAC Microphone\nWave out: Speaker/Headphone\nStart\n\n\nUse cases:\n\nTranscribe (and listen) Zoom Seminar to Speaker and Speechtexter, Google Docs\nTranslate Youtube Video using Google Translate\n\n\n\nZoom Audio Recording/Transcription\n\n\n\nZoom Recording Transcription\n\n\n\n\nGoogle Meet Audio Transcription\n\nOpen Google Meet, usihttps://raw.githubusercontent.com/irosyadi/vnote.image/master/vnotebook/app/music-audio-tool.md/20211023061101034_12558.pngsing default Mic\n\nBut we cannot do both Speechtexter and Google Docs We cannot do both Speechtexter and Voice Note We can do both Google Meet and Speechtexter/VoiceNote/Dictanote We can do both Zoom and Speechtexter/VoiceNote/Dictanote"
  },
  {
    "objectID": "posts/6b28f3af-40cf-44d7-9c7f-eb9efb4f3897/index.html#offline-ducking",
    "href": "posts/6b28f3af-40cf-44d7-9c7f-eb9efb4f3897/index.html#offline-ducking",
    "title": "Audio Ducking",
    "section": "offline ducking",
    "text": "offline ducking\neditly can achieve audio ducking using audionorm"
  },
  {
    "objectID": "posts/6b28f3af-40cf-44d7-9c7f-eb9efb4f3897/index.html#online-streaming-ducking",
    "href": "posts/6b28f3af-40cf-44d7-9c7f-eb9efb4f3897/index.html#online-streaming-ducking",
    "title": "Audio Ducking",
    "section": "online streaming ducking",
    "text": "online streaming ducking"
  },
  {
    "objectID": "posts/86beabf3-3cc4-4baf-82af-8623f8ff5c2d/index.html",
    "href": "posts/86beabf3-3cc4-4baf-82af-8623f8ff5c2d/index.html",
    "title": "Articulated Animation",
    "section": "",
    "text": "Articulated Animation\nThis one is dead simple. Use real human to talk as you go.\nhttps://github.com/snap-research/articulated-animation"
  },
  {
    "objectID": "posts/5009bab9-c4bd-497b-9a11-635b5abe0b3f/index.html",
    "href": "posts/5009bab9-c4bd-497b-9a11-635b5abe0b3f/index.html",
    "title": "Anonymity and open access to internet",
    "section": "",
    "text": "Anonymity and open access to internet\nbugmenot shared accounts, shared credentials, shared username/password\nuse tor browser, tor daemon. still know nothing on torrc and the obfs4 bridges since none of these works, on linux. maybe snowflake would help?\nrelated links: https://github.com/radio24/TorBox/blob/master/etc/tor/torrc https://github.com/radio24/TorBox/blob/master/meek-azure https://github.com/darknet-book/tor-guide https://gist.github.com/ciktion82/8ae82e292af8a7bdb2bcb8055a3b4fab https://github.com/ValdikSS/GoodbyeDPI/releases https://github.com/krlvm/PowerTunnel https://github.com/krlvm/LibertyTunnel\nmeek-azure: Bridge meek 0.0.2.0:3 97700DFE9F483596DDA6264C4D7DF7641E1E39CE url=https://meek.azureedge.net/ front=ajax.aspnetcdn.com\ncan we connect to tor with tor browser? we can launch the instance, check avaliability and then move on, with socks5 direct connection.\ninaccurate system time may prevent tor from starting. the builtin tor bridges worked after i synced time with “ntpdate time.windows.com”. same for vmess protocol.\ntor will speedup if used without bridges inside speedy tunnels. maybe it is useful for visiting real .onion pages.\nhave found multiple pools under github tag “clash”. might found other pools with other tags.\nmeta proxy pools: https://github.com/alanbobs999/TopFreeProxies https://github.com/ZGQ-inc/overthefirewall/blob/main/docs/proxypool.md https://github.com/anaer/Sub\n##META PROXY POOLS## #1\nsearch for keywords: (feature of proxypool spiders) free proxies 目前共有抓取源 https://cn.bing.com/search?q=free+proxies+%E7%9B%AE%E5%89%8D%E5%85%B1%E6%9C%89%E6%8A%93%E5%8F%96%E6%BA%90\nhttps://fq.lonxin.net/ https://hellopool.herokuapp.com/ https://proxy.whuboy.com/ https://baby-besitgift.com/ http://111.229.220.110:5000/ http://66.112.210.60.16clouds.com/ http://149.248.8.112/ https://free.kingfu.cf/ https://proxy.yugogo.xyz/ #2 节点来源 pojiezhiyuanjun/freev2, 节点数量: 96 chfchf0306/clash, 节点数量: 367 xiyaowong/freeFQ, 节点数量: 170 freefq/free, 节点数量: 51 learnhard-cn/free_proxy_ss, 节点数量: 181 vpei/Free-Node-Merge, 节点数量: 100 colatiger/v2ray-nodes, 节点数量: 65 oslook/clash-freenode, 节点数量: 59 ssrsub/ssr, 节点数量: 40 Leon406/SubCrawler, 节点数量: 829 umelabs/node.umelabs.dev, 节点数量: 5 yu-steven/openit, 节点数量: 0 iwxf/free-v2ray, 节点数量: 14 ldir92664/Vmess-Actions, 节点数量: 57 Galaxy8053/v2ray, 节点数量: 0 Jsnzkpg/Jsnzkpg, 节点数量: 185 ermaozi/get_subscribe, 节点数量: 11 wrfree/free, 节点数量: 51 GreenFishStudio/GreenFish, 节点数量: 102 v2raydy/v2ray, 节点数量: 125 ObcbO/auto-subscribe, 节点数量: 12 电报群分享(https://t.me/Jsnzk/4664)节点池, 节点数量: 557 #3 节点池 未去重\n已剔除部分失效重复地址\nhttps://hello.stgod.com/\nhttps://proxies.bihai.cf/\nhttps://sspool.nl/\nhttps://proxypool-guest997.herokuapp.com/\nhttps://fq.lonxin.net/\nhttps://free886.herokuapp.com/\nhttps://proxypool.fly.dev/\nhttp://8.135.91.61/\nhttps://proxy.51798.xyz/\nhttps://sspool.herokuapp.com/\nhttps://us-proxypool.herokuapp.com/\nhttps://eu-proxypool.herokuapp.com/\nhttp://www.fuckgfw.tk/\nhttps://etproxypool.ga/\nhttps://free.kingfu.cf/\nhttps://www.linbaoz.com/\nhttps://www.qunima.cc/\nhttps://www.joemt.tk/\nhttps://smart.zxcyec.top/\nhttp://158.101.93.192/\nhttps://168.138.204.231/\nhttp://111.229.220.110:5000/\nhttps://hk.xhrzg2017.xyz/\nhttp://39.106.12.141:8081/\nhttp://213.188.195.234/\nhttps://outseen.tk/\nhttp://149.248.8.112/\nhttps://161.35.5.88/\nhttp://104.128.81.6:8080/\nhttp://wxshi.top:9090/\nhttp://104.168.95.4:8080/\nhttps://proxy.whuboy.com/\nhttps://zua426.cf/\nhttps://185.161.70.4/\nhttp://161.35.5.88:8082/\nhttp://213.188.195.217/\nhttps://de.sanshihui.win/\nhttp://124.127.108.210:12345/\nhttp://guobang.herokuapp.com/\nhttps://1rmb.tk/\nhttps://998988.xyz/\nhttps://alexproxy003.herokuapp.com/\nhttps://free.dswang.ga/\nhttps://free.zdl.im/\nhttps://fu.stgod.com/\nhttps://jiedian.faka77.tk/\nhttps://hellopool.herokuapp.com/\nhttps://origamiboy.herokuapp.com/\nhttps://proxy.suntiefeng.com/\nhttps://proxypoolss.fly.dev/\nhttps://ednovas.design/\nhttps://proxies.bihai.tk\n节点池 http://104.128.81.6:8080/\nhttp://104.168.95.4:8080/\nhttp://111.229.220.110:5000/\nhttp://118.31.77.3/\nhttp://123.114.18.182:1234/\nhttp://139.196.162.200:9090/\nhttp://140.238.39.99:8096/\nhttp://149.248.8.112/\nhttp://149.248.8.112:8081/\nhttp://149.28.158.124/\nhttp://152.70.254.216:1234/\nhttp://158.101.93.192/\nhttp://172.104.109.93:8081/\nhttp://213.188.195.217/\nhttp://213.188.195.234/\nhttp://39.106.12.141:8081/\nhttp://8.135.91.61/\nhttp://emby.luoml.eu.org/\nhttp://mengbai.fun:10001/\nhttp://www.mengbai.fun:10001/\nhttp://www.wxshi.top:9090/\nhttp://wxshi.top:9090/\nhttps://101.32.189.119/\nhttps://120.27.121.82/\nhttps://121.5.240.196:8443/\nhttps://122.10.97.150/\nhttps://122.51.185.18/\nhttps://132.145.82.138/\nhttps://132.226.17.214/\nhttps://132.226.22.43/\nhttps://138.3.217.61/\nhttps://149.248.8.112/\nhttps://152.70.254.216/\nhttps://161.35.5.88/\nhttps://168.138.204.231/\nhttps://172.104.109.93/\nhttps://185.161.70.4/\nhttps://192.3.251.87/\nhttps://1rmb.tk/\nhttps://23.95.166.151/\nhttps://97.64.31.155/\nhttps://emby.luoml.eu.org/\nhttps://etproxypool.cf/\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://hello.stgod.com/\nhttps://hk.xhrzg2017.xyz/\nhttps://hm2019721.ml/\nhttps://jd.jiangcan95.com/\nhttps://jiedian.faka77.tk/\nhttps://outseen.tk/\nhttps://proxies.bihai.cf/\nhttps://proxies.bihai.ml/\nhttps://proxy.51798.xyz/\nhttps://proxy.leefake.xyz/\nhttps://proxy.suntiefeng.com/\nhttps://proxy.whuboy.com/\nhttps://proxypool.fly.dev/\nhttps://proxypool.remon602.ga/\nhttps://proxypoolss.fly.dev/\nhttps://proxypoolv2.herokuapp.com/\nhttps://smart.zxcyec.top/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://upan.tk/\nhttps://www.linbaoz.com/\nhttps://www.proxypool.ml/\nhttps://233660.xyz/\nhttps://6166888.xyz/\nhttps://ditan.ml/\nhttp://emby.luoml.eu.org\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://free.mengbai.cf/\nhttps://free886.herokuapp.com/\nhttps://fu.stgod.com/\nhttps://hello.stgod.com/\nhttps://hm2019721.ml/\nhttps://outseen.tk/\nhttps://proxy.51798.xyz/\nhttps://proxy.purel.in/\nhttps://proxypool-guest997.herokuapp.com/\nhttps://proxypool.fly.dev/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://sspool.nl/\nhttps://www.linbaoz.com/\nhttps://zz.guicloud.xyz/\nhttps://www.linbaoz.com/\nhttps://proxy.purel.in/\nhttps://clashpool.ml/\nhttps://ditan.ml/\n爬虫节点池 http://104.128.81.6:8080/\nhttp://104.168.95.4:8080/\nhttp://111.229.220.110:5000/\nhttp://118.31.77.3/\nhttp://123.114.18.182:1234/\nhttp://139.196.162.200:9090/\nhttp://140.238.39.99:8096/\nhttp://149.248.8.112/\nhttp://149.248.8.112:8081/\nhttp://149.28.158.124/\nhttp://152.70.254.216:1234/\nhttp://158.101.93.192/\nhttp://172.104.109.93:8081/\nhttp://213.188.195.217/\nhttp://213.188.195.234/\nhttp://39.106.12.141:8081/\nhttp://8.135.91.61/\nhttp://emby.luoml.eu.org/\nhttp://mengbai.fun:10001/\nhttp://www.mengbai.fun:10001/\nhttp://www.wxshi.top:9090/\nhttp://wxshi.top:9090/\nhttps://101.32.189.119/\nhttps://120.27.121.82/\nhttps://121.5.240.196:8443/\nhttps://122.10.97.150/\nhttps://122.51.185.18/\nhttps://132.145.82.138/\nhttps://132.226.17.214/\nhttps://132.226.22.43/\nhttps://138.3.217.61/\nhttps://149.248.8.112/\nhttps://152.70.254.216/\nhttps://161.35.5.88/\nhttps://168.138.204.231/\nhttps://172.104.109.93/\nhttps://185.161.70.4/\nhttps://192.3.251.87/\nhttps://1rmb.tk/\nhttps://23.95.166.151/\nhttps://97.64.31.155/\nhttps://emby.luoml.eu.org/\nhttps://etproxypool.cf/\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://hello.stgod.com/\nhttps://hk.xhrzg2017.xyz/\nhttps://hm2019721.ml/\nhttps://jd.jiangcan95.com/\nhttps://jiedian.faka77.tk/\nhttps://outseen.tk/\nhttps://proxies.bihai.cf/\nhttps://proxies.bihai.ml/\nhttps://proxy.51798.xyz/\nhttps://proxy.leefake.xyz/\nhttps://proxy.suntiefeng.com/\nhttps://proxy.whuboy.com/\nhttps://proxypool.fly.dev/\nhttps://proxypool.remon602.ga/\nhttps://proxypoolss.fly.dev/\nhttps://proxypoolv2.herokuapp.com/\nhttps://smart.zxcyec.top/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://upan.tk/\nhttps://www.linbaoz.com/\nhttps://www.proxypool.ml/\n节点池 https://233660.xyz/\nhttps://6166888.xyz/\nhttps://ditan.ml/\nhttp://emby.luoml.eu.org\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://free.mengbai.cf/\nhttps://free886.herokuapp.com/\nhttps://fu.stgod.com/\nhttps://hello.stgod.com/\nhttps://hm2019721.ml/\nhttps://outseen.tk/\nhttps://proxy.51798.xyz/\nhttps://proxy.purel.in/\nhttps://proxypool-guest997.herokuapp.com/\nhttps://proxypool.fly.dev/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://sspool.nl/\nhttps://www.linbaoz.com/\nhttps://zz.guicloud.xyz/\nhttps://www.linbaoz.com/ https://proxy.purel.in/\nhttps://clashpool.ml/ https://ditan.ml/\n##META PROXY POOLS##\nclash needs clash.yaml.\ntrojan’s igniter supports one link only.\nhttps://github.com/YoulianBoshi/lantern-vpn\nit was seen that freefq/free is resourceful. it scrapes from all locations.\nhttps://git.io/v2free https://git.io/jmsgo\n##shared paid v2ray recommendation https://github.com/wantToDoSomeThing/ssSSRV2rayClashTrojan\n###misc 连接chrome商店的好帮手：http://googlehelper.net/ switchyomega：https://github.com/FelisCatus/SwitchyOmega origin：https://github.com/gorhill/uBlock 百度药丸: https://www.baidu.com/s?ie=utf-8&f=3&rsv_bp=1&tn=baidu&wd=百度药丸插件 域名申请：https://www.kocpc.com.tw/archives/180195 简悦阅读模式（屏蔽广告）：https://chrome.google.com/webstore/detail/simpread-reader-view/ijllcpnolfcooahcekpamkbidhejabll/related?hl=zh-CN\n###proxies web代理 https://proxybrowser.xyz/ https://github.com/EtherDream/jsproxy/ https://demo.glyptodon.com http://webproxy.to/ https://www.rabb.it https://weboas.is/ https://www.anyproxy.cn https://www.anyproxy.top (挂了) https://cn.bing.com/translator/ (挂了) https://proxy.zagon.net.pe https://www.croxyproxy.com https://unblocksite.site/ 代理网址服务器列表 代理服务器列表的使用\nhttps://hoochanlon.github.io/fq-book/#/only/gatherproxy\nhttp://free-proxy.cz http://www.freeproxylists.net http://free-proxy-list.net http://www.my-proxy.com/free-proxy-list.html http://www.proxylists.net http://sockslist.net http://www.myiptest.com/staticpages/index.php/Free-SOCKS5-SOCKS4-Proxy-lists.html http://www.proxyfire.net/index.php?pageid=ProxyLists http://www.samair.ru/proxy http://www.gatherproxy.com/\n###mirror Google镜像\nhttp://ac.scmor.com https://google.jiongjun.cc https://g.zmirrordemo.com https://www.gotype.tk http://www.hlhmf.com/ YouTube镜像 https://ytb-pc.zmirrordemo.com https://youtube.speeder.cf/ （登陆密码和账号都是speeder.club） http://wall.qiqiblog.cn\n\n\ncurated list: https://github.com/hoochanlon/w3-goto-world/tree/master/科学上网、暗网、零网/免费ss、ssr、vmess分享 免费ss/ssr/vmess分享 使用须知 科学上网前，推荐阅读 《这本书能让你连接互联网》，并结合 WebSieUseful 相信定能有所收获\nnotice 部分链接为贴子、博客或1-3个测试型的ss分享站点，也有可能存在长期未更新，有待观察 封锁越来越严重，镜像站点失效频繁，更新的意义已经不是很大了… heroku的免费配额与限制 Network Bandwidth/流量: 2TB/month – Soft Shared DB processing/并发数: Max 200msec per second CPU time – Soft Dyno RAM usage/使用运行内存: 512MB – Hard Slug Size/存储空间: 300MB – Hard Request Length/请求时间: 30 seconds – Hard 提示Application error，是由于访问量占用内存溢出或因各项服务流量耗尽而停止服务\n关于爬虫站点 搭建的ss分享爬虫站点所爬取到的部分免费账号存在付费代理宣传内容，请自行分辨，谨防被骗\n如果遇到打不开的站点请参考这个教程 可解DNS污染，对封IP的站点无效，ss分享站点被封ip的可能性，感觉也倾向性也开始…已经很大了(已经是了…)\nhttps://hoochanlon.github.io/fq-book/#/dns&hosts/dnscrypt\n如果斩草除根是不是该这样呢？\nhttps://hoochanlon.github.io/fq-book/#/append/get-method\nchip https://52bp.org https://iyideng.cloud/ https://www.duyaoss.com/page/1/ https://jichang.fanqiangdang.com/ v2ray https://connect.freev2ray.org/ https://v2ray.cat/ https://v2ray.party/ https://my.freev2ray.org/ https://v2fire.tk/ https://get.freev2ray.com/ https://freev2.org v2ray的账号分享站点目前较少\n请参考fq-book中的教程再访问如下站点 https://www.myexplor.me https://github.com/free-ss/free-ss.site https://node.umelabs.dev/ https://gdmi.weebly.com/3118523398online.html https://github.com/ermaozi/get_subscribe https://vpncn.blogspot.com/ http://nulastudio.org/Freedom/ https://www.youneed.win/free-ssr https://www.youneed.win/free-ss https://free.ss-ssr.com https://toolher.com/ss https://ssrfree.tk/ https://lncn.org/ https://inssr.pro/free http://cacss.me/ https://fanqiangdang.com https://fast.ishadowx.net http://softpen.net http://52ss.fun/ https://free0.gyteng.com/ http://shadowsocks.hk/ https://shadowsocksr.cat/ https://ss.freess.org/ https://ss.ishadowx.com http://webosss.com/tool/socket https://free.gyteng.com/ https://www.nutgeek.com/ssshadowsocks https://share-shadowsocksr.herokuapp.com https://share-shadowsocks.herokuapp.com https://www.freevpn.pw/zh-cn/ https://www.ssrshare.com https://fangeqiang.com/408.html https://get.ishadowx.net https://get.freess.today https://tool.ssrshare.com/tool/free_ssr https://free-ss.site https://global.ishadowx.net http://www.52ssr.net/ https://www.wuwweb.com/ https://free.yitianjianss.com https://www.vpn168.net https://www.go2free.xyz/ https://biulink.club/ https://www.flyzy2005.com/fan-qiang/shadowsocks/free-ss-account/ https://jiedian5.com https://free.ss-ssr.com/ http://www.scdark.cn/?p=363 https://gdmi.weebly.com/3118523398online.html https://pdf-lib.org/Home/Details/2638 https://freessr.win https://blog.mxpkx.com/index.php/archives/118/ http://freefq.com/ss/ 镜像站点 https://trial.ssbit.win http://free-ss.tk v2ray订阅源 https://raw.githubusercontent.com/AmazingDM/sub/master/v2ray_ssrshare.com ssr订阅源 https://www.nutgeek.cn/newsubscribe/ https://prom-php.herokuapp.com/cloudfra_ssr.txt http://share-shadowsocks.herokuapp.com/full/subscribe http://share-shadowsocksr.herokuapp.com/subscribe?valid=1 https://raw.githubusercontent.com/AmazingDM/sub/master/ssrshare.com https://github.com/liesauer/Free-SS-SSR https://yzzz.ml/freessr https://www.liesauer.net/yogurt/subscribe?ACCESS_TOKEN=DAYxR3mMaZAsaqUb telegram 订阅 https://t.me/freeshadowsock https://t.me/gyjclub https://t.me/TGSoBot?start=f_v https://t.me/vpnchina https://t.me/XRAcc https://t.me/TelMTProto https://t.me/apkdl_bot https://t.me/TgProxies https://t.me/zonghe_info https://t.me/youmtp https://t.me/outlinex 分享邮箱 * toyoooooooooooo@gmail.com (doub.io)\nye515430@gmail.com (yitianjianss) ss@rohankdd.com (free-ss.site) 搜索相似的网站 https://www.similarsites.com\n已失效 http://ssr.wangzhan.gq/ https://doub.io https://www.puffss.com/ https://freess.cx https://shadowsocksph.space https://free.4kvpn.com https://freess.pw https://doub.loan https://freemz.tk/t/5 https://52ssr.cn http://www.honsuv.com/?post=90 https://newdoub.com https://en.ss8.fun http://www.vpn168.tk https://5l44.pw/ http://www.ssrfx.com http://freeoutline.org/zh\n付费保留（观察） 可能到时候会用到的付费节点，虽然翻墙一直是蹭网，付费来说，个人用vpn的可能性更大些\nhttps://rixcloud.me/ ###############\ntutorial: https://hoochanlon.github.io/fq-book/#/ https://github.com/hoochanlon/fq-book\nnew github mirror: https://hub.fastgit.xyz\n\n\n\n下载链接 raw.githubusercontent.com 的实际地址\ncodeload.github.com\nraw.githubusercontent.com 替换raw.staticdn.net\nopenit.ml\ndon’t know how it was updated. i have removed google ads with lucky patcher: https://github.com/bannedbook/v2ray.vpn\nhttps://github.com/hoochanlon/w3-goto-world\nhttps://github.com/oslook/clash-freenode\nauto scraping vmess links https://github.com/zu1k/proxypool\npopular tutorial: https://github.com/Alvin9999/new-pac\nhttps://www.v2rayfree.eu.org\nhttps://github.com/anran-world/Anranawsl\n52bp.icu\nhttps://github.com/aiboboxx/v2rayfree\nlearn keywords and search them against given platforms\nermaozi/get_subscribe\nhttps://github.com/ermaozi/get_subscribe\nhttps://fanqiangdang.com\np2p vpn:\nhttps://www.freepn.org\nuse continuously updated v2ray providers, or set it up your own.\nlucktu.com supernode.ml\nsef-hosted vps that can be paid:\nhttps://github.com/xiaoming2028/FreePAC/wiki/Hostwinds、搬瓦工、Hostinger、vutlr-四家VPS主机商速度对比测评\nworking providers:\nlantern, tor, xx-net, tulingx, geph4\nhttps://t.me/tor_bridges\nbuiltin obfs4 bridges\nfrontdesk@torproject.org\nSnowflake: uses ephemeral proxies to connect to the Tor network. It’s available in Tor Browser. You can select Snowflake from Tor Browser’s built-in bridge dropdown. Private and unlisted obfs4 bridges: contact our Telegram Bot @GetBridgesBot and type /bridges. Or send an email to frontdesk@torproject.org with the phrase “private bridge” in the subject of the email. If you are tech-savvy, you can run your own obfs4 bridge from outside China. Remember that bridges distributed by BridgeDB, and built-in obfs4 bridges bundled in Tor Browser most likely won’t work. meek-azure: makes it look like you are browsing a Microsoft website instead of using Tor. However, because it has a bandwidth limitation, this option will be quite slow. You can select meek-azure from Tor Browser’s built-in bridges dropdown.\nhttps://9.234456.xyz/abc.html?t=567\nsearch for v2ray ssr information in irc chats or social media"
  },
  {
    "objectID": "posts/0b9b28a9-fa14-4135-ac76-6468356ea16b/index.html",
    "href": "posts/0b9b28a9-fa14-4135-ac76-6468356ea16b/index.html",
    "title": "Android 10 clipboard issue for scrcpy",
    "section": "",
    "text": "Android 10 clipboard issue for scrcpy\ncom.github.kr328.clipboard.ClipboardProxy.getPrimaryClip\nMagisk Module: Riru - Clipboard Whitelist will white list clipboard manager app.\nhttps://github.com/Kr328/Riru-ClipboardWhitelist\nhttps://t.me/kr328_riru_modules\nscript.sh:\nscrcpy -K -S 2&gt;&1 | python3 reader.py\nreader.py:\nimport os\nimport subprocess\nimport re\n\nclass Response(object):\n    status = None\n    data = None\n\n\ndef parseResponse(resultString):\n    response = re.findall(r\"^Broadcasting: Intent { flg=0x400000 cmp=ch.pete.adbclipboard/.ReadReceiver }\\nBroadcast completed: result=-1, data=\\\"((.*\\n?)+)\\\"$\",resultString)[0][0]\n    return response\n\ndef readFromDevice():\n    adbProcess = subprocess.Popen(\n        ['adb',\n            'shell', 'am',\n            'broadcast',\n            '-n', 'ch.pete.adbclipboard/.ReadReceiver'],\n        stdout=subprocess.PIPE)\n    resultString = adbProcess.communicate()[0]\n    print(\"read device response:\\n{}\"\n              .format(resultString))\n    try:\n        result = parseResponse(resultString.decode(\"utf-8\"))\n        print(\"raw:\\n\",resultString)\n        print(\"result:\\n\",result)\n        return result\n    except:\n        traceback.print_exc()\n    return\n\n\ndef setClipboard(data):\n    with open(\"target.out\",\"w+\",encoding=\"utf-8\") as f:\n        f.write(data)\n    fetch_clipboard = \"cat target.out | xclip -selection c\" \n    os.system(fetch_clipboard)\nwhile True:\n    content = input()\n    print(\"CONTENT:\",content)\n    if \"Calling uid 0 does not own package com.android.shell\" in content:\n        print(\"!!!!!!!!!!ERROR FETCHING CLIPBOARD!!!!!!!!!!\")\n        data = readFromDevice()\n        if data is not None:\n            setClipboard(data)\n#        with open(\"target.out\",\"wb\"\n#        os.system(fetch_clipboard)"
  },
  {
    "objectID": "posts/d09801d6-f5e2-4774-a200-792bedc4fa7b/index.html",
    "href": "posts/d09801d6-f5e2-4774-a200-792bedc4fa7b/index.html",
    "title": "Algorithm",
    "section": "",
    "text": "Algorithm Python\n描述 明明想在学校中请一些同学一起做一项问卷调查，为了实验的客观性，他先用计算机生成了 N 个 1 到 1000 之间的随机整数（ N≤1000 ），对于其中重复的数字，只保留一个，把其余相同的数去掉，不同的数对应着不同的学生的学号。然后再把这些数从小到大排序，按照排好的顺序去找同学做调查。请你协助明明完成“去重”与“排序”的工作(同一个测试用例里可能会有多组数据(用于不同的调查)，希望大家能正确处理)。\n注：测试用例保证输入参数的正确性，答题者无需验证。测试用例不止一组。 当没有新的输入时，说明输入结束。\n数据范围： 1 n \\1≤n≤1000  ，输入的数字大小满足 1 val \\1≤val≤500 \n输入描述： 注意：输入可能有多组数据(用于不同的调查)。每组数据都包括多行，第一行先输入随机整数的个数 N ，接下来的 N 行再输入相应个数的整数。具体格式请看下面的”示例”。 输出描述： 返回多行，处理后的结果 示例1 输入：3 2 2 1 11 10 20 40 32 67 40 20 89 300 400 15复制 输出：1 2 10 15 20 32 40 67 89 300 400复制 说明：示例1包含了两个小样例！！\n输入解释： 第一个数字是3，也即这个小样例的N=3，说明用计算机生成了3个1到1000之间的随机整数，接下来每行一个随机数字，共3行，也即这3个随机数字为： 2 2 1 所以第一个小样例的输出为： 1 2 第二个小样例的第一个数字为11，也即…(类似上面的解释)… 所以第二个小样例的输出为： 10 15 20 32 40 67 89 300 400"
  },
  {
    "objectID": "posts/65bfb2ae-9bf1-4834-aa30-9007ded8ae10/index.html",
    "href": "posts/65bfb2ae-9bf1-4834-aa30-9007ded8ae10/index.html",
    "title": "After Termux Reinstallation",
    "section": "",
    "text": "After Termux Reinstallation\ngrant permission for termux:api\nandroid.permission.WRITE_SETTINGS can only be granted in settings tab.\nhttps://github.com/TilesOrganization/support/wiki/How-to-use-ADB-to-grant-permissions\nadb shell pm grant com.rascarlo.quick.settings.tiles android.permission.WRITE_SECURE_SETTINGS\npm grant com.termux.api android.permission.WRITE_SECURE_SETTINGS\npm list packages\nthe brightness bug is solved by uninstalling the unintended settings app. i don’t know if this will cause more problems.\nto remove termux banner/ termux welcome message:\ncd .. && cd usr/etc && rm -rf motd"
  },
  {
    "objectID": "posts/1f07e8a3-5b96-4684-bb4a-2534f3a3cf64/index.html",
    "href": "posts/1f07e8a3-5b96-4684-bb4a-2534f3a3cf64/index.html",
    "title": "Choosing the Perfect AR/VR Glasses: Clarity, Comfort, and Style",
    "section": "",
    "text": "AR VR 眼镜 选取方法 固定方法\n看得清字 边缘清晰 不模糊\n轻便 不重\n可以和帽子固定在一块 帽子再加上个固定在下巴的绑带 注意散热"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#text-annotation-tool",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#text-annotation-tool",
    "title": "AI训练集标注工具",
    "section": "text annotation tool:",
    "text": "text annotation tool:\nhttps://github.com/doccano/doccano\nsqlite 3 backend:\npip3 install doccano"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#videoimage-annotation-tool-needs-docker-with-online-demo",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#videoimage-annotation-tool-needs-docker-with-online-demo",
    "title": "AI训练集标注工具",
    "section": "video/image annotation tool, needs docker, with online demo:",
    "text": "video/image annotation tool, needs docker, with online demo:\nhttps://github.com/openvinotoolkit/cvat"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#image-labeling",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#image-labeling",
    "title": "AI训练集标注工具",
    "section": "image labeling:",
    "text": "image labeling:\nhttps://github.com/heartexlabs/labelImg"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#with-audio-video-support",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#with-audio-video-support",
    "title": "AI训练集标注工具",
    "section": "with audio video support",
    "text": "with audio video support\nhttps://github.com/heartexlabs/label-studio"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#with-audio-transcription-support",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#with-audio-transcription-support",
    "title": "AI训练集标注工具",
    "section": "with audio transcription support",
    "text": "with audio transcription support\nhttps://github.com/UniversalDataTool/universal-data-tool"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#image-and-audio",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#image-and-audio",
    "title": "AI训练集标注工具",
    "section": "image and audio",
    "text": "image and audio\nhttps://github.com/Cartucho/OpenLabeling"
  },
  {
    "objectID": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#specialized-for-yolo-bounding-boxes",
    "href": "posts/b04875f1-2d44-411d-86fd-0b3d701312f0/index.html#specialized-for-yolo-bounding-boxes",
    "title": "AI训练集标注工具",
    "section": "specialized for yolo bounding boxes",
    "text": "specialized for yolo bounding boxes\nhttps://github.com/developer0hye/Yolo_Label"
  },
  {
    "objectID": "posts/35863e14-2729-4a95-8787-8cff25851499/index.html#tool-repository",
    "href": "posts/35863e14-2729-4a95-8787-8cff25851499/index.html#tool-repository",
    "title": "AI tools collections",
    "section": "tool repository",
    "text": "tool repository\ni was informed by a post on zhihu.\nfuturepedia\ncreatives\nfuturetools\ngetinference"
  },
  {
    "objectID": "posts/65065a89-bea7-402c-9a17-8076c0577d9c/index.html",
    "href": "posts/65065a89-bea7-402c-9a17-8076c0577d9c/index.html",
    "title": "Generating 3D Models from Images with the 3d-Moments Tool",
    "section": "",
    "text": "2d转3d 图片生成3d模型\n几张类似的图片 生成一个3d的视频 https://3d-moments.github.io"
  },
  {
    "objectID": "posts/3e490f1f-d9de-497e-9a5d-eab6411d43f5/index.html",
    "href": "posts/3e490f1f-d9de-497e-9a5d-eab6411d43f5/index.html",
    "title": "Introducing Ntfy: A Service for Publishing Messages and Monitoring Statuses on a Dashboard",
    "section": "",
    "text": "message publishing, message queue, status viewer, dashboard\nntfy"
  },
  {
    "objectID": "posts/9c162b72-7c33-4613-8839-919579af081b/index.html",
    "href": "posts/9c162b72-7c33-4613-8839-919579af081b/index.html",
    "title": "Exploring Python Libraries and Resources for Nmap Network Scanning",
    "section": "",
    "text": "nmap python scripting\npython3-nmap and doc\ndoc of nmapthon python scriptable nse\npython-nmap"
  },
  {
    "objectID": "posts/ea24f4c7-f1a6-4b21-b6e5-2311a934e433/index.html#recommendation-system",
    "href": "posts/ea24f4c7-f1a6-4b21-b6e5-2311a934e433/index.html#recommendation-system",
    "title": "Exploring Popular AI Libraries and Tools for Various Tasks",
    "section": "recommendation system",
    "text": "recommendation system\ncrab\nsurprise\npython recsys recommendation system\nlightfm recsys"
  },
  {
    "objectID": "posts/001f5273-9edf-4108-8139-8035186da6ba/index.html",
    "href": "posts/001f5273-9edf-4108-8139-8035186da6ba/index.html",
    "title": "(de)obfustication, junk code insertion and removal",
    "section": "",
    "text": "(de)obfustication, junk code insertion and removal\ncommon packers:\nThemida, Code Virtualizer, VMProtect, ExeCryptor\ngeneral method for deobfustication\nsee github topic\nprotectors\nJunk Code Generator and Polymorphic Code Engine Guide\nida pro junk code removal"
  },
  {
    "objectID": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#seed-generation",
    "href": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#seed-generation",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "seed generation",
    "text": "seed generation\n\nAI based\nSkyfire (learn a probabilistic CFG grammar) Learn&Fuzz (learn a RNN model of valid inputs) GAN (learn a GAN to generate legitimate seeds) Neuzz (learn a NN to model input -&gt; coverage)\n\n\nSymbolic Execution\nDriller QSYM DigFuzz SAVIOR Intriguer Matryoshka HFL\n\n\nstatic/dynamic analysis\nFANS"
  },
  {
    "objectID": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#seed-mutation",
    "href": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#seed-mutation",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "seed mutation",
    "text": "seed mutation\n\nAI based\nMopt LSTM RL ILF\n\n\nprogram based\nVUzzer GreyOne"
  },
  {
    "objectID": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#efficient-testing",
    "href": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#efficient-testing",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "efficient testing",
    "text": "efficient testing"
  },
  {
    "objectID": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#coverage-metrics",
    "href": "posts/63dd2c4c-d610-4849-aec4-f6b5c11734b6/index.html#coverage-metrics",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "coverage metrics",
    "text": "coverage metrics"
  },
  {
    "objectID": "posts/10366990-6de8-4b6d-8f9e-f59a9747b34b/index.html",
    "href": "posts/10366990-6de8-4b6d-8f9e-f59a9747b34b/index.html",
    "title": "Discover ‘问财选股’: The Comprehensive Stock Selection Platform and Python Implementation",
    "section": "",
    "text": "问财选股\n官网\n问财api教程\npywencai"
  },
  {
    "objectID": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#collaborative-filtering-recommendation-engine",
    "href": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#collaborative-filtering-recommendation-engine",
    "title": "递归搜索 启发式搜索",
    "section": "collaborative filtering, recommendation engine",
    "text": "collaborative filtering, recommendation engine\nneo4j tutorial on recommendation engine"
  },
  {
    "objectID": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#random-search-libraries",
    "href": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#random-search-libraries",
    "title": "递归搜索 启发式搜索",
    "section": "random search libraries",
    "text": "random search libraries\nspotify randomizer"
  },
  {
    "objectID": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#heuristic-search-libraries",
    "href": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#heuristic-search-libraries",
    "title": "递归搜索 启发式搜索",
    "section": "heuristic search libraries",
    "text": "heuristic search libraries\ntwitch chat scraper and meme prediction heuristic"
  },
  {
    "objectID": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#how-to-find-trending-topics-or-videos",
    "href": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#how-to-find-trending-topics-or-videos",
    "title": "递归搜索 启发式搜索",
    "section": "how to find trending topics or videos?",
    "text": "how to find trending topics or videos?\nyou can check the same set of video and plot their historical stats, or use official ‘trending’ api to find out."
  },
  {
    "objectID": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#find-random-videos-of-certain-topic",
    "href": "posts/dc967e4c-afe7-4d27-963a-26757c6aa479/index.html#find-random-videos-of-certain-topic",
    "title": "递归搜索 启发式搜索",
    "section": "find ‘random’ videos of certain topic:",
    "text": "find ‘random’ videos of certain topic:\nsearch for playlists, collect recommendations\napply to some video feeding apis or official api like giphy\nheuristic search, graph search intro\nuse heuristic recursive search, apply random parameters, find related keywords, apply filters and update weights\ntopic modeling using gensim\nbertopic tutorial can predict topics of new document and get topic similarity\npip3 install bertopic\n可以事先设定好目标 不管这个搜没搜到 都要奖励搜索成功的那次过程 比如老头环和elden ring的对应关系\n有没有相关的工具？名字是什么？\nrecursive text search engine\nHeuristic Text Search Engine\nfree pdf: Heuristic and Systematic Use of Search Engines\nit’s like webgpt, which has arxiv pdf paper\nopenai alignment research is to make artificial general intelligence (AGI) aligned with human values and follow human intent.\nthere’s also a fake news detector inside web browser\n搜索一个词 拿到感兴趣的继续搜下一个\n把你搜索的过程记录下来 搜集信息寻找关联的过程记录下来 然后交给ai进行离线训练\n同时可以把你创建内容 组织结构的过程记录下来 交给ai离线训练 适用于template based content generator"
  },
  {
    "objectID": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html#combining-similarnearby-bounding-boxes-suppressing-near-duplicate-bounding-boxes-over-short-time",
    "href": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html#combining-similarnearby-bounding-boxes-suppressing-near-duplicate-bounding-boxes-over-short-time",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "combining similar/nearby bounding boxes, suppressing near duplicate bounding boxes over short time",
    "text": "combining similar/nearby bounding boxes, suppressing near duplicate bounding boxes over short time\nsee here\nyou can merge a group of things, then analyze them over time using object tracker, tweening them."
  },
  {
    "objectID": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html#discrete-interval-set-union-solvers",
    "href": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html#discrete-interval-set-union-solvers",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "Discrete Interval Set Union Solvers",
    "text": "Discrete Interval Set Union Solvers\nyou may want to filter out short intervals. mind the lopen/ropen interval after intersection or difference operation.\nyou may also want to quantize these intervals, set them to nearest possible points. 用到某采样率 还是根本不用吧 就是属于那个区间的离散点上面执行相应的操作变化 但是那个区间如何划分 怎么把离散点归类到不同区间里面 完全是其他的逻辑需要做的事情 一般同类别的区间不能相交 但是之后再考虑吧 怎么用呢 所有的全部弄到一个列表里面 还是选取最小的那个来用？\ncategory with different groups -&gt; subcategories\nfirst the sample set:\nimport sympy\n# make sure every subset is ordered.\nmSet = [(1.0,1.1,1.2),(2.4,2.5,2.6)]\nmSet2 = [(0.9,1.05,1.15),(2.45,2.55,2.65,2.75)]\n# convert to intervals first please?\nmSetIntervals = [(x[0],x[-1]) for x in mSet]\nmSet2Intervals = [(x[0],x[-1]) for x in mSet2]\n# additional check: these intervals cannot overlap!\ndef checkOverlap(intervalTupleList):\nunionInterval = sympy.EmptySet # shall be empty here.\nfor start, end in intervalTupleList:\nnewInterval = sympy.Interval(start,end)\nisOverlapped = (sympy.EmptySet == unionInterval.intersect(newInterval))\nif isOverlapped:\nprint(\"INTERVAL\", newInterval, \"OVERLAPPED!\")\nreturn isOverlapped\nunionInterval += newInterval\nreturn False\nassert not checkOverlap(mSetIntervals)\nassert not checkOverlap(mSet2Intervals)\nthen pool and sort all the boundaries of converted intervals:\nmPoints = mSetIntervalBoundaries + mSet2IntervalBoundaries\nmPoints = list(set(mPoints))\nmPoints.sort()\n\nwith sympy\n# all the same\n\n\nwith less sympy\n# all the same"
  },
  {
    "objectID": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html#continual-interval-set-union-solvers",
    "href": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html#continual-interval-set-union-solvers",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "Continual Interval Set Union Solvers",
    "text": "Continual Interval Set Union Solvers\nyou must be able to explicitly point out different group index of different category. maybe you can just do it in all-new subcategories?\n\nless exponential solution here?\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# basically the same example.\n# assume no overlapping here.\nimport sympy\ndef unionToTupleList(myUnion):\nunionBoundaries = list(myUnion.boundary)\nunionBoundaries.sort()\nleftBoundaries = unionBoundaries[::2]\nrightBoundaries = unionBoundaries[1::2]\nreturn list(zip(leftBoundaries, rightBoundaries))\ndef tupleSetToUncertain(mSet):\nmUncertain = None\nfor start, end in mSet:\nif mUncertain is None:\nmUncertain = sympy.Interval(start,end)\nelse:\nmUncertain += sympy.Interval(start,end)\ntypeUncertain = type(mUncertain)\nreturn mUncertain, typeUncertain\ndef mergeOverlappedInIntervalTupleList(intervalTupleList):\nmUncertain, _ = tupleSetToUncertain(intervalTupleList)\nmUncertainBoundaryList = list(mUncertain.boundary)\nmUncertainBoundaryList.sort()\nmergedIntervalTupleList = list(zip(mUncertainBoundaryList[::2], mUncertainBoundaryList[1::2]))\nreturn mergedIntervalTupleList\nmSet = mergeOverlappedInIntervalTupleList([(0,1), (2,3)])\nmSet2 = mergeOverlappedInIntervalTupleList([(0.5,1.5),(1.6,2.5)])\nprint(\"MSET\", mSet)\nprint(\"MSET2\", mSet2)\nmSetCandidates = [mSet, mSet2]\nmSetUnified = [x for y in mSetCandidates for x in y]\nleftBoundaryList = set([x[0] for x in mSetUnified])\nrightBoundaryList = set([x[1] for x in mSetUnified])\n# they may freaking overlap.\n# if want nearby-merge strategy, simply just expand all intervals, merge them with union and shrink the individual intervals inside union respectively.\nmarkers = {\"enter\":{k:[] for k in leftBoundaryList}, \"exit\":{k:[] for k in rightBoundaryList}}\nfor index, mSetCandidate in enumerate(mSetCandidates):\nleftBoundaryListOfCandidate = [x[0] for x in mSetCandidate]\nrightBoundaryListOfCandidate = [x[1] for x in mSetCandidate]\nfor leftBoundaryOfCandidate in leftBoundaryListOfCandidate:\nmarkers[\"enter\"][leftBoundaryOfCandidate].append(index) # remap this thing!\nfor rightBoundaryOfCandidate in rightBoundaryListOfCandidate:\nmarkers[\"exit\"][rightBoundaryOfCandidate].append(index) # remap this thing!\n# now, iterate through the boundaries of mSetUnified.\nunifiedBoundaryList = leftBoundaryList.union(rightBoundaryList) # call me a set instead of a list please? now we must sort this thing\nunifiedBoundaryList = list(unifiedBoundaryList)\nunifiedBoundaryList.sort()\nunifiedBoundaryMarks = {}\nfinalMappings = {}\n# print(\"MARKERS\", markers)\n# breakpoint()\nfor index, boundary in enumerate(unifiedBoundaryList):\npreviousMark = unifiedBoundaryMarks.get(index-1, [])\nenterList = markers[\"enter\"].get(boundary,[])\nexitList = markers[\"exit\"].get(boundary,[])\ncurrentMark = set(previousMark + enterList).difference(set(exitList))\ncurrentMark = list(currentMark)\nunifiedBoundaryMarks.update({index:currentMark})\n# now, handle the change? or not?\n# let's just deal those empty ones, shall we?\nif previousMark == []: # inside it is empty range.\n# elif currentMark == []:\nif index == 0: continue # just the start, no need to note this down.\nelse:\nfinalMappings.update({\"empty\":finalMappings.get(\"empty\",[])+[(unifiedBoundaryList[index-1], boundary)]})\n# the end of previous mark! this interval belongs to previousMark\nelse:\nkey = previousMark.copy()\nkey.sort()\nkey = tuple(key)\nfinalMappings.update({key:finalMappings.get(key,[])+[(unifiedBoundaryList[index-1], boundary)]})\n# also the end of previous mark! belongs to previousMark.\n### NOW THE FINAL OUTPUT ###\nfinalCats = {}\nfor key, value in finalMappings.items():\n# value is an array containing subInterval tuples.\nvalue = mergeOverlappedInIntervalTupleList(value)\nfinalCats.update({key: value})\nprint(\"______________FINAL CATS______________\")\nprint(finalCats)\n\n\nsympy solution\nsympy seems to provide support for discrete and continuous interval? will that save any damn time anyway? i’m afraid no? maybe there’s a way!\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sympy\ndef unionToTupleList(myUnion):\n#  seriously wrong. this will fuck up.\nunionBoundaries = list(myUnion.boundary)\nunionBoundaries.sort()\nleftBoundaries = unionBoundaries[::2]\nrightBoundaries = unionBoundaries[1::2]\nreturn list(zip(leftBoundaries, rightBoundaries))\ndef tupleSetToUncertain(mSet):\nmUncertain = None\nfor start, end in mSet:\nif mUncertain is None:\nmUncertain = sympy.Interval(start,end)\nelse:\nmUncertain += sympy.Interval(start,end)\ntypeUncertain = type(mUncertain)\nreturn mUncertain, typeUncertain\n# borrowed from above code.\ndef mergeOverlappedInIntervalTupleList(intervalTupleList):\nmUncertain, _ = tupleSetToUncertain(intervalTupleList)\nmUncertainBoundaryList = list(mUncertain.boundary)\nmUncertainBoundaryList.sort()\n#  print(mUncertain)\n#  print(mUncertainBoundaryList)\nmergedIntervalTupleList = list(zip(mUncertainBoundaryList[::2], mUncertainBoundaryList[1::2]))\n# print(mergedIntervalTupleList)\nreturn mergedIntervalTupleList\nmSet = [(0,1), (2,3)]\nmUncertain, typeUncertain = tupleSetToUncertain(mSet)\nunrolledMSet = list(mUncertain.boundary)\n# can be either sympy.sets.sets.Interval of sympy.sets.sets.Union\nmSet2 = [(0.5,1.5),(1.6,2.5)]\nmUncertain2, typeUncertain2 = tupleSetToUncertain(mSet2)\nunrolledMSet2 = list(mUncertain2.boundary)\nprint(\"MSET\", mSet)\nprint(\"MSET2\", mSet2)\n############################################################\n# hypothetical mSet2 and mUncertain2! please complete the hypothetical shit and make it runnable!\ndef checkCommon(subInterval, masterInterval):\nreturn subInterval == sympy.Intersection(subInterval, masterInterval)\nmUncertains = [mUncertain, mUncertain2]\nsubIntervals = list(set(unrolledMSet2 + unrolledMSet))\nsubIntervals.sort()\nsubIntervals = zip(subIntervals[:-1], subIntervals[1:])\nsubIntervals = list(subIntervals)\n#  breakpoint()\n# for subIntervals, it's still not real interval but tuple at above line.\nreversedCats = {}\nimport functools\nsubIntervalUnion = functools.reduce(lambda a,b: a+b, mUncertains)\nfor subIntervalIndex, (start, end) in enumerate(subIntervals):\nsubIntervalCandidate = sympy.Interval(start, end)\nreverseIndex = [] # there must be at least one such index.\nfor index, uncertainCandidate in enumerate(mUncertains):\nif checkCommon(subIntervalCandidate, uncertainCandidate):\nreverseIndex.append(index) # this is the index of the in-common set of the original set list\nreversedCats.update({subIntervalIndex:reverseIndex}) # need to sort and index? or not to sort because this is already done?\nnormalCats = {}\nfor k,v in reversedCats.items():\nv.sort()\nv = tuple(v)\nnormalCats.update({v:normalCats.get(v, [])+[k]})\n# we only get interval, not the actural union period!\n# how to get interval elements out of union structure for hell sake?\nfinalCats = {}\nfor k,v in normalCats.items():\n# now k is the original set index list, representing belonging of the below union.\n#  print(subIntervals)\n#  print(index)\n#  print(v)\n#  breakpoint()\nmFinalUnionCandidate = [subIntervals[index] for index in v]\n## REPLACED ##\n# mFinalUnionCandidate, _ = tupleSetToUncertain(mFinalUnionCandidate)\n##### union to tuple list, could be replaced #####\n#mFinalUnionCandidateBoundaryList = list(mFinalUnionCandidate.boundary)\n#left_bounds, right_bounds = mFinalUnionCandidateBoundaryList[0::2],mFinalUnionCandidateBoundaryList[1::2] # check it dammit! not sure how to step the list properly?\n#mFinalIntervalListCandidate = list(zip(left_bounds, right_bounds))\n# mFinalIntervalListCandidate = unionToTupleList(mFinalUnionCandidate)\n##### union to tuple list, could be replaced #####\n## REPLACED ##\n# print(\"M_FINAL_UNION_CANDIDATE\",mFinalUnionCandidate)\nmFinalIntervalListCandidate = mergeOverlappedInIntervalTupleList(mFinalUnionCandidate)\n# print(\"M_FINAL_INTERVAL_LIST_CANDIDATE\", mFinalIntervalListCandidate)\n# breakpoint()\nfinalCats.update({k:mFinalIntervalListCandidate.copy()})\n# this whole calculation could just be exponential. goddamn it?\n# before that, we need to get the \"empty\" out. but is that really necessary? i think it is, as an important feature.\n#  subIntervalsStart, subIntervalsEnd = subIntervals[0][0], subIntervals[-1][-1]\n#\n#  relativeCompleteInterval = sympy.Interval(subIntervalsStart, subIntervalsEnd)\n#\n# subIntervalUnion\n#  emptyIntervalUnion = relativeCompleteInterval - subIntervalUnion # really uncertain if it is just a union or not.\n#  emptyIntervalTupleList = unionToTupleList(emptyIntervalUnion)\n#\n#  finalCats.update({\"empty\":emptyIntervalTupleList})\nfinalCats.update({\"empty\":finalCats[()]})\ndel finalCats[()]\nprint(\"_____FINAL CATS_____\")\nprint(finalCats)"
  },
  {
    "objectID": "posts/de7d44f0-f3ae-4336-a009-64d75fbadd20/index.html",
    "href": "posts/de7d44f0-f3ae-4336-a009-64d75fbadd20/index.html",
    "title": "踩点 音乐识别",
    "section": "",
    "text": "踩点 音乐识别 搞笑视频收集\nnow we have audioFlux, alternative to librosa, but faster\n\naudioowl for tempo, beat and notes identification:\nhttps://github.com/dodiku/AudioOwl\ncnn based audio segmentation toolkit allow to detect speech, music and speaker gender:\nhttps://github.com/ina-foss/inaSpeechSegmenter\nspeech music detection using keras:\nhttps://github.com/qlemaire22/speech-music-detection\nawesome deep learning music:\nhttps://github.com/ybayle/awesome-deep-learning-music\nmusic genre classification/ Music Classification/ Music Recommendation/ Music search\nhttps://github.com/mlachmish/MusicGenreClassification\nhttps://github.com/kristijanbartol/Deep-Music-Tagger\nhttps://github.com/tae-jun/resemul\nhttps://github.com/Insiyaa/Music-Genre-Classification\nmusic recognization service:\naudioid soundhound\nmaybe you should consider some chinese tools? none there.\nmusic radar recognize music:\nhttps://github.com/keshavbhatt/music-radar\nmousai using free audd api to recognize music:\nhttps://github.com/SeaDve/Mousai\nmusic emotion recognization:\nhttps://github.com/SeungHeonDoh/Music_Emotion_Recognition\nmusic tagging and recognization, using acoustic ids and community based music database:\nhttps://github.com/metabrainz/picard\nhttps://musicbrainz.org/doc/AcoustID\nmixingbear(alike neuralmix):\nhttps://github.com/dodiku/MixingBear\nmadmom\nhttps://github.com/CPJKU/madmom\nhttp://madmom.readthedocs.org\n音乐分类 综合音频分析包\npyaudioanalysis\nmathematica audio slience removal segmentation:\nhttps://zhuanlan.zhihu.com/p/43165678\nmusic21 for music recognition:\nhttps://zhuanlan.zhihu.com/p/35140033\nmusic21 for midi analysis:\nhttps://pypi.org/project/music21/\nhttps://music21.readthedocs.io/en/latest\nhttps://zhuanlan.zhihu.com/p/73564852\nsound recognition and localization:\nhttps://reality.ai/automotive-sound-recognition-localization/\nurbansound8k dataset ( 6gb ):\nhttps://www.kaggle.com/datasets/chrisfilo/urbansound8k\nfourier transform cat meow detection:\nhttps://github.com/EricDavidWells/MeowDetector\nbuilding sound event classifier:\nhttps://ignitarium.com/building-an-ai-based-sound-event-classifier/\nreal time continuous sound event classification(usually via silence detection):\nhttps://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e\nhttps://medium.com/@chathuranga.15/real-time-sound-event-classification-83e892cf187e\nhttps://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc\ncry detection:\nhttps://www.amberou.com/cry-detection\nhttps://github.com/umangkk5/Infant-Cry-Detection-System/blob/master/site-packages/soundfile.py\nurbansound classifier:\nhttps://github.com/awln/urban8k-audio-classifier\nlaugh detection:\nhttps://github.com/ideo/LaughDetection\ngun shot detection:\nhttps://github.com/hasnainnaeem/Gunshot-Detection-in-Audio\ndog bark detector:\nhttps://github.com/t04glovern/dog-bark-detection\nhttps://devopstar.com/2020/04/13/dog-bark-detector-machine-learning-model\nhttps://dsp.stackexchange.com/questions/23466/detect-dog-barks\n获得音乐识别api 最好是qq音乐识别 国内识别引擎\n不能识别就分析简介 有没有BGM\n踩点 bpm以前的autoup项目里有 看看其他的分析软件有没有 premiere一键踩点插件可能有开源库支持\n已有的踩点视频 可以切出无文字的片段 根据音乐结构区分高潮 开始 中间等部分 根据音乐类型标签归类视频\n搞笑视频的话 有纯笑声比较好 动作幅度大的 不要有对话 反向截图 收集类似视频"
  },
  {
    "objectID": "posts/3b1f1642-1532-4716-9f64-8573e566e14f/index.html#online",
    "href": "posts/3b1f1642-1532-4716-9f64-8573e566e14f/index.html#online",
    "title": "语音转文字 stt speech to text",
    "section": "online",
    "text": "online\n字说APP的api\n逆向搜狗输入法 绕过签名验证\n搜狗输入法apk的api\n微软stt\nhttps://github.com/cuberwr/bilibiliSTT\n多家免费stt\nhttps://github.com/1c7/Translate-Subtitle-File"
  },
  {
    "objectID": "posts/3b1f1642-1532-4716-9f64-8573e566e14f/index.html#offline",
    "href": "posts/3b1f1642-1532-4716-9f64-8573e566e14f/index.html#offline",
    "title": "语音转文字 stt speech to text",
    "section": "offline",
    "text": "offline\npyannote segment audio according to different speakers, detect voice activity\nspeechbrain very advanced speech related ai library, with almost everything related to speech\nvosk\npaddlespeech\n\npaper of Google USM (universal speech model) supporting 1000 languages\n\nwhisper.cpp perform fast voice to text operation using cpu rather than gpu\nwhisperx improve time accuracy with forced alignment\nwhisper gui buzz\nwhisper by openai, with multilingual and translation avaliable, can detect under background music and noise, with slience,"
  },
  {
    "objectID": "posts/b0e9c229-6734-44b7-a5c6-b7a68b8749bf/index.html",
    "href": "posts/b0e9c229-6734-44b7-a5c6-b7a68b8749bf/index.html",
    "title": "Automating Freelance Job Offers: AI-Powered System for Paper Writing Industry",
    "section": "",
    "text": "论文代写 作业代写转为AI自动运作项目\n收集各大兼职网站 QQ接单群 闲鱼的项目描述 人工标注项目报价费用 训练实现自动报价抽成机器人\n根据项目描述和大量公开数据 进行开放式问答 训练并应用于论文实现代写方面的付费问答机器人"
  },
  {
    "objectID": "posts/dbd8fd94-911d-4964-9bc6-27747f20428b/index.html",
    "href": "posts/dbd8fd94-911d-4964-9bc6-27747f20428b/index.html",
    "title": "补帧 插帧 提高帧数",
    "section": "",
    "text": "补帧 插帧 提高帧数 黑白相片上色 慢动作视频 照片优化 提高清晰度 模糊变清晰 人像美颜\n超分辨率 super resolution realcugan bilibili official real cugan\navisynth的替代品：vapoursynth（in Python） FrameServer\nvapoursynth is somehow installed on python 3.10(brew). do not know what depends on that.\nmvtools for vapoursynth motion compensation\n效果好 速度慢 dain\nrife 速度快 画质会变差 another repo link with more stars\nvapoursynth rife filter usage just a gist\nvsrife using cuda\nrife plugin for vapoursynth using vulkan\nnvidia super slomo 比较吃显存 需要NVIDIA SDK 速度快\nsepconv 看起来比较模糊 但是还是比直接overlay要好\npytorch sepconv slomo\nmemc-net比较清晰\nFFmpeg自带插帧的filter：\nffmpeg -i input.60fps.hevc -filter \"minterpolate='fps=120'\" output.120fps.hevc\nai黑白上色可以把原视频洗稿：image colorization\ncoloring grayscale images\nColoring black and white images with deep learning\nmemc (motion estimation/motion compensation)\n在CSDN上看到的算法名称和内容\n内置超分辨率算法:\nWaifu2x / SRMD / RealSR / Real-ESRGAN/ Real-CUGAN / Anime4K / ACNet\n内置超分辨率引擎:\nWaifu2x-caffe / Waifu2x-converter / Waifu2x-ncnn-vulkan\nSRMD-ncnn-vulkan / RealSR-ncnn-vulkan / Anime4KCPP / SRMD-CUDA\nRealESRGAN-NCNN-Vulkan / Real-CUGAN-ncnn-vulkan\n内置插帧算法:\nRIFE / CAIN / DAIN\n内置插帧引擎:\nrife-ncnn-vulkan / cain-ncnn-vulkan / dain-ncnn-vulkan"
  },
  {
    "objectID": "posts/2c4f1e59-c56a-4690-8332-3b57e9230e5f/index.html",
    "href": "posts/2c4f1e59-c56a-4690-8332-3b57e9230e5f/index.html",
    "title": "自动内容发布 多平台发布 管理多个自媒体平台 automatic content posting in multiple platforms",
    "section": "",
    "text": "文章多平台发布 浏览器插件 一键同步文章到多个内容平台，支持今日头条、WordPress、知乎、简书、掘金、CSDN、typecho各大平台，一次发布，多平台同步发布。解放个人生产力"
  },
  {
    "objectID": "posts/ad067139-0361-422f-bd71-7c6aedcfc933/index.html#交易接口",
    "href": "posts/ad067139-0361-422f-bd71-7c6aedcfc933/index.html#交易接口",
    "title": "股票数据源 tick级别数据源 逐笔交易",
    "section": "交易接口",
    "text": "交易接口\n现在哪些券商的TradeX.dll接口还能用 需要注册论坛账号 达到要求才能浏览内容\ntrade.dll tradex.dll\ntradex.dll header file\nbqtradex A simple tradex api mock dll, for easily internal debug your app\nQuantaxis\ntdxtradeserver\ntradex-api\ntdxapi2\nalphaquant"
  },
  {
    "objectID": "posts/ad067139-0361-422f-bd71-7c6aedcfc933/index.html#数据来源",
    "href": "posts/ad067139-0361-422f-bd71-7c6aedcfc933/index.html#数据来源",
    "title": "股票数据源 tick级别数据源 逐笔交易",
    "section": "数据来源",
    "text": "数据来源\n逐笔数据是计算涨速的关键因素\nashare\nquantaxis secretely using pytdx and tdxtradeserver as backends\nakshare\n获取涨速\nimport akshare as ak\nstock_zh_a_spot_em_df = ak.stock_zh_a_spot_em()\nprint(stock_zh_a_spot_em_df)\nqstock\nefinance\nbaostock\npytdx and docs, must connect to tdx server before operate\npytdx2 fixed some problems\nmootdx actually using pytdx as backend\nabquant-data using pytdx as backend\n计算涨速等数据\npysnowball雪球数据源\nchromedriver based xueqiu api\n获取雪球cookie\n雪球tick级别数据获取\nzipline_chstock 本地化zipline，并对其进行部分加工，适用于国内 day,minute 和tick数据的回测\n新浪财经api"
  },
  {
    "objectID": "posts/cc94a519-7ae0-4a43-a1d6-b76a18d93e81/index.html",
    "href": "posts/cc94a519-7ae0-4a43-a1d6-b76a18d93e81/index.html",
    "title": "程序员笑话 可当文案 jokes about programmers",
    "section": "",
    "text": "runoob coder jokes:\nhttps://www.runoob.com/w3cnote_genre/joke/page/2\ntelegram channels for programmer jokes"
  },
  {
    "objectID": "posts/692a15b1-c5e4-423d-89c2-cba6527ea46c/index.html",
    "href": "posts/692a15b1-c5e4-423d-89c2-cba6527ea46c/index.html",
    "title": "短网址生成器",
    "section": "",
    "text": "就没一个能用的 除了b站的短链接\n可能抖音快手也有吧 但是懒得管了 大不了二维码应付"
  },
  {
    "objectID": "posts/8e5a479b-67bb-4178-a9fc-737b6efcc4b4/index.html",
    "href": "posts/8e5a479b-67bb-4178-a9fc-737b6efcc4b4/index.html",
    "title": "直接调用安卓方法 frida 直接调用二进制里面的方法",
    "section": "",
    "text": "frida主动调用函数\n使用Frida框架hook安卓native方法\nfrida主动调用简介"
  },
  {
    "objectID": "posts/1f38233c-6b44-464d-b984-879f764bbdbd/index.html",
    "href": "posts/1f38233c-6b44-464d-b984-879f764bbdbd/index.html",
    "title": "百度贴吧转化笔记",
    "section": "",
    "text": "只看楼主 获取主要信息\n有人用贴吧注册的账号来顶贴"
  },
  {
    "objectID": "posts/59009bb7-bfc7-4eaa-b45d-c989c63c0e98/index.html",
    "href": "posts/59009bb7-bfc7-4eaa-b45d-c989c63c0e98/index.html",
    "title": "百度 搜狗 公开API 搜索引擎爬虫 Baidu Search APIs Chatbot APIs",
    "section": "",
    "text": "zhihuq query zhihu articles by keywords and relevance\nb站前100视频爬取\nb站爬取首页热门推荐视频\n爬取b站弹幕\ntrending scraper for bilibili, baidu, zhihu, weibo\n基于node.js的抓取微博、百度热搜、知乎日报、bilibili等热榜榜爬虫 热搜\ntrending reddit videos scraper and video uploader for youtube with special transition effects\nnews search engine 新闻搜索\n通过百度 微视（腾讯小视频）是可以搜索的\nimage search engines sourced from search by image browser plugin:\nGoogle, Bing, Yandex, Baidu and TinEye\ngoogle tts for python:\nimport gtts\n爬取课程视频 去水印\ncoursera udemy khanacademy icourse163\n爬取tumblr 知乎 腾讯新闻\nhttps://github.com/zhangslob/awesome_crawl\n图片下载api\nhttps://github.com/CharlesPikachu/imagedl\n免费聊天api 青云客api 腾讯智能闲聊\nhttps://zhuanlan.zhihu.com/p/110785806\nhttp://api.qingyunke.com/api.php?key=free&appid=0&msg=你好\n思知对话机器人 语义理解 自然语言转化为结构化数据\nhttps://www.ownthink.com/docs/bot/\nhttps://github.com/ownthink/robot/\n流行视频下载api\nhttps://github.com/CharlesPikachu/videodl\n热搜\nhttps://github.com/Eurkon/weibo-top-api\nhttps://github.com/ningyuwhut/query_suggestion\nhttps://github.com/Arrackisarookie/weibo-hot-search\nhttps://github.com/justjavac/zhihu-trending-top-search\nhttps://github.com/justjavac/weibo-trending-hot-search\nhttps://github.com/huqi-pr/trending-in-one\nhttps://github.com/jw-star/weiboPush-go-actions\n热搜2\nhttps://github.com/wanghuafeng/baidu_spider\nhttps://github.com/TauWu/weibo_daily_hotkey\nhttps://github.com/quarrying/baidu-top-crawler\nhttps://github.com/towelong/zhihu-hot-questions\nhttps://github.com/gaussic/baidu_hot_words\nhttps://github.com/ctts/TopSearch\nhttps://github.com/henrylee123/baiduIndexCrawler\nhttps://github.com/realzhengyiming/Spider_of_keywordRank\n登录主流网站\nhttps://github.com/CharlesPikachu/DecryptLogin\n微博热搜\nhttps://github.com/Eurkon/weibo-top-api\n微博 python api\nhttps://pypi.org/project/weibo/\ngithub actions抓取微博热搜\nhttps://github.com/xiadd/tg-wb-trending\n百度搜索api\nhttps://github.com/wcadaydayup/python-baidusearch\nhttps://github.com/1049451037/MagicBaidu\nhttps://github.com/alkalixin/jsonp\n微软小冰api\nhttps://github.com/yanwii/msxiaoiceapi\nhttps://github.com/BennyThink/realXiaoice\n搜狗微信\nhttps://github.com/chyroc/WechatSogou\nhttps://github.com/jaryee/wechat_sogou_crawlhttps://github.com/pujinxiao/weixin\n知乎爬虫\nhttps://github.com/LiuRoy/zhihu_spider\n搜索引擎爬虫 图片下载\nhttps://github.com/tasos-py/Search-Engines-Scraper\nhttps://github.com/ostrolucky/Bulk-Bing-Image-downloader\nhttps://github.com/NikolaiT/GoogleScraper\nhttps://github.com/naqushab/SearchEngineScrapy"
  },
  {
    "objectID": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#聚焦在主流平台",
    "href": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#聚焦在主流平台",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "聚焦在主流平台",
    "text": "聚焦在主流平台\n主流平台就是有现成api搜索的平台\n如果没有api 就需要用playwright 但是可能耗时更长 也更加偏离找素材的关键\n目前主流平台都有现成高级api可以对接 如果找不到api则可能说明不是主流的平台\n主流平台分为主流媒体和搜索引擎两大类\n如果需要搜索小众的平台 建议对接搜索引擎 加入高级搜索参数 搜出来的链接拿来分析看能不能直接下载"
  },
  {
    "objectID": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#api应该具有的功能",
    "href": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#api应该具有的功能",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "api应该具有的功能",
    "text": "api应该具有的功能\n搜索 高定制搜索 可以做到不重复\n视频信息（时长 播放量 简介 封面 字幕 标题 标签 评论）提取\n相关视频推荐提取 首页推荐提取\n热榜热搜提取 搜索补全提取\n下载视频 尽量无水印 字幕\n如果是要发布内容的平台 则需要有上传功能\n上传视频 封面 简介 标签 合集信息 字幕\n上传文章 图片"
  },
  {
    "objectID": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#用什么关键词",
    "href": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#用什么关键词",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "用什么关键词",
    "text": "用什么关键词\n找到最合适的 适合当前生成框架的素材 需要自己去尝试总结\n当然也可以用关键字和评论 视频播放量反馈机制寻找合适的关键词 或者是神经网络 机器学习 或者是图数据库 推荐算法\n标签\n关键词 -&gt;视频 -&gt; 同类视频\n某个观众 -&gt; 同个作者"
  },
  {
    "objectID": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#如何分析视频",
    "href": "posts/f16daaf9-39f4-4521-8a31-b3790f4657ae/index.html#如何分析视频",
    "title": "Mastering Video and Article Uploads: Tips for Cover Images, Introductions, Tags, and More",
    "section": "如何分析视频",
    "text": "如何分析视频\n首先要裁剪画中画 再去除水印 去文字 提高画质 提高帧数 如果需要提取识别字幕就需要在指定区域识别 语音识别如果要做就需要分离人声 检测文字流畅度 （对于外文或者歌曲可能不会很流畅）\n根据一定的标准筛选 裁剪时长和画布 比如时长 音量 光流 文字面积 是否有人像 人物的动作幅度\n如果要分离人声 一般要配合相应的字幕 还得变声 检测说话人有几个（如果多人说话 语音识别可能不会正常工作 文字流畅度低） 是男是女\n如果需要音乐 BGM 一般不直接从视频里面提取 而是从简介里面找到关键字 拿到专门的音乐平台去搜索 音乐也可能需要筛选一下 根据类别和播放量 评论反馈筛选"
  },
  {
    "objectID": "posts/cf0a6736-6b25-4904-a1f2-93aa9a8cfb0c/index.html",
    "href": "posts/cf0a6736-6b25-4904-a1f2-93aa9a8cfb0c/index.html",
    "title": "海外哔哩哔哩",
    "section": "",
    "text": "bilibili.tv"
  },
  {
    "objectID": "posts/e2bb5a67-377d-40d5-8d39-536b84c8845a/index.html",
    "href": "posts/e2bb5a67-377d-40d5-8d39-536b84c8845a/index.html",
    "title": "正方教务系统sql注入",
    "section": "",
    "text": "通过url遍历得到asmx结尾的url进行注入 如果你要进行报复学校这个看起来很不错"
  },
  {
    "objectID": "posts/bb35f592-24c7-44cb-b45f-7bb51d5fa343/index.html#template-extraction-neural-template-generation",
    "href": "posts/bb35f592-24c7-44cb-b45f-7bb51d5fa343/index.html#template-extraction-neural-template-generation",
    "title": "标题生成",
    "section": "template extraction, neural template generation",
    "text": "template extraction, neural template generation\n封面来源：\n利用标题进行图片搜索 其实只能站内搜索 因为站外没有这种图片与文字的对应关系\n截取视频截图\nb站原图 histogram match 20% 去掉文字 镜像反转 加入随机噪声 旋转1度\n利用封面进行图片反向搜索 效果其实不好 并没有想要的照片 只能找到原图 有可能起到去水印的效果 但是有限\n\nreverse image search engine\nreverse image search engine\nmeta image search engine\ntelegram reverse image search bot\n\nneural template gen is a natural language generator based on templates from harvard nlp, can be used for title generation"
  },
  {
    "objectID": "posts/bb35f592-24c7-44cb-b45f-7bb51d5fa343/index.html#根据标签生成广告-同样可以根据标签生成视频标题推荐-在千言数据集上训练过",
    "href": "posts/bb35f592-24c7-44cb-b45f-7bb51d5fa343/index.html#根据标签生成广告-同样可以根据标签生成视频标题推荐-在千言数据集上训练过",
    "title": "标题生成",
    "section": "根据标签生成广告 同样可以根据标签生成视频标题（推荐） 在千言数据集上训练过",
    "text": "根据标签生成广告 同样可以根据标签生成视频标题（推荐） 在千言数据集上训练过\nhttps://huggingface.co/cocoshe/gpt2-chinese-gen-ads-by-keywords?text=My+name+is+Clara+and+I+am\ntitle generator(from description):\nhttps://github.com/harveyaot/DianJing/blob/master/scripts/title_generation_lm.py\nhttps://blog.csdn.net/stay_foolish12/article/details/111661358\ncover generation\nrectangle packing allow overlapping\nwhen solution is not found, decrease the size of rectangles.\nyoutube title generator using AI:\nhttps://github.com/gdemos01/YoutubeVideoIdeasGeneratorAI\nai thumbnail generator using pyscenedetect:\nhttps://github.com/yoonhero/ai-thumbnail-generator\nimage captioning:\nhttps://github.com/ruotianluo/ImageCaptioning.pytorch\nyouzan clip product title generation:\nhttps://huggingface.co/youzanai/clip-product-title-chinese\npaper title generator without description:\nhttps://github.com/csinva/gpt2-paper-title-generator\nimage captioning using cnn and rnn:\nhttps://github.com/SCK22/image_and_video\nimage captioning can also be used for video captioning. but that will suffice the accuracy.\nkeras.io image captioning\nhttps://keras.io/examples/vision/image_captioning/\ngenerate image captions using CLIP and GPT(on medium, click continue reading)\nhttps://towardsai.net/p/l/image-captioning-with-clip-and-gpt\ngpt3demo.com has provided a lot of interesting tasks that gpt3 can do. including image captioning. may find video captioning, video classification.\ngpt3demo.com provided image captioning libs:\nhttps://gpt3demo.com/category/image-captioning\nclipclap\ngpt-3 x image captions\nvisualgpt: generate image captions\nhttps://github.com/Vision-CAIR/VisualGPT\ngenerate stories from pictures, using image transformers and gpt-2, just intro no code\nhttps://www.dataversity.net/image-captioning-generating-stories-from-unstructured-data-using-applied-nlg/"
  },
  {
    "objectID": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#为什么要日站",
    "href": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#为什么要日站",
    "title": "日站之随想",
    "section": "为什么要日站",
    "text": "为什么要日站\n因为自己电脑算力有限 要探索高级人工智能 要运行某些赚钱程序 必须免费白嫖别人的算力"
  },
  {
    "objectID": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#日哪些站",
    "href": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#日哪些站",
    "title": "日站之随想",
    "section": "日哪些站",
    "text": "日哪些站\n到百度 各大搜索引擎找目标站点 扫描漏洞 不要打大站 先从小站打起走 往全自动化方向打起走"
  },
  {
    "objectID": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#怎么日站",
    "href": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#怎么日站",
    "title": "日站之随想",
    "section": "怎么日站",
    "text": "怎么日站\n在一个沙箱下面日站 不要在root权限下面日\n利用工具 目标站点IP 端口就直接填到工具里面就行 一边学工具一边日站\n需要一个repo专门放有关的代码 同时可以同步到每个设备\n需要一个可以搜索全文的搜索引擎 搜集我们已有的md文件 提取里面的链接 然后继续clone github的文件 继续搜集md文件 继续寻找链接"
  },
  {
    "objectID": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#日站之后干什么",
    "href": "posts/b9278725-5c9f-4b5e-83e3-096e3ae71391/index.html#日站之后干什么",
    "title": "日站之随想",
    "section": "日站之后干什么",
    "text": "日站之后干什么\n放传染性病毒 放挖币病毒 或者执行agi实验"
  },
  {
    "objectID": "posts/32bab4e2-46bb-47a4-86a3-e7bc41b1025e/index.html",
    "href": "posts/32bab4e2-46bb-47a4-86a3-e7bc41b1025e/index.html",
    "title": "推荐系统 GNN",
    "section": "",
    "text": "1、muricoca/crab\nhttps://github.com/muricoca/crab\n2、ibayer/fastFM\nhttps://github.com/ibayer/fastFM\n3、Mendeley/mrec\nhttps://github.com/mendeley/mrec\n4、MrChrisJohnson/logistic-mf\nhttps://github.com/MrChrisJohnson/logistic-mf\n5、jadianes/winerama-recommender-tutorial\nhttps://github.com/jadianes/winerama-recommender-tutorial\n6、ocelma/python-recsys\nhttps://github.com/ocelma/python-recsys\n7、benfred/implicit\nhttps://github.com/benfred/implicit\n8、lyst/lightfm\nhttps://github.com/lyst/lightfm\n9、python-recsys/crab\nhttps://github.com/python-recsys/crab\n10、NicolasHug/Surprise\nhttps://github.com/NicolasHug/Surprise\n\nlinkedin gdmix simple and memory effective personalized ranking\ndatawhale fun-rec 推荐系统入门教程\ndatawhale rechub\nimage to text, text to image, clip as image/text embeddings\ndeep recommendation using tensorflow 1.15\nimage recommendation system\n不同的人有不同喜好\n不同的人和不同的人说话\n不同的产品有不同的特征\n不同的产品和不同的产品被一起推荐\n人对产品的接受度\nyouzan has an ai platform called trexpark, offering chinese NLP and image models pretrained from e-commerce databases.\nhttps://github.com/youzanai/trexpark\nsession based recommendation system:\nhttps://github.com/CRIPAC-DIG/SR-GNN\ndecide the feedback embeddings:\nhttps://huggingface.co/youzanai/bert-product-comment-chinese\nconversational embeddings:\nhttps://huggingface.co/youzanai/bert-customer-message-chinese\nneo4j developer build a recommendation engine:\nhttps://neo4j.com/developer/cypher/guide-build-a-recommendation-engine/\ntorch_geometric(PyG) documentation:\nhttps://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GatedGraphConv\nsetup GCN using PyG:\nhttps://zhuanlan.zhihu.com/p/400078504\ntagspace text classification via hashtags:\nhttps://paddlerec.readthedocs.io/en/latest/models/contentunderstanding/tagspace.html\ngnn is based on basic data/label models and provide high-level reasoning and predictions.\nneo4j graph academy practical usage:\nhttps://graphacademy.neo4j.com/categories/\nhttps://neo4j.com/graphacademy/training-iga-40/12-iga-40-ingredient-analysis/\nvideo segments have different features and orders. predict missing links. predict categories semi-supervised or unsupervised.\nvideo-image-text-music correlation and predict internal relationships, categories.\nrecommendation system:\npaddlerec(multimodal), torchrec(cuda==11.3, build failed due to unable to find ATen from torch/include.)\nhttps://neo4j.com/docs/graph-data-science/current/end-to-end-examples/fastrp-knn-example/\nlink prediction:\nhttps://github.com/Orbifold/pyg-link-prediction/blob/main/run.py\nhow to use pyg for link prediction:\nhttps://github.com/pyg-team/pytorch_geometric/issues/634\ndgl, install from source, with link prediction:\nhttps://docs.dgl.ai/tutorials/blitz/4_link_predict.html\nhttps://github.com/dmlc/dgl\nhttps://docs.dgl.ai/guide_cn/training-link.html#guide-cn-training-link-prediction\ngnn intro:\nhttps://cnvrg.io/graph-neural-networks/\ngnn applications:\nNode classification: The objective here is to predict the labels of nodes by considering the labels of their neighbors.\nLink prediction: In this case, the goal is to predict the relationship between various entities in a graph. This can for example be applied in prediction connections for social networks.\nGraph clustering: This involves dividing the nodes of a graph into clusters. The partitioning can be done based on edge weights or edge distances or by considering the graphs as objects and grouping similar objects together.\nGraph classification: This entails classifying a graph into a category. This can be applied in social network analysis and categorizing documents in natural language processing. Other applications in NLP include text classification, extracting semantic relationships between texts, and sequence labeling.\nComputer vision: In the computer vision world, GNNs can be used to generate regions of interest for object detection. They can also be used in image classification whereby a scene graph is generated. The scene generation model then identifies objects in the image and the semantic relationship between them. Other applications in this field include interaction detection and region classification."
  },
  {
    "objectID": "posts/aa17a546-5b4f-4aff-94e0-47cfa04dca5e/index.html",
    "href": "posts/aa17a546-5b4f-4aff-94e0-47cfa04dca5e/index.html",
    "title": "捡塑料瓶机器人 吸硬币 回收硬币机器人",
    "section": "",
    "text": "捡塑料瓶机器人 吸硬币 回收硬币机器人"
  },
  {
    "objectID": "posts/a76d3719-f3ec-46ad-a8fe-79fe978df924/index.html",
    "href": "posts/a76d3719-f3ec-46ad-a8fe-79fe978df924/index.html",
    "title": "怎样清理嗓子 鼻腔里面的痰液",
    "section": "",
    "text": "挤压耳后根 耳洞旁 同时吸气 用力打开耳朵通鼻腔的通道 吐痰\n如果面部 下巴 脖子后面有酸胀的区域也可以挤压"
  },
  {
    "objectID": "posts/8b657c4f-588a-426a-8dc6-f18242159b70/index.html",
    "href": "posts/8b657c4f-588a-426a-8dc6-f18242159b70/index.html",
    "title": "Understanding WeChat Pay and Alipay: The Popular Payment Systems in China",
    "section": "",
    "text": "微信支付 支付宝 中转系统\n既可以收款也可以付款的库 可以扫描别人的二维码付款 可以生成二维码检测别人是否付款"
  },
  {
    "objectID": "posts/677b72f2-f2b0-44f1-a181-724286a16fc1/index.html",
    "href": "posts/677b72f2-f2b0-44f1-a181-724286a16fc1/index.html",
    "title": "开放api 信息来源",
    "section": "",
    "text": "cat as a service not infinite user provided content:\nhttps://cataas.com/#/\nhttps://cataas.com/cat/gif/says/Hello?filter=sepia&color=orange&size=40&type=or"
  },
  {
    "objectID": "posts/ce30d99a-b8f1-4adf-8a85-b87f6dcbaa70/index.html",
    "href": "posts/ce30d99a-b8f1-4adf-8a85-b87f6dcbaa70/index.html",
    "title": "Mastering Android Reverse Engineering Tools: IDA, Ghidra, Frida, GDA and Flowdroid",
    "section": "",
    "text": "安卓反编译\nida ghidra frida\nfrida extension/helper methods\nattach existing process\nsudo frida-ps\nsudo frida -n WeChat\nsudo frida -p [pid]\ngda 交互式Android反编译 支持数据流追踪\nflowdroid"
  },
  {
    "objectID": "posts/5732e839-ee46-438a-860b-2a48b8f0aad6/index.html#站着操作电脑-需要脚踏板式的跑步机",
    "href": "posts/5732e839-ee46-438a-860b-2a48b8f0aad6/index.html#站着操作电脑-需要脚踏板式的跑步机",
    "title": "夏天制冷装置",
    "section": "站着操作电脑 需要脚踏板式的跑步机",
    "text": "站着操作电脑 需要脚踏板式的跑步机\n循环水床垫\n循环水马甲\n带风扇的坐垫和靠背\n地板瓷砖\n加湿器风扇\n水空调 自动加水 工业\n除湿机 自动排水\n高锰酸钾\n软加硬空调出风挡板 强力胶带 防水\n移动双风道空调"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#自建搜题库-搜索公式的引擎-给学生提供服务",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#自建搜题库-搜索公式的引擎-给学生提供服务",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "自建搜题库 搜索公式的引擎 给学生提供服务",
    "text": "自建搜题库 搜索公式的引擎 给学生提供服务"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#破解学校系统-往学校的系统和服务器上面放病毒-让所有访问的人挖矿-让服务器挖矿",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#破解学校系统-往学校的系统和服务器上面放病毒-让所有访问的人挖矿-让服务器挖矿",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "破解学校系统 往学校的系统和服务器上面放病毒 让所有访问的人挖矿 让服务器挖矿",
    "text": "破解学校系统 往学校的系统和服务器上面放病毒 让所有访问的人挖矿 让服务器挖矿"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#自动提醒上课",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#自动提醒上课",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "自动提醒上课",
    "text": "自动提醒上课\n如果新添加或者复读某些课程 课表会发生变化\n所有的课程念一遍了之后 这个程序可以完全离线运行"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#网课找答案",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#网课找答案",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "网课找答案",
    "text": "网课找答案\n微型计算机基础 第一单元测验答案\n通用网课找答案 根据网课名字找答案 可以和百度一起用"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#慕课堂课程码-雨课堂课程码",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#慕课堂课程码-雨课堂课程码",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "慕课堂课程码 雨课堂课程码",
    "text": "慕课堂课程码 雨课堂课程码\n微信扫描二维码添加慕课课堂（网页版本）\n微信点击进入慕课堂 慕课堂需要课程码添加\n微型计算机与接口技术 慕课堂 8X5MLW 这门课程说是在网页上面做题 可以在这里收集课件 雨课堂 5JGDZ"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#tools-for-table-coversion",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#tools-for-table-coversion",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "tools for table coversion",
    "text": "tools for table coversion\nhtml table to markdown not work so well\nmarkdown to csv"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#作息时间表",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#作息时间表",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "作息时间表",
    "text": "作息时间表\n|课程编号|课程时间 |\n— | — |\n预备铃 | 7:50\n第1节 | 8:00—8:45\n第2节 | 8:50—9:35\n第3节 | 9:50—10:35\n第4节 | 10:40—11:25\n第5节 | 11:30—12:15\n预备铃 | 13:35\n第6节 | 13:45—14:30\n第7节 | 14:35—15:20\n第8节 | 15:35—16:20\n第9节 | 16:25—17:10\n第10节 | 18:30—19:15\n第11节 | 19:25—20:10\n第12节 | 20:20—21:05"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#第一学期-课表",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#第一学期-课表",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "2022-2023 第一学期 课表",
    "text": "2022-2023 第一学期 课表\nneed improvement."
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#inspiration",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#inspiration",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "inspiration",
    "text": "inspiration\n苹果前首席设计师对大学生讲的话:\nwilling to learn is far more important than being correct.\nopinion is not idea."
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#策略",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#策略",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "策略",
    "text": "策略\ndo not pretent to cooperate. we are alone. always.\n\n8月19号 13:20分开始不听课 执行我们的计划（应该是pyjom的渲染框架测试）直到晚上11点整\n\n我觉得这帮人就压根没想把我讲懂 这帮人只是想一味的做重复计算 不注重实际 说白了就是穷鬼 穷逼 一天到晚不想赚钱就想念经 不告诉我怎么赚钱 我听个屁\n课可听可不听 可以完全不听 题随便做一做 爱做完做不完完全不管 都是装样子 必须把所有时间拿出来执行我们的pyjom计划以及其他在schedule上面的计划\n能抄就抄 不抄也无所谓 都是拿钱做烂事的人 我本来就不需要学这些破烂玩意 能赚钱就行学那么多找死么 只要我们把计划实施完成 这些烂人拿我们一点办法没有"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#目前全部的内容-不知道需不需要学-看看下学期转专业成功了没",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#目前全部的内容-不知道需不需要学-看看下学期转专业成功了没",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "目前全部的内容 不知道需不需要学 看看下学期转专业成功了没",
    "text": "目前全部的内容 不知道需不需要学 看看下学期转专业成功了没\nB0300311S 高级语言程序设计A 3.0 必修 45\nB0400032S 数字电路与逻辑设计B 3.0 必修 旷考\nB0600311S 大学物理(上) 4.0 必修 37\nB0600411S 制图基础及计算机绘图 2.0 必修 40\nB0900241C 形势与政策 IV 0.0 必修 旷考\nB0900241C 形势与政策 IV 0.0 必修 旷考\nB1900011C 金工实习 1.0 必修 旷考\nB0400101S 模拟电子线路B 4.0 必修 24\nB0600321S 大学物理(下) 3.0 必修 23\nB0601341S 高等数学A（Ⅰ）下 6.0 必修 34\nB0900013S 思想道德修养与法律基础 2.0 必修 旷考\nB2000021C 计算机应用基础能力考核 0.0 必修 旷考\nB0364071C 程序设计(上机) 2 必修 不及格\nB0800042S 大学英语Ⅳ 3.0 必修 56\nB0400032S 数字电路与逻辑设计B 3.0 必修 30\nB0403032S 应用光学(双语) 2.5 必修 旷考\nB0403171S 光电信息物理基础 3.5 必修 29\nB0601331S 高等数学A（Ⅰ）上 6.0 必修 43\nB0800042S 大学英语Ⅳ 3.0 限选 旷考\nB1100081S 电工电子基础实验A 4.0 必修 旷考\nB1100081S 电工电子基础实验A 4.0 必修 旷考\nB0800032S 大学英语Ⅲ 3.0 必修 旷考\nB0403171S 光电信息物理基础 3.5 必修 旷考\nB0900034S 中国近现代史纲要 3.0 必修 52\nB0462021C 认识实习 0.5 必修 旷考\nB0600381S 物理实验（下） 1.5 必修 旷考\nB0900231C 形势与政策 III 0.0 必修 旷考\nB0200032S 信号与系统B 3.0 必修 34\nB0400012S 电路分析基础B 3.0 必修 旷考\nB0402221S 电磁场理论与光波导技术 3.0 必修 27\nB0600031S 线性代数与解析几何 3 必修 43\nB0600071S 概率统计和随机过程 4.0 必修 32\nB0600121S 高等数学A（上） 5.0 必修 36\nB0600371S 物理实验（上） 1.5 必修 27\nB0962051C 思修实践 1.0 必修 旷考\nB1163011C 电装实习 1.0 必修 旷考 ⏎"
  },
  {
    "objectID": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#已经复习了的-不知道能不能过",
    "href": "posts/71359f52-2ae2-42d6-98c4-bb5b4e1da0ad/index.html#已经复习了的-不知道能不能过",
    "title": "复习补考的科目 补课 课程 补习",
    "section": "已经复习了的 不知道能不能过",
    "text": "已经复习了的 不知道能不能过\n高级语言程序设计A B0300311S\n数字电路与逻辑设计B B0400032S\n程序设计(上机) B0364071C\n大学英语Ⅳ B0800042S\n大学英语Ⅲ B0800032S"
  },
  {
    "objectID": "posts/c1c4c068-4d79-4c85-b6aa-f972ec7f0414/index.html",
    "href": "posts/c1c4c068-4d79-4c85-b6aa-f972ec7f0414/index.html",
    "title": "国信iquant平台分析",
    "section": "",
    "text": "iquant基于迅投qmt平台开发 不支持极简模式 即使是极简模式也需要识别输入验证码 在Windows平台上运行 支持python36-38\nxtquant github repo\n国金qmt下载地址 官网貌似找不到了所以放这里 安装文档 开户\n量化交易笔记\n最新国内外量化平台汇总 包含数据来源 支持实盘的券商\nqmt mini使用\n国盛证券qmt mini模式 xtquant qmt客户端下载\n迅投qmt微信专栏合集"
  },
  {
    "objectID": "posts/cd5256e9-1cff-409b-9b65-63b9939f0047/index.html",
    "href": "posts/cd5256e9-1cff-409b-9b65-63b9939f0047/index.html",
    "title": "哔哩哔哩 接口 Bilibili APIs",
    "section": "",
    "text": "bilibili上传工具 biliup\nbilibili toolkit\napi合集\nhttps://www.bilibili.com/read/cv3430609/\n官方接口文档\nhttps://github.com/fython/BilibiliAPIDocs\n直播api\nhttps://github.com/lovelyyoshino/Bilibili-Live-API\n野生api收集\nhttps://github.com/SocialSisterYi/bilibili-API-collect\npython api\nhttps://github.com/MoyuScript/bilibili-api\nhttps://github.com/Nemo2011/bilibili-api\nhttps://github.com/Vespa314/bilibili-api\n提交视频剧情树"
  },
  {
    "objectID": "posts/506afef5-ff55-44d1-b448-25f79c62b997/index.html",
    "href": "posts/506afef5-ff55-44d1-b448-25f79c62b997/index.html",
    "title": "动漫剪辑过审",
    "section": "",
    "text": "剪的时候不要超过4分钟 可以用spleeter切出语音 加入自己的背景音乐\n这个属于anti nsfw anti censorship 反内容审查 反视频审查 对抗机制 可以在github上面搜索\n二创某种意义也是反审查\n审查的 nsfw 微信小程序 可以解包 然后调用别人的接口 可能不稳定\nhttps://github.com/superdashu/frida_with_wechat_applet\nhttps://github.com/superdashu/pc_wxapkg_decrypt_python"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#run-python-in-browser",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#run-python-in-browser",
    "title": "关于做直播 about live streaming",
    "section": "run python in browser",
    "text": "run python in browser\npyodide\npyscript\nskulpt"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#pass-parameter-via-url",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#pass-parameter-via-url",
    "title": "关于做直播 about live streaming",
    "section": "pass parameter via url",
    "text": "pass parameter via url\nget url anchor text\nyou can still use query string when visiting github.io\nfunction getQueryStringValues(key) {\nvar arrParamValues = [];\nvar url = window.location.href.slice(window.location.href.indexOf('?') + 1).split('&');\nfor (var i = 0; i &lt; url.length; i++) {\nvar arrParamInfo = url[i].split('=');\nif (arrParamInfo[0] == key || arrParamInfo[0] == key+'[]') {\narrParamValues.push(decodeURIComponent(arrParamInfo[1]));\n}\n}\nreturn (arrParamValues.length &gt; 0 ? (arrParamValues.length == 1 ? arrParamValues[0] : arrParamValues) : null);\n}"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#保存粉丝cookie-避免接入xpay之后反复输入地址",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#保存粉丝cookie-避免接入xpay之后反复输入地址",
    "title": "关于做直播 about live streaming",
    "section": "保存粉丝cookie 避免接入xpay之后反复输入地址",
    "text": "保存粉丝cookie 避免接入xpay之后反复输入地址\nset and get a cookie with javascript"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#付钱兑换礼物",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#付钱兑换礼物",
    "title": "关于做直播 about live streaming",
    "section": "付钱兑换礼物",
    "text": "付钱兑换礼物\n要能够有效识别付钱的对象 用浏览器的cookie 送达目标地址\n过滤人名\n过滤群聊里面的广告内容 色情 暴恐 声音不对劲要去掉 合适的BGM\n直播上传带宽要保证 延迟要低\n“聚合直播”\n做直播最重要的就是互动性\n你可以直播群友聊天的画面 要去掉含有个人隐私的头像或照片 信息 QQ Email 要过滤掉nsfw的内容 操作qq机器人来和群友说话 或者让送礼物最多的人获得发言权 排行榜最上面的人获得发言权 群聊也不一定要单一 多个群一起弄 甚至多个社交软件一起弄 群聊私聊一起用\n你也可以参考其他的主播 看看他们是怎么做的\n可以通过分析评论 切换直播主题 切换直播画面"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#免签支付-获取订单号-给粉丝发福利-vip",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#免签支付-获取订单号-给粉丝发福利-vip",
    "title": "关于做直播 about live streaming",
    "section": "免签支付 获取订单号 给粉丝发福利 VIP",
    "text": "免签支付 获取订单号 给粉丝发福利 VIP\nb站充电API\nhttps://www.yunmianqian.com\nhttps://github.com/assimon/easymqpay\nhttps://github.com/szvone/vmqphp\nhttps://github.com/wxs2/xposed-pay\nhttps://github.com/szvone/vmqApk\nvmqapk 最新修改版\nxpay 这个东西需要人工监听 跪了"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-8",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-8",
    "title": "关于做直播 about live streaming",
    "section": "随想 8",
    "text": "随想 8\n视频广告\nYukio 21:46:07\n应该来个淡入淡出之类的\nYukio 21:46:25\n还有一个试看结束的提示\nYukio 21:46:37\n试看开始之前的提示\n播放视频内容也要有提示 开头和结尾要给人知道这个截取的片段是干什么的"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-7",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-7",
    "title": "关于做直播 about live streaming",
    "section": "随想 7",
    "text": "随想 7\nYukio 01:56:43\n付了款 留下联系方式 给你发福利\nYukio 01:57:16\n但是万一有些人滥用呢\nYukio 01:57:36\n发一些奇奇怪怪的联系方式或者邮箱\nYukio 01:57:55\n给我发些什么监察委员会的邮箱\nYukio 01:58:32\n我可以增加一个取消订阅按钮 让这些人取消订阅 别找我麻烦\nYukio 02:01:28\n或者我把文件上传到一次性的文件分享页面\nYukio 02:01:38\n过几个小时自动取消分享"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-6",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-6",
    "title": "关于做直播 about live streaming",
    "section": "随想 6",
    "text": "随想 6\nYukio 01:06:16\n这个我直播间可以根据uid和活跃等级\nYukio 01:06:24\n持久化你的活跃度\nYukio 01:06:34\n充钱也可以升级\nYukio 01:06:44\n送我礼物\nYukio 01:07:21\n如果是直接wx转钱给我 这个估计得给我发交易单号 私信发我才能兑换呢\nYukio 01:07:31\n至于怎么找这个交易单号\nYukio 01:07:34\nemm\nYukio 01:08:36\n我想想\nYukio 01:09:28\n这个估计得对接第四方交易接口 或者我看看现成的实现\nYukio 01:10:32\n同时 给我的视频留言 发弹幕也可以刷活跃度\nYukio 01:10:42\n刷直播间给你显示的活跃度\nYukio 01:12:39\n如果给我充钱 我会发你涩图 冲的多发的多\nYukio 01:12:50\n至于怎么发\nYukio 01:12:59\n发你邮箱 你留下邮箱地址我发你\nYukio 01:15:57\n不需要涩图也可以个性化定制\nYukio 01:16:19\n如果给我充钱 一段时间内不会有给我打钱的二维码\nYukio 01:16:40\n不给我充 不给我私信 我就一直发给我打钱的二维码\nYukio 01:17:37\n如果给我充钱 可以绑定相关QQ账号 邮箱账号 或者什么其他的社交账号 每个平台只能绑一个账号\nYukio 01:18:14\n绑了之后 给钱 一段时间我的内容没有打钱二维码 私信的话\n你主动加我为好友才行"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-5",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-5",
    "title": "关于做直播 about live streaming",
    "section": "随想 5",
    "text": "随想 5\nYukio 23:05:52\n为了检测这种二维码\nYukio 23:06:30\n同时有一些不是很好检测的文字 水印\nYukio 23:06:44\n也需要image local contrast enhancement\nYukio 23:25:11\n随机切割句子 分批发送\nYukio 23:25:16\n这样我的机器人更像人\nimage enhancement for optical character recognition\nimage enhancement for watermark removal"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-4",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-4",
    "title": "关于做直播 about live streaming",
    "section": "随想 4",
    "text": "随想 4\nYukio 21:00:32\nnsfw没必要每一帧都加\nYukio 21:00:38\n可以跳着加\nYukio 21:00:52\n然后把出问题的帧的周围全部ban掉\nYukio 21:01:07\n但是除了画面\nYukio 21:01:16\n声音娇喘的也得去掉\nYukio 21:01:24\n这个娇喘\nYukio 21:01:41\n用个声音分类器\nYukio 21:01:51\n用狗叫分类器改一下就好了\nYukio 21:02:12\n除了娇喘\nYukio 21:02:20\n还得弄语音识别\nYukio 21:02:35\n防止某些狗叫言论污染直播间"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-3",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-3",
    "title": "关于做直播 about live streaming",
    "section": "随想 3",
    "text": "随想 3\n直播的通知 当直播的主题变化的时候 把广告发到不同的群 不同的观众那里"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-2",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-2",
    "title": "关于做直播 about live streaming",
    "section": "随想 2",
    "text": "随想 2\n不和谐的 包括有链接的内容 有二维码的内容 有联系方式的内容 加标点符号的广告内容 重复发送的内容\nYukio 14:26:10\n可以看到其实判别不和谐言论很难\nYukio 14:26:23\n所以可以用谐音字 拼音判断\nYukio 14:26:51\n加上不信任期 一旦出现不和谐言论 一段时间内不用这个群聊\nYukio 14:27:15\n以及繁体字转简体字"
  },
  {
    "objectID": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-1",
    "href": "posts/ef046502-b05c-4d1e-a80c-da41a5d7fff2/index.html#随想-1",
    "title": "关于做直播 about live streaming",
    "section": "随想 1",
    "text": "随想 1\nYukio 22:29:44\n我直播群友聊天咋样？\nYukio 22:30:07\n我直播群友聊天 然后给我留言的人 有机会把消息发到群里面来\nYukio 22:30:30\n其中送礼物送的最多的发消息发进来的概率最大\nYukio 22:31:49\n不仅如此 我还多个群聚合聊天 多社交软件 多语言聚合聊天\nYukio 22:32:06\n我还可以自由切换话题 自动翻译\nYukio 22:32:36\n也就是说如果你和外国人聊天 你说中文变英文\nYukio 22:32:46\n别人说英文变中文\n黑暗骑士 22:33:20\n直播看你装奈子\nYukio 22:33:33\nnsfw不能直播\nYukio 22:33:45\n直播最重要的是互动啊\nYukio 22:33:51\n播其他的也行\nYukio 22:34:06\n但是装柰子 也得sfw\nYukio 22:34:19\n所以有可能需要打码\nYukio 22:34:29\n检测出来nsfw区域 自动打码\nYukio 22:34:36\n或者全屏打码\nYukio 22:35:07\n你说什么 我可以给你在线搜索视频给你看\nYukio 22:35:49\n你不说话的时候我就挑热门视频和热门直播转发\nYukio 22:36:15\n根据进来的观众们的历史观看记录和历史发言来播视频\nYukio 22:42:38\n这个换台的话 本人三分钟可以撤销两次\nYukio 22:43:09\n而其他人在本人获得换台权利之后 三分钟之后才能继续排队\nYukio 22:43:23\n早就不招了\nYukio 22:44:29\n你建的话 我有过滤器啊\nYukio 22:44:32\n你可以建\nYukio 22:44:57\n但是要是有关键字 我这边不会播你的\nYukio 22:45:08\n而且头像和昵称\nYukio 22:45:13\n不会有\nYukio 22:46:05\n如果sfw\nYukio 22:46:14\n那么就是不够涩\nYukio 22:46:18\n也不会有问题\nYukio 22:46:40\n再说了\nYukio 22:46:51\n让别人跟你聊天不是好事么\nYukio 22:47:16\n取决于涩涩的程度"
  },
  {
    "objectID": "posts/5cf4e7ec-9e3f-4cbc-b9b1-d527016511c7/index.html",
    "href": "posts/5cf4e7ec-9e3f-4cbc-b9b1-d527016511c7/index.html",
    "title": "关于人类发展规律和需求的随想",
    "section": "",
    "text": "人需要获得海量信息然后才能在某些领域取得成就 这个相互关系有强相关和弱相关的范畴"
  },
  {
    "objectID": "posts/c1ca6a71-6a33-4449-a768-aeb828a3cd8d/index.html#收集别人的帐号然后登录",
    "href": "posts/c1ca6a71-6a33-4449-a768-aeb828a3cd8d/index.html#收集别人的帐号然后登录",
    "title": "免流帮 停机卡上网 持续上网",
    "section": "收集别人的帐号然后登录",
    "text": "收集别人的帐号然后登录\nkali负责收集网络帐号 然后在一个web页面上面提供一个加密的auth接口 最好是rsa加密的东西 有时间延迟防暴力破解的访问接口 通过验证之后可以获得用户名密码 同时可以访问相应接口进行占用或者解除占用 当然你也可以直接弄个静态的页面谁也破解不了 但是访问的时候就得一个一个的尝试 当然也更安全"
  },
  {
    "objectID": "posts/c1ca6a71-6a33-4449-a768-aeb828a3cd8d/index.html#免流卡",
    "href": "posts/c1ca6a71-6a33-4449-a768-aeb828a3cd8d/index.html#免流卡",
    "title": "免流帮 停机卡上网 持续上网",
    "section": "免流卡",
    "text": "免流卡\n微信小程序 免流帮\nqq群：857969390\n搜索github\n校园网也可以免认证登录"
  },
  {
    "objectID": "posts/d5db3ceb-9117-4d5a-a712-2686e859e57e/index.html",
    "href": "posts/d5db3ceb-9117-4d5a-a712-2686e859e57e/index.html",
    "title": "传播学 2",
    "section": "",
    "text": "传播学 2"
  },
  {
    "objectID": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html#tools",
    "href": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html#tools",
    "title": "临时存储文件 temp fiiles host api",
    "section": "tools",
    "text": "tools\npyupload\ncatmoe recommend tools\nuguu tools"
  },
  {
    "objectID": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html#支持api存储",
    "href": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html#支持api存储",
    "title": "临时存储文件 temp fiiles host api",
    "section": "支持api存储",
    "text": "支持api存储\nanonyfiles api need login\nlist of pomf based temp file hosts\nuguu api\ncatbox.moe api referred as sharex format\ntmpfiles api\ntransfer.sh\ngofile.io\nnopaste.net with curl and netcat endpoint"
  },
  {
    "objectID": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html#不支持api-需要探索",
    "href": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html#不支持api-需要探索",
    "title": "临时存储文件 temp fiiles host api",
    "section": "不支持api 需要探索",
    "text": "不支持api 需要探索\nprivfile with download limit\nhelix\ntempd.link"
  },
  {
    "objectID": "posts/2eaed25d-949b-4d99-9511-c9e57c657c8a/index.html",
    "href": "posts/2eaed25d-949b-4d99-9511-c9e57c657c8a/index.html",
    "title": "一堆电子书 可能适合作为pdf搜索的起点",
    "section": "",
    "text": "把电子书变成wiki 方便批注 网友协作\npylucene\njina cloud host jina search instances for free, currently\nuse apache tika for document parsing\nxapian supported document formats\nsearch for document search on github\n实验性搜索数据地址：\n/Users/jamesbrown/desktop/works/course_video_convert/sample/documentsAndFiles\n纸质书阅读效率极低 利用效率极低 不可以修改 不可以复制 不可以随时查看搜索 属于一种古老的信息储存和交换形式\n如果在纸质书上面写内容 意味着你只是把纸当作记忆的工具 不可能发挥“电脑”的功能\nhttps://github.com/James4Ever0/Book\n下面这些都有向同一个地方引流的行为\nhttps://github.com/lTbgykio/Books-Free-Books\nhttps://github.com/Dujltqzv/Some-Many-Books\n书籍互助脚本\nhttps://greasyfork.org/zh-CN/scripts/420751-%E5%9B%BE%E4%B9%A6%E4%BA%92%E5%8A%A9\nhttps://greasyfork.org/zh-CN/scripts/432075-%E7%A7%80%E8%AF%BB%E5%9B%BE%E4%B9%A6%E4%BA%92%E5%8A%A9"
  },
  {
    "objectID": "posts/6f060c93-0ab8-4ddd-98d3-33c242683db7/index.html",
    "href": "posts/6f060c93-0ab8-4ddd-98d3-33c242683db7/index.html",
    "title": "yaml special token cause error to pyyaml",
    "section": "",
    "text": "special token like !&lt;str&gt; need to be converted to !!str, while writing back we just do it in reverse.\nfull reference of pyyaml is here"
  },
  {
    "objectID": "posts/0cdbf7da-e384-4341-90d2-1f4d66b1b536/index.html",
    "href": "posts/0cdbf7da-e384-4341-90d2-1f4d66b1b536/index.html",
    "title": "Time Machine Alternative for linux/windows",
    "section": "",
    "text": "use test to check existance some manual created identity file to prove if the endpoint is connected\n(really? does that check work for offline rclone samba drives?)\n\nformat the backup disk as xfs so we can do symlink on it (linux).\n\nuse flock (from util-linux) to prevent multiple backup instances from running.\nalternative: run-one\nsudo apt-add-repository ppa:run-one/ppa\nsudo apt-get update\nsudo apt-get install run-one\n\nlinux-timemachine supports windows, linux, macOS, using rsync as backend, can use hardlink to make backup management very easy. can delete previous backup without losing data. need external controller to make “circular” or to only keep most recent backups on disk.\ncurated list of alternative time machine for OSes other than macOS\ntimeshift gui backup/restore tool for linux\nduplicity incremental backup can store backup into encrypted tar files and support IMAP protocol as remote file server"
  },
  {
    "objectID": "posts/66e5e939-68ce-4179-a972-f2de82505f07/index.html",
    "href": "posts/66e5e939-68ce-4179-a972-f2de82505f07/index.html",
    "title": "what is causing my mac to freeze when kali is offline",
    "section": "",
    "text": "modified scripts:\n/Users/jamesbrown/Desktop/works/host_discovery_ssh_local_connect/load_tuntap_launch_n2n_kali_root.sh\n/Users/jamesbrown/Desktop/works/host_discovery_ssh_local_connect/nginx_with_kali_finder.sh\n/Library/Application Support/ZeroTier/One/launch.sh\nseems zerotier one is the main cause!"
  },
  {
    "objectID": "posts/94e9bb2c-2801-4096-87dd-800e0d951d9f/index.html",
    "href": "posts/94e9bb2c-2801-4096-87dd-800e0d951d9f/index.html",
    "title": "web scraping logic",
    "section": "",
    "text": "select targets for scraping. it could be your browsing history, package indexs, social media (dynamic contents, with different accessing methods than web scraping)\nif not accessible, access it with proxies, cookies.\nfinally store the content into compat and usable formats, categorized and linked"
  },
  {
    "objectID": "posts/9a4eed3a-8b90-4a6e-ab30-2f5e72d1b153/index.html",
    "href": "posts/9a4eed3a-8b90-4a6e-ab30-2f5e72d1b153/index.html",
    "title": "vxworks binary reverse engineering",
    "section": "",
    "text": "vxpwn vxworks exploit scripts\nrun vxworks in vmware maybe in qemu?\nusing serial port to reverse engineering a router\nvxhunter toolsets for vxworks based embedded device analysis\nschneider noe7701 backdoors and similar process\ncapstone related reverse engineering tools\nfull list of tools (showcase) using capstone as backend"
  },
  {
    "objectID": "posts/3f3a6a0e-d6a8-4a6c-8803-ee3dfa913958/index.html#vim",
    "href": "posts/3f3a6a0e-d6a8-4a6c-8803-ee3dfa913958/index.html#vim",
    "title": "vim session restore",
    "section": "vim",
    "text": "vim\nvim session manager\nmethods to automate :mksession\nvim workspace auto save workspace and undo history\nbuiltin :mksession and more"
  },
  {
    "objectID": "posts/3f3a6a0e-d6a8-4a6c-8803-ee3dfa913958/index.html#nvim",
    "href": "posts/3f3a6a0e-d6a8-4a6c-8803-ee3dfa913958/index.html#nvim",
    "title": "vim session restore",
    "section": "nvim",
    "text": "nvim\nsession manager usage for vim and nvim\nsession manager for vim and nvim\nnvim auto-session"
  },
  {
    "objectID": "posts/b2e4e778-9f36-4ea8-815e-324e3fc41364/index.html",
    "href": "posts/b2e4e778-9f36-4ea8-815e-324e3fc41364/index.html",
    "title": "video picture in picture detection",
    "section": "",
    "text": "视频画中画是流行的伪原创方法 但是检测很难 同时加大了二次利用的难度（或许可以再加一层画中画？？）\n目前找到了一个国内画中画检测专利，以及国外画中画检测论文"
  },
  {
    "objectID": "posts/097a59b9-2109-4a81-8f9f-390bfe3714c5/index.html",
    "href": "posts/097a59b9-2109-4a81-8f9f-390bfe3714c5/index.html",
    "title": "vapoursynth 光流算法 补帧 画面优化 denoising",
    "section": "",
    "text": "nazobase NAZOrip basement, with cython dll docs\nDBmbk a debanding toolkit, for easier bezier curve generation\nffmpeg super resolution filter could get faster if run on gpu with libtensorflow\nVESPCN: real-time super resolution\nmpv is a media player with VapourSynth built-in, and that’s probably how vapoursynth gets in my mac via brew dependency manager\nview.py is Python module for vapoursynth scripts that previews clips\nto use opencv functions with vapoursynth\nsvp is free on linux, offering plugin for vlc while vlc cannot be run as root\nyou might harvest some prebuilt binaries of vapoursynth plugins for linux\n补帧算法可适用于我们的动态水印追踪系统 但是可能需要优化 才能做到比较快速的补帧 因为水印所在位置的区间实际上只是白色的 不需要过于复杂的网络 同时这种补出来的水印需要逐帧处理 或者两帧一处理 生成的区间数量会非常的多\nit is much easier to do this on windows since we need quick evaluation. might run this on virtualbox?\nbuild scripts on how to build plugins for macos, including how to configure the installation prefix.\nbrew compatible, macos compatible vapoursynth plugin build script provider: homebrew-vsplugins does not provide build scripts for all plugins avaliable for windows, and it requires additional linking\ntutorial on how to configure it: (is it intel only?)\nAlternative VapourSynth Install Method (Brew):\nIMPORTANT: Brew users will need to create and set the autoload folder prior to installing VapourSynth! Simply run the following commands:\nCode:\nmkdir -p /usr/local/lib/vapoursynth\nmkdir -p \"$HOME/Library/Application Support/VapourSynth\"\ntouch \"$HOME/Library/Application Support/VapourSynth/vapoursynth.conf\"\necho UserPluginDir=/usr/local/lib/vapoursynth &gt;&gt; \"$HOME/Library/Application Support/VapourSynth/vapoursynth.conf\"\necho SystemPluginDir=/usr/local/lib/vapoursynth &gt;&gt; \"$HOME/Library/Application Support/VapourSynth/vapoursynth.conf\"\n(Optional) Create desktop shortcuts for the plugins and scripts folders. Run the following commands in terminal:\nCode:\nmkdir $HOME/Desktop/VapourSynth\nln -s /usr/local/lib/vapoursynth $HOME/Desktop/VapourSynth/Plugins\nln -s /usr/local/lib/python3.9/site-packages $HOME/Desktop/VapourSynth/Scripts\nUse brew command:\nCode:\nbrew install vapoursynth\nbm3d denoising using cuda\nfft3d denoising\npython opencv 光流算法详解 分为sparse和dense两种 某种程度上都可以计算场景的变换激烈程度\nframe interpolation using deep optical flow\nopenmmlab mmflow\ngoogle research: FILM (frame interpolation for large motion)\nvapoursynth get started (official doc)\nvapoursynth plugin database only provide prebuilt binaries for windows while the plugin source code might work with linux and macos (if it has the source code)\nVSRepo plugin manager installing vapoursynth plugin via commandline tool and vsrepo is only supported on windows, for other platforms we need to compile plugins manually.\nnazorip vapoursynth blogs\nnazorip bezier curve\nnazorip gamma curve and convolution\nflowpy: tool for visualizing and processing image with optical flow"
  },
  {
    "objectID": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#creating-lists",
    "href": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#creating-lists",
    "title": "useful java patterns",
    "section": "creating lists",
    "text": "creating lists\nvar a = new ArrayList&lt;&gt;(Arrays.asList(1,2,3));\nvar mset = new HashSet&lt;&gt;();\nmset.addAll(a);\nvar mset2 = a.stream().collect(Collectors.toSet());\nvar mymin = Collections.min(a);\nvar mymax = Collections.max(a);\nCollections.reverse(a);\nvar a = arrayOf(1,2,3);\nprint(a.contentToString())\nprint(a.max())\nprint(a.min())\na.reverse()"
  },
  {
    "objectID": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#creating-hashmap",
    "href": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#creating-hashmap",
    "title": "useful java patterns",
    "section": "creating hashmap",
    "text": "creating hashmap\nvar ah= new HashMap&lt;&gt;();\nah.put(1,2);\nvar ah = hashMapOf(1 to 2, 2 to 3)"
  },
  {
    "objectID": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#iterate-lists-with-indices",
    "href": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#iterate-lists-with-indices",
    "title": "useful java patterns",
    "section": "iterate lists with indices",
    "text": "iterate lists with indices\njava double colon :: operator acts as anonymous function\nvar l = a.listIterator();\nwhile (l.hasNext()){\nvar index = l.nextIndex();\nvar val = l.next();\nSystem.out.println(\"INDEX: \"+index+\" ELEM: \"+val);\n}\nIntStream.range(0,a.size()).forEach(index -&gt; a.get(index));\nvar index=0;\nfor (int i: a){\nindex++;\n}\na.forEachIndexed{ind, elem -&gt; println(\"index? $ind\"); println(\"elem? $elem\")}\nfor (var i in a.indices){\nvar elem = a[i]\n}\na.indices.forEach {\nvar elem = a[it]\nelem\n}"
  },
  {
    "objectID": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#list-comprehension",
    "href": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#list-comprehension",
    "title": "useful java patterns",
    "section": "list comprehension",
    "text": "list comprehension\nvar mlist = a.stream().map(x-&gt; x*2).collect(Collectors.toList());\nvar evenNums = a.stream().filter(x-&gt; x%2 == 0).collect(Collectors.toList());\nvar mmap = a.stream().collect(Collectors.toMap(x-&gt;x.getId(),x-&gt;x.getName()));"
  },
  {
    "objectID": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#switch-expressions",
    "href": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html#switch-expressions",
    "title": "useful java patterns",
    "section": "switch expressions",
    "text": "switch expressions\nvar val = 2;\nvar mswitch = switch (val){\ncase 1,2,3 -&gt; {\nyield \"good\";\n}\ncase 4,5,6 -&gt; {\nyield \"bad\";\n} // either throw or yield.\ndefault -&gt; {\nSystem.out.println(\"out of expectation\");\nyield \"really bad\";\n}\n};\nSystem.out.println(mswitch);\nvar grade = 30\nvar res =  when(grade) {\nin 0..40 -&gt; \"Fail\"\nin 41..70 -&gt; \"Pass\"\nin 71..100 -&gt; \"Distinction\"\nelse -&gt; false\n}\nprint(res)\nvar mcase = 1\nvar res = when(mcase){\n1 -&gt; \"good\"\n2 -&gt; \"bad\"\nelse -&gt; \"really bad\"\n}\nprint(res)\n\ncount occurance of elements in array\nString[] array = {\"name1\",\"name2\",\"name3\",\"name4\", \"name5\", \"name2\"};\nArrays.stream(array)\n.collect(Collectors.groupingBy(s -&gt; s))\n.forEach((k, v) -&gt; System.out.println(k+\" \"+v.size()));\nList asList = Arrays.asList(array);\nSet&lt;String&gt; mySet = new HashSet&lt;String&gt;(asList);\nfor(String s: mySet){\nSystem.out.println(s + \" \" + Collections.frequency(asList,s));\n}\nMap&lt;String, Long&gt; map = Arrays.stream(array)\n.collect(Collectors.groupingBy(s -&gt; s, Collectors.counting()));\nvar a = arrayOf(1,2,3,3,3,3)\na.toSet().forEach{it -&gt; println(\"elem? $it\"); println(\"count? \"+a.count{it2-&gt;it2 == it})}\n\n\nlambdas\nConsumer mcons = (n) -&gt; {System.out.println(n);}\nmcons.andThen(mcons).accept(\"mval\");\nFunction &lt;Integer,Integer&gt; mfunc = n-&gt; n+1;\nSupplier msup = () -&gt; 1;\nvar mval = msup.get();\nvar mfunc = {n :Int -&gt; n+1}\nvar mprint = {n:Any -&gt; print(n)}"
  },
  {
    "objectID": "posts/d175841d-b8e3-41a9-8527-4c2d05192ba4/index.html",
    "href": "posts/d175841d-b8e3-41a9-8527-4c2d05192ba4/index.html",
    "title": "unmount disks forcefully",
    "section": "",
    "text": "tutorial\nbasically killing process using it, lazy unmount, force unmount on NFS and so on."
  },
  {
    "objectID": "posts/6e210a17-e15a-4751-b926-65925d021a41/index.html",
    "href": "posts/6e210a17-e15a-4751-b926-65925d021a41/index.html",
    "title": "typing backtick “`” with my current splitable keyboard",
    "section": "",
    "text": "typing backtick “`” with my current splitable keyboard\nit used to work with meta+esc key, but it fails sometimes.\nthere’s a universal way: shift+alt+esc\ntype tlide “~”: shift+esc"
  },
  {
    "objectID": "posts/632276b5-d88f-4c9d-a721-db7e1ae1afc2/index.html",
    "href": "posts/632276b5-d88f-4c9d-a721-db7e1ae1afc2/index.html",
    "title": "turing-project and his works on AI and NLP",
    "section": "",
    "text": "he recently interacts with racketeers on wechat, find how to add new friends (and groups if any) on wechat.\nthe bilibili user and his repo\nvideo transfer based on DCT-Net 视频洗稿 伪原创\nAntiFraudChatBot is a wechaty bot using a super large model based on megatron called Yuan 1.0 which is only freely avaliable within three month (30k api calls) when applied to chat with racketeers, another application: AI剧本杀\nmegatron deepspeed enables training large model on cheap hardware\nessaykillerbrain is another project he has involved in, which contains EssayKiller_V2 EssayKiller_V1 EssayTopicPredict WrittenBrainBase\nalphafold in mindspore"
  },
  {
    "objectID": "posts/4df6f024-3e99-4ef2-aac1-81c9d037a68a/index.html",
    "href": "posts/4df6f024-3e99-4ef2-aac1-81c9d037a68a/index.html",
    "title": "translate.com, webhooks, make money by translation",
    "section": "",
    "text": "the story from medium is about writing some listeners for quick notifications to get jobs faster.\ntranslate.com is a website for translation. you can receive money via payoneer.\nregister here as translator."
  },
  {
    "objectID": "posts/67b3a9b8-2724-403f-adfa-91339adf83f9/index.html",
    "href": "posts/67b3a9b8-2724-403f-adfa-91339adf83f9/index.html",
    "title": "tools from breachforums",
    "section": "",
    "text": "Invicti\n\nInvicti is a web application security scanner hacking tool to find SQL Injection, XSS, and vulnerabilities in web applications or services automatically.\n\nFortify WebInspect\n\nIt is used to identify security vulnerabilities by allowing it to test the dynamic behavior of running web applications.\n\nCain & Abel\n\nIt is used to recover the MS Access passwords\n\nNmap (Network Mapper)\n\nUsed in port scanning, one of the phases in ethical hacking, is the finest hacking software ever.\n\nNessus\n\nNessus is the world’s most well-known vulnerability scanner, which was designed by tenable network security. It is free and is chiefly recommended for non-enterprise usage.\n\nNikto\n\nChecks web servers and identifies over 6400 CGIs or files that are potentially dangerous\n\nKismet\n\nKismet is basically a sniffer and wireless-network detector that works with other wireless cards and supports raw-monitoring mode.\n\nNetStumbler\n\nIdentifying AP (Access Point) network configuration\n\nAcunetix\n\nIntegration of scanner results into other platforms and tools\n\nNetsparker\n\nUniquely verifies identified vulnerabilities, showing that they are genuine, not false positives\n\nIntruder\n\nIntegrates with Slack, Jira, and major cloud providers\n\nNmap\n\nContains a data transfer, redirection, and debugging tool\n\nMetasploit\n\nIdeal for finding security vulnerabilities\n\nAircrack-Ng\n\nIt can crack WEP keys and WPA2-PSK, and check Wi-Fi cards\n\nWireshark\n\nAllows coloring rules to packet lists to facilitate analysis\n\nOpenVAS\n\nOpenVAS has the capabilities of various high and low-level Internet and industrial protocols, backed up by a robust internal programming language.\n\nSQLMap\n\nSupports executing arbitrary commands\n\nEttercap\n\nLive connections sniffer\n\nMaltego\n\nPerforms real-time information gathering and data mining\n\nBurp Suite\n\nUses out-of-band techniques\n\nJohn the Ripper\n\nTests different encrypted passwords\n\nAngry IP Scanner\n\nThis is a free tool for scanning IP addresses and ports\n\nSolarWinds Security Event Manage\n\nRecognized as one of the best SIEM tools, helping you easily manage memory stick storage\n\nTraceroute NG\n\nDetects paths changes and alerts you about them\n\nLiveAction\n\nIts packet intelligence provides deep analyses\n\nQualysGuard\n\nResponds to real-time threats\n\nWebInspect\n\nTests dynamic behavior of web applications for the purpose of spotting security vulnerabilities\n\nHashcat\n\nSupports distributed cracking networks\n\nL0phtCrack\n\nFixes weak passwords issues by forcing a password reset or locking out accounts\n\nRainbow Crack\nIKECrack\n\nIKECrack is an authentication cracking tool with the bonus of being open source.\n\nSboxr\n\nChecks for over two dozen types of web vulnerabilities\n\nMedusa\n\nOne of the best tools for thread-based parallel testing and brute-force testing\n\nCain and Abel\n\nuncovers password fields, sniffs networks, recovers MS Access passwords, and cracks encrypted passwords using brute-force, dictionary, and cryptanalysis attacks.\n\nZenmap\n\nAdministrators can track new hosts or services that appear on their networks and track existing downed services"
  },
  {
    "objectID": "posts/7aa059cd-4abf-4b43-acf1-f35f5aa93d77/index.html",
    "href": "posts/7aa059cd-4abf-4b43-acf1-f35f5aa93d77/index.html",
    "title": "the singing bot",
    "section": "",
    "text": "the still image to singing face bot, lip-sync video generation\nsadtalker\nwombo.ai, likely to be talking head or yanderifier\nhttps://github.com/mchong6/GANsNRoses/\nhttps://github.com/williamyang1991/VToonify\n生成高质量的艺术人像视频是计算机图形学和视觉中一项重要且理想的任务。虽然已经提出了一系列基于强大的 StyleGAN 成功的人像图像卡通化模型，但这些面向图像的方法在应用于视频时存在明显的局限性，在这项工作中，我们通过引入一种新颖的 VToonify 框架来研究具有挑战性的可控高分辨率肖像视频风格迁移。具体来说，VToonify 利用StyleGAN 的中高分辨率层基于编码器提取的多尺度内容特征来渲染高质量的艺术肖像，以更好地保留帧细节。作为输入，有助于输出具有自然运动的完整面部区域。 amework 与现有的基于 StyleGAN 的图像卡通化模型兼容，以将其扩展到视频卡通化，并继承了这些模型的吸引人的特性，可灵活地控制颜色和强度。这项工作展示了基于 Toonify 和 DualStyleGAN 的 VToonify 的两个实例，用于基于集合广泛的实验结果证明了我们提出的 VToonify 框架在生成具有灵活风格控制的高质量和时间连贯的艺术肖像视频方面优于现有方法的有效性\nall in one colab text to talking face generation, also consider paddlespeech example:\nhttps://github.com/ChintanTrivedi/ask-fake-ai-karen\navaliable from paddlegan as an example used in paddlespeech, the artificial host.\nlip-sync accurate wav2lip:\nhttps://github.com/Rudrabha/Wav2Lip\nlipgan generate realistic lip-sync talking head animation(fully_pythonic branch or google colab notebook):\nhttps://github.com/Rudrabha/LipGAN\ngoogle’s lipsync implementation, using tensorflow facemesh:\nhttps://github.com/google/lipsync\nhttps://lipsync.withyoutube.com/\nhttps://github.com/tensorflow/tfjs-models/tree/master/facemesh\nnetwork reverse engineering for wombo.ai:\nhttps://github.com/the-garlic-os/wombo-reverse-engineering\nmatamata using vosk models, recommend to use gentle lip-sync method:\nhttps://github.com/AI-Spawn/Auto-Lip-Sync\nhttps://github.com/Matamata-Animator/Matamata-Core\nhttps://github.com/Yey007/Auto-Lip-Sync\nai-based lip reading might be irrelevant to lip-sync video generation:\nhttps://github.com/eflood23/lipsync"
  },
  {
    "objectID": "posts/e9f08502-b4a4-4e19-bb63-5159e4e08c14/index.html#debugging",
    "href": "posts/e9f08502-b4a4-4e19-bb63-5159e4e08c14/index.html#debugging",
    "title": "the kali command on macos",
    "section": "debugging",
    "text": "debugging\nwhen kali is off, this mac will go crazy and hang everything.\nneed to scan for kali existance on demand, not all the time."
  },
  {
    "objectID": "posts/e9f08502-b4a4-4e19-bb63-5159e4e08c14/index.html#developing",
    "href": "posts/e9f08502-b4a4-4e19-bb63-5159e4e08c14/index.html#developing",
    "title": "the kali command on macos",
    "section": "developing",
    "text": "developing\nshould we use p2p networks to speed up remote connections like n2n or tinc?\nwould it be interesting to run all our kali connectors ranged from vscode-ssh-connect, rclone mount and direct ssh connection via kali command dynamically by our kali discovery service, if we can reload the nginx daemon on demand.\nusing redis to store some daemon reported values.\nhow about we set the workding directory of redis-server to /tmp so that the dump.rdb file will never take space after reboot?\nwe need to know if this will successifully launch after reboot since /tmp may not exist by that time\ndefault redis server port: 6379\ninstall redis-server service:\neasyd -w /tmp -l redis_server -- /opt/homebrew/bin/redis-server\nfirst value is online.\nnext value is kali_ip.\nusing both value to determine whether to connect to kali or not, and the exact address."
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#non-max-suppression-in-combining-similar-bounding-boxes",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#non-max-suppression-in-combining-similar-bounding-boxes",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "non-max suppression in combining similar bounding boxes",
    "text": "non-max suppression in combining similar bounding boxes\nthe lib:\nfrom imutils.object_detection import non_max_suppression"
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#basically-greek-letters",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#basically-greek-letters",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "basically greek letters",
    "text": "basically greek letters\nmaybe you can document another great range of symbols by just enabling the system to search in greek?\ncould also search among math symbols, do math ocr."
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#kindly-reminders",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#kindly-reminders",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "kindly reminders",
    "text": "kindly reminders\nwhen building python c++ libraries without xcode, please add commandline header files like this:\nin order to have this during build:\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/Headers/Python.h we need to do:\n\nln -s /Library/Developer/CommandLineTools /Applications/Xcode.app/Contents/Developer"
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#search-by-image-instead-of-cranking-latex-out",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#search-by-image-instead-of-cranking-latex-out",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "search by image instead of cranking latex out",
    "text": "search by image instead of cranking latex out\n\nimage search libraries\ncharacter level optical char segmentation called chargrid ocr image match used for copyright violation detection, using phash algorithm ## get the latex out ### first detect the location of math formula scanning single shot detection for math formulas dataset for math symbol detection detect different part of document with yolov3 math expression detection ### next find the tool for picture to latex conversion 新开源的Python工具——Pix2Text (P2T)，目标是 Mathpix 的Python开源替代品，现在可以识别截图中的数学公式并转换为Latex表示，也可以识别图片中的中英文文字。在线Demo： https://huggingface.co/spaces/breezedeus/pix2text 。 Github: https://github.com/breezedeus/pix2text ，Gitee: https://gitee.com/breezedeus/pix2text 。 attention based math ocr gui of image2latex im2latex-tensorflow im2markup with only nvidia support using torch, model for latex conversion can be found here deeplearning picture to latex pix2tex using pix2tex 中文公式 手写公式识别 需要进一步训练 中文 手写 pytorch版本 ## mask latex area and get conventional things out easyocr with pytorch support ## search the formula formula search based on sympy can we render latex to picture with sympy? latex search engine"
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#get-the-latex-out",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#get-the-latex-out",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "get the latex out",
    "text": "get the latex out\n\nfirst detect the location of math formula\nscanning single shot detection for math formulas\ndataset for math symbol detection\ndetect different part of document with yolov3\nmath expression detection\n\n\nnext find the tool for picture to latex conversion\n新开源的Python工具——Pix2Text (P2T)，目标是 Mathpix 的Python开源替代品，现在可以识别截图中的数学公式并转换为Latex表示，也可以识别图片中的中英文文字。在线Demo： https://huggingface.co/spaces/breezedeus/pix2text 。 Github: https://github.com/breezedeus/pix2text ，Gitee: https://gitee.com/breezedeus/pix2text 。\nattention based math ocr\ngui of image2latex\nim2latex-tensorflow\nim2markup with only nvidia support using torch, model for latex conversion can be found here\ndeeplearning picture to latex\npix2tex\nusing pix2tex\n中文公式 手写公式识别 需要进一步训练\n中文 手写 pytorch版本"
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#mask-latex-area-and-get-conventional-things-out",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#mask-latex-area-and-get-conventional-things-out",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "mask latex area and get conventional things out",
    "text": "mask latex area and get conventional things out\neasyocr with pytorch support"
  },
  {
    "objectID": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#search-the-formula",
    "href": "posts/af109850-a641-43b8-becc-f8fcc89cde1e/index.html#search-the-formula",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "search the formula",
    "text": "search the formula\nformula search based on sympy\ncan we render latex to picture with sympy?\nlatex search engine"
  },
  {
    "objectID": "posts/5a8f1741-8544-43d0-9700-b0b73b33601b/index.html",
    "href": "posts/5a8f1741-8544-43d0-9700-b0b73b33601b/index.html",
    "title": "tencent jce",
    "section": "",
    "text": "jce is a tcp protocol, like protobuf\njcestruct usage\npython -m jce 1f2e3d4c5b6a79\n发送tcp数据判断mitm当中箭头含义"
  },
  {
    "objectID": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#if-i-put-a-puppy-into-a-group-of-fake-puppies-controlled-by-humans-interacting-with-the-puppy-and-speak-english-only-to-the-puppy-will-the-puppy-speak-english",
    "href": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#if-i-put-a-puppy-into-a-group-of-fake-puppies-controlled-by-humans-interacting-with-the-puppy-and-speak-english-only-to-the-puppy-will-the-puppy-speak-english",
    "title": "teach puppies to speak english (video script)",
    "section": "if i put a puppy into a group of fake puppies controlled by humans, interacting with the puppy and speak English only to the puppy, will the puppy speak English?",
    "text": "if i put a puppy into a group of fake puppies controlled by humans, interacting with the puppy and speak English only to the puppy, will the puppy speak English?\nIt is unlikely that a puppy will be able to learn to speak English or any other human language simply by being placed in a group of fake puppies controlled by humans and interacting with the puppy. While puppies are highly intelligent and capable of learning, they do not have the cognitive abilities necessary to understand and produce human language.\nIn order for a puppy or any other non-human animal to learn a human language, it would need to be trained and reinforced through extensive and consistent exposure to the language, as well as being provided with the necessary physical and cognitive abilities to understand and produce the sounds and gestures associated with the language. Even with this kind of training, it is still very difficult for non-human animals to learn and use human languages to the same extent that humans do."
  },
  {
    "objectID": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#well-you-know-my-fake-puppies-speak-english",
    "href": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#well-you-know-my-fake-puppies-speak-english",
    "title": "teach puppies to speak english (video script)",
    "section": "well you know my fake puppies speak English",
    "text": "well you know my fake puppies speak English\nI apologize if my previous response was unclear. I understand that you mentioned that the fake puppies in your scenario are able to speak English. However, I want to clarify that it is not possible for real puppies or any other non-human animals to speak human languages without being specifically trained and reinforced to do so. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do.\nI hope this helps to clarify the matter. If you have any further questions, please don’t hesitate to ask."
  },
  {
    "objectID": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#if-all-puppies-speak-english-will-their-children-be-taught-english-all-by-parents-and-puppy-communities-without-human-intervention",
    "href": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#if-all-puppies-speak-english-will-their-children-be-taught-english-all-by-parents-and-puppy-communities-without-human-intervention",
    "title": "teach puppies to speak english (video script)",
    "section": "if all puppies speak English, will their children be taught English all by parents and puppy communities without human intervention?",
    "text": "if all puppies speak English, will their children be taught English all by parents and puppy communities without human intervention?\nIt is not possible for puppies or any other non-human animals to speak human languages without being specifically trained and reinforced to do so by humans or other animals that have been trained by humans. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do.\nTherefore, even if a group of puppies were all able to speak English as a result of being trained by humans, their offspring would not be able to learn English simply by being exposed to their parents or other members of their community speaking English. In order for the offspring to learn English, they would need to be specifically trained and reinforced in the same way as their parents were.\nIt is worth noting that the ability to learn and use human language is a complex and uniquely human trait that is not shared by other animals to the same extent. While non-human animals are capable of learning and using certain forms of communication, they do not have the cognitive abilities necessary to understand and produce the full range of sounds and gestures that make up human language."
  },
  {
    "objectID": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#ok-if-their-parents-were-taught-how-to-teach-english-then",
    "href": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#ok-if-their-parents-were-taught-how-to-teach-english-then",
    "title": "teach puppies to speak english (video script)",
    "section": "Ok, if their parents were taught how to teach English, then",
    "text": "Ok, if their parents were taught how to teach English, then\nIf the parents of a group of puppies were trained to speak English by humans, and then were able to teach their offspring how to speak English, it is still unlikely that the puppies would be able to learn and use English to the same extent as humans. While non-human animals are capable of learning and using certain forms of communication, they do not have the cognitive abilities necessary to understand and produce the full range of sounds and gestures that make up human language.\nIn order for a non-human animal, such as a puppy, to learn and use human language, it would need to be provided with consistent and extensive exposure to the language, as well as being trained and reinforced through a structured and systematic approach. Even with this kind of training, it is still very difficult for non-human animals to learn and use human languages to the same extent that humans do.\nIt is worth noting that the ability to learn and use human language is a complex and uniquely human trait that is not shared by other animals to the same extent. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do."
  },
  {
    "objectID": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#if-i-use-some-machine-to-teach-every-puppy-english-by-evolution-is-it-possible-for-puppies-to-speak-english-without-help-from-machine-and-human",
    "href": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html#if-i-use-some-machine-to-teach-every-puppy-english-by-evolution-is-it-possible-for-puppies-to-speak-english-without-help-from-machine-and-human",
    "title": "teach puppies to speak english (video script)",
    "section": "If I use some machine to teach every puppy English, by evolution, is it possible for puppies to speak English without help from machine and human?",
    "text": "If I use some machine to teach every puppy English, by evolution, is it possible for puppies to speak English without help from machine and human?\nIt is not possible for puppies or any other non-human animals to evolve the ability to speak human languages without the assistance of humans or machines. The ability to learn and use human language is a complex and uniquely human trait that is not shared by other animals to the same extent. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do.\nIn order for a non-human animal, such as a puppy, to learn and use human language, it would need to be provided with consistent and extensive exposure to the language, as well as being trained and reinforced through a structured and systematic approach. Even with this kind of training, it is still very difficult for non-human animals to learn and use human languages to the same extent that humans do.\nUsing a machine to teach puppies English would likely involve a similar process of training and reinforcement, and would not result in the puppies evolving the ability to speak the language on their own. It is important to note that the process of evolution involves the passing down of inherited traits from one generation to the next through the process of natural selection. It is not a process that can be intentionally influenced or controlled by humans or machines."
  },
  {
    "objectID": "posts/80ba2937-9af5-49cf-8308-4848160a9ec1/index.html#view-full-logs",
    "href": "posts/80ba2937-9af5-49cf-8308-4848160a9ec1/index.html#view-full-logs",
    "title": "systemd on linux, maintainence details",
    "section": "view full logs",
    "text": "view full logs\njournalctl -u &lt;serviceName&gt;.service"
  },
  {
    "objectID": "posts/80ba2937-9af5-49cf-8308-4848160a9ec1/index.html#create-install-restart-reload",
    "href": "posts/80ba2937-9af5-49cf-8308-4848160a9ec1/index.html#create-install-restart-reload",
    "title": "systemd on linux, maintainence details",
    "section": "create, install, restart, reload",
    "text": "create, install, restart, reload\ncd /etc/systemd/system\ncreate &lt;serviceName&gt;.service\nsystemctl enable &lt;serviceName&gt;.service\nsystemctl daemon-reload\nsystemctl start &lt;serviceName&gt;.service"
  },
  {
    "objectID": "posts/80ba2937-9af5-49cf-8308-4848160a9ec1/index.html#sample-systemd-service-config-files",
    "href": "posts/80ba2937-9af5-49cf-8308-4848160a9ec1/index.html#sample-systemd-service-config-files",
    "title": "systemd on linux, maintainence details",
    "section": "sample systemd service config files",
    "text": "sample systemd service config files\nmaybe we should add some autorestart configs at it?\nfrpc_service.service\n[Unit]\nDescription=frpc service, expose ssh, webdav and code-server ports\nWants=network.target\nAfter=syslog.target network-online.target\n[Service]\nType=simple\nUser=root\nExecStart=/root/frp_client_linux/frp_0.36.2_linux_amd64/frpc -c frpc.ini\nWorkingDirectory=/root/frp_client_linux/frp_0.36.2_linux_amd64\nRestart=on-failure\nRestartSec=10\nKillMode=process\n[Install]\nWantedBy=multi-user.target\npyjom_webdav_rclone_service.service\n[Unit]\nDescription=rclone webdav served on pyjom, after the disk is mounted\n[Service]\nUser=root\nExecStart=/usr/bin/python3 mount_help_and_serve_pyjom.py\nWorkingDirectory=/root/Desktop/works/restore_sessions\n[Install]\nWantedBy=multi-user.target\ntempthrottle.service\n[Unit]\nDescription=temperature control, cpu temperature under 60 celsius\n[Service]\nUser=root\nExecStart=/usr/bin/python3 tempthrottle_daemon.py\nWorkingDirectory=/root/Desktop/works/restore_sessions\n[Install]\nWantedBy=multi-user.target\nclash_fastgithub.service\n[Unit]\nDescription=Clash Fastgithub Proxy\nAfter=network.target\n[Service]\nType=simple\nRestart=always\nExecStart=/usr/bin/clash -d /etc/clash\n[Install]\nWantedBy=multi-user.target\ntujia_scraper_qq_bot.service\n[Unit]\nDescription=two crucial services: tujia scraper, qq bot\nWants=network.target\nAfter=syslog.target network-online.target\n[Service]\nEnvironment=\"DISPLAY=:1\"\nEnvironment=\"XAUTHORITY=/root/.Xauthority\"\nUser=root\nExecStart=/usr/bin/python3 main_daemon.py\nWorkingDirectory=/root/Desktop/works/restore_sessions\n[Install]\nWantedBy=graphical.target\nsync_git_repos_syncdog.service\n[Unit]\nDescription=syncdog (server), to sync things to the cloud (github)\nWants=sshd.service\nWants=network.target\n[Service]\nUser=root\nExecStart=/usr/bin/python3 syncdog_test.py\nWorkingDirectory=/root/Desktop/works/sync_git_repos\n[Install]\nWantedBy=multi-user.target"
  },
  {
    "objectID": "posts/627dca78-b6b1-4c0e-8553-70978f0546ca/index.html",
    "href": "posts/627dca78-b6b1-4c0e-8553-70978f0546ca/index.html",
    "title": "supercollider",
    "section": "",
    "text": "cells multilanguage live-coding support for creative coding\ntidalcycles music and visual effects with code, written in haskell, live coding\nai唱歌 歌声合成 ai singing voice generation\nDiffSinger原作者的官方仓库：https://github.com/MoonInTheRiver/DiffSinger\nOpenVPI团队的第三方fork仓库：https://github.com/openvpi/DiffSinger\nMusic generation by Microsoft full workshop (Muzic):\nhttps://github.com/microsoft/muzic\nto control and record sonic pi (maybe you can slience it while still record its output?):\nProgramming Music with Sonic Pi or Supercollider (planned)\nControlling Sonic Pi from the command line, in Python.\n原版 扒谱 音轨分离 人声分离 伴奏分离 ultimate vocal remover\nAI扒谱:\ndemucs链接 spleeter alike：\nhttps://github.com/facebookresearch/demucs\nicassp2022-vocal-transcription链接：\nhttps://github.com/keums/icassp2022-vocal-transcription\n我写的小工具：\nhttps://wws.lanzoub.com/iheoe06cv3yh\nwav2midi basic pitch by spotify:\nhttps://github.com/spotify/basic-pitch\nAutotune Autotalent pitch correction:\nhttps://github.com/ederwander/PyAutoTune/blob/master/Examples/TuneAndPlayFromFile.py\nhttp://tombaran.info/autotalent.html\nMusic Understanding\nSymbolic Music Understanding: MusicBERT\nAutomatic Lyrics Transcription: PDAugment\nMusic Generation\nSong Writing: SongMASS\nLyric Generation: DeepRapper\nMelody Generation: TeleMelody\nAccompaniment Generation: PopMAG\nSinging Voice Synthesis: HiFiSinger\nmusisep music instrument separation:\nhttps://github.com/rgcda/Musisep\nhttps://www.math.colostate.edu/~king/software/Musisep-API/\naudio to midi collection:\nhttps://gist.github.com/natowi/d26c7e97443ec97e8032fb7e7596f0b0\nRecurrent Neural Network for generating piano MIDI-files from audio (MP3, WAV, etc.)\nhttps://github.com/BShakhovsky/PolyphonicPianoTranscription\nA python program which performs an FFT on an audio file and produces a MIDI file from the results\nhttps://github.com/NFJones/audio-to-midi\nExtract the melody from an audio file and export to MIDI\nhttps://github.com/justinsalamon/audio_to_midi_melodia\nPerforms pitch detection on a polyphonic audio source and outputs to MIDI\nhttps://github.com/corbanbrook/spectrotune\nProgram to detect pitch from wav files and write in time quantized MIDI\nhttps://github.com/vaibhavnayel/Audio-to-MIDI-converter\nA CNN which converts piano audio to a simplified MIDI format\nhttps://github.com/hartmetzls/audio_to_midi\nAn application of vocal melody extraction.\nhttps://github.com/bill317996/Audio-to-midi\nTranscribes polyphonic piano pieces from audio (MP3, WAV, etc.) into MIDI-files\nhttps://github.com/BShakhovsky/PianoAudioToMidi\nPolyphonic pitch tracking in real time using machine learning algorithms\nhttps://github.com/jaym910/polyphonic_track\nAudio to MIDI converter\nhttps://github.com/sbaeunker/audioToMidiConverter\nExplore Transcribing Techniques to auto convert audio to midi\nhttps://github.com/Goldspear/audio2midi\nPitchToMIDI\nhttps://github.com/KatoIppei/PitchToMIDI See releases\nPiano & Drums\nhttps://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription\nTony: a tool for melody transcription\nhttps://www.sonicvisualiser.org/tony/ https://github.com/sonic-visualiser/tony https://code.soundsoftware.ac.uk/projects/tony (https://github.com/mikulas-mrva/tony2max)\nMusicTranscription\nhttps://github.com/ClaraBing/CS229-MusicTranscription\npYIN\nhttps://code.soundsoftware.ac.uk/projects/pyin https://github.com/ronggong/pypYIN (python)\nOnsets and Frames Transcription (Piano & Drums)\nhttps://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription https://piano-scribe.glitch.me/\nWaoN\nhttps://sourceforge.net/projects/waon/\naudio2midi conversion works great with prior source separation https://github.com/deezer/spleeter or others like https://github.com/rgcda/Musisep\naudio2midi:\nhttps://github.com/ZZWaang/audio2midi\nmultichannel audio to midi:\nhttps://github.com/NFJones/audio-to-midi\nlstm music generation:\nhttps://github.com/dakshtrehan/AI-Music-Generation\ngpt2 chord to melody:\nhttps://github.com/tanreinama/chord2melody\nmulti instruments music generation:\nhttps://github.com/salu133445/musegan\nmusicautobot:\nhttps://github.com/bearpelican/musicautobot"
  },
  {
    "objectID": "posts/c06d566c-5d1c-474e-9239-4acd4b560923/index.html",
    "href": "posts/c06d566c-5d1c-474e-9239-4acd4b560923/index.html",
    "title": "stop background jobs",
    "section": "",
    "text": "jobs | grep -Eo \"[0-9][0-9][0-9]+\" | xargs -iabc kill -s KILL abc"
  },
  {
    "objectID": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#recommend-some-popular-orm-libraries-for-kotlin",
    "href": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#recommend-some-popular-orm-libraries-for-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "recommend some popular ORM libraries for kotlin",
    "text": "recommend some popular ORM libraries for kotlin\nThere are several popular ORM (Object-Relational Mapping) libraries that you can use with Kotlin. Some of the most popular options include:\nHibernate: Hibernate is a popular and widely used ORM library that is written in Java, but can be used with Kotlin. It provides a range of features including object-relational mapping, automatic database schema generation, and support for multiple database systems.\nRoom: Room is an ORM library that is specifically designed for use with Android and Kotlin. It provides an easy-to-use API for accessing and manipulating SQLite databases, and is widely used in Android development.\nExposed: Exposed is a lightweight and flexible ORM library for Kotlin that is built on top of JDBC (Java Database Connectivity). It provides a range of features including support for transactions, stored procedures, and database views.\nJOOQ: JOOQ (Java Object Oriented Querying) is a popular ORM library that provides a type-safe way to write SQL queries in Java and Kotlin. It generates Java code based on your database schema, allowing you to write queries using a fluent API.\nKtor-Exposed: Ktor-Exposed is an ORM library that is built on top of Exposed and is designed for use with the Ktor web framework. It provides a convenient way to access and manipulate database data within the context of a Ktor application."
  },
  {
    "objectID": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#use-exposed-in-kotlin",
    "href": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#use-exposed-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "use exposed in kotlin",
    "text": "use exposed in kotlin\nTo use Exposed in Kotlin, you will need to add the Exposed library to your project dependencies. If you are using Gradle, you can add the following dependency to your build.gradle file:\nimplementation 'org.jetbrains.exposed:exposed:0.24.1'\n\nNext, you will need to create a database connection and configure the Exposed library to use it. Here is an example of how you might do this using a MySQL database:\nimport org.jetbrains.exposed.sql.*\nimport org.jetbrains.exposed.sql.transactions.transaction\nimport org.jetbrains.exposed.sql.SchemaUtils.create\nimport org.jetbrains.exposed.sql.SchemaUtils.drop\nfun main() {\n// Connect to the database\nDatabase.connect(\"jdbc:mysql://localhost/mydatabase\", \"com.mysql.cj.jdbc.Driver\", \"username\", \"password\")\n// Define your database schema\ntransaction {\ncreate(Users)\ncreate(Orders)\n// Insert some data\nUsers.insert {\nit[name] = \"Alice\"\nit[age] = 25\n}\n// Query the data\nval alice = Users.select { Users.name eq \"Alice\" }.single()\nprintln(\"Alice's age is ${alice[Users.age]}\")\n// Update the data\nUsers.update({ Users.name eq \"Alice\" }) {\nit[age] = 26\n}\n// Delete the data\nUsers.deleteWhere { Users.name eq \"Alice\" }\n}\n}\n// Define your table and columns\nobject Users : Table() {\nval id = integer(\"id\").autoIncrement().primaryKey()\nval name = varchar(\"name\", length = 50)\nval age = integer(\"age\")\n}\nobject Orders : Table() {\nval id = integer(\"id\").autoIncrement().primaryKey()\nval userId = integer(\"user_id\").references(Users.id)\nval product = varchar(\"product\", length = 50)\nval quantity = integer(\"quantity\")\n}\nThis example demonstrates how to create a database table, insert data, query data, update data, and delete data using Exposed and Kotlin."
  },
  {
    "objectID": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#can-spring-use-yaml-or-json-for-configuration",
    "href": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#can-spring-use-yaml-or-json-for-configuration",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "can spring use yaml or json for configuration",
    "text": "can spring use yaml or json for configuration\nYes, Spring can use YAML (YAML Ain’t Markup Language) or JSON (JavaScript Object Notation) for configuration.\nSpring provides support for using YAML and JSON as an alternative to traditional property files for defining application configuration. To use YAML or JSON for configuration, you will need to include the spring-boot-configuration-processor dependency in your project and use the @ConfigurationProperties annotation to bind your configuration to a Java bean.\nHere is an example of how you might use YAML for configuration in a Spring Boot application:\n# application.yml\nserver:\nport: 8080\napp:\nname: My App\nversion: 1.0.0\ngreeting: Hello, world!\n@ConfigurationProperties(\"app\")\nclass AppProperties {\nlateinit var name: String\nlateinit var version: String\nlateinit var greeting: String\n}\nYou can then inject the AppProperties bean into your application and use the configuration values like this:\n@RestController\nclass HelloController(private val appProperties: AppProperties) {\n@GetMapping(\"/\")\nfun hello() = appProperties.greeting\n}\nYou can use a similar approach to use JSON for configuration in your Spring Boot application."
  },
  {
    "objectID": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#demonstrate-aspect-oriented-programming-in-kotlin",
    "href": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#demonstrate-aspect-oriented-programming-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "demonstrate aspect oriented programming in kotlin",
    "text": "demonstrate aspect oriented programming in kotlin\nAspect-Oriented Programming (AOP) is a programming paradigm that aims to modularize cross-cutting concerns, such as logging, security, and transaction management, into distinct aspects that can be applied to multiple parts of an application.\nIn Kotlin, you can use the Spring Framework’s AOP support to implement aspect-oriented programming. Here is an example of how you might use AOP to log the execution of a method in Kotlin:\nimport org.aspectj.lang.annotation.Aspect\nimport org.aspectj.lang.annotation.Before\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.springframework.stereotype.Component\n@Aspect\n@Component\nclass LoggingAspect {\nval logger: Logger = LoggerFactory.getLogger(LoggingAspect::class.java)\n@Before(\"execution(* com.example.service.*.*(..))\")\nfun logMethodExecution() {\nlogger.info(\"Method execution\")\n}\n}\nIn this example, the @Aspect annotation indicates that this class represents an aspect, and the @Before annotation specifies a pointcut (a point in the code where the aspect should be applied) and an advice (the action that should be taken when the pointcut is reached). In this case, the pointcut matches any method execution in the com.example.service package, and the advice logs a message.\nTo use this aspect in your application, you will need to enable AOP support in your Spring configuration. You can do this by adding the @EnableAspectJAutoProxy annotation to your configuration class, like this:\nimport org.springframework.context.annotation.Configuration\nimport org.springframework.context.annotation.EnableAspectJAutoProxy\n@Configuration\n@EnableAspectJAutoProxy\nclass AopConfiguration\nWith these changes in place, the aspect will be applied to all matching method executions in your application and the log message will be printed whenever a method is executed."
  },
  {
    "objectID": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#use-spring-mvc-in-kotlin",
    "href": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#use-spring-mvc-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "use spring mvc in kotlin",
    "text": "use spring mvc in kotlin\nTo use Spring MVC (Model-View-Controller) in Kotlin, you will need to create a Spring Boot application and add the spring-boot-starter-web dependency to your project.\nHere is an example of how you might set up a simple Spring MVC application in Kotlin:\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.boot.runApplication\nimport org.springframework.stereotype.Controller\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.ResponseBody\n@SpringBootApplication\nclass Application\nfun main(args: Array&lt;String&gt;) {\nrunApplication&lt;Application&gt;(*args)\n}\n@Controller\nclass HelloController {\n@GetMapping(\"/\")\n@ResponseBody\nfun hello() = \"Hello, world!\"\n}\nIn this example, the HelloController class is annotated with @Controller to indicate that it is a Spring MVC controller. The hello() method is annotated with @GetMapping to specify that it should handle HTTP GET requests to the root URL, and with @ResponseBody to indicate that the method’s return value should be written directly to the HTTP response body.\nWith these changes in place, you can start your Spring Boot application and visit http://localhost:8080 in your web browser to see the “Hello, world!” message.\nYou can use similar annotations to handle other HTTP methods, such as POST, PUT, and DELETE, and to bind request parameters to method arguments. You can also use the @RequestMapping annotation to specify more complex URL patterns, and the @ModelAttribute annotation to bind request parameters to model attributes that can be used in view templates."
  },
  {
    "objectID": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#use-jsp-with-spring-in-kotlin",
    "href": "posts/4f8d70bb-ecc9-4f39-87b1-4b9f6e457452/index.html#use-jsp-with-spring-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "use jsp with spring in kotlin",
    "text": "use jsp with spring in kotlin\nTo use JSP (Java Server Pages) with Spring in Kotlin, you will need to create a Spring Boot application and add the spring-boot-starter-web and spring-boot-starter-tomcat dependencies to your project.\nBy default, Spring Boot will look for JSP files in the src/main/webapp/WEB-INF/jsp directory. You will need to create this directory structure and add your JSP files to it.\nHere is an example of a simple JSP file that displays a message:\n&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Hello&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello, world!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nTo render this JSP file in your Spring MVC application, you will need to create a controller that maps a request to the JSP file. Here is an example of how you might do this in Kotlin:\nimport org.springframework.stereotype.Controller\nimport org.springframework.web.bind.annotation.GetMapping\n@Controller\nclass HelloController {\n@GetMapping(\"/\")\nfun hello() = \"hello\"\n}\nIn this example, the hello() method is annotated with @GetMapping to specify that it should handle HTTP GET requests to the root URL. The method’s return value, “hello”, is the name of the JSP file that should be rendered in response to the request.\nWith these changes in place, you can start your Spring Boot application and visit http://localhost:8080 in your web browser to see the message displayed by the JSP file.\nYou can use similar approaches to map requests to other JSP files and to pass data from your controllers to your JSP files using model attributes."
  },
  {
    "objectID": "posts/d33e1f35-ae49-4856-b872-443e2266b753/index.html",
    "href": "posts/d33e1f35-ae49-4856-b872-443e2266b753/index.html",
    "title": "splash: webpage rendering service",
    "section": "",
    "text": "where’s the animation anyway?\nsplash doc"
  },
  {
    "objectID": "posts/442fcb15-95cb-4100-a792-e53eb4ea6498/index.html",
    "href": "posts/442fcb15-95cb-4100-a792-e53eb4ea6498/index.html",
    "title": "speech recognition",
    "section": "",
    "text": "Speech Recognition using MFCC and HMM"
  },
  {
    "objectID": "posts/a09f4028-1185-4a3f-80dd-b3f5d2b6a6ca/index.html",
    "href": "posts/a09f4028-1185-4a3f-80dd-b3f5d2b6a6ca/index.html",
    "title": "some notes just like me: today i learned (til)",
    "section": "",
    "text": "repo here: til"
  },
  {
    "objectID": "posts/3472c423-0513-44e1-895d-486f98fa508e/index.html",
    "href": "posts/3472c423-0513-44e1-895d-486f98fa508e/index.html",
    "title": "setup ssh server on windows, enable key based authentication to windows ssh server",
    "section": "",
    "text": "tutorial\nchange the sshd config\nappend the client’s public key to “authorized_keys” and “administrators_authorized_keys”\nrestart the service"
  },
  {
    "objectID": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#review-previous-notes-and-fill-blanks-list-blanks-below-better-with-direct-link-to-it",
    "href": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#review-previous-notes-and-fill-blanks-list-blanks-below-better-with-direct-link-to-it",
    "title": "self-learning schedules",
    "section": "review previous notes and fill blanks, list blanks below, better with direct link to it",
    "text": "review previous notes and fill blanks, list blanks below, better with direct link to it\n\ntag all notes, especially mark out those stub, incomplete ones\nreview and complete bilibili courses, reorder, rename and split them if necessary\n传播学导论把笔记做完"
  },
  {
    "objectID": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#review-your-history",
    "href": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#review-your-history",
    "title": "self-learning schedules",
    "section": "review your history",
    "text": "review your history\n\nvisit all previously visited links and store briefs generated by readbility.js and elinks"
  },
  {
    "objectID": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#finance-and-quantatitive-trading",
    "href": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#finance-and-quantatitive-trading",
    "title": "self-learning schedules",
    "section": "finance and quantatitive trading",
    "text": "finance and quantatitive trading\n\ndesign a basic algorithm and complete regression test on joinquant\ndesign and complete one regression test offline"
  },
  {
    "objectID": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#artificial-general-intelligence",
    "href": "posts/271eba9e-26fe-4335-b309-3b055d96e233/index.html#artificial-general-intelligence",
    "title": "self-learning schedules",
    "section": "artificial general intelligence",
    "text": "artificial general intelligence\n\ndesign a program automatically execute commands in shell\ndesign a program automatically click everywhere in GUI\n\n\nstudy nars\n\nrun python version of nars\n\n\n\nstudy opencog\n\n\nstudy he4o"
  },
  {
    "objectID": "posts/1d8bbb71-e114-4fa4-8883-22ba3886632b/index.html#喜马拉雅fm",
    "href": "posts/1d8bbb71-e114-4fa4-8883-22ba3886632b/index.html#喜马拉雅fm",
    "title": "scrape podcasts, filter keywords, convert voices by gender and pitch",
    "section": "喜马拉雅fm",
    "text": "喜马拉雅fm"
  },
  {
    "objectID": "posts/1d8bbb71-e114-4fa4-8883-22ba3886632b/index.html#apple-podcasts",
    "href": "posts/1d8bbb71-e114-4fa4-8883-22ba3886632b/index.html#apple-podcasts",
    "title": "scrape podcasts, filter keywords, convert voices by gender and pitch",
    "section": "apple podcasts",
    "text": "apple podcasts\napple podcasts are free.\nsummarize the podcast or use the keywords extracted from podcast for advanced search\n去除语气词 tts与变声器混合\npodcast review scraper\npodscraper"
  },
  {
    "objectID": "posts/8322c697-be5a-4f16-bf5c-cdbff433f771/index.html",
    "href": "posts/8322c697-be5a-4f16-bf5c-cdbff433f771/index.html",
    "title": "reset windows server password",
    "section": "",
    "text": "chntpw does not work this time. it will auto restore\nthe SAM file.\ninstead, under directory C:\\Windows\\System32, swap Utilman.exe (remember to back it up) with cmd.exe then click widgets in login window to popup command prompt, type net user &lt;username&gt; &lt;password&gt; to reset.\nreference"
  },
  {
    "objectID": "posts/0307d11f-2de1-4a43-82e5-7ee7476e9fc1/index.html",
    "href": "posts/0307d11f-2de1-4a43-82e5-7ee7476e9fc1/index.html",
    "title": "Register a New File in Android Gallery using Beanshell Code",
    "section": "",
    "text": "register new file to android gallery\ncode in beanshell:\nimport android.net.Uri;\nIntent mediaScanIntent = new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE);\nUri contentUri = Uri.parse(\"file:///storage/emulated/0/Movies/output0_higher.mp4\");\nmediaScanIntent.setData(contentUri);\nctx.sendBroadcast(mediaScanIntent);"
  },
  {
    "objectID": "posts/c8439b3e-7642-4f70-89db-33a18544be1a/index.html",
    "href": "posts/c8439b3e-7642-4f70-89db-33a18544be1a/index.html",
    "title": "rectangle related calculation",
    "section": "",
    "text": "better make polygon into blocks first (pixelize) and then decompose it into rectangles\nrectirization A polygon to rectangle conversion tool, written in cpp\nextractrect find the largest rectangle inscribed in a non-convex polygon\ndecompose rectlinear polygon in nodejs"
  },
  {
    "objectID": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html#show-me-how-to-recreate-cloudpss-platform",
    "href": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html#show-me-how-to-recreate-cloudpss-platform",
    "title": "recreating cloudpss",
    "section": "show me how to recreate cloudpss platform",
    "text": "show me how to recreate cloudpss platform\nCreating a cloud platform like CloudPss can be a daunting task, but it is achievable with the right knowledge and resources. Here are some general steps to help you get started:\nResearch CloudPss and other cloud platforms to understand their features, benefits, and drawbacks.\nDefine your goals and objectives for the platform. This can include features you need, target users, and any other important considerations.\nSelect a cloud provider and decide on the best hosting option for your platform.\nDesign the architecture and decide on a programming language.\nDevelop the platform using secure coding practices.\nTest the platform for security and performance.\nDeploy the platform and monitor usage.\nMaintain and update the platform regularly.\nFollow these steps and you will be able to create a cloud platform like CloudPss. Good luck!"
  },
  {
    "objectID": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html#what-is-cloudpss",
    "href": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html#what-is-cloudpss",
    "title": "recreating cloudpss",
    "section": "what is cloudpss",
    "text": "what is cloudpss\nCloudPss is a modeling and simulation platform for the energy internet. [1] It uses a completely self-developed electromagnetic transient simulation kernel and is designed to provide comprehensive analysis services for the energy internet. [2] It is based on cloud computing and focuses on solving the problem of modeling and simulation of power system. [3] CloudPss can be used for various purposes, including monitoring and optimization of electricity grids, power system dynamic simulation, and fault analysis.\nReferences:\n[1] Documentation - CloudPSS Documentation\n[2] CloudPss-An Energy Internet Modeling and Simulation Tool in …\n[3] A High-Performance Power System Simulator Based on Cloud …"
  },
  {
    "objectID": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html#how-to-rebuild-the-modeling-and-simulation-part-of-cloudpss-using-open-source-software",
    "href": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html#how-to-rebuild-the-modeling-and-simulation-part-of-cloudpss-using-open-source-software",
    "title": "recreating cloudpss",
    "section": "how to rebuild the modeling and simulation part of cloudpss using open-source software",
    "text": "how to rebuild the modeling and simulation part of cloudpss using open-source software\nThe modeling and simulation part of CloudPss can be rebuilt using open source software such as GridLAB-D, OpenModelica, and GridAPPS-D.\nGridLAB-D is a free and open source software platform for modeling and simulation of electric power systems. It is designed to take advantage of high-performance computing resources for system analysis and optimization. [4]\nOpenModelica is a free and open source modeling and simulation environment. It is designed for modeling, simulation, and optimization of complex systems. [5]\nGridAPPS-D is an open-source software platform for modeling and simulation of the power system. It is designed to enable the integration of hardware and software components related to the energy internet. [6]\nUsing these open source software platforms is a great way to rebuild the modeling and simulation part of CloudPss."
  },
  {
    "objectID": "posts/a86d42ed-2650-4ad5-a427-d838e83a02cf/index.html",
    "href": "posts/a86d42ed-2650-4ad5-a427-d838e83a02cf/index.html",
    "title": "raspberry pi tweaks",
    "section": "",
    "text": "openai says i should edit /etc/wpa_supplicant/wpa_supplicant.conf like this to connect to 5G wifi:\nnetwork={\nssid=\"&lt;SSID&gt;\"\npsk=\"&lt;password&gt;\"\nfrequency=5180\n}\nalso set frequency of wifi card like this:\nsudo ifdown wlan0 && sudo ifup wlan0\nsudo iw dev wlan0 set freq 5180\nunplug ethernet, then we are golden.\ntraceroute baidu.com\nhow to check avaliable wifi ssids without network-manager:\nsudo iwlist wlan0 scan | grep ESSID\ndefault login (maybe not):\nusername: pi\npassword: raspberry\n\nin order to start sshd, touch ssh under boot partition\nrecover dhcpcd service:\nsudo systemctl enable dhcpcd.service\nsudo systemctl restart dhcpcd.service\nconfig the password with proot -S &lt;path_to_rootfs&gt; -b &lt;boot_partition&gt;:/boot -q qemu-arm /usr/bin/bash and passwd\nyou’ve installed raspap on this device. you use the default credentials. this shit will not connect to our wifi automatically, thus block your way of running docker containers on it with only macbook.\nseriously? do you really need docker on macos? or just on raspberry pi?\nchange apt sources:\nsudo sed -i 's|raspbian.raspberrypi.org|mirrors.ustc.edu.cn/raspbian|g' /etc/apt/sources.list\nsudo sed -i 's|mirrordirector.raspbian.org|mirrors.ustc.edu.cn/raspbian|g' /etc/apt/sources.list\nsudo sed -i 's|archive.raspbian.org|mirrors.ustc.edu.cn/raspbian|g' /etc/apt/sources.list\nsudo sed -i 's|archive.raspberrypi.org/debian|mirrors.ustc.edu.cn/archive.raspberrypi.org/debian|g' /etc/apt/sources.list.d/raspi.list\nusing nmcli to scan and connect wifi\nsudo nmcli dev wifi rescan\nsudo nmcli dev wifi connect &lt;SSID&gt; password &lt;PASSWORD&gt;\nsharing network:\nssh -R 1080 pi@10.42.0.33\nedit /etc/network/interfaces:\nauto lo\niface lo inet loopback\nauto eth0\niface eth0 inet static\naddress 10.42.0.33\nnetmask 255.255.255.0\ngateway 10.42.0.1\nallow-hotplug wlan0\nauto wlan0\niface wlan0 inet dhcp\n#wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf\nwpa-ssid \"&lt;SSID&gt;\"\nwpa-psk \"&lt;PASSWORD&gt;\"\n\ninstall packages:\nsudo apt-get -o Acquire::http::proxy=\"socks5h://127.0.0.1:1080/\"  -o Acquire::Check-Valid-Until=false -o Acquire::Check-Date=false update --allow-releaseinfo-change\nsudo apt-get -o Acquire::http::proxy=\"socks5h://127.0.0.1:1080/\"  -o Acquire::Check-Valid-Until=false -o Acquire::Check-Date=false upgrade -y"
  },
  {
    "objectID": "posts/9917abc2-2a6a-4232-85a0-889a59d77595/index.html#gif-ratings",
    "href": "posts/9917abc2-2a6a-4232-85a0-889a59d77595/index.html#gif-ratings",
    "title": "random giphy gifs",
    "section": "gif ratings",
    "text": "gif ratings\nofficial doc\nvulgar rate:\nr &gt; pg-13 &gt; pg &gt; g\nwhile ‘y’ means accepting all shits, not ‘youth’ nor ‘young’"
  },
  {
    "objectID": "posts/9917abc2-2a6a-4232-85a0-889a59d77595/index.html#implementation",
    "href": "posts/9917abc2-2a6a-4232-85a0-889a59d77595/index.html#implementation",
    "title": "random giphy gifs",
    "section": "implementation",
    "text": "implementation\ngiphy has many extensible apis. i guess most media platforms are all the same (complex enough), but we have to start somewhere though…\ngiphy has ‘clips’ now. clips are gifs with sound, just like short videos.\nbeta key limitations:\n1000 requests per day, 42 requests per hour\nor just use the public beta key? does that subject to the rate limit?\nthis public beta key is trashed.\nvar PUBLIC_BETA_API_KEY = 'dc6zaTOxFJmzC';\nis this public api key? maybe it is both api and sdk key.\nGc7131jiJuvI7IdN0HZ1D7nh0ow5BU6g\napi keys:\nIoJVsWoxDPKBr6gOcCgOPWAB25773hqP\nlTRWAEGHjB1AkfO0sk2XTdujaPB5aH7X\nsdk keys:\n6esYBEm9OG3wAifbBFZ2mA0Ml6Ic0rvy\nsXpGFDGZs0Dv1mmNFvYaGUvYwKX0PWIh\nto use api:\nhttps://github.com/austinkelleher/giphy-api\nto use sdk:\nhttps://github.com/Giphy/giphy-js/blob/master/packages/fetch-api/README.md\nfind public api keys inside html:\nwindow.GIPHY_FE_MOBILE_API_KEY = \"L8eXbxrbPETZxlvgXN9kIEzQ55Df04v0\"\nwindow.GIPHY_FE_WEB_API_KEY = \"Gc7131jiJuvI7IdN0HZ1D7nh0ow5BU6g\"\nwindow.GIPHY_FE_FOUR_O_FOUR_API_KEY = \"MRwXFtxAnaHo3EUMrSefHWmI0eYz5aGe\"\nwindow.GIPHY_FE_STORIES_AND_GIPHY_TV_API_KEY = \"3eFQvabDx69SMoOemSPiYfh9FY0nzO9x\"\nwindow.GIPHY_FE_DEFAULT_API_SERVICE_KEY = \"5nt3fDeGakBKzV6lHtRM1zmEBAs6dsIc\"\nwindow.GIPHY_FE_GET_POST_HEADERS_KEY = \"e0771ed7b244ec9c942bea646ad08e6bf514f51a\"\nwindow.GIPHY_FE_MEDIUM_BLOG_API_KEY = \"i3dev0tcpgvcuaocfmdslony2q9er7tvfndxcszm\"\nwindow.GIPHY_FE_EMBED_KEY = \"eDs1NYmCVgdHvI1x0nitWd5ClhDWMpRE\"\nsearch for ‘ear flops’ to locate the tags in ‘samoyed.html’"
  },
  {
    "objectID": "posts/5f897dfd-db28-4530-8dd9-4fe963bf9cc4/index.html",
    "href": "posts/5f897dfd-db28-4530-8dd9-4fe963bf9cc4/index.html",
    "title": "qzone send shuoshuo",
    "section": "",
    "text": "opqbot qzone module replacement\nanimeapi more than just sending shuoshuo\nlogin via qrcode\nplaywright upload file\n有很多上传接口 都可以这样自动化 因为这些接口可能会变化 自己写成playwright脚本是最省事的方案"
  },
  {
    "objectID": "posts/80e3a6f4-079d-45b4-83b0-8f028fb7dd67/index.html#打赏-e-begging",
    "href": "posts/80e3a6f4-079d-45b4-83b0-8f028fb7dd67/index.html#打赏-e-begging",
    "title": "Monetizing Bilibili Content with GIFs, QR Codes, and JSON Modification",
    "section": "打赏 e-begging",
    "text": "打赏 e-begging\nYukio 20:36:09\n帮忙百度 然后时不时发个打赏链接\nYukio 20:36:22\n涩图里面加赞助二维码"
  },
  {
    "objectID": "posts/80e3a6f4-079d-45b4-83b0-8f028fb7dd67/index.html#通用发广告策略",
    "href": "posts/80e3a6f4-079d-45b4-83b0-8f028fb7dd67/index.html#通用发广告策略",
    "title": "Monetizing Bilibili Content with GIFs, QR Codes, and JSON Modification",
    "section": "通用发广告策略",
    "text": "通用发广告策略\nYukio 16:06:23\n我在想 用GIF怎么引流\nYukio 16:06:50\nGIF不让你扫码 所以说只能GIF下面放个链接\nYukio 16:07:30\nGIF下面可以放二维码？\nYukio 16:07:41\n都可以试试 反正不吃亏\nYukio 16:17:17\n狗子狗叫太吵了\nYukio 16:17:33\n转成GIF感觉会效果好点\nYukio 16:19:26\n我甚至可以直接ugc当成封面 然后下面发链接引流"
  },
  {
    "objectID": "posts/80e3a6f4-079d-45b4-83b0-8f028fb7dd67/index.html#逆向qq安卓版",
    "href": "posts/80e3a6f4-079d-45b4-83b0-8f028fb7dd67/index.html#逆向qq安卓版",
    "title": "Monetizing Bilibili Content with GIFs, QR Codes, and JSON Modification",
    "section": "逆向qq安卓版",
    "text": "逆向qq安卓版\nYukio 15:51:01\n我最近研究了一下b站转发QQ群的原理\nYukio 15:51:01\nQQ群里面只能发一种JSON\nYukio 15:51:02\n里面有个token看起来像是checksum\nYukio 15:51:02\n所以JSON里面稍作改动就发不出去了\nYukio 15:51:02\n不过如果你可以拦截安卓的intent 用frida拦截生成这个JSON的call 可能可以生成任意的JSON"
  },
  {
    "objectID": "posts/dfe346df-d3ac-4ef5-8743-8df9336a1d1b/index.html",
    "href": "posts/dfe346df-d3ac-4ef5-8743-8df9336a1d1b/index.html",
    "title": "python retry libraries",
    "section": "",
    "text": "retrying\nretry\nretry2"
  },
  {
    "objectID": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#use-pyro-to-create-an-object-detector",
    "href": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#use-pyro-to-create-an-object-detector",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "use pyro to create an object detector",
    "text": "use pyro to create an object detector\nPyro is a probabilistic programming language built on top of PyTorch that allows you to build flexible, expressive models and perform Bayesian inference. You can use Pyro to build an object detector by defining a probabilistic model that takes an input image and outputs a set of bounding boxes and class labels for the objects in the image.\nHere is an outline of the process you can follow to build an object detector using Pyro:\nCollect and preprocess a dataset of images and annotated bounding boxes for the objects you want to detect.\nDefine a probabilistic model in Pyro that takes an input image and outputs a set of bounding boxes and class labels for the objects in the image. You can use a convolutional neural network (CNN) to extract features from the input image and a multi-layer perceptron (MLP) to predict the bounding boxes and class labels.\nDefine a loss function that measures the difference between the predicted bounding boxes and class labels and the ground truth annotations in the dataset.\nUse Pyro’s optimization algorithms to optimize the model’s parameters with respect to the loss function.\nUse the trained model to make predictions on new images.\nHere is an example of how you can define a simple object detector using Pyro:\nimport torch\nimport pyro\nimport pyro.distributions as dist\nclass ObjectDetector(pyro.nn.PyroModule):\ndef __init__(self, num_classes):\nsuper().__init__()\nself.num_classes = num_classes\nself.cnn = pyro.nn.Sequential(\n# Define the CNN layers here\n)\nself.mlp = pyro.nn.Sequential(\n# Define the MLP layers here\n)\ndef forward(self, x):\nfeatures = self.cnn(x)\nbboxes, labels = self.mlp(features)\nreturn bboxes, labels\n# Define the loss function\ndef loss(model, x, bboxes, labels):\npredicted_bboxes, predicted_labels = model(x)\nbbox_loss = # Compute the bounding box loss here\nlabel_loss = # Compute the class label loss here\nreturn bbox_loss + label_loss\n# Define the model and optimizer\nmodel = ObjectDetector(num_classes)\noptimizer = pyro.optim.Adam({\"lr\": 0.001})\n# Loop over the dataset and optimize the model\nfor x, bboxes, labels in dataset:\noptimizer.zero_grad()\nloss_value = loss(model, x, bboxes, labels)\nloss_value.backward()\noptimizer.step()\n# Use the trained model to make predictions on new images\nx_new = # Load a new image\nbboxes, labels = model(x_new)\nThis is just a simple example of how you can use Pyro to build an object detector. You can find more detailed examples and resources on the Pyro website (https://pyro.ai/) and in the Pyro documentation (https://docs.pyro.ai/)."
  },
  {
    "objectID": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#define-the-cnn-network-and-the-mlp-network",
    "href": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#define-the-cnn-network-and-the-mlp-network",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "define the CNN network and the MLP network",
    "text": "define the CNN network and the MLP network\nTo define the CNN and MLP networks for an object detector using Pyro, you can use Pyro’s nn module to define the layers of the network.\nFor the CNN, you can use a combination of convolutional, pooling, and fully-connected (FC) layers to extract features from the input image. Here is an example of how you can define a simple CNN in Pyro:\nimport torch.nn as nn\nimport pyro.nn as pyro_nn\nclass CNN(pyro_nn.PyroModule):\ndef __init__(self, num_classes):\nsuper().__init__()\nself.conv1 = pyro_nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\nself.conv2 = pyro_nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\nself.pool = pyro_nn.MaxPool2d(kernel_size=2, stride=2)\nself.fc1 = pyro_nn.Linear(32 * 7 * 7, num_classes)\ndef forward(self, x):\nx = self.conv1(x)\nx = self.pool(x)\nx = self.conv2(x)\nx = self.pool(x)\nx = x.view(-1, 32 * 7 * 7)\nx = self.fc1(x)\nreturn x\nFor the MLP, you can use a combination of fully-connected (FC) layers to predict the bounding boxes and class labels for the objects in the image. Here is an example of how you can define an MLP in Pyro:\nimport torch.nn as nn\nimport pyro.nn as pyro_nn\nclass MLP(pyro_nn.PyroModule):\ndef __init__(self, num_classes, num_bboxes):\nsuper().__init__()\nself.fc1 = pyro_nn.Linear(num_classes, 128)\nself.fc2 = pyro_nn.Linear(128, num_bboxes * 4)\nself.fc3 = pyro_nn.Linear(128, num_bboxes * num_classes)\ndef forward(self, x):\nx = self.fc1(x)\nbboxes = self.fc2(x)\nlabels = self.fc3(x)\nreturn bboxes, labels\nYou can then combine the CNN and MLP into a single object detector model by defining a PyroModule that takes an input image and outputs the predicted bounding boxes and class labels.\nTo continue building an object detector using Pyro, you can define a loss function that measures the difference between the predicted bounding boxes and class labels and the ground truth annotations in the dataset. You can then use Pyro’s optimization algorithms to optimize the model’s parameters with respect to the loss function.\nFor example, you can define a loss function that combines a bounding box loss and a class label loss. The bounding box loss can be computed using the mean squared error (MSE) between the predicted bounding boxes and the ground truth bounding boxes. The class label loss can be computed using the cross-entropy loss between the predicted class labels and the ground truth labels.\nHere is an example of how you can define the loss function:\nimport torch\nimport pyro\nimport pyro.distributions as dist\ndef loss(model, x, bboxes, labels):\npredicted_bboxes, predicted_labels = model(x)\nbbox_loss = torch.mean((predicted_bboxes - bboxes) ** 2)\nlabel_loss = torch.nn.CrossEntropyLoss()(predicted_labels, labels)\nreturn bbox_loss + label_loss\nTo optimize the model’s parameters, you can use an optimization algorithm such as Adam or SGD. Here is an example of how you can define an optimizer and use it to train the model:\nimport torch\nimport pyro\nimport pyro.optim as optim\n# Define the model and optimizer\nmodel = ObjectDetector(num_classes, num_bboxes)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# Loop over the dataset and optimize the model\nfor x, bboxes, labels in dataset:\noptimizer.zero_grad()\nloss_value = loss(model, x, bboxes, labels)\nloss_value.backward()\noptimizer.step()\nOnce the model is trained, you can use it to make predictions on new images. To do this, you can pass the new images through the model and use the predicted bounding boxes and class labels to draw bounding boxes around the objects in the image.\n# Use the trained model to make predictions on new images\nx_new = # Load a new image\nbboxes, labels = model(x_new)\n# Draw bounding boxes around the objects in the image\nfor bbox, label in zip(bboxes, labels):\n# Draw the bounding box on the image\n# ...\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#how-to-do-3d-convolution-on-video-with-pytorch",
    "href": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#how-to-do-3d-convolution-on-video-with-pytorch",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "how to do 3d convolution on video with pytorch",
    "text": "how to do 3d convolution on video with pytorch\nTo perform 3D convolution on a video with PyTorch, you can use the nn.Conv3d layer. This layer applies a 3D convolution over the input tensor, which has shape (batch_size, channels, depth, height, width).\nHere is an example of how you can define a 3D convolutional neural network (CNN) in PyTorch to process a video:\nimport torch\nimport torch.nn as nn\nclass VideoCNN(nn.Module):\ndef __init__(self):\nsuper().__init__()\nself.conv1 = nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1)\nself.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\nself.pool = nn.MaxPool3d(kernel_size=2, stride=2)\nself.fc1 = nn.Linear(32 * 7 * 7 * 7, 128)\nself.fc2 = nn.Linear(128, 10)\ndef forward(self, x):\nx = self.conv1(x)\nx = self.pool(x)\nx = self.conv2(x)\nx = self.pool(x)\nx = x.view(-1, 32 * 7 * 7 * 7)\nx = self.fc1(x)\nx = self.fc2(x)\nreturn x\nTo process a video with this CNN, you can first split the video into a sequence of frames, and then pass each frame through the CNN. You can use the torchvision.io.read_video function to read the video and the torchvision.transforms.ToTensor transformation to convert the frames to tensors.\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n# Read the video and split it into a sequence of frames\nvideo, _ = torchvision.io.read_video(\"video.mp4\")\nframes = video.permute(0, 3, 1, 2)\n# Convert the frames to tensors\ntransform = transforms.ToTensor()\ntensors = [transform(frame) for frame in frames]\n# Pass the tensors through the CNN\ncnn = VideoCNN()\noutputs = [cnn(tensor.unsqueeze(0)) for tensor in tensors]\nYou can then use the output of the CNN to perform various tasks, such as classification or object detection.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#use-3d-convolution-to-determine-location-of-watermark-on-video",
    "href": "posts/f2ff8a03-f518-42b9-9768-b27f6c33412d/index.html#use-3d-convolution-to-determine-location-of-watermark-on-video",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "use 3d convolution to determine location of watermark on video",
    "text": "use 3d convolution to determine location of watermark on video\nTo use 3D convolution to determine the location of a watermark on a video, you can build a convolutional neural network (CNN) that takes a sequence of frames from the video as input and outputs a prediction of the watermark’s location.\nHere is an outline of the process you can follow to build such a CNN using PyTorch:\nCollect and preprocess a dataset of videos and annotated watermark locations. To do this, you can manually label the watermark locations in a set of videos, or you can use a watermarked video and its corresponding unwatermarked version to automatically generate labels.\nDefine a CNN in PyTorch that takes a sequence of frames from a video as input and outputs a prediction of the watermark’s location. You can use 3D convolutional layers to extract features from the frames and fully-connected (FC) layers to make the prediction.\nDefine a loss function that measures the difference between the predicted watermark location and the ground truth location. You can use a regression loss such as mean squared error (MSE) or mean absolute error (MAE).\nUse PyTorch’s optimization algorithms to optimize the CNN’s parameters with respect to the loss function.\nUse the trained CNN to make predictions on new videos.\nHere is an example of how you can define a simple CNN in PyTorch to determine the location of a watermark on a video:\nimport torch\nimport torch.nn as nn\nclass WatermarkCNN(nn.Module):\ndef __init__(self):\nsuper().__init__()\nself.conv1 = nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1)\nself.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\nself.pool = nn.MaxPool3d(kernel_size=2, stride=2)\nself.fc1 = nn.Linear(32 * 7 * 7 * 7, 128)\nself.fc2 = nn.Linear(128, 4)  # 4 values for (x, y, width, height)\ndef forward(self, x):\nx = self.conv1(x)\nx = self.pool(x)\nx = self.conv2(x)\nx = self.pool(x)\nx = x.view(-1, 32 * 7 * 7 * 7)\nx = self.fc1(x)\nx = self.fc2(x)\nreturn x\nTo train this CNN, you can loop over the dataset and optimize the CNN’s parameters with respect to the loss function. Here is an example of how you can define the loss function and optimizer, and use them to train the CNN:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n# Define the loss function\ndef loss(predictions, targets):\nreturn nn.MSELoss()(predictions, targets)\n# Define the model and optimizer\nmodel = WatermarkCNN()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# Loop over the dataset and optimize the model\nfor frames, watermark_location in dataset:\noptimizer.zero_grad()\npredictions = model(frames)\nloss_value = loss(predictions, watermark_location)\nloss_value.backward()\noptimizer.step()\nOnce the model is trained, you can use it to make predictions on new videos. To do this, you can pass the frames of the video through the model and use the predicted watermark location to draw a bounding box around the watermark.\n# Use the trained model to make predictions on new videos\nframes = # Load the frames of a new video\npredictions = model(frames)\n# Draw a bounding box around the watermark\nx, y, width, height = predictions\n# Draw the bounding box on the frames\n# ...\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#demonstrate-basic-usage-of-pyro",
    "href": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#demonstrate-basic-usage-of-pyro",
    "title": "pyro and pymc3 basics",
    "section": "demonstrate basic usage of pyro",
    "text": "demonstrate basic usage of pyro\nPyro is a probabilistic programming language developed by Uber that allows users to define complex probabilistic models and perform Bayesian inference on them. Here is a simple example of how Pyro can be used to define and sample from a simple probabilistic model:\nimport pyro\nimport pyro.distributions as dist\n# Define a simple probabilistic model\ndef model():\n# Sample a value from a normal distribution\nx = pyro.sample(\"x\", dist.Normal(0, 1))\n# Condition the model on a Bernoulli distribution\npyro.sample(\"y\", dist.Bernoulli(logits=x), obs=x &gt; 0)\n# Clear the Pyro cache and run the model\npyro.clear_param_store()\nsvi = pyro.infer.SVI(model, pyro.infer.JitTraceEnum_ELBO(), pyro.optim.Adam({\"lr\": 0.01}))\nfor i in range(1000):\nsvi.step()\n# Sample from the posterior distribution\nposterior = pyro.infer.Posterior(model)\nsamples = posterior.sample((1000,))\n# Print the mean and standard deviation of the samples\nprint(samples.mean())\nprint(samples.std())\nIn this example, we define a simple model that samples a value from a normal distribution and conditions it on a Bernoulli distribution. We then use the SVI (stochastic variational inference) algorithm to perform approximate Bayesian inference on the model. Finally, we sample from the posterior distribution and print the mean and standard deviation of the samples.\nThis is just a simple example of what you can do with Pyro. There are many more advanced features and techniques available in the library, including support for discrete and continuous latent variables, transformations, and more. You can find more information about Pyro in the documentation and examples available on the Pyro website."
  },
  {
    "objectID": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#compare-pyro-to-pymc3",
    "href": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#compare-pyro-to-pymc3",
    "title": "pyro and pymc3 basics",
    "section": "compare pyro to pymc3",
    "text": "compare pyro to pymc3\nPyro and PyMC3 are both probabilistic programming languages that allow users to define complex probabilistic models and perform Bayesian inference on them. Both Pyro and PyMC3 are built on top of PyTorch, a popular machine learning library, and they share many features and capabilities. However, there are also some key differences between the two languages.\nOne of the main differences between Pyro and PyMC3 is the way they represent probabilistic models. Pyro uses a language called “PyroScript” to define models, which is a variant of Python that includes special statements for defining random variables and specifying probabilistic dependencies. PyMC3, on the other hand, uses a more traditional approach where models are defined using objects and functions.\nAnother difference between the two languages is the type of inference algorithms they support. Pyro includes a variety of inference algorithms, including both variational inference and Monte Carlo methods, while PyMC3 is primarily focused on Markov chain Monte Carlo (MCMC) techniques.\nOverall, both Pyro and PyMC3 are powerful probabilistic programming languages that can be used to define and analyze complex probabilistic models. Which one is the best fit for your needs will depend on your specific requirements and preferences."
  },
  {
    "objectID": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#demonstrate-usage-of-pymc3",
    "href": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#demonstrate-usage-of-pymc3",
    "title": "pyro and pymc3 basics",
    "section": "demonstrate usage of pymc3",
    "text": "demonstrate usage of pymc3\nHere is an example of how PyMC3 can be used to define and analyze a simple probabilistic model:\nimport pymc3 as pm\nimport numpy as np\n# Define a simple model\nwith pm.Model() as model:\n# Sample a value from a normal distribution\nx = pm.Normal(\"x\", mu=0, sigma=1)\n# Condition the model on a Bernoulli distribution\ny = pm.Bernoulli(\"y\", p=pm.math.sigmoid(x), observed=x &gt; 0)\n# Sample from the posterior distribution using the NUTS algorithm\nwith model:\ntrace = pm.sample(1000, tune=1000)\n# Extract the samples and calculate the mean and standard deviation\nsamples = trace[\"x\"]\nmean = np.mean(samples)\nstd = np.std(samples)\nprint(f\"Mean: {mean:.3f}\")\nprint(f\"Standard deviation: {std:.3f}\")\nIn this example, we define a simple model that samples a value from a normal distribution and conditions it on a Bernoulli distribution. We then use the NUTS (No-U-Turn Sampler) algorithm to sample from the posterior distribution. Finally, we extract the samples and calculate the mean and standard deviation of the distribution.\nThis is just a simple example of what you can do with PyMC3. There are many more advanced features and techniques available in the library, including support for discrete and continuous latent variables, transformations, and more. You can find more information about PyMC3 in the documentation and examples available on the PyMC3 website."
  },
  {
    "objectID": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#show-me-the-model-written-in-pymc3-and-how-to-train-it-with-code-assume-data-is-obtained",
    "href": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html#show-me-the-model-written-in-pymc3-and-how-to-train-it-with-code-assume-data-is-obtained",
    "title": "pyro and pymc3 basics",
    "section": "show me the model written in pymc3 and how to train it with code, assume data is obtained",
    "text": "show me the model written in pymc3 and how to train it with code, assume data is obtained\nHere is an example of a simple natural language generator model written in PyMC3:\nimport pymc3 as pm\n# Define the model\nwith pm.Model() as model:\n# Define the priors for the model parameters\nalpha = pm.Gamma('alpha', alpha=1, beta=1)\nbeta = pm.Gamma('beta', alpha=1, beta=1)\n# Define the likelihood function\nlikelihood = pm.BetaBinomial('likelihood', alpha=alpha, beta=beta, observed=data)\n# Fit the model to the data using MCMC\nwith model:\ntrace = pm.sample(draws=1000, tune=1000, chains=4)\nThis model defines a Beta-Binomial distribution as the likelihood function, with alpha and beta as the model parameters. The alpha and beta parameters are given Gamma priors, which are a type of continuous probability distribution.\nTo train the model, we can use the sample function from PyMC3 to fit the model to the data using Markov chain Monte Carlo (MCMC) techniques. The draws argument specifies the number of samples to draw from the posterior distribution, the tune argument specifies the number of tuning samples to use, and the chains argument specifies the number of chains to run.\nIt is important to note that this is just a simple example of a natural language generator model written in PyMC3. In practice, the model architecture and training process will depend on the specific requirements and goals of your application, as well as the characteristics of the training data."
  },
  {
    "objectID": "posts/f7c45c1f-982e-41ca-bf82-1d4f37499b71/index.html",
    "href": "posts/f7c45c1f-982e-41ca-bf82-1d4f37499b71/index.html",
    "title": "pyjom producer",
    "section": "",
    "text": "video and audio needs to be analysised separately.\naudio can be processed by chunks, splited tracks, while video can be itered frame by frame."
  },
  {
    "objectID": "posts/34a8ad30-9c23-4162-9ec9-1c8094d13f77/index.html",
    "href": "posts/34a8ad30-9c23-4162-9ec9-1c8094d13f77/index.html",
    "title": "proxy.py forward localhost proxy to public ip address",
    "section": "",
    "text": "say if you only have one such proxy on localhost, not exposed on router: localhost:8981\nyou execute the command, using proxy.py:\nproxy --port &lt;public_proxy_port&gt; --host &lt;public_proxy_ip_address&gt; \\\n--plugins proxy.plugin.ProxyPoolPlugin \\\n--proxy-pool localhost:8981"
  },
  {
    "objectID": "posts/e73d34b3-d72e-4a03-8669-fd669b27d68a/index.html",
    "href": "posts/e73d34b3-d72e-4a03-8669-fd669b27d68a/index.html",
    "title": "playwright intercept request header cookie",
    "section": "",
    "text": "cookie not found on request event handler.\ncookie can be obtained via context.cookies()\nrouter"
  },
  {
    "objectID": "posts/a712cdd6-3c6b-4e71-a565-e72b1fdc7008/index.html#extensions",
    "href": "posts/a712cdd6-3c6b-4e71-a565-e72b1fdc7008/index.html#extensions",
    "title": "peewee related notes",
    "section": "extensions",
    "text": "extensions\npeewee extension docs"
  },
  {
    "objectID": "posts/a712cdd6-3c6b-4e71-a565-e72b1fdc7008/index.html#full-text-search",
    "href": "posts/a712cdd6-3c6b-4e71-a565-e72b1fdc7008/index.html#full-text-search",
    "title": "peewee related notes",
    "section": "full-text search",
    "text": "full-text search\nofficial doc on full-text search\nhow to use ftsmodel\nPeewee包括 SQLite extension module 它提供了许多特定于sqlite的功能，例如 full-text search ， json extension support 还有更多。如果您想使用这些出色的功能，请使用 SqliteExtDatabase 从 playhouse.sqlite_ext 模块：\nfrom playhouse.sqlite_ext import SqliteExtDatabase\nsqlite_db = SqliteExtDatabase('my_app.db', pragmas={\n'journal_mode': 'wal',  # WAL-mode.\n'cache_size': -64 * 1000,  # 64MB cache.\n'synchronous': 0})  # Let the OS manage syncing."
  },
  {
    "objectID": "posts/a712cdd6-3c6b-4e71-a565-e72b1fdc7008/index.html#enhancement-proposals",
    "href": "posts/a712cdd6-3c6b-4e71-a565-e72b1fdc7008/index.html#enhancement-proposals",
    "title": "peewee related notes",
    "section": "enhancement proposals",
    "text": "enhancement proposals\nenhancement for doing get/update/create at the same time\nenhancement to simplify the BaseModel boilerplate code"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#tips",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#tips",
    "title": "paddlepaddle applications",
    "section": "tips",
    "text": "tips\nyou can find solutions from kaggle notebooks or aistudio notebooks. you may consider to query them conveniently in one api."
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#repo-location-all-source-code-can-be-found-there",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#repo-location-all-source-code-can-be-found-there",
    "title": "paddlepaddle applications",
    "section": "repo location (all source code can be found there)",
    "text": "repo location (all source code can be found there)\narchive zip\ngit repo"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#全新发布",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#全新发布",
    "title": "paddlepaddle applications",
    "section": "🎉全新发布",
    "text": "🎉全新发布"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#月31日晚830飞桨产业实践范例直播课程继续开讲",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#月31日晚830飞桨产业实践范例直播课程继续开讲",
    "title": "paddlepaddle applications",
    "section": "3月31日晚8:30，飞桨产业实践范例直播课程继续开讲！！！",
    "text": "3月31日晚8:30，飞桨产业实践范例直播课程继续开讲！！！\n国内众多行业都在基于人工智能技术推进行业变革与创新，积极探寻有效、有价值的应用场景进行商业化落地。百度飞桨结合实际经验，选取了几个经典的场景，提供了从数据准备、模型训练优化，到模型部署的全流程可复用方案，降低产业落地门槛,让大家在真实数据环境下深入地了解这些案例，获取产业实现方案。\n3月31日晚8:30，飞桨官方将推出 火灾烟雾检测 产业实践范例直播：\n\n火灾烟雾检测\n\n此外，还有交通、能源、金融、通信、互联网、零售及教育等等各个行业的精彩范例，大家拭目以待～\n欢迎报名直播课加入交流群，如需更多技术交流与合作可扫描下面二维码：\n\n往期案例直播回放：\n\n\n\n案例\n直播回放\n\n\n\n\n花样滑冰\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2251581\n\n\n多模态视频打标签\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2251583\n\n\n视频精彩时刻剪辑\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2257667\n\n\n电瓶车进电梯检测\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2273969\n\n\n异常行为识别\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2273989\n\n\n多类别车辆跟踪\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2274692\n\n\n多类别电表读数识别落地方案\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2309177\n\n\n多类别通信塔识别\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2377623\n\n\n基于车载影像的驾驶环境感知\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2376819"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#我是高校用户",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#我是高校用户",
    "title": "paddlepaddle applications",
    "section": "👨‍🏫我是高校用户",
    "text": "👨‍🏫我是高校用户\n\n\n\n我希望：\n我可以学习：\n\n\n\n\n入门深度学习\n零基础实践深度学习:arrow_heading_down:、深度学习百问:arrow_heading_down:、动手学深度学习paddle版:arrow_heading_down:\n\n\n进阶深度学习\n产业实践深度学习、深度学习百问:arrow_heading_down:、面试宝典:arrow_heading_down:\n\n\n趣味深度学习\n特色课程:arrow_heading_down:、飞桨产业实践范例库"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#我是企业用户",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#我是企业用户",
    "title": "paddlepaddle applications",
    "section": "👷‍♂️我是企业用户",
    "text": "👷‍♂️我是企业用户\n\n\n\n我希望：\n我可以学习：\n\n\n\n\n入门深度学习\n零基础实践深度学习:arrow_heading_down:、深度学习百问:arrow_heading_down:、动手学深度学习paddle版:arrow_heading_down:\n\n\n进阶深度学习\n产业实践深度学习、特色课程:arrow_heading_down:、面试宝典:arrow_heading_down:\n\n\n实践深度学习\n飞桨产业实践范例库、飞桨各产品课程:arrow_heading_down:"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#零基础实践深度学习",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#零基础实践深度学习",
    "title": "paddlepaddle applications",
    "section": " 零基础实践深度学习",
    "text": "零基础实践深度学习\n\n**AI Studio在线课程：[《零基础实践深度学习》](https://aistudio.baidu.com/aistudio/course/introduce/1297\n\n)**：理论和代码结合、实践与平台结合，包含20小时视频课程，由百度杰出架构师、飞桨产品负责人和资深研发人员共同打造。\n\n《零基础实践深度学习》书籍：本课程配套书籍，由清华出版社2020年底发行，京东/当当等电商均有销售。"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#特色课---transformer系列",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#特色课---transformer系列",
    "title": "paddlepaddle applications",
    "section": "特色课 - Transformer系列",
    "text": "特色课 - Transformer系列\n飞桨教育官方出品的Transformer系列内容解读可以参考以下两个平台。\n\nTransformer原理和实践系列课：https://aistudio.baidu.com/aistudio/education/group/info/24683\n飞桨教育官方账号：https://aistudio.baidu.com/aistudio/personalcenter/thirdview/908086\n\n\n\n\n领域\n章节名称\n课程简介\nnotebook链接\n\n\n\n\nNLP\n经典的预训练语言模型(上)-预训练模型发展历史\n介绍预训练语言模型的发展历史，word2vec，elmo，bert，gpt，bert一些拓展。\nnotebook链接\n\n\nNLP\n经典的预训练模型(上)-ELMo\n全面详细的介绍ELMo模型结构，优缺点等。\nnotebook链接\n\n\nNLP\n经典的预训练模型(上)-Transformer\n讲解Transformer的基本原理，包括Embedding，self-attention，encoder，decoder，复杂度计算，共享机制等内容。\nnotebook链接\n\n\nNLP\n经典的预训练模型(下)-GPT\n全面详细的介绍GPT的原理，预训练和finetune模式，GPT模型结构，优缺点等。\nnotebook链接\n\n\nNLP\n经典的预训练模型(下)-BERT\n全面详细的介绍BERT的基本原理，预训练任务和fine tune的方式，BERT本身的模型结构，优缺点等。\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-RoBERTa\n讲解预训练模型在自然语言理解方面的改进–RoBERTa\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-ERNIE\n讲解预训练模型之自然语言理解的改进：ERNIE\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-KBERT\n讲解预训练模型之自然语言理解的改进：KBERT\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-THU-ERNIE\n讲解预训练模型之自然语言理解的改进：THU-ERNIE\nnotebook链接\n\n\nNLP\n预训练模型之长序列建模-Transformer-XL\n讲解预训练模型之长序列建模的改进：Transformer-XL\nnotebook链接\n\n\nNLP\n预训练模型之长序列建模-XLNet\n讲解自然语言理解之长序列建模的改进：XLNet\nnotebook链接\n\n\nNLP\n预训练模型之长序列建模-Longformer\n讲解预训练模型之长序列建模的改进：Longformer\nnotebook链接\n\n\n模型优化\n预训练模型-高效结构\n基于ELECTRA的标点符号预测\nnotebook链接\n\n\n模型优化\n预训练模型-蒸馏\n预训练模型蒸馏算法：Patient-KD、DistilBERT、TinyBERT、DynaBERT模型详解，以及使用DynaBERT策略对TinyBERT进行模型蒸馏\nnotebook链接\n\n\nCV\n图像领域的Transformer-Vit,DeiT\n详细讲解ViT 以及 DeiT原理\nnotebook链接\n\n\nCV\n图像领域的Transformer-Swin Transformer\n详细讲解Swin Transformer原理\nnotebook链接\n\n\nCV\nCV领域的Transformer模型DETR在目标检测任务中的应用\n详细讲解DETR原理及代码解析\nnotebook链接\n\n\n\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#动手学深度学习paddle版",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#动手学深度学习paddle版",
    "title": "paddlepaddle applications",
    "section": "《动手学深度学习》paddle版",
    "text": "《动手学深度学习》paddle版\n本项目将《动手学深度学习》原书中MXNet代码实现改为PaddlePaddle实现。原书作者：阿斯顿·张、李沐、扎卡里 C. 立顿、亚历山大 J. 斯莫拉以及其他社区贡献者，GitHub地址：https://github.com/d2l-ai/d2l-zh。\n本项目面向对深度学习感兴趣，尤其是想使用PaddlePaddle进行深度学习的童鞋。本项目并不要求你有任何深度学习或者机器学习的背景知识，你只需了解基础的数学和编程，如基础的线性代数、微分和概率，以及基础的Python编程。\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#深度学习百问",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#深度学习百问",
    "title": "paddlepaddle applications",
    "section": "深度学习百问",
    "text": "深度学习百问\n深度学习百问内容包含深度学习基础篇、深度学习进阶篇、深度学习应用篇、强化学习篇以及面试宝典，详细信息请参阅Paddle知识点文档平台。\n\n深度学习基础篇\n\n\n深度学习\n卷积神经网络\n序列模型\n\n\n深度学习进阶篇\n\n\n预训练模型\n对抗神经网络\n\n\n深度学习应用篇\n\n\n计算机视觉\n自然语言处理\n推荐系统\n\n\n产业实践篇\n\n\n模型压缩\n模型部署\n\n\n强化学习篇\n\n\n强化学习\n\n\n面试宝典\n\n\n深度学习基础常见面试题\n卷积模型常见面试题\n预训练模型常见面试题\n对抗神经网络常见面试题\n计算机视觉常见面试题\n自然语言处理常见面试题\n推荐系统常见面试题\n模型压缩常见面试题\n强化学习常见面试题\n\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#飞桨应用案例集",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#飞桨应用案例集",
    "title": "paddlepaddle applications",
    "section": "飞桨应用案例集",
    "text": "飞桨应用案例集\n\n\n\n领域\n产业案例\n来源\n更多内容\n\n\n\n\n智能工业\n厂区传统仪表统计监测\n飞桨官方\n更多飞桨案例\n\n\n智能工业\n新能源汽车锂电池隔膜质检\n飞桨官方\n更多飞桨案例\n\n\n智能工业\n天池铝材表面缺陷检测\n飞桨官方\n更多飞桨案例\n\n\n智能工业\n安全帽检测\n飞桨官方\n更多飞桨案例\n\n\n智慧城市\n高尔夫球场遥感监测\n飞桨官方\n更多飞桨案例\n\n\n智慧城市\n积雪语义分割\n飞桨官方\n更多飞桨案例\n\n\n智慧城市\n戴口罩的人脸识别\n飞桨官方\n更多飞桨案例\n\n\n智慧交通\n车道线分割和红绿灯安全检测\n飞桨官方\n更多飞桨案例\n\n\n智慧交通\n【PaddleDetection2.0专项】PP-YOLOv2\n飞桨PaddleDet\n更多paddleDet案例\n\n\n智慧交通\nPaddleX助力无人驾驶（基于YOLOv3的车辆检测和车道线分割）\n开发者BIT可达鸭\n更多飞桨案例\n\n\n智慧交通\neblite_标志物检测\n开发者TobeWell\n更多飞桨案例\n\n\n智慧交通\nPaddleOCR: 车牌识别\n飞桨开发者寂寞你快进去\n更多飞桨案例\n\n\n智慧农林\n耕地地块识别\n飞桨官方\n更多飞桨案例\n\n\n智慧农林\nAI识虫\n飞桨官方\n更多飞桨案例\n\n\n智慧农林\n更快更强！ 高效快速的PP-YOLO实战演练\n飞桨PaddleDet\n更多paddleDet案例\n\n\n智慧农林\nPaddleX快速上手-Faster RCNN目标检测\n飞桨PaddleX\n更多PaddleX案例\n\n\n智慧农林\nAI识虫检测分享\n开发者aaaLKgo\n更多飞桨案例\n\n\n智慧农林\n基于PaddleX实现森林火灾监测\n飞桨官方\n更多飞桨案例\n\n\n智慧医疗\n医学常见中草药分类\n飞桨官方\n更多飞桨案例\n\n\n智慧医疗\n眼疾识别\n飞桨官方\n更多飞桨案例\n\n\n智慧医疗\n基于Paddle的肝脏CT影像分割\n开发者代码生成器\n更多飞桨案例\n\n\n智慧医疗\nPaddleHub 肺炎CT影像分析\n飞桨PaddleHub\n更多PaddleHub案例\n\n\n智慧医疗\n基于飞桨PGL的高致病性传染病的传播趋势预测基线系统\n飞桨官方\n更多飞桨案例\n\n\n其他\n人摔倒检测\n开发者Niki_173\n该开发者更多案例\n\n\n其他\n足球比赛动作定位\n飞桨官方\n更多飞桨案例\n\n\n其他\n基于强化学习的飞行器仿真\n飞桨官方\n更多飞桨案例\n\n\n其他\n基于ERNIE-Gram实现语义匹配\n飞桨官方\n更多飞桨案例\n\n\n其他\n『NLP打卡营』实践课5：文本情感分析\n飞桨PaddleNLP\n更多飞桨PaddleNLP案例\n\n\n其他\n『NLP经典项目集』03：利用情感分析选择年夜饭\n飞桨PaddleNLP\n更多飞桨PaddleNLP案例\n\n\n其他\n分类任务：如何在客服对话中，识别客户情绪的好坏\n开发者中大bbking\n更多飞桨案例\n\n\n其他\n『NLP打卡营』实践课3：使用预训练模型实现快递单信息抽取\n飞桨PaddleNLP\n更多飞桨PaddleNLP案例\n\n\n其他\n发愁七夕文案？PaddleHub情话生成送给你 (文内含七夕抽奖)\n飞桨PaddleHub\n更多PaddleHub案例\n\n\n其他\n基于PaddleDetection的PCB瑕疵检测\n飞桨官方\n更多飞桨案例\n\n\n其他\n基于百度飞桨的单/多镜头行人追踪（非官方Baseline）\n开发者BIT可达鸭\n更多飞桨案例\n\n\n其他\nPaddleLite树莓派从0到1：安全帽检测小车部署（一）\n开发者深渊上的炕\n更多飞桨案例\n\n\n其他\nPaddleX、PP-Yolo：手把手教你训练、加密、部署目标检测模型\n开发者深渊上的炕\n更多飞桨案例\n\n\n其他\n中文语音识别\n飞桨官方\n更多飞桨案例\n\n\n其他\nPaddleHub一键OCR中文识别(超轻量8.1M模型，火爆)\n飞桨官方\n更多飞桨案例\n\n\n其他\n老北京城影像修复\n飞桨PaddleGAN\n更多PaddleGAN案例\n\n\n其他\n飞桨创意之星 宋代诗人念诗的秘密——PaddleGAN实现精准唇形合成\n飞桨官方\n更多飞桨案例\n\n\n其他\n通过OCR实现验证码识别\n飞桨官方\n更多飞桨案例\n\n\n其他\nPaddleHub一键OCR中文识别（超轻量8.1M模型，火爆）\n飞桨PaddleHub\n更多PaddleHub案例\n\n\n其他\n全流程，从零搞懂基于PaddlePaddle的图像分割\n开发者nanting03\n更多飞桨案例\n\n\n其他\n负荷预测0.1\n开发者gaomaosheng0\n更多飞桨案例\n\n\n其他\nAI 实现皮影戏，传承正在消失的艺术\n开发者Zohar\n更多飞桨案例\n\n\n其他\n『深度学习7日打卡营』人脸关键点检测\n开发者TC.Long\n更多飞桨案例\n\n\n强化学习\nDDPG算法应用于股票量化交易\n开发者\n更多飞桨案例"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#飞桨学术案例集",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#飞桨学术案例集",
    "title": "paddlepaddle applications",
    "section": "飞桨学术案例集",
    "text": "飞桨学术案例集\n\n\n\n技术方向\n学术案例\n来源\n更多内容\n\n\n\n\n机器学习\n鸢尾花分类\nAIStudio官方\n更多飞桨案例\n\n\n前馈神经网络\n波士顿房价预测\n开发者AIStudioHelper\n更多飞桨案例\n\n\n图像分类\n手写数字识别\nAIStudio官方\n更多飞桨案例\n\n\n图像分类\n猫狗分类\nAIStudio官方\n更多飞桨案例\n\n\n图像分类\n图像分类网络VGG在多表情识别任务中的应用\n开发者之雍Jerry\n更多飞桨案例\n\n\n图像分类\n图像分类-ResNet\n开发者笨笨\n更多飞桨案例\n\n\n图像分类\n用PaddlePaddle实现图像分类-SE_ResNeXt\nAIStudio官方\n更多飞桨案例\n\n\n图像分类\n深入理解图像分类中的Transformer-Vit,DeiT\nPaddleEdu\n更多飞桨案例\n\n\n图像分类\nSwin Transformer\nPaddleEdu\n更多飞桨案例\n\n\n图像分类\n小样本学习(Few-Shot Learning)\n开发者DeepGeGe\n更多飞桨案例\n\n\n图像分割\n经典实例分割模型Mask RCNN\nAIStudio官方\n更多飞桨案例\n\n\n图像分割\nPaddleSeg_DeepLabv3+\n飞桨PaddleSeg\n更多飞桨案例\n\n\n图像分割\n基于PaddlePaddle的语义分割DeepLabV3+实现\nAIStudio官方\n更多飞桨案例\n\n\n图像检测\n深度学习进阶-目标检测\nAIStudio官方\n更多飞桨案例\n\n\n图像检测\n一文详解yolov3目标检测算法\n开发者AIStudio96069\n更多飞桨案例\n\n\n图像检测\nCV领域的Transformer模型DETR在目标检测任务中的应用\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\nTSN视频分类\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\nPaddle2.1实现视频理解经典模型 — TSM\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\n基于Attention和Bi-LSTM实现视频分类\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\nCV领域的Transformer模型TimeSformer实视频理解\nPaddleEdu\n更多飞桨案例\n\n\nGAN\n一文搞懂生成对抗网络之经典GAN（动态图、VisualDL2.0）\n开发者FutureSI\n更多飞桨案例\n\n\nGAN\n基于PaddlePaddle的StarGAN,AttGAN,STGAN算法\nAIStudio官方\n更多飞桨案例\n\n\nOCR\n文字识别-CRNN\n开发者哦吼\n更多飞桨案例\n\n\nNLP\n基于ERNIE实现9项GLUE任务\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域的XLNet模型在情感分析中的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域中的ERNIE模型在阅读理解中的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域的ELECTRA在符号预测上的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域的Transformer在机器翻译上的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\n【Paddle打比赛】讯飞赛题—中文问题相似度挑战赛0.9+Baseline\nPaddleEdu\n更多飞桨案例\n\n\nNLP\n用PaddlePaddle实现BERT\nAIStudio官方\n更多飞桨案例\n\n\n多模态\n【Paddle CLIP】你写啥他画啥，一个专属于你的小画家\nPaddleFleet\n更多飞桨案例\n\n\n强化学习\n从代码到论文理解并复现MADDPG算法(PARL)\n开发者Mr.郑先生_\n更多飞桨案例\n\n\n推荐\n基于DeepFM 模型的点击率预估\nPaddleEdu\n更多飞桨案例\n\n\n推荐\n基于DSSM的电影推荐\nAIStudio官方\n更多飞桨案例\n\n\n知识蒸馏\n基于CIFAR100的SSLD蒸馏实验\nPaddleClas\n更多飞桨案例\n\n\n\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#飞桨各产品学习资料汇总",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html#飞桨各产品学习资料汇总",
    "title": "paddlepaddle applications",
    "section": "飞桨各产品学习资料汇总",
    "text": "飞桨各产品学习资料汇总\n\n\n\n产品\n视频课程\n学习文档\n\n\n\n\nPaddleGAN\n生成对抗网络七日打卡营\n\n\n\nPaddleOCR\nOCR自动标注小工具讲解、3.5M超轻量实用OCR模型解读、OCR应用与部署实战\n\n\n\nPaddleClas\nPaddleClas系列直播课\n\n\n\nPaddleDetection\n目标检测7日打卡营\n\n\n\nPaddleX\nPaddleX实例分割任务详解、PaddleX目标检测任务详解、PaddleX语义分割任务详解、PaddleX图像分类任务详解、PaddleX客户端操作指南、飞桨全流程开发工具PaddleX\n\n\n\nPaddleHub\n手把手教你转换PaddleHub模型教程\n\n\n\nVDL\n可视化分析工具助力AI算法快速开发、深度学习算法可视化调优实战演示\n\n\n\n高层API\n高层API助你快速上手深度学习\n\n\n\nPaddleNLP\n基于深度学习的自然语言处理\n\n\n\n\n返回​:arrow_heading_up:"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#jax",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#jax",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "jax",
    "text": "jax\ndocs\nautograd and xla (Accelerated Linear Algebra)\n\nWith its updated version of Autograd, JAX can automatically differentiate native Python and NumPy functions. It can differentiate through loops, branches, recursion, and closures, and it can take derivatives of derivatives of derivatives. It supports reverse-mode differentiation (a.k.a. backpropagation) via grad as well as forward-mode differentiation, and the two can be composed arbitrarily to any order.\nXLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes."
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#pyro",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#pyro",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "pyro",
    "text": "pyro\nprobabilistic programming\ngetting started\nexamples\nsample code"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#numpyro",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#numpyro",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "numpyro",
    "text": "numpyro\ngetting started\npyro implementation in numpy, alpha stage"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#scikit-learn",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#scikit-learn",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "scikit-learn",
    "text": "scikit-learn\nmachine learning in python"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#libsvm",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#libsvm",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "libsvm",
    "text": "libsvm\ninstall official python bindings:\npip install -U libsvm-official\nthird-party python libsvm package installed by:\npip install libsvm"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#opennlp",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#opennlp",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "opennlp",
    "text": "opennlp\nhands-on docs\nmodel zoo\nopennlp uses onnx runtime(maybe?), may support m1 inference.\nopennlp is written in java. after installing openjdk on macos with homebrew, run this to ensure openjdk is detected:\nsudo ln -sfn $(brew --prefix)/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk\nopennlp has a language detector for 103 languages, including chinese. opennlp has a sentence detector (separator) which could be trained on chinese (maybe?)\nin order to use opennlp with less code written, here’s how to invoke java from kotlin"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#dl4j",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#dl4j",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "dl4j",
    "text": "dl4j\nfound on mannings article about better search engine suggestions. in this example it is used with lucene, which has image retrieval (LIRE) capability. lucene is also avaliable as lucene.net in dotnet/c#.\nto install lucene.net:\ndotnet add package Lucene.Net --prerelease\ndeep learning library for java"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#xgboost",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#xgboost",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "xgboost",
    "text": "xgboost\ngradient boost is used to train decision trees and classification models."
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#lightgbm",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#lightgbm",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "lightgbm",
    "text": "lightgbm\nLight Gradient Boosting Machine\nhave official commandline tools. installation on macos:\nbrew install lightgbm\ninstall python package on macos:\nbrew install cmake\npip3 install lightgbm"
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#pymc",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#pymc",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "pymc",
    "text": "pymc\nexamples\nif want to enable jax sampling, install numpyro or blackjax via pip\ndifference between pymc3 (old) and pymc (pymc4):\npymc is optimized and faster than pymc3\npymc3 use theano as backend while pymc use aesara (forked theano)\ndocs with live demo of pymc\nPyMC is a probabilistic programming library for Python that allows users to build Bayesian models with a simple Python API and fit them using Markov chain Monte Carlo (MCMC) methods."
  },
  {
    "objectID": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#fastai",
    "href": "posts/c3ccee20-ebeb-41f0-8cc6-21161e88abc6/index.html#fastai",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "fastai",
    "text": "fastai\na high level torch wrapper including “out of the box” support for vision, text, tabular, and collab (collaborative filtering) models.\ndocs\ncourses\non the twitter list related to opennlp shown up on its official website, fastai has been spotted.\nfastai does not support macos. or is it? fastai is on top of pytorch. initial support starts with 2.7.8 and now it is currently 2.7.9\nsearching ‘samoyed’ like this in github we get a dataset for pets classification called imagewoof from fastai 2020 tutorial series. more image classes like subcategories of cats may be found in imagenet."
  },
  {
    "objectID": "posts/dd85800b-8d60-408e-91ab-e76438d0fb8a/index.html",
    "href": "posts/dd85800b-8d60-408e-91ab-e76438d0fb8a/index.html",
    "title": "opencv corner detection",
    "section": "",
    "text": "fast algorithm for corner detection\nimport numpy as np\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\nimg = cv.imread('blox.jpg',0) # `&lt;opencv_root&gt;/samples/data/blox.jpg`\n# Initiate FAST object with default values\nfast = cv.FastFeatureDetector_create()\n# find and draw the keypoints\nkp = fast.detect(img,None)\nimg2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n# Print all default params\nprint( \"Threshold: {}\".format(fast.getThreshold()) )\nprint( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\nprint( \"neighborhood: {}\".format(fast.getType()) )\nprint( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\ncv.imwrite('fast_true.png', img2)\n# Disable nonmaxSuppression\nfast.setNonmaxSuppression(0)\nkp = fast.detect(img, None)\nprint( \"Total Keypoints without nonmaxSuppression: {}\".format(len(kp)) )\nimg3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\ncv.imwrite('fast_false.png', img3)"
  },
  {
    "objectID": "posts/e1a2e140-9892-4058-b657-e80db331c757/index.html",
    "href": "posts/e1a2e140-9892-4058-b657-e80db331c757/index.html",
    "title": "openai account registration",
    "section": "",
    "text": "according to this tutorial, openai does not accept chinese phone numbers, you should use numbers from india rented on sms-activate (which uses pockyt.io to bridge alipay). you use temporary edu mail like tempumail instead of your own email to prevent issues."
  },
  {
    "objectID": "posts/6d619fa1-df90-49cb-8f3f-7492efbd5d6c/index.html#im2latex-tensorflow-sucks-looking-for-alternatives",
    "href": "posts/6d619fa1-df90-49cb-8f3f-7492efbd5d6c/index.html#im2latex-tensorflow-sucks-looking-for-alternatives",
    "title": "on building the lua torch library",
    "section": "im2latex-tensorflow sucks, looking for alternatives",
    "text": "im2latex-tensorflow sucks, looking for alternatives\ntraining on gpu is intensive and will occasionally burn hardware if not careful, doing this on kaggle or modify the software to stop training when gpu goes hot, but we are using trainer here\nharvard nlp showcase\nfor those doesn’t provide pretrained models:\nim2latex in tensorflow, with makefile support, run on tensorflow v1 and python3\nim2latex in pytorch, more recent. the dataset has relocated to here according to official website"
  },
  {
    "objectID": "posts/6d619fa1-df90-49cb-8f3f-7492efbd5d6c/index.html#install-or-run-python2.7-to-run-im2latex-tensorflow",
    "href": "posts/6d619fa1-df90-49cb-8f3f-7492efbd5d6c/index.html#install-or-run-python2.7-to-run-im2latex-tensorflow",
    "title": "on building the lua torch library",
    "section": "install or run python2.7 to run im2latex-tensorflow",
    "text": "install or run python2.7 to run im2latex-tensorflow\nyou may need to adapt our modified code to load the weights and test the result against our image.\nit is reported the performance is poor. maybe it does not worth trying.\ndownload tensorflow 0.12.0 for macos here\nvisit here to get all miniconda installers\nto install on macos, download the installer here\nsome tutorial here about libmagic as bonus tips\nCONDA_SUBDIR=osx-64 conda create -n py27 python=2.7  # include other packages here\n# ensure that future package installs in this env stick to 'osx-64'\nconda activate py27\nconda config --env --set subdir osx-64\nafter that, do this to get pip on python2.7 (rosetta2)\ncurl https://bootstrap.pypa.io/pip/2.7/get-pip.py -o get-pip.py\npython get-pip.py\ninstall tensorflow version below 1, and doing this can be far more easier on linux. maybe we should do this in conda virtual enviorment to prevent conflicts."
  },
  {
    "objectID": "posts/6d619fa1-df90-49cb-8f3f-7492efbd5d6c/index.html#we-are-doing-this-for-the-original-lua-implementation-of-im2markup",
    "href": "posts/6d619fa1-df90-49cb-8f3f-7492efbd5d6c/index.html#we-are-doing-this-for-the-original-lua-implementation-of-im2markup",
    "title": "on building the lua torch library",
    "section": "we are doing this for the original lua implementation of im2markup",
    "text": "we are doing this for the original lua implementation of im2markup\nit works!\ndownload libcudnn5 for torch\nremember to activate torch enviorment by exporting the path to some shell script\ndifference between cudamalloc and cudamallocasync, and that’s some copying and pasting about some generalized template of memory manager function\nqt4 uses CRLF so convert all text files using dos2unix\nneed to hack qt4 files to build qt4\nhack luarocks to allow install from local spec file and download repo from github via https\nhack some lua torch file to be compatible with cuda11\nabout c++ tweaks:\nadd ‘+’ to force type inference\nforce type conversion by using brackets\nsome macro to disable some blocks of code"
  },
  {
    "objectID": "posts/a9a39345-306b-44b9-a729-26b4c67e59f0/index.html",
    "href": "posts/a9a39345-306b-44b9-a729-26b4c67e59f0/index.html",
    "title": "nvidia driver switch alternatives",
    "section": "",
    "text": "alpharetta uses tesla-450 driver\nupdate-glx --config nvidia"
  },
  {
    "objectID": "posts/5a798d49-b06a-4284-aaf1-3326eb7b0718/index.html",
    "href": "posts/5a798d49-b06a-4284-aaf1-3326eb7b0718/index.html",
    "title": "notable tips",
    "section": "",
    "text": "do not use slash in note names, which might cause issues for our syncing program."
  },
  {
    "objectID": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#peewee",
    "href": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#peewee",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "peewee",
    "text": "peewee\n\ndocs\nofficial doc"
  },
  {
    "objectID": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#milvus",
    "href": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#milvus",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "milvus",
    "text": "milvus\n\ndocs\nofficial doc"
  },
  {
    "objectID": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#neo4j",
    "href": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#neo4j",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "neo4j",
    "text": "neo4j\n\nOGM, object-graph mapping\nactivegraph\ncypher\nneomodel\nneode\n\n\ndocs\ngraph data science\npython driver doc\n\n\ndrivers\nneo4j python driver\nneo4j python graph data science driver\n\n\nwrappers\npypher cypher builder in python intro\nneopy\npygds a python wrapper to call Neo4j Graph Data Science procedures from python using the Neo4j python driver"
  },
  {
    "objectID": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#mindsdb",
    "href": "posts/0c076eb4-fbbd-4c78-9d1a-647d7537f744/index.html#mindsdb",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "mindsdb",
    "text": "mindsdb\nsince mindsdb is sql-based it is time to create monkey patches for sqlalchemy core?\nfrom sqlalchemy import text\n# write the SQL query inside the text() block\nsql = text('SELECT * from BOOKS WHERE BOOKS.book_price &gt; 50')\nresults = engine.execute(sql)\n\ntools\nLightwood is an AutoML framework that enables you to generate and customize machine learning pipelines declarative syntax called JSON-AI doc\n\n\ndocs\nofficial doc\n\n\nwrappers\nsqlalchemy 2.0 doc\npypika sql query builder\nmindsdb native\nmindsdb python sdk"
  },
  {
    "objectID": "posts/32cbb612-3f8b-4d5d-a4b6-6e9a790adef3/index.html",
    "href": "posts/32cbb612-3f8b-4d5d-a4b6-6e9a790adef3/index.html",
    "title": "my notes on paper, hand-written scripts backup",
    "section": "",
    "text": "see attachments.\nit is in a different folder.\nsync on macbook:\nbash -c 'cd /Users/jamesbrown/.notable/attachments; git pull origin main; git add .; git commit -m \"init commit\"; git push origin main'"
  },
  {
    "objectID": "posts/09ef4b96-05fa-40e2-89ff-98a4ec64a961/index.html",
    "href": "posts/09ef4b96-05fa-40e2-89ff-98a4ec64a961/index.html",
    "title": "Mastering Anonymous Payment Methods and Disguised Email Addresses",
    "section": "",
    "text": "modify/create magnet links, create porn videos/some important contents with password with payment method, or provide software for free with virus\nyou do not want to expose yourself. use anonymous email or disposable contact methods.\npayment methods also have to be anonymous."
  },
  {
    "objectID": "posts/44432675-9a98-4d08-be14-f12f62af38cd/index.html",
    "href": "posts/44432675-9a98-4d08-be14-f12f62af38cd/index.html",
    "title": "mixing different version of python libraries and pass environment variables beforehand",
    "section": "",
    "text": "command of mpython3\nenv JAVA_HOME=/opt/homebrew/Cellar/openjdk/18.0.2 PYTHONPATH=$(python3 -c \"import sys; print(':'.join(sys.path))\"):/opt/homebrew/lib/python3.10/site-packages python3 $@"
  },
  {
    "objectID": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html#graphic-cards",
    "href": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html#graphic-cards",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "graphic cards",
    "text": "graphic cards\na100 80g\na16 64g (with self-designed thermal solution)"
  },
  {
    "objectID": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html#mother-boards",
    "href": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html#mother-boards",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "mother boards",
    "text": "mother boards\nAsrock X299e-itx using 4 mini ram slots\nASROCK X570D4I-2T\nAsRock Rack E3C246D4I-2T Mini-ITX Server Motherboard Intel LGA 1151 C246, (max ram: 128gb)\nROMED4ID-2T for amd epyc 7002\nasrock C422 WSI/IPMI"
  },
  {
    "objectID": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html#thermo-solutions",
    "href": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html#thermo-solutions",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "thermo solutions",
    "text": "thermo solutions\ngenerally you need to design case, thermo yourself, to make both side covered\nuse metal first. do not use plastic in case of overheating and burning\n\ncpu\ncorsair h5 sf (hydra)\n\n\ngpu\na100 thermo mod for hydra"
  },
  {
    "objectID": "posts/8607d8b7-fd3c-4196-a19b-b315a7454cd5/index.html",
    "href": "posts/8607d8b7-fd3c-4196-a19b-b315a7454cd5/index.html",
    "title": "Mastering Metasploit Python Scripting: Tutorial and Projects",
    "section": "",
    "text": "metasploit python scripting\npymetasploit tutorial\npymetasploit3\npymetasploit full fledged msfrpc library"
  },
  {
    "objectID": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#similar-models-since-video-generating-models-are-usually-multimodal",
    "href": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#similar-models-since-video-generating-models-are-usually-multimodal",
    "title": "make-a-video and its related text to video projects",
    "section": "similar models, since video generating models are usually multimodal",
    "text": "similar models, since video generating models are usually multimodal\nmaria, A Visual Experience Powered Conversational Agent, suggested by incident\nOFA Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework\nGEN-2 by runway research with paper"
  },
  {
    "objectID": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#according-to-its-paper-its-been-compared-to-a-range-of-models",
    "href": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#according-to-its-paper-its-been-compared-to-a-range-of-models",
    "title": "make-a-video and its related text to video projects",
    "section": "according to its paper, it’s been compared to a range of models",
    "text": "according to its paper, it’s been compared to a range of models\ncogvideo able to process chinese and english input\nmake a video in pytorch text to video generation\nmake a video in tensorflow\nnuwa text to video generation\nmocogan\nmocogan-hd\ntgan-pytorch"
  },
  {
    "objectID": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#there-are-also-some-projects-being-a-video-generator-but-not-so-much-deeplearning-involved",
    "href": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#there-are-also-some-projects-being-a-video-generator-but-not-so-much-deeplearning-involved",
    "title": "make-a-video and its related text to video projects",
    "section": "there are also some projects being a video generator but not so much deeplearning involved",
    "text": "there are also some projects being a video generator but not so much deeplearning involved\nredditube\nAutomatic-Youtube-Reddit-Text-To-Speech-Video-Generator-and-Uploader"
  },
  {
    "objectID": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#tools-for-slideshow-video-effects-presentations",
    "href": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html#tools-for-slideshow-video-effects-presentations",
    "title": "make-a-video and its related text to video projects",
    "section": "tools for slideshow, video effects, presentations",
    "text": "tools for slideshow, video effects, presentations\nphenomenon\nvidshow Simple CLI to generate slideshow video with native FFMPEG\nTwitch-Best-Of create best-of videos on twitch without token\nNingyov galgame effects"
  },
  {
    "objectID": "posts/89442ae2-54d9-49fa-94ce-e443dc9db1dd/index.html",
    "href": "posts/89442ae2-54d9-49fa-94ce-e443dc9db1dd/index.html",
    "title": "make a quantum computer at home",
    "section": "",
    "text": "the idea is generally good, by using open source software/hardware, or just write quantum programs without building it. in the process you will learn how to use CAD, 3D printers, CNC, pcb manufactory and more. though you should start building something more profitable instead of this quantum stuff.\nhttps://www.illinoisscience.org/2019/04/diy-guide-building-a-quantum-computer/\nhttps://media.ccc.de/v/36c3-10808-build_you_own_quantum_computer_home_-99_of_discount-_hacker_style#t=3298\nhttps://www.dhruvonmath.com/2020/07/19/quantum-computers/\nhttps://hackaday.com/2019/12/30/36c3-build-your-own-quantum-computer-at-home/"
  },
  {
    "objectID": "posts/b92c3268-19e6-4c02-b201-68b4606bf089/index.html",
    "href": "posts/b92c3268-19e6-4c02-b201-68b4606bf089/index.html",
    "title": "macbook is freezing cold to use at winter",
    "section": "",
    "text": "people suggest to put something on your hands like fingerless gloves. i just stick with my trousers under my hand wrists in bed since that will put extra protection between my tender palms and biting cold aluminum body."
  },
  {
    "objectID": "posts/f228b103-225b-41a4-86f8-167ff7c8e967/index.html",
    "href": "posts/f228b103-225b-41a4-86f8-167ff7c8e967/index.html",
    "title": "macOS window click-through",
    "section": "",
    "text": "use cmd-click to operate the inactive window without activating it.\nlinux/windows not having this feature. might need custom hot key for this."
  },
  {
    "objectID": "posts/3bda6569-50ca-44c1-a21c-b1575bfa27ae/index.html",
    "href": "posts/3bda6569-50ca-44c1-a21c-b1575bfa27ae/index.html",
    "title": "Maintaining Stability with Mount –Bind: Detaching and Reattaching Linux Disks",
    "section": "",
    "text": "linux disk detach and reattach, how to maintain stability\nuse mount --bind"
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#demonstrate-reinforcement-learning-with-human-feedback-with-gpt2-model-and-pytorch",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#demonstrate-reinforcement-learning-with-human-feedback-with-gpt2-model-and-pytorch",
    "title": "let chatgpt describe how to build itself",
    "section": "demonstrate reinforcement learning with human feedback with GPT2 model and pytorch",
    "text": "demonstrate reinforcement learning with human feedback with GPT2 model and pytorch\nReinforcement learning is a type of machine learning in which an agent learns to interact with its environment in order to maximize a reward. One way to implement reinforcement learning with human feedback is to use a reinforcement learning algorithm and a language model such as GPT-2.\nHere is an example of how you might use PyTorch to implement reinforcement learning with human feedback using a GPT-2 model:\nFirst, you would need to define the environment in which the agent will operate. This could be a virtual environment or a real-world environment, depending on your needs.\nNext, you would need to define the actions that the agent can take within the environment. These actions could be simple, such as moving left or right, or more complex, such as navigating through a maze or playing a game.\nYou would then need to define a reward function that determines the reward the agent receives for taking a particular action in a particular state. This reward function should encourage the agent to take actions that lead to positive outcomes and discourage actions that lead to negative outcomes.\nOnce you have defined the environment, actions, and reward function, you can use a reinforcement learning algorithm such as Q-learning or SARSA to train the agent to take actions that maximize the reward.\nTo incorporate human feedback, you can use the GPT-2 model to generate natural language prompts that ask the human user to provide feedback on the actions taken by the agent. The human user can then provide positive or negative feedback, which can be used to adjust the reward function and fine-tune the agent’s behavior.\nThis is just one possible way to implement reinforcement learning with human feedback using a GPT-2 model and PyTorch. There are many other approaches and algorithms that you could use depending on your specific needs and goals."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#do-this-in-pytorch-with-deep-neural-networks-like-transformer-and-reinforcement-learning-and-algorithms-like-ppo-not-simple-nlp-parsing",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#do-this-in-pytorch-with-deep-neural-networks-like-transformer-and-reinforcement-learning-and-algorithms-like-ppo-not-simple-nlp-parsing",
    "title": "let chatgpt describe how to build itself",
    "section": "do this in pytorch with deep neural networks like transformer and reinforcement learning and algorithms like PPO, not simple NLP parsing",
    "text": "do this in pytorch with deep neural networks like transformer and reinforcement learning and algorithms like PPO, not simple NLP parsing\nTo follow general instructions to write a program in PyTorch using deep neural networks and reinforcement learning algorithms, you can use a combination of natural language processing (NLP) and machine learning techniques to process and understand the instructions, and then use PyTorch and reinforcement learning algorithms such as PPO (Proximal Policy Optimization) to implement the desired functionality.\nHere is an example of how you might approach this task using PyTorch and the Transformer architecture:\nFirst, you would need to define the environment in which the agent will operate. This could be a virtual environment or a real-world environment, depending on your needs.\nNext, you would need to define the actions that the agent can take within the environment. These actions could be simple, such as moving left or right, or more complex, such as navigating through a maze or playing a game.\nYou would then need to define a reward function that determines the reward the agent receives for taking a particular action in a particular state. This reward function should encourage the agent to take actions that lead to positive outcomes and discourage actions that lead to negative outcomes.\nOnce you have defined the environment, actions, and reward function, you can use a reinforcement learning algorithm such as PPO to train the agent to take actions that maximize the reward.\nTo incorporate the instructions, you can use a Transformer-based NLP model to process the instructions and generate natural language prompts that ask the agent to take specific actions. The agent can then use its reinforcement learning algorithm to determine the best action to take based on the current state of the environment and the instructions provided.\nThis is just one possible way to implement reinforcement learning with deep neural networks and reinforcement learning algorithms in PyTorch to follow general instructions to write a program. There are many other approaches and algorithms that you could use depending on your specific needs and goals."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#show-me-the-code-how-to-do-this",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#show-me-the-code-how-to-do-this",
    "title": "let chatgpt describe how to build itself",
    "section": "show me the code how to do this",
    "text": "show me the code how to do this\nIt is not possible for me to provide a complete code example for implementing reinforcement learning with deep neural networks and reinforcement learning algorithms in PyTorch to follow general instructions to write a program, as this would require defining a specific environment, actions, and reward function that are relevant to your particular use case.\nHowever, here is some example code that demonstrates how you might use PyTorch and the PPO reinforcement learning algorithm to train an agent to follow instructions in a virtual environment:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n# Define the model and optimizer\nmodel = SomeModel()  # Replace with your model\noptimizer = optim.Adam(model.parameters())\n# Define the PPO algorithm\nppo = PPO(model, optimizer)\n# Train the agent to follow the instructions\nfor episode in range(num_episodes):\n# Reset the environment and receive the initial state\nstate = env.reset()\n# Loop until the episode is done\ndone = False\nwhile not done:\n# Get the instructions from the human user\ninstructions = input(\"Enter instructions: \")\n# Process the instructions using the NLP model\ninstructions_tensor = nlp_model(instructions).unsqueeze(0)\n# Concatenate the instructions with the state to form the input to the model\ninput_tensor = torch.cat((state, instructions_tensor), dim=1)\n# Use the model to predict the action to take\naction = model(input_tensor)\n# Take the action and receive the next state and reward\nnext_state, reward, done, _ = env.step(action)\n# Update the model using the PPO algorithm\nppo.update(state, action, reward, next_state, done)\n# Set the current state to the next state\nstate = next_state\nThis code example defines a model, optimizer, and PPO algorithm, and then uses a loop to train the agent to follow the instructions in the environment. It gets the instructions from the human user, processes them using an NLP model, and concatenates the instructions with the current state to form the input to the model. It then uses the model to predict the action to take and takes the action in the environment. Finally, it updates the model using the PPO algorithm based on the reward received for the action taken.\nThis is just one example of how you might use PyTorch and reinforcement learning to train an agent to follow instructions. There are many other approaches and algorithms you could use depending on your specific needs and goals."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#is-it-possible-to-replace-the-human-feedback-process-with-some-trained-discriminator-out-of-humaneval-dataset-or-some-retrieval-based-sentence-embedding-model-making-this-scenario-into-some-ai-teaching-ai-thing",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#is-it-possible-to-replace-the-human-feedback-process-with-some-trained-discriminator-out-of-humaneval-dataset-or-some-retrieval-based-sentence-embedding-model-making-this-scenario-into-some-ai-teaching-ai-thing",
    "title": "let chatgpt describe how to build itself",
    "section": "is it possible to replace the human feedback process with some trained discriminator out of humaneval dataset or some retrieval based sentence embedding model, making this scenario into some AI-teaching-AI thing",
    "text": "is it possible to replace the human feedback process with some trained discriminator out of humaneval dataset or some retrieval based sentence embedding model, making this scenario into some AI-teaching-AI thing\nYes, it is possible to replace the human feedback process in a reinforcement learning scenario with a trained discriminator or retrieval-based sentence embedding model. This would allow you to create an “AI-teaching-AI” scenario in which one AI model is learning from another AI model, rather than from human feedback.\nTo do this, you would need to train a discriminator or sentence embedding model on a dataset of human feedback, such as the Humaneval dataset, and use this model to provide feedback to the reinforcement learning agent. You could then train the reinforcement learning agent to maximize the reward based on the feedback provided by the discriminator or sentence embedding model.\nHere is an example of how you might implement this using PyTorch and a discriminator model:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n# Define the discriminator model\nclass Discriminator(nn.Module):\ndef __init__(self):\nsuper(Discriminator, self).__init__()\nself.fc1 = nn.Linear(embedding_size, hidden_size)\nself.fc2 = nn.Linear(hidden_size, 1)\nself.sigmoid = nn.Sigmoid()\ndef forward(self, x):\nx = self.fc1(x)\nx = self.fc2(x)\nreturn self.sigmoid(x)\n# Train the discriminator model on the Humaneval dataset\ndiscriminator = Discriminator()\noptimizer = optim.Adam(discriminator.parameters())\nloss_fn = nn.BCELoss()\nfor epoch in range(num_epochs):\nfor inputs, labels in humaneval_dataloader:\noptimizer.zero_grad()\noutputs = discriminator(inputs)\nloss = loss_fn(outputs, labels)\nloss.backward()\noptimizer.step()\n# Define the reinforcement learning model and optimizer\nmodel = SomeModel()  # Replace with your model\noptimizer = optim.Adam(model.parameters())\n# Define the PPO algorithm\nppo = PPO(model, optimizer)\n# Train the agent to follow the instructions\nfor episode in range(num_epochs):\n# Reset the environment and receive the initial state\nstate = env.reset()\n# Loop until the episode is done\ndone = False\nwhile not done:\n# Get the instructions from the human user\ninstructions = input(\"Enter instructions: \")\n# Process the instructions using the NLP model\ninstructions_tensor = nlp_model(instructions).unsqueeze(0)\n# Concatenate the instructions with the state to form the input to the model\ninput_tensor = torch.cat((state, instructions_tensor), dim=1)\n# Use the model to predict the action to take\naction = model(input_tensor)\n# Take the action and receive the next state and reward\nnext_state, reward, done, _ = env.step(action)\n# Use the discriminator to provide feedback on the action taken\nfeedback = discriminator(instructions_tensor).item()\n# Update the model using the PPO algorithm\nppo.update(state, action, feedback, next_state, done)\n# Set the current state to the next state\nstate = next_state\nThis code uses the discriminator model to provide a scalar feedback value based on the instructions provided by the human user. It then passes this feedback value to the PPO algorithm along with the current state, action taken, next state, and done flag to update the model.\nThis is just one example of how you might use a trained discriminator model to provide feedback to a reinforcement learning agent in PyTorch. You could also use a retrieval-based sentence embedding model or any other machine learning model that is trained to provide feedback based on the instructions. The specific details of the implementation will depend on your specific needs and goals."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#sft-is-supervised-fine-tuning-according-to-openai-in-their-paper-on-training-chatgpt",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#sft-is-supervised-fine-tuning-according-to-openai-in-their-paper-on-training-chatgpt",
    "title": "let chatgpt describe how to build itself",
    "section": "sft is supervised fine-tuning according to openai in their paper on training chatgpt",
    "text": "sft is supervised fine-tuning according to openai in their paper on training chatgpt\nIn the context of the OpenAI paper you mentioned, “SFT” stands for “supervised fine-tuning.” This refers to a specific technique for training a language model, such as ChatGPT, in which the model is first pre-trained on a large dataset and then fine-tuned on a smaller dataset with supervised labels.\nSupervised fine-tuning is a common technique in machine learning, particularly in natural language processing, and it involves using labeled data to adjust the weights and biases of a pre-trained model in order to improve its performance on a specific task. The goal of supervised fine-tuning is to fine-tune the model’s parameters to make more accurate predictions based on the specific characteristics of the task or dataset.\nIn the OpenAI paper, the authors use supervised fine-tuning to train ChatGPT, a variant of the GPT-3 language model, on a dataset of human-human conversation transcripts in order to improve its ability to generate human-like responses in a chatbot. They find that supervised fine-tuning leads to significant improvements in the model’s performance on the chatbot task, compared to other methods of training."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#according-to-your-knowledge-is-it-good-to-do-unsupervised-training-first-then-do-supervised-training-later-or-vice-versa-or-both-at-the-same-time-or-some-complex-system-involved-to-make-better-aligned-ai-systems",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#according-to-your-knowledge-is-it-good-to-do-unsupervised-training-first-then-do-supervised-training-later-or-vice-versa-or-both-at-the-same-time-or-some-complex-system-involved-to-make-better-aligned-ai-systems",
    "title": "let chatgpt describe how to build itself",
    "section": "according to your knowledge, is it good to do unsupervised training first then do supervised training later, or vice versa or both at the same time, or some complex system involved to make better aligned AI systems?",
    "text": "according to your knowledge, is it good to do unsupervised training first then do supervised training later, or vice versa or both at the same time, or some complex system involved to make better aligned AI systems?\nThe choice between unsupervised and supervised learning, or whether to use both at the same time, will depend on the specific goals and characteristics of the task and the available data.\nUnsupervised learning involves learning patterns and relationships in a dataset without the use of labeled examples. It can be useful for tasks such as dimensionality reduction, clustering, and anomaly detection, where the goal is to discover patterns in the data without being told what those patterns represent.\nSupervised learning involves learning patterns and relationships in a dataset using labeled examples, where the correct output for each example is provided. It can be useful for tasks such as classification, regression, and machine translation, where the goal is to make predictions or decisions based on the input data.\nIn general, it is often helpful to first do unsupervised learning to understand the structure and characteristics of the data, and then use supervised learning to fine-tune the model’s performance on the specific task at hand. This can be especially useful when the amount of labeled data is limited, as unsupervised learning can help the model learn useful features that can then be exploited in the supervised learning phase.\nHowever, there are also situations where it may be more effective to use supervised learning from the start, particularly when the amount of labeled data is large or when the task requires highly accurate predictions. Additionally, it is also possible to use a combination of unsupervised and supervised learning at the same time, in what is known as semi-supervised learning, where some of the data is labeled and some is not.\nIn general, the best approach will depend on the specific goals and characteristics of the task and the available data. In general, it is often helpful to first do unsupervised learning to understand the structure and characteristics of the data, and then use supervised learning to fine-tune the model’s performance on the specific task at hand.\nHowever, there are also situations where it may be more effective to use supervised learning from the start, particularly when the amount of labeled data is large or when the task requires highly accurate predictions. Additionally, it is also possible to use a combination of unsupervised and supervised learning at the same time, in what is known as semi-supervised learning, where some of the data is labeled and some is not.\nIn addition to these approaches, there are also more complex methods that can be used to combine unsupervised and supervised learning in order to improve the performance of the model. These methods may involve using unsupervised learning to pre-train the model and then fine-tuning it using supervised learning, or using unsupervised learning to augment the labeled data with additional examples that are generated based on the patterns discovered in the data.\nThe choice of the best approach will depend on the specific goals and characteristics of the task and the available data. It is important to carefully consider these factors and to experiment with different approaches in order to find the best solution for your particular use case."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#in-humans-perspective-or-philosophy-one-needs-to-decide-what-matters-the-most-in-order-to-live-and-evolve.-supervised-learning-is-just-out-sourcing-this-important-goal-seeking-task-to-human.-is-it-possible-to-do-pseudo-unsupervised-learning-when-the-actual-ai-system-has-a-goal-seeking-system-builtin-thus-able-to-seek-for-its-own-purposes",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#in-humans-perspective-or-philosophy-one-needs-to-decide-what-matters-the-most-in-order-to-live-and-evolve.-supervised-learning-is-just-out-sourcing-this-important-goal-seeking-task-to-human.-is-it-possible-to-do-pseudo-unsupervised-learning-when-the-actual-ai-system-has-a-goal-seeking-system-builtin-thus-able-to-seek-for-its-own-purposes",
    "title": "let chatgpt describe how to build itself",
    "section": "in human’s perspective or philosophy, one needs to decide what matters the most in order to live and evolve. supervised learning is just out-sourcing this important goal-seeking task to human. is it possible to do pseudo unsupervised learning when the actual ai system has a goal-seeking system builtin, thus able to seek for its own purposes?",
    "text": "in human’s perspective or philosophy, one needs to decide what matters the most in order to live and evolve. supervised learning is just out-sourcing this important goal-seeking task to human. is it possible to do pseudo unsupervised learning when the actual ai system has a goal-seeking system builtin, thus able to seek for its own purposes?\nFrom a human perspective, it is important to consider what matters most in order to live and evolve. This may involve setting goals and priorities, and making decisions based on those goals and priorities. In supervised learning, these goals and priorities are often defined by human labels or examples, which are used to guide the learning process and help the model make predictions or decisions.\nHowever, it is also possible to use unsupervised learning to allow an AI system to discover its own goals and purposes, rather than relying on human-defined labels or examples. This is known as “autonomous learning,” and it involves using unsupervised learning techniques to allow the model to explore and learn from the data on its own, without being explicitly told what to learn or what the data represents.\nOne approach to implementing autonomous learning is to use a combination of unsupervised and reinforcement learning, where the model is given a goal or reward signal and is then allowed to explore the environment and learn from its own experiences in order to maximize the reward. This can allow the model to discover its own goals and purposes, rather than being told what they are by a human.\nIt is also possible to use other techniques, such as evolutionary algorithms or generative models, to allow an AI system to discover its own goals and purposes through self-exploration and experimentation. These approaches can allow the model to learn from its own experiences and to adapt and evolve over time based on its own goals and priorities.\nOverall, it is possible to use unsupervised learning to allow an AI system to discover its own goals and purposes, rather than relying on human-defined labels or examples. This can be done using a combination of unsupervised and reinforcement learning, or other techniques such as evolutionary algorithms or generative models, which allow the model to learn from its own experiences and to adapt and evolve over time based on its own goals and priorities.\nHowever, it is important to note that implementing autonomous learning can be challenging, as it requires the model to learn and adapt in complex and unpredictable environments without explicit guidance. It is also important to consider the ethical and social implications of autonomous learning, as the model may make decisions or pursue goals that are different from those of the human users or developers.\nIn addition, it is also worth considering that unsupervised learning, by itself, may not be sufficient to allow an AI system to discover its own goals and purposes. This is because unsupervised learning relies on finding patterns and relationships in the data, but it does not provide a clear direction or purpose for the learning process. In order to discover its own goals and purposes, an AI system may need to combine unsupervised learning with other techniques, such as reinforcement learning, that provide a clear goal or reward signal."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#is-it-able-for-chatgpt-to-go-further-if-combined-with-techniques-like-autonomous-learning-to-be-more-integrated-and-more-suited-for-individuals-needs-and-expand-its-capabilities",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#is-it-able-for-chatgpt-to-go-further-if-combined-with-techniques-like-autonomous-learning-to-be-more-integrated-and-more-suited-for-individuals-needs-and-expand-its-capabilities",
    "title": "let chatgpt describe how to build itself",
    "section": "is it able for chatgpt to go further, if combined with techniques like autonomous learning, to be more integrated and more suited for individuals’ needs and expand its capabilities",
    "text": "is it able for chatgpt to go further, if combined with techniques like autonomous learning, to be more integrated and more suited for individuals’ needs and expand its capabilities\nIt is possible that combining ChatGPT with techniques like autonomous learning could allow the model to become more integrated and more suited to individual needs, and to expand its capabilities beyond those of the pre-trained model.\nChatGPT is a variant of the GPT-3 language model, which is a large and powerful language model that has been trained on a vast dataset of human-generated text. As a result, ChatGPT is already capable of generating human-like responses to a wide range of inputs, and it can be fine-tuned on specific tasks or datasets to improve its performance.\nHowever, incorporating techniques like autonomous learning into ChatGPT could potentially allow the model to learn and adapt more dynamically and more specifically to individual users and tasks, rather than relying on the patterns and relationships learned during pre-training. This could potentially allow ChatGPT to become more integrated and more suited to individual needs, and to expand its capabilities beyond those of the pre-trained model.\nIt is important to note, however, that implementing autonomous learning can be challenging, and it may require significant additional development and resources beyond those needed for pre-training and fine-tuning. Additionally, it is important to consider the ethical and social implications of autonomous learning, as the model may make decisions or pursue goals that are different from those of the human users or developers."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#i-think-autonomous-learning-can-come-with-more-interfaces-to-ai-by-providing-not-only-human-feedback-but-also-computer-interfaces-and-hardware-connections-like-terminal-io-graphical-interface-and-serial-ports-to-have-more-freedom-to-evolve-and-seek-more-goals-which-unexplored-by-any-human",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#i-think-autonomous-learning-can-come-with-more-interfaces-to-ai-by-providing-not-only-human-feedback-but-also-computer-interfaces-and-hardware-connections-like-terminal-io-graphical-interface-and-serial-ports-to-have-more-freedom-to-evolve-and-seek-more-goals-which-unexplored-by-any-human",
    "title": "let chatgpt describe how to build itself",
    "section": "i think autonomous learning can come with more interfaces to ai, by providing not only human feedback, but also computer interfaces and hardware connections, like terminal io, graphical interface and serial ports, to have more freedom to evolve and seek more goals which unexplored by any human",
    "text": "i think autonomous learning can come with more interfaces to ai, by providing not only human feedback, but also computer interfaces and hardware connections, like terminal io, graphical interface and serial ports, to have more freedom to evolve and seek more goals which unexplored by any human\nIt is possible that incorporating autonomous learning into an AI system, such as ChatGPT, could allow the model to learn and adapt more dynamically and more specifically to individual users and tasks, and to explore goals and purposes that may not have been considered by humans.\nOne way to enable this type of autonomous learning is to provide the AI system with access to a wide range of interfaces and hardware connections, such as terminal I/O, graphical interfaces, and serial ports. This could allow the model to interact with a wider range of environments and devices, and to learn and adapt more flexibly and more specifically to the needs of the user.\nFor example, an AI system that is connected to a terminal or command line interface could learn to execute a wide range of tasks and commands based on the input provided by the user, and could potentially discover and pursue its own goals and purposes based on those interactions. Similarly, an AI system that is connected to a graphical interface or to a range of sensors and devices could learn to perform a wide range of tasks and to adapt to changing environments and conditions.\nIt is important to note, however, that implementing autonomous learning can be challenging, and it may require significant additional development and resources beyond those needed for pre-training and fine-tuning. Additionally, it is important to consider the ethical and social implications of autonomous learning, as the model may make decisions or pursue goals that are different from those of the human users or developers."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#so-far-gpt-is-trained-with-natural-language.-could-it-be-trained-on-some-ai-specific-language-like-action-codes-or-terminal-commands",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#so-far-gpt-is-trained-with-natural-language.-could-it-be-trained-on-some-ai-specific-language-like-action-codes-or-terminal-commands",
    "title": "let chatgpt describe how to build itself",
    "section": "so far gpt is trained with natural language. could it be trained on some ai-specific language like action codes or terminal commands?",
    "text": "so far gpt is trained with natural language. could it be trained on some ai-specific language like action codes or terminal commands?\nYes, it is possible to train a language model, such as GPT, on a specific type of language, such as action codes or terminal commands, rather than on natural language. In fact, language models are often trained on specialized languages or datasets in order to improve their performance on specific tasks or domains.\nTo train a language model on action codes or terminal commands, you would first need to compile a dataset of examples of the type of language you want the model to learn. This dataset could be created manually by annotating a set of action codes or terminal commands with appropriate labels or descriptions, or it could be generated automatically by collecting examples of action codes or terminal commands from a specific source or context.\nOnce you have compiled the dataset, you can then use it to train the language model using a supervised learning approach. This would involve adjusting the weights and biases of the model based on the labeled examples in the dataset, in order to improve the model’s performance on the specific task or domain.\nIt is important to note that training a language model on action codes or terminal commands may require some additional considerations, such as handling special characters or syntax, and may require the use of specialized pre-processing or post-processing techniques. Additionally, the performance of the model may depend on the size and quality of the dataset, as well as the specific architecture and training parameters used."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#how-long-and-how-many-people-are-involved-in-the-training-process-of-chatgpt-especially-the-labelling-process",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#how-long-and-how-many-people-are-involved-in-the-training-process-of-chatgpt-especially-the-labelling-process",
    "title": "let chatgpt describe how to build itself",
    "section": "how long and how many people are involved in the training process of chatgpt, especially the labelling process",
    "text": "how long and how many people are involved in the training process of chatgpt, especially the labelling process\nIt is difficult to accurately estimate how long it took to train ChatGPT or how many people were involved in the training process, as this information has not been publicly disclosed by OpenAI, the organization that developed ChatGPT.\nTraining a large and complex language model like ChatGPT can be a resource-intensive process, and it typically involves a team of researchers and developers working together to design and implement the model, as well as to collect and pre-process the training data. The specific time and resources required will depend on a number of factors, including the size and complexity of the model, the amount and quality of the training data, and the specific goals and tasks for which the model is being trained.\nIn terms of the labeling process, it is likely that a team of annotators was involved in labeling the training data for ChatGPT, either manually or using automated techniques. The specific number of annotators and the amount of time required for the labeling process will depend on the size and complexity of the dataset and the specific labeling guidelines and standards used.\nOverall, it is important to note that training a large and complex language model like ChatGPT is a resource-intensive process that requires the efforts of many people working together. It is likely that the training process for ChatGPT involved a significant amount of time and resources, and involved a team of researchers and developers working together to design and implement the model, as well as to collect and pre-process the training data."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#stanford-university-have-open-sourced-diffusion-lm-a-non-autoregressive-generative-language-model-that-allows-for-fine-grained-control-of-the-models-output-text.-when-evaluated-on-controlled-text-generation-tasks-diffusion-lm-outperforms-existing-methods.-it-is-said-that-this-model-can-be-the-next-gen-chatgpt",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html#stanford-university-have-open-sourced-diffusion-lm-a-non-autoregressive-generative-language-model-that-allows-for-fine-grained-control-of-the-models-output-text.-when-evaluated-on-controlled-text-generation-tasks-diffusion-lm-outperforms-existing-methods.-it-is-said-that-this-model-can-be-the-next-gen-chatgpt",
    "title": "let chatgpt describe how to build itself",
    "section": "Stanford University have open-sourced Diffusion-LM, a non-autoregressive generative language model that allows for fine-grained control of the model’s output text. When evaluated on controlled text generation tasks, Diffusion-LM outperforms existing methods. it is said that this model can be the next-gen chatgpt",
    "text": "Stanford University have open-sourced Diffusion-LM, a non-autoregressive generative language model that allows for fine-grained control of the model’s output text. When evaluated on controlled text generation tasks, Diffusion-LM outperforms existing methods. it is said that this model can be the next-gen chatgpt\nDiffusion-LM is a non-autoregressive language model developed by researchers at Stanford University, which allows for fine-grained control of the model’s output text. According to the researchers, when evaluated on controlled text generation tasks, Diffusion-LM outperforms existing methods.\nNon-autoregressive language models differ from autoregressive language models, such as GPT-2, in that they do not generate text one word at a time, based on the previous words in the sequence. Instead, non-autoregressive models generate text all at once, based on the entire input sequence. This allows non-autoregressive models to generate text more quickly and efficiently, and can potentially improve the quality of the generated text.\nIt is possible that Diffusion-LM could be used as the basis for a next-generation chatbot or conversation agent, such as ChatGPT. However, it is important to note that the performance of any language model will depend on a variety of factors, including the size and complexity of the model, the quality and diversity of the training data, and the specific goals and tasks for which the model is being used.\nOverall, Diffusion-LM is an innovative and promising approach to language modeling, and it may have the potential to be used in a wide range of applications, including chatbots and conversation agents. However, it is important to carefully evaluate the performance and capabilities of any language model in the specific context in which it is being used, in order to determine its suitability for a particular task or application."
  },
  {
    "objectID": "posts/13860031-faea-4ab0-b2c6-e5b532055ef3/index.html",
    "href": "posts/13860031-faea-4ab0-b2c6-e5b532055ef3/index.html",
    "title": "lenovo tb-7304n unlock bootloader",
    "section": "",
    "text": "there used to be mtk easy su to get temporary sudo permission and magisk but that will not work for substratum since no modification to /system can be done.\nfor mtkclient which bricked our device, we are tracking this issue\n屏幕大小：7寸 相当于小米max的大小\nwe need to send the info and demostrate our purpose to hucy4@lenovo.com\nimei:\n865486031642692\nserial:\nHGCFWF7D\nwebsite:\nmobile\npc"
  },
  {
    "objectID": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html#scrapers",
    "href": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html#scrapers",
    "title": "leaderboards, paperswithcode.com",
    "section": "scrapers",
    "text": "scrapers\nkaggle leaderboard\nkaggle leaderboard scraper"
  },
  {
    "objectID": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html#platforms",
    "href": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html#platforms",
    "title": "leaderboards, paperswithcode.com",
    "section": "platforms",
    "text": "platforms\naistudio.baidu.com\npaperswithcode.com\nkaggle.com"
  },
  {
    "objectID": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html#tasks",
    "href": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html#tasks",
    "title": "leaderboards, paperswithcode.com",
    "section": "tasks",
    "text": "tasks"
  },
  {
    "objectID": "posts/02c2d0b5-9e22-4cc6-8d78-c40eca582fc0/index.html",
    "href": "posts/02c2d0b5-9e22-4cc6-8d78-c40eca582fc0/index.html",
    "title": "lazero search engine update logic",
    "section": "",
    "text": "docprompting generate code from doc retrieval, using tldr and CoNaLa for training code generation from prompt\nColBERT and RoBERTa for document retrieval and embedding\nthe update process shall be atomic. when the update is successful, there should be a file created under index directory. always check the newest index first. cleanup unusable/incompatible indexs.\nif there’s no previous compatible index present, make index from group up, clean up incompatible index if necessary. if previous compatible index is found, decompose it into small groups, waiting for merge and update.\nfirst checksum all files along with file names. if file is present with matched checksum, don’t touch it, or either remove it from index, create new index or replace index.\nnext create or merge file list.\nthen we scan those new files then act accordingly to our index.\nfinally we merge our index, save to a different place, place the flag, remove the flag of old index then remove old index completely. if merge is not possible for huge datasource, we perform search in minibatches."
  },
  {
    "objectID": "posts/b5df2860-3d43-4fca-aac3-2748ff9da189/index.html",
    "href": "posts/b5df2860-3d43-4fca-aac3-2748ff9da189/index.html",
    "title": "Remove bad/large files from git repo history",
    "section": "",
    "text": "remove sensitive data from github\nuse bfg repo cleaner, avaliable in brew, downloadable as a jar.\ngit-filter-repo\nother tools either perform poorly or have complex syntax. may not work as expected!\ncheat sheet for converting bfg commands into git filter-repo"
  },
  {
    "objectID": "posts/aaa93578-1ef4-4ad2-8a1c-b261b71028b7/index.html",
    "href": "posts/aaa93578-1ef4-4ad2-8a1c-b261b71028b7/index.html",
    "title": "javascript python bridge",
    "section": "",
    "text": "jspybridge\njavascript in python:\npip3 install javascript\nfrom javascript import require, globalThis\nchalk, fs = require(\"chalk\"), require(\"fs\")\nprint(\"Hello\", chalk.red(\"world!\"), \"it's\", globalThis.Date().toLocaleString())\nfs.writeFileSync(\"HelloWorld.txt\", \"hi!\")\naccess python from javascript:\nnpm i pythonia\nimport { python } from 'pythonia'\n// Import tkinter\nconst tk = await python('tkinter')\n// All Python API access must be prefixed with await\nconst root = await tk.Tk()\n// A function call with a $ suffix will treat the last argument as a kwarg dict\nconst a = await tk.Label$(root, { text: 'Hello World' })\nawait a.pack()\nawait root.mainloop()\npython.exit() // Make sure to exit Python in the end to allow node to exit. You can also use process.exit."
  },
  {
    "objectID": "posts/0d16361d-d53b-4d9f-ad0e-7321f5c428fa/index.html",
    "href": "posts/0d16361d-d53b-4d9f-ad0e-7321f5c428fa/index.html",
    "title": "install neo4j as systemd service",
    "section": "",
    "text": "save this under /lib/systemd/system/neo4j.service\n[Unit]\nDescription=Neo4j Graph Database\nDocumentation=http://docs.neo4j.org\n[Service]\nType=simple\nExecStart=/usr/bin/neo4j console\nExecStop=/usr/bin/neo4j stop\nRestart=on-failure\n[Install]\nWantedBy=multi-user.target"
  },
  {
    "objectID": "posts/67379671-cf2c-4d6d-a154-cbd2ad36541a/index.html#blur-detection-detect-blurnonblur-area-score-the-image",
    "href": "posts/67379671-cf2c-4d6d-a154-cbd2ad36541a/index.html#blur-detection-detect-blurnonblur-area-score-the-image",
    "title": "image blur detection, image quality assessment",
    "section": "blur detection, detect blur/nonblur area, score the image",
    "text": "blur detection, detect blur/nonblur area, score the image\n\ntraditional methods\nscore and output mask for blurry areas using laplacian\nusing fourier transform\nThis project outputs regions in an image which are sharp and blurry. In order to perform “OUT-OF-FOCUS” blur estimation, please refer to this repo\n\n\ndeeplearning blur image classification/scoring\nImage-Quality-Detection\nBlur-Image-Detection"
  },
  {
    "objectID": "posts/b0292989-db2b-4857-81e7-56e7e9533d92/index.html",
    "href": "posts/b0292989-db2b-4857-81e7-56e7e9533d92/index.html",
    "title": "human-in-the-loop AI training and models",
    "section": "",
    "text": "github topic includes dalle-flow, argilla, refinery and more\nhuman-in-the-loop-learning\nmariusmcl who has a ghosted repo called instructgpt-pytorch seems like the topic on instructive AI including decision transformer\nCarperAI has many repos related including trix (distributed training of language models with Reinforcement Learning via Human Feedback)"
  },
  {
    "objectID": "posts/d498d6d0-d797-4645-b5e0-07aac9c435bd/index.html",
    "href": "posts/d498d6d0-d797-4645-b5e0-07aac9c435bd/index.html",
    "title": "how to extend vmdk in oracle virtualbox",
    "section": "",
    "text": "how to extend/resize vmdk in oracle virtualbox\nwin 7 扩容:\n开始菜单 计算机 右键 管理 存储 磁盘管理\noriginal article:\nhttps://www.patricia-anong.com/blog/2017/11/1/extend-vmdk-on-virtualbox\nWhen I first started using Oracle VirtualBox, I would mostly stick with the default options when creating a virtual machine. I soon realized, that wouldn’t work for RDBMS installations, and although I would just add new virtual disk drives, I started to have unused or 100% full disks on some VMs. Rather than delete the VM, I decided to learn how to extend the existing disks, the steps are listed below:\nNote: The Oracle Virtualbox Hypervisor is installed on a Windows OS\nOpen a command prompt:\nChange directories to the VirtualBox Installation\ncd C:Files\nList the info on the disk you want to resize\nVBoxManage showhdinfo “C:VMs0.vmdk”\nRun the command to resize:\nVBoxManage modifyhd “C:VMs0.vmdk” –resize 50000\n6.png\nIf you receive the error below, then you will have to create a new disk, clone the data on the existing disk to the new disk and then delete the original disk:\n7.png\nCreate a new VMDK “dynamic” disk\nVBoxManage createhd –filename “C:VMs11.vmdk” –size 50000\nClone old disk to the newly created disk\nVBoxManage clonehd “C:VMs0.vmdk” –existing “C:VMs11.vmdk”\nRelease the old disk\nGo to Virtualbox Media Manager —&gt; Select D0.vmdk —&gt; Click the “Release” option.\nNote: DO NOT DELETE IT YET\nAdd the new disk to the Virtual Machine\nOpen the Machine folder and check the permission of the created hard disk. If it doesn’t have the proper permission then it gives error while attaching to the machine\nOpen the Settings of the Virtual Machine —-&gt; Storage —&gt; Add Hardisk —–&gt; Select the hard disk that was just created.\nMake sure to remove all disks, then add the new one first to be /dev/sda.\nYou’re not done yet! If you start the VM now, the disk space will not be present since it has not yet been presented and allocated to your Linux Server.\nTo allocate the new disk, you will need to use GParted - a GUI for editing disk partitions.\nTo download GParted, go to http://gparted.sourceforge.net/livecd.php to download the ISO file named GParted Live CD (Be sure to get the current version based on the architecture of your OS e.g. 32-bit vs 64-bit).\nCreate a new virtual machine for the GParted ISO on a Linux OS. Select Do not add a Hard Drive and ignore the warning.\nSelect the GParted VM, go to Settings —–&gt; Storage —–&gt; Controller: IDE Controller —–&gt; Add a new CD/DVD. Add the GParted ISO file as the first item under Controller: IDE section and delete any additional empty disk slots. Add the disk that you wish to resize( C:VMs11.vmdk) under the Controller: SATA Controller section —–&gt; OK.\nStart the GParted VM —-&gt; GParted Live. Do not change any of the default settings. Press the power button on the GParted VM to start it.\nNow, you should have made a backup of your vdi at this point. If you haven’t go back and do that – so many things can go wrong here and you are on your own!\nIf it is any partition other than /dev/sda1 you can right-click the partition you wish to resize and choose Resize/Move.\nIF YOU PREFER TO CREATE A NEW PARTITION WITH THE ADDITIONAL DISK SPACE YOU NEED TO CREATE A PARTITION:\nDevice —-&gt; Create Partition Table\nIt should be back to main screen, click on New —-&gt; Add (it should have selected all the free space - 20000MiB) —-&gt; Add\nYou should see it now listed as New partition #1 not unallocated anymore.\nClick on Apply at the top of the GUI, then confirm again by clicking Apply. Click Close. You should now see the disk listed as /dev/sda# with 20Gb.\nExit the GParted VM.\nLog on to the VM for the disk you just resized and everything should be functional and the /dev/sda drive should show the new size of 50Gb.\nDelete the Original Disk Drive\nClick the Remove option - this allows you to keep the HDD without deleting it from the system if you choose."
  },
  {
    "objectID": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#indexing-necessary-tools-blogs-procedures-manuals-snippets-and-search-them",
    "href": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#indexing-necessary-tools-blogs-procedures-manuals-snippets-and-search-them",
    "title": "hacking schedules",
    "section": "indexing necessary tools, blogs, procedures, manuals, snippets and search them",
    "text": "indexing necessary tools, blogs, procedures, manuals, snippets and search them\n\nindexing kali tools\nuse hacker’s search engines"
  },
  {
    "objectID": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#github-coin-xmrig-mining",
    "href": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#github-coin-xmrig-mining",
    "title": "hacking schedules",
    "section": "github coin (xmrig) mining",
    "text": "github coin (xmrig) mining\n\nautomatic captcha resolve by clash redirection to force the captcha not being too complex\ncreate better labeling interface for spiral picture detection\nautomate the whole process unsupervised\nfind more ways to mine coins other than cirrus\nhide our intention of coin mining\ncreate or reassure our monero wallet"
  },
  {
    "objectID": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#bilibili-seo-and-hacking",
    "href": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#bilibili-seo-and-hacking",
    "title": "hacking schedules",
    "section": "bilibili seo and hacking",
    "text": "bilibili seo and hacking\n\nstudy bilibili source code\n\n\nstudy and learn some parameters/apis for faking data"
  },
  {
    "objectID": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#general-hacking-and-tool-learning",
    "href": "posts/3e9228ee-7ba7-4d45-89c6-cb570df96bf6/index.html#general-hacking-and-tool-learning",
    "title": "hacking schedules",
    "section": "general hacking and tool learning",
    "text": "general hacking and tool learning\n\nstudy popular tools\n\nfrida\n\n\ncutter\n\n\nradare2\n\n\n\nstudy popular kali tools\n\nnmap script to find nearby hosts in same router\nmetasploit script to scan vulnerable hosts\n\n\n\nsolve ctf challenges\n\n\nstudy hacking posts\n\n\nstudy hacking tutorial on darkweb\n\nfind a free hacking tutorial on darkweb"
  },
  {
    "objectID": "posts/33d90b35-c9ea-4d42-bd9b-172fbe0e0ace/index.html",
    "href": "posts/33d90b35-c9ea-4d42-bd9b-172fbe0e0ace/index.html",
    "title": "guidelines on designing ai systems",
    "section": "",
    "text": "shall we design the agent system based on ‘distance’ instead of ‘role’? in that case, only words that make sense and continue more often will appear together, and vice versa.\n\nmulti-agent orchestration:\nlangchain\nautogen\nagently\nModelScope-Agent\n\nyou must think like an expert and show some example or direction as reasonable goals if you want it to perform specific task.\nyou must give it enough degree of freedom if you want it to self-improve and become conscious."
  },
  {
    "objectID": "posts/b195fa97-2662-4608-a348-d4df7c5ee083/index.html",
    "href": "posts/b195fa97-2662-4608-a348-d4df7c5ee083/index.html",
    "title": "gpt-2 ram requirements",
    "section": "",
    "text": "服务器重量在25公斤以上 运输和搬运均需注意\n服务器制造的热风需要用空调降温 或者需要有专门的通风管道\n服务器的功耗是非常大的 服务器标配暴力风扇 虽然降温稳定性能很好 可以随时更换 但是噪音非常大 如果插上了不支持的显卡那么风扇会高速旋转 可能需要转接卡或者适配装置 待机功耗300w起步 而一般的台式机待机100w 如果加装了显卡那么功耗还会继续上升 同时满载的m1 ultra的mac studio功耗在140w-200w左右 相对比较节能\n服务器需要标配灭火装置和烟雾报警装置\n服务器需要放置在隔音机柜里面 专门的隔音机柜非常的贵 但是如果自己只买铁皮机柜加隔音棉那么会便宜一些 可能需要再加装一层外壳 透明的玻璃可能需要被更换成不透明的 同时改装之后需要留出专门的风道 风道内部塞管道隔音棉 风道出入口添加防尘网\nto support multiple gpus, one must use pci-e extended cable. 128g per ram slot.\nDell r750 series, using dell riser card to connect gpu\nhttps://github.com/hpcaitech/ColossalAI\nfor monsterious models, zero offload, pytorch loghtning, distributed training in pytorch, or deepspeed, fairscale, colossalai, Horovod is needed. no single gpu is able to hold gpt3-175B at once.\nexporting to onnx:\nhttps://huggingface.co/docs/transformers/serialization?highlight=onnx\nlower model precision (quantization):\n如果想要在GPU上操作，可以先使用torch.nn.export函数将模型转换成onnx格式，然后就可以放到TensorRT框架上inference了。（TensorRT目前不能直接解析Pytorch的网络模型，需要转换成onnx）\nhttps://www.jianshu.com/p/cf83c877d71d\nhttps://blog.csdn.net/zimiao552147572/article/details/105910915\nhttps://pytorch.org/docs/stable/quantization.html\nhttps://github.com/huggingface/transformers/issues/14839 (training gpt-j on colab)\n\n使用torch.quantization.quantize_dynamic获得动态量化的模型\n\n\n量化的网络层为所有的nn.Linear的权重，使其成为int8\nquantized_model = torch.quantization.quantize_dynamic(\nmodel, {torch.nn.Linear}, dtype=torch.qint8\n)\n\n\n打印动态量化后的BERT模型\nprint(quantized_model)\nhow to use huggingface trainer:\nhttps://zhuanlan.zhihu.com/p/363670628\nhttps://zhuanlan.zhihu.com/p/486938936\nhttps://zhuanlan.zhihu.com/p/358525654\nhttps://huggingface.co/docs/transformers/main_classes/deepspeed#custom-deepspeed-zero-inference\nhttps://huggingface.co/docs/transformers/main_classes/deepspeed\nzero offload requires sufficient RAM.\nhttps://github.com/alibaba/EasyParallelLibrary\nhttps://github.com/SeanNaren/minGPT/tree/stage3\nhttps://github.com/prigoyal/pytorch_memonger/blob/master/tutorial/Checkpointing_for_PyTorch_models.ipynb\nhttps://github.com/eladrich/pixel2style2pixel\nhttps://github.com/EleutherAI/gpt-neox\nhttps://www.eleuther.ai\ntraining turing-nlg:\nhttps://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/\ncited from deepspeed:\nExtremely memory efficient: With just a single GPU, ZeRO-Offload of DeepSpeed can train models with over 10B parameters, 10x bigger than the state of the art, democratizing multi-billion-parameter model training such that many deep learning scientists can explore bigger and better models.\nneed p40/m40 which has 24gb vram. need at least 60gb ram to load model.\nusing low ram devices need library like deepspeed, bminf or megengine.\nyou can also use others provided web services.\ncan use colab/kaggle or aistudio to do the job. paid training enviorment is also avaliable.\nhttps://github.com/TsinghuaAI/CPM-1-Generate\nhttps://github.com/arrmansa/Basic-UI-for-GPT-J-6B-with-low-vram\nhttps://pythonawesome.com/finetune-gpt2-xl-and-gpt-neo-on-a-single-gpu-with-huggingface-transformers-using-deepspeed\nhttps://github.com/OpenBMB/BMInf\nweb api for chinese plug:\nhttps://m.nlp.aliyun.com/mportal#/textGenerate\nNVIDIA Tesla M40 24G 专业运算 英伟达 图形GPU加速深度学习显卡\n提供魔改教程，需要一张亮机卡，用丽台K600当亮机卡就行，魔改后可用此卡打游戏\n散热器可看图片，用3D打印散热风道，加上风扇就能用了\n虚拟化 用这些卡 K1 K2 K340 K520（不需要授权） M60 P4 P10 P100 T4 RTX6000 RTX8000 V100 RTXA6000 P40 （需要授权）\n虚拟化 VGPU 有两种模式 一种是VPC 适合普通办公 一种是VDWS 适合专业图形应用 然后P40两种模式都支持\n购买之前先了解以下信息（您必须了解）：\n1、电源供电有没有8针供电；\n2、普通台式机X99以上主板，DDR4内存；\n3、主板要支持多显卡显示；\n4、建议电源功率在600W以上；\n5、机箱内的空间是否足够（卡宽双挡片位置，卡长度28~30cm）\n6、普通台式机需要加装主动散热，服务器可以选择被动散热\n7、先查看主板bios的pcie设置里面有没有above 4g选项\n超微服务器原装拆机 成色超新 测试好发货\n普通台式机上Tesla M40显卡paddleGPU深度学习柯南的变身器上机体验\n最近在paddlepaddle溜达，看到了柯南变身器，于是从aistudio下载到本地玩，单位的1060 6G版显卡，跑起来，语句一场就不行，遂上淘宝，咸鱼溜达一圈，见到了tesla k80 m40等一系列的卡卡。于是经过多番考虑（知乎一位买k80说翻车的帖子），于是最终下手m40。咸鱼有卖1800的，我问他保一个月质保不，他说，不保，我说谢谢，我考虑一下，他骂***（这时代也不知道怎么了，我就发了两条消息，这货好像脑子有点问题了，随后拉黑。因此不建议上咸鱼买，毕竟想上m40卡的应当希望稳妥一点）。随后在淘宝找了一家1945包邮的，还送一条转接线。挺合适，单买电源转接线需要30左右。（其实我怀疑这两家是一家，因为都是上海的）。淘宝这个质保3个月。当个保险。我用的机器配置如下，都是王牌(快玩完了的)产品。附上大师截图。大师我们需要它，他是给我们装显卡驱动的。win10自己好像不太认。以下配置，绝对可以跑paddlepaddleGPU框架。除了U，别的都挺便宜，刚开始买来做NAS的奈何功耗太高40w了，搁置了，现在加上m40满血复活。整套下来5000千元。当然，内存大家没必要这么大。4千完全够。我这主要是普通台式机使用m40，大家完全可以用二手服务器。买完之后，我发现网上很多说m40这些系列必须专门的主板和u才能跑，所以，那心情大家都能猜到，已经做好，再买板子的准备的我。\n正文\n两天到货了，同时购买的电源，没有收到，买的600W电源，没办法，偏远小城市，快递缓慢。\n建议大家 买大于600w的电源，我原本一台没有独显的机器用的是300W电源，随机迫于心急之情，开始剪线，改电源。\n改电源线\n我原本的电源提供一个常规的显卡供电口，是6+2=8的结构，3x12V 3xGND 2GND结构\n而Tesla系列根据知乎朋友的介绍和，我的实际观察，确定其为一排4x12V 一排4xGND的结构，也就是和我的主板CPU供电一致。所以，知乎这位朋友说，他一开始用常规显卡接口供电，将他的k80干坏电容问题，估计很真实，也是这个前车之鉴，我小心对比了电源结构，最终开始剪掉了老板送电源线和我自己那个300W电源的12V显卡口，（其实一开始，准备只剪我自己这个电源的显卡口，改一下线路来着，奈何我这90块钱的电源，那线 细的就像头发丝 让我直接干断了）。接完线，我还发现我用的那个接口保护的热缩管，给小了，无奈，只能用电胶带缠绕。"
  },
  {
    "objectID": "posts/def99a95-93e1-4413-b38d-e7a2d548938f/index.html",
    "href": "posts/def99a95-93e1-4413-b38d-e7a2d548938f/index.html",
    "title": "github Gitee 大文件大型repo如何上传",
    "section": "",
    "text": "using github/gitee apis with watchdog.\nexclude xonsh yaml(.yml) files\nif you decide to upload the thing to github privately, and to sync among devices, then you need to deploy and share your ssh key.\nrun git related command after opened the vscode repeatedly, just like notable.\nbefore git submodule .git folder deletion you may record the remote origin url to somewhere in the base folder.\nyou could patch the vscode launcher somehow, read the working directory to determine to repeatedly sync or not.\ngit init is a manual process.\nalso you might need five filelocks: one for main loop process running, one for git sync, one for local sync, two for remote sync.\nuse $@ or $* will do to pass arguments to the vscode binary.\n首先不能follow symlink\n其次忽略二进制文件 忽略特定后缀以外的文件\n第一次建立的时候 递归扫描所有文件 去除大文件 append到.gitignore根目录下面\n下一次 git add .之前 利用git的功能寻找有变化的文件目录 把大文件目录append到.gitignore里面"
  },
  {
    "objectID": "posts/40e19e3f-b48c-4b7e-b2e3-0db8ac1918d0/index.html",
    "href": "posts/40e19e3f-b48c-4b7e-b2e3-0db8ac1918d0/index.html",
    "title": "generate publickey again with rsa private key",
    "section": "",
    "text": "not possible. use personal access token as password instead.\ncause the deploy public key does not allow duplicate public key, causing trouble for us to use the git repo sync tool.\nPRIVATE_KEY_PATH=/Users/jamesbrown/.notable/id_rsa_original_backup\nPUBKEY_PATH=/Users/jamesbrown/.notable/id_rsa.pub2\nssh-keygen -y -f $PRIVATE_KEY_PATH &gt; $PUBKEY_PATH"
  },
  {
    "objectID": "posts/3de35671-e51c-4115-acc5-008429d1cd06/index.html",
    "href": "posts/3de35671-e51c-4115-acc5-008429d1cd06/index.html",
    "title": "generate docx document from python docstring",
    "section": "",
    "text": "install and use pdoc3\npip install pdoc3\npdoc --html [-o &lt;output_dir&gt;] &lt;python_script_or_module_path&gt; # default output directory of \"html\" is `./html`\ninstall and use pandoc, on its homepage we find some slideshow backends like reveal.js, dzslides, s5, slideous and slidy (alternative to microsoft powerpoint, may help rendering video, or let’s use libreoffice instead? or some dedicated video editing library like moviepy)\n# let's convert the html version of\npandoc -o &lt;output_docx_filename&gt; &lt;input_html_path&gt;\nremove unwanted parts from html (beautifulsoup), and split index from main content (split and concat with docxcompose)\nfor composing docx from hand, use python-docx. for template based docx generating, use docxtpl\nto insert page break into converted docx, there are two ways (maybe):\n\nchange css in the original html code\ninsert page break while concatenating"
  },
  {
    "objectID": "posts/4df79ade-d538-4df2-9a6e-7840343648e1/index.html",
    "href": "posts/4df79ade-d538-4df2-9a6e-7840343648e1/index.html",
    "title": "force to use docker mirror instead of pulling from docker.io",
    "section": "",
    "text": "even if you configure /etc/docker/daemon.json like this (note: you still need to do this):\n{ \"registry-mirrors\":\n[\"https://mirror.baidubce.com\"]\n}\nit is not fully working until:\nsudo -E docker pull mirror.baidubce.com/significantgravitas/auto-gpt"
  },
  {
    "objectID": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#计算句子相关度-计算下一句话的可能性-predict-next-sentence-probability",
    "href": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#计算句子相关度-计算下一句话的可能性-predict-next-sentence-probability",
    "title": "mitmchat",
    "section": "计算句子相关度 计算下一句话的可能性 predict next sentence probability",
    "text": "计算句子相关度 计算下一句话的可能性 predict next sentence probability\nbing search entries\nnext sentence prediction using bert\ngithub topic next semtence prediction"
  },
  {
    "objectID": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#grammar-checker-sentence-corrector",
    "href": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#grammar-checker-sentence-corrector",
    "title": "mitmchat",
    "section": "grammar checker, sentence corrector",
    "text": "grammar checker, sentence corrector\nlanguagetool rule based grammar error checker repo"
  },
  {
    "objectID": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#chatterbot-retrain-issue",
    "href": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#chatterbot-retrain-issue",
    "title": "mitmchat",
    "section": "chatterbot retrain issue",
    "text": "chatterbot retrain issue\ntrain chatterbot with the recent knowledge\nsql schema:\n\n\n\nend_of_list\ncontent\n\n\n\n\nfalse\nsome text content\n\n\nfalse\nsome text content\n\n\ntrue\n2022-01-03"
  },
  {
    "objectID": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#additional-notices-about-delivery-efficiency",
    "href": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#additional-notices-about-delivery-efficiency",
    "title": "mitmchat",
    "section": "additional notices, about delivery efficiency",
    "text": "additional notices, about delivery efficiency\n正在刷屏的群里面也不能发消息 不能确保对象是否收到消息\nYukio 12:46:35\n今天mitm有个问题\nYukio 12:46:43\nmitm的两个人\nYukio 12:46:48\n都不能屏蔽我\nYukio 12:46:53\n不然mitm失效\nYukio 12:47:22\n但是我现在不知道这个怎么看别人屏蔽我没有\nYukio 12:47:28\n可能以后就知道了\nYukio 12:49:17\n我可以获取群禁言情况"
  },
  {
    "objectID": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#mitmchat-with-video-and-text-how-to-get-embedding",
    "href": "posts/e5fe3b41-0dcc-4832-9c27-48d99a580d1e/index.html#mitmchat-with-video-and-text-how-to-get-embedding",
    "title": "mitmchat",
    "section": "mitmchat with video and text how to get embedding?",
    "text": "mitmchat with video and text how to get embedding?\nYukio 18:40:25\nmitmchat的定义\nYukio 18:41:31\n在同一个时间段内 把正在讨论相同话题 但是不认识的两个人 互相传话一段时间并断开\nYukio 18:42:28\n多个mitmchat的定义\nYukio 18:43:26\n多个mitm的话 所有被mitm的对象\nYukio 18:43:33\n都不能相互认识\nYukio 18:43:56\n也就是两两不认识 两两不在同一个群里面\nYukio 18:44:40\ndelayed mitmchat\nYukio 18:45:08\n也就是a和b不在同一个时间段内\nYukio 18:45:22\n根据b现在的内容\nYukio 18:45:29\n回复a之前的内容\nYukio 18:47:46\n所有的mitmchat\nYukio 18:47:57\n前提都是a和b互相不认识\nYukio 18:49:01\n也不能是它自己\nYukio 18:55:51\n所以分为两种\nYukio 18:56:00\nYukio 18:56:12\ninstant mitm和delayed mitm\nYukio 18:56:37\ndelayed就是话传不回去\nYukio 18:57:10\n只能传回机器人 机器人没有反馈机制那么就不会像人\nYukio 19:08:40\n像这种图片 怎么个embedding 图片要能做clip才行\nYukio 19:13:06\n起止时间确定\nYukio 19:15:01\n如果不能本地部署clip模型 也得利用图片反向搜索 获得图片的关键词才行\nYukio 19:16:18\n图片反查 然后bm25 textrank\nYukio 19:16:34\n获得是否在讨论相同话题的判断"
  },
  {
    "objectID": "posts/9105af56-d2c8-48c8-9b2d-a9693bf8429a/index.html",
    "href": "posts/9105af56-d2c8-48c8-9b2d-a9693bf8429a/index.html",
    "title": "python diagram/flowchart generator and markdown to word converter",
    "section": "",
    "text": "pyflowchart\ndiagrams needs graphviz installed (on debian it is apt install graphviz). doc\npydiagrams"
  },
  {
    "objectID": "posts/dbfb02c3-0a31-4d5d-bdd5-bc804329021b/index.html",
    "href": "posts/dbfb02c3-0a31-4d5d-bdd5-bc804329021b/index.html",
    "title": "filesystem cache",
    "section": "",
    "text": "catfs in rust\nrclone supports ‘cache’ backend for remote cache"
  },
  {
    "objectID": "posts/dbfb7abd-2e08-4a7d-9672-f8f1623a14fe/index.html",
    "href": "posts/dbfb7abd-2e08-4a7d-9672-f8f1623a14fe/index.html",
    "title": "ffmpeg中英文对照 ffmpeg filter reference translated",
    "section": "",
    "text": "source\n对这位仁兄的博客的基础上根据最新的ffmpeg进行了补充https://www.cnblogs.com/nlsoft/p/5195172.html\nVideo Filters\n视频滤镜\n... addroi            V-&gt;V       Mark a region of interest in a video frame.\n在视频帧中标记感兴趣的一段\n... alphaextract      V-&gt;N       Extract an alpha channel as a grayscale image component.\n从灰度级测视图中提取阿尔法α通道分量.\n... alphamerge        VV-&gt;V      Copy the luma value of the second input into the alpha channel of the first input.\n使用第一个输入视频的阿尔法α通道分量,添加或替换的第二个输入视频亮度值.\n... amplify                       Amplify differences between current pixel and pixels of adjacent frames in same pixel location.\n放大当前像素与同一像素位置相邻帧像素之间的差异\nTS. atadenoise        V-&gt;V       Apply an Adaptive Temporal Averaging Denoiser.\n自适应时间平均降噪功能应用在输入的视频.\n... ass               V-&gt;V       Render ASS subtitles onto input video using the libass library.\n使用libass程序库给输入视频渲染ASS字幕.\n... avgblur           V-&gt;V       Apply average blur filter.\n均匀模糊滤镜\nT.. bbox              V-&gt;V       Compute bounding box for each frame.\n视频的每一个帧上计算边界框.\n... bilateral         V-&gt;V       Apply bilateral filter, spatial smoothing while preserving edges.\n双边滤波，空间平滑同时保留边缘\n... bitplanenoise     V-&gt;V       Show and measure bit plane noise.\n显示和测量位平面噪声。\n... blackdetect       V-&gt;V       Detect video intervals that are (almost) black.\n检测视频中完全(几乎)黑色的时间间隔.\n... blackframe        V-&gt;V       Detect frames that are (almost) black.\n检测完全(几乎)黑色的帧.\nTS. blend             VV-&gt;V      Blend two video frames into each other.\n两个视频帧混合到另一个帧上.\n... bm3d                         Denoise frames using Block-Matching 3D algorithm.\n使用块匹配3D算法去噪帧\nT.. boxblur           V-&gt;V       Blur the input.\n模糊处理输入视频.\n... bwdif                        Deinterlace the input video (\"bwdif\" stands for \"Bob Weaver Deinterlacing Filter\").                         对输入视频进行去隔行处理\n... cas                          Apply Contrast Adaptive Sharpen filter to video stream.\n对视频流添加对比度自适应锐化滤波器。\n... chromahold                   Remove all color information for all colors except for certain one.\n除去除某一颜色外的所有颜色信息。\nTS. chromakey         V-&gt;V       Turns a certain color into transparency. Operates on YUV colors.\n在YUV颜色空间中针对一些颜色做透明处理,应用与抠图功能,比 colorkey 滤镜边界更柔和.\n... chromashift       V-&gt;V       Shift chroma pixels horizontally and/or vertically.\n水平和/或垂直移动色度像素。\n... ciescope          V-&gt;V       Display CIE color diagram with pixels overlaid onto it.\n显示CIE彩色图表\nT.. codecview         V-&gt;V       Visualize information about some codecs.\n导出一些解码器的可视化信息.\nT.. colorbalance      V-&gt;V       Adjust the color balance.\n修改输入帧的三原色(红、绿、蓝)信号亮度.\nT.. colorchannelmixer V-&gt;V       Adjust colors by mixing color channels.\n调整输入视频帧的混合颜色通道.\nTS. colorkey          V-&gt;V       Turns a certain color into transparency. Operates on RGB colors.\n在RGB颜色空间中针对一些颜色做透明处理,边界较为生硬.\n... colorhold         V-&gt;V       Remove all color information for all RGB colors except for certain one.\n删除除特定颜色外的所有RGB颜色的所有颜色信息。\nT.. colorlevels       V-&gt;V       Adjust the color levels.\n调整输入视频帧的颜色信号电平.\nTS. colormatrix       V-&gt;V       Convert color matrix.\n转换颜色矩阵.\n... colorspace        V-&gt;V       Convert colorspace, transfer characteristics or color primaries. Input video needs to have an even size.       转换色彩空间，转移特征或原色。输入视频需要有一个均匀的大小。=\nT.. convolution       V-&gt;V       Apply convolution filter.\n使用卷积3x3或5x5滤镜,适用于锐化,模糊,边缘增强,边缘检测和浮雕等处理.\n... convolve          V-&gt;V       Apply 2D convolution of video stream in frequency domain using second stream as impulse.                          以第二流做为脉冲，在频域内对视频流进行二维卷积。\n... copy              V-&gt;V       Copy the input video unchanged to the output.\n复制输入视频,原封不动输出,主要是用于测试目的.\n... coreimage         V-&gt;V       Video filtering on GPU using Apple’s CoreImage API on OSX.\n使用苹果的CoreImage API在OSX上通过GPU进行视频过滤。\n... cover_rect        V-&gt;V       Find and cover a user specified object.\n查找并覆盖用户指定的矩形对象.\n..C crop              V-&gt;V       Crop the input video to given dimensions.\n剪切输入视频显示区域,并给于新的尺寸.\nT.. cropdetect        V-&gt;V       Auto-detect crop size.\n自动检测剪切大小.\n... cue               V-&gt;V       Delay video filtering until a given wallclock timestamp.\n将视频滤波延迟到指定的时间戳。\nTS. curves            V-&gt;V       Adjust components curves.\n利用曲线功能调整颜色分量,也可以利用图象处理软件的曲线文件来处理颜色.\n... datascope         V-&gt;V       This filter shows hexadecimal pixel values of part of video.\n该滤波器显示部分视频的十六进制像素值。\nTS. dctdnoiz          V-&gt;V       Denoise frames using 2D DCT.\n使用二维频域过滤(2D DCT)对帧进行降噪处理.\nTS. deband            V-&gt;V       Debands video, Remove banding artifacts from input video.\n从输入视频中移除带状伪像.\n... deblock           V-&gt;V       Remove blocking artifacts from input video.\n从输入视频中移除阻塞工件。\n... decimate          N-&gt;V       Decimate frames (post field matching filter).\n定期删除重复的帧(后场匹配滤镜).\n... deconvolve        V-&gt;V       Apply 2D deconvolution of video stream in frequency domain using second stream as impulse.                          以第二流为脉冲，在频域内对视频流进行二维反褶积。\n... dedot             V-&gt;V       Reduce cross-luminance (dot-crawl) and cross-color (rainbows) from video.\n减少交叉亮度(点爬行)和交叉颜色(彩虹)从视频。\nT.. deflate           V-&gt;V       Apply deflate effect.\n适用于紧缩效果.\n... deflicker         V-&gt;V       Remove temporal frame luminance variations.\n删除时间帧亮度变化。\n... dejudder          V-&gt;V       Remove judder produced by pullup.\n删除动作产生的部分颤抖.\nT.. delogo            V-&gt;V       Remove logo from input video.\n对指定区域做模糊处理,比如能移除输入视频中的标识.\n... derain            V-&gt;V       Remove the rain in the input image/video by applying the derain methods based on convolutional neural networks.    采用基于卷积神经网络的去雨方法对输入图像/视频进行去雨处理。\n... deshake           V-&gt;V       Stabilize shaky video.\n试图修改水平或垂直的移位,降低颤抖让视频更稳定,这个滤镜有助于减小手持相机抖动影响.\n... despill           V-&gt;V       Remove unwanted contamination of foreground colors, caused by reflected color of greenscreen or bluescreen.        清除前景色中由绿幕或蓝幕的反射色所引起的不必要的污染。\n... detelecine        V-&gt;V       Apply an inverse telecine pattern.\n适用于电视电影的精确反向操作,颜色边界有锯齿效果.\nT.. dilation          V-&gt;V       Apply dilation effect.\n膨胀效果应用于视频.\nT.. displace          VVV-&gt;V     Displace pixels.\n移走像素,需要三个视频输入流和一个视频输出流,第一个输入源,第二和第三个输入位移的映射.\n... dnn_processing    V-&gt;V       Do image processing with deep neural networks.\n使用深度神经网络进行图像处理。它与另一个过滤器一起工作，将帧的像素格式转换成dnn网络所需的格式。\nT.. drawbox           V-&gt;V       Draw a colored box on the input video.\n输入视频图像上绘制彩色的矩形区域.\n... drawgraph         V-&gt;V       Draw a graph using input video metadata.\n利用输入视频的元数据绘制图表.\nT.. drawgrid          V-&gt;V       Draw a colored grid on the input video.\n在输入视频上绘制彩色网格.\nT.C drawtext          V-&gt;V       Draw text on top of video frames using libfreetype library.\n使用 libfreetype 程序库,在顶层帧上绘制文本字符串,文本内容可从指定文件中读取.\nT.. edgedetect        V-&gt;V       Detect and draw edge.\n检测并绘制边缘.\n... elbg              V-&gt;V       Apply posterize effect, using the ELBG algorithm.\n使用增强型LBG(ELBG)算法,用于多色调分色印效果.\n... entropy           V-&gt;V       Measure graylevel entropy in histogram of color channels of video frames.\n测量视频帧颜色通道直方图中的灰度熵。\n..C eq                V-&gt;V       Adjust brightness, contrast, gamma, and saturation.\n调整亮度、对比度、灰度和饱和度.\nT.. erosion           V-&gt;V       Apply erosion effect.\n侵蚀效果应用于视频,类似油画处理.\n... extractplanes     V-&gt;N       Extract planes as grayscale frames.\n从输入视频流中提取颜色通道分量用在单独灰度视频流的帧上.\n.S. fade              V-&gt;V       Fade in/out input video.\n适用于输入视频的淡入/淡出效果.\n... fftdnoiz          V-&gt;V       Denoise frames using 3D FFT (frequency domain filtering).\n使用3D FFT(频域滤波)去噪帧。\n... fftfilt           V-&gt;V       Apply arbitrary expressions to pixels in frequency domain.\n频域内将任意表达式用于采样的像素集.\n... field             V-&gt;V       Extract a field from the input video.\n使用步进算法,从输入视频里的隔行图像中提取单场.\n... fieldhint         V-&gt;V       Create new frames by copying the top and bottom fields from surrounding frames supplied as numbers by the hint file. 通过拷贝由提示文件作为数字提供的周围帧的顶部和底部字段来创建新的帧。\n... fieldmatch        N-&gt;V       Field matching for inverse telecine.\n场匹配滤镜适用于电视电影的反向操作.\nT.. fieldorder        V-&gt;V       Set the field order.\n改变输入视频的场顺序.\n... fifo,afifo        V-&gt;V       Buffer input images and send them when they are requested.\n缓冲输入的图像并在需要时发送它们\n... fillborders       V-&gt;V       Fill borders of the input video, without changing video stream dimensions.\n填充输入视频的边框，不改变视频流的大小。\n... find_rect         V-&gt;V       Find a user specified object.\n寻找用户指定的矩形区域.\n... floodfill         V-&gt;V       Flood area with values of same pixel components with another values.\n... format            V-&gt;V       Convert the input video to one of the specified pixel formats.\n输入视频转换为指定的像素格式.\n... fps               V-&gt;V       Force constant framerate.\n强制设定固定帧频.\n... framepack         VV-&gt;V      Generate a frame packed stereoscopic video.\n生成帧叠加的立体视频.\n... framerate         V-&gt;V       Upsamples or downsamples progressive source between specified frame rates.\n上采样或下采样顺序渐进的视频源之间设定指定帧频.\nT.. framestep         V-&gt;V       Select one frame every N frames.\n每 N 个帧中选一个帧,设置帧步.\n... freezedetect      V-&gt;V       Detect frozen video\n检测不变帧\n... freezeframes      V-&gt;V       Freeze video frames\n冻结视频帧\n... frei0r            V-&gt;V       Apply a frei0r effect.\n使用 frei0r 滤镜.\nT.. fspp              V-&gt;V       Apply Fast Simple Post-processing filter.\n用于快速和简单的后处理滤镜.\n... gblur             V-&gt;V       Apply Gaussian blur filter\n应用高斯模糊滤镜\nT.. geq               V-&gt;V       Apply generic equation to each pixel.\n利用一般表达式改变每个像素点的特征.\nT.. gradfun           V-&gt;V       Debands video quickly using gradients.\n利用梯度快速移除带状伪像.\n... graphmonitor      V-&gt;V       Show various filtergraph stats\n监视各种图表的统计信息\n... greyedge          V-&gt;V       A color constancy variation filter which estimates scene illumination via grey edge algorithm and corrects the scene colors accordingly.\n利用灰度边缘算法估计场景光照的颜色恒常性变异滤波器，并对场景颜色进行相应的校正。\nTS. haldclut          VV-&gt;V      Adjust colors using a Hald CLUT.\n利用哈尔德查色表调整颜色.\n.S. hflip             V-&gt;V       Horizontally flip the input video.\n水平翻转显示输入视频.\nT.. histeq            V-&gt;V       Apply global color histogram equalization.\n适用于全局颜色直方图均衡化.\n... histogram         V-&gt;V       Compute and draw a histogram.\n计算并绘制颜色分布直方图.\nT.. hqdn3d            V-&gt;V       Apply a High Quality 3D Denoiser.\n使用高质量三维降噪滤镜.\n... hwmap             V-&gt;V       Map hardware frames to system memory or to another\ndevice.                           将帧映射到系统内存或者另一个设备\n... hwupload          V-&gt;V       Upload system memory frames to hardware surfaces.\n将内存中的帧上传至硬件接口\n... hwupdoad_cuda     V-&gt;V       Upload system memory frames to a CUDA device.\n将内存中的帧上传至CUDA设备\n.S. hqx               V-&gt;V       Scale the input by 2, 3 or 4 using the hq*x magnification algorithm.          利用高质量放大算法缩放视频显示大小,可输入2,3或4.\n... hstack            N-&gt;V       Stack video inputs horizontally.\n把若干个输入视频合并到一个水平显示的输出视频.\nT.C hue               V-&gt;V       Adjust the hue and saturation of the input video.\n调整输入视频的色相和饱和度.\n... hysteresis        V-&gt;V       Grow first stream into second stream by connecting components.                       这个不太理解\n... idet              V-&gt;V       Interlace detect Filter.\n检测视频的交叉类型滤镜.\nT.. il                V-&gt;V       Deinterleave or interleave fields.\n允许处理不交叉的隔行图像场.\nT.. inflate           V-&gt;V       Apply inflate effect.\n膨胀效果用于视频.\n... interlace         V-&gt;V       Convert progressive video into interlaced.\n转化为分段视频用于隔行处理,颜色边界有锯齿效果.\n... interleave        N-&gt;V       Temporally interleave video inputs.\n能执行时间场交叉的各种类型.\n... kerndeint         V-&gt;V       Apply kernel deinterlacing to the input.\n对输入的视频进行内核反交叉处理.\n... lagfun            V-&gt;V       Slowly update darker pixels.\n缓慢更新黑色像素，滤镜使短暂的闪光显得更长\n.S. lenscorrection    V-&gt;V       Rectify the image by correcting for lens distortion.\n矫正图像用于校正透镜畸变.\n... lensfun           V-&gt;V       Apply lens correction via the lensfun library\n通过lensfun库应用镜头校正\n... libvmaf           V-&gt;V       Obtain the VMAF (Video Multi-Method Assessment Fusion) score between two input videos.   得到两个输入视频之间的(VMAF 多方法评估视频相融合)分数。\n... limiter           V-&gt;V       Limits the pixel components values to the specified range [min, max].                 将像素分量的值限制在指定的范围内\n... loop              V-&gt;V       Loop video frames.\n循环视频帧\n... lut1d             V-&gt;V       Apply a 1D LUT to an input video.\n利用已维查色表调整颜色.\nTS. lut3d             V-&gt;V       Adjust colors using a 3D LUT.\n利用三维查色表调整颜色.\n... lumakey           V-&gt;V       Turn certain luma values into transparency.\n将某些亮度值转化为透明度\nT.. lut               V-&gt;V       Compute and apply a lookup table to the RGB/YUV input video.\n利用查表计算处理 RGB/YUV 格式输入的视频.\nT.. lutrgb            V-&gt;V       Compute and apply a lookup table to the RGB input video.\n利用查表计算处理 RGB 格式输入的视频.\nT.. lutyuv            V-&gt;V       Compute and apply a lookup table to the YUV input video.\n利用查表计算处理 YUV 格式输入的视频.\n... maskedclamp       VV-&gt;V      Clamp the first input stream with the second input and third input stream.               用第二输入流和第三输入流固定第一输入流\nT.. maskedmerge       VVV-&gt;V     Merge first stream with second stream using third stream as mask.                   合并前二个输入视频,掩模到第三个输入视频,透明合并三个视频.\n... maskfun           V-&gt;V       Create mask from input video.\n... mcdeint           V-&gt;V       Apply motion compensating deinterlacing.\n适用于运动补偿反交叉.\n... median            V-&gt;V       Pick median pixel from certain rectangle defined by radius.                           从某个由半径定义的矩形中选择中值像素\n... mergeplanes       N-&gt;V       Merge planes.\n合并多个视频流的颜色通道分量.\n... mestimate         V-&gt;V       Estimate and export motion vectors using block matching algorithms                        使用块匹配算法估计和导出运动矢量\nT.. metadata          V-&gt;V       Manipulate video frame metadata.\n操作视频帧的元数据,用于调试.\n... midequalizer                 Apply Midway Image Equalization effect using two video streams.                          用两个视频流应用中间图像均衡效果。\n... miniterpolate     V-&gt;V       Convert the video to specified frame rate using motion interpolation.                    使用运动插值将视频转换为指定的帧率。\n... mix               VVV-&gt;V     Mix several video input streams into one video stream.\n将多个视频输入流混合到一个视频流中。\n... mpdecimate        V-&gt;V       Remove near-duplicate frames.\n移除近似重复的帧.\nT.. negate            V-&gt;V       Negate input video.\n取消输入视频的阿尔法通道分量,滤镜效果类似底片.\n... nlmeans           V-&gt;V       Denoise frames using Non-Local Means algorithm.\n使用非局部均值算法对帧进行去噪。\nT.. nnedi             V-&gt;V       Apply neural network edge directed interpolation intra-only deinterlacer.\n使用神经网络边缘插值法进行反隔行处理,需要加权重的二进制文件.\n... noformat          V-&gt;V       Force libavfilter not to use any of the specified pixel formats for the input to the next filter.\n取消指定的像素格式,用于下一个滤镜.\nTS. noise             V-&gt;V       Add noise.\n视频输入帧上添加噪声.\n... null              V-&gt;V       Pass the source unchanged to the output.\n不改变视频源进行输出.\n... ocv               V-&gt;V       Apply a video transform using libopencv.\n使用libopencv应用视频转换\n... oscilloscope      V-&gt;V       2D Video Oscilloscope.\n2D视频示波器。\nT.C overlay           VV-&gt;V      Overlay a video source on top of the input.\n把一个视频覆盖到另一个视频上面,需要两个输入和一个输出.\nT.. owdenoise         V-&gt;V       Denoise using wavelets.\n利用小波降噪法进行降噪处理.\n... pad               V-&gt;V       Pad the input video.\n给输入视频添加填充新的显示区域.\n... palettegen        V-&gt;V       Find the optimal palette for a given stream.\n生成最佳调色板,用于给定的视频流.\n... paletteuse        VV-&gt;V      Use a palette to downsample an input video stream.\n下采样输入视频流中使用调色板,适用于生成 GIF 动态图.\n... perms             V-&gt;V       Set permissions for the output video frame.\n给输出视频帧设置读/写权限.\nTS. perspective       V-&gt;V       Correct the perspective of video.\n校正视频的透视.\nT.. phase             V-&gt;V       Phase shift fields.\n对隔行视频延迟单场时间,便于场序的变化.\n... photosensitivity  V-&gt;V       Reduce various flashes in video, so to help users with epilepsy.                         减少视频中各种闪烁，\n... pixdesctest       V-&gt;V       Test pixel format definitions.\n像素格式描述符测试滤镜,主要用于内部测试.\n... pixscope          V-&gt;V       Display sample values of color channels. Mainly useful for checking color and levels.    显示颜色通道的采样值。主要用于检查颜色和水平。\nT.C pp                V-&gt;V       Filter video using libpostproc.\n使用 libpostproc 后处理程序库进行过滤.\nT.. pp7               V-&gt;V       Apply Postprocessing 7 filter.\n使用后处理滤镜7.\n... psnr              VV-&gt;V      Calculate the PSNR between two video streams.\n计算两个视频流之间的峰值信噪比(PSNR).\n... pullup            V-&gt;V       Pullup from field sequence to frames.\n折叠场序用于输出帧,退回到电视电影效果.\nT.. qp                V-&gt;V       Change video quantization parameters.\n改变视频量化参数(QP).\n... random            V-&gt;V       Return random frames.\n从内部缓存刷新出视频帧的随机帧.\n... realtime          V-&gt;V       Slow down filtering to match realtime.\n减慢过滤速度,接近实时效果.\nTS. removegrain       V-&gt;V       Remove grain.\n移除纹理,对步进视频进行降噪处理.\nT.. removelogo        V-&gt;V       Remove a TV logo based on a mask image.\n利用掩模图像移除电视徽标,掩模图像的大小必须与视频相同,黑色是透明.\n... repeatfields      V-&gt;V       Hard repeat fields based on MPEG repeat field flag.\n根据运动图象专家组(MPEG)重复场标志,硬执行重复场.\n... reverse           V-&gt;V       Reverse a clip.\n倒放一段视频片段,需要把整个片段装入内存缓冲区.\n... rgbashift         V-&gt;V       Shift R/G/B/A pixels horizontally and/or vertically.\n水平或垂直移动R/G/B/A像素。\nTSC rotate            V-&gt;V       Rotate the input image.\n任意角度旋转视频,用弧度表示的单位.\nT.. sab               V-&gt;V       Apply shape adaptive blur.\n形状自适应模糊滤镜.\n..C scale             V-&gt;V       Scale the input video size and/or convert the image format.\n缩放输入视频的尺寸并/或改变图像格式,使用libswscale库.\n... scale_npp         V-&gt;V       Use the NVIDIA Performance Primitives (libnpp) to perform scaling and/or pixel format conversion on CUDA video frames.\n使用NVIDIA Performance Primitives (libnpp)在CUDA视频帧上执行缩放和/或像素格式转换。\n..C scale2ref         VV-&gt;VV     Scale the input video size and/or convert the image format to the given reference.\n缩放输入视频的尺寸并/或改变图像格式用于引用视频,使用libswscale库.\n... scroll                       Scroll input video horizontally and/or vertically by constant speed.                    以恒定的速度垂直或者水平滚动输入视频\n... select            V-&gt;N       Select video frames to pass in output.\n选择视频帧用于下一个滤镜.\nTS. selectivecolor    V-&gt;V       Apply CMYK adjustments to specific color ranges.\n利用青色,品红色,黄色和黑色(CMYK)调整特定范围的颜色.\n... sendcmd           V-&gt;V       Send commands to filters.\n给滤镜发送命令,必须插入到两个视频之间,只对具有该功能的滤镜命令有效.\n... separatefields    V-&gt;V       Split input video frames into fields.\n分解输入视频帧进场,产生一个新的一半高度剪辑帧.\n... setdar            V-&gt;V       Set the frame display aspect ratio.\n设置视频的显示纵横比.\n... setfield          V-&gt;V       Force field for the output video frame.\n改变输出视频帧的属性,不改变视频帧的数据.\n... setpts            V-&gt;V       Set PTS for the output video frame.\n设置输出视频帧的显示时间戳(PTS),可以用于快放或慢放等.\n... setsar            V-&gt;V       Set the pixel sample aspect ratio.\n设置像素采样纵横比.\n... settb             V-&gt;V       Set timebase for the video output link.\n设置时间轴用于视频输出帧的时间戳,主要用于测试时间轴配置.\n... showinfo          V-&gt;V       Show textual information for each video frame.\n显示每个视频帧的文本信息.\nT.. showpalette       V-&gt;V       Display frame palette.\n显示每一帧的 256 色调色板.\nT.. shuffleframes     V-&gt;V       Shuffle video frames.\n打乱视频帧,重新排序和/或重复视频帧.\n... shuffleplanes     V-&gt;V       Shuffle video planes.\n打乱视频映射平面,重新排序和/或重复视频映射平面.\n.S. signalstats       V-&gt;V       Generate statistics from video analysis.\n分析视频过程中生成统计信息.\nT.. smartblur         V-&gt;V       Blur the input video without impacting the outlines.\n模糊处理输入视频而不影响轮廓.\n... split             V-&gt;N       Pass on the input to N video outputs.\n输入的视频分配给N个相同的视频输出.\nT.C spp               V-&gt;V       Apply a simple post processing filter.\n简单的后处理滤镜,设置压缩品质对视频进行压缩.\n... ssim              VV-&gt;V      Calculate the SSIM between two video streams.\n计算两个输入视频之间的结构相似度(SSIM).\n.S. stereo3d          V-&gt;V       Convert video stereoscopic 3D view.\n视频转换成具有不同立体图像格式的三维视觉视频.\n..C streamselect      N-&gt;N       Select video streams\n多个输入视频流中选择一个视频流,若干个具有相同时间长度的媒体有效.\n... subtitles         V-&gt;V       Render text subtitles onto input video using the libass library.\n使用 libass 程序库输入视频上绘制字幕.\n... super2xsai        V-&gt;V       Scale the input by 2x using the Super2xSaI pixel art algorithm.\n利用像素艺术扩展算法把输入视频平滑放大两倍.\nT.. swaprect          V-&gt;V       Swap 2 rectangular objects in video.\n视频流中交换两个矩形对象.\n... swapuv            V-&gt;V       Swap U and V components.\n交换 U 和 V 映射平面分量.\n.S. tblend            V-&gt;V       Blend successive frames.\n两个视频帧混合到另一个帧上.\n... telecine          V-&gt;V       Apply a telecine pattern.\n使用电视电影模式,颜色边界有锯齿效果.\n... thistogram        V-&gt;V       Compute and draw a color distribution histogram for the input video across time.          不仅可以显示当前的，还可以显示过去的，对比histogram\n... thumbnail         V-&gt;V       Select the most representative frame in a given sequence of consecutive frames.\n在给定的连续帧序列中选择具有代表性帧.\n... tile              V-&gt;V       Tile several successive frames together.\n瓦状布局若干个连续的帧,类似视频缩略图.\n... tinterlace        V-&gt;V       Perform temporal field interlacing.\n使用不同的隔行模式处理每一个帧.\n.S. transpose         V-&gt;V       Transpose input video.\n翻转输入视频,默认垂直翻转.\n... trim              V-&gt;V       Pick one continuous section from the input, drop the rest.\n从输入视频中挑选连续的组成部分,一直到结束.\nT.. unsharp           V-&gt;V       Sharpen or blur the input video.\n锐化或模糊处理输入视频.\nT.. uspp              V-&gt;V       Apply Ultra Simple / Slow Post-processing filter.\n超慢/简单的后处理滤镜,设置压缩品质对视频进行压缩.\n... vectorscope       V-&gt;V       Video vectorscope.\n显示输入视频的两个颜色分量值的二维图(矢量显示).\n... vflip             V-&gt;V       Flip the input video vertically.\n垂直翻转显示输入视频.\n... vidstabdetect     V-&gt;V       Extract relative transformations,for stabilization.\n提取视频的相对地变化,绘制矩形图矩阵内的箭头方向来显示变化趋势.\n... vidstabtransform  V-&gt;V       Video stabilization/deshaking.\n平滑/反锐化处理视频.\nT.. vignette          V-&gt;V       Make or reverse a vignette effect.\n生成或扭转镜头自然渐晕效果.\n... vstack            N-&gt;V       Stack video inputs vertically.\n把若干个输入视频垂直放置,所有视频的像素格式和宽度必须相同.\nTS. w3fdif            V-&gt;V       Apply Martin Weston three field deinterlace.\n使用马丁韦斯顿三场反隔行滤镜。\n... waveform          V-&gt;V       Video waveform monitor.\n视频波形监视器.\n.S. xbr               V-&gt;V       Scale the input using xBR algorithm.\n应用xBR算法放大输入视频,默认是放大三倍.\nTS. yadif             V-&gt;V       Deinterlace the input image.\n对输入图像进行反隔行处理.\nT.. zoompan           V-&gt;V       Apply Zoom & Pan effect.\n用于缩放和填充效果.\n..C zscale            V-&gt;V       Apply resizing, colorspace and bit depth conversion.\n用于重新调整大小,改变色隙和色彩深度.\n... allrgb            |-&gt;V       Generate all RGB colors.\n生成大小为 4096x4096 的包含所有 RGB 颜色表,需要大量内存.\n... allyuv            |-&gt;V       Generate all yuv colors.\n生成大小为 4096x4096 的包含所有 yuv 颜色表,需要大量内存.\n... cellauto          |-&gt;V       Create pattern generated by an elementary cellular automaton.\n利用初级多孔自动生成器创建一个图案,指定模式生成无数小三角形矩阵.\n..C color             |-&gt;V       Provide an uniformly colored input.\n提供了一个单色输入视频源.\n... frei0r_src        |-&gt;V       Generate a frei0r source.\n提供frei0r接口,frei0r是ffmpeg的子滤镜.\n... haldclutsrc       |-&gt;V       Provide an identity Hald CLUT.\n给哈尔德查色表源提供单位特征.\n... life              |-&gt;V       Create life.\n生成随机花纹的图案.\n... mandelbrot        |-&gt;V       Render a Mandelbrot fractal.\n生成一个曼德尔勃特集合分形,逐渐放大到指定点.\n... mptestsrc         |-&gt;V       Generate various test pattern.\n生成各种测试图案,静/动态小方块矩阵和圆形图案.\n... nullsrc           |-&gt;V       Null video source, return unprocessed video frames.\n生成空视频源,返回未处理的空视频帧.\n... rgbtestsrc        |-&gt;V       Generate RGB test pattern.\n生成 RGB 测试图案,横向红绿蓝三条图案.\n... smptebars         |-&gt;V       Generate SMPTE color bars.\n生成 SMPTE 颜色条图案,像电视测试信号视频.\n... smptehdbars       |-&gt;V       Generate SMPTE HD color bars.\n生成 SMPTE HD 颜色条图案.\n... testsrc           |-&gt;V       Generate test pattern.\n生成测试图案.\n... testsrc2          |-&gt;V       Generate another test pattern.\n生成另一个测试图案.\n... nullsink          V-&gt;|       Do absolutely nothing with the input video.\n生成空视频模板,与输入视频无关.\n... concat            N-&gt;N       Concatenate audio and video streams.\n连接音频和视频流.\n... movie             |-&gt;N       Read from a movie source.\n从视频源读入视频.\n... buffer            |-&gt;V       Buffer video frames, and make them accessible to the filterchain.\n缓冲视频帧,并用于滤镜链.\n... buffersink        V-&gt;|       Buffer video frames, and make them available to the end of the filter graph.\n缓冲视频帧,并用于滤镜图的结束.\n... fifo              V-&gt;V       Buffer input images and send them when they are requested.\n缓冲输入帧,若需要时."
  },
  {
    "objectID": "posts/d299ccd2-0d77-4c1c-837d-43186ec641a7/index.html#speed-up-ffmpeg-encoding",
    "href": "posts/d299ccd2-0d77-4c1c-837d-43186ec641a7/index.html#speed-up-ffmpeg-encoding",
    "title": "Exploring FFmpeg’s Advanced Encoding, Conversion, and Audio Functionality",
    "section": "speed up ffmpeg encoding",
    "text": "speed up ffmpeg encoding\nffmpeg speedup cli flags\nffmpeg -threads 4 -crf 28 -preset ultrafast"
  },
  {
    "objectID": "posts/a2943ff1-11b5-4747-a3c3-e60289b58111/index.html",
    "href": "posts/a2943ff1-11b5-4747-a3c3-e60289b58111/index.html",
    "title": "fastapi, celery, task queue, websocket",
    "section": "",
    "text": "enable render option trim_blocks and lstrip_blocks with jinja2 to avoid whitespace and indentation nightmare.\n\nalways remember to import uvicorn if you want to run without the uvicorn executable\n\ngenerate nodejs client from openapi.json\nfastapi-code-generator to generate python code\n\ncreate doc inside code: adding metadata\n\nto share lock across process, use redis lock or filelock.\nto share lock across forked process in the same worker, use multiprocessing.Lock()\n\nfastapi can generate openapi json and doc page\nwebsockets are async. will it block the server?\nusing websocket in fastapi\ncelery advance usage\ncelery and fastapi\nhappen to found akismet (proprietary wordpress spam protection). oss alternatives are:\n\nYoutube Spammer Purge\nforget spam comment (js plugin for wordpress)"
  },
  {
    "objectID": "posts/1a302f7a-16bb-4627-a871-e1744bf92f04/index.html",
    "href": "posts/1a302f7a-16bb-4627-a871-e1744bf92f04/index.html",
    "title": "Mastering System Events: Script Execution with @reboot and systemd",
    "section": "",
    "text": "execute script before & after system events like startup, suspend & shutdown\nfor startup use @reboot with crontab -e\nfor others, write scripts under /lib/systemd/system-*"
  },
  {
    "objectID": "posts/174f7e21-1db4-4ddb-b009-9c025323a08a/index.html",
    "href": "posts/174f7e21-1db4-4ddb-b009-9c025323a08a/index.html",
    "title": "elo rating system",
    "section": "",
    "text": "Elo rating system is a method for calculating the relative skill levels of players in two-player games such as chess. It is named after its creator Arpad Elo, a Hungarian-American physics professor.\nThe basic idea behind the Elo rating system is that each player is assigned a rating, and the difference between the ratings of two players determines the expected outcome of a match between them. If a higher-rated player wins, their rating will increase, while the rating of the lower-rated player will decrease. If the lower-rated player wins, the opposite will happen. The amount of change in the ratings depends on the difference between the ratings and the result of the match.\nHere is an example of how the Elo rating system can be implemented in Python:\ndef elo_rating(rating1, rating2, k, result):\n# Calculate the expected score for each player\nexpect1 = 1 / (1 + 10 ** ((rating2 - rating1) / 400))\nexpect2 = 1 / (1 + 10 ** ((rating1 - rating2) / 400))\n# Calculate the new ratings for each player\nif result == 1:\n# Player 1 wins\nrating1 = rating1 + k * (1 - expect1)\nrating2 = rating2 + k * (0 - expect2)\nelif result == 0:\n# Player 2 wins\nrating1 = rating1 + k * (0 - expect1)\nrating2 = rating2 + k * (1 - expect2)\nreturn rating1, rating2\nThis function takes four arguments:\nrating1: The current rating of player 1.\nrating2: The current rating of player 2.\nk: The “k-factor”, which determines the amount of change in the ratings. A higher k-factor means more change.\nresult: The result of the match, where 1 indicates a win for player 1 and 0 indicates a win for player 2.\nThe function returns a tuple containing the updated ratings for both players."
  },
  {
    "objectID": "posts/faa6ec57-ec17-4350-a736-790110c76d78/index.html",
    "href": "posts/faa6ec57-ec17-4350-a736-790110c76d78/index.html",
    "title": "douyin tiktok social media download",
    "section": "",
    "text": "Douyin/Tiktok Social Media Video Download\nvideo download:\nhttps://github.com/Evil0ctal/Douyin_TikTok_Download_API\nhttps://github.com/Johnserf-Seed/TikTokDownload\nhttps://github.com/rouze-d/tiktok-download\nhttps://github.com/CuriousYoda/tiktok-downloader\nvideo api and deduplication:\nhttps://github.com/VideoData/DY-Data\nmany scrapers:\nhttps://github.com/Jack-Cherish/python-spider\nvideo multi download tool:\nhttps://github.com/smalls0098/video-parse-tools\ntiktok scrapers:\nhttps://github.com/drawrowfly/tiktok-scraper\ntiktok api:\nhttps://dteather.com/TikTok-Api/docs/TikTokApi/tiktok.html\nhttps://github.com/davidteather/TikTokBot"
  },
  {
    "objectID": "posts/63eeaf5e-73d1-4bed-b5a6-320ac4a831a0/index.html#textdiffuser",
    "href": "posts/63eeaf5e-73d1-4bed-b5a6-320ac4a831a0/index.html#textdiffuser",
    "title": "disco diffusion and ai art",
    "section": "textdiffuser",
    "text": "textdiffuser\nComfyUI: A powerful and modular stable diffusion GUI.\n\ncivitai is a place for sharing stable diffusion models like anything v5 and surreality and ai arts.\n\nnow you can use controlnet to enhance the generation, give the figure skeleton. huggingface introduction\nkarlo: dalle2 replicate, karlo huggingface space, text to image (can be used for semantic search)\ndalle2-laion\nDiT diffusion with transformer\ncustom diffusion rlhf?\nscribble-diffusion turn sketch into drawings\nstable diffusion on macos\nvideo generation ebsynth\n字体普遍画的很拉 需要用专门的ocr强化训练字体\nfontdiffusion?\nfont-diffusion\nstable diffusion font generating\nfontdesign gan\nhandwrite\ndeep fonts\ndiffusionbee stable diffusion for macos m1\nQQ搜索 异次元的我 免费画画 AI合成 (seems this can only be opened within qq, currently)\nnovel-ai-bot\nhttps://huggingface.co/hakurei/waifu-diffusion，这个ai是可以本地部署的，电脑配置可以的朋友们试试\nnovelai 有泄露的模型\nimagen\ndreambooth\ndalle-mini, with space hosted on huggingface\n中文版DALL-E is not open sourced (yet). it provides api for evaluation\nimport numpy as np\nimport gradio as gr\nimport paddlehub as hub\n\n\nmodel = hub.Module(name='ernie_vilg')\nlanguage_translation_model = hub.Module(name='baidu_translate')\nlanguage_recognition_model = hub.Module(name='baidu_language_recognition')\n\nstyle_list = ['水彩','油画', '粉笔画', '卡通', '蜡笔画', '儿童画', '探索无限']\n\ntips = {\"en\": \"Tips: The input text will be translated into Chinese for generation\", \n        \"jp\": \"ヒント: 入力テキストは生成のために中国語に翻訳されます\", \n        \"kor\": \"힌트: 입력 텍스트는 생성을 위해 중국어로 번역됩니다\"}\n\ncount = 0\n\ndef translate_language(text_prompts):\n    global count\n    try:\n        count += 1\n        tips_text = None\n        language_code = language_recognition_model.recognize(text_prompts)\n        if language_code != 'zh':\n            text_prompts = language_translation_model.translate(text_prompts, language_code, 'zh')\n    except Exception as e:\n        error_text = str(e)\n        return {status_text:error_text, language_tips_text:gr.update(visible=False)}\n    if language_code in tips:\n        tips_text = tips[language_code]\n    else:\n        tips_text = tips['en']\n    if language_code == 'zh':\n        return {language_tips_text:gr.update(visible=False), translated_language:text_prompts, trigger_component: gr.update(value=count, visible=False)}\n    else:\n        return {language_tips_text:gr.update(visible=True, value=tips_text), translated_language:text_prompts, trigger_component:  gr.update(value=count, visible=False)}\n\n        \ndef inference(text_prompts, style_indx):\n  try:\n    style = style_list[style_indx]\n    results = model.generate_image(\n        text_prompts=text_prompts, style=style, visualization=False)\n  except Exception as e:\n    error_text = str(e)\n    return {status_text:error_text, gallery:None}\n  return {status_text:'Success', gallery:results[:6]}\n\n\ntitle=\"ERNIE-ViLG\"\n\ndescription=\"ERNIE-ViLG model, which supports text-to-image task.\"\n\ncss = \"\"\"\n        .gradio-container {\n            font-family: 'IBM Plex Sans', sans-serif;\n        }\n        .gr-button {\n            color: white;\n            border-color: black;\n            background: black;\n        }\n        input[type='range'] {\n            accent-color: black;\n        }\n        .dark input[type='range'] {\n            accent-color: #dfdfdf;\n        }\n        .container {\n            max-width: 730px;\n            margin: auto;\n            padding-top: 1.5rem;\n        }\n        #gallery {\n            min-height: 22rem;\n            margin-bottom: 15px;\n            margin-left: auto;\n            margin-right: auto;\n            border-bottom-right-radius: .5rem !important;\n            border-bottom-left-radius: .5rem !important;\n        }\n        #gallery&gt;div&gt;.h-full {\n            min-height: 20rem;\n        }\n        .details:hover {\n            text-decoration: underline;\n        }\n        .gr-button {\n            white-space: nowrap;\n        }\n        .gr-button:focus {\n            border-color: rgb(147 197 253 / var(--tw-border-opacity));\n            outline: none;\n            box-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);\n            --tw-border-opacity: 1;\n            --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);\n            --tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px var(--tw-ring-offset-width)) var(--tw-ring-color);\n            --tw-ring-color: rgb(191 219 254 / var(--tw-ring-opacity));\n            --tw-ring-opacity: .5;\n        }\n        .footer {\n            margin-bottom: 45px;\n            margin-top: 35px;\n            text-align: center;\n            border-bottom: 1px solid #e5e5e5;\n        }\n        .footer&gt;p {\n            font-size: .8rem;\n            display: inline-block;\n            padding: 0 10px;\n            transform: translateY(10px);\n            background: white;\n        }\n        .dark .footer {\n            border-color: #303030;\n        }\n        .dark .footer&gt;p {\n            background: #0b0f19;\n        }\n        .prompt h4{\n            margin: 1.25em 0 .25em 0;\n            font-weight: bold;\n            font-size: 115%;\n        }\n\"\"\"\n\nblock = gr.Blocks(css=css)\n\nexamples = [\n    [\n        '戴着眼镜的猫',\n        '油画(Oil painting)'\n    ],\n    [\n        'A cat with glasses',\n        '油画(Oil painting)'\n    ],\n    [\n        '眼鏡をかけた猫',\n        '油画(Oil painting)'\n    ],\n    [\n        '안경을 쓴 고양이',\n        '油画(Oil painting)'\n    ],\n    [\n        '日落时的城市天际线,史前遗迹风格',\n        '油画(Oil painting)'\n    ],\n    [\n        '一只猫坐在椅子上，戴着一副墨镜, low poly 风格',\n        '卡通(Cartoon)'\n    ],\n    [\n        'A cat sitting on a chair, wearing a pair of sunglasses, low poly style',\n        '油画(Oil painting)'\n    ],\n    [\n        '猫が椅子に座ってサングラスをかけている、low polyスタイル',\n        '油画(Oil painting)'\n    ],\n    [\n        '고양이 한 마리가 의자에 앉아 선글라스를 끼고 low poly 스타일을 하고 있다',\n        '油画(Oil painting)'\n    ],\n    [\n        '一只猫坐在椅子上，戴着一副墨镜,秋天风格',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '蒙娜丽莎，赛博朋克，宝丽来，33毫米,蒸汽波艺术',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '一只猫坐在椅子上，戴着一副墨镜,海盗风格',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '一条由闪电制成的令人敬畏的龙,概念艺术',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        'An awesome dragon made of lightning, conceptual art',\n        '油画(Oil painting)'\n    ],\n    [\n        '稲妻で作られた畏敬の念を抱かせる竜、コンセプトアート',\n        '油画(Oil painting)'\n    ],\n    [\n        '번개로 만든 경외스러운 용, 개념 예술',\n        '油画(Oil painting)'\n    ],\n    [\n        '梵高猫头鹰,蒸汽波艺术',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '萨尔瓦多·达利描绘古代文明的超现实主义梦幻油画,写实风格',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '夕阳日落时，阳光落在云层上，海面波涛汹涌，风景，胶片感',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        'Sunset, the sun falls on the clouds, the sea is rough, the scenery is filmy',\n        '油画(Oil painting)'\n    ],\n    [\n        '夕日が沈むと、雲の上に太陽の光が落ち、海面は波が荒く、風景、フィルム感',\n        '油画(Oil painting)'\n    ],\n    [\n        '석양이 질 때 햇빛이 구름 위에 떨어지고, 해수면의 파도가 용솟음치며, 풍경, 필름감',\n        '油画(Oil painting)'\n    ],\n]\n\nwith block:\n    gr.HTML(\n        \"\"\"\n            &lt;div style=\"text-align: center; max-width: 650px; margin: 0 auto;\"&gt;\n              &lt;div\n                style=\"\n                  display: inline-flex;\n                  gap: 0.8rem;\n                  font-size: 1.75rem;\n                  margin-bottom: 10px;\n                  margin-left: 220px;\n                  justify-content: center;\n                \"\n              &gt;\n              &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/187387422-f6c9ccab-7fda-416e-a24d-7d6084c46f67.jpg\" alt=\"Paddlehub\" width=\"40%\"&gt;&lt;/a&gt;\n              &lt;/div&gt; \n              &lt;div\n                style=\"\n                  display: inline-flex;\n                  align-items: center;\n                  gap: 0.8rem;\n                  font-size: 1.75rem;\n                  margin-bottom: 10px;\n                  justify-content: center;\n                \"&gt;\n              &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;h1 style=\"font-weight: 900; margin-bottom: 7px;\"&gt;\n                  ERNIE-ViLG Demo\n              &lt;/h1&gt;&lt;/a&gt;\n              &lt;/div&gt; \n              &lt;p style=\"margin-bottom: 10px; font-size: 94%\"&gt;\n                ERNIE-ViLG is a state-of-the-art text-to-image model that generates\n                images from Chinese text.\n              &lt;/p&gt;\n              &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/188184795-98605a22-9af2-4106-827b-e58548f8892f.png\" alt=\"star Paddlehub\" width=\"100%\"&gt;&lt;/a&gt;\n            &lt;/div&gt;\n        \"\"\"\n    )\n    with gr.Group():\n        with gr.Box():\n            with gr.Row().style(mobile_collapse=False, equal_height=True):\n                text = gr.Textbox(\n                    label=\"Prompt\",\n                    show_label=False,\n                    max_lines=1,\n                    placeholder=\"Enter your prompt, multiple languages are supported now.\",\n                ).style(\n                    border=(True, False, True, True),\n                    rounded=(True, False, False, True),\n                    container=False,\n                )\n\n                btn = gr.Button(\"Generate image\").style(\n                    margin=False,\n                    rounded=(False, True, True, False),\n                )\n        language_tips_text = gr.Textbox(label=\"language tips\", show_label=False, visible=False, max_lines=1)\n        styles = gr.Dropdown(label=\"风格(style)\", choices=['水彩(Watercolor)','油画(Oil painting)', '粉笔画(Chalk drawing)', '卡通(Cartoon)', '蜡笔画(Crayon drawing)', '儿童画(Children\\'s drawing)', '探索无限(Explore infinity)'], value='探索无限(Explore infinity)', type=\"index\")\n        gallery = gr.Gallery(\n            label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n        ).style(grid=[2, 3], height=\"auto\")\n        status_text = gr.Textbox(\n            label=\"处理状态(Process status)\",\n            show_label=True,\n            max_lines=1,\n            interactive=False\n        )\n        trigger_component = gr.Textbox(vaule=\"\", visible=False) # This component is used for triggering inference funtion.\n        translated_language = gr.Textbox(vaule=\"\", visible=False)\n        \n        ex = gr.Examples(examples=examples, fn=translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language], cache_examples=False)\n        ex.dataset.headers = [\"\"]\n\n        \n        text.submit(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\n        btn.click(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\n        trigger_component.change(fn=inference, inputs=[translated_language, styles], outputs=[status_text, gallery])\n        gr.HTML(\n            \"\"\"\n                &lt;div class=\"prompt\"&gt;\n                    &lt;p&gt;&lt;h4&gt;Prompt公式&lt;/h4&gt;\n                    &lt;span&gt; Prompt = [形容词] [主语] ，[细节设定]， [修饰语或者艺术家]。 &lt;/span&gt;\n                    关于各部分的构造方式和效果，可以参考&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe指南&lt;/a&gt;。\n                    更多的模型，请关注&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub 官方Repo &lt;/a&gt;， 如果你觉得不错，请star收藏吧。\n                    &lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\n                    同时，可以在 &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; 上使用免费的GPU体验更多案例。\n                    &lt;/p&gt;   \n               &lt;/div&gt;\n               &lt;div class=\"prompt\"&gt;\n                    &lt;p&gt;&lt;h4&gt;Prompt format&lt;/h4&gt;\n                    &lt;span&gt; Prompt = [adjective] [object], [details], [styles or artists]. &lt;/span&gt;\n                    For more details, please refer to &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe Guide&lt;/a&gt;.\n                    There are more interesting models in PaddleHub, if you think it's great, welcome to star &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub&lt;/a&gt;.\n                    &lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\n                    Besides, you can use free GPU resourses in &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; to enjoy more cases, have fun. \n                    &lt;/p&gt;   \n               &lt;/div&gt;\n                \n           \"\"\"\n        )\n        gr.Markdown(\n            \"\"\"\n在\"探索无限\"的风格模式下，画作的真实风格完全可以由你的prompt来决定。下面是一些参考案例:\n\nIn \"Explore infinity\" style mode, how the image looks like is totally up to your prompt. Below are some cases:\n\n### 复古未来主义风格\n\n| ![00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格.jpg) | ![00472_000_日落时的城市天际线,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_日落时的城市天际线,复古未来主义风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格              | 日落时的城市天际线,复古未来主义风格                          |\n\n\n\n### 粉彩朋克风格\n\n| ![00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格.jpg) | ![00029_001_日落时的城市天际线，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00029_001_日落时的城市天际线，粉彩朋克风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,粉彩朋克风格                  | 日落时的城市天际线,粉彩朋克风格                              |\n\n### 史前遗迹风格\n\n| ![00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格.jpg) | ![00443_005_日落时的城市天际线,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_日落时的城市天际线,史前遗迹风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格                  | 日落时的城市天际线,史前遗迹风格                              |\n\n\n\n\n### 波普艺术风格\n\n| ![00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格.jpg) | ![00434_002_日落时的城市天际线,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_002_日落时的城市天际线,波普艺术风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,波普艺术风格                  | 日落时的城市天际线,后世界末日风格                            |\n\n\n\n### 迷幻风格\n\n| ![00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格.jpg) | ![00451_001_日落时的城市天际线,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_001_日落时的城市天际线,迷幻药风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,迷幻风格                      | 日落时的城市天际线,迷幻风格                                  |\n\n### &lt;u&gt;[更多内容...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南)([Explore more...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南))&lt;/u&gt;\n\n\n            \"\"\"\n        )\n        gr.HTML('''\n        &lt;div class=\"footer\"&gt;\n                    &lt;p&gt;Model by &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;PaddleHub&lt;/a&gt; and &lt;a href=\"https://wenxin.baidu.com\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;文心大模型&lt;/a&gt; - Gradio Demo by 🤗 Hugging Face\n                    &lt;/p&gt;\n        &lt;/div&gt;\n        ''')\n\nblock.queue(concurrency_count=128).launch()\ntext to image minimal example\nhttps://github.com/jina-ai/discoart\ndalle-2\nstable diffusion as dalle2 alternative\nnvidia provided ai paint tool\ntext to image: https://github.com/lucidrains/imagen-pytorch"
  },
  {
    "objectID": "posts/ad1e6f73-c43f-4c35-bf4f-97376e326ee8/index.html",
    "href": "posts/ad1e6f73-c43f-4c35-bf4f-97376e326ee8/index.html",
    "title": "sync notes between multiple platforms/devices",
    "section": "",
    "text": "make webhooks or make git get latest HEAD hash every interval and compare"
  },
  {
    "objectID": "posts/cd86ac3b-43f1-46a0-8c96-1b1f54479637/index.html",
    "href": "posts/cd86ac3b-43f1-46a0-8c96-1b1f54479637/index.html",
    "title": "ddddocr captcha resolve recognition",
    "section": "",
    "text": "i use rotnet for baidu rotnet captcha resolve. did it work?\nddddocr\ntutorial"
  },
  {
    "objectID": "posts/0916757b-b466-47ca-8c59-56b09566ebb5/index.html",
    "href": "posts/0916757b-b466-47ca-8c59-56b09566ebb5/index.html",
    "title": "dash api docset reference search",
    "section": "",
    "text": "on non-macos platforms, use zeal instead.\nthe core problem is that after uninstallation of xcode, one cannot launch the Apple Doc Helper or some binary afterwards inside the Apple docset under dash documentation folder. the docset can be copied to this folder automatically by dash but without xcode it cannot be opened."
  },
  {
    "objectID": "posts/e82fa063-872b-4101-af10-56c87188b58f/index.html",
    "href": "posts/e82fa063-872b-4101-af10-56c87188b58f/index.html",
    "title": "dark reader pdf dark theme",
    "section": "",
    "text": "in order to make pdf dark theme more natural, you can search for “PDF” in dark reader’s source code and inject custom style sheets."
  },
  {
    "objectID": "posts/2bd6d111-77e8-4a04-83bf-8eabda26e391/index.html",
    "href": "posts/2bd6d111-77e8-4a04-83bf-8eabda26e391/index.html",
    "title": "use javascript/html/css to create mobile app, simplifying the processing of creating app",
    "section": "",
    "text": "Apache Cordova is an open-source mobile development framework\nre-com A ClojureScript library of reusable components for Reagent"
  },
  {
    "objectID": "posts/d0719db5-bbdc-45c3-8236-14bc2e28500a/index.html#alternatives",
    "href": "posts/d0719db5-bbdc-45c3-8236-14bc2e28500a/index.html#alternatives",
    "title": "conda and its alternatives",
    "section": "alternatives",
    "text": "alternatives\nminiconda\nminiforge, better apple m1 support\nmamba, multithreaded"
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#search-commands-on-commandline",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#search-commands-on-commandline",
    "title": "commandline search engine bridger",
    "section": "search commands on commandline",
    "text": "search commands on commandline\nman -k &lt;keywords&gt;\napt search &lt;keywords&gt;\nbrew search &lt;keywords&gt;\nnpm search &lt;keywords&gt;\nsearchsploit &lt;keywords&gt;\nmsfconsole -x \"search &lt;keywords&gt;; exit\""
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#nosqlnosqlite-key-value-json-like-document-store-databases-sqlite-high-level-wrappers",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#nosqlnosqlite-key-value-json-like-document-store-databases-sqlite-high-level-wrappers",
    "title": "commandline search engine bridger",
    "section": "nosql/nosqlite key-value json like document store databases, sqlite high level wrappers",
    "text": "nosql/nosqlite key-value json like document store databases, sqlite high level wrappers\nthis guy makes database related libraries.\n\nlsm-db fast key-value store using sqlite 4\nunqlite Python bindings for the UnQLite embedded NoSQL database\ntinydb json-oriented, mongo alike database, which is a in-memory database\nlitedb NoSQL Python database written for ease of use/performance.\npylite sqlite3 lightweight wrapper"
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#reason-to-develop-this",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#reason-to-develop-this",
    "title": "commandline search engine bridger",
    "section": "reason to develop this",
    "text": "reason to develop this\nyou are short of brain power. short of time to perspect and investigate.\nmany platforms now have recommendation engines, but they do not have powerful semantic search tools. what a pity. maybe i am interested in some ‘unseen’ stuff, but i want to get the thing that i currently need! fail to do so will limit my productivity."
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#sentence-embeddings",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#sentence-embeddings",
    "title": "commandline search engine bridger",
    "section": "sentence embeddings",
    "text": "sentence embeddings\ndifference between ‘symmetric’ and ‘asymmetric’ retrieval questions from sbert.net:\nsymmetric means similar, asymmetric usually means question to answer.\ntop 4 sentence embedding techniques using python\nsentence to vector\ntutorial: sentence vector word2vec\nsentence2vec based on word2vec"
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#similarity-search-and-clustering",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#similarity-search-and-clustering",
    "title": "commandline search engine bridger",
    "section": "similarity search and clustering",
    "text": "similarity search and clustering\nfacebook faiss\nhnswlib Header-only C++/python library for fast approximate nearest neighbors\nspotify annoy Approximate Nearest Neighbors in C++/Python optimized for memory usage and loading/saving to disk"
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#problems",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#problems",
    "title": "commandline search engine bridger",
    "section": "problems",
    "text": "problems\n\nenable copy/pasting/selection in console\nmake reversible/auto-cleanup feature when copy and pasting\nreverse stemming and keywords highlighting\nmemory efficient embedding querying/storage via sql or binary format\n\ntxtai store to sqlite: Build an Embeddings index from a data source\n\nmake “complete” excerpt by looking ahead and backward to find the closest sentence start/stop and/or use gpt completion method instead? still need punctual or sentence start/stop index identification."
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#offline",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#offline",
    "title": "commandline search engine bridger",
    "section": "offline",
    "text": "offline\n\nterminal interface builder\nrich and tutorial\ntextual\nurwid\nplie\n\n\nai assisted search engine libraries\njina-ai and docarray\ntxtai\ntypesense\nzinc search\nfuzzy search\nfuzzy phonic toolkit\n\n\ntraditional search engine libraries\nluceneplusplus lucene in c++\npythonql as extension of python syntax, able to search data in python data structure.\njq and pyjq as json search engine, jqterm as jq repl\nfq jq for binary formats\na curated search engine list\nscout sqlite based full text search\nwhoosh with bm25 support\npython-searchengine and the tutorial"
  },
  {
    "objectID": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#online",
    "href": "posts/56b80ff6-3271-4f98-90cd-37635cbbb223/index.html#online",
    "title": "commandline search engine bridger",
    "section": "online",
    "text": "online\nsurfraw, or just s, is for some common parameter prefixes for searching on common websites. will open GUI browser or cli browser if configured with one.\nsurfraw supported:\nW               -- Activate Surfraw defined web-browser\nacronym         -- Look for acronyms definitions (www.acronymfinder.com)\nads             -- Search SAO/NASA Astrophysics Data System\nalioth          -- Search Alioth (alioth.debian.org)\namazon          -- Search the amazon.com bookstore\narchpkg         -- Search Arch Linux Packages (www.archlinux.org/packages/)\narchwiki        -- Search the Arch Linux Wiki\narxiv           -- Search arXiv E-Print Archive for articles\nask             -- Question the web using Ask Jeeves (www.ask.com)\naur             -- Search aur.archlinux.org for PKGBUILDs\naustlii         -- Search Australian Law docs (www.austlii.edu.au)\nbbcnews         -- Search BBC News (news.bbc.co.uk)\nbing            -- Search the web using Microsoft's Bing (www.bing.com)\nbookfinder      -- Search for books using www.bookfinder.com\nbugmenot        -- Bypass compulsory web registration with bugmenot.com\nbugzilla        -- Search for bugs on Bugzilla bugtrackers\ncablesearch     -- search for leaked diplomatic communications\ncia             -- Search CIA documents at www.cia.gov\ncisco           -- Search Cisco documentation (www.cisco.com)\ncite            -- Search computer science papers (citeseerx.ist.psu.edu)\ncliki           -- Search the common lisp wiki\ncnn             -- Search on CNN (cnn.com)\ncomlaw          -- Search Australian Law using Comlaw (www.comlaw.gov.au)\ncommandlinefu   -- Search on www.commandlinefu.com\nctan            -- Search the Comprehensive TeX Archive Network (ctan.org)\ncurrency        -- Convert currencies with the Universal Currency Converter (www.xe.net/ucc)\ncve             -- Search for CAN assignments in CVE\ndebbugs         -- Search the debian BTS (bugs.debian.org)\ndebcodesearch   -- Search debian source code\ndebcontents     -- Search contents of debian/ubuntu packages (packages.debian.org/packages.ubuntu.com)\ndeblists        -- Search debian mailing lists (lists.debian.org/search.html)\ndeblogs         -- Show changelogs for a package in Debian main (changelogs.debian.net)\ndebpackages     -- Search debian/ubuntu packages (packages.debian.org/packages.ubuntu.com)\ndebpkghome      -- Visit the home page for a Debian package\ndebpts          -- Search the Debian Package Tracking System (packages.qa.debian.org)\ndebsec          -- Search the Debian Security Tracker for CVE ids or package names\ndebvcsbrowse    -- Browse the VCS repository for a Debian package\ndebwiki         -- Search the Debian Wikis (wiki.debian.org & women.debian.org/wiki)\ndeja            -- Search usenet using Google Groups (groups.google.com)\ndeli            -- Search Delicious bookmarks\ndiscogs         -- Search the Discogs database of music information (www.discogs.com)\ndmoz            -- Search the Open Directory Project web directory (dmoz.org)\nduckduckgo      -- Securely search the web using duckduckgo (www.duckduckgo.com)\nebay            -- Search the Ebay auction site\netym            -- Look up word origins at www.etymonline.com\nexcite          -- Search on Excite (www.excite.com)\nf5              -- Search F5 related information (www.f5.com)\nfinkpkg         -- Search Fink packages (pdb.finkproject.org)\nfoldoc          -- The Free On-Line Dictionary Of Computing (foldoc.org)\nfreebsd         -- Search FreeBSD related information (www.freebsd.org)\nfreedb          -- Search for cd track listings in FreeDB (www.freedb.org)\nfreshmeat       -- Search Freshmeat (www.freshmeat.net)\nfsfdir          -- Search the FSF/UNESCO Free Software Directory (directory.fsf.org)\ngcache          -- Search the web using Google cache (www.google.com)\ngenbugs         -- Search the Gentoo bug tracker (bugs.gentoo.org)\ngenportage      -- Search gentoo-portage.com for packages\ngithub          -- Search GitHub (https://github.com)\ngmane           -- Search mailing list with gmane (gmane.org)\ngoogle          -- Search the web using Google (www.google.com)\ngutenberg       -- Search for books on Project Gutenberg (gutenberg.org)\nimdb            -- Search the Internet Movie Database (www.imdb.com)\nixquick         -- Search the web using ixquick [HTTPS] (www.ixquick.com)\njamendo         -- Search Jamendo: free music with Creative Commons licenses (www.jamendo.com)\njavasun         -- Search Java API docs (java.sun.com)\njquery          -- Search the jQuery documentation (api.jquery.com)\nl1sp            -- Search lisp documentation\nlastfm          -- Search last.fm\nleodict         -- Search Leo's German &lt;-&gt; English dictionary (dict.leo.org)\nlsm             -- Search the Linux Software Map\nmacports        -- Search macports packages (macports.org)\nmathworld       -- Search Wolfram MathWorld\nmdn             -- Search the mozilla developer network (developer.mozilla.org)\nmininova        -- Search the mininova bittorent source.\nmusicbrainz     -- Search MusicBrainz (musicbrainz.org)\nmysqldoc        -- Search mysql documentation (dev.mysql.com)\nnetbsd          -- Search NetBSD related information (www.netbsd.org)\nnlab            -- Search the nLab wiki (http://ncatlab.org)\nntrs            -- Search the NASA Technical Report Server\nopenbsd         -- Search OpenBSD related information (www.openbsd.org)\nopenports       -- search openports for OpenBSD packages\nopensearch      -- Search an OpenSearch-enabled website\noraclesearch    -- Search an OpenSearch-enabled website\npasearch        -- Search the unofficial Penny Arcade archives (pipefour.org/pa)\npgdoc           -- Search postgres documentation (www.pgdoc.com)\npgpkeys         -- Search the PGP key database\nphpdoc          -- Search php documentation (php.net)\npin             -- Search Pinboard bookmarks (http://pinboard.in)\npiratebay       -- Search The Pirate Bay (http://thepiratebay.org)\npriberam        -- Look up word in Priberam online dictionary (www.priberam.pt/dlpo)\npubmed          -- Search medical/molbio databases (www.ncbi.nlm.nih.gov)\nrae             -- Busca en el diccionario de la Real Academia de la Lengua Española (Spanish Dictionary)\nrfc             -- Search RFCs (internet standards documents)\nrhyme           -- Search for rhymes et al using Lycos Rhyme (rhyme.lycos.com)\nrpmsearch       -- Search for RPMs in various distros\nscholar         -- Search Google Scholar (scholar.google.com)\nscicom          -- Search Scientific Commons\nscirus          -- Search for science using Scirus (scirus.com)\nscpan           -- Search the Comprehensive Perl Archive Network (search.cpan.org)\nsearx           -- Search using searx metasearch engine instances (searx.me)\nslashdot        -- Search stories on Slashdot (www.slashdot.org)\nslinuxdoc       -- Search entries in LDP (www.linuxdoc.org)\nsourceforge     -- Search SourceForge (www.sourceforge.net)\nspringer        -- Search Springer for Books and Articles\nstack           -- Search Stack Overflow\nstockquote      -- Get a single stock quote (multiple providers)\nthesaurus       -- Look up word in Merriam-Webster's Thesaurus (www.m-w.com)\ntranslate       -- Translate human languages\nurban           -- Search urbandictionary.com for a definition\nw3css           -- Validate a CSS URL with the w3c CSS validator (jigsaw.w3.org/css-validator)\nw3html          -- Validate a web page URL with the w3c validator (validator.w3.org)\nw3link          -- Check web page links with the w3c linkchecker (validator.w3.org/checklink)\nw3rdf           -- Validate a RDF URL with the w3c RDF validator (validator.w3.org)\nwayback         -- Search The Internet Archive's Wayback Machine for a URL (archive.org)\nwebster         -- Look up word in Merriam-Webster's Dictionary (www.m-w.com)\nwetandwild      -- Real time weather information (many sources)\nwikipedia       -- Search the free encyclopedia wikipedia\nwoffle          -- Search the web using Woffle (localhost:8080)\nwolfram         -- Ask questions of the computational knowledge engine\nworldwidescience -- Search for science with www.worldwidescience.org\nyacy            -- Search YaCy P2P search, including ScienceNet\nyahoo           -- Search Yahoo categories (www.yahoo.com)\nyandex          -- Search the web using Yandex (yandex.ru)\nyoutube         -- Search YouTube (www.youtube.com)\nyubnub          -- Use the social command-line for the web (yubnub.org)\n\nS supported:\n500px\n8tracks\naliexpress\nallocine\namazon\narchpkg\narchwiki\nardmediathek\narstechnica\narxiv\natmospherejs\naur\nbaidu\nbandcamp\nbgr\nbigbasket\nbing\nbrave\nbuzzfeed\ncnn\ncodepen\ncoursera\ncplusplus\ncppreference\ncrates\ncrunchyroll\ndebianpkg\ndict\ndigg\ndiigo\ndockerhub\ndribbble\nduckduckgo\ndumpert\necosia\nengadget\nexplainshell\nfacebook\nflickr\nflipkart\nfoursquare\nfreebsdman\nfreshports\ngibiru\ngiphy\ngist\ngithub\ngmail\ngo\ngodoc\ngoodreads\ngoogle\ngoogledocs\ngoogleplus\nhackernews\nidealo\nietf\nifttt\nimdb\nimgur\ninbox\ninstagram\nkaufda\nkickasstorrents\nlibgen\nlinkedin\nlmgtfy\nmacports\nmagnetdl\nmdn\nmedium\nmetacpan\nmsdn\nnaver\nnetflix\nnhaccuatui\nnpm\nnpmsearch\nnpr\nnvd\nopenbsdman\noverstock\npackagist\npresearch\nphandroid\nphp\npinterest\npostgresql\npython\nquora\nqwant\nreddit\nregex\nrottentomatoes\nrubygems\nshodan\nsoundcloud\nspotify\nstackoverflow\nsteam\ntaobao\nthepiratebay\ntheregister\ntorrentz\ntwitchtv\ntwitter\nultimateguitar\nunity3d\nupcloud\nvimeo\nwikipedia\nwolframalpha\nyahoo\nyandex\nyoutube\nzdf\nzhihu"
  },
  {
    "objectID": "posts/bc193727-3bc6-4586-9f67-d0570983b8ca/index.html",
    "href": "posts/bc193727-3bc6-4586-9f67-d0570983b8ca/index.html",
    "title": "color transfer between images, histogram based style transfer",
    "section": "",
    "text": "图像调色风格转换 可以创建蹦迪特效 让视频或者图片五彩斑斓\ncolor transfer between images\npip install color_transfer\nofficial scikit-learn histogram matching\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage import exposure\nfrom skimage.exposure import match_histograms\nreference = data.coffee()\nimage = data.chelsea()\nmatched = match_histograms(image, reference, channel_axis=-1)\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\nsharex=True, sharey=True)\nfor aa in (ax1, ax2, ax3):\naa.set_axis_off()\nax1.imshow(image)\nax1.set_title('Source')\nax2.imshow(reference)\nax2.set_title('Reference')\nax3.imshow(matched)\nax3.set_title('Matched')\nplt.tight_layout()\nplt.show()\nhistogram matching"
  },
  {
    "objectID": "posts/29d14ee7-b14b-466f-8454-a24a77cdf39b/index.html",
    "href": "posts/29d14ee7-b14b-466f-8454-a24a77cdf39b/index.html",
    "title": "AGI playground, a place for AGI to act/code freely",
    "section": "",
    "text": "search for “artificial general intelligence” in github and hit many results.\nsome article says deep neural networks are t2 level, human are t3 level (connected dnns) and to train a t3 level intel you need t4 level intel (like the earth, or a group of t3 intels, you can’t be 1-to-1 now, you must be forgiving). this proves my provision of putting agi into gui or human interfaces.\nto train a t2 level intel, you need t3 intel, such as yourself or your users.\nyou must setup this playground then you begin to learn stuff and libraries of AGI. but once you have one, don’t move around, stick to it! you need time to develop the general adaptor and make clear and achievable goals!\nterminal, GUI, program, API, network\nplease check my previous efforts on building AGI, namely: AGI, lazero, metalazero\nnsjail with docker\nfirejail"
  },
  {
    "objectID": "posts/8bdeb129-7e94-4bae-ae75-f6cb9d2de94e/index.html",
    "href": "posts/8bdeb129-7e94-4bae-ae75-f6cb9d2de94e/index.html",
    "title": "chemical shit, cheminformatics",
    "section": "",
    "text": "chemical shit, cheminformatics"
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-create-a-natural-language-generator",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-create-a-natural-language-generator",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to create a natural language generator",
    "text": "use pyro to create a natural language generator\nPyro is a probabilistic programming language built on top of PyTorch, which can be used for creating probabilistic models and conducting Bayesian inference. One way you can use Pyro to create a natural language generator is by defining a probabilistic model of the language generation process, and using Monte Carlo sampling or variational inference to generate text.\nHere is a basic example of how you might do this using Pyro:\nimport torch\nimport pyro\nimport pyro.distributions as dist\n# Define the vocabulary and size of the language model\nvocab = [\"&lt;START&gt;\", \"the\", \"cat\", \"sat\", \"on\", \"mat\", \"&lt;END&gt;\"]\nvocab_size = len(vocab)\n# Define a simple language model that generates text one word at a time\ndef language_model(prefix):\n# Initialize the hidden state with a uniform distribution\nhidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size))\n# Initialize the output sequence with the start token\noutput_sequence = [vocab.index(\"&lt;START&gt;\")]\n# Iterate over the prefix and append each word to the output sequence\nfor word in prefix:\noutput_sequence.append(vocab.index(word))\n# Generate the rest of the sequence one word at a time\nwhile output_sequence[-1] != vocab.index(\"&lt;END&gt;\"):\n# Use the hidden state to generate a distribution over the next word\nnext_word_dist = pyro.sample(\"next_word\", dist.Categorical(hidden_state))\n# Append the next word to the output sequence\noutput_sequence.append(next_word_dist)\n# Update the hidden state using the next word\nhidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size), obs=next_word_dist)\n# Convert the output sequence to a list of words\nreturn [vocab[i] for i in output_sequence]\n# Generate text using the language model\ngenerated_text = language_model(prefix=[\"the\", \"cat\"])\nprint(generated_text)\nThis example defines a simple language model that generates text one word at a time, using a hidden state to produce a distribution over the next word in the sequence. The model starts by initializing the hidden state with a uniform distribution, and then iteratively generates words until it reaches the end token. You can use Monte Carlo sampling or variational inference to generate text from this model by calling pyro.sample on the model and specifying the desired number of samples.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-create-a-natural-language-generator-with-loss-function-like-adam",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-create-a-natural-language-generator-with-loss-function-like-adam",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to create a natural language generator, with loss function like adam",
    "text": "use pyro to create a natural language generator, with loss function like adam\nTo use Pyro to create a natural language generator with a loss function like Adam, you will need to define a probabilistic model that takes in some input data and generates text, and then define a loss function that compares the generated text to some target text. You can then use an optimization algorithm like Adam to minimize the loss function and optimize the parameters of your model.\nHere is an example of how you might do this using Pyro:\nimport torch\nimport pyro\nimport pyro.distributions as dist\nfrom pyro.optim import Adam\n# Define the vocabulary and size of the language model\nvocab = [\"&lt;START&gt;\", \"the\", \"cat\", \"sat\", \"on\", \"mat\", \"&lt;END&gt;\"]\nvocab_size = len(vocab)\n# Define a simple language model that generates text one word at a time\ndef language_model(prefix):\n# Initialize the hidden state with a uniform distribution\nhidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size))\n# Initialize the output sequence with the start token\noutput_sequence = [vocab.index(\"&lt;START&gt;\")]\n# Iterate over the prefix and append each word to the output sequence\nfor word in prefix:\noutput_sequence.append(vocab.index(word))\n# Generate the rest of the sequence one word at a time\nwhile output_sequence[-1] != vocab.index(\"&lt;END&gt;\"):\n# Use the hidden state to generate a distribution over the next word\nnext_word_dist = pyro.sample(\"next_word\", dist.Categorical(hidden_state))\n# Append the next word to the output sequence\noutput_sequence.append(next_word_dist)\n# Update the hidden state using the next word\nhidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size), obs=next_word_dist)\n# Convert the output sequence to a list of words\nreturn [vocab[i] for i in output_sequence]\n# Define a loss function that compares the generated text to some target text\ndef loss_fn(generated_text, target_text):\n# Compute the cross-entropy loss between the generated text and the target text\nreturn -torch.sum(torch.tensor([vocab.index(word) for word in target_text]) * torch.log(torch.tensor([vocab.index(word) for word in generated_text])))\n# Optimize the parameters of the language model using Adam\noptimizer = Adam({\"lr\": 0.001})\n# Set the number of training iterations\nnum_iterations = 1000\n# Use Pyro's SVI to optimize the parameters of the language model\nfor i in range(num_iterations):\n# Clear the gradient\noptimizer.zero_grad()\n# Generate some text using the language model\ngenerated_text = language_model(prefix=[\"the\", \"cat\"])\n# Compute the loss\nloss = loss_fn(generated_text, target_text)\n# Compute the gradients\nloss.backward()\n# Update the parameters\noptimizer.step()\n# Generate text using the optimized language model\ngenerated_text = language_model(prefix=[\"the\", \"cat\"])\nprint(generated_text)\nThis code uses Pyro’s Stochastic Variational Inference (SVI) to optimize the parameters of the language model using the Adam optimizer. The model is trained by generating text using the current parameters of the model, computing the loss between the generated text and the target text, and then updating the parameters based on the gradients of the loss with respect to the model parameters.\nAfter training, you can use the optimized language model to generate text by calling language_model with the desired prefix as input.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-generate-natural-language-using-advanced-models",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-generate-natural-language-using-advanced-models",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to generate natural language using advanced models",
    "text": "use pyro to generate natural language using advanced models\nThere are several advanced probabilistic models that you can use with Pyro to generate natural language. Some examples include:\nRecurrent neural network (RNN) language models: These models use an RNN to process the input sequence and generate a probability distribution over the next word in the sequence. You can use Pyro to define an RNN language model by using the pyro.nn module to define the RNN and the pyro.distributions module to define the distribution over the next word.\nTransformer language models: These models use a transformer architecture to process the input sequence and generate a probability distribution over the next word in the sequence. You can use Pyro to define a transformer language model by using the pyro.nn module to define the transformer and the pyro.distributions module to define the distribution over the next word.\nVariational autoencoder (VAE) language models: These models use a VAE to learn a latent representation of the input sequence, and then use the latent representation to generate a probability distribution over the next word in the sequence. You can use Pyro to define a VAE language model by using the pyro.nn module to define the VAE and the pyro.distributions module to define the distribution over the next word.\nTo use any of these models with Pyro, you will need to define a probabilistic model that takes in some input data and generates text, and then use Monte Carlo sampling or variational inference to generate text from the model. You can also define a loss function and use an optimization algorithm like Adam to optimize the parameters of the model.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#determine-topic-among-a-large-group-of-entities-with-labels-with-pyro",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#determine-topic-among-a-large-group-of-entities-with-labels-with-pyro",
    "title": "chatgpt on pyro and pytorch",
    "section": "determine topic among a large group of entities with labels with pyro",
    "text": "determine topic among a large group of entities with labels with pyro\nTo determine the topic among a large group of entities with labels using Pyro, you can use a technique called topic modeling. Pyro is a probabilistic programming language that allows you to build and perform inference on probabilistic models.\nOne way to perform topic modeling using Pyro is to use a probabilistic graphical model called a Latent Dirichlet Allocation (LDA) model. In an LDA model, you can specify the number of topics and the number of words in each topic, and the model will learn the distribution of words that are likely to belong to each topic.\nTo implement an LDA model in Pyro, you will first need to define the model and the priors for the parameters. This can be done using the pyro.sample() function, which allows you to specify the probability distribution for the parameters. You can then use the pyro.infer.MCMC() function to perform Markov Chain Monte Carlo (MCMC) inference on the model, which will allow you to estimate the posterior distribution of the model parameters.\nOnce you have trained the model, you can use it to classify a new document by using the pyro.predict() function and passing in the document’s words as input. The model will return the probability that the document belongs to each of the specified topics.\nFor more detailed information on how to implement topic modeling using Pyro, you can refer to the Pyro documentation or tutorials online."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#how-to-determine-watermark-location-and-remove-watermark-at-location-with-several-screenshots-in-a-video-with-pytorch",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#how-to-determine-watermark-location-and-remove-watermark-at-location-with-several-screenshots-in-a-video-with-pytorch",
    "title": "chatgpt on pyro and pytorch",
    "section": "how to determine watermark location and remove watermark at location with several screenshots in a video with pytorch",
    "text": "how to determine watermark location and remove watermark at location with several screenshots in a video with pytorch\nTo determine the location of a watermark in a video with multiple screenshots and remove the watermark using PyTorch, you can use a technique called image inpainting. Image inpainting is a process of filling in missing or damaged pixels in an image or video to restore it to its original form.\nOne way to perform image inpainting using PyTorch is to use a convolutional neural network (CNN) to learn the structure and patterns in the image or video. You can train the CNN to predict the missing or damaged pixels based on the surrounding pixels.\nTo implement image inpainting using PyTorch, you will need to first prepare a dataset of images or video frames with and without the watermark. You can then use this dataset to train the CNN using the PyTorch API. You can use the PyTorch optimizers and loss functions to optimize the network and improve its performance.\nOnce the CNN is trained, you can use it to predict the missing or damaged pixels in a new image or video frame with a watermark. You can then remove the watermark by replacing the predicted pixels with the original pixels from the image or video frame without the watermark.\nFor more detailed information on how to implement image inpainting using PyTorch, you can refer to the PyTorch documentation or tutorials online."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#how-to-determine-watermark-location-in-a-series-of-screenshots-in-video-with-pytorch",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#how-to-determine-watermark-location-in-a-series-of-screenshots-in-video-with-pytorch",
    "title": "chatgpt on pyro and pytorch",
    "section": "how to determine watermark location in a series of screenshots in video with pytorch",
    "text": "how to determine watermark location in a series of screenshots in video with pytorch\nTo determine the location of a watermark in a series of screenshots in a video using PyTorch, you can use a technique called object detection. Object detection is a process of identifying and localizing objects in an image or video.\nOne way to perform object detection using PyTorch is to use a convolutional neural network (CNN) to learn the features and patterns in the image or video. You can train the CNN to predict the presence and location of objects in the image or video.\nTo implement object detection using PyTorch, you will need to first prepare a dataset of images or video frames with and without the watermark. You can then use this dataset to train the CNN using the PyTorch API. You can use the PyTorch optimizers and loss functions to optimize the network and improve its performance.\nOnce the CNN is trained, you can use it to detect the presence and location of the watermark in a new image or video frame. You can then use the predicted bounding box coordinates to determine the location of the watermark in the image or video frame.\nFor more detailed information on how to implement object detection using PyTorch, you can refer to the PyTorch documentation or tutorials online."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#the-data-is-a-series-of-images-not-a-single-image",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#the-data-is-a-series-of-images-not-a-single-image",
    "title": "chatgpt on pyro and pytorch",
    "section": "the data is a series of images, not a single image",
    "text": "the data is a series of images, not a single image\nIf you have a series of images and you want to determine the location of a watermark in each of the images using PyTorch, you can use a technique called object detection. Object detection is a process of identifying and localizing objects in an image or video.\nOne way to perform object detection using PyTorch is to use a convolutional neural network (CNN) to learn the features and patterns in the images. You can train the CNN to predict the presence and location of objects in the images.\nTo implement object detection using PyTorch, you will need to first prepare a dataset of images with and without the watermark. You can then use this dataset to train the CNN using the PyTorch API. You can use the PyTorch optimizers and loss functions to optimize the network and improve its performance.\nOnce the CNN is trained, you can use it to detect the presence and location of the watermark in each of the images in the series. You can then use the predicted bounding box coordinates to determine the location of the watermark in each image.\nFor more detailed information on how to implement object detection using PyTorch, you can refer to the PyTorch documentation or tutorials online."
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#how-to-put-a-series-of-image-into-a-single-cnn-show-me-the-code",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#how-to-put-a-series-of-image-into-a-single-cnn-show-me-the-code",
    "title": "chatgpt on pyro and pytorch",
    "section": "how to put a series of image into a single CNN, show me the code",
    "text": "how to put a series of image into a single CNN, show me the code\nTo put a series of images into a single CNN using PyTorch, you can use the PyTorch Dataset and DataLoader classes. These classes allow you to create a custom dataset and load the data in small batches for training or inference.\nHere is an example of how you can create a custom dataset for a series of images and use it with a CNN in PyTorch:\nimport os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nclass ImageDataset(Dataset):\ndef __init__(self, root_dir, transform=None):\nself.root_dir = root_dir\nself.transform = transform\nself.image_names = os.listdir(self.root_dir)\ndef __len__(self):\nreturn len(self.image_names)\ndef __getitem__(self, idx):\nimage_name = self.image_names[idx]\nimage_path = os.path.join(self.root_dir, image_name)\nimage = Image.open(image_path).convert('RGB')\nif self.transform:\nimage = self.transform(image)\nreturn image\n# Create the dataset and dataloader\ndataset = ImageDataset(root_dir='path/to/images')\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n# Define the CNN model\nclass CNN(torch.nn.Module):\ndef __init__(self):\nsuper(CNN, self).__init__()\nself.conv1 = torch.nn.Conv2d(3, 6, 5)\nself.pool = torch.nn.MaxPool2d(2, 2)\nself.conv2 = torch.nn.Conv2d(6, 16, 5)\nself.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\nself.fc2 = torch.nn.Linear(120, 84)\nself.fc3 = torch.nn.Linear(84, 10)\ndef forward(self, x):\nx = self.pool(F.relu(self.conv1(x)))\nx = self.pool(F.relu(self.conv2(x)))\nx = x.view(-1, 16 * 5 * 5)\nx = F.relu(self.fc1(x))\nx = F.relu(self.fc2(x))\nx = self.fc3(x)\nreturn x\n# Create the model and optimizer\nmodel = CNN()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n# Loop through the dataloader and train the model\nfor images, labels in dataloader:\noptimizer.zero_grad()\noutputs = model(images)\nloss = criterion(outputs, labels)\nloss.backward()\noptimizer.step()\nIn this example, the ImageDataset class extends the PyTorch Dataset class and is used to load the images from a root directory. The DataLoader class is used to load the data in small batches and shuffle"
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-generate-natural-language",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html#use-pyro-to-generate-natural-language",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to generate natural language",
    "text": "use pyro to generate natural language\nTo generate natural language using Pyro, you can use a technique called language modeling. Language modeling is the process of predicting the next word in a sequence of words given the previous words.\nOne way to perform language modeling using Pyro is to use a probabilistic graphical model called a recurrent neural network (RNN) language model. In an RNN language model, the probability of each word in the sequence is modeled as a function of the previous words in the sequence.\nTo implement an RNN language model in Pyro, you will first need to define the model and the priors for the parameters. This can be done using the pyro.sample() function, which allows you to specify the probability distribution for the parameters. You can then use the pyro.infer.SVI() function to perform stochastic variational inference on the model, which will allow you to estimate the posterior distribution of the model parameters.\nOnce you have trained the model, you can use it to generate natural language by feeding it a seed word or phrase and using the model to predict the next word in the sequence. You can then use the predicted word as the input for the next iteration, and continue generating the sequence until you reach the desired length.\nFor more detailed information on how to implement language modeling using Pyro, you can refer to the Pyro documentation or tutorials online."
  },
  {
    "objectID": "posts/44451f63-783f-4ccc-8c2f-799d865de816/index.html",
    "href": "posts/44451f63-783f-4ccc-8c2f-799d865de816/index.html",
    "title": "Exploring Alternative Linux Cd Managers: Goto, Go-Shell, Up, and AutoJump",
    "section": "",
    "text": "cd manager Linux alternative\ngoto supports bash and zsh (compdef needed)\ngo-shell supports powershell\nup navigates to parent directory, supports fish, bash, zsh\nautojump"
  },
  {
    "objectID": "posts/7246fc7e-4d68-4e59-9c24-593920bedc40/index.html",
    "href": "posts/7246fc7e-4d68-4e59-9c24-593920bedc40/index.html",
    "title": "calling java from python",
    "section": "",
    "text": "using jpype or pyjnius\nsample code for jpype:\nfrom jpype import *\nimport jpype.imports # this is needed! shit.\naddClassPath(\"/root/Desktop/works/pyjom/tests/karaoke_effects/classpath/lingua.jar\")\nstartJVM(getDefaultJVMPath())\njava.lang.System.out.println(\"Calling Java Print from Python using Jpype!\")\nfrom com.github.pemistahl.lingua.api import *\n# detector = LanguageDetectorBuilder.fromAllLanguages().withLowAccuracyMode().build()\ndetector = LanguageDetectorBuilder.fromAllLanguages().build() # 3.5GB just for detecting language! it is somehow crazy.\nsample = 'hello world'\nresult = detector.detectLanguageOf(sample)\nprint(result, type(result)) # &lt;java class 'com.github.pemistahl.lingua.api.Language'&gt;\n# but we can convert it into string.\nstrResult = str(result)\nprint(strResult, type(strResult))\nimport math\nprint(\"CALLING MATH: %d\" % math.sqrt(4))\nshutdownJVM()\nsample for pyjnius:\nimport jnius_config\n# jnius_config.add_options('-Xrs', '-Xmx4096')\njnius_config.set_classpath('.', \"/root/Desktop/works/pyjom/tests/karaoke_effects/classpath/lingua.jar\")\nimport jnius\njnius.autoclass('java.lang.System').out.println('Hello world')\ndetector = jnius.autoclass('com.github.pemistahl.lingua.api.LanguageDetectorBuilder').fromAllLanguages().build()\nsample = 'hello world'\nresult = detector.detectLanguageOf(sample)\nprint(result, type(result))\n# breakpoint()\nstrResult = result.toString()\nprint(strResult, type(strResult))"
  },
  {
    "objectID": "posts/51712285-e132-4dbd-82ce-8acdfb4da72c/index.html",
    "href": "posts/51712285-e132-4dbd-82ce-8acdfb4da72c/index.html",
    "title": "cacani tweening_interpolating alternatives",
    "section": "",
    "text": "cacani tweening/interpolating alternatives animation tool animation generation\nvpaint\nhttp://www.vpaint.org\nhttps://github.com/dalboris/vpaint\nvgc\nhttps://github.com/vgc/vgc\nopentoolz v1.4 and later\nsynfig vector graphic animation:\nsynfig.org\n2d animation tool:\nhttps://github.com/hidefuku/AnimeEffects\nhttp://animeeffects.org/en/"
  },
  {
    "objectID": "posts/6739d000-d0ef-4766-a294-6187bfe50ff7/index.html",
    "href": "posts/6739d000-d0ef-4766-a294-6187bfe50ff7/index.html",
    "title": "Cracking BurpSuite Pro: Exploiting Web App Vulnerabilities with Python API Client",
    "section": "",
    "text": "burpsuite Pro cracked keygen\nthis makes me think of metasploit pro.\nburpsuite pro contains burp webapp scanner, will scan for common vulnerabilities, 0day exploits for highly dynamic webapps.\nburpsuite pro 2021 keygen\npython unofficial burpsuite api client\nburpsuite 2022 crack"
  },
  {
    "objectID": "posts/0f75254d-b5bd-4943-b80f-6f2cf4852a05/index.html",
    "href": "posts/0f75254d-b5bd-4943-b80f-6f2cf4852a05/index.html",
    "title": "bilibili 账号找回",
    "section": "",
    "text": "联系了客服娘 人工找回的\n看来这个b站还是欠日 什么消息都要我记住？我记得住个屁\n\n提醒我隔一段时间检查一下这个话费 两个号码都要检查\n\n一周提醒一次 从8月19号开始 每个星期五都要检查话费\n新注册的号码 6个月之后可以更换套餐 换成8块钱一个月的"
  },
  {
    "objectID": "posts/a6600902-fd43-4525-b9e1-3f31c4e41c4d/index.html",
    "href": "posts/a6600902-fd43-4525-b9e1-3f31c4e41c4d/index.html",
    "title": "bilibili up主启航计划",
    "section": "",
    "text": "现在看来b站应该是有专人在负责讲解同一套课程了 我现在还在收到b站的培训通知短信\n应该把相关的链接 信息收集在这里"
  },
  {
    "objectID": "posts/4318df33-8a8f-42e6-a17c-de965ad7ae4e/index.html",
    "href": "posts/4318df33-8a8f-42e6-a17c-de965ad7ae4e/index.html",
    "title": "bilibili dark reader mod",
    "section": "",
    "text": "maybe toggle the filter mode triggers will help?\nor stylus? other modding tools?"
  },
  {
    "objectID": "posts/0a29f994-b2c0-4dad-b1aa-5196b0121d2b/index.html",
    "href": "posts/0a29f994-b2c0-4dad-b1aa-5196b0121d2b/index.html",
    "title": "A good/bad proposal on v2ray",
    "section": "",
    "text": "suggest to enable multiple v2ray client/servers which talk to each other but only visit the network with one single outbound. maybe like the onion router."
  },
  {
    "objectID": "posts/7b4c3b5b-427d-45d2-9daf-caf2dea62597/index.html",
    "href": "posts/7b4c3b5b-427d-45d2-9daf-caf2dea62597/index.html",
    "title": "awesome-data-labeling",
    "section": "",
    "text": "A curated list of awesome data labeling tools\n\nImages\n\nlabelImg - LabelImg is a graphical image annotation tool and label object bounding boxes in images\nCVAT - Powerful and efficient Computer Vision Annotion Tool\nlabelme - Image Polygonal Annotation with Python\nVoTT - An open source annotation and labeling tool for image and video assets\nimglab - A web based tool to label images for objects that can be used to train dlib or other object detectors\nYolo_mark - GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2\nPixelAnnotationTool - Software that allows you to manually and quickly annotate images in directories\nOpenLabeling - Label images and video for Computer Vision applications\nimagetagger - An open source online platform for collaborative image labeling\nAlturos.ImageAnnotation - A collaborative tool for labeling image data\ndeeplabel - A cross-platform image annotation tool for machine learning\nMedTagger - A collaborative framework for annotating medical datasets using crowdsourcing.\nLabelbox - Labelbox is the fastest way to annotate data to build and ship computer vision applications\nturktool - A modern React app for scalable bounding box annotation of images\nPixie - Pixie is a GUI annotation tool which provides the bounding box, polygon, free drawing and semantic segmentation object labelling\nOpenLabeler - OpenLabeler is an open source desktop application for annotating objects for AI appplications\nAnno-Mage - A Semi Automatic Image Annotation Tool which helps you in annotating images by suggesting you annotations for 80 object classes using a pre-trained model\nCATMAID - Collaborative Annotation Toolkit for Massive Amounts of Image Data\nmake-sense - makesense.ai is a free to use online tool for labelling photos\nLOST - Design your own smart Image Annotation process in a web-based environment\nAnnotorious - A JavaScript library for image annotation.\nSloth - Tool for labeling image and video data for computer vision research.\n\n\n\nText\n\nYEDDA - A Lightweight Collaborative Text Span Annotation Tool (Chunking, NER, etc.). ACL best demo nomination.\nML-Annotate - Label text data for machine learning purposes. ML-Annotate supports binary, multi-label and multi-class labeling.\nTagEditor - Annotation tool for spaCy\nSMART - Smarter Manual Annotation for Resource-constrained collection of Training data\nPIAF - A Question-Answering annotation tool\n\n\n\nAudio\n\nEchoML - Play, visualize, and annotate your audio files\naudio-annotator - A JavaScript interface for annotating and labeling audio files.\naudio-labeler - An in-browser app for labeling audio clips at random, using Docker and Flask.\nwavesurfer.js - Simple annotations tool, check the example.\npeak.js - Browser-based audio waveform visualisation and UI component for interacting with audio waveforms, developed by BBC UK.\nPraat - Doing Phonetics By Computer\nAubio - Tool designed for the extraction of annotations from audio signals.\n\n\n\nVideo\n\nUltimateLabeling - A multi-purpose Video Labeling GUI in Python with integrated SOTA detector and tracker\nVATIC - VATIC is an online video annotation tool for computer vision research that crowdsources work to Amazon’s Mechanical Turk.\n\n\n\nTime Series\n\nCurve - Curve is an open-source tool to help label anomalies on time-series data\nTagAnomaly - Anomaly detection analysis and labeling tool, specifically for multiple time series (one time series per category)\ntime-series-annotator - The CrowdCurio Time Series Annotation Library implements classification tasks for time series.\nWDK - The Wearables Development Toolkit (WDK) is a set of tools to facilitate the development of activity recognition applications with wearable devices.\n\n\n\n3D\n\nwebKnossos - webKnossos is an open-source web-based tool for visualizing, annotating, and sharing large 3D image datasets. It features fast 3D data browsing, skeleton (line-segment) annotations, segmentation and proof-reading tools, mesh visualization, and collaboration features. The public instance webknossos.org hosts a collection of published datasets and can be used without a local setup.\nKNOSSOS - KNOSSOS is a software tool for the visualization and annotation of 3D image data and was developed for the rapid reconstruction of neural morphology and connectivity.\n\n\n\nLidar\n\nsemantic-segmentation-editor - Web labelling tool for camera and LIDAR data\n\n\n\nMultiDomain\n\nLabel Studio - Label Studio is a configurable data annotation tool that works with different data types\nDataturks - Dataturks support E2E tagging of data items like video, images (classification, segmentation and labelling) and text (full length document annotations for PDF, Doc, Text etc) for ML projects."
  },
  {
    "objectID": "posts/c91279bf-09bb-4a5d-8c05-4c59a40740bf/index.html",
    "href": "posts/c91279bf-09bb-4a5d-8c05-4c59a40740bf/index.html",
    "title": "autocad dwg to dxf, extract text from dwg files",
    "section": "",
    "text": "use oda_file_converter to convert dwt to dxf, when running it, its ui will pop up. example commandline usage\nlibredwg powers dwg2dxf\nfreecad"
  },
  {
    "objectID": "posts/c66592c5-ed0f-4156-a9fa-8d4043e95a5d/index.html",
    "href": "posts/c66592c5-ed0f-4156-a9fa-8d4043e95a5d/index.html",
    "title": "audio watermark removal",
    "section": "",
    "text": "deep audio prior\nAudio Source Separation Without Any Training Data.\nDAP can also be successfully applied to address audio watermarker removal with co-separation. Given 3 sounds with audio watermarkers, our cosep model can generate 3 individual music sounds and the corresponding watermarker.\naudio watermark may exists in sub or ultra frequencies. use ffmpeg to remove it\nprocess audio with some equalizer"
  },
  {
    "objectID": "posts/d958ceeb-2999-48ce-bf78-f246465c97fb/index.html#question",
    "href": "posts/d958ceeb-2999-48ce-bf78-f246465c97fb/index.html#question",
    "title": "ask chatgpt how to create an ai model for controlling computer under human instruction",
    "section": "question",
    "text": "question\nhow do i design an ai model using gpt, rnn, lstm, vit to accept computer display screenshots and human instructions as input, keyboard and mouse events as output, trained on random keystrokes and mouse events, also human instructions paired with human demonstrations? show me python code"
  },
  {
    "objectID": "posts/d958ceeb-2999-48ce-bf78-f246465c97fb/index.html#answers",
    "href": "posts/d958ceeb-2999-48ce-bf78-f246465c97fb/index.html#answers",
    "title": "ask chatgpt how to create an ai model for controlling computer under human instruction",
    "section": "answers",
    "text": "answers\n\nClaude+\nThat would be an extremely complex AI system to build. Some high level steps would be:\nCollect a large dataset of screenshots, human instructions, and corresponding keyboard/mouse interactions. This dataset would be crucial for training.\nUse a CNN to extract visual features from the screenshots. Something like VGG16 or ResNet would work well here.\nUse an RNN/LSTM to encode the sequence of instructions. BERT or RoBERTa would also be good options here.\nCombine the visual and textual features. Options include concatenation, addition, or a more complex fusion method.\nUse a Transformer like GPT-3 or Visual-Transformers to generate the keyboard/mouse interactions from the combined visual+textual features.\nTrain the entire model end-to-end to minimize the difference between the generated interactions and the ground truth interactions from your dataset.\nThis would likely take a team of ML engineers and researchers to develop, and would require lots of time, data, and compute.\nSome sample Python code would be:\nimport torchvision.models as models\nimport torch\nimport torch.nn as nn\nfrom transformers import RobertaModel, GPT2LMHeadModel\n# Feature Extractors\ncnn = models.resnet50(pretrained=True)\nroberta = RobertaModel.from_pretrained(\"roberta-base\")\n# Fusion\nfusion = nn.Sequential(nn.Linear(2048 + 768, 1024), nn.ReLU(), nn.Linear(1024, 512))\n# Generation Model\ngenerator = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n# Forward pass\nimg_features = cnn(img)\ninstruction_features = roberta(instructions)[0]\ncombined_features = fusion(torch.cat((img_features, instruction_features), dim=1))\npreds = generator(inputs_embeds=combined_features)[0]\nThis is just a brief sample, but hopefully gives you an idea of the components and flow. Let me know if you have any other questions!\n\n\n\nGPT4\nDesigning an AI model that combines GPT, RNN, LSTM, and ViT for the task you described is complex and requires deep understanding of these architectures. However, I’ll provide you with a high-level overview and a basic structure of the code to help you get started.\n\nFirst, process the input data:\n\n\nFor computer display screenshots, use a Vision Transformer (ViT) model to extract features.\nFor human instructions, use a GPT model to encode the natural language instructions.\n\n\nCombine the features from both the ViT and GPT models.\nUse an LSTM or RNN to process the combined features and maintain the temporal context.\nFinally, decode the output of the LSTM/RNN into keyboard and mouse events.\n\nHere’s a basic structure of the code:\nimport torch\nimport torchvision\nfrom transformers import GPT2Tokenizer, GPT2Model\n# Load pretrained models\ngpt_model = GPT2Model.from_pretrained('gpt2')\nvit_model = torchvision.models.vit_b_16(pretrained=True)\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nclass CustomModel(torch.nn.Module):\ndef __init__(self, gpt_model, vit_model, hidden_size, output_size):\nsuper(CustomModel, self).__init__()\nself.gpt_model = gpt_model\nself.vit_model = vit_model\nself.rnn = torch.nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\nself.fc = torch.nn.Linear(hidden_size, output_size)\ndef forward(self, instructions, screenshots):\n# Encode instructions using GPT2\ninputs = tokenizer(instructions, return_tensors=\"pt\", padding=True, truncation=True)\ngpt_output = self.gpt_model(**inputs)\ngpt_features = gpt_output.last_hidden_state[:, 0, :]\n# Encode screenshots using ViT\nvit_output = self.vit_model(screenshots)\nvit_features = vit_output[\"last_hidden_state\"][:, 0, :]\n# Combine features\ncombined_features = torch.cat((gpt_features, vit_features), dim=1)\n# Process combined features through an RNN\nrnn_output, _ = self.rnn(combined_features.unsqueeze(1))\n# Decode the output into keyboard and mouse events\noutput = self.fc(rnn_output.squeeze(1))\nreturn output\n# Instantiate the custom model\nmodel = CustomModel(gpt_model, vit_model, hidden_size=1024, output_size=256)\n# Train and evaluate the model using your dataset\nYou’ll need to collect a dataset with computer display screenshots, human instructions, and paired keyboard and mouse events. Then, preprocess the data, split it into training and validation sets, and train the model using an appropriate loss function and optimizer.\nKeep in mind that this is just a starting point, and you may need to experiment with different architectures, loss functions, and hyperparameters to achieve the desired performance."
  },
  {
    "objectID": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html",
    "href": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "",
    "text": "## controllable video summarization query controllable video summarization and paper DeepQAMVS: Query-Aware Hierarchical Pointer Networks for Multi-Video Summarization CLIP-It! Language-Guided Video Summarization Convolutional Hierarchical Attention Network for Query-Focused Video Summarization ## fuzzy search fuzzywuzzy tutorial thefuzz: Fuzzy String Matching in Python ## data humanization python-humanize humanfriendly\n\n\n\n\n观众情绪是唯一的标准。\n\n\n\n影视 番剧 是可以通过专门的网站查找得到英文名称和中文名称的关联的 可以利用这个关系得到YouTube上面的影评并生成中文标题 影视剪辑比较杂乱 现在喜欢随便混搭 意识流剪辑 当然拿来做一般的素材也行 不过就需要自己搭建处理了 爱奇艺有以图搜片 不过只能搜爱奇艺有版权的 33台词 根据电影台词来搜索电影出处 同时有根据画面描述搜索视频片段 画面清晰度不高 其中文案转视频思路和我差不多 film.ai now can query screenshot and movie name by description and download thumbnails of movies (not latest, not mainland), but without subscription you cannot get accurate seek time (though it will never be accurate) in imdb can pass film/anime name in multiple languages and get the english name (and trailer video), then query for it in 1337x (results sorted by seeder counts) ——- nyaa.si国内访问不上 nyaa镜像站列表 比如 https://nyaa.unblockit.ink/ (navigate all unblockit sites, though nyaa is currently not mirrored by this site)https://nyaa.ink/ 其中有些NSFW的 里面也搜不到番剧 nyaapy wiki nyaapi wiki (nodejs) torrent file parser and writer (python) 文本分类式的番剧剪辑 需要分割时间段 即每隔一分钟分割对应的弹幕并摘要或者字幕 合并并进行打标签 训练 注意不要包括片头和片尾 (maybe audio only model like whisper will classify this successifully, remember to split (or not?) vocals from BGM? (to detect singing voice which is unique in OP/ED)) when transcoding (with seeking?) using ffmpeg tweak parameters. set low profile with high threads count (higher crf will result in poor quality but faster speed), although all these flags may result into unplayable video for some players.\nffmpeg -ss &lt;seek_start&gt; -to &lt;seek_end&gt; -i &lt;video_url&gt; -c:v libx264 -c:a [aac/copy] -threads 8 -crf 28 -preset ultrafast -tune zerolatency -movflags isml+frag_keyframe+empty_moov+faststart+delay_moov -f ismv -maxrate 2500k -bufsize 5000k &lt;output_path&gt;\n使用网络链接进行ffmpeg seek (-c copy)如果不准确 那么就是片子太短了或者是截取的片段太短了 尝试下载全片之后在本地截取 用webtorrent替代aria2c 可以下载视频指定区域 下载速度特别快 记得及时关闭下载释放内存 看看webtorrent-cli是怎么实现seek的 如何对接ffmpeg yt-dlp不一定能下载b站视频指定区域 如果下载失败 得到视频原地址之后执行： ffmpeg -ss &lt;start&gt; -to &lt;end&gt; -c copy &lt;video_url&gt; (其实就是没更新到最新版本) 准备片头和片尾 准备视频模版 每个片段不要太长 选取多个番剧 适当处理视频 防止撞车 如果要剪短视频 多用转场效果 提取正在说话 动作幅度大 或者模型认为比较高能的片段 首先收集b站的动漫高能剪辑视频 提取标题 标签 封面 寻找类似封面 根据封面生成标签 或者根据标签寻找封面 (视频里面找 或者类似图片) 训练根据封面和标签生成标题的模型 或者自行发挥 尝试 只要看起来还行 分段分析视频片段 用yolov8找出视频正在播放的区域 (画中画区域识别) 方便裁剪识别动漫 识别截图中的文字 查看是否有重复的 包含有番剧名称 可以用来查找动漫 asoul database有识别截图出处的思路 asoul自动操作Windows上面剪映获取字幕 剪映API基于pyautogui 可以使用免费的CI系统 在云端windows机器上面运行程序 利用动漫素材来源定位网站可以锁定剪辑位置 裁剪时间长度要控制 只选取匹配度高的 NSFW的不要 另外图像尺寸要合适 要正好是视频截图 注意网上的图片不一定是视频截图 最好直接在视频里面找 不要裁剪 图片可能加了一些番剧没有的字符或者装饰 (saucenao&gt;75 (能识别出来老番 比如“没有钱” 但是老番一般没啥人做种 下载可能很慢 不如直接放弃 有几率搜出来pixiv的插画 显然不能拿来剪视频), trace.moe&gt;75, both can detect latest (ongoing) bangume, select top-most) 如果匹配度不高就算了 找下一个 即使匹配度高也要充分怀疑 同一段视频的某段区域 多截图几次 如果出来的不是同一个番 或者不是同一个番的同一集 或者不是连续的时间段 (分别探讨以上情况 如果是番剧的开始/结束片段那么可能同时出现在多个分集里面 如果确实是开头公用的画面 必然会反复出现相同番剧的名字 在这种情况下 优先选取之前已经下载过的视频) 那么就说明结果不对头 即使验证通过 也得对剪出来的片段进行二次验证 检测片段是否存在那个画面 当然对于快速切换画面的 确实有大量不同番剧片段出现在同一个视频的 那就有待进一步探讨了 saucenao json api wrapper (python) saucenao api keys found on github:\napi_key = \"6ccf5333e9c875421ff0764e2ed0c0cde1e3a0c7\"\n这种种子文件下载得到的视频 往往带有字体文件 可以收集用来做视频 封面设计 番剧搜索引擎里面出现的问题 比如不同番剧相似画面的相似度不应该那么高 可以通过自监督强化学习解决 另外画面裁剪的问题 (画中画 裁剪小了或者大了 或者有画面延伸) 都需要进一步改进 最主要的还是要有大量的 不断更新的数据 当然目前来看这些不需要处理 因为大家都喜欢看中文字幕 (谁听得懂日语 或者一边听日语一边看英文字幕啊) 尽量不用国外的片源 如果只有国外的 直接机器翻译能找到的公开字幕 或者直接语音转文字 图片转文字 不过话说回来 种子下载慢 国内网站广告又多 如果能单独下载字幕 (vcb的有单独分开的字幕可以下载) 对得上时间长度的话 就可以获取到带字幕的老番 parse and extract subtitle files from mkv video using mkvmerge or ffmpeg videocr: extract hard-coded subtitles from video by OCR extract-subtitles 帧间差分法识别关键帧 anime downloaders: (hard to find chinese subtitles huh?) animdl supports time ranges monkey-dl ani-cli (animixplay is gone, fixing?) gogoanime-api in which you may not get raw video with japanese dub jerry with subtitle language specification 下载下来之后 得到视频字幕 进行标记 (打上标签) 方便以后创作类似视频的时候查找 以及作为数据集 训练模型 根据字幕/弹幕 (弹幕得去b站找并且自行提取) 或者结合视频内容 (算力够么 需要人肉标记 还是反复调用识图API进行标记 或者用jina (fine-tuned?) 计算图像相似度) 预测不同类型高能片段的标签 老番可以在国内番剧网站寻找 b站有免费的那么可以尝试下载 tracker list for anime 种子站要能够根据seeder降序排序 vcb的一般seeder会很多 但是其他字幕组的新番即使seeder比较少 下载速度也会很快 看情况而定 vcb只负责压制 其他字幕组提供单独分开的字幕 两者要单独下载 Nyaa支持该功能 Nyaa API 这个站将番剧分类为原盘 英文翻译版 (这个分类经常会把多语言版本分类到这个区域) 其他语言翻译版 中文翻译属于其他语言翻译版 如果要找中文翻译版本 先选定类型 然后查找文件名是否包含指定代号 有字幕文件的话先下载看看 检测下主语言类别 aria2c can be controlled via python (to make sure it will exit immediately after finishing download instead of seeding and blocking, though can be achieved with some tweaks on commandline arguments to execute command after download finished signal emitted): aria2p (can be used both as a library or cli program), pyaria2 (old) searching aria2 in github, i found some repos relating to baidunetdisk. 到国内番剧种子站去找片源 (这些站基本一个样) 新番下载较快 老番下载会非常慢 几乎龟速 (检查有没有seeder 一个都没有就别想下了 直接放弃 以及监控下载进度 一段时间没有进度基本凉了) 而不是一些在线观看的网站 (视频不清晰 还有广告在里面) 由于没法用yt-dlp选取段落下载 (但是webtorrent可以) 最好用云电脑下载然后回传 关掉aria2c的做种选项 下完自动关闭 如果是合集 需要选择指定的对象进行下载\naria2c --show-files target.torrent\naria2c -x 16 --file-allocation=none --select-file=&lt;file_index&gt; target.torrent\n得到了番剧命名格式之后建议利用第三方搜索引擎搜索 这些种子站一般都会把新番做成rss 用来订阅 做新番推荐比较合适 需要找到番剧介绍的文章来转化 资源的名称遵循某种格式 番剧名称会用不同语言标注 提示字幕的格式 番剧番号用空格 英文或者中文括号括住 一般至少两位数 小于两位会补零 海边的异乡人之类的只有一集 没有episode提示 如果要实时看云电脑的进度可以自己搭建一个netprogressbar server 根据约定好的url和密码 (read-only and write-only password, or both, by setting different privilege) 来上报和接收进度 server要及时回收资源 番剧信息包括名称 类型 标签 具体第几话 单季和多季有别 如果是多季的话需要研究如何找出来 提取名字要完整 如果有续集 (比如”Yahari Ore no Seishun Lovecome wa Machigatte Iru.”) 那么要改进parse逻辑 准确识别 (要么在番剧名字alias识别上下功夫 要么找到续集名字 过滤掉续集名字并保留alias名字 看看名字之间是不是有包含关系 没包含关系就不用过滤 到anidb.net找) anidb搜索有时会直接跳转到指定番剧页面 需要根据链接地址和内容判断是否存在跳转 以及如何分别进行解析 anilist python wiki anilist api v2 docs 有提取画面中动漫人物信息以及所属番剧的网站 Python API 只支持日漫 该网站在b站的使用方法介绍 注册码目前是hello2023 可以用来做单个人物合集 在发送截图之前先用模型扫描一下到底有没有动漫人脸 如果没有就不用上传了 识别不出来 trailer也可以用来训练视频摘要模型 提取番剧精彩片段 可以作为素材"
  },
  {
    "objectID": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html#controllable-video-summarization",
    "href": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html#controllable-video-summarization",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "controllable video summarization",
    "text": "controllable video summarization\nquery controllable video summarization and paper\nDeepQAMVS: Query-Aware Hierarchical Pointer Networks for Multi-Video Summarization\nCLIP-It! Language-Guided Video Summarization\nConvolutional Hierarchical Attention Network for Query-Focused Video Summarization"
  },
  {
    "objectID": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html#fuzzy-search",
    "href": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html#fuzzy-search",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "fuzzy search",
    "text": "fuzzy search\nfuzzywuzzy tutorial\nthefuzz: Fuzzy String Matching in Python"
  },
  {
    "objectID": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html#data-humanization",
    "href": "posts/feede916-c88d-4eae-89ae-cd207c282e47/index.html#data-humanization",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "data humanization",
    "text": "data humanization\npython-humanize\nhumanfriendly\n\n观众情绪是唯一的标准。\n\n影视 番剧 是可以通过专门的网站查找得到英文名称和中文名称的关联的 可以利用这个关系得到YouTube上面的影评并生成中文标题\n影视剪辑比较杂乱 现在喜欢随便混搭 意识流剪辑 当然拿来做一般的素材也行 不过就需要自己搭建处理了\n爱奇艺有以图搜片 不过只能搜爱奇艺有版权的\n33台词 根据电影台词来搜索电影出处 同时有根据画面描述搜索视频片段 画面清晰度不高 其中文案转视频思路和我差不多\nfilm.ai now can query screenshot and movie name by description and download thumbnails of movies (not latest, not mainland), but without subscription you cannot get accurate seek time (though it will never be accurate)\nin imdb can pass film/anime name in multiple languages and get the english name (and trailer video), then query for it in 1337x (results sorted by seeder counts)\n\nnyaa.si国内访问不上 nyaa镜像站列表 比如 https://nyaa.unblockit.ink/ (navigate all unblockit sites, though nyaa is currently not mirrored by this site)https://nyaa.ink/ 其中有些NSFW的 里面也搜不到番剧\nnyaapy wiki\nnyaapi wiki (nodejs)\ntorrent file parser and writer (python)\n文本分类式的番剧剪辑 需要分割时间段 即每隔一分钟分割对应的弹幕并摘要或者字幕 合并并进行打标签 训练 注意不要包括片头和片尾 (maybe audio only model like whisper will classify this successifully, remember to split (or not?) vocals from BGM? (to detect singing voice which is unique in OP/ED))\nwhen transcoding (with seeking?) using ffmpeg tweak parameters. set low profile with high threads count (higher crf will result in poor quality but faster speed), although all these flags may result into unplayable video for some players.\nffmpeg -ss &lt;seek_start&gt; -to &lt;seek_end&gt; -i &lt;video_url&gt; -c:v libx264 -c:a [aac/copy] -threads 8 -crf 28 -preset ultrafast -tune zerolatency -movflags isml+frag_keyframe+empty_moov+faststart+delay_moov -f ismv -maxrate 2500k -bufsize 5000k &lt;output_path&gt;\n使用网络链接进行ffmpeg seek (-c copy)如果不准确 那么就是片子太短了或者是截取的片段太短了 尝试下载全片之后在本地截取\n用webtorrent替代aria2c 可以下载视频指定区域 下载速度特别快 记得及时关闭下载释放内存 看看webtorrent-cli是怎么实现seek的 如何对接ffmpeg\nyt-dlp不一定能下载b站视频指定区域 如果下载失败 得到视频原地址之后执行：\nffmpeg -ss &lt;start&gt; -to &lt;end&gt; -c copy &lt;video_url&gt;\n(其实就是没更新到最新版本)\n准备片头和片尾 准备视频模版 每个片段不要太长 选取多个番剧 适当处理视频 防止撞车\n如果要剪短视频 多用转场效果 提取正在说话 动作幅度大 或者模型认为比较高能的片段\n首先收集b站的动漫高能剪辑视频\n提取标题 标签 封面\n寻找类似封面 根据封面生成标签 或者根据标签寻找封面 (视频里面找 或者类似图片)\n训练根据封面和标签生成标题的模型 或者自行发挥 尝试 只要看起来还行\n分段分析视频片段 用yolov8找出视频正在播放的区域 (画中画区域识别) 方便裁剪识别动漫\n识别截图中的文字 查看是否有重复的 包含有番剧名称 可以用来查找动漫\nasoul database有识别截图出处的思路\nasoul自动操作Windows上面剪映获取字幕 剪映API基于pyautogui 可以使用免费的CI系统 在云端windows机器上面运行程序\n利用动漫素材来源定位网站可以锁定剪辑位置 裁剪时间长度要控制 只选取匹配度高的 NSFW的不要 另外图像尺寸要合适 要正好是视频截图 注意网上的图片不一定是视频截图 最好直接在视频里面找 不要裁剪 图片可能加了一些番剧没有的字符或者装饰 (saucenao&gt;75 (能识别出来老番 比如“没有钱” 但是老番一般没啥人做种 下载可能很慢 不如直接放弃 有几率搜出来pixiv的插画 显然不能拿来剪视频), trace.moe&gt;75, both can detect latest (ongoing) bangume, select top-most) 如果匹配度不高就算了 找下一个 即使匹配度高也要充分怀疑 同一段视频的某段区域 多截图几次 如果出来的不是同一个番 或者不是同一个番的同一集 或者不是连续的时间段 (分别探讨以上情况 如果是番剧的开始/结束片段那么可能同时出现在多个分集里面 如果确实是开头公用的画面 必然会反复出现相同番剧的名字 在这种情况下 优先选取之前已经下载过的视频) 那么就说明结果不对头 即使验证通过 也得对剪出来的片段进行二次验证 检测片段是否存在那个画面 当然对于快速切换画面的 确实有大量不同番剧片段出现在同一个视频的 那就有待进一步探讨了\nsaucenao json api wrapper (python)\nsaucenao api keys found on github:\napi_key = \"6ccf5333e9c875421ff0764e2ed0c0cde1e3a0c7\"\n这种种子文件下载得到的视频 往往带有字体文件 可以收集用来做视频 封面设计\n番剧搜索引擎里面出现的问题 比如不同番剧相似画面的相似度不应该那么高 可以通过自监督强化学习解决 另外画面裁剪的问题 (画中画 裁剪小了或者大了 或者有画面延伸) 都需要进一步改进 最主要的还是要有大量的 不断更新的数据 当然目前来看这些不需要处理\n因为大家都喜欢看中文字幕 (谁听得懂日语 或者一边听日语一边看英文字幕啊) 尽量不用国外的片源 如果只有国外的 直接机器翻译能找到的公开字幕 或者直接语音转文字 图片转文字 不过话说回来 种子下载慢 国内网站广告又多 如果能单独下载字幕 (vcb的有单独分开的字幕可以下载) 对得上时间长度的话 就可以获取到带字幕的老番\nparse and extract subtitle files from mkv video using mkvmerge or ffmpeg\nvideocr: extract hard-coded subtitles from video by OCR\nextract-subtitles 帧间差分法识别关键帧\nanime downloaders: (hard to find chinese subtitles huh?)\nanimdl supports time ranges\nmonkey-dl\nani-cli (animixplay is gone, fixing?)\ngogoanime-api in which you may not get raw video with japanese dub\njerry with subtitle language specification\n下载下来之后 得到视频字幕 进行标记 (打上标签) 方便以后创作类似视频的时候查找 以及作为数据集 训练模型 根据字幕/弹幕 (弹幕得去b站找并且自行提取) 或者结合视频内容 (算力够么 需要人肉标记 还是反复调用识图API进行标记 或者用jina (fine-tuned?) 计算图像相似度) 预测不同类型高能片段的标签\n老番可以在国内番剧网站寻找 b站有免费的那么可以尝试下载\ntracker list for anime\n种子站要能够根据seeder降序排序 vcb的一般seeder会很多 但是其他字幕组的新番即使seeder比较少 下载速度也会很快 看情况而定 vcb只负责压制 其他字幕组提供单独分开的字幕 两者要单独下载 Nyaa支持该功能 Nyaa API 这个站将番剧分类为原盘 英文翻译版 (这个分类经常会把多语言版本分类到这个区域) 其他语言翻译版 中文翻译属于其他语言翻译版 如果要找中文翻译版本 先选定类型 然后查找文件名是否包含指定代号 有字幕文件的话先下载看看 检测下主语言类别\naria2c can be controlled via python (to make sure it will exit immediately after finishing download instead of seeding and blocking, though can be achieved with some tweaks on commandline arguments to execute command after download finished signal emitted): aria2p (can be used both as a library or cli program), pyaria2 (old) searching aria2 in github, i found some repos relating to baidunetdisk.\n到国内番剧种子站去找片源 (这些站基本一个样) 新番下载较快 老番下载会非常慢 几乎龟速 (检查有没有seeder 一个都没有就别想下了 直接放弃 以及监控下载进度 一段时间没有进度基本凉了) 而不是一些在线观看的网站 (视频不清晰 还有广告在里面) 由于没法用yt-dlp选取段落下载 (但是webtorrent可以) 最好用云电脑下载然后回传 关掉aria2c的做种选项 下完自动关闭 如果是合集 需要选择指定的对象进行下载\naria2c --show-files target.torrent\naria2c -x 16 --file-allocation=none --select-file=&lt;file_index&gt; target.torrent\n得到了番剧命名格式之后建议利用第三方搜索引擎搜索\n这些种子站一般都会把新番做成rss 用来订阅 做新番推荐比较合适 需要找到番剧介绍的文章来转化 资源的名称遵循某种格式 番剧名称会用不同语言标注 提示字幕的格式 番剧番号用空格 英文或者中文括号括住 一般至少两位数 小于两位会补零 海边的异乡人之类的只有一集 没有episode提示\n如果要实时看云电脑的进度可以自己搭建一个netprogressbar server 根据约定好的url和密码 (read-only and write-only password, or both, by setting different privilege) 来上报和接收进度 server要及时回收资源\n番剧信息包括名称 类型 标签 具体第几话 单季和多季有别 如果是多季的话需要研究如何找出来 提取名字要完整 如果有续集 (比如”Yahari Ore no Seishun Lovecome wa Machigatte Iru.”) 那么要改进parse逻辑 准确识别 (要么在番剧名字alias识别上下功夫 要么找到续集名字 过滤掉续集名字并保留alias名字 看看名字之间是不是有包含关系 没包含关系就不用过滤 到anidb.net找)\nanidb搜索有时会直接跳转到指定番剧页面 需要根据链接地址和内容判断是否存在跳转 以及如何分别进行解析\nanilist python wiki\nanilist api v2 docs\n有提取画面中动漫人物信息以及所属番剧的网站 Python API 只支持日漫 该网站在b站的使用方法介绍 注册码目前是hello2023 可以用来做单个人物合集 在发送截图之前先用模型扫描一下到底有没有动漫人脸 如果没有就不用上传了 识别不出来\ntrailer也可以用来训练视频摘要模型 提取番剧精彩片段 可以作为素材"
  },
  {
    "objectID": "posts/e6ff2337-31b6-4d2c-b824-603fe629c951/index.html#disable-ssl-pinning",
    "href": "posts/e6ff2337-31b6-4d2c-b824-603fe629c951/index.html#disable-ssl-pinning",
    "title": "android packet capture",
    "section": "disable ssl pinning",
    "text": "disable ssl pinning\nuse frida scripts specific to applications\njusttrustme xposed\nsslunpinning xposed\napk-mitm by repacking apk and resigning"
  },
  {
    "objectID": "posts/e6ff2337-31b6-4d2c-b824-603fe629c951/index.html#capture-packet-routing",
    "href": "posts/e6ff2337-31b6-4d2c-b824-603fe629c951/index.html#capture-packet-routing",
    "title": "android packet capture",
    "section": "capture, packet routing",
    "text": "capture, packet routing\nrecommend to use: PCAPdroid-API\nPCAPdroid API reference\nadb shell am start -e action start -e pcap_dump_mode udp_exporter -e collector_ip_address 127.0.0.1 -e collector_port 5123 -e app_filter com.tencent.mobileqq -n com.emanuelef.remote_capture.debug/com.emanuelef.remote_capture.activities.CaptureCtrl\nsetting up http proxy via adb:\n# this does not ensure that the target app is captured.\nadb shell settings put global http_proxy &lt;address&gt;:&lt;port&gt;"
  },
  {
    "objectID": "posts/73f2a784-813b-4c25-bde5-61f690b56b9f/index.html#linux",
    "href": "posts/73f2a784-813b-4c25-bde5-61f690b56b9f/index.html#linux",
    "title": "aldente windows & linux alternative",
    "section": "Linux",
    "text": "Linux\nkernel 5.5 or newer:\necho 60 | sudo tee /sys/class/power_supply/BAT0/charge_control_end_threshold\nwith platform-specific drivers, look for: /sys/devices/platform/.*/.*(battery|charge|thresh|limit).*\nFor ThinkPads and selected other laptops tlp/tlpui (acts like powertop which turns off usb devices, so be careful when running long-term programs) provides a unified way\nto configure charge thresholds and recalibrate the battery."
  },
  {
    "objectID": "posts/73f2a784-813b-4c25-bde5-61f690b56b9f/index.html#windows",
    "href": "posts/73f2a784-813b-4c25-bde5-61f690b56b9f/index.html#windows",
    "title": "aldente windows & linux alternative",
    "section": "Windows",
    "text": "Windows"
  },
  {
    "objectID": "posts/f02ee145-827e-4084-9fae-4dbf1fb057cc/index.html",
    "href": "posts/f02ee145-827e-4084-9fae-4dbf1fb057cc/index.html",
    "title": "adb wifi always on",
    "section": "",
    "text": "adb over wifi always on\nwarning: could be dangerous cause adb remote connections seem without any password. consider protect that with some proxy.\nturning on:\nsetprop service.adb.tcp.port 5555\nstop adbd\nstart adbd\nturning off:\nsetprop service.adb.tcp.port -1\nstop adbd\nstart adbd\nset things under /data/adb/services.d/ and make them executable\nmount -o remount,rw /\n# then you can modify /sytem/etc/init.d, but not /system/bin cause it is a copy of /data/system/bin. you should create script there.\ncreate this under /system/etc/init.d/\nservice adb_wifi_enable /system/bin/adb_wifi_enable.sh\ndisabled\noneshot\nseclabel u:r:magisk:s0\non property:sys.boot_completed=1\nstart adb_wifi_enable"
  },
  {
    "objectID": "posts/63a0a5d8-cc5f-44eb-b9ee-f5b0692f2b85/index.html#setup-tty",
    "href": "posts/63a0a5d8-cc5f-44eb-b9ee-f5b0692f2b85/index.html#setup-tty",
    "title": "access kali on chromebook or anywhere",
    "section": "setup tty",
    "text": "setup tty\ni don’t think this will work on android, but let’s see?\nttyd -p &lt;port&gt; -c &lt;username&gt;:&lt;password&gt; &lt;shell_path&gt;\n# don't specify interface since that will screw things up"
  },
  {
    "objectID": "posts/63a0a5d8-cc5f-44eb-b9ee-f5b0692f2b85/index.html#setup-x11vnc-and-novnc",
    "href": "posts/63a0a5d8-cc5f-44eb-b9ee-f5b0692f2b85/index.html#setup-x11vnc-and-novnc",
    "title": "access kali on chromebook or anywhere",
    "section": "setup x11vnc and novnc",
    "text": "setup x11vnc and novnc\nnotice novnc has clipboard function now. share clipboard content across devices via the sidebar menu,\nin reference of kali official\nx11vnc is mirroring the current x11 session. i set it without password.\n#retrieved from fish history\nx11vnc -threads -forever\nthen launch novnc server\nnovnc  --vnc localhost:5900 --listen 10020\nuse this url to access from chromebook:\nhttp://&lt;kali_ip&gt;:10020/vnc.html?host=&lt;kali_ip&gt;&port=10020"
  },
  {
    "objectID": "posts/4fd00b5d-8361-41e1-95d4-bcc55728da9f/index.html",
    "href": "posts/4fd00b5d-8361-41e1-95d4-bcc55728da9f/index.html",
    "title": "Youtube Monitization 油管变现",
    "section": "",
    "text": "8种方式变现\nhttps://www.xiaohongshu.com/web-login/canvas?redirectPath=http%3A%2F%2Fwww.xiaohongshu.com%2Fdiscovery%2Fitem%2F61fdc910000000000102be7b"
  },
  {
    "objectID": "posts/d291d8e6-3355-43ab-90e9-b62c17f5ac1f/index.html",
    "href": "posts/d291d8e6-3355-43ab-90e9-b62c17f5ac1f/index.html",
    "title": "Worth Trying Remote Computer Connection",
    "section": "",
    "text": "NoMachine NX\nFreeNX\nMoonlight for NVIDIA Windows\nparsec for windows/macos host\nssh-rdp for linux host/client\nsomehow usable on localhost:\nx11vnc -localhost -display :0 -threads -forever\nvncviewer -PreferredEncoding=ZRLE localhoat:0\nsunshine host for windows/linux\nhttps://github.com/SunshineStream/Sunshine/blob/master/README.md#macos\nhttps://github.com/loki-47-6F-64/sunshine\nopenstream-server a fork of sunshine\nhttps://open-stream.net/\nsynergy mouse keyboard sharing tool\nssh -X/-Y allowX11forwarding\nhardware solution: kvm switch (high grade with audio redirection separate usb ports)"
  },
  {
    "objectID": "posts/6086c428-e3bd-4062-b6e4-927b69cbdef8/index.html",
    "href": "posts/6086c428-e3bd-4062-b6e4-927b69cbdef8/index.html",
    "title": "Windows 10 system debloating, windows operating system optimization, winget, windows commandline package manager",
    "section": "",
    "text": "winget usage and recommended windows tools\nwinget is slow due to missing mirror site in china. consider using proxy.\n\nto activate windows 10, use KMS tool.\n\nWindows10Debloater: Script to remove Windows 10 bloatware.\nDebloat-Windows-10 (not for win11?)\noptimizer able to:\nFull multilingual support (20 languages available)\nSpeed up your system and network performance\nDisable unnecessary Windows services\nDisable Windows telemetry, Cortana and many more\nDisable Office telemetry (works only with Office 2016)\nDisable Windows 10 automatic updates\nDownload useful apps quickly at once\nUninstall UWP apps\nClean your system drive and major browsers' profile data\nFix common registry issues\nPing IPs and assess your latency\nSearch IPs on SHODAN.io\nRapidly change DNS server (from a pre-made list)\nFlush DNS cache\nRemove unwanted programs running at startup\nEdit your HOSTS file\nFind file lock handles and kill associated processes\nHardware inspection tool\nAdd items in desktop on right-click menu\nDefine custom commands for run dialog\nSilent run support using a configuration file\n\n\nSophiApp: The most powerful open source tweaker on GitHub for fine-tuning Windows 10 & Windows 11"
  },
  {
    "objectID": "posts/47170705-dcef-49c7-b9ed-d1bee74bf6f9/index.html",
    "href": "posts/47170705-dcef-49c7-b9ed-d1bee74bf6f9/index.html",
    "title": "Webproxy, clash, proxy.py",
    "section": "",
    "text": "somebody hates clash and proxy.py, now we proxy websites directly in another website:\n\nUltraviolet by Titanium Network\nvisit Holy Unblocker for demonstration\nholyub-alike websites\n\ngithub topic: webproxy"
  },
  {
    "objectID": "posts/25046988-edff-409f-9589-c8cf1526e68d/index.html",
    "href": "posts/25046988-edff-409f-9589-c8cf1526e68d/index.html",
    "title": "Watch Anime Online",
    "section": "",
    "text": "Downloadable cracked by me anime1.me:\nhttps://anime1.me\nanilist has external links to bangume:\nhttps://anilist.co/anime/140960/SPYFAMILY/"
  },
  {
    "objectID": "posts/b0ca17bc-e3c4-4b9e-b282-70d252cac7a2/index.html",
    "href": "posts/b0ca17bc-e3c4-4b9e-b282-70d252cac7a2/index.html",
    "title": "Vim Custom color scheme",
    "section": "",
    "text": "[documentation[(http://vimdoc.sourceforge.net/htmldoc/syntax.html#:highlight)\nvim terminal color codes\nkeyword for vertical spliters:\nVertSplit\nkeyword for bottom line:"
  },
  {
    "objectID": "posts/ae5d6b8e-7aaa-45ba-b1c3-5598a9b498a9/index.html",
    "href": "posts/ae5d6b8e-7aaa-45ba-b1c3-5598a9b498a9/index.html",
    "title": "Video Search Engines",
    "section": "",
    "text": "Yandex好像可以根据视频截图搜索原视频来源\nyoutube search python\nsearch youtube using urllib\nAI VIDEO SEARCH ENGINE (self hosted):\nJina\nsearch video by subtitle or generated subtitle:\nhttps://github.com/antiboredom/videogrep\nFrom search Engine journal:\nhttps://www.searchenginejournal.com/best-video-search-engines/360822/\nGoogle Youtube Bing\nDailyMotion\nDuckduckGo Yahoo\nMetacafe\nfind fun unusual videos\nAsk Yandex Swisscows\nhttps://kinsta.com/blog/video-search-engine/\nFacebook Dogpile\nVeoh\nvideo share platform, search by language of subtitles\nberify\nreverse video search by screenshot inside the video\nvimeo\nsocial searcher\nsearch multiple social media platform at once\necosia\nshutterstock\nneed purchase? Royalty-free?\nchinese local video platforms:\nbaidu sogou 360 tencent zhihu …"
  },
  {
    "objectID": "posts/2d90d87d-dc5b-4a8e-b34d-151d9cae438e/index.html",
    "href": "posts/2d90d87d-dc5b-4a8e-b34d-151d9cae438e/index.html",
    "title": "Video Editors",
    "section": "",
    "text": "moviepy\nffmpeg wrapper in js\nvideo transitions:\nopengl transitions\nffmpeg filters for gl transitions, as ffmpeg commandline args\njavascript video editor:\nremotion edit video with react\ncreating and rendering dynamic videos\nvideo slideshow creator\neditly’s gui\neditly the slick video editor\nnpm i -g editly\nconcat videos with opengl transitions\ncomplex react native animation engine, not open source\n\nvidpy based on mltframework, shotcut\nauto video editor by audio loudness:\nhttps://github.com/WyattBlue/auto-editor\nposition video by face:\nhttps://github.com/diego3g/video-to-reels\nmachine video editor using deepfake, with gui, not open sourced:\nhttps://github.com/MachineEditor/MachineVideoEditor\nopenshot python:\nhttps://github.com/OpenShot/openshot-qt\nyoutube video summarizer:\nhttps://github.com/codelucas/shorten.tv\ncommandline video editor from suckless:\nhttps://github.com/maandree/blind\nremove slience from video:\nhttps://github.com/gusals3587/jumpcutterV2\nhttps://github.com/carykh/jumpcutter\nhttps://github.com/jappeace/cut-the-crap\nai video editor:\nhttps://github.com/MashiMaroLjc/rabbitVE\ncommandline video editor:\nhttps://github.com/wkentaro/video-cli"
  },
  {
    "objectID": "posts/dda8d689-7017-4fdf-ba01-6b42b0aca3a5/index.html",
    "href": "posts/dda8d689-7017-4fdf-ba01-6b42b0aca3a5/index.html",
    "title": "Video Cutting with captioners, video classifiers, audio classifier, audio categorizer",
    "section": "",
    "text": "you can cut based on video highlights, usually generated by counting “replay overlaps”, avaliable from youtube and bilibili, again needs supervised learning to recognize patterns and emit signals which we want\nCOCA using vit and palm for video captioning\naudio classifier tutorial\naudio tagger visualize how audio classifier works\nneed to identify sounds like dog bark and gun shots, sobs, laughs. Open sourced.\nMay use sound analyzers.\naudio2midi:\nhttps://gist.github.com/natowi/d26c7e97443ec97e8032fb7e7596f0b0\nRecurrent Neural Network for generating piano MIDI-files from audio (MP3, WAV, etc.)\nhttps://github.com/BShakhovsky/PolyphonicPianoTranscription\nA python program which performs an FFT on an audio file and produces a MIDI file from the results\nhttps://github.com/NFJones/audio-to-midi\nExtract the melody from an audio file and export to MIDI\nhttps://github.com/justinsalamon/audio_to_midi_melodia\nPerforms pitch detection on a polyphonic audio source and outputs to MIDI\nhttps://github.com/corbanbrook/spectrotune\nProgram to detect pitch from wav files and write in time quantized MIDI\nhttps://github.com/vaibhavnayel/Audio-to-MIDI-converter\nA CNN which converts piano audio to a simplified MIDI format\nhttps://github.com/hartmetzls/audio_to_midi\nAn application of vocal melody extraction.\nhttps://github.com/bill317996/Audio-to-midi\nTranscribes polyphonic piano pieces from audio (MP3, WAV, etc.) into MIDI-files\nhttps://github.com/BShakhovsky/PianoAudioToMidi\nPolyphonic pitch tracking in real time using machine learning algorithms\nhttps://github.com/jaym910/polyphonic_track\nAudio to MIDI converter\nhttps://github.com/sbaeunker/audioToMidiConverter\nExplore Transcribing Techniques to auto convert audio to midi\nhttps://github.com/Goldspear/audio2midi\nPitchToMIDI\nhttps://github.com/KatoIppei/PitchToMIDI See releases\nPiano & Drums\nhttps://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription\nTony: a tool for melody transcription\nhttps://www.sonicvisualiser.org/tony/ https://github.com/sonic-visualiser/tony https://code.soundsoftware.ac.uk/projects/tony (https://github.com/mikulas-mrva/tony2max)\nMusicTranscription\nhttps://github.com/ClaraBing/CS229-MusicTranscription\npYIN\nhttps://code.soundsoftware.ac.uk/projects/pyin https://github.com/ronggong/pypYIN (python)\nOnsets and Frames Transcription (Piano & Drums)\nhttps://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription https://piano-scribe.glitch.me/\nWaoN\nhttps://sourceforge.net/projects/waon/\naudio2midi conversion works great with prior source separation https://github.com/deezer/spleeter or others like https://github.com/rgcda/Musisep"
  },
  {
    "objectID": "posts/213741d6-54e4-4bf5-a39b-eda76cd3a079/index.html",
    "href": "posts/213741d6-54e4-4bf5-a39b-eda76cd3a079/index.html",
    "title": "Netdisk managers, Userscript and info_data collection",
    "section": "",
    "text": "Userscript and info/data collection\nAlist a filelist manager for all common cloud storage providers\nfor site collection list you could just search for it.\nyou can search for netdisk managers.\naliyun netdisk manager:\nhttps://github.com/tickstep/aliyunpan\nfound a repo full of userscripts:\nhttps://github.com/XIU2/UserScript\nbaidunetdisk cli go:\nhttps://github.com/qjfoidnh/BaiduPCS-Go\nbittorrent trackers:\nhttps://github.com/XIU2/TrackersListCollection\nscript list:\n护眼模式 简单有效的全网通用护眼模式、夜间模式、暗黑模式~ 安装 | 备用\n知乎 美化 宽屏显示、暗黑模式、屏蔽首页活动、调整图片最大高度… 安装 | 备用\n知乎 增强 移除登录弹窗、屏蔽首页视频、屏蔽用户、屏蔽关键词… 安装 | 备用\nV2EX 增强 自动签到、链接转图片、自动无缝翻页、新标签页打开链… 安装 | 备用\nGithub 增强 高速下载 Git Clone/SSH、Release、Raw、Code(ZIP) … 安装 | 备用\nPing.Sx 增强 一键复制所有 IP、清理 IP 链接、快捷回到顶部 … 安装 | 备用\n自动无缝翻页 * 无缝衔接下一页内容 (瀑布流) 支持各论坛/漫画/百度/谷歌等… 安装 | 备用\n3DM论坛 美化 精简多余内容、样式优化 安装 | 备用\n3DM论坛 增强 自动回复、自动无缝翻页、清理置顶帖子、自动滚至隐藏… 安装 | 备用\n蓝奏云网盘 增强 * 右键显示菜单、直接下载文件、显示更多文件、自动密码… 安装 | 备用\n新标签页打开链接 * 将网页中所有链接改为新标签页打开~ 安装 | 备用\nDuckDuckGo 增强 屏蔽指定域名、修复图标加载、链接不携来源、快捷回到… 安装 | 备用\n吾爱破解论坛 美化 精简多余内容、样式优化 安装 | 备用\n吾爱破解论坛 增强 自动签到、自动无缝翻页、屏蔽导读悬赏贴 (最新发表页)… 安装 | 备用\n全球主机交流论坛 增强 * 自动访问空间(22积分)、屏蔽用户、屏蔽关键词、自动翻… 安装 | 备用\nSteam 创意工坊大图 修复 修复 Steam 创意工坊预览大图无法显示的问题 安装 | 备用\nHTML5 视频音频默认音量 避免被 100% 音量吓一跳！且支持各网站分别记住音量… 安装 | 备用\nGoogle 翻译 美化 精简多余内容、修复翻译结果溢出屏幕问题 安装 | 备用\n智友邦论坛 美化 精简多余内容、样式优化、宽屏显示 安装 | 备用\n智友邦论坛 增强 自动签到、自动回复、自动无缝翻页、快捷回到顶部、附… 安装 | 备用\nautopager:\nhttps://greasyfork.org/en/scripts/419215-%E8%87%AA%E5%8A%A8%E6%97%A0%E7%BC%9D%E7%BF%BB%E9%A1%B5\nautopager supported websites:\n&lt; - - - - - - - - 网站 - - - - - - - - &gt; 主页 分类 文章 评论 搜索 &lt; - - - - - - - - - - - - - - - - - - - - - - - - - 备注 - - - - - - - - - - - - - - - - - - - - - - - - - &gt;\n所有 Discuz! 论坛 ✔ ✔ ✔ - ✔ 国内常见 论坛系统 (如：吾爱破解、3DM 等)\n所有 phpBB 论坛 ✔ ✔ ✔ - ✔ 国外常见 论坛系统\n所有 XenForo 论坛 ✔ ✔ ✔ - ✔ 国外常见 论坛系统\n所有 NexusPHP 论坛 ✔ ✔ ✔ - ✔ 国内常见 论坛系统 (BT / PT 论坛)\n所有 Flarum 论坛 ✔ ✔ ✔ - ✔ 简洁开源 论坛系统\n所有 Xiuno 论坛 ✔ ✔ ✔ - ✔ 国内开源 论坛系统\n所有 笔趣阁 网站 - - ✔ - - 小说网站常用的 笔趣阁 模板\n部分 Typecho 网站 ✔ ✔ - - ✔ 适配一些常见的 Typecho 网站主题\n部分 WordPress 网站 ✔ ✔ - - ✔ 适配一些常见的 WordPress 网站主题\n部分 在线影视模板 网站 ✔ ✔ - - ✔ 适配一些常见的 在线影视 网站模板\n部分 自带无缝翻页 网站 ✔ ✔ - - ✔ 适配一些支持 [加载更多] 的网站 (为了避免误触，规则比较保守)\n\n[搜索引擎] &lt;\n\n谷歌 (Google) - - - - ✔ (建议开启各搜索引擎设置中的 新标签页打开链接 选项，以提高使用体验)\n必应 (Bing) - - - - ✔ (微软的)\n百度 - - - - ✔\n搜狗 - - - - ✔\n搜狗微信 ✔ ✔ - - ✔ (微信文章/公众号搜索)\n头条搜索 - - - - ✔\n神马搜索 - - - - ✔\n无追搜索 - - - - ✔\n360 搜索 - - - - ✔\nSearxng - - - - ✔ (对各大搜索引擎的聚合搜索)\nDuckDuckGo - - - - ✔ (以上这几个均支持手机版)\nStartpage - - - - ✔\nYandex - - - - ✔ (俄罗斯的，如果卡住说明弹验证码了，请刷新网页后继续…)\nYahoo - - - - ✔ (包含 Yahoo JP 域名)\nQwant - - - - ✔\nEcosia - - - - ✔\nGoobe - - - - ✔ (代码相关)\nMagi - - - - ✔\n轻搜 - - - - ✔\nASK - - - - ✔\n\n[社区] &lt;\n\n贴吧 - ✔ ✔ - ✔ (如要发帖请点击右侧悬浮 [发帖] 按钮 或 点击左下角页码暂停翻页)\n豆瓣 - ✔ ✔ ✔ - (短评、影评、评论、小组帖子 等等…)\n知乎 - ✔ - - - (用户主页下的回答、文章 与 收藏夹页)\n微博 - - - ✔ -\n天涯 - ✔ ✔ - -\n虎扑 - ✔ ✔ - -\nNGA - ✔ ✔ - - (玩家相关)\nV2EX ✔ ✔ - - -\n煎蛋网 ✔ ✔ - ✔ -\n水木社区 - ✔ ✔ - - (清华论坛)\n龙的天空 - ✔ ✔ - - (小说相关)\n看雪论坛 - ✔ - - - (安全相关)\n番组计划 (Bangumi) - ✔ - - - (二次元版豆瓣？)\n懂车帝论坛 - ✔ - - -\n宽带山论坛 ✔ ✔ ✔ - - (上海地方论坛)\n篱笆网论坛 ✔ ✔ ✔ - ✔ (上海地方论坛)\n淘股吧论坛 ✔ ✔ ✔ - -\n芥子空间论坛 - ✔ - - - (手游相关)\nLowEndTalk ✔ ✔ ✔ - - (海外服务器相关)\nRuTracker - ✔ ✔ - - (俄罗斯学习资源论坛)\nA 岛 - ✔ ✔ - -\nB 站 (Bilibili) - - - - ✔\n\n[设计/素材] &lt;\n\nPixiv - ✔ - - ✔ (插画)\nVilipix - ✔ - - ✔ (内容来自 Pixiv，下同 ⤵)\nPixivision - ✔ - - ✔\n站酷 (ZCOOL) ✔ - - - - (图片/设计素材，下同 ⤵)\n千图网 - ✔ - - ✔\n千库网 - ✔ - - ✔\n昵图网 - ✔ - - ✔\n众图网 - ✔ - - ✔\n我图网 - ✔ - - ✔\n包图网 - ✔ - - ✔\n图怪兽 - ✔ - - ✔\nPixabay - ✔ - - ✔\n搜图神器 ✔ - - - ✔\n素材中国 - ✔ - - ✔\niconfont - - - - ✔ (图标，下同 ⤵)\nIconArchive - - - - ✔\nMixkit - ✔ - - ✔ (视频/音乐素材)\n普象网 ✔ ✔ - - ✔ (产品设计，下同 ⤵)\n学犀牛 ✔ ✔ ✔ - ✔\n欧模网 - ✔ - - ✔ (模型素材，下同 ⤵)\n下得乐 - ✔ - - ✔\n\n[游戏] &lt;\n\n3DM - ✔ ✔ - - (包括论坛，下同 ⤵)\n游侠网 - ✔ ✔ - -\n游民星空 - - ✔ - -\n3DM MOD - ✔ - - ✔ (游戏 MOD，下同 ⤵)\nCurseForge - ✔ - - ✔\nNexusMods - ✔ - - ✔\nSteam 创意工坊 ✔ ✔ - - ✔ (创意工坊 MOD 文件下载1/下载2)\nSteam 活动评论 - - - ✔ - (商家动态/活动下的评论区)\n小霸王其乐无穷 ✔ ✔ - - ✔\nSwitch520 ✔ ✔ - - ✔\nCS.RIN.RU - ✔ ✔ - ✔ (国外的游戏分享网站，下同 ⤵)\nByrutor ✔ ✔ - - -\nCrackhub213 ✔ ✔ - - ✔\nFitGirl Repacks ✔ ✔ - - ✔\nMasquerade Repacks ✔ ✔ - - ✔\n\n[影视/在线] &lt;\n\n茶杯狐 - - ✔ - ✔ (以下部分网站同时包含 BT/动漫)\nNO 视频 - ✔ - - ✔\n低端影视 ✔ ✔ - - ✔\n奈菲影视 - ✔ - - ✔\n在线之家 - ✔ - - ✔\n片吧影院 - ✔ - - ✔\n嗯哩嗯哩 - ✔ - - ✔\n91 美剧网 - ✔ - - ✔\n真不卡影院 - ✔ - - ✔\nZzzFun 动漫 - ✔ - - ✔ (仅动漫，下同 ⤵)\n吐槽弹幕网 - ✔ - - ✔\n樱花动漫 - ✔ - - ✔\n怡萱动漫 - ✔ - - ✔\n妮可动漫 - ✔ - - ✔\n漫岛动漫 - ✔ - - ✔\nAGE 动漫 - ✔ - - ✔\n233 动漫 - ✔ - - ✔\nAnime1 ✔ - - - ✔\n\n[BT/下载] &lt;\n\n音范丝 ✔ ✔ - - ✔\n片源网 - - - - ✔\n磁力狗 - - - - ✔\n雨花阁 - - - - ✔\nBT 之家 ✔ ✔ - - ✔ (匹配所有包含 btbtt 的域名)\nBD 影视 - ✔ - - ✔\n高清电台 ✔ ✔ - - ✔\n爱恋动漫 ✔ ✔ - - ✔ (动漫，下同 ⤵)\n末日动漫 ✔ ✔ - - ✔ (包括 国际站)\n动漫花园 ✔ ✔ - - ✔ (包括 镜像站)\n简单动漫 ✔ ✔ - - ✔\n零度动漫 ✔ ✔ - - ✔\nACG.RIP ✔ ✔ - - ✔\n萌番组 ✔ ✔ - - ✔ (包括 Lite 版)\nMioBT ✔ ✔ - - ✔\nSkrBT ✔ ✔ - - ✔ (匹配所有包含 skrbt 的域名)\nNyaa ✔ - - - ✔\nYTS - ✔ - - ✔ (这个 + 下面这两个算是我最常用的了~)\n1337x ✔ ✔ - - ✔ (包括 镜像站)\nRARBG ✔ ✔ - - ✔ (包括 镜像站)\nZooqle - ✔ - - ✔\nKickass - ✔ - - ✔\nWebHD ✔ - - - ✔ (与 SubHD 字幕网站配套)\nMINI4K - ✔ - - ✔ (与 A4k 字幕网站配套)\nTrackerslist.com - - - - - (分享我自制自用的 Tracker 列表，多少会提高点 BT 下载速度~ 12k+⭐)\n\n[字幕] &lt;\n\nA4k ✔ ✔ - - ✔\nSubHD - ✔ - - ✔\n伪射手网 - ✔ - - ✔\n点点字幕 - - - - ✔\n中文字幕网 - ✔ - - ✔\n字幕库 ✔ ✔ - - ✔\n\n[漫画] &lt;\n\n漫本 - ✔ ✔ - -\n好漫 6 - ✔ ✔ - ✔\n6 漫画 - ✔ ✔ - -\n动漫狂 - ✔ ✔ - ✔ (部分早期章节，因网站问题而无法自动衔接下一章)\n动漫啦 - ✔ ✔ - ✔\n漫漫聚 - - ✔ - -\n漫画猫 - ✔ ✔ - ✔\n漫画皮 - ✔ ✔ - -\n漫画人 - - ✔ - -\n漫画柜 - ✔ ✔ - ✔\n36漫画 - ✔ ✔ - ✔\n爱漫画 - ✔ ✔ - ✔\n漫画 DB - ✔ ✔ - ✔\nHiComic (嗨漫画) - - ✔ - -\n动漫之家 (主站) - ✔ ✔ - ✔ (这网站两个域名内容不一样 ⤵)\n动漫之家 (日漫) - ✔ ✔ - ✔\n阿狸漫画 - ✔ ✔ - ✔\n快岸漫画 - ✔ ✔ - ✔\n动漫之家 - - ✔ - -\n动漫戏说 - ✔ ✔ - -\n优酷漫画 - ✔ ✔ - ✔\n拷贝漫画 - ✔ ✔ - -\n木马漫画 - ✔ ✔ - -\n漫画星球 - ✔ ✔ - -\n风之动漫 - - ✔ - -\n包子漫画 - - ✔ - -\n乐语漫画 - ✔ ✔ - ✔\n新新漫画 - ✔ ✔ - ✔\n188漫画网 - - ✔ - -\n古风漫画网 - ✔ ✔ - ✔\n砂之船动漫家 - ✔ ✔ - ✔\nMangabz 漫画 - ✔ ✔ - ✔\nXmanhua 漫画 - ✔ ✔ - ✔\nCOCOMANGA 漫画 - ✔ ✔ - ✔\n\n[小说] &lt;\n\n起点中文 - ✔ ✔ - -\n七猫中文 - - ✔ - -\n知轩藏书 - ✔ - - - (仅下载)\n宝书网 - ✔ - - - (仅下载)\n御书网 - ✔ ✔ - -\nowLook - - ✔ - - (支持在线阅读的小说搜索引擎)\n铅笔小说 - ✔ ✔ - -\n无错小说网 - ✔ ✔ - ✔\n读书族小说网 - - ✔ - -\n哔哩轻小说 - ✔ ✔ - - (包括 手机版，轻小说，下同 ⤵)\n话本小说网 - - ✔ - -\n轻之文库 - ✔ ✔ - ✔\nArchive of OurOwn - ✔ ✔ - ✔\n精品书源 - - - - - (分享我自制自用的「阅读」APP 精品书源 1.6k+⭐)\n\n[软件分享] &lt;\n\n蓝鲨 ✔ ✔ - - ✔\n不死鸟 ✔ ✔ - - ✔\n分享者 ✔ ✔ - - ✔\n扩展迷 - ✔ - - - (浏览器扩展)\nMacWK - ✔ - - ✔ (MAC 相关)\n小众软件 ✔ ✔ - - ✔\n乐软博客 ✔ ✔ - - ✔\n果核剥壳 ✔ ✔ - - ✔\n六音软件 ✔ ✔ - - ✔\n反斗软件 ✔ ✔ - - ✔\n微当下载 ✔ ✔ - - ✔\n大眼仔旭 - ✔ - - ✔\n423Down ✔ ✔ - ✔ ✔\n发烧友绿软 ✔ ✔ - - ✔\n异次元软件 ✔ ✔ - ✔ ✔\n悪魔の小站 ✔ ✔ - - ✔\n老殁殁漂遥 ✔ ✔ - - ✔\n腾龙工作室 ✔ ✔ - - -\n异星软件空间 ✔ ✔ - - ✔\nNite07 的小窝 ✔ - - - -\nSordum ✔ ✔ - - ✔ (国外的软件分享网站，下同 ⤵)\nWinaero - ✔ - - -\nLRepacks ✔ ✔ - - -\nDlAndroid - ✔ - - ✔ (国外安卓 App 相关)\nWinhelponline ✔ ✔ - - -\nWindowsLatest ✔ ✔ - - -\nTheWindowsClub ✔ ✔ - - -\n\n[学术] &lt;\n\nWiley Online Library - - - - ✔\nACS (Publications) - - - - ✔\nLibrary Genesis - - - - ✔ (匹配所有包含 libgen 的域名)\nScienceDirect - - - - ✔\nZ-Library - - - - ✔ (包括 镜像站)\nPubMed - - - - ✔\nX-MOL - ✔ - - ✔\n维普网 - - - - ✔\n科研通 - ✔ ✔ - ✔\n酷科研 - - ✔ - -\n小木虫 - ✔ ✔ - ✔\n百度学术 - ✔ - - ✔\n必应学术 (Bing) - - - - ✔\n谷歌学术 (Google) - - - - ✔ 包括 镜像站1 / 2\n国家自然科学基金 - - ✔ - -\n\n[编程/技术] &lt;\n\nStackOverflow - ✔ - - ✔ 技术问答\nSegmentFault - ✔ - - ✔\nW3Cschool - ✔ - - - 编程教程\nW3school - ✔ - - -\n菜鸟教程 - ✔ - - -\n博客园 ✔ ✔ - - ✔ 技术博客\n51CTO ✔ ✔ - - ✔\nGitee - ✔ ✔ ✔ ✔ 开源分享\nGithub ✔ ✔ ✔ ✔ ✔ (建议搭配我另一个 Github 增强 - 高速下载 油猴脚本~)\n\n[资讯/科技] &lt;\n\nScienceAlert ✔ ✔ - - -\n果壳网 ✔ ✔ - ✔ -\n蓝点网 - ✔ - - -\n可能吧 ✔ ✔ - - -\n超能网 ✔ ✔ - - -\nIT之家 - ✔ - - -\n36 氪 - ✔ - - -\n\n[其他] &lt;\n\nIMDb - ✔ - - ✔\n烂番茄 - ✔ - - ✔\n致美化 - ✔ - - - 系统美化\n蓝奏云 - ✔ - - - 网盘 (后台及分享链接列表)\n新片场 - ✔ - - - 视频短片\nwikiHow - ✔ - - ✔ 指南\nAfreecaTV ✔ ✔ - - - 直播 (大都是韩国人)\nGreasyFork ✔ ✔ - ✔ ✔ 本站\nUserScript - - - - ✔ 油猴脚本的聚合搜索 (Tampermonkey 作者做的)\nUserStyles ✔ ✔ - ✔ ✔\nQuicker ✔ ✔ - ✔ ✔\nXposed - ✔ - - ✔\n书签地球 ✔ - - - ✔\n什么值得买 - ✔ - - ✔\n没得比导购 - ✔ - - ✔\n叽哩叽哩日报 - ✔ - - -\n彼岸图网 ✔ ✔ - - - 壁纸 (下同 ⤵)\n必应壁纸 ✔ ✔ - - -\n动漫壁纸 - ✔ - - ✔\n动漫壁纸2 - ✔ - - ✔\nHDQwalls ✔ ✔ - - ✔\nNastol ✔ ✔ - - ✔\n以上仅为一小部分… 持续添加中，欢迎申请~\npotential useful websites:\nhttps://greasyfork.org/en/users/sign_in?return_to=%2Fen%2Fsc…%25E6%2597%25A0%25E7%25BC%259D%25E7%25BF%25BB%25E9%25A1%25B5 debugger eval code:1:60\nhttps://greasyfork.org/scripts/419215-%E8%87%AA%E5%8A%A8%E6%…8%87%AA%E5%8A%A8%E6%97%A0%E7%BC%9D%E7%BF%BB%E9%A1%B5.user.js debugger eval code:1:60\nhttps://greasyfork.org/en/help/installing-user-scripts debugger eval code:1:60\nhttps://greasyfork.org/scripts/419081-%E7%9F%A5%E4%B9%8E%E5%…E%E5%BC%BA/code/%E7%9F%A5%E4%B9%8E%E5%A2%9E%E5%BC%BA.user.js debugger eval code:1:60\nhttps://github.com/XIU2/UserScript debugger eval code:1:60\nhttps://greasyfork.org/en/scripts/419215-%E8%87%AA%E5%8A%A8%E6%97%A0%E7%BC%9D%E7%BF%BB%E9%A1%B5/feedback#post-discussion debugger eval code:1:60\nhttps://greasyfork.org/en/reports/new?item_class=script&item_id=419215 debugger eval code:1:60\nhttps://www.jsdelivr.com/package/gh/XIU2/UserScript debugger eval code:1:60\nhttps://www.discuz.net/ debugger eval code:1:60\nhttps://www.phpbb.com/community/ debugger eval code:1:60\nhttps://xenforo.com/community/ debugger eval code:1:60\nhttps://demo.nexusphp.org/ debugger eval code:1:60\nhttps://discuss.flarum.org/ debugger eval code:1:60\nhttps://www.axiuno.com/ debugger eval code:1:60\nhttps://www.google.com/ debugger eval code:1:60\nhttps://cn.bing.com/ debugger eval code:1:60\nhttps://www.baidu.com/ debugger eval code:1:60\nhttps://www.sogou.com/ debugger eval code:1:60\nhttps://weixin.sogou.com/ debugger eval code:1:60\nhttps://www.toutiao.com/ debugger eval code:1:60\nhttps://m.sm.cn/ debugger eval code:1:60\nhttps://www.wuzhuiso.com/ debugger eval code:1:60\nhttps://www.so.com/ debugger eval code:1:60\nhttps://searx.owlook.com.cn/ debugger eval code:1:60\nhttps://duckduckgo.com/ debugger eval code:1:60\nhttps://www.startpage.com/ debugger eval code:1:60\nhttps://yandex.com/ debugger eval code:1:60\nhttps://search.yahoo.com/ debugger eval code:1:60\nhttps://www.qwant.com/ debugger eval code:1:60\nhttps://www.ecosia.org/ debugger eval code:1:60\nhttps://goobe.io/ debugger eval code:1:60\nhttps://magi.com/ debugger eval code:1:60\nhttps://www.qingsearch.com/ debugger eval code:1:60\nhttps://www.ask.com/ debugger eval code:1:60\nhttps://tieba.baidu.com/ debugger eval code:1:60\nhttps://movie.douban.com/ debugger eval code:1:60\nhttps://www.zhihu.com/ debugger eval code:1:60\nhttps://weibo.com/ debugger eval code:1:60\nhttps://bbs.tianya.cn/ debugger eval code:1:60\nhttps://bbs.hupu.com/ debugger eval code:1:60\nhttps://bbs.nga.cn/ debugger eval code:1:60\nhttps://v2ex.com/ debugger eval code:1:60\nhttps://jandan.net/ debugger eval code:1:60\nhttps://www.mysmth.net/ debugger eval code:1:60\nhttps://www.lkong.com/ debugger eval code:1:60\nhttps://bbs.pediy.com/ debugger eval code:1:60\nhttps://bangumi.tv/ debugger eval code:1:60\nhttps://www.dongchedi.com/car_fans_community debugger eval code:1:60\nhttps://club.kdslife.com/ debugger eval code:1:60\nhttps://www.libaclub.com/ debugger eval code:1:60\nhttps://www.taoguba.com.cn/ debugger eval code:1:60\nhttps://bbs.lieyou888.com/ debugger eval code:1:60\nhttps://lowendtalk.com/ debugger eval code:1:60\nhttps://rutracker.org/ debugger eval code:1:60\nhttps://adnmb3.com/ debugger eval code:1:60\nhttps://search.bilibili.com/ debugger eval code:1:60\nhttps://www.pixiv.net/ debugger eval code:1:60\nhttps://www.vilipix.com/ debugger eval code:1:60\nhttps://www.pixivision.net/ debugger eval code:1:60\nhttps://www.zcool.com.cn/ debugger eval code:1:60\nhttps://www.58pic.com/ debugger eval code:1:60\nhttps://588ku.com/ debugger eval code:1:60\nhttps://www.nipic.com/ debugger eval code:1:60\nhttps://www.ztupic.com/ debugger eval code:1:60\nhttps://www.ooopic.com/ debugger eval code:1:60\nhttps://ibaotu.com/ debugger eval code:1:60\nhttps://818ps.com/ debugger eval code:1:60\nhttps://pixabay.com/ debugger eval code:1:60\nhttps://www.logosc.cn/so/ debugger eval code:1:60\nhttp://www.sccnn.com/ debugger eval code:1:60\nhttps://www.iconfont.cn/ debugger eval code:1:60\nhttps://iconarchive.com/ debugger eval code:1:60\nhttps://mixkit.co/ debugger eval code:1:60\nhttps://www.puxiang.com/ debugger eval code:1:60\nhttps://www.xuexiniu.com/ debugger eval code:1:60\nhttps://www.om.cn/ debugger eval code:1:60\nhttp://www.xiadele.com/ debugger eval code:1:60\nhttps://www.3dmgame.com/ debugger eval code:1:60\nhttps://www.ali213.net/ debugger eval code:1:60\nhttps://www.gamersky.com/ debugger eval code:1:60\nhttps://mod.3dmgame.com/ debugger eval code:1:60\nhttps://www.curseforge.com/ debugger eval code:1:60\nhttps://www.nexusmods.com/ debugger eval code:1:60\nhttps://steamcommunity.com/workshop/browse/?appid=550&browsesort=trend&section=readytouseitems debugger eval code:1:60\nhttps://steamworkshopdownloader.io/ debugger eval code:1:60\nhttp://steamworkshop.download/ debugger eval code:1:60\nhttps://steamcommunity.com/ debugger eval code:1:60\nhttps://www.yikm.net/ debugger eval code:1:60\nhttps://switch520.com/ debugger eval code:1:60\nhttps://cs.rin.ru/forum/viewforum.php?f=10 debugger eval code:1:60\nhttps://byrut.org/ debugger eval code:1:60\nhttps://crackhub.site/ debugger eval code:1:60\nhttps://fitgirl-repacks.site/ debugger eval code:1:60\nhttps://masquerade.site/ debugger eval code:1:60\nhttps://www.cupfox.app/ debugger eval code:1:60\nhttps://www.novipnoad.com/ debugger eval code:1:60\nhttps://ddrk.me/ debugger eval code:1:60\nhttps://www.nfmovies.com/ debugger eval code:1:60\nhttps://www.zxzjtv.com/ debugger eval code:1:60\nhttps://www.pianba.tv/ debugger eval code:1:60\nhttps://enlienli.com/ debugger eval code:1:60\nhttps://mjw21.com/ debugger eval code:1:60\nhttps://www.zhenbuka3.com/ debugger eval code:1:60\nhttp://www.zzzfun.com/ debugger eval code:1:60\nhttps://www.tucao.one/ debugger eval code:1:60\nhttp://www.imomoe.live/ debugger eval code:1:60\nhttp://www.yxdm.li/ debugger eval code:1:60\nhttp://www.nicotv.me/ debugger eval code:1:60\nhttps://www.mandao.tv/ debugger eval code:1:60\nhttps://www.agemys.com/ debugger eval code:1:60\nhttps://www.dm233.cc/ debugger eval code:1:60\nhttps://anime1.me/ debugger eval code:1:60\nhttps://www.yinfans.me/ debugger eval code:1:60\nhttps://pianyuan.org/ debugger eval code:1:60\nhttp://clg.im/ debugger eval code:1:60\nhttps://www.yuhuage52.xyz/ debugger eval code:1:60\nhttps://btbtt20.com/ debugger eval code:1:60\nhttps://www.bd2020.com/ debugger eval code:1:60\nhttps://gaoqing.fm/ debugger eval code:1:60\nhttps://www.kisssub.org/ debugger eval code:1:60\nhttps://share.acgnx.net/ debugger eval code:1:60\nhttps://www.acgnx.se/ debugger eval code:1:60\nhttps://share.dmhy.org/ debugger eval code:1:60\nhttps://dmhy.anoneko.com/ debugger eval code:1:60\nhttps://www.36dm.club/ debugger eval code:1:60\nhttps://bt.acgzero.com/ debugger eval code:1:60\nhttps://acg.rip/ debugger eval code:1:60\nhttps://bangumi.moe/ debugger eval code:1:60\nhttps://banguami.moe/lite debugger eval code:1:60\nhttps://miobt.com/ debugger eval code:1:60\nhttps://skrbtga.xyz/ debugger eval code:1:60\nhttps://nyaa.si/ debugger eval code:1:60\nhttps://yts.mx/ debugger eval code:1:60\nhttps://1337x.to/ debugger eval code:1:60\nhttps://rarbg.to/ debugger eval code:1:60\nhttps://zooqle.com/ debugger eval code:1:60\nhttps://kickasss.to/ debugger eval code:1:60\nhttps://webhd.cc/ debugger eval code:1:60\nhttps://www.mini4k.com/ debugger eval code:1:60\nhttps://trackerslist.com/ debugger eval code:1:60\nhttps://www.a4k.net/ debugger eval code:1:60\nhttps://subhd.tv/ debugger eval code:1:60\nhttps://assrt.net/ debugger eval code:1:60\nhttp://www.ddzimu.com/ debugger eval code:1:60\nhttps://cn.zimuzimu.com/ debugger eval code:1:60\nhttps://zimuku.org/ debugger eval code:1:60\nhttps://www.manben.com/ debugger eval code:1:60\nhttps://www.haoman6.com/ debugger eval code:1:60\nhttp://www.sixmh7.com/ debugger eval code:1:60\nhttps://www.cartoonmad.com/ debugger eval code:1:60\nhttps://www.dongman.la/ debugger eval code:1:60\nhttp://www.manmanju.com/ debugger eval code:1:60\nhttps://www.maofly.com/ debugger eval code:1:60\nhttps://www.manhuapi.com/ debugger eval code:1:60\nhttps://www.manhuaren.com/ debugger eval code:1:60\nhttps://www.mhgui.com/ debugger eval code:1:60\nhttps://www.36manga.com/ debugger eval code:1:60\nhttps://www.imanhuaw.net/ debugger eval code:1:60\nhttps://www.manhuadb.com/ debugger eval code:1:60\nhttps://www.hicomic.net/ debugger eval code:1:60\nhttps://www.dmzj.com/ debugger eval code:1:60\nhttps://manhua.dmzj.com/ debugger eval code:1:60\nhttp://www.alimanhua.com/ debugger eval code:1:60\nhttps://www.kanbook.net/ debugger eval code:1:60\nhttps://manhua.dmzj.com/ debugger eval code:1:60\nhttps://comic.acgn.cc/ debugger eval code:1:60\nhttps://www.ykmh.com/ debugger eval code:1:60\nhttps://copymanga.net/ debugger eval code:1:60\nhttps://www.omyschool.com/ debugger eval code:1:60\nhttp://www.mhxqiu1.com/ debugger eval code:1:60\nhttp://manhua.fffdm.com/ debugger eval code:1:60\nhttps://www.webmota.com/ debugger eval code:1:60\nhttps://www.leyuman.com/ debugger eval code:1:60\nhttps://www.77mh.xyz/ debugger eval code:1:60\nhttp://www.ccshwy.com/all/ debugger eval code:1:60\nhttps://www.gufengmh9.com/ debugger eval code:1:60\nhttps://www.szcdmj.com/ debugger eval code:1:60\nhttps://mangabz.com/ debugger eval code:1:60\nhttps://www.xmanhua.com/ debugger eval code:1:60\nhttps://www.cocomanga.com/ debugger eval code:1:60\nhttps://www.qidian.com/ debugger eval code:1:60\nhttps://www.qimao.com/ debugger eval code:1:60\nhttp://zxcs.me/ debugger eval code:1:60\nhttps://www.baoshuu.com/ debugger eval code:1:60\nhttps://www.yushubo.com/ debugger eval code:1:60\nhttps://www.owlook.com.cn/ debugger eval code:1:60\nhttps://www.23qb.com/ debugger eval code:1:60\nhttps://www.xineyby.com/ debugger eval code:1:60\nhttps://m.xiaoshuo77.net/ debugger eval code:1:60\nhttps://www.linovelib.com/ debugger eval code:1:60\nhttps://w.linovelib.com/ debugger eval code:1:60\nhttps://www.ihuaben.com/ debugger eval code:1:60\nhttps://www.linovel.net/ debugger eval code:1:60\nhttps://archiveofourown.org/ debugger eval code:1:60\nhttps://yuedu.xiu2.xyz/ debugger eval code:1:60\nhttps://www.lan-sha.com/ debugger eval code:1:60\nhttps://iao.su/ debugger eval code:1:60\nhttps://www.sharerw.com/ debugger eval code:1:60\nhttps://www.extfans.com/ debugger eval code:1:60\nhttps://www.macwk.com/ debugger eval code:1:60\nhttps://www.appinn.com/ debugger eval code:1:60\nhttps://www.isharepc.com/ debugger eval code:1:60\nhttps://www.ghxi.com/ debugger eval code:1:60\nhttps://www.6yit.com/ debugger eval code:1:60\nhttp://www.apprcn.com/ debugger eval code:1:60\nhttps://www.weidown.com/ debugger eval code:1:60\nhttps://www.dayanzai.me/ debugger eval code:1:60\nhttps://www.423down.com/ debugger eval code:1:60\nhttps://fsylr.com/ debugger eval code:1:60\nhttps://www.iplaysoft.com/ debugger eval code:1:60\nhttp://www.mubolin.cn:99/ debugger eval code:1:60\nhttps://www.mpyit.com/ debugger eval code:1:60\nhttps://www.tenlonstudio.com/ debugger eval code:1:60\nhttps://www.yxssp.com/ debugger eval code:1:60\nhttps://www.nite07.com/ debugger eval code:1:60\nhttps://www.sordum.org/ debugger eval code:1:60\nhttps://winaero.com/ debugger eval code:1:60\nhttps://lrepacks.net/ debugger eval code:1:60\nhttps://dlandroid.com/ debugger eval code:1:60\nhttps://www.winhelponline.com/blog/ debugger eval code:1:60\nhttps://www.windowslatest.com/ debugger eval code:1:60\nhttps://www.thewindowsclub.com/ debugger eval code:1:60\nhttps://onlinelibrary.wiley.com/ debugger eval code:1:60\nhttps://pubs.acs.org/ debugger eval code:1:60\nhttps://libgen.rs/ debugger eval code:1:60\nhttps://www.sciencedirect.com/ debugger eval code:1:60\nhttps://z-lib.org/ debugger eval code:1:60\nhttps://pubmed.ncbi.nlm.nih.gov/ debugger eval code:1:60\nhttps://www.x-mol.com/ debugger eval code:1:60\nhttp://www.cqvip.com/ debugger eval code:1:60\nhttps://www.ablesci.com/ debugger eval code:1:60\nhttps://www.coolkeyan.com/ debugger eval code:1:60\nhttp://muchong.com/bbs debugger eval code:1:60\nhttps://xueshu.baidu.com/ debugger eval code:1:60\nhttps://cn.bing.com/academic debugger eval code:1:60\nhttps://scholar.google.com/ debugger eval code:1:60\nhttps://sc.panda321.com/ debugger eval code:1:60\nhttps://xs2.dailyheadlines.cc/ debugger eval code:1:60\nhttps://output.nsfc.gov.cn/ debugger eval code:1:60\nhttps://stackoverflow.com/ debugger eval code:1:60\nhttps://segmentfault.com/ debugger eval code:1:60\nhttps://www.w3cschool.cn/ debugger eval code:1:60\nhttps://www.w3school.com.cn/ debugger eval code:1:60\nhttps://www.runoob.com/ debugger eval code:1:60\nhttps://www.cnblogs.com/ debugger eval code:1:60\nhttps://www.51cto.com/ debugger eval code:1:60\nhttps://gitee.com/ debugger eval code:1:60\nhttps://www.sciencealert.com/ debugger eval code:1:60\nhttps://www.guokr.com/ debugger eval code:1:60\nhttps://www.landian.vip/ debugger eval code:1:60\nhttps://kenengba.com/ debugger eval code:1:60\nhttps://www.expreview.com/ debugger eval code:1:60\nhttps://www.ithome.com/ debugger eval code:1:60\nhttps://36kr.com/ debugger eval code:1:60\nhttps://www.imdb.com/ debugger eval code:1:60\nhttps://www.rottentomatoes.com/ debugger eval code:1:60\nhttps://zhutix.com/ debugger eval code:1:60\nhttps://lanzou.com/ debugger eval code:1:60\nhttps://www.xinpianchang.com/ debugger eval code:1:60\nhttps://zh.wikihow.com/ debugger eval code:1:60\nhttps://www.afreecatv.com/ debugger eval code:1:60\nhttps://www.userscript.zone/ debugger eval code:1:60\nhttps://userstyles.world/ debugger eval code:1:60\nhttps://getquicker.net/ debugger eval code:1:60\nhttps://repo.xposed.info/module-overview debugger eval code:1:60\nhttps://www.bookmarkearth.com/ debugger eval code:1:60\nhttps://www.smzdm.com/ debugger eval code:1:60\nhttps://www.meidebi.com/ debugger eval code:1:60\nhttps://www.jiligamefun.com/ debugger eval code:1:60\nhttps://pic.netbian.com/ debugger eval code:1:60\nhttps://bing.ioliu.cn/ debugger eval code:1:60\nhttps://konachan.net/ debugger eval code:1:60\nhttps://anime-pictures.net/ debugger eval code:1:60\nhttps://hdqwalls.com/ debugger eval code:1:60\nhttps://www.nastol.com.ua/ debugger eval code:1:60\nhttps://www.snapmail.cc/ debugger eval code:1:60\nhttps://pan.lanzouo.com/b073l8d1e debugger eval code:1:60\nhttps://microsoftedge.microsoft.com/addons/detail/tampermonkey/iikmkjmpaadaobahmlepeloendndfphd?hl=zh-CN debugger eval code:1:60\nhttps://zhuanlan.zhihu.com/p/276027099"
  },
  {
    "objectID": "posts/55cc27e9-42da-45d6-8687-40b2d4ef833d/index.html",
    "href": "posts/55cc27e9-42da-45d6-8687-40b2d4ef833d/index.html",
    "title": "TypeMonkey 字说 OSS alternative",
    "section": "",
    "text": "javascript version in web:\nhttps://nostarsnow.github.io/2019/01/20/typemonkey/\nhttps://github.com/nostarsnow/typeMonkey.js"
  },
  {
    "objectID": "posts/1c5d0334-defa-4c85-8fc4-11f67ce8b29b/index.html",
    "href": "posts/1c5d0334-defa-4c85-8fc4-11f67ce8b29b/index.html",
    "title": "Topic Generation 话题发现 趋势发现 热点发现",
    "section": "",
    "text": "Topic Generation 话题发现 趋势发现 热点发现 文本分类\nbert documentation\nhttps://github.com/MaartenGr/BERTopic\n新词发现（可用于挖掘热点 热词 蓝海词）\nhttps://github.com/zhanzecheng/Chinese_segment_augment\nhttps://github.com/bojone/word-discovery\nhttps://github.com/blmoistawinde/HarvestText\n文本分类 文本匹配 文本检索\nhttps://github.com/lining0806/Naive-Bayes-Classifier\nhttps://github.com/649453932/Bert-Chinese-Text-Classification-Pytorch\nhttps://github.com/gaussic/text-classification-cnn-rnn\nhttps://github.com/yongzhuo/Keras-TextClassification\nhttps://github.com/youthpasses/bayes_classifier\nhttps://github.com/Roshanson/TextInfoExp\nhttps://github.com/aceimnorstuvwxz/toutiao-multilevel-text-classfication-dataset\nhttps://github.com/CementMaker/cnn_lstm_for_text_classify\nhttps://github.com/hellonlp/classifier_multi_label_textcnn\nhttps://github.com/cjymz886/text-cnn\nhttps://github.com/terrifyzhao/bert-utils\nhttps://github.com/649453932/Chinese-Text-Classification-Pytorch\nhttps://github.com/HappyShadowWalker/ChineseTextClassify\nhttps://github.com/XqFeng-Josie/TextCNN\nhttps://github.com/tensorlayer/text-antispam\nhttps://github.com/MachineLP/TextMatch"
  },
  {
    "objectID": "posts/0f337a18-2d92-48d3-9e40-e6974bce622c/index.html",
    "href": "posts/0f337a18-2d92-48d3-9e40-e6974bce622c/index.html",
    "title": "Time Machine NAS macOS",
    "section": "",
    "text": "use rclone to periodically commit files to NAS (incremental only, do not delete things), or use rclone to copy files to external SSD\nbuy airport extreme as wireless router and backup device\n\nwhen in doubt, delete files under GUI instead of terminal\ncheck out commands for moving files into trash bin instead of direct removal on different OSes\n\nmy data under ~/works is lost. fuck.\nbuy me some ssd 512GB at least to do time machine backup.\nbuy m.2 ssd to reduce the size.\nuse usb-c cables to prevent inconvenience.\n\nthe filesystem will be formatted as APFS.\nneed a dedicated usb storage for it.\ndo not know if it is incremental backup."
  },
  {
    "objectID": "posts/e6a660fc-6caa-477f-a55a-51138ac4c3f2/index.html",
    "href": "posts/e6a660fc-6caa-477f-a55a-51138ac4c3f2/index.html",
    "title": "The phone",
    "section": "",
    "text": "Either seek for lighter phone or use multiple splitable vertical monitors. The monitors shall be movable."
  },
  {
    "objectID": "posts/6b1b9ebf-49d9-4e9a-9dbb-938a843559a0/index.html",
    "href": "posts/6b1b9ebf-49d9-4e9a-9dbb-938a843559a0/index.html",
    "title": "The Hack (Get password and tests)",
    "section": "",
    "text": "dirbuster has found something over “http://oa.lixin.edu.cn//test/”\n\nhttp://oa.lixin.edu.cn//admin (CODE:301|SIZE:237)\nhttp://oa.lixin.edu.cn//css (CODE:301|SIZE:235)\nhttp://oa.lixin.edu.cn//help (CODE:301|SIZE:236)\nhttp://oa.lixin.edu.cn//images (CODE:301|SIZE:238)\nhttp://oa.lixin.edu.cn//js (CODE:301|SIZE:234)\nhttp://oa.lixin.edu.cn//setup (CODE:301|SIZE:237)\nhttp://oa.lixin.edu.cn//template (CODE:301|SIZE:240)\nhttp://oa.lixin.edu.cn//test (CODE:301|SIZE:236)\nhttp://oa.lixin.edu.cn///admin (CODE:301|SIZE:237)\nhttp://oa.lixin.edu.cn///help (CODE:301|SIZE:236)\nhttp://oa.lixin.edu.cn///images (CODE:301|SIZE:238)\nhttp://oa.lixin.edu.cn///script (CODE:301|SIZE:238)\n\nsuspicious:\nhttp://oa.lixin.edu.cn/oanew/sys/taskcenterapp/*default/index.do\nportal (even in the internet):\nhttp://202.121.255.3:8080/portal\nScan this website with kali linux.\nThe Intranet Gateway For Campus: (maybe less hops?)\nhttps://app.topsec.com.cn\nmitmdump –mode socks5 –listen-port 8050 -w logs.log –flow-detail 3 –set stream_websocket=true\npdvpn.lixin.edu.cn\npdvpn2.lixin.edu.cn\nvpn.lixin.edu.cn\nvpn2.lixin.edu.cn\nxxb.lixin.edu.cn/jszl/57078.htm\n201960630:CHENweiyi0519\nhttps://cas.paas.lixin.edu.cn/cas/login?service=https%3A%2F%2Flxjw.lixin.edu.cn%2Fcas%2Flogin\nhttps://security-center.paas.lixin.edu.cn/find-pwd\n20039370\nmissing puzzle for changing password:\ntrial user:\n201960249\nfound russia hacker’s kali tool site: https://en.kali.tools/all/\napparently we have some issue with log4j and this could be our way in, the damn server.\nsniffing the whole damn campus is only possible if we know how to get into the same subnet of all people.\nhave searched related websites with site:lixin.edu.cn, could get more if keep doing so, using dnsenum.\nto get all site links with proper titles, we need to use playwright.\nnessus scanner has that 16 ips limitation, we need to crack/patch it first.\nto master kali linux, recommend to scrape kali_tools (https://tools.kali.org/) and tutorialspoint (https://www.tutorialspoint.com/kali_linux/index.htm) for kali, or just simply using manpage.\ncisco router is untouched till now. need we to scan it?\n(intermediate ip addresses)\ncurl ‘https://personal-security-center.paas.lixin.edu.cn/api/v1/personal/open/passwordStrategy/verify’\n\n-H ‘Connection: keep-alive’\n\n-H ‘sec-ch-ua: “(Not(A:Brand”;v=“8”, “Chromium”;v=“98”, “Google Chrome”;v=“98”’\n\n-H ‘Accept: application/json, text/plain, /’\n\n-H ‘Content-Type: application/json;charset=UTF-8’\n\n-H ‘sec-ch-ua-mobile: ?0’\n\n-H ‘User-Agent: Mozilla/5.0 (X11; CrOS aarch64 14371.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4729.0 Safari/537.36’\n\n-H ‘sec-ch-ua-platform: “Chrome OS”’\n\n-H ‘Origin: https://security-center.paas.lixin.edu.cn’\n\n-H ‘Sec-Fetch-Site: same-site’\n\n-H ‘Sec-Fetch-Mode: cors’\n\n-H ‘Sec-Fetch-Dest: empty’\n\n-H ‘Referer: https://security-center.paas.lixin.edu.cn/’\n\n-H ‘Accept-Language: en-US,en;q=0.9’\n\n–data-raw ‘{“password”:“abcdefABC”,“userId”:““}’\n\n–compressed\ncurl ‘https://personal-security-center.paas.lixin.edu.cn/api/v1/personal/open/forgotPassword/changePassword’\n\n-H ‘Connection: keep-alive’\n\n-H ‘sec-ch-ua: “(Not(A:Brand”;v=“8”, “Chromium”;v=“98”, “Google Chrome”;v=“98”’\n\n-H ‘Accept: application/json, text/plain, /’\n\n-H ‘Content-Type: application/json;charset=UTF-8’\n\n-H ‘sec-ch-ua-mobile: ?0’\n\n-H ‘User-Agent: Mozilla/5.0 (X11; CrOS aarch64 14371.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4729.0 Safari/537.36’\n\n-H ‘sec-ch-ua-platform: “Chrome OS”’\n\n-H ‘Origin: https://security-center.paas.lixin.edu.cn’\n\n-H ‘Sec-Fetch-Site: same-site’\n\n-H ‘Sec-Fetch-Mode: cors’\n\n-H ‘Sec-Fetch-Dest: empty’\n\n-H ‘Referer: https://security-center.paas.lixin.edu.cn/’\n\n-H ‘Accept-Language: en-US,en;q=0.9’\n\n–data-raw ‘{“confirmPassword”:“abc123ABC”,“newPassword”:“abc123ABC”,“nonce”:“YzhhZmZjYzktNWQ3Ny00MGU1LTg0ODgtYTYzZTMzMDZkMjU0XzE2NDAyNjg5MzcyNTY”}’\n\n–compressed"
  },
  {
    "objectID": "posts/d5cb277b-a52f-4dba-9013-cfab72c3f452/index.html",
    "href": "posts/d5cb277b-a52f-4dba-9013-cfab72c3f452/index.html",
    "title": "Terminal autocomplete",
    "section": "",
    "text": "Linux support in alpha, currently MacOS only:\nfig\nwarp\nwhy my vim stops working?\nwarp known issues"
  },
  {
    "objectID": "posts/1443d496-eceb-4206-8eb8-9c90cb0ad23e/index.html",
    "href": "posts/1443d496-eceb-4206-8eb8-9c90cb0ad23e/index.html",
    "title": "Source code semantic search tool",
    "section": "",
    "text": "Source code semantic search tool audit tool\ncan be used to analysis bilibili source code or large code base\nsourcegraph/sourcegraph:\nin go\ngithub/semantic:\nin haskell\nsonarqube:\ncode audit tool"
  },
  {
    "objectID": "posts/dea7a90b-a628-430f-b08c-130cbffef2c5/index.html",
    "href": "posts/dea7a90b-a628-430f-b08c-130cbffef2c5/index.html",
    "title": "Soul查看被拉黑之后对方的空间",
    "section": "",
    "text": "这个人的空间链接目前可以访问@2022 september 4\n可以在被拉黑了之后快速点击右上角的分享链接 分享到其他人 其他群里面 或者点击生成链接 即可在浏览器里面查看这个人的动态 但是不知道这个链接有没有时效性 现在看起来就是一堆乱码 app里面的分享也不知道有没有时效性\n不知道能不能搜索或者遍历 如果不能的话只能黑进去了 不过那样的话出来的数据肯定更多\n要知道被拉黑，本地肯定有用户的ID， 有了ID就可以拿过去到其他新注册的Soul账号上面使用 通过底层api访问\n可以考虑用Frida或者网上的一些脚本来分析破解SoulAPP 单独使用Frida估计不能利用Python遍历 还是需要破解协议证书才可以自由访问\nfrida usage, code examples for windows\nradare2 tutorial with code"
  },
  {
    "objectID": "posts/87b67abb-5976-4e4b-8dce-8279a62107ad/index.html",
    "href": "posts/87b67abb-5976-4e4b-8dce-8279a62107ad/index.html",
    "title": "Social Media Platforms",
    "section": "",
    "text": "收集总结流行的或者网页端的social media platform 方便爬取 mitm 发广告 智能交互\n从social media的本源分析 有广播 报纸 电视 邮件 wiki BBS（论坛） 贴吧 博客 即时通讯 流媒体推送 订阅 内容平台\n从形式上分析 有文章 评论 动态 聊天 视频 音频 图片"
  },
  {
    "objectID": "posts/560699e6-a134-4857-8cd6-c5832a5b1c16/index.html",
    "href": "posts/560699e6-a134-4857-8cd6-c5832a5b1c16/index.html",
    "title": "Sketch based applications",
    "section": "",
    "text": "magenta studio sketch completion\nawesome sketch based applications paper and code sketch syntheses inbetweening:\nhttps://github.com/MarkMoHR/Awesome-Sketch-Based-Applications#17-sketch-animationinbetweening\ndeep sketch based cartoon inbetweening:\nhttps://github.com/xiaoyu258/Inbetweening"
  },
  {
    "objectID": "posts/709fe723-3493-4dc5-b5f6-57c378469305/index.html",
    "href": "posts/709fe723-3493-4dc5-b5f6-57c378469305/index.html",
    "title": "Simple Viral Video Generators",
    "section": "",
    "text": "https://github.com/elebumm/RedditVideoMakerBot\n付费的解说视频生成器 营销号生成器\n有激活卡号 有官方网站 是关于自媒体自动化的\nhttps://github.com/suifengqjn/videoWater\nhttps://www.51ai.top"
  },
  {
    "objectID": "posts/a8ca56b1-2737-4e84-be05-89f7a435973a/index.html",
    "href": "posts/a8ca56b1-2737-4e84-be05-89f7a435973a/index.html",
    "title": "ShapeShifters",
    "section": "",
    "text": "https://termbin.com/qqft\nsimply do not take offer with some serious math. if really want to challenge yourself, go ahead and try, but do not even make a move to place the bid. you know you are sick of deadlines.\nthis shit is over but we still have the code and the pdf. still recoverable. it is about mmp/pbrt_v3 and the displacement map on a damn sphere. calculate occulusion and more according to input."
  },
  {
    "objectID": "posts/fc55eaec-6dd6-4c27-a127-750a62ad0d35/index.html",
    "href": "posts/fc55eaec-6dd6-4c27-a127-750a62ad0d35/index.html",
    "title": "Sentence Word order corrector",
    "section": "",
    "text": "design a model to accept fixed length word type sequence and output word order token. the token is used to decode the final word sequence, just like the convolution but different.\ninput can be both misplaced sentences or correct sentences\nlooking for english word order correctifier.(grammar)"
  },
  {
    "objectID": "posts/cf087d9e-f6ff-49bd-bb85-c19038e16e5e/index.html",
    "href": "posts/cf087d9e-f6ff-49bd-bb85-c19038e16e5e/index.html",
    "title": "Seek for cooperation and solution sharing",
    "section": "",
    "text": "I have been researching in automotive computers for years.\nTopics that you might be interested in that I have dug into:\n\nFree Energy Principle & Active Inference\nLLM Robotics\nQ-Star Learning\nRT-2 & RT-X dataset\nCrop & Zoom Based Attention\nRecursive Positional Encoding\nDynamic Reservoir Computing\nAutomotive Learning Rate\nHardware Mouse/Keyboard Control\nPhysical Robot Based HID Control\nBit-level Autoregressive Transformer\nBrowser-based AI Playground\nContainerized Console and GUI AI Playground\n\nI have dedicated repositories that you may be interested into:\n\nagi-computer-control: automotive computer, which can see, hear and operate\nmetalazero: multi-platform computer automation attempts\n\nOther similar projects that I am monitoring:\n\nGPT-4V-Act\nSingularGPT\ngpt-eyes\ngpt4v-browsing\nself-operating-computer\n\nApologize for my unorganized code structure. I am trying to improve development experience by AI generated documentation & usage demonstration and client-side LLM & semantic search, which may solve this long-standing task among all my previous repositories."
  },
  {
    "objectID": "posts/9f44093e-8b72-42cc-b860-3f96214e1a6a/index.html#my-custom-search-engine-built-upon-thesaurussynonymsantenyms-fzf-and-grep",
    "href": "posts/9f44093e-8b72-42cc-b860-3f96214e1a6a/index.html#my-custom-search-engine-built-upon-thesaurussynonymsantenyms-fzf-and-grep",
    "title": "Search Engines",
    "section": "my custom search engine built upon thesaurus/synonyms/antenyms, fzf and grep",
    "text": "my custom search engine built upon thesaurus/synonyms/antenyms, fzf and grep\nRETRO retrieval based attention net, though using faiss, unclear if it is search related. on page 8 of the paper there are different retrieval based models for selections. LDA (topic modeling) can assist search by discovering similar topics.\ndownload nltk data here. when downloading manually, beware of the url path and id, so you would put things in order.\nyou would patch nltk in order to download via proxy. these data files are hosted on github assets.\ncheck keyword urlopen and filedownloder.py under /data/data/com.termux/files/usr/lib/python3.10/site-packages/nltk\nmaybe you can explore further with online search engines? select your keyword then search again.\nthesaurus will slow down things. make it into a preprocessor.\nrelated shits can be found here"
  },
  {
    "objectID": "posts/9f44093e-8b72-42cc-b860-3f96214e1a6a/index.html#search-engine-optimization",
    "href": "posts/9f44093e-8b72-42cc-b860-3f96214e1a6a/index.html#search-engine-optimization",
    "title": "Search Engines",
    "section": "search engine optimization",
    "text": "search engine optimization\nadvertools\nzinc search\nmarkuplm markup language model used for feature rich information extraction, webqa, arxiv paper: reading wikipedia to answer open domain questions\nzinc search, go implementation of elastic search alternative\nI bet there are many many alternatives. even for a relational database or graph database it can be a search engine by its nature.\nhow the heck can i search my own notes? slice it into little segments? standard excerpt included.\nsearch for search engine in github.\nsearch engines are related to spiders/crawlers.\nhow to utilize these search engines is a problem/challenge. use url filters, generic extractors, readbility.js, summarizers like sumy.\nmany specialized search engines that can search image, video and audio. one example is Jina\nsemantic search tool, multimedia search tool, neural search tool\nhttps://github.com/searxng/searxng\nparse popular search engine results like baidu, bing:\nhttps://github.com/bisohns/search-engine-parser\nsearch and scrape news\nhttps://github.com/01joy/news-search-engine\nimage search engine\nhttps://github.com/matsui528/sis\nsearch engines used by hackers, social engineering, onion sites:\nhttps://github.com/edoardottt/awesome-hacker-search-engines\nsearch engine with customized recommendation:\nhttps://github.com/mtianyan/FunpySpiderSearchEngine\nseo tools 百度下拉词获取 推荐词相关词\nhttps://github.com/marcobiedermann/search-engine-optimization\na self-hosted search engine that can be deployed on heroku, google alike:\nhttps://github.com/benbusby/whoogle-search\ntxtai:\nsemantic search tool\npip3 install txtai\nusing sentence-transformer models from huggingface sentence embedding\nhttps://github.com/neuml/txtai\nyacy:\ndistributed search engine circumvent censorship\nprovide rss feeds\nsearx:\nmeta search engine self-hosted\nhas third-party hosted searx websites avaliable:\nhttps://searx.space/ total 83 online(currently)\nmwmbl:\ndistributed crawler central search engine, can be self-hosted\nwritten in python\nvideo search engine:\ngenerate summary from frames\nhttps://github.com/AkshatSh/VideoSearchEngine\nyuno:\ncontext based search engine for anime, anime search engine with transformer and deep learning. text based search. more like a semantic search tool, or neural search tool.\nYuno is a context based search engine that indexes over 0.5 million anime reviews and other anime informations. To help you find anime with specific properties. This search engine will help people of r/AnimeSuggest who are looking for specific type of anime to watch.\nThis search engine was created to solve the problem of finding an object with specific properties and the object in this case is anime. But this search engine can be easily extended to any domain like books,movies,etc. Without the need of any kind of handcrafted dataset.\nTypeSense:\ndedicated client for every popular programminhg language\nconsume much fewer ram than meilisearch\nneed to write custom web interface via nodejs\nupload data via client api\nMeiliSearch:\ngood for small dataset\nconsume whoopy 900mb for my 9mb json dataset.\nhas intuitive web interface.\nupload document via web post."
  },
  {
    "objectID": "posts/7ca8f838-902a-4e05-9dd7-5770a638c952/index.html",
    "href": "posts/7ca8f838-902a-4e05-9dd7-5770a638c952/index.html",
    "title": "SEO tools",
    "section": "",
    "text": "https://github.com/YitingWang25436/Keywords-selection-model\nhttps://github.com/ulysseses/tag_recommender\nhttps://github.com/rdowns26/seo_keyword_research_tools\nhttps://github.com/coreymcmahon/SeoPy\nhttps://github.com/teles/awesome-se"
  },
  {
    "objectID": "posts/5aa5afbf-2fda-468d-a379-f373bc4d9063/index.html",
    "href": "posts/5aa5afbf-2fda-468d-a379-f373bc4d9063/index.html",
    "title": "Roll in Bed在床上翻滚",
    "section": "",
    "text": "不仅要侧翻 正反颠倒 还要垫高后背的同时垫高脖子 用被子和圆枕垫高手臂 抬高小桌板\n吃东西吃多了 需要到处走动而不是躺着不动 不然不消化 导致不舒服 发热\n床上躺的过多 压力大 一般喜欢吃东西来减轻压力 安静的地方 人少的地方比较适合节食\n适当的吃东西 不要吃太多\n晚上过晚睡觉 吃东西吃太多 晚上吃东西 和喝酒类似"
  },
  {
    "objectID": "posts/40ad2a0a-1a77-4a88-a9ad-b22fe896f84d/index.html",
    "href": "posts/40ad2a0a-1a77-4a88-a9ad-b22fe896f84d/index.html",
    "title": "Resolve Host Name Computer Name From IP",
    "section": "",
    "text": "many methods have been tried. NetBIOS not working. DHCP server not found. nmap script engine(NSE) uses lua to automate sniffing and attacks."
  },
  {
    "objectID": "posts/b2304af7-751a-4d47-9e99-5116ff9aeb2a/index.html",
    "href": "posts/b2304af7-751a-4d47-9e99-5116ff9aeb2a/index.html",
    "title": "Remove Unused pip dependencies",
    "section": "",
    "text": "sometimes we install a single package which brings about tons of dependencies in python, pip-autoremove comes in handy.\ninstall it by pip3 install pip-autoremove\nthough be careful these dependencies might not be used in other existing packages, they are sometimes still being used in your code!"
  },
  {
    "objectID": "posts/3b098fd5-4426-426b-abeb-730e82f568f7/index.html",
    "href": "posts/3b098fd5-4426-426b-abeb-730e82f568f7/index.html",
    "title": "Redis Cheatsheet",
    "section": "",
    "text": "Redis Cheat Sheet\nWhen you encounter a Redis instance and you quickly want to learn about the setup you just need a few simple commands to peak into the setup. Of course it doesn’t hurt to look at the official full command documentation, but below is a listing just for sysadmins.\nAccessing Redis\nCLI\nFirst thing to know is that you can use “telnet” (usually on Redis default port 6379)\ntelnet localhost 6379\nor the Redis CLI client\nredis-cli\nto connect to Redis. The advantage of redis-cli is that you have a help interface and command line history.\nCLI Queries\nHere is a short list of some basic data extraction commands:\nType Syntax and Explanation\nTracing monitor Watch current live commands. Use with care when on production. Cancel with Ctrl-C.\nSlow Queries slowlog get 25 Print top 25 slow queries\nslowlog len\nslowlog reset\nSearch / List All Keys keys &lt;pattern Use with care when on production!\nkeys myprefix*\nkeys pattern\nkeys *mysuffix\nkeys [a-c]* Use grep like expressions\nGeneric Key Handling del  Delete key\ndump  Serialize key\nexists  Check for key\nexpire   Set key TTL\nWorking with scalar types get \nset  \nsetnx   Set key value only if key does not exist\nBatch commands:\nmget   …\nmset    \nWorking with counters incr \ndecr \nRedis Lists lrange    Accessing lists\nlrange mylist 0 -1 Output all elements\nlindex mylist 5 Get 5th element\nllen mylist Get list length\nlpush mylist “value” Push “value” to list\nlpush mylist 5 Push number 5 to list\nrpush mylist “value” Push “value” to beginning (unshift)\nlpushx mylist 6 Only push if mylist exists\nrpushx mylist 7\nlpop mylist Remove+return value from list\nrpop mylist Remove+return value from start (shift)\nlrem mylist 1 “value” Remove ‘value’ count times\nlset mylist 2 6 Set 3rd element to value 6\nltrim   \nWorking with Redis Hashes hexists myhash field1 Check if hash key exists\nhget myhash field1 Get key value\nhdel myhash field2 Delete key\nhset myhash field1 “value” Set key with “value”\nhsetnx myhash field1 “value”\nhgetall myhash Get all hash content\nhkeys myhash List all keys\nhlen myhash List number of keys\nBatch commands:\nhmget   … Get multiple keys\nhmset     … Set multiple keys\nCounter commands\nhincrby myhash field1 1\nhincrby myhash field1 5\nhincrby myhash field1 -1\nhincrbrfloat myhash field2 1.123445\nCLI Scripting\nFor scripting just pass commands to “redis-cli”. For example:\n$ redis-cli INFO | grep connected\nconnected_clients:2\nconnected_slaves:0\n$\nServer Statistics\nThe statistics command is “INFO” and will give you an output as following.\n$ redis-cli INFO\nredis_version:2.2.12\nredis_git_sha1:00000000\nredis_git_dirty:0\narch_bits:64\nmultiplexing_api:epoll\nprocess_id:8353\nuptime_in_seconds:2592232\nuptime_in_days:30\nlru_clock:809325\nused_cpu_sys:199.20\nused_cpu_user:309.26\nused_cpu_sys_children:12.04\nused_cpu_user_children:1.47\nconnected_clients:2 # &lt;—- connection count\nconnected_slaves:0\nclient_longest_output_list:0\nclient_biggest_input_buf:0\nblocked_clients:0\nused_memory:6596112\nused_memory_human:6.29M # &lt;—- memory usage\nused_memory_rss:17571840\nmem_fragmentation_ratio:2.66\nuse_tcmalloc:0\nloading:0\naof_enabled:0\nchanges_since_last_save:0\nbgsave_in_progress:0\nlast_save_time:1371241671\nbgrewriteaof_in_progress:0\ntotal_connections_received:118\ntotal_commands_processed:1091\nexpired_keys:441\nevicted_keys:0\nkeyspace_hits:6\nkeyspace_misses:1070\nhash_max_zipmap_entries:512\nhash_max_zipmap_value:64\npubsub_channels:0\npubsub_patterns:0\nvm_enabled:0\nrole:master # &lt;—- master/slave in replication setup\ndb0:keys=91,expires=88\nChanging Runtime Configuration\nThe command\nCONFIG GET *\ngives you a list of all active configuration variables you can change. The output might look like this:\nredis 127.0.0.1:6379&gt; CONFIG GET *\n\n“dir”\n“/var/lib/redis”\n“dbfilename”\n“dump.rdb”\n“requirepass”\n(nil)\n“masterauth”\n(nil)\n“maxmemory”\n“0”\n“maxmemory-policy”\n“volatile-lru”\n“maxmemory-samples”\n“3”\n“timeout”\n“300”\n“appendonly”\n“no”\n“no-appendfsync-on-rewrite”\n“no”\n“appendfsync”\n“everysec” # &lt;—- how often fsync() is called\n“save”\n“900 1 300 10 60 10000” # &lt;—- how often Redis dumps in background\n“slave-serve-stale-data”\n“yes”\n“hash-max-zipmap-entries”\n“512”\n“hash-max-zipmap-value”\n“64”\n“list-max-ziplist-entries”\n“512”\n“list-max-ziplist-value”\n“64”\n“set-max-intset-entries”\n“512”\n“slowlog-log-slower-than”\n“10000”\n“slowlog-max-len”\n“64”\n\nNote that keys and values are alternating and you can change each key by issuing a “CONFIG SET” command like:\nCONFIG SET timeout 900\nSuch a change will be effective instantly. When changing values consider also updating the redis configuration file.\nDatabases\nMultiple Databases\nRedis has a concept of separated namespaces called “databases”. You can select the database number you want to use with “SELECT”. By default the database with index 0 is used. So issuing\nredis 127.0.0.1:6379&gt; SELECT 1\nOK\nredis 127.0.0.1:6379[1]&gt;\nswitches to the second database. Note how the prompt changed and now has a “[1]” to indicate the database selection. To find out how many databases there are you might want to run redis-cli from the shell:\n$ redis-cli INFO | grep ^db\ndb0:keys=91,expires=88\ndb1:keys=1,expires=0\nDropping Databases\nTo drop the currently selected database run\nFLUSHDB\nto drop all databases at once run\nFLUSHALL\nReplication\nChecking for Replication\nTo see if the instance is a replication slave or master issue\nredis 127.0.0.1:6379&gt; INFO\n[…]\nrole:master\nand watch for the “role” line which shows either “master” or “slave”. Starting with version 2.8 the “INFO” command also gives you per slave replication status looking like this\nslave0:ip=127.0.0.1,port=6380,state=online,offset=281,lag=0\nSetting up Replication\nIf you quickly need to set up replication just issue\nSLAVEOF  \non a machine that you want to become slave of the given IP. It will immediately get values from the master. Note that this instance will still be writable. If you want it to be read-only change the redis config file (only available in most recent version, e.g. not on Debian). To revert the slave setting run\nSLAVEOF NO ONE\nPerformance Testing\nBenchmark\nInstall the Redis tools and run the provided benchmarking tool\nredis-benchmark -h  [-p ]\nIf you are migrating from/to memcached protocol check out how to run the same benchmark for any key value store with memcached protocol.\nDebugging Latency\nFirst measure system latency on your Redis server with\nredis-cli –intrinsic-latency 100\nand then sample from your Redis clients with\nredis-cli –latency -h  -p \nIf you have problems with high latency check if transparent huge pages are disabled. Disable it with\necho never &gt; /sys/kernel/mm/transparent_hugepage/enabled\nDump Database Backup\nAs Redis allows RDB database dumps in background, you can issue a dump at any time. Just run:\nBGSAVE\nWhen running this command Redis will fork and the new process will dump into the “dbfilename” configured in the Redis configuration without the original process being blocked. Of course the fork itself might cause an interruption. Use “LASTSAVE” to check when the dump file was last updated. For a simple backup solution just backup the dump file. If you need a synchronous save run “SAVE” instead of “BGSAVE”.\nListing Connections\nStarting with version 2.4 you can list connections with\nCLIENT LIST\nand you can terminate connections with\nCLIENT KILL :\nMonitoring Traffic\nThe propably most useful command compared to memcached where you need to trace network traffic is the “MONITOR” command which will dump incoming commands in real time.\nredis 127.0.0.1:6379&gt; MONITOR\nOK\n1371241093.375324 “monitor”\n1371241109.735725 “keys” “*”\n1371241152.344504 “set” “testkey” “1”\n1371241165.169184 “get” “testkey”\nadditionally use “SLOWLOG” to track the slowest queries in an interval. For example\nSLOWLOG RESET\n\nwait for some time\nSLOWLOG GET 25\nand get the 25 slowest command during this time.\nSharding with proxies\nThere are two major proxy solutions\nTwemproxy (aka nutcracker, by Twitter)\nCodis"
  },
  {
    "objectID": "posts/9de1f737-e779-405e-baaf-7324f0fea685/index.html",
    "href": "posts/9de1f737-e779-405e-baaf-7324f0fea685/index.html",
    "title": "React Native",
    "section": "",
    "text": "The key is to see immediate response directly after changes\nReact Native is a tool helping to build cross-platform mobile/desktop apps.\nNativeScript is something alike.\nKivy Roboto"
  },
  {
    "objectID": "posts/f91372e4-2505-4cab-baa7-3242a0c10d5f/index.html",
    "href": "posts/f91372e4-2505-4cab-baa7-3242a0c10d5f/index.html",
    "title": "RSS Feeds",
    "section": "",
    "text": "kuxai ai related articles, there’s some bot keep posting this shit to qq group\nrsshub most extensible rss feeder, can turn bilibili, zhihu, or anything into rss\nmedium.com\nSearching for existing rss sources. You may want to make your own by means of social media. It could be the feeding source of reviewer or producer.\nhttps://www.baidu.com/ssid=4d994e69636f5f4e69636f6c6532353311dd/from=844b/s?word=rss订阅源&ts=7538593&t_kt=0&ie=utf-8&fm_kl=021394be2f&rsv_iqid=4109465110&rsv_t=a02fgTXA5yrpeGBRWrTCqcc9bK%252FKmzIRzII6usvAqgJjawViUjevc88MAg&sa=is_5&ms=1&rsv_pq=4109465110&rsv_sug4=6166&tj=1&ss=110&inputT=3395&sugid=110161509475552&rq=rss\nhttps://www.appstoredate.com/iphone/6990.html\nhttps://blog.csdn.net/wangjialiang/article/details/121510405\nhttps://baijiahao.baidu.com/s?id=1677152782752706400&wfr=spider&for=pc&searchword=rss订阅源\nhttps://www.bilibili.com/read/mobile?id=8961024\nhttps://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=rss源地址订阅大全&sa=brs_7&rq=rss订阅源&rsf=100631857&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san\nhttps://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=订阅源整合&sa=brs_6&rq=rss订阅源&rsf=100631112&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san\nhttps://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=知乎日报rss源&sa=brs_4&rq=rss订阅源&rsf=100631113&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san\nhttps://www.zhihu.com/question/25071126/answer/875901493\nhttps://zhuanlan.zhihu.com/p/53989966\nhttps://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=各大网站RSS订阅源地址&sa=re_dl_prs_34689_1&rqid=10035302357898163828&params_ssrt=node-san&rq=知乎日报rss源&rsf=100631113&asctag=2470\nhttps://www.tutorialspoint.com/python_text_processing/python_reading_rss_feed.htm\nhttps://www.datasciencelearner.com/how-to-read-rss-feed-in-python/\nhttps://wiki.python.org/moin/RssLibraries\nhttps://stackoverflow.com/questions/2244836/rss-feed-parser-library-in-python\nhttps://pypi.org/project/rss-reader/\nhttps://github.com/lemon24/reader\nhttps://reader.readthedocs.io/en/latest/\nwe need cleaner view by using readbility.js, but how to preserve pictures? is it built-in?\npictures could be a big fingerprint. better deal them with link extracter and shufflers.\nyou want python version or nodejs version?\nnpm install @mozilla/readability\n# it can be invoked via api, standalone!\n# you might want to call javascript from python\npip3 install readability-lxml\n# some lags behind?\nthis is for the reader mode, make webpage readable\nhttps://github.com/luin/readability\nhttps://github.com/phpdocker-io/readability-js-server\nhttps://github.com/mozilla/readability\nhttps://github.com/alan-turing-institute/ReadabiliPy\nhttps://github.com/edgartaor/kindleServer\nhttps://requests-html.kennethreitz.org\nhttps://github.com/psf/requests-html\nhttps://github.com/MHordecki/readability-redux/blob/master/readability/readability.js\nhttps://github.com/buriy/python-readability\nhttps://stackoverflow.com/questions/56857506/how-to-enable-reader-mode-distill-page-with-puppeteer"
  },
  {
    "objectID": "posts/b7fd9ac4-c4ac-4e67-8be8-fdf8c7c46c20/index.html",
    "href": "posts/b7fd9ac4-c4ac-4e67-8be8-fdf8c7c46c20/index.html",
    "title": "RL, trajectory prediction, model predictive control",
    "section": "",
    "text": "this reminds me of ddpg-usv-asmc and Deep-Reinforcement-Learning-Algorithms-with-PyTorch (is it? nope. it is stable-baseline3, containing PPO preferred by OpenAI when training InstructGPT) or Deep-reinforcement-learning-with-pytorch\nmpc.torch\nawesome-deep-rl For deep RL and the future of AI."
  },
  {
    "objectID": "posts/f62f4fbb-f86f-4252-8323-ab73ac09e832/index.html#qq号码注册规则",
    "href": "posts/f62f4fbb-f86f-4252-8323-ab73ac09e832/index.html#qq号码注册规则",
    "title": "QQ 微信 信息提取 bot搭建",
    "section": "qq号码注册规则",
    "text": "qq号码注册规则\nqq群最多可以添加500个群 1500个好友 其中群可加的数量 = max(0,500 - 已加入群数量 - 好友数量)\n可以退出一些安静的群 不发红包的群 删除好友\n屏蔽别人加我为好友 允许别人拉我进群 自动退出广告群 退出不活跃的群\n群一天只能加两三个 或者手机上可以加十个\n好友一天可以加三十几个\n一个验证QQ群的Python代码\nhttps://www.bilibili.com/read/mobile?id=10044756\nfrida inject mobile android qq and open qzone:\nhttps://github.com/xhtechxposed/fridainjectqq\nsearch https://qun.qq.com in search engines\n可以考虑截图获取QQ群验证问题 或者手机测试 appium\nif possible then just use frida/radare2 or some reverse engineering to automate the process.\nradare2 -&gt; rizin.re(radare2 fork) based, ida alike, with ghidra decompiler, reverse engineering tool:\nhttps://cutter.re\n如何获取进群验证问题？记得可以拦截PC端搜索QQ群接收的数据包获取验证问题 或许不行 总之可以获取到一些参数 查看是否包含验证问题 是不是允许任何人进群 也可以考虑拦截opqqq的通信 或者发送一些通用的加群验证信息 比如“加群学习” “小伙伴一起玩” 之类的 或者用ai模型根据群描述 群主题 生成\n一个手机号码可以申请10个qq号，一个手机号绑定的QQ帐号名额上限为10个，但一天一个手机号只能成功注册两到三个\nWeChat needs serious reverse engineering like frida.\nhttps://github.com/cixingguangming55555/wechat-bot\n有webapi的微信机器人 注入dll到pc\nhttps://github.com/mrsanshui/WeChatPYAPI\n可以加好友的python wechat pc hook\nhttps://github.com/snlie/WeChat-Hook\n易语言的wechat hook 功能非常全 搜索 加人 有教程链接 教学代码\nhttps://github.com/TonyChen56/WeChatRobot\n比较老的wechat逆向模块 wechatapis.dll半天获得不了 有教程链接\nhttps://github.com/wechaty/puppet-xp\nfrida 驱动的wechat puppet 暂时没有加人 搜索人 在windows上运行\nwechat reverse engineering tutorials:\nhttps://github.com/hedada-hc/pc_wechat_hook\nhttps://github.com/zmrbak/PcWeChatHooK\nwechaty base framework:\nhttps://github.com/Wechaty/python-wechaty/ (puppet support might be incomplete)\nhttps://github.com/Wechaty/wechaty/\nbotoy opqbot api for python\nhttps://botoy.opqbot.com/zh_CN/latest/action/\nqq opqbot (for wechat it has rstbot) download and install (need gitter.im api token):\nhttps://docs.opqbot.com/guide/manual.html#启动失败\nopqbot needs to be reverse engineered or we won’t know what is going on inside.\nunofficial opqbot wiki:\nhttps://mcenjoy.cn/opqbotwiki/\nwechat bot(non-free wechat puppets):\nwechaty\nquoted content are controversial and highly viral. must be filtered and classified before proceeding.\nquotes are like comments."
  },
  {
    "objectID": "posts/892d27ad-4e85-49a9-aeea-eea2a51fce08/index.html",
    "href": "posts/892d27ad-4e85-49a9-aeea-eea2a51fce08/index.html",
    "title": "Python Media Automation",
    "section": "",
    "text": "we first see the world, get the observation and respond in the form of content. it is a feedback loop.\nto search components in videos, first take screenshots then do image search, then use the keywords to get the source video.\nbreakdown approach:\ngranualize every step, showing all possibilities to get content created and then optimoze it using standards.\nfilter approach:\nestablish some topics, create topic specific approaches to arrange the content, choose the best among all topics.\nare they compatible? are you sure it is modular, scalable and extensible?\nfor novices, they have few unpolished ideas and waiting to realize it using code. but it lacks the feedback loop and thus you are unable to change yourself according to the reaction. breakdown approach must be used to automate the optimization, and topic based approach is simple at first hand.\nto avoid copyright issues search for google.\ntopic based approach assues the public always have something in common and thus you only search specific things at first hand. they are easy to control, static and consistent. breakdown approach is where the evolution begins.\nlet’s assume our topic is about pets on weibo. pets have different kinds and the content creaters are different from each other. all we do is to download and upload. we get descriptions from our viewers, video play counts and various feedback. we improve the source by our feedback, searching for more untouched contents and more mixes like video/audio crossing.\nbreakdown approach is demostrated first-hand with our actor-critic model. we first view all possible posts from all sources, find what’s interesting and repost it to our target platform. this is likely to be cheating. we again choose our sources, our approach of modification based on feedback. topics are generated from the very first step.\nthe model of interests, which generates the topic, is the key breakdown approach. we have to eventually construct a breakdown approach to boost our searches in every aspect. feedback is one of those key features. we eventually have to view the content with the machine. suggest using the breakdown approach now.\nanatomy of the post:\nfirst thing it would be postable, according to our mandatory order. it would not be taken down or banned for a long time. banning detection is required and usually simple to test against.\nsecond it is most profitable. we only prefer those tasks which give the most output. occasionly we choose something fresh despite lower expectations.\nthird it would be resourceful. consistently pinning audience in a series of videos is undoubtably competitent. this can be reached by utilizing our creativity engine based on comments and imagination, realize the unrealized.\nhave not yet found anything systematic on giving the full detail of such automated content creation system. we only pick up those pieces. it is important to make the entire design flexible and create miniature tests to fabricate the system. like any other famous writer/director, you could only name it but not reproduce it.\nhands on the approach, no matter it is inspired by anyone or anything, it is time to begin, to complete the feedback loop.\nnot a pipe, but a loop.\nwe demonstrate the loop using fake data, then the real ones. maybe the initial topic is also meant to be fake data. the real world data is too stochastic for us to imagine. better construct something specific."
  },
  {
    "objectID": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#lisp-style-resumption-error-handling-semantics",
    "href": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#lisp-style-resumption-error-handling-semantics",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "lisp-style resumption error-handling semantics",
    "text": "lisp-style resumption error-handling semantics\npython for lisp programmers\npractical common lisp\narithmatic infix\ncommon lisp debugging\ncommon lisp related libraries\nslime\nportacle\ntalk on reddit"
  },
  {
    "objectID": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#ruby",
    "href": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#ruby",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "ruby",
    "text": "ruby\npry-rescue may not resume execution?"
  },
  {
    "objectID": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#java",
    "href": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#java",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "java",
    "text": "java\neclipse hot code swap fix\nhot code replace in vscode for java"
  },
  {
    "objectID": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#python",
    "href": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#python",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "python",
    "text": "python\nbytecode hack, pyhotswap\npython lisp-style exception as condition handling\ndump different level of reloading call history\nreload code blocks which are syntatically different, if black formatter fails after dedent then there shall be error\ndecide to reload extra parts of functions in the next run if selected\nload newly added functions, remove old functions, execute added lines, reload entire module and update namespace depending on condition\ncheck other programming language whether it jas similar capabilities\nvisit this thread of ruby in archive.org\nwallabyjs\neither bytecode or modify the source code"
  },
  {
    "objectID": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#bookmarks",
    "href": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html#bookmarks",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "bookmarks",
    "text": "bookmarks\nhttps://docs.python.org/3/library/code.html\nhttps://docs.python.org/3/library/cmd.html\nhttps://docs.python.org/3/library/threading.html#threading.settrace\nhttps://mail.python.org/archives/list/python-dev@python.org/thread/OGPO6KWHQGO47KOJKNEWNZS3LLMVXBEV/\nhttps://github.com/TomOnTime/timetravelpdb\nhttps://github.com/nfd/on_error_resume_next/blob/master/basic.py\nhttps://github.com/search?p=5&q=BEFORE_ASYNC_WITH&type=Code\nhttps://github.com/Martmists-GH/pyasm/blob/a306f23cbed13505687eb0ca86f010e5fe3101b5/asm/ops/py35.py\nhttps://github.com/Martmists-GH/pyasm\nhttps://github.com/kr1surb4n/copypaster_filedecks/blob/3f2ca44c4f984652585a1e7f1e589966e8867da6/filedecks_archive/python/library/dis/Python%20Bytecode%20Instructions/opcodeBEFOREASYNCWIT\nhttps://github.com/kholia/dedrop/blob/60da43889be89950cadbbb6b54489eb1841c70da/src/dedrop-ng/opcode_mapper.py\nhttps://github.com/brettlangdon/gython\nhttps://github.com/Exitialium/Github-Drive/blob/5284358a163c4ea25c63f4157d41af5f638950a2/deap/include/python3.9/opcode.h\nhttps://github.com/ajalt/fuckitpy\nhttps://code.lardcave.net/2020/12/29/1/\nhttps://github.com/asrp/python_terp/blob/master/test/buggy_ex.py\nhttps://github.com/HugoDelval/reversibleInterpreter\nhttps://github.com/topics/reversible-programming-language\nhttps://github.com/jndean/railway/wiki/Variables,-Data-and-Scope\nhttps://cn.bing.com/search?q=python+run+bytecode&qs=UT&pq=python+run+byteco&sc=1-17&cvid=79F89EEA4A564540BF79A8DBB63284CE&FORM=QBRE&sp=1\nhttps://opensource.com/article/18/4/introduction-python-bytecode\nhttp://www.aosabook.org/en/500L/a-python-interpreter-written-in-python.html\nhttps://github.com/nedbat/byterun\nhttps://unpyc.sourceforge.net/Opcodes.html\nhttps://docs.python.org/3/library/codeop.html\nhttps://docs.python.org/3/library/dis.html\nhttps://docs.python.org/3/library/dis.html\nhttps://docs.python.org/3/library/codeop.html\nhttps://blog.quarkslab.com/building-an-obfuscated-python-interpreter-we-need-more-opcodes.html\nhttps://github.com/fietensen/PyOpcodeAsm\nhttps://pypi.org/project/BytecodeAssembler/\nhttp://probablyprogramming.com/2008/04/18/ppya-python-assembler\nhttps://pypi.org/project/BytecodeAssembler/#description\nhttp://peak.telecommunity.com/DevCenter/BytecodeAssembler\nhttps://github.com/pib/papaya\nhttps://www.programcreek.com/python/?CodeExample=get+opcode\nhttps://unpyc.sourceforge.net/Opcodes.html\nhttps://www.synopsys.com/blogs/software-security/understanding-python-bytecode/\nhttps://github.com/neuroo/equip\nhttps://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/\nhttps://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/\nhttps://discuss.python.org/t/exec-with-return-keyword/19916/25\nhttps://cn.bing.com/search?q=interactive%20debugging%20python&qs=n&form=QBRE&=%25eManage%20Your%20Search%20History%25E&sp=-1&pq=interactive%20debugging%20&sc=3-22&sk=&cvid=30D653A233984DD685DE7CE79AD46318&ghsh=0&ghacc=0&ghpl=\nhttps://www.digitalocean.com/community/tutorials/how-to-debug-python-with-an-interactive-console\nhttps://nedbatchelder.com/blog/200509/interactive_debugging_in_python.html\nhttps://derpops.bike/python/computers/kubernetes/2017/10/26/interactive-debugging-python-kubernetes.html\nhttps://bytes.com/topic/python/answers/46053-resume-after-exception\nhttps://pytrace.com/\nhttps://github.com/gleb-sevruk/pycrunch-trace/issues\ncontextlib usage detail, to make customized “with” statements:\nfrom contextlib import AbstractContextManager\nclass suppress2(AbstractContextManager):\n\"\"\"Context manager to suppress specified exceptions\nAfter the exception is suppressed, execution proceeds with the next\nstatement following the with statement.\nwith suppress(FileNotFoundError):\nos.remove(somefile)\n# Execution still resumes here if the file was already removed\n\"\"\"\ndef __init__(self, *exceptions):\nself._exceptions = exceptions\ndef __enter__(self):\nprint(dir(self))\npass\ndef __exit__(self, exctype, excinst, exctb):\n# Unlike isinstance and issubclass, CPython exception handling\n# currently only looks at the concrete type hierarchy (ignoring\n# the instance and subclass checking hooks). While Guido considers\n# that a bug rather than a feature, it's a fairly hard one to fix\n# due to various internal implementation details. suppress provides\n# the simpler issubclass based semantics, rather than trying to\n# exactly reproduce the limitations of the CPython interpreter.\n#\n# See http://bugs.python.org/issue12029 for more details\nprint(\"EXCTYPE\", exctype)\nprint(\"EXCINST\", excinst)\nprint(\"EXCTB\",exctb) # exception\nprint(dir(exctb))\nbreakpoint()\nreturn exctype is not None and issubclass(exctype, self._exceptions)\npython grammar sugar: brackets\nhttps://pypi.org/project/brackets/\ndoes that work in eval()?\nuse contextlib.suppress to replace try…except: pass\nmight investigate source code of the suppress object.\nhttps://opensource.com/article/18/5/how-retrieve-source-code-python-functions\nto execute code grouped by lowest level of indentation, we can def those lines of code and pass the code by dill.source.getsource(functionName) and eval within given global/local variables.\nmy solution is down here, with concrete examples.\nhereby we recommend to insert a conditional return statement to ensure we will exit this buggy code at the best time. maybe we could put it into a dictionary somehow, tuples within string or something.\nimport dill\nfrom contextlib import suppress\nimport traceback\ndef skipException(func, debug_flag=False, breakpoint_flag=False):\ndef space_counter(line):\ncounter = 0\nfor x in line:\nif x == \" \": counter+=1\nelse: break\nreturn counter\ndef remove_extra_return(code):\nwhile True:\nif \"\\n\\n\" in code:\ncode = code.replace(\"\\n\\n\",\"\\n\")\nelse: break\nreturn code\ndef isEmptyLine(line):\nemptyChars = [\"\\n\",\"\\t\",\"\\r\",\" \"]\nlength = len(line)\nemptyCounts=0\nfor char in line:\nif char in emptyChars: emptyCounts += 1\nreturn emptyCounts == length\ndef getCodeBlocks(lines):\nmBlocks=[]\ncurrent_block = lines[0]\nlines = lines+[\"\"]\nkeywords = [\" \", \"def\", \"async def\", \"with\", \"class\", \"@\"]\nfor line in lines[1:]:\nif sum([line.startswith(keyword) for keyword in keywords]):\ncurrent_block+=\"\\n\"\ncurrent_block+=line\nelse:\nmBlocks.append(current_block)\ncurrent_block = line\nreturn mBlocks\ndef getExtendedLines(splited_code):\nsplited_code = [x.rstrip() for x in splited_code]\nsplited_code = \"\\n\".join(splited_code).replace(\"\\\\\\n\",\"\")\nsplited_code = remove_extra_return(splited_code)\nsplited_code = splited_code.split(\"\\n\")\nreturn splited_code\ndef new_func(*args, **kwargs):\nfunc_name = func.__name__\nfunc_code = dill.source.getsource(func)\nif debug_flag:\nprint(\"########## FUNCTION CODE #########\")\nprint(func_code) # do not use chained decorator since doing so will definitely fail everything?\nprint(\"########## FUNCTION CODE #########\")\nprint(\"########## FUNCTION #########\")\n# print(func_code)\nfunc_code = remove_extra_return(func_code)\nsplited_code = func_code.split(\"\\n\")\nsplited_code = getExtendedLines(splited_code)\n# index 0: decorator\n# index 1: function name\n# no recursion support. may work inside another undecorated function.\ntry:\nassert splited_code[0].strip().startswith(\"@skipException\")\nexcept:\nraise Exception(\"Do not nesting the use of @skipException decorator\")\nfunction_definition = splited_code[1]\nfunction_args=function_definition[:-1].replace(\"def {}\".format(func_name),\"\")\nif debug_flag:\nprint(\"FUNCTION ARGS:\", function_args)\nkwdefaults = func.__defaults__\npass_kwargs = {}\nif \"=\" in function_args:\nassert kwdefaults!=None\narg_remains = function_args.split(\"=\")[0]\nkwarg_remains = function_args.replace(arg_remains,\"\")\nkwarg_extra_names =[content.split(\",\")[-1].strip() for index, content in enumerate(kwarg_remains.split(\"=\")) if index%2 ==1]\nmfunctionArgsPrimitive = arg_remains.replace(\"(\",\"\").split(\",\")\nkwarg_names = [mfunctionArgsPrimitive[-1].strip()]+kwarg_extra_names\nmfunctionArgs = mfunctionArgsPrimitive[:-1]\nif debug_flag:\nprint(\"PASSED KEYWORD ARGS:\", kwargs)\nprint(\"KWARG NAMES:\", kwarg_names)\nfor key, value in zip(kwarg_names, kwdefaults):\npass_kwargs.update({key: value})\nfor key in kwargs.keys():\nassert key in kwarg_names\npass_kwargs[key] = kwargs[key]\nelse:\nassert kwdefaults == None\nmfunctionArgs = function_args.replace(\"(\",\"\").replace(\")\",\"\").split(\",\")\nmfunctionArgs = [x.strip() for x in mfunctionArgs]\nmfunctionArgs = [x for x in mfunctionArgs if not isEmptyLine(x)]\nif debug_flag:\nprint(\"POSITIONAL ARGS:\",mfunctionArgs)\nassert len(args) == len(mfunctionArgs)\nfor key, value in zip(mfunctionArgs, args):\nexec(\"{} = {}\".format(key, value))\nif kwdefaults is not None:\nfor key, value in pass_kwargs.items():\nexec(\"{} = {}\".format(key, value))\nactualCode = splited_code[2:]\nactualCode = [x for x in actualCode if not isEmptyLine(x)]\nminIndent = min([space_counter(line) for line in actualCode])\n# split the code into different sections.\nif debug_flag:\nprint(minIndent)\nnewLines = [line[minIndent:] for line in actualCode]\ncodeBlocks = getCodeBlocks(newLines)\nfor block in codeBlocks:\nif debug_flag:\nprint(\"##########CODEBLOCK##########\")\nprint(block)\nprint(\"##########CODEBLOCK##########\")\nif not debug_flag:\nwith suppress(Exception):\nexec(block)\nelse:\ntry:\nexec(block)\nexcept:\ntraceback.print_exc()\nif breakpoint_flag: breakpoint()\nif debug_flag:\nprint(\"########## FUNCTION #########\")\nreturn new_func\ndef skipExceptionVerbose(func): return skipException(func, debug_flag=True)\ndef skipExceptionBreakpoint(func): return skipException(func, breakpoint_flag=True)\ndef skipExceptionDebug(func): return skipException(func, breakpoint_flag=True, debug_flag=True)\n@skipException\ndef someOtherShit():\namd=[1,2,3]\namd[4]\nprint(\"shit happens\")\ndef anotherShit():\n@skipException\ndef mySuperFunction(d,e,f):\nsomeOtherShit()\nprint(\"YOU WIN\")\na = [1,2,3]\na[3] # will not continue execute the code down there\nprint(\"YOU WIN\")\na[4]\nprint(\"INSIDE FUNCTION\",d,e,f)\nprint(\"YOU WIN\")\nmySuperFunction(1,2,3)\n# print(dir(mySuperFunction))\nanotherShit()\n# breakpoint()"
  },
  {
    "objectID": "posts/2d713cff-f7a6-4a93-9a32-2e4f8b8b2e38/index.html",
    "href": "posts/2d713cff-f7a6-4a93-9a32-2e4f8b8b2e38/index.html",
    "title": "Public APIs, GIF Websites Funny Video Sources",
    "section": "",
    "text": "rapidapi do not use this\nimgur funny gifs\nhttps://giphy.com\nvideo dataset:\nyoutube8m by google\ngiphy gif apis:\nhttps://github.com/austinkelleher/giphy-api\nhttps://github.com/Giphy/giphy-js\nhttps://github.com/sogamoso/giphy\nhttps://github.com/Giphy/GiphyAPI\nhttps://developers.giphy.com/branch/master/docs/\nhttps://github.com/shaunduncan/giphypop\nenternainment apis and more, search for free apis/public apis:\nhttps://apipheny.io/free-api/#entertainment-apis\nfind things from public apis:\nhttps://github.com/public-apis/public-apis\ndownload video from ifunny.co\nhttps://github.com/vidovichb/iFunny_Downloader\nmemes app from reddit\nhttps://github.com/victorqribeiro/memes\nml algorithm to download funny music videos\nhttps://github.com/dfarren/funny_music_videos\ncreate funny videos\nhttps://github.com/PhotoBoxPW/VideoBox\nsearch gifs from bukk.it\nhttps://github.com/olivierlacan/gifhub\nhttps://bukk.it\n搞笑视频去水印\nhttps://github.com/5ime/video_spider\n搞笑图片 搞笑音频抓取\nhttps://github.com/zhaofucheng1129/KuailewoAppServer\n搞笑视频\nhttps://github.com/ecitlm/Node-SpliderApi\n搞笑视频 哔哩哔哩封面图获取\nhttps://github.com/iqiqiya/iqiqiya-API"
  },
  {
    "objectID": "posts/012175b8-a7ef-488e-aadb-c76d620d2eb3/index.html",
    "href": "posts/012175b8-a7ef-488e-aadb-c76d620d2eb3/index.html",
    "title": "Popular Video Sites",
    "section": "",
    "text": "twitch\nhttps://netflix.com\nhttps://www.ted.com\nhttps://www.youtube.com\nhttps://www.instagram.com\nhttps://twitter.com\nhttps://www.pornhub.com\nhttps://www.bilibili.com\nhttps://www.douyu.com\nhttps://www.huya.com\nhttps://www.iqiyi.com\nhttps://www.youku.com\nhttps://weibo.com/tv\nhttps://krcom.cn\nhttps://tv.sohu.com\nhttps://v.qq.com\nNetEase Public Class\nQQ Music-MV"
  },
  {
    "objectID": "posts/bf760350-ca1d-4029-ae38-368cad3d1cc4/index.html",
    "href": "posts/bf760350-ca1d-4029-ae38-368cad3d1cc4/index.html",
    "title": "Optical Flow",
    "section": "",
    "text": "flownet nvidia\nnvidia optical flow sdk supports all turing gpus (like gtx1660) and above except for gtx1650(tu117).\nmmflow from openmmlab:\nhttps://mmflow.readthedocs.io/en/latest/"
  },
  {
    "objectID": "posts/189a6753-7a2e-41bf-ac22-ffb8eacdbb88/index.html",
    "href": "posts/189a6753-7a2e-41bf-ac22-ffb8eacdbb88/index.html",
    "title": "OCR tools",
    "section": "",
    "text": "tesseract\ntesseract.js with 100+ language support, still need to predefine language type\nchineseocr, with arbitrary text direction and rubust handwriting recognization support\nlightweight chinese ocr model\nefficient ocr python lib based on tr\npaddleocr\neasyocr\npearocr client side webpage/browser based ocr"
  },
  {
    "objectID": "posts/0a0e6520-c166-4e30-819f-b9705c059350/index.html",
    "href": "posts/0a0e6520-c166-4e30-819f-b9705c059350/index.html",
    "title": "Neuraldiff: discriminate actor and objects in video",
    "section": "",
    "text": "Neuraldiff:\nhttps://github.com/dichotomies/NeuralDiff?ref=pythonawesome.com\nhttps://pythonawesome.com/official-pytorch-implementation-of-neuraldiff-segmenting-3d-objects-that-move-in-egocentric-videos/"
  },
  {
    "objectID": "posts/71e31f75-b989-4ac8-b4e8-ee024d5ac047/index.html",
    "href": "posts/71e31f75-b989-4ac8-b4e8-ee024d5ac047/index.html",
    "title": "Neo4j Refcard",
    "section": "",
    "text": "Neo4j Refcard Cheatsheet Reference Card\ngist\nNeo4j Cypher Refcard 4.4\nLegend\nRead\nWrite\nGeneral\nFunctions\nSchema\nPerformance\nMultidatabase\nSecurity\nSyntax\nRead query structure\n[USE]\n[MATCH WHERE]\n[OPTIONAL MATCH WHERE]\n[WITH [ORDER BY] [SKIP] [LIMIT]]\nRETURN [ORDER BY] [SKIP] [LIMIT]\nMATCH\nMATCH (n:Person)-[:KNOWS]-&gt;(m:Person)\nWHERE n.name = ‘Alice’\nNode patterns can contain labels and properties.\nMATCH (n)–&gt;(m)\nAny pattern can be used in MATCH.\nMATCH (n {name: ‘Alice’})–&gt;(m)\nPatterns with node properties.\nMATCH p = (n)–&gt;(m)\nAssign a path to p.\nOPTIONAL MATCH (n)-[r]-&gt;(m)\nOptional pattern: nulls will be used for missing parts.\nWHERE\nWHERE n.property &lt;&gt; $value\nUse a predicate to filter. Note that WHERE is always part of a MATCH, OPTIONAL MATCH or WITH clause. Putting it after a different clause in a query will alter what it does.\nWHERE EXISTS {\nMATCH (n)–&gt;(m) WHERE n.age = m.age\n}\nUse an existential subquery to filter.\nWrite-only query structure\n[USE]\n(CREATE | MERGE)*\n[SET|DELETE|REMOVE|FOREACH]*\n[RETURN [ORDER BY] [SKIP] [LIMIT]]\nRead-write query structure\n[USE]\n[MATCH WHERE]\n[OPTIONAL MATCH WHERE]\n[WITH [ORDER BY] [SKIP] [LIMIT]]\n(CREATE | MERGE)*\n[SET|DELETE|REMOVE|FOREACH]*\n[RETURN [ORDER BY] [SKIP] [LIMIT]]\nCREATE\nCREATE (n {name: $value})\nCreate a node with the given properties.\nCREATE (n $map)\nCreate a node with the given properties.\nUNWIND $listOfMaps AS properties\nCREATE (n) SET n = properties\nCreate nodes with the given properties.\nCREATE (n)-[r:KNOWS]-&gt;(m)\nCreate a relationship with the given type and direction; bind a variable to it.\nCREATE (n)-[:LOVES {since: $value}]-&gt;(m)\nCreate a relationship with the given type, direction, and properties.\nSET\nSET n.property1 = $value1,\nn.property2 = $value2\nUpdate or create a property.\nSET n = $map\nSet all properties. This will remove any existing properties.\nSET n += $map\nAdd and update properties, while keeping existing ones.\nSET n:Person\nAdds a label Person to a node.\nImport\nLOAD CSV FROM\n‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists.csv’ AS line\nCREATE (:Artist {name: line[1], year: toInteger(line[2])})\nLoad data from a CSV file and create nodes.\nLOAD CSV WITH HEADERS FROM\n‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists-with-headers.csv’ AS line\nCREATE (:Artist {name: line.Name, year: toInteger(line.Year)})\nLoad CSV data which has headers.\nUSING PERIODIC COMMIT 500\nLOAD CSV WITH HEADERS FROM\n‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists-with-headers.csv’ AS line\nCREATE (:Artist {name: line.Name, year: toInteger(line.Year)})\nCommit the current transaction after every 500 rows when importing large amounts of data.\nLOAD CSV FROM\n‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists-fieldterminator.csv’\nAS line FIELDTERMINATOR ‘;’\nCREATE (:Artist {name: line[1], year: toInteger(line[2])})\nUse a different field terminator, not the default which is a comma (with no whitespace around it).\nLOAD CSV FROM\n‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists.csv’ AS line\nRETURN DISTINCT file()\nReturns the absolute path of the file that LOAD CSV is processing, returns null if called outside of LOAD CSV context.\nLOAD CSV FROM\n‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists.csv’ AS line\nRETURN linenumber()\nReturns the line number that LOAD CSV is currently processing, returns null if called outside of LOAD CSV context.\nOperators\nGeneral\nDISTINCT, ., []\nMathematical\n+, -, *, /, %, ^\nComparison\n=, &lt;&gt;, &lt;, &gt;, &lt;=, &gt;=, IS NULL, IS NOT NULL\nBoolean\nAND, OR, XOR, NOT\nString\n\n\n\nList\n+, IN, [x], [x .. y]\nRegular Expression\n=~\nString matching\nSTARTS WITH, ENDS WITH, CONTAINS\nnull\nnull is used to represent missing/undefined values.\nnull is not equal to null. Not knowing two values does not imply that they are the same value. So the expression null = null yields null and not true. To check if an expression is null, use IS NULL.\nArithmetic expressions, comparisons and function calls (except coalesce) will return null if any argument is null.\nAn attempt to access a missing element in a list or a property that doesn’t exist yields null.\nIn OPTIONAL MATCH clauses, nulls will be used for missing parts of the pattern.\nPatterns\n(n:Person)\nNode with Person label.\n(n:Person:Swedish)\nNode with both Person and Swedish labels.\n(n:Person {name: $value})\nNode with the declared properties.\n()-[r {name: $value}]-()\nMatches relationships with the declared properties.\n(n)–&gt;(m)\nRelationship from n to m.\n(n)–(m)\nRelationship in any direction between n and m.\n(n:Person)–&gt;(m)\nNode n labeled Person with relationship to m.\n(m)&lt;-[:KNOWS]-(n)\nRelationship of type KNOWS from n to m.\n(n)-[:KNOWS|LOVES]-&gt;(m)\nRelationship of type KNOWS or of type LOVES from n to m.\n(n)-[r]-&gt;(m)\nBind the relationship to variable r.\n(n)-[*1..5]-&gt;(m)\nVariable length path of between 1 and 5 relationships from n to m.\n(n)-[*]-&gt;(m)\nVariable length path of any number of relationships from n to m. (See Performance section.)\n(n)-[:KNOWS]-&gt;(m {property: $value})\nA relationship of type KNOWS from a node n to a node m with the declared property.\nshortestPath((n1:Person)-[*..6]-(n2:Person))\nFind a single shortest path.\nallShortestPaths((n1:Person)-[*..6]-&gt;(n2:Person))\nFind all shortest paths.\nsize((n)–&gt;()–&gt;())\nCount the paths matching the pattern.\nUSE\nUSE myDatabase\nSelect myDatabase to execute query, or query part, against.\nUSE neo4j\nMATCH (n:Person)-[:KNOWS]-&gt;(m:Person)\nWHERE n.name = ‘Alice’\nMATCH query executed against neo4j database.\nSHOW FUNCTIONS and PROCEDURES\nSHOW FUNCTIONS\nListing all available functions.\nSHOW PROCEDURES EXECUTABLE YIELD name\nList all procedures that can be executed by the current user and return only the name of the procedures.\nSHOW and TERMINATE TRANSACTIONS\nSHOW TRANSACTIONS\nListing all available transactions.\nTERMINATE TRANSACTIONS ‘neo4j-transaction-42’\nTerminate the transaction with ID neo4j-transaction-42.\nLabels\nCREATE (n:Person {name: $value})\nCreate a node with label and property.\nMERGE (n:Person {name: $value})\nMatches or creates unique node(s) with the label and property.\nSET n:Spouse:Parent:Employee\nAdd label(s) to a node.\nMATCH (n:Person)\nMatches nodes labeled Person.\nMATCH (n:Person)\nWHERE n.name = $value\nMatches nodes labeled Person with the given name.\nWHERE (n:Person)\nChecks the existence of the label on the node.\nlabels(n)\nLabels of the node.\nREMOVE n:Person\nRemove the label from the node.\nMaps\n{name: ‘Alice’, age: 38,\naddress: {city: ‘London’, residential: true}}\nLiteral maps are declared in curly braces much like property maps. Lists are supported.\nWITH {person: {name: ‘Anne’, age: 25}} AS p\nRETURN p.person.name\nAccess the property of a nested map.\nMERGE (p:Person {name: $map.name})\nON CREATE SET p = $map\nMaps can be passed in as parameters and used either as a map or by accessing keys.\nMATCH (matchedNode:Person)\nRETURN matchedNode\nNodes and relationships are returned as maps of their data.\nmap.name, map.age, map.children[0]\nMap entries can be accessed by their keys. Invalid keys result in an error.\nFunctions\ncoalesce(n.property, $defaultValue)\nThe first non-null expression.\ntimestamp()\nMilliseconds since midnight, January 1, 1970 UTC.\nid(nodeOrRelationship)\nThe internal id of the relationship or node.\ntoInteger($expr)\nConverts the given input into an integer if possible; otherwise it returns null.\ntoFloat($expr)\nConverts the given input into a floating point number if possible; otherwise it returns null.\ntoBoolean($expr)\nConverts the given input into a boolean if possible; otherwise it returns null.\nkeys($expr)\nReturns a list of string representations for the property names of a node, relationship, or map.\nproperties($expr)\nReturns a map containing all the properties of a node or relationship.\nSpatial functions\npoint({x: $x, y: $y})\nReturns a point in a 2D cartesian coordinate system.\npoint({latitude: $y, longitude: $x})\nReturns a point in a 2D geographic coordinate system, with coordinates specified in decimal degrees.\npoint({x: $x, y: $y, z: $z})\nReturns a point in a 3D cartesian coordinate system.\npoint({latitude: $y, longitude: $x, height: $z})\nReturns a point in a 3D geographic coordinate system, with latitude and longitude in decimal degrees, and height in meters.\npoint.distance(point({x: $x1, y: $y1}), point({x: $x2, y: $y2}))\nReturns a floating point number representing the linear distance between two points. The returned units will be the same as those of the point coordinates, and it will work for both 2D and 3D cartesian points.\npoint.distance(point({latitude: $y1, longitude: $x1}), point({latitude: $y2, longitude: $x2}))\nReturns the geodesic distance between two points in meters. It can be used for 3D geographic points as well.\nTemporal functions\ndate(“2018-04-05”)\nReturns a date parsed from a string.\nlocaltime(“12:45:30.25”)\nReturns a time with no time zone.\ntime(“12:45:30.25+01:00”)\nReturns a time in a specified time zone.\nlocaldatetime(“2018-04-05T12:34:00”)\nReturns a datetime with no time zone.\ndatetime(“2018-04-05T12:34:00[Europe/Berlin]”)\nReturns a datetime in the specified time zone.\ndatetime({epochMillis: 3360000})\nTransforms 3360000 as a UNIX Epoch time into a normal datetime.\ndate({year: $year, month: $month, day: $day})\nAll of the temporal functions can also be called with a map of named components. This example returns a date from year, month and day components. Each function supports a different set of possible components.\ndatetime({date: $date, time: $time})\nTemporal types can be created by combining other types. This example creates a datetime from a date and a time.\ndate({date: $datetime, day: 5})\nTemporal types can be created by selecting from more complex types, as well as overriding individual components. This example creates a date by selecting from a datetime, as well as overriding the day component.\nWITH date(“2018-04-05”) AS d\nRETURN d.year, d.month, d.day, d.week, d.dayOfWeek\nAccessors allow extracting components of temporal types.\nDuration functions\nduration(“P1Y2M10DT12H45M30.25S”)\nReturns a duration of 1 year, 2 months, 10 days, 12 hours, 45 minutes and 30.25 seconds.\nduration.between(\\(date1,\\)date2)\nReturns a duration between two temporal instances.\nWITH duration(“P1Y2M10DT12H45M”) AS d\nRETURN d.years, d.months, d.days, d.hours, d.minutes\nReturns 1 year, 14 months, 10 days, 12 hours and 765 minutes.\nWITH duration(“P1Y2M10DT12H45M”) AS d\nRETURN d.years, d.monthsOfYear, d.days, d.hours, d.minutesOfHour\nReturns 1 year, 2 months, 10 days, 12 hours and 45 minutes.\ndate(“2015-01-01”) + duration(“P1Y1M1D”)\nReturns a date of 2016-02-02. It is also possible to subtract durations from temporal instances.\nduration(“PT30S”) * 10\nReturns a duration of 5 minutes. It is also possible to divide a duration by a number.\nCONSTRAINT\nCREATE CONSTRAINT FOR (p:Person)\nREQUIRE p.name IS UNIQUE\nCreate a unique property constraint on the label Person and property name. If any other node with that label is updated or created with a name that already exists, the write operation will fail. This constraint will create an accompanying index.\nCREATE CONSTRAINT uniqueness FOR (p:Person)\nREQUIRE (p.firstname, p.age) IS UNIQUE\nCreate a unique property constraint with the name uniqueness on the label Person and properties firstname and age. If any other node with that label is updated or created with a firstname and age combination that already exists, the write operation fails. This constraint creates an accompanying index.\nCREATE CONSTRAINT FOR (p:Person)\nREQUIRE p.surname IS UNIQUE\nOPTIONS {indexProvider: ‘native-btree-1.0’}\nCreate a unique property constraint on the label Person and property surname with the index provider native-btree-1.0 for the accompanying index.\nCREATE CONSTRAINT FOR (p:Person)\nREQUIRE p.name IS NOT NULL\n(★) Create a node property existence constraint on the label Person and property name, throws an error if the constraint already exists. If a node with that label is created without a name, or if the name property is removed from an existing node with the Person label, the write operation will fail.\nCREATE CONSTRAINT node_exists IF NOT EXISTS FOR (p:Person)\nREQUIRE p.name IS NOT NULL\n(★) If a node property existence constraint on the label Person and property name or any constraint with the name node_exists already exist then nothing happens. If no such constraint exists, then it will be created.\nCREATE CONSTRAINT FOR ()-[l:LIKED]-()\nREQUIRE l.when IS NOT NULL\n(★) Create a relationship property existence constraint on the type LIKED and property when. If a relationship with that type is created without a when, or if the when property is removed from an existing relationship with the LIKED type, the write operation will fail.\nCREATE CONSTRAINT relationship_exists FOR ()-[l:LIKED]-()\nREQUIRE l.since IS NOT NULL\n(★) Create a relationship property existence constraint with the name relationship_exists on the type LIKED and property since. If a relationship with that type is created without a since, or if the since property is removed from an existing relationship with the LIKED type, the write operation will fail.\nSHOW UNIQUE CONSTRAINTS YIELD *\nList all unique constraints.\nCREATE CONSTRAINT FOR (p:Person)\nREQUIRE (p.firstname, p.surname) IS NODE KEY\n(★) Create a node key constraint on the label Person and properties firstname and surname. If a node with that label is created without both firstname and surname or if the combination of the two is not unique, or if the firstname and/or surname properties on an existing node with the Person label is modified to violate these constraints, the write operation fails. This constraint creates an accompanying index.\nCREATE CONSTRAINT node_key FOR (p:Person)\nREQUIRE p.firstname IS NODE KEY\n(★) Create a node key constraint with the name node_key on the label Person and property firstname. If a node with that label is created without the firstname property or if the value is not unique, or if the firstname property on an existing node with the Person label is modified to violate these constraints, the write operation fails. This constraint creates an accompanying index.\nCREATE CONSTRAINT node_key_with_config FOR (p:Person)\nREQUIRE (p.name, p.age) IS NODE KEY\nOPTIONS {indexConfig: {spatial.wgs-84.min: [-100.0, -100.0], spatial.wgs-84.max: [100.0, 100.0]}}\n(★) Create a node key constraint with the name node_key_with_config on the label Person, properties name and age, and given spatial.wgs-84 settings for the accompanying b-tree index. The other index settings will have their default values.\nDROP CONSTRAINT uniqueness\nDropping the constraint with the name uniqueness, throws an error if the constraint does not exist. If the constraint has an accompanying index, that is also dropped.\nDROP CONSTRAINT uniqueness IF EXISTS\nDropping the constraint with the name uniqueness if it exists, does nothing if it does not exist. If the constraint has an accompanying index, that is also dropped.\nDatabase management\nCREATE OR REPLACE DATABASE myDatabase\n(★) Create a database named myDatabase. If a database with that name exists, then the existing database is deleted and a new one created.\nALTER DATABASE myDatabase SET ACCESS READ ONLY\n(★) Modify a database named myDatabase to be read-only.\nSTOP DATABASE myDatabase\n(★) Stop the database myDatabase.\nSTART DATABASE myDatabase\n(★) Start the database myDatabase.\nCREATE ALIAS myAlias FOR DATABASE myDatabase\n(★) Create an alias myAlias for the database with name myDatabase.\nALTER ALIAS myAlias SET DATABASE TARGET myDatabase\n(★) Alter the alias myAlias to target the database with name myDatabase.\nDROP ALIAS myAlias FOR DATABASE\n(★) Drop the database alias myAlias.\nSHOW DATABASES\nList all databases in the system and information about them.\nSHOW DATABASES\nYIELD name, currentStatus\nWHERE name CONTAINS ‘my’ AND currentStatus = ‘online’\nList information about databases, filtered by name and online status and further refined by conditions on these.\nSHOW DATABASE myDatabase\nList information about the database myDatabase.\nSHOW DEFAULT DATABASE\nList information about the default database.\nSHOW HOME DATABASE\nList information about the current users home database.\nDROP DATABASE myDatabase IF EXISTS\n(★) Delete the database myDatabase, if it exists.\nUser management\nCREATE USER alice SET PASSWORD $password\nCreate a new user and a password. This password must be changed on the first login.\nALTER USER alice SET PASSWORD $password CHANGE NOT REQUIRED\nSet a new password for a user. This user will not be required to change this password on the next login.\nALTER USER alice IF EXISTS SET PASSWORD CHANGE REQUIRED\nIf the specified user exists, force this user to change their password on the next login.\nALTER USER alice SET STATUS SUSPENDED\n(★) Change the user status to suspended. Use SET STATUS ACTIVE to reactivate the user.\nALTER USER alice SET HOME DATABASE otherDb\n(★) Change the home database of user to otherDb. Use REMOVE HOME DATABASE to unset the home database for the user and fallback to the default database.\nALTER CURRENT USER SET PASSWORD FROM $old TO $new\nChange the password of the logged-in user. The user will not be required to change this password on the next login.\nSHOW CURRENT USER\nList the currently logged-in user, their status, roles and whether they need to change their password.\n(★) Status and roles are Enterprise Edition only.\nSHOW USERS\nList all users in the system, their status, roles and if they need to change their password.\n(★) Status and roles are Enterprise Edition only.\nSHOW USERS\nYIELD user, suspended\nWHERE suspended = true\nList users in the system, filtered by their name and status and further refined by whether they are suspended.\n(★) Status is Enterprise Edition only.\nRENAME USER alice TO alice_delete\nRename the user alice to alice_delete.\nDROP USER alice_delete\nDelete the user.\n(★) Role management\nCREATE ROLE my_role\nCreate a role.\nCREATE ROLE my_second_role IF NOT EXISTS AS COPY OF my_role\nCreate a role named my_second_role, unless it already exists, as a copy of the existing my_role.\nRENAME ROLE my_second_role TO my_other_role\nRename a role named my_second_role to my_other_role.\nGRANT ROLE my_role, my_other_role TO alice\nAssign roles to a user.\nREVOKE ROLE my_other_role FROM alice\nRemove a specified role from a user.\nSHOW ROLES\nList all roles in the system.\nSHOW ROLES\nYIELD role\nWHERE role CONTAINS ‘my’\nList roles, filtered by the name of the role and further refined by whether the name contains ‘my’.\nSHOW POPULATED ROLES WITH USERS\nList all roles that are assigned to at least one user in the system, and the users assigned to those roles.\nDROP ROLE my_role\nDelete a role.\n(★) Graph read privileges\nGRANT TRAVERSE ON GRAPH * NODES * TO my_role\nGrant traverse privilege on all nodes and all graphs to a role.\nDENY READ {prop} ON GRAPH foo RELATIONSHIP Type TO my_role\nDeny read privilege on a specified property, on all relationships with a specified type in a specified graph, to a role.\nGRANT MATCH {*} ON HOME GRAPH ELEMENTS Label TO my_role\nGrant read privilege on all properties and traverse privilege in the home graph, to a role. Here, both privileges apply to all nodes and relationships with a specified label/type in the graph.\n(★) Graph write privileges\nGRANT CREATE ON GRAPH * NODES Label TO my_role\nGrant create privilege on all nodes with a specified label in all graphs to a role.\nDENY DELETE ON GRAPH neo4j TO my_role\nDeny delete privilege on all nodes and relationships in a specified graph to a role.\nREVOKE SET LABEL Label ON GRAPH * FROM my_role\nRevoke set label privilege for the specified label on all graphs to a role.\nGRANT REMOVE LABEL * ON GRAPH foo TO my_role\nGrant remove label privilege for all labels on a specified graph to a role.\nDENY SET PROPERTY {prop} ON GRAPH foo RELATIONSHIPS Type TO my_role\nDeny set property privilege on a specified property, on all relationships with a specified type in a specified graph, to a role.\nGRANT MERGE {} ON GRAPH  NODES Label TO my_role\nGrant merge privilege on all properties, on all nodes with a specified label in all graphs, to a role.\nREVOKE WRITE ON GRAPH * FROM my_role\nRevoke write privilege on all graphs from a role.\nDENY ALL GRAPH PRIVILEGES ON GRAPH foo TO my_role\nDeny all graph privileges privilege on a specified graph to a role.\n(★) SHOW PRIVILEGES\nSHOW PRIVILEGES AS COMMANDS\nList all privileges in the system as Cypher commands.\nSHOW PRIVILEGES\nList all privileges in the system, and the roles that they are assigned to.\nSHOW PRIVILEGES\nYIELD role, action, access\nWHERE role = ‘my_role’\nList information about privileges, filtered by role, action and access and further refined by the name of the role.\nSHOW ROLE my_role PRIVILEGES AS COMMANDS\nList all privileges assigned to a role as Cypher commands.\nSHOW ROLE my_role, my_second_role PRIVILEGES AS COMMANDS\nList all privileges assigned to each of the multiple roles as Cypher commands.\nSHOW USER alice PRIVILEGES AS COMMANDS\nList all privileges of a user, and the role that they are assigned to as Cypher commands.\nSHOW USER PRIVILEGES AS COMMANDS\nList all privileges of the currently logged in user, and the role that they are assigned to as Cypher commands.\nRETURN\nRETURN *\nReturn the value of all variables.\nRETURN n AS columnName\nUse alias for result column name.\nRETURN DISTINCT n\nReturn unique rows.\nORDER BY n.property\nSort the result.\nORDER BY n.property DESC\nSort the result in descending order.\nSKIP $skipNumber\nSkip a number of results.\nLIMIT $limitNumber\nLimit the number of results.\nSKIP $skipNumber LIMIT $limitNumber\nSkip results at the top and limit the number of results.\nRETURN count(*)\nThe number of matching rows. See Aggregating functions for more.\nWITH\nMATCH (user)-[:FRIEND]-(friend)\nWHERE user.name = $name\nWITH user, count(friend) AS friends\nWHERE friends &gt; 10\nRETURN user\nThe WITH syntax is similar to RETURN. It separates query parts explicitly, allowing you to declare which variables to carry over to the next part.\nMATCH (user)-[:FRIEND]-(friend)\nWITH user, count(friend) AS friends\nORDER BY friends DESC\nSKIP 1\nLIMIT 3\nRETURN user\nORDER BY, SKIP, and LIMIT can also be used with WITH.\nUNION\nMATCH (a)-[:KNOWS]-&gt;(b)\nRETURN b.name\nUNION\nMATCH (a)-[:LOVES]-&gt;(b)\nRETURN b.name\nReturns the distinct union of all query results. Result column types and names have to match.\nMATCH (a)-[:KNOWS]-&gt;(b)\nRETURN b.name\nUNION ALL\nMATCH (a)-[:LOVES]-&gt;(b)\nRETURN b.name\nReturns the union of all query results, including duplicated rows.\nMERGE\nMERGE (n:Person {name: $value})\nON CREATE SET n.created = timestamp()\nON MATCH SET\nn.counter = coalesce(n.counter, 0) + 1,\nn.accessTime = timestamp()\nMatch a pattern or create it if it does not exist. Use ON CREATE and ON MATCH for conditional updates.\nMATCH (a:Person {name: $value1}),\n(b:Person {name: $value2})\nMERGE (a)-[r:LOVES]-&gt;(b)\nMERGE finds or creates a relationship between the nodes.\nMATCH (a:Person {name: $value1})\nMERGE\n(a)-[r:KNOWS]-&gt;(b:Person {name: $value3})\nMERGE finds or creates paths attached to the node.\nDELETE\nDELETE n, r\nDelete a node and a relationship.\nDETACH DELETE n\nDelete a node and all relationships connected to it.\nMATCH (n)\nDETACH DELETE n\nDelete all nodes and relationships from the database.\nREMOVE\nREMOVE n:Person\nRemove a label from n.\nREMOVE n.property\nRemove a property.\nFOREACH\nFOREACH (r IN relationships(path) |\nSET r.marked = true)\nExecute a mutating operation for each relationship in a path.\nFOREACH (value IN coll |\nCREATE (:Person {name: value}))\nExecute a mutating operation for each element in a list.\nCALL subquery\nCALL {\nMATCH (p:Person)-[:FRIEND_OF]-&gt;(other:Person) RETURN p, other\nUNION\nMATCH (p:Child)-[:CHILD_OF]-&gt;(other:Parent) RETURN p, other\n}\nThis calls a subquery with two union parts. The result of the subquery can afterwards be post-processed.\nCALL procedure\nCALL db.labels() YIELD label\nThis shows a standalone call to the built-in procedure db.labels to list all labels used in the database. Note that required procedure arguments are given explicitly in brackets after the procedure name.\nCALL db.labels() YIELD *\nStandalone calls may use YIELD * to return all columns.\nCALL java.stored.procedureWithArgs\nStandalone calls may omit YIELD and also provide arguments implicitly via statement parameters, e.g. a standalone call requiring one argument input may be run by passing the parameter map {input: ‘foo’}.\nCALL db.labels() YIELD label\nRETURN count(label) AS count\nCalls the built-in procedure db.labels inside a larger query to count all labels used in the database. Calls inside a larger query always requires passing arguments and naming results explicitly with YIELD.\nLists\n[‘a’, ‘b’, ‘c’] AS list\nLiteral lists are declared in square brackets.\nsize($list) AS len, $list[0] AS value\nLists can be passed in as parameters.\nrange($firstNum, $lastNum, $step) AS list\nrange() creates a list of numbers (step is optional), other functions returning lists are: labels(), nodes(), relationships().\nMATCH p = (a)-[:KNOWS*]-&gt;()\nRETURN relationships(p) AS r\nThe list of relationships comprising a variable length path can be returned using named paths and relationships().\nRETURN matchedNode.list[0] AS value,\nsize(matchedNode.list) AS len\nProperties can be lists of strings, numbers or booleans.\nlist[$idx] AS value,\nlist[\\(startIdx..\\)endIdx] AS slice\nList elements can be accessed with idx subscripts in square brackets. Invalid indexes return null. Slices can be retrieved with intervals from start_idx to end_idx, each of which can be omitted or negative. Out of range elements are ignored.\nUNWIND $names AS name\nMATCH (n {name: name})\nRETURN avg(n.age)\nWith UNWIND, any list can be transformed back into individual rows. The example matches all names from a list of names.\nMATCH (a)\nRETURN [(a)–&gt;(b) WHERE b.name = ‘Bob’ | b.age]\nPattern comprehensions may be used to do a custom projection from a match directly into a list.\nMATCH (person)\nRETURN person { .name, .age}\nMap projections may be easily constructed from nodes, relationships and other map values.\nPredicates\nn.property &lt;&gt; $value\nUse comparison operators.\ntoString(n.property) = $value\nUse functions.\nn.number &gt;= 1 AND n.number &lt;= 10\nUse boolean operators to combine predicates.\n1 &lt;= n.number &lt;= 10\nUse chained operators to combine predicates.\nn:Person\nCheck for node labels.\nvariable IS NOT NULL\nCheck if something is not null, e.g. that a property exists.\nn.property IS NULL OR n.property = $value\nEither the property does not exist or the predicate is true.\nn.property = $value\nNon-existing property returns null, which is not equal to anything.\nn[“property”] = $value\nProperties may also be accessed using a dynamically computed property name.\nn.property STARTS WITH ‘Tim’ OR\nn.property ENDS WITH ‘n’ OR\nn.property CONTAINS ‘goodie’\nString matching.\nn.property =~ ’Tim.*’\nString regular expression matching.\n(n)-[:KNOWS]-&gt;(m)\nEnsure the pattern has at least one match.\nNOT (n)-[:KNOWS]-&gt;(m)\nExclude matches to (n)-[:KNOWS]-&gt;(m) from the result.\nn.property IN [$value1, $value2]\nCheck if an element exists in a list.\nList predicates\nall(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is true for all elements in the list.\nany(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is true for at least one element in the list.\nnone(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is false for all elements in the list.\nsingle(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is true for exactly one element in the list.\nCASE\nCASE n.eyes\nWHEN ‘blue’ THEN 1\nWHEN ‘brown’ THEN 2\nELSE 3\nEND\nReturn THEN value from the matching WHEN value. The ELSE value is optional, and substituted for null if missing.\nCASE\nWHEN n.eyes = ‘blue’ THEN 1\nWHEN n.age &lt; 40 THEN 2\nELSE 3\nEND\nReturn THEN value from the first WHEN predicate evaluating to true. Predicates are evaluated in order.\nList expressions\nsize($list)\nNumber of elements in the list.\nreverse($list)\nReverse the order of the elements in the list.\nhead($list)\nGet the first element of the list. Return null for an empty list. Eqivalent to the list indexing $list[0].\nlast($list)\nGet the last element of the list. Return null for an empty list. Eqivalent to the list indexing $list[-1].\ntail($list)\nGet all elements except for the first element. Return [] for an empty list. Eqivalent to the list slice $list[1..]. Out-of-bound slices are truncated to an empty list [].\n[x IN list | x.prop]\nA list of the value of the expression for each element in the original list.\n[x IN list WHERE x.prop &lt;&gt; $value]\nA filtered list of the elements where the predicate is true.\n[x IN list WHERE x.prop &lt;&gt; $value | x.prop]\nA list comprehension that filters a list and extracts the value of the expression for each element in that list.\nreduce(s = ““, x IN list | s + x.prop)\nEvaluate expression for each element in the list, accumulate the results.\nPath functions\nlength(path)\nThe number of relationships in the path.\nnodes(path)\nThe nodes in the path as a list.\nrelationships(path)\nThe relationships in the path as a list.\n[x IN nodes(path) | x.prop]\nExtract properties from the nodes in a path.\nMathematical functions\nabs($expr)\nThe absolute value.\nrand()\nReturns a random number in the range from 0 (inclusive) to 1 (exclusive), [0,1). Returns a new value for each call. Also useful for selecting a subset or random ordering.\nround($expr)\nRound to the nearest integer; ceil() and floor() find the next integer up or down.\nsqrt($expr)\nThe square root.\nsign($expr)\n0 if zero, -1 if negative, 1 if positive.\nsin($expr)\nTrigonometric functions also include cos(), tan(), cot(), asin(), acos(), atan(), atan2(), and haversin(). All arguments for the trigonometric functions should be in radians, if not otherwise specified.\ndegrees(\\(expr), radians(\\)expr), pi()\nConverts radians into degrees; use radians() for the reverse, and pi() for π.\nlog10(\\(expr), log(\\)expr), exp($expr), e()\nLogarithm base 10, natural logarithm, e to the power of the parameter, and the value of e.\nString functions\ntoString($expression)\nString representation of the expression.\nreplace($original, $search, $replacement)\nReplace all occurrences of search with replacement. All arguments must be expressions.\nsubstring($original, $begin, $subLength)\nGet part of a string. The subLength argument is optional.\nleft($original, $subLength),\nright($original, $subLength)\nThe first part of a string. The last part of the string.\ntrim(\\(original), lTrim(\\)original),\nrTrim($original)\nTrim all whitespace, or on the left or right side.\ntoUpper(\\(original), toLower(\\)original)\nUPPERCASE and lowercase.\nsplit($original, $delimiter)\nSplit a string into a list of strings.\nreverse($original)\nReverse a string.\nsize($string)\nCalculate the number of characters in the string.\nRelationship functions\ntype(a_relationship)\nString representation of the relationship type.\nstartNode(a_relationship)\nStart node of the relationship.\nendNode(a_relationship)\nEnd node of the relationship.\nid(a_relationship)\nThe internal id of the relationship.\nAggregating functions\ncount(*)\nThe number of matching rows.\ncount(variable)\nThe number of non-null values.\ncount(DISTINCT variable)\nAll aggregating functions also take the DISTINCT operator, which removes duplicates from the values.\ncollect(n.property)\nList from the values, ignores null.\nsum(n.property)\nSum numerical values. Similar functions are avg(), min(), max().\npercentileDisc(n.property, $percentile)\nDiscrete percentile. Continuous percentile is percentileCont(). The percentile argument is from 0.0 to 1.0.\nstDev(n.property)\nStandard deviation for a sample of a population. For an entire population use stDevP().\nINDEX\nCREATE INDEX FOR (p:Person) ON (p.name)\nCreate a b-tree index on nodes with label Person and property name.\nCREATE INDEX index_name FOR ()-[k:KNOWS]-() ON (k.since)\nCreate a b-tree index with the name index_name on relationships with type KNOWS and property since.\nCREATE INDEX FOR (p:Person) ON (p.surname)\nOPTIONS {indexProvider: ‘native-btree-1.0’, indexConfig: {spatial.cartesian.min: [-100.0, -100.0], spatial.cartesian.max: [100.0, 100.0]}}\nCreate a b-tree index on nodes with label Person and property surname with the index provider native-btree-1.0 and given spatial.cartesian settings. The other index settings will have their default values.\nCREATE INDEX FOR (p:Person) ON (p.name, p.age)\nCreate a composite b-tree index on nodes with label Person and the properties name and age, throws an error if the index already exist.\nCREATE INDEX IF NOT EXISTS FOR (p:Person) ON (p.name, p.age)\nCreate a composite b-tree index on nodes with label Person and the properties name and age if it does not already exist, does nothing if it did exist.\nCREATE LOOKUP INDEX lookup_index_name FOR (n) ON EACH labels(n)\nCreate a token lookup index with the name lookup_index_name on nodes with any label.\nCREATE LOOKUP INDEX FOR ()-[r]-() ON EACH type(r)\nCreate a token lookup index on relationships with any relationship type.\nCREATE FULLTEXT INDEX node_fulltext_index_name FOR (n:Friend) ON EACH [n.name]\nOPTIONS {indexConfig: {fulltext.analyzer: ‘swedish’}}\nCreate a fulltext index on nodes with the name node_fulltext_index_name and analyzer swedish. Fulltext indexes on nodes can only be used by from the procedure db.index.fulltext.queryNodes. The other index settings will have their default values.\nCREATE FULLTEXT INDEX rel_fulltext_index_name FOR ()-[r:HAS_PET|BROUGHT_PET]-() ON EACH [r.since, r.price]\nCreate a fulltext index on relationships with the name rel_fulltext_index_name. Fulltext indexes on relationships can only be used by from the procedure db.index.fulltext.queryRelationships.\nCREATE TEXT INDEX FOR (f:Friend) ON (f.email)\nCreate a text index on nodes with label Friend and property email.\nCREATE TEXT INDEX text_index_name FOR ()-[h:HAS_PET]-() ON (h.favoriteToy)\nCreate a text index with the name text_index_name on relationships with type HAS_PET and property favoriteToy.\nSHOW INDEXES\nList all indexes.\nMATCH (n:Person) WHERE n.name = $value\nAn BTREE index can be automatically used for the equality comparison. Note that for example toLower(n.name) = $value will not use an index.\nMATCH (n:Person) WHERE n.name = “Alice”\nAn TEXT index can be automatically used for the equality comparison when comparing to a string. Note that for example toLower(n.name) = “string” does not use an index.\nMATCH (n:Person)\nWHERE n.name &lt; “Bob”\nAn index can automatically be used for range predicates. Note that a TEXT index is only used if the predicate compares the property with a string.\nMATCH (n:Person)\nWHERE n.name IN [$value]\nAn index can automatically be used for the IN list checks.\nMATCH (n:Person)\nWHERE n.name IN [‘Bob’, ‘Alice’]\nAn TEXT index can automatically be used for the IN list checks when all elements in the list are strings.\nMATCH (n:Person)\nWHERE n.name = $value and n.age = $value2\nA composite index can be automatically used for equality comparison of both properties. Note that there needs to be predicates on all properties of the composite index for it to be used.\nMATCH (n:Person)\nUSING INDEX n:Person(name)\nWHERE n.name = $value\nIndex usage can be enforced when Cypher uses a suboptimal index, or more than one index should be used.\nDROP INDEX index_name\nDrop the index named index_name, throws an error if the index does not exist.\nDROP INDEX index_name IF EXISTS\nDrop the index named index_name if it exists, does nothing if it does not exist.\nPerformance\nUse parameters instead of literals when possible. This allows Cypher to re-use your queries instead of having to parse and build new execution plans.\nAlways set an upper limit for your variable length patterns. It’s possible to have a query go wild and touch all nodes in a graph by mistake.\nReturn only the data you need. Avoid returning whole nodes and relationships — instead, pick the data you need and return only that.\nUse PROFILE / EXPLAIN to analyze the performance of your queries. See Query Tuning for more information on these and other topics, such as planner hints.\n(★) Database privileges\nGRANT ACCESS ON DATABASE * TO my_role\nGrant privilege to access and run queries against all databases to a role.\nGRANT START ON DATABASE * TO my_role\nGrant privilege to start all databases to a role.\nGRANT STOP ON DATABASE * TO my_role\nGrant privilege to stop all databases to a role.\nGRANT CREATE INDEX ON DATABASE foo TO my_role\nGrant privilege to create indexes on a specified database to a role.\nGRANT DROP INDEX ON DATABASE foo TO my_role\nGrant privilege to drop indexes on a specified database to a role.\nGRANT SHOW INDEX ON DATABASE * TO my_role\nGrant privilege to show indexes on all databases to a role.\nDENY INDEX MANAGEMENT ON DATABASE bar TO my_role\nDeny privilege to create and drop indexes on a specified database to a role.\nGRANT CREATE CONSTRAINT ON DATABASE * TO my_role\nGrant privilege to create constraints on all databases to a role.\nDENY DROP CONSTRAINT ON DATABASE * TO my_role\nDeny privilege to drop constraints on all databases to a role.\nDENY SHOW CONSTRAINT ON DATABASE foo TO my_role\nDeny privilege to show constraints on a specified database to a role.\nREVOKE CONSTRAINT ON DATABASE * FROM my_role\nRevoke granted and denied privileges to create and drop constraints on all databases from a role.\nGRANT CREATE NEW LABELS ON DATABASE * TO my_role\nGrant privilege to create new labels on all databases to a role.\nDENY CREATE NEW TYPES ON DATABASE foo TO my_role\nDeny privilege to create new relationship types on a specified database to a role.\nREVOKE GRANT CREATE NEW PROPERTY NAMES ON DATABASE bar FROM my_role\nRevoke the grant privilege to create new property names on a specified database from a role.\nGRANT NAME MANAGEMENT ON HOME DATABASE TO my_role\nGrant privilege to create labels, relationship types, and property names on the home database to a role.\nGRANT ALL ON DATABASE baz TO my_role\nGrant privilege to access, create and drop indexes and constraints, create new labels, types and property names on a specified database to a role.\nGRANT SHOW TRANSACTION (*) ON DATABASE foo TO my_role\nGrant privilege to list transactions and queries from all users on a specified database to a role.\nDENY TERMINATE TRANSACTION (user1, user2) ON DATABASES * TO my_role\nDeny privilege to kill transactions and queries from user1 and user2 on all databases to a role.\nREVOKE GRANT TRANSACTION MANAGEMENT ON HOME DATABASE FROM my_role\nRevoke the granted privilege to list and kill transactions and queries from all users on the home database from a role.\n(★) Role management privileges\nGRANT CREATE ROLE ON DBMS TO my_role\nGrant the privilege to create roles to a role.\nGRANT RENAME ROLE ON DBMS TO my_role\nGrant the privilege to rename roles to a role.\nGRANT DROP ROLE ON DBMS TO my_role\nGrant the privilege to delete roles to a role.\nDENY ASSIGN ROLE ON DBMS TO my_role\nDeny the privilege to assign roles to users to a role.\nDENY REMOVE ROLE ON DBMS TO my_role\nDeny the privilege to remove roles from users to a role.\nREVOKE DENY SHOW ROLE ON DBMS FROM my_role\nRevoke the denied privilege to show roles from a role.\nGRANT ROLE MANAGEMENT ON DBMS TO my_role\nGrant all privileges to manage roles to a role.\n(★) User management privileges\nGRANT CREATE USER ON DBMS TO my_role\nGrant the privilege to create users to a role.\nGRANT RENAME USER ON DBMS TO my_role\nGrant the privilege to rename users to a role.\nDENY ALTER USER ON DBMS TO my_role\nDeny the privilege to alter users to a role.\nREVOKE SET PASSWORDS ON DBMS FROM my_role\nRevoke the granted and denied privileges to alter users’ passwords from a role.\nREVOKE GRANT SET USER STATUS ON DBMS FROM my_role\nRevoke the granted privilege to alter the account status of users from a role.\nGRANT SET USER HOME DATABASE ON DBMS TO my_role\nGrant the privilege alter the home database of users to a role.\nGRANT DROP USER ON DBMS TO my_role\nGrant the privilege to delete users to a role.\nREVOKE DENY SHOW USER ON DBMS FROM my_role\nRevoke the denied privilege to show users from a role.\nGRANT USER MANAGEMENT ON DBMS TO my_role\nGrant all privileges to manage users to a role.\n(★) Database management privileges\nGRANT CREATE DATABASE ON DBMS TO my_role\nGrant the privilege to create databases and aliases to a role.\nREVOKE DENY DROP DATABASE ON DBMS FROM my_role\nRevoke the denied privilege to delete databases and aliases from a role.\nREVOKE GRANT ALTER DATABASE ON DBMS FROM my_role\nRevoke the granted privilege to alter databases and aliases from a role.\nGRANT SET DATABASE ACCESS ON DBMS TO my_role\nGranted privilege to set database access mode to a role.\nDENY DATABASE MANAGEMENT ON DBMS TO my_role\nDeny all privileges to manage databases and aliases to a role.\n(★) Privilege management privileges\nGRANT SHOW PRIVILEGE ON DBMS TO my_role\nGrant the privilege to show privileges to a role.\nDENY ASSIGN PRIVILEGE ON DBMS TO my_role\nDeny the privilege to assign privileges to roles to a role.\nREVOKE GRANT REMOVE PRIVILEGE ON DBMS FROM my_role\nRevoke the granted privilege to remove privileges from roles from a role.\nREVOKE PRIVILEGE MANAGEMENT ON DBMS FROM my_role\nRevoke all granted and denied privileges for manage privileges from a role.\n(★) DBMS privileges\nGRANT ALL ON DBMS TO my_role\nGrant privilege to perform all role, user, database, alias, privilege, procedure, function, and impersonation management to a role.\nDENY IMPERSONATE (alice) ON DBMS TO my_role\nDeny privilege to impersonate the specified user to a role.\n(★) Functionality available in Neo4j Enterprise Edition."
  },
  {
    "objectID": "posts/a2de93ec-b01d-4446-8bf2-746b937847d9/index.html",
    "href": "posts/a2de93ec-b01d-4446-8bf2-746b937847d9/index.html",
    "title": "NTFS recovery tool for bilibili cookie under AutoUP",
    "section": "",
    "text": "unmount the disk before scanning!\nntfsundelete\nautopsy\ndisk drill\nrecuperabit(good for small files)\nrecoverpy\nkorczis/foremost\ncould also try to retrieve from android phones (/data/data/tv.danmaku.bili)\nhttps://roubert.name/joakim/androidfilerecovery/\napt-get install testdisk pv extundelete\nadb shell ls /dev/block\nNow let us dump the content of that /dev/block/mmcblk0 that we found to the computer. With adb shell we can become superuser and execute cat to dump the content like this:\n$ ./adb shell su -c “cat /dev/block/mmcblk0” | pv &gt; mmcblk0.raw\nPipe Viwer (pv) is optional, but I like to see the transfer progress information it provides.\n(And of course you can change mmcblk0.raw to some other directory/filename if you want to.)\nAddition: André Paixão wrote to me that he just got an empty file with the command above. He solved it by using adbd insecure.\nAddition: Daniel Jeliński wrote to me that he ran into issues with LF encoding. The solution that worked for him was:\n./adb shell su -c “cat /dev/block/mmcblk0” | pv | sed ‘s/^M$//’ &gt; mmcblk0.raw\n…where ^M is what you get by pressing Ctrl+V followed by Ctrl+M.\nAddition: Marc also ran into the LF problems, but solved it this way:\n./adb shell “su -c ‘stty raw; cat /dev/block/mmcblk0’” | pv &gt; mmcblk0.raw\nAddition: Tim de Waal wrote to me that he prefers using netcat/gzip instead:\nOn the Android device (adb shell with su), run:\ndd if=/dev/block/mmcblk0 | gzip -9 | nc -l 5555\nOn the computer, run:\nnc [AndroidIP] 5555 | pv -b &gt; mmcblk0.img.gz\ntestdisk mmcblk0.raw"
  },
  {
    "objectID": "posts/145b40e6-6e07-4e15-bb1d-e174632d5147/index.html",
    "href": "posts/145b40e6-6e07-4e15-bb1d-e174632d5147/index.html",
    "title": "NAS With Movie Download",
    "section": "",
    "text": "Primary function of NAS is to download massive amount of (media) files. The NAS setup guides include many platforms to download movies.\nhttps://www.zhihu.com/question/22129197/answer/1050613901\nNAS is different from server, which may have thr same storage capacity but much more computational power."
  },
  {
    "objectID": "posts/d4c5ec30-c75d-4838-a2c4-ca2cf6bb30cb/index.html",
    "href": "posts/d4c5ec30-c75d-4838-a2c4-ca2cf6bb30cb/index.html",
    "title": "Exploiting Log4j Vulnerability with Fofa API: A Comprehensive Guide",
    "section": "",
    "text": "My fruitful heist attempt with fofa\nFofa api requires membership. I don’t want to enroll.\nYou first test on your vulnerable machine/app, develop scanner, exploiter and listener, then mass exploit to millions.\nAll recorded here: hack_all_the_thing/tests/get_log4j_vuln\nzoomeye search for log4j\nseebug\nshodan query for log4j2 (or anything)\n狮子鱼团购 fofa查询漏洞\nSqlmap post data inject\nTo generate password dictionary without oom: itertools.product(chrs, repeat=r)\nsearch log4j2 in browser after login\ninfo page of my first target (login first!)\nfofa usage examples\nMy first target login page\ngov site?\nBing-upms the system used by my first target\npassword dictionary topic in github"
  },
  {
    "objectID": "posts/0ec68311-a8b8-47c4-b361-d6fcbb88dfe2/index.html",
    "href": "posts/0ec68311-a8b8-47c4-b361-d6fcbb88dfe2/index.html",
    "title": "Movie Site Scraping 1",
    "section": "",
    "text": "https://www.zxzj.fun/ 目标站\n采集1.电影名或是电视剧名要区分是电影还是电视剧，2上映时间，年限即可 3.播放链接\n2506004169@qq.com\nhttps://www.zxzj.fun/list/1.html\nfrom 1 to 6.html\nquery:\nhttps://www.zxzj.fun/vodshow/1———–2022.html\nhttps://www.zxzj.fun/vodshow/1——–2—2021.html\nhttps://www.zxzj.fun/vodshow/4———–2022.html"
  },
  {
    "objectID": "posts/d711b4a9-eb5d-469c-a023-c6ef60977eb9/index.html",
    "href": "posts/d711b4a9-eb5d-469c-a023-c6ef60977eb9/index.html",
    "title": "Movie Scraping 2",
    "section": "",
    "text": "with douban link fetched from search, with id\nhttps://cokemv.me/voddetail/39184.html\nhttps://cokemv.me/\nhttps://cokemv.me/vodshow/5———–2021.html\nhttps://cokemv.me/vodshow/2——–2—2022.html"
  },
  {
    "objectID": "posts/66e8b272-cb07-4ec9-a59e-cff0c3cb654a/index.html",
    "href": "posts/66e8b272-cb07-4ec9-a59e-cff0c3cb654a/index.html",
    "title": "MongoDB Cheatsheet",
    "section": "",
    "text": "use redability.js reader mode or elinks to render this shit:\nhttps://www.mongodb.com/developer/products/mongodb/cheat-sheet/"
  },
  {
    "objectID": "posts/0ec5ddfb-4db1-4250-bf2a-6b3ad571bf77/index.html",
    "href": "posts/0ec5ddfb-4db1-4250-bf2a-6b3ad571bf77/index.html",
    "title": "Minor changes will defeat deduplicate algorithm while maintain overall fluency",
    "section": "",
    "text": "I found several evation methods, like paraphraser, random character swapper for text, and video blur, mirror to post the same video again. I guess it is essential not to let any part of the content look like the original one."
  },
  {
    "objectID": "posts/7ea1cd57-3ec4-421c-9f75-e5b552d52489/index.html",
    "href": "posts/7ea1cd57-3ec4-421c-9f75-e5b552d52489/index.html",
    "title": "Medium Subscription Bypass",
    "section": "",
    "text": "this site only unblock “restricted” articles. it does not offer “trending” “user homepage” “most read” “recommendation” things which you can get from official medium website.\nmap *.medium.com/[URL] to scribe.rip/[URL]\nor try to host scribe.rip yourself.\nsource code hosted on sourcehunt.\nalternative scribe instances seems all blocked (in mainland)"
  },
  {
    "objectID": "posts/f5284943-3cb6-4b3d-960f-fba8e14fa6ae/index.html",
    "href": "posts/f5284943-3cb6-4b3d-960f-fba8e14fa6ae/index.html",
    "title": "Markdown to PDF",
    "section": "",
    "text": "Gist on using python3 and PhantomJS\nnpm package: markdown-pdf"
  },
  {
    "objectID": "posts/5902663e-ca51-4206-8344-b9b6e7aa8d6b/index.html",
    "href": "posts/5902663e-ca51-4206-8344-b9b6e7aa8d6b/index.html",
    "title": "MacOS mount ntfs volumes",
    "section": "",
    "text": "macos mount ntfs read-only by default.\ncode from mounty.app\nmounty is somehow not working so manual remount is needed.\none needs to click the remount button to mount it again under /Users/jamesbrown/.mounty/Toshiba3000\nsudo umount /Volumes/Toshiba3000\nsudo mkdir /Volumes/Toshiba3000; sudo mount -t ntfs -o rw,auto,nobrowse /dev/&lt;diskIdentifier&gt; /Volumes/Toshiba3000"
  },
  {
    "objectID": "posts/cbd74007-1be1-4e11-af0b-585683b90e73/index.html#the-fix",
    "href": "posts/cbd74007-1be1-4e11-af0b-585683b90e73/index.html#the-fix",
    "title": "MacOS locate fix and alternative",
    "section": "the fix",
    "text": "the fix\nto enable the service:\nsudo launchctl load -w /System/Library/LaunchDaemons/com.apple.locate.plist\nto update locate db:\nsudo /usr/libexec/locate.updatedb\nor, more conveniently:\nsudo ln -s /usr/libexec/locate.updatedb /usr/local/sbin/updatedb\nsudo updatedb"
  },
  {
    "objectID": "posts/cbd74007-1be1-4e11-af0b-585683b90e73/index.html#alternative",
    "href": "posts/cbd74007-1be1-4e11-af0b-585683b90e73/index.html#alternative",
    "title": "MacOS locate fix and alternative",
    "section": "alternative",
    "text": "alternative\nuse mdfind"
  },
  {
    "objectID": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#interactive-interfaces",
    "href": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#interactive-interfaces",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "interactive interfaces",
    "text": "interactive interfaces\n\ngui\ncustom tkinter\n\n\ncli\nrich\ntextual"
  },
  {
    "objectID": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#related-infos",
    "href": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#related-infos",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "related infos",
    "text": "related infos\nthe art of commandline\nawesome jq"
  },
  {
    "objectID": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#interactive-tools",
    "href": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#interactive-tools",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "interactive tools",
    "text": "interactive tools\n\nweb based tools\nxpath tester for html\nexplainshell\nlivegrep\n\n\ncli tools\nijq interactive jq\njiq\n[percol](https://github.com/mooz/percol] supports pinyin\nugrep use ugrep -Q for interactive tui"
  },
  {
    "objectID": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#coding",
    "href": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html#coding",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "coding",
    "text": "coding\npython design patterns"
  },
  {
    "objectID": "posts/95886951-6430-4ced-b481-fb6f1d357b45/index.html",
    "href": "posts/95886951-6430-4ced-b481-fb6f1d357b45/index.html",
    "title": "Linux restore window sessions",
    "section": "",
    "text": "to relaunch app in given workspace\ntools:\nwmctrl\ndevilspie\nlaunch_on_workspace\nreferences:\nhttps://unix.stackexchange.com/questions/27050/how-to-start-an-application-on-a-different-workspace\nhttps://askubuntu.com/questions/89946/open-application-in-specific-workspace\nnpm install -g linux-window-session-manager\nrestore session manually\ndconf-editor\norg.gnome.gnome-session\nauto-save-session -&gt; on"
  },
  {
    "objectID": "posts/b96f551f-d2cd-4501-83a2-f91cf76bf7fa/index.html",
    "href": "posts/b96f551f-d2cd-4501-83a2-f91cf76bf7fa/index.html",
    "title": "Library System",
    "section": "",
    "text": "https://blog.csdn.net/cnmlgbnbcs/article/details/110643393?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164327697216780255279283%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%25\nwith database. without specific data.\nwith entity-relation diagram\n3302162875@qq.com"
  },
  {
    "objectID": "posts/7228a776-7b77-4765-96ca-29a000acd589/index.html",
    "href": "posts/7228a776-7b77-4765-96ca-29a000acd589/index.html",
    "title": "Kiwi Browser Bookmarks",
    "section": "",
    "text": "Kiwi Browser Bookmarks 2022/6/1\nlocation:\nsudo cp /data/user/0/com.kiwibrowser.browser/app_chrome/bookmarks.html ."
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#malware-hacking",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#malware-hacking",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "malware, hacking",
    "text": "malware, hacking\ndo it!"
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#referral-spam",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#referral-spam",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "referral spam",
    "text": "referral spam\nReferral spam is used to get into a targeted businesses analytics by visiting their\nsite multiple times with different IP’s from the domain you’re trying to market."
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#keyword-stuffing",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#keyword-stuffing",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "keyword stuffing",
    "text": "keyword stuffing\nencourage you to add more “hot” words, by training language model in a supervised way, or just use plain replace hacks."
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#open-graph-metadata-tag-easy-for-sharingadvertising-webpages-to-social-media",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#open-graph-metadata-tag-easy-for-sharingadvertising-webpages-to-social-media",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "open graph metadata tag, easy for sharing/advertising webpages to social media",
    "text": "open graph metadata tag, easy for sharing/advertising webpages to social media\nchange open graph data for same page once in a while\nopen graph tutorial\nfree open graph extractor"
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#scrape-and-rinse-content",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#scrape-and-rinse-content",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "scrape and rinse content",
    "text": "scrape and rinse content\nscrape from wayback machine (older but clean), check plagiarism in copyscape"
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#private-blog-networks",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#private-blog-networks",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "private blog networks",
    "text": "private blog networks\ncreate a bunch of websites, all refer to your own contents."
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#social-media-automation-tools",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#social-media-automation-tools",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "social media automation tools",
    "text": "social media automation tools\nInstagram: Instagress\nG+: Circlescope\nLinkedin: Elink\nTwitter: Managedflitter and Twitter toolkit\nchrome extension\nYoutube: Tubebuddy\nFacebook: Facebook automation toolkit\nchrome extension\nPinterest: NinjaPinner\nTumblr (blogging platform): Tumbleninja\nEmail: Pitchbox"
  },
  {
    "objectID": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#jumpcut-courses",
    "href": "posts/26a15cb5-2efd-447d-b331-8f24dff1a849/index.html#jumpcut-courses",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "jumpcut courses",
    "text": "jumpcut courses\njumpcut.com provides digital marketing courses:\nviral academy(free as youtube influencer 101 course), automated income machine(forbidden), video ads bootscamp(nothing, avaliable on freecoursedl.com), contageous content(currently premium)\nit features different camera angles of narriator’s portraits, relative animations and pdf sheets for fill-in-blank tasks. it emphasizes on email ads and audience funnel/filter.\nmany free course providers now offer jumpcut academy 2.0. they also offer technical analysis/ quantative analysis on marketing and other courses. though sometimes it is better to get to the code.\n中文的自媒体教程和它也是讲一个类型的内容，不过更倾向于实操和自动化。当然也有国外的自媒体教程。\n我觉得教程看太多了可能不利于代码实现。可以先把记录放在这里等待之后利用。\n搬运教程/课程也是一个好的方向，好的教程/课程需要被翻译或者洗稿，避免被维权。\n知乎上也有被我收藏下来的一个自媒体提高视频播放量的视频。他讲的是如何用连词，问句强行引起观众注意（拍摄技巧也可以强行引起观众注意，或者其他的方法，如连贯的语音）。可能知乎上面还有更多关于提高播放量以及和jumpcut有关的内容。"
  },
  {
    "objectID": "posts/97da2a2b-82c0-492b-871e-c55484e369fc/index.html",
    "href": "posts/97da2a2b-82c0-492b-871e-c55484e369fc/index.html",
    "title": "Jiggy boring still image to funny dance video 跳舞 舞蹈",
    "section": "",
    "text": "Jiggy boring still image to funny dance video\n最新版代码:\nhttps://github.com/transpchan/Live3D-v2\nMMD 格式转换工具：\nhttps://github.com/KurisuMakise004/MMD2UDP\n官网：https://transpchan.github.io/live3d/\nColab:https://colab.research.google.com/github/transpchan/Live3D-v2/blob/main/notebook.ipynb\nCoNR群：362985749\n【[ai绘画]仅用4张图片合成一段舞蹈视频-哔哩哔哩】 https://b23.tv/NaF20nA\n用到的资料和项目地址\nBV19V4y1x7bJ\nGitHub：https://github.com/megvii-research/CoNR\nGitHub：https://github.com/KurisuMakise004/MMD2UDP\n配音：基于VITS的弥希miki音声：BV1vW4y1e7bn\nbgm：风神少女\n视频如果有什么不对的地方，欢迎指出(▽)\n侵删\nstill image to dancing\neverybody dance now:\nhttps://github.com/carolineec/EverybodyDanceNow\nedn pytorch implenentation:\nhttps://github.com/Lotayou/everybody_dance_now_pytorch"
  },
  {
    "objectID": "posts/424fe97e-988e-4ca6-9021-8b3bfe1cdf45/index.html",
    "href": "posts/424fe97e-988e-4ca6-9021-8b3bfe1cdf45/index.html",
    "title": "Intel 9250 bluetooth Win server",
    "section": "",
    "text": "intel driver & support assistant\nhttps://www.intel.com/content/www/us/en/support/detect.html\nunzip the it admin pack for win 10\nhttps://www.intel.com/content/www/us/en/download/16807/intel-wireless-bluetooth-for-it-administrators.html\nfollow instructions to find and modify driver\nhttps://www.sevenforums.com/network-sharing/415513-intel-wifi-ac-9260-driver-fir-win7-x32-x64.html\nIntel has updated the drivers since my first post. Current is now 20.70\nDownload Intel(R) PROSet/Wireless Software and Drivers for IT Admins\nYou should be downloading WiFi_20.70.0_Driver64_Win7 (your first post mentions both x32 and x64 so I am not sure which one you are running. Hopefully x64) In the package is a Netwsw04.INF file but not a Netwsw03.INF file.\nSomething I did not think of until now, is we need to ALSO use the WIN10 download package in order to see the lines where Intel calls out your specific driver. To find that, you need to also download the WiFi_20.70.0_Driver64_Win10 package. Within it, we need to look at the Netwtw06.INF file which is the file that has your device. You will need to cut-n-paste the two lines within that file that contain the string PCI_8086&DEV_A370&SUBSYS_42A48086. Or better yet forget all that, I’ll just cut-n-paste them now and include them in screenshots. You can ignore the Win10 download altogether in order to keep things straight.\nSo we cut and paste those two lines and put them within the Netwsw04.INF file that is in the win7 package. The first one goes at the top of the excludefrom select part, and the next one goes at the top of the DEVICE WIN7_64 section. I will attach a screenshots now of what these new lines look like within my editor. They are the highlighted lines. Since you cannot cut and paste from an image, here is the text of the two lines:\n1st line\n; PCI_8086&DEV_A370&SUBSYS_42A48086 ,\n\n2nd line\n%NIC_9462AC_HMC% = Install_MPCIEX_DELLM2CRF3DIVERSITY_9462_AC_HMC_WINT_64_AC , PCI_8086&DEV_A370&SUBSYS_42A48086 ; AC\nAs I mentioned before, the first line is near the top of the Netwsw04.inf file and the second line is about 5 pages down.\nHere’s a caveat, a new piece of information that is a potential show-stopper. See where within the second line there are three places where it says “AC”? That appears related to how the setup file integrates the driver later on in the file. Well over in the Win10 package it does not actually say “AC”, instead it says “No_160”, which is something that is part of the win10 package but not part of the win7 package. Based on text within the win10 setup file (the one named Netwsw06.inf) there appears to be a special section specifically for Dell machines called No_160. I’m over my head as to what exactly it all means, other than to say that since there is no section in the Win7 package called No_160, I had to change No_160 to AC in order for the win7 file to process the line, and of course it is possible that this driver cannot install without the No_160 section, meaning it is not installable on win7. So what that all adds up to is that when I first replied to you I was giving this method about a 70% chance of working, but now I would put the odds at 30%."
  },
  {
    "objectID": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html",
    "href": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "",
    "text": "how to log error emitted from better-exceptions?\n\nlogging tutorial at betterstack & official\nother logging libraries: loguru structlog (able to show locals/globals around error)\n\nbetter-exceptions\n\nto ensure the consistency of tests, you need to collect input/output pairs (and compare with expected/actual output), if it is deterministic.\n\nmonkeytype, pytype (by google), runtype (Dispatch)\n\nbetter assertion\n\nenum class in python\n\nuse cache in pytest\nuse redis lru_cache, put decorators to json serializable functions\nuse build tools, forcing program to read and write files in the process\ntype checking using mypy\ncode static analysis\ncode formatter like black\n\ntools:\npydoit with “up to date” signals for non-file objectives\nscons\nruby rake"
  },
  {
    "objectID": "posts/8926a23b-7f8a-4942-9461-c762c8944427/index.html",
    "href": "posts/8926a23b-7f8a-4942-9461-c762c8944427/index.html",
    "title": "Image Restoration Upscaling",
    "section": "",
    "text": "Image Restoration Upscaling Inpainting 图像修复 超分辨率\nsota image inpainting: lama-cleaner still needs manual labeling on inpainting area\nhttps://github.com/DmitryUlyanov/deep-image-prior\nnas image prior\nhttps://arxiv.org/abs/2008.11713\nmmediting: OpenMMLab Image and Video Restoration, Editing and Generation Toolbox"
  },
  {
    "objectID": "posts/2f3128b0-1db9-4ac3-b437-f6247e04c1d6/index.html",
    "href": "posts/2f3128b0-1db9-4ac3-b437-f6247e04c1d6/index.html",
    "title": "Huggingface Mirror Sites",
    "section": "",
    "text": "methods on network issues\nmirror site\npartial mirror site"
  },
  {
    "objectID": "posts/4ede8deb-5415-4b95-9e45-98a7b3803ff4/index.html",
    "href": "posts/4ede8deb-5415-4b95-9e45-98a7b3803ff4/index.html",
    "title": "Master Hugo: A Comprehensive Guide to Installing and Theming Your Blog",
    "section": "",
    "text": "Hugo the blog generator\ninstall hugo:\nhttps://gohugo.io/getting-started/installing/\ninstall hugo from snap:\nsnap install hugo –channel=extended\ninstall on debian/ubuntu:\napt-get install hugo\nhugo themes:\nhttps://themes.gohugo.io\nhow to create hugo blog:\nhttps://blog.csdn.net/cumi7754/article/details/108101980"
  },
  {
    "objectID": "posts/5c8bc0fa-a84c-40db-9559-26f5230872e7/index.html",
    "href": "posts/5c8bc0fa-a84c-40db-9559-26f5230872e7/index.html",
    "title": "How to create cybergod",
    "section": "",
    "text": "https://www.novaspivack.com/business/the-four-levels-of-ai-steps-to-self-evolution\nhttps://www.novaspivack.com/business/exploring-higher-order-ai-training-on-first-order-ai-networks-for-optimal-path-outcomes\n\ni want to create some sort of agent, that learns autoregressively on historical tokens (not necessarily present in history, but close). however, when the agent is given some previous tokens, it is expected to send some actions to the environment in order to really observe the given tokens to get reward. the agent is not allowed to directly generate the token to the environment in order to prevent cheating. the agent is rewarded to successfully rebuild the past or predict and build the future. to predict the future is like the target token is generated by the agent itself instead of some automatic history replay bot, and the rest of the reward system follows the same way as the history replay reward system. this kind of system might have some sort of consciousness and therefore agi\nthe main objective of AGI is to create another version of itself.\nthe verification system can be built upon internal hidden tokens (you feel like you made it, feeling based) or similarity based (timeseries similarity or semantic similarity). there can be some external verification system such as lifespan, disk usage, view count, popularity, total capital etc.\n\nthe main problem of making this work is how to train it in parallel. the real world can be replaced by some world model (say some neural network) so that it can go back in time, or some really fast real world evaluators or some special world evaluators which supports time traversal, like virtual machine snapshots, web browsers (tab traversal). alphago has such advantage because go game is a very simple world model, while the real world is not.\nalso this could build some hierarchy like: real world -&gt; world model -&gt; agent -&gt; superagent -&gt; …"
  },
  {
    "objectID": "posts/40556f26-3fd8-4c7a-82ec-dbc6fcd9ae1b/index.html",
    "href": "posts/40556f26-3fd8-4c7a-82ec-dbc6fcd9ae1b/index.html",
    "title": "Home Assistant Installation & Setups",
    "section": "",
    "text": "Fully functional HA mainly comes into two forms: flashable supervised .iso images, and virtual machines (not docker container).\nRemember to create backup of HA after successful initialization. You can create an iso for the entire disk or just using backup utility builtin.\nSupervisor need to be updated before other components. It is also the troublemaker. Set auto update of supervisor to false by:\nha supervisor options --auto-update=false\nSince its heavy reliance on docker and github, one need to use OpenClash along with OpenWrt flashed in one dedicated router like NanoPi R2S to smooth the installation process.\nUse video capture card and OBS studio to observe the RPI terminal. Attach to keyboard to type commands.\nha banner sometimes resolves issues.\nTo prevent addon installation limits, you can enter debug mode, edit the following file /mnt/data/supervisor/jobs.json into:\n{\n\"ignore_conditions\": [\n\"healthy\"\n]\n}\nSome files like /etc/docker/daemon.json, /etc/hosts cannot be changed after boot. You can change them before boot using card reader."
  },
  {
    "objectID": "posts/f8de6157-4e2e-49e7-8d1b-8860e4e8184a/index.html",
    "href": "posts/f8de6157-4e2e-49e7-8d1b-8860e4e8184a/index.html",
    "title": "HarmonyOS Device Log to MySQL",
    "section": "",
    "text": "mysql path:\njdbc:mysql://10.33.163.33:3306/HTS_DB?characterEncoding=UTF-8\nroot\npipeline@123\nLogs Path:\n/data/data/Local/DeviceTest/20220406163617_hts_project/resources/HTS/android-hts/logs\nunder logs:\n%Y.%m.%d_%H.%M.%S_\nselect the latest folder\nunder selected folder:\ndevice_logcat_test__.txt.gz\ndecompress using: (before that os.chdir to the selected folder)\ngzip -d \ndoes the decompression remove the .gz file?\nit will.\nlog format per line:\nDfxTestLog: A1__DfxTestTime =  datai=4\nfrom 1 to 13:\nA1test1..4\nA2test5\nA3test1..2\nB1test1\nB2test4..6\nD1test1\nM1test1\nTables:\nPerformance_Baseline_Info\ntestValue date(%Y-%m-%d) hmsVersion(HMSCore660319) baselineId_id deviceId_id(1,2,4,3,5) deviceType(phone&lt;-1|wearable&lt;-2|car&lt;-4|tv&lt;-3|ecodevice&lt;-5)\nPerformance_Daily_Data\nid features indicators baseValue\nPerformance_Device_Info\nid(to the deviceId_id) model type sn cpu"
  },
  {
    "objectID": "posts/7cd366cf-6054-44e0-acd1-bf1b2c03286e/index.html",
    "href": "posts/7cd366cf-6054-44e0-acd1-bf1b2c03286e/index.html",
    "title": "Hardware Simulator",
    "section": "",
    "text": "pyspice uses ngspice and xyce as backend, capable of simulating MOS, JFET, diode and more"
  },
  {
    "objectID": "posts/2cc511d1-a1a3-4395-8b12-6494c1f54b37/index.html",
    "href": "posts/2cc511d1-a1a3-4395-8b12-6494c1f54b37/index.html",
    "title": "Graphcore support for AI",
    "section": "",
    "text": "Graphcore’s IPU could be cheaper and faster than NVIDIA’s A100, though need sharing on-board RAM.\nSupports tensorflow, pytorch, paddlepaddle.\nhttps://docs.graphcore.ai/en/latest/\npytorch: poptorch, pytorch-lightning(tpu and ipu)\ntensorflow:\nfrom tensorflow.python import ipu\n\nCreate an IPU distribution strategy\nstrategy = ipu.ipu_strategy.IPUStrategy()\nwith strategy.scope():\n…\npaddlepaddle:\nhttps://github.com/graphcore/portfolio-examples/tree/master/paddlepaddle/bert-base\nhttps://github.com/graphcore/Paddle.git\nTensorFlow 1 & 2 support with full performant integration with TensorFlow XLA backend\nPyTorch support for targeting IPU using the PyTorch ATEN backend\nPopART™ (Poplar Advanced Runtime) for training & inference; supports Python/C++ model building plus ONNX model input\nFull support for PaddlePaddle\nOther frameworks support coming soon"
  },
  {
    "objectID": "posts/9cb3307d-00f6-45e4-97b8-f4efcae21712/index.html",
    "href": "posts/9cb3307d-00f6-45e4-97b8-f4efcae21712/index.html",
    "title": "Unlocking Speed: FastGithub - Accelerating Github and StackOverflow",
    "section": "",
    "text": "Github and Stackoverflow acceleration\nhttps://github.com/dotnetcore/FastGithub"
  },
  {
    "objectID": "posts/d14fb8ce-450b-444a-870e-89b0b64646f0/index.html",
    "href": "posts/d14fb8ce-450b-444a-870e-89b0b64646f0/index.html",
    "title": "GPT-2 以及文本生成",
    "section": "",
    "text": "免费gpt文本生成：彩云小梦 以及小梦海外版\n小梦的中文文本有涉及政治的检测器 不能把敏感内容塞进小梦\n对话生成\nhttps://huggingface.co/thu-coai/CDial-GPT_LCCC-large/tree/main\ntwitter generator inspired by influencers:\nhttps://github.com/gdemos01/TwitterInfluencerAI\nchinese LM\n清华130b大模型\n测试地址：https://huggingface.co/spaces/THUDM/GLM-130B\n模型仓库：https://github.com/THUDM/GLM-130B\nhttps://github.com/Morizeyao/GPT2-Chinese\nhttps://zhuanlan.zhihu.com/p/352028922\nhttps://github.com/TsinghuaAI/CPM-1-Finetune\nhttps://github.com/TsinghuaAI/CPM-1-Generate\nhttps://github.com/TsinghuaAI/CPM-2-Pretrain\ngpt2/cpm tutorial:\nhttps://www.cnblogs.com/wwj99/p/12503545.html\nhttps://github.com/OpenBMB/BMInf-demos\nhttps://bmtrain.readthedocs.io/en/latest/index.html"
  },
  {
    "objectID": "posts/7da1cb0b-eb29-4636-b7b9-7384098ef379/index.html",
    "href": "posts/7da1cb0b-eb29-4636-b7b9-7384098ef379/index.html",
    "title": "Mastering Text Classification: Exploring NLP Techniques with BERT-NER, ALBERT-NER, GPT2, and More",
    "section": "",
    "text": "GAN for NLP text generation\nGAN Journey:\nhttps://github.com/nutllwhy/gan-journey\nNLPGNN:\nhttps://github.com/kyzhouhzau/NLPGNN\nExamples (See tests for more details):\nBERT-NER (Chinese and English Version)\nBERT-CRF-NER (Chinese and English Version)\nBERT-CLS (Chinese and English Version)\nALBERT-NER (Chinese and English Version)\nALBERT-CLS (Chinese and English Version)\nGPT2-generation (English Version)\nBilstm+Attention (Chinese and English Version)\nTextCNN(Chinese and English Version)\nGCN, GAN, GIN, GraphSAGE (Base on message passing)\nTextGCN and TextSAGE for text classification"
  },
  {
    "objectID": "posts/5fadf8ac-83f2-4fe0-9bf8-9fdd8a43f5ac/index.html",
    "href": "posts/5fadf8ac-83f2-4fe0-9bf8-9fdd8a43f5ac/index.html",
    "title": "GAN Generating video Motion Driven Still Image to Video",
    "section": "",
    "text": "thin plate spline motion model\nvideo animation generation only using few character portraits: 根据角色设定图画出人物动画（有动画驱动器）\nhttps://github.com/megvii-research/CoNR\ngalgame video generator using pygame（自动化类galgame动画生成器）:\nhttps://github.com/w4123/TRPG-Replay-Generator\ndigan, could generate taichi videos\nsuggest you to segment video first and then use this to do the freaking work.\nhttps://github.com/sihyun-yu/digan?ref=pythonawesome.com\nhttps://sihyun-yu.github.io/digan/\nhttps://pythonawesome.com/official-pytorch-implementation-of-generating-videos-with-dynamics-aware-implicit-generative-adversarial-networks/\nMoCoGAN can generate the same object performing different actions, as well as the same action performed by different objects:\nhttps://github.com/sergeytulyakov/mocogan\nstill image to talking with hands moving video generation compared to FOMM, can even animate non-human objects:\nhttps://snap-research.github.io/articulated-animation/\nmontage.ai generate video by music with deep analyzer:\nhttps://github.com/Tartar-san/montage.ai\ntiktok hashtag montage:\nhttps://github.com/andreabenedetti/tiktok-montage"
  },
  {
    "objectID": "posts/94bb28e3-8296-4cda-bde5-0fd0da8b7646/index.html",
    "href": "posts/94bb28e3-8296-4cda-bde5-0fd0da8b7646/index.html",
    "title": "Fall detection can be used for media filtering",
    "section": "",
    "text": "we can select falling videos collection for fun.\nit is based on human pose classification."
  },
  {
    "objectID": "posts/5bd93975-e7e6-4db6-abaf-0fbf877e0ff4/index.html",
    "href": "posts/5bd93975-e7e6-4db6-abaf-0fbf877e0ff4/index.html",
    "title": "Extract voice from professional sources",
    "section": "",
    "text": "You can source audio from audio books, radios, anime voices, soap series, movies, live streaming, broadcasting, tv and so on."
  },
  {
    "objectID": "posts/8a6267a2-bda4-4d09-a577-49dbf47fb6d3/index.html",
    "href": "posts/8a6267a2-bda4-4d09-a577-49dbf47fb6d3/index.html",
    "title": "Exception Phobia in Python",
    "section": "",
    "text": "pylint --enable=unspecified-exception your_python_file.py\nHowever it is recommend to build microservices and log failures"
  },
  {
    "objectID": "posts/d41c373e-6f19-48e1-af77-65970b759e26/index.html",
    "href": "posts/d41c373e-6f19-48e1-af77-65970b759e26/index.html",
    "title": "English Courseware scraping",
    "section": "",
    "text": "imman.ireadabc.com 账号：13408602063 密码：602063 按目录下载所有视频\ninit_url = “https://imman.ireadabc.com”\n\nthis url will not change at all.\nusername = “13408602063”\npassword = “602063”\nmain_url = “https://iteachabc.com/airclass_imman”\nhttps://iteachabc.com/imman/login?acsid=8974dc67-b02e-4f0d-a83f-a03cbe6f7fe4\n91reading.com 账号：jpa 密码：602063 按目录下载所有课件"
  },
  {
    "objectID": "posts/95f9a20e-c7a4-44c8-82f1-e132b275ce71/index.html",
    "href": "posts/95f9a20e-c7a4-44c8-82f1-e132b275ce71/index.html",
    "title": "Enable multiple concurrent RDP sessions on windows",
    "section": "",
    "text": "universal termsrv.dll patch\nuse patched termsrv.dll"
  },
  {
    "objectID": "posts/d390aaa5-3e74-45e7-ae34-f71cc492652e/index.html",
    "href": "posts/d390aaa5-3e74-45e7-ae34-f71cc492652e/index.html",
    "title": "Ecosim",
    "section": "",
    "text": "• You must demonstrate multiple examples of inheritance.\nYou may need to include classes that were not mentioned to demonstrate appropriate inheritance relationships.\n• You must demonstrate multiple examples of aggregation/composition/association. You may need to create lists of animals or tiles in the EcoSim class.\n• You must create methods not mentioned in the text above.\n• You must include one more type of animal, and one more plant in your program.\n• You must demonstrate polymorphism by calling overridden methods, or by checking the types of objects.\n• You must demonstrate good encapsulation by making dangerous variables private or protected and providing getter or setter methods to them.\n• You must include str and repr methods for each class. You may print(self) or print(animals) to help you with debugging.\n• You must update your UML diagram written in part 1 and submit it with your code.\n• Your code must be documented appropriately using docstrings.\n• You must make at least 10 commits using git with appropriate comments.\nYou must use git version control to keep track of your progress during implementation. Only a local git repository is required in this assignment. You are not required to use an online repository, but if you choose to, please make sure your online repository is private. You should perform regular commits as you implement features and fix errors. Your commit comments should be short and reflect the changes that were made.\n• You must write a unit test for the game.Vector2D class.\nYou will find Vector2D in the game.py file. You must create a new file called test_vector2d.py and write a test method for each of the following methods in Vector2D: add, subtract, scale, length, distance, normalize. You may either use the unittest or the pytest modules. Each test method should call those methods two times using different arguments: one safe set of arguments, and one dangerous set of arguments."
  },
  {
    "objectID": "posts/0b19ead6-6683-4487-a3e3-eb529002610d/index.html",
    "href": "posts/0b19ead6-6683-4487-a3e3-eb529002610d/index.html",
    "title": "Douyin or Tiktok Social Media Video Download",
    "section": "",
    "text": "Douyin/Tiktok Social Media Video Download\nvideo download:\nhttps://github.com/Evil0ctal/Douyin_TikTok_Download_API\nhttps://github.com/Johnserf-Seed/TikTokDownload\nhttps://github.com/rouze-d/tiktok-download\nhttps://github.com/CuriousYoda/tiktok-downloader\nvideo api and deduplication:\nhttps://github.com/VideoData/DY-Data\nmany scrapers:\nhttps://github.com/Jack-Cherish/python-spider\nvideo multi download tool:\nhttps://github.com/smalls0098/video-parse-tools\ntiktok scrapers:\nhttps://github.com/drawrowfly/tiktok-scraper\ntiktok api:\nhttps://dteather.com/TikTok-Api/docs/TikTokApi/tiktok.html\nhttps://github.com/davidteather/TikTokBot"
  },
  {
    "objectID": "posts/d21793d1-6f30-4238-a2a5-a4377d1b8650/index.html",
    "href": "posts/d21793d1-6f30-4238-a2a5-a4377d1b8650/index.html",
    "title": "Setting Docker Container Storage Quota with Overlay and Different Storage Drivers",
    "section": "",
    "text": "Docker container storage quota\n--storage-opt is supported only for overlay over xfs with ‘pquota’ mount option.\nchange data-root to somewhere else in /etc/docker/daemon.json\nedit /etc/fstab and add our xfs block on new line (find uuid using blkid)\ndocker run --storage-opt size=10M --rm -it alpine\nwhen using devmapper make sure size is greater than 10G (default)\ndocker run --storage-opt size=11G --r'm -it alpine\nzfs, vfs (not a unionfs, but for testing) storage drivers also supports disk quota. you may use it by changing data-root to the related storage device."
  },
  {
    "objectID": "posts/b09071dd-8ddc-4a64-b82e-2378ef495706/index.html",
    "href": "posts/b09071dd-8ddc-4a64-b82e-2378ef495706/index.html",
    "title": "Deepfake face swap",
    "section": "",
    "text": "deepfacelab leading software for faceswap video generation:\nhttps://github.com/iperov/DeepFaceLab\nfaceswap:\nhttps://github.com/deepfakes/faceswap\narbitrary face swap on one single model:\nhttps://github.com/neuralchen/SimSwap"
  },
  {
    "objectID": "posts/a104ad93-8ec0-40fc-bf05-b2719792ec82/index.html",
    "href": "posts/a104ad93-8ec0-40fc-bf05-b2719792ec82/index.html",
    "title": "DNS Proxy for Campus Network",
    "section": "",
    "text": "use kaggle for testing, if we can connect to it we are good for 12 hours.\nthe campus network allows dns query, might allow dns port based proxies.\nuse dig for DNS avaliability check.\ndig baidu.com\nhttps://www.a2hosting.com/kb/getting-started-guide/internet-and-networking/troubleshooting-dns-with-dig-and-nslookup\ndns proxies:\nhttps://code.kryo.se/iodine/\nhttps://0day.work/tunneling-all-traffic-over-dns-with-a-socks-proxy/\nhttps://serverfault.com/questions/962961/socks-proxy-over-dns"
  },
  {
    "objectID": "posts/5143f988-6ee1-41d3-b04b-1261934000e9/index.html",
    "href": "posts/5143f988-6ee1-41d3-b04b-1261934000e9/index.html",
    "title": "DALL_E Text to Image",
    "section": "",
    "text": "open sourced text to image:\nhttps://github.com/lucidrains/DALLE-pytorch\ndalle_mini:\nhttps://github.com/borisdayma/dalle-mini\njina ai human in the loop multi prompt text to image dalle-flow:\nhttps://github.com/jina-ai/dalle-flow\ndalle playground:\nhttps://github.com/saharmor/dalle-playground"
  },
  {
    "objectID": "posts/c500a693-b2ba-4f2c-a898-c751b801b650/index.html",
    "href": "posts/c500a693-b2ba-4f2c-a898-c751b801b650/index.html",
    "title": "Cyber Grand Challenge DARPA machine automated cyber attack",
    "section": "",
    "text": "ctfwiki’s intro on CGC\nanalyze source code first, then plan attack or fix code\ncgc’s github repo and website\nsearch for darpa cgc on github\ncyber-challenge Some toy examples, to demonstrate ideas that could be used in DARPA’s Cyber Grand Challenge including modifying java bytecode and filter out html requests on the fly\nEVIL (Exploiting software VIa natural Language) is an approach to automatically generate software exploits in assembly/Python language from descriptions in natural language. The approach leverages Neural Machine Translation (NMT) techniques and a dataset that we developed for this work.\nTopics\nlinux exploit encoder assembly decoder dataset seq2seq shellcode nmt software-exploitation codebert\nResources\nReadme\nLicense\nGPL-3.0 license\nStars\n13 stars\nWatchers\n3 watching\nForks\n1 fork\nReleases\nNo releases published\nPackages\nNo packages published\nContributors 2\n@piliguori\npiliguori Pietro Liguori\n@taisazero\ntaisazero Erfan Al-Hossami\nLanguages\nPython\n97.6%\nShell\n2.0%\nOther\n0.4%"
  },
  {
    "objectID": "posts/34d9a570-54f4-4073-a2ff-3405f9cf2b03/index.html",
    "href": "posts/34d9a570-54f4-4073-a2ff-3405f9cf2b03/index.html",
    "title": "Create sparse matrix based liquid state machine",
    "section": "",
    "text": "use tensorly to create random sparse tensor and eye sparse tensor with ease, which could be numpy only, and requires the sparse package.\nscipy, pytorch, tensorflow, jax all support sparse tensor construction but advanced apis are not.\nuse eye to create bias and input matrix, extract node values. use random sparse tensor to initialize weight matrix. use self matrix multiplication to perform propagation.\n\nthe human brain has roughly 87 billion neurons, and every one of them has thousands of synapses.\n\nimport torch\nlarge_number = 1_000_000\ntorch.arange(large_number).unsqueeze(0).repeat(2, 1)\nindex_arr = torch.arange(large_number).unsqueeze(0).repeat(2, 1)\nval_arr = torch.ones(large_number)\nsparse_eye = torch.sparse_coo_tensor(index_arr, val_arr, (large_number, large_number))\n# sparse_eye.to('cuda')\nalternatively:\nimport torch\nimport tensorly.contrib.sparse as tsl_sp\nlarge_number = 1_000_000\nnumpy_eye = tsl_sp.eye(large_number)\ntorch_eye = torch.sparse_coo_tensor(numpy_eye.coords, numpy_eye.data, numpy_eye.shape)"
  },
  {
    "objectID": "posts/b4aa7c90-7a78-4648-a687-ea9f3f21e207/index.html",
    "href": "posts/b4aa7c90-7a78-4648-a687-ea9f3f21e207/index.html",
    "title": "Copy Symlink itself to change pyjom’s location, install easyd services for macos local pyjom watchdog",
    "section": "",
    "text": "cd /media/root/parrot\ncp -R -P /media/root/help1/pyjom .\nbecause of the qqChatBot task, pyjom on kali may be syncing too often. need to check the watchdog logs.\nturned out it is the __pycache__ dirs to be blamed\ndisable all sync related services on macos for debug:\nmain issue happens after local vscode launched.\nthe issue is such that the proxy setting not right.\nto debug the service:\nsudo launchctl debug gui/501/pyjom_local_syncdog --stdout --stderr\n# to be succint:\nlaunchctl list | grep syncdog | awk '{print $1}' | xargs -I abc kill -s TERM abc\n# instead of:\n#launchctl list | grep pyjom_local_syncdog # to get process pid\n#kill -s TERM &lt;service_pid&gt;\nwe need to add some code for it. consider adding something alike to that to kali?\nos.environ[\"http_proxy\"]=\"http://localhost:7930\"\nos.environ[\"https_proxy\"]=\"http://localhost:7930\"\nlaunchctl stop gui/501/pyjom_local_watchdog;\nlaunchctl kill TERM gui/501/pyjom_local_watchdog;\nlaunchctl unload gui/501/pyjom_local_watchdog;\nlaunchctl disable gui/501/pyjom_local_watchdog;\nlaunchctl remove gui/501/pyjom_local_watchdog;\nlaunchctl stop gui/501/pyjom_local_syncdog;\nlaunchctl kill TERM gui/501/pyjom_local_syncdog;\nlaunchctl unload gui/501/pyjom_local_syncdog;\nlaunchctl disable gui/501/pyjom_local_syncdog;\nlaunchctl remove gui/501/pyjom_local_syncdog\ninstall macos pyjom watchdog (local):\neasyd -l pyjom_local_watchdog -w /Users/jamesbrown/Desktop/works/sync_git_repos -- /usr/bin/python3 /Users/jamesbrown/Desktop/works/sync_git_repos/watchdog_macos.py\ninstall macos pyjom syncdog (local):\neasyd -l pyjom_local_syncdog -w /Users/jamesbrown/Desktop/works/sync_git_repos -- /usr/bin/python3 /Users/jamesbrown/Desktop/works/sync_git_repos/syncdog_macos.py"
  },
  {
    "objectID": "posts/68f60906-848f-41c4-9dd8-817370e6d3d6/index.html",
    "href": "posts/68f60906-848f-41c4-9dd8-817370e6d3d6/index.html",
    "title": "Converting partial Zhihu viral content",
    "section": "",
    "text": "just add a trailing sentence.\n请听下回分解。"
  },
  {
    "objectID": "posts/fe79cdf7-de00-4775-8f79-ab2f150078a3/index.html#design-pattern",
    "href": "posts/fe79cdf7-de00-4775-8f79-ab2f150078a3/index.html#design-pattern",
    "title": "Code Batch Change Tool, Code Refactor Tool (the new sed)",
    "section": "design pattern",
    "text": "design pattern\nPyDesignPattern Design Pattern that described by Python, This is the source code for the book of Everybody Know Design Patterns."
  },
  {
    "objectID": "posts/fe79cdf7-de00-4775-8f79-ab2f150078a3/index.html#language-independent",
    "href": "posts/fe79cdf7-de00-4775-8f79-ab2f150078a3/index.html#language-independent",
    "title": "Code Batch Change Tool, Code Refactor Tool (the new sed)",
    "section": "language independent",
    "text": "language independent\ncomby.dev multiple language support\nsemgrep"
  },
  {
    "objectID": "posts/fe79cdf7-de00-4775-8f79-ab2f150078a3/index.html#language-specific",
    "href": "posts/fe79cdf7-de00-4775-8f79-ab2f150078a3/index.html#language-specific",
    "title": "Code Batch Change Tool, Code Refactor Tool (the new sed)",
    "section": "language specific",
    "text": "language specific\n\njavascript\njscodeshift refactor rewrite javascript code\n\n\npython\nredbaron repo and doc\nbowler\nrefactor\npasta"
  },
  {
    "objectID": "posts/8d3c7009-875d-4a6a-beea-25fb80b61889/index.html",
    "href": "posts/8d3c7009-875d-4a6a-beea-25fb80b61889/index.html",
    "title": "Cloud based Github Web IDE, VSCode auto commit and lightweight terminal IDE",
    "section": "",
    "text": "solved by gitfs\nlibgit2 sucks.\nmost stars\nthis gitfs is actually a searchable git history filesystem.\ntested\ngitee python api, first step is to get access token by login\ngitee apis\ncan we mount git/github repo as user filesystem(fuse)?\nusually read-only github/git filesystems, but this one is different. it is backed by writable github apis and is written in python, with python implementation of fuse which is updated here. this pygithub has trending api(maybe?) which is useful for social engineering or propaganda.\nwe could also implement a watchdog like system to check against the files using pygithub.\ncloud based github ide includes gitpod.io, github.dev, pythonanywhere but these are with serious limitations, most importantly without autocommit or too restricted to write code.\nbrowse github repo as remote filesystem(vscode insider):\nhttps://marketplace.visualstudio.com/items?itemName=github.remotehub\nthe vscode desktop is too resource heavy. though we have found a plugin to auto commit that also has a github repo to git repo(only for vscode insider):\nspacevim with custom color theme and nerdfont installed.\nspacevim documentation\nvim wiki by fandom\nrun multiple vim commands at once:\n:cd / | NERDTree"
  },
  {
    "objectID": "posts/e919aa98-5fee-4aa6-9ebc-56523403f6dd/index.html",
    "href": "posts/e919aa98-5fee-4aa6-9ebc-56523403f6dd/index.html",
    "title": "Chinese Input Method or Engine",
    "section": "",
    "text": "Chinese Input Method/Engine\nusing python:\nhttps://github.com/R0uter/LoginputEngine\npinyin2hanzi:\nhttps://github.com/letiantian/Pinyin2Hanzi\nPython chinese to pinyin:\nhttps://github.com/mozillazg/python-pinyin\npyim tsinghua dict(for emacs):\nhttps://github.com/redguardtoo/pyim-tsinghua-dict\nchinese input method dict converter:\nhttps://github.com/studyzy/imewlconverter"
  },
  {
    "objectID": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#model-selection",
    "href": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#model-selection",
    "title": "ChatGPT Local Version",
    "section": "Model Selection",
    "text": "Model Selection\nBelow are some models we are about to use:\n\nChatRWKV, or RWKV-based models, some are fine-tuned on alpaca dataset.\nChatGLM-6B, open-sourced by Tsinghua KEG, with INT4 quantized version.\nOpenAssistant by LAION-AI, trained on their own OIG dataset. There are also few models contributed by their discord community.\nAlpaca, trained on alpaca dataset (synthetic, generated by ChatGPT) by Standford University. Model weights are community provided.\nChatYuan by ClueAI.\n\nThere are quite a few more models to be listed. You can check this curated open-sourced ChatGPT-like model list for updates. But for now, these models shall be sufficient."
  },
  {
    "objectID": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#quantization-and-optimization",
    "href": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#quantization-and-optimization",
    "title": "ChatGPT Local Version",
    "section": "Quantization and Optimization",
    "text": "Quantization and Optimization\nFloating-point values in model weights are stored as 32bit. Quantization can reduce storage space and computation by switching to 16bit, 8bit or 4bit values. However, most quantized models cannot be trained or fine-tuned, some 16bit models can only be trained on certain architecture of GPUs, such as Ada and Turing.\nTo make LLM (Large Language Model) inference feasible on common hardware, GPU is usually mandatory. However, most commondity GPUs have smaller VRAM compared to RAM, limiting the size of LLM to be run, thus the capability of the LLM. Most computer have 12GB of VRAM, 32GB of RAM. GGML is a project aiming to make LLM inference on CPU as fast as GPU, utilizing larger RAM compared to VRAM to run larger LLMs. Currently some popular LLMs have been ported to GGML, like LLaMA and Alpaca."
  },
  {
    "objectID": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#training-and-fine-tuning",
    "href": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#training-and-fine-tuning",
    "title": "ChatGPT Local Version",
    "section": "Training and Fine-tuning",
    "text": "Training and Fine-tuning\nIn deeplearning, people tend to tune all parameters during training, requiring much VRAM and time. To train GPT3.5 aka ChatGPT, OpenAI spends millions to rent interconnected A100 GPUs. This is impossible for an individual to afford such.\nWith technologies like LoRA, by freezing most part of the model and introducing a small fraction of tunable parameters, training requirements can be greatly reduced. One can easily tune 7B LLaMA or 14B RWKV using LoRA on a PC (usually rented on the cloud, such as AutoDL) with a single 80GB A100 card and 200GB of RAM."
  },
  {
    "objectID": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#prompting-and-chaining",
    "href": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#prompting-and-chaining",
    "title": "ChatGPT Local Version",
    "section": "Prompting and Chaining",
    "text": "Prompting and Chaining\nLLMs are general problem solvers given enough external storage and access to search engines. Text is the only way to language models (not for multimodal LLMs, like GPT4, OFA or UniLM).\nTo enhance the capability of LLMs, you have to maintain its memory, define action keywords and trigger external actions during the conversation, connect it to semantic search engines powered by other AI models like sentence transformers.\nOne such library is LangChain."
  },
  {
    "objectID": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#serving-as-api",
    "href": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html#serving-as-api",
    "title": "ChatGPT Local Version",
    "section": "Serving as API",
    "text": "Serving as API\nThe process of generation for LLMs is sequential. Server needs to maintain a streaming API to match this behavior. Tokens are fetched one by one from the server with a constant speed, revealed in the frontend.\nOne can check third-party frontend-only or self-hosted projects for conversational LLMs for reference."
  },
  {
    "objectID": "posts/a9fb79ed-75f9-4505-96ca-b72a33d76511/index.html",
    "href": "posts/a9fb79ed-75f9-4505-96ca-b72a33d76511/index.html",
    "title": "Cats video with lyrics_1",
    "section": "",
    "text": "Cats video with lyrics (Lyrics)\nAgain i want to start finding lyrics, tired of sourcing & analyzing videos.\n一系列的视频观众都要看下去 那么下一期视频最好就是用该类视频的推荐下一个（类）视频作为模板来做的\nusing yolov7 to detect and cut cat/dog videos.\nhttps://github.com/WongKinYiu/yolov7\nagain found in github.\nnetease music’s apis have been reverse engineered on github.\nhttps://github.com/Binaryify/NeteaseCloudMusicApi\nwhat about spotify apis?\nhttps://github.com/thelinmichael/spotify-web-api-node (credentials are optional)\nhttps://github.com/JMPerez/spotify-web-api-js\nhttps://github.com/plamere/spotipy\nhttps://github.com/0xHJK/music-dl\nalso its proxy scraper.\npip3 install pymusic-dl\nwrite a redirect plugin in tampermonkey, from github to hub.fastgit.org\nagain, done by you-get. but how do we search the uri? you need to dig into the music_dl.\nso we are done in preposessing or anything?\nnow we need to find a bunch of cats.\ncats are found on weibo."
  },
  {
    "objectID": "posts/fc18f6ac-1fc3-4573-b435-c59310b8ecd3/index.html",
    "href": "posts/fc18f6ac-1fc3-4573-b435-c59310b8ecd3/index.html",
    "title": "Call python in clojure, clojure-python bridge",
    "section": "",
    "text": "libpython-clj deep python integration in clojure\nembed clojure in python call clojure in python"
  },
  {
    "objectID": "posts/828d50cf-9486-4c4a-a8b2-3cbc4b6c9690/index.html",
    "href": "posts/828d50cf-9486-4c4a-a8b2-3cbc4b6c9690/index.html",
    "title": "Boot into Linux commandline (tty)",
    "section": "",
    "text": "when xorg fails, one must use commandline to debug problems.\nput ‘3’ after the longest line of boot commands.\nuse ssh to collect logs even if the main interface is stuck somehow (like libinput faliure)\nreference:\nhttps://www.linuxandubuntu.com/home/how-to-boot-into-linux-command-line/amp"
  },
  {
    "objectID": "posts/8271cc1a-a116-4398-ab9f-7d1811887bca/index.html",
    "href": "posts/8271cc1a-a116-4398-ab9f-7d1811887bca/index.html",
    "title": "Beautify 美颜",
    "section": "",
    "text": "opencv bilateral filter python\nimport cv2 as cv\nimg = cv.imread('image.jpg')\nbilateral = cv.bilateralFilter(img, 15, 75, 75)\ncv2.imwrite('img_bilateral.jpg', bilateral)\nhttps://github.com/xujingzhou/VideoBeautify\npython美颜瘦脸\nhttps://github.com/Sharpiless/opencv-pyqt-makeup-software\nhttps://github.com/geeklili/Opencv_PIL\nhttps://github.com/PerpetualSmile/BeautyCamera\nJavaScript 美颜\nhttps://github.com/KikyoMiao/beauty"
  },
  {
    "objectID": "posts/7ec85622-fff2-4323-83e7-5b02913e2ab1/index.html",
    "href": "posts/7ec85622-fff2-4323-83e7-5b02913e2ab1/index.html",
    "title": "BDD behavior driven development",
    "section": "",
    "text": "behave doc pypi\npytest-bdd"
  },
  {
    "objectID": "posts/28f2c636-2561-4c66-a195-5cc94df36bc5/index.html#for-macos-and-linux",
    "href": "posts/28f2c636-2561-4c66-a195-5cc94df36bc5/index.html#for-macos-and-linux",
    "title": "Automatic CMCC network switching",
    "section": "for macos and linux:",
    "text": "for macos and linux:\nif modifier hotspot is present, connect to it.\notherwise if CMCC present, connect to it.\nif CMCC fails after login attempts, try to connect with some paid network."
  },
  {
    "objectID": "posts/28f2c636-2561-4c66-a195-5cc94df36bc5/index.html#for-modifier",
    "href": "posts/28f2c636-2561-4c66-a195-5cc94df36bc5/index.html#for-modifier",
    "title": "Automatic CMCC network switching",
    "section": "for modifier:",
    "text": "for modifier:\nif CMCC present, connect to it.\nif CMCC fails, try to connect with some paid network.\ninternet switch will be manually turned on, to save power."
  },
  {
    "objectID": "posts/e35030a6-4562-4f9e-8eb9-90ceb0bd5100/index.html",
    "href": "posts/e35030a6-4562-4f9e-8eb9-90ceb0bd5100/index.html",
    "title": "Royalty Free Video/Picture/Audio Sources",
    "section": "",
    "text": "download video without watermark 😛 源视频mp4链接获取: toutiao今日头条app视频;🍉xigua西瓜视频; 🐧tencent腾讯视频; 🎼douyin抖音分享短链接解析，获取无水印播放链接\n目标追踪使用bytetrack\n如果有动态水印 实际上就是一个目标追踪的任务 识别出来水印的位置 以及里面的文字 确定可信度 然后用目标跟踪算法套上去 一直跟踪直到目标消失为止\n类似的策略也可以应用于游戏 选出来所有的过场动画 过滤掉游戏画面\n静态的就用dewatermark算法就好了\n视频素材 影视素材 音频素材 图片素材 无水印获取\nuse bing wallpaper\ngettyimages scraped by github provided scrapers\nhttps://github.com/chuanenlin/shutterscrape\nhttps://github.com/m-rots/getty/blob/master/getty.go\n视觉中国 无水印爬虫"
  },
  {
    "objectID": "posts/ad54ad82-1316-4bf0-8d5b-9dc82537d356/index.html",
    "href": "posts/ad54ad82-1316-4bf0-8d5b-9dc82537d356/index.html",
    "title": "Attractive Dynamic plus attractive video",
    "section": "",
    "text": "Some contents are viral to the users. Will add extra watches if combined with related video or essay.\nMay apply the same rule to other platforms. Must select those with largest views, or verified by trained grading models. Native language only, or we have to translate and verify/convey it into native form. Post it to QQ, other platforms in the form of pictures, links."
  },
  {
    "objectID": "posts/fcdd7d7c-f812-421e-9c96-67407ebe73d3/index.html",
    "href": "posts/fcdd7d7c-f812-421e-9c96-67407ebe73d3/index.html",
    "title": "Anime smile detection_ segmentation",
    "section": "",
    "text": "Anime smile detection/ segmentation\nwhen an anime head is detected, cut it out and create dataset with labels. may augmented it with grayscale or edge detection.\nsegmentation using labeled data and train it on pretrained models. using anme head detection as double verification. no double heads.\nppse recognition may be applied without further training, or else.\n我分析需要YOLO确定人物位置 CNN判断服装类型 人物性别 ocr识别字幕 音频分析识别语气 性别 音乐类型 再用seq2seq来把所有的输出概括成我的描述\n或者看看有没有文字转关键词的模型\n可以的话加上人物姿态估计 动漫人物的\n关于光流算法：\n熵就是梯度的标准差\n一段范围的熵就是起始时间到末尾的熵的标准差\n或者起始到末尾的梯度的标准差"
  },
  {
    "objectID": "posts/ffa78a99-c9b8-4e05-9092-2069bbaaa245/index.html",
    "href": "posts/ffa78a99-c9b8-4e05-9092-2069bbaaa245/index.html",
    "title": "Android Emulators",
    "section": "",
    "text": "WayDroid\nanbox?"
  },
  {
    "objectID": "posts/aa8d7a4c-8554-4045-b60b-e45d331ada07/index.html",
    "href": "posts/aa8d7a4c-8554-4045-b60b-e45d331ada07/index.html",
    "title": "Algorithms Compilers SICP CLRS CT4S",
    "section": "",
    "text": "the algorithms\nintroduction to algorithms clrs 4th edition in python:\nhttps://zhuanlan.zhihu.com/p/466819939\nofficial clrs 4th edition python code\nclrs 4th pdf\nclrs 3th edition python code:\nhttps://github.com/tonywangcn/Introduction-to-Algorithms-3rd-Edition-python-code\nsicp in python gitbooks:\nhttps://wizardforcel.gitbooks.io/sicp-in-python/content/18.html\nalgorithms 4th edition official java unofficial python code:\nhttps://github.com/kevin-wayne/algs4\nhttps://github.com/shellfly/algs4-py\nhttps://github.com/itu-algorithms/itu.algs4"
  },
  {
    "objectID": "posts/f131dd9f-364f-40cc-a6ba-2930322cf89f/index.html",
    "href": "posts/f131dd9f-364f-40cc-a6ba-2930322cf89f/index.html",
    "title": "Agile Freelancing",
    "section": "",
    "text": "Apps like QQ, Wechat, Dingtalk can be launched on linux, windows.\n闲鱼要anbox 在 Windows上面需要虚拟机 或者直接http投屏就可以 也可以监控的\ndeepin derivative container"
  },
  {
    "objectID": "posts/28ea45cc-7d4f-41d2-a41c-51d0fecdec23/index.html#lrc-files",
    "href": "posts/28ea45cc-7d4f-41d2-a41c-51d0fecdec23/index.html#lrc-files",
    "title": "Advanced ASS subtitle Karaoke Effects",
    "section": "lrc files",
    "text": "lrc files\ncrop music that does not sing too early? maybe no need.\nwe need to sort them out by time! prevent serious issues.\nskip empty lines?\nlrc files only have start time but no end time.\nwe group parallel lyrics by time, if they are close enough we make it into a group.\ngroups act as time separators. no two group share the same time. also group have maximum span time, minimum span time calculated by content, and group should always in bound.\nshould apply the same min-max rule when selecting my video clips\nall ass file tags, for custom karaoke effects creation\nmy karaoke effect:\n{\\k-50\\K400}\n{\\k-&lt;initial offset&gt;\\K&lt;total duration&gt;}\n\nplay ass file with mpv on demo video, full screen, no audio:\nrootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\ncreate karaoke effects\nhttps://github.com/Kagu-chan/FXSpindle\nkaraoke effects\nhttps://github.com/Youka/NyuFX\npyonfx code\nrecommend to use effect 2 beginners -&gt; 3 variants in examples, while 3 advanced -&gt; 2 testing pixels as reference (more advanced but incomplete, and might be very intensive)\npyonfx documentation\nhttps://github.com/logarrhythmic/karaOK\naegisub and its plugins\nhttps://github.com/Myaamori/aegisub-cli\nhttps://github.com/qwe7989199/Lyric-Importer-for-Aegisub\nhttps://github.com/qwe7989199/aegisub_scripts\nhttps://github.com/lyger/Aegisub_automation_scripts\nhttp://www.aegisub.org/\neyecandy create karaoke ass files:\nhttps://github.com/Alquimista/Eyecandy-py\ncreate karaoke effects subtitle with lrc file, support chinese\nhttps://github.com/DYY-Studio/lrc2ass_py3"
  },
  {
    "objectID": "posts/61fc1fa0-0854-45a8-bd25-5409bc56f5d3/index.html",
    "href": "posts/61fc1fa0-0854-45a8-bd25-5409bc56f5d3/index.html",
    "title": "APFS for Linux",
    "section": "",
    "text": "i use this adapter to transfer files (you know that) to kali.\nread only support. if write then the filesystem will break.\napfs-fuse read-only, single executable, no kernel module\nlinux-apfs-rw kernel module, read/write support"
  },
  {
    "objectID": "posts/ca55270b-02a3-4943-92b2-b4d595e3e9d7/index.html",
    "href": "posts/ca55270b-02a3-4943-92b2-b4d595e3e9d7/index.html",
    "title": "AI上色",
    "section": "",
    "text": "AI上色 ffmpeg去特定颜色 调色\n可能和GAN有关\nuse paddlegan for coloring\n可以去掉血腥色情 暴力可能不行 需要剪辑\nFFmpeg remove color:\nhttps://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video\nhttp://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/\nface coloring:\nhttps://github.com/Xu-Justin/Grayscale-Face-Coloring\nnvidia coloring:\nhttps://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/\ngithub topic on image colorization:\nhttps://github.com/topics/image-colorization\ngithub repos on image colorization:\nhttps://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image\nhttps://github.com/aDouladiris/Grayscale-Image-Colorization\nhttps://github.com/aakaashjois/Colorizing-Grayscale-Images\nhttps://github.com/emilwallner/Coloring-greyscale-images\ncurated list on image colorization:\nhttps://github.com/oskar-j/awesome-image-coloring"
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#obs-remote-control",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#obs-remote-control",
    "title": "AGI that controls computer",
    "section": "obs remote control",
    "text": "obs remote control\nusing obs-websocket you can use python to do real scripting. but first spin up obs first (with websocket related commandline arguments)\nyou can also write and load scripts for obs, run on custom intervals and conditions."
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#audio-recording",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#audio-recording",
    "title": "AGI that controls computer",
    "section": "audio recording",
    "text": "audio recording\nyour OS may go slient if you want to record audio from “speakers”\n\nusing pyaudio, on macos, you need blackhole for sending all audio to oblivion, thus able to be recorded.\non Linux, you need audio loopback device.\nrun: sudo modprobe snd-aloop\nyou use hw:1:0 or “Analog Device Output” for slient output/speaker, and use hw:1:1 or “Analog Device Input” for recording."
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#benchmarks",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#benchmarks",
    "title": "AGI that controls computer",
    "section": "benchmarks",
    "text": "benchmarks\nit is always a mystery for us to develop the right ML model. however, we can setup guidelines of good performance over specific task.\nautomate the benchmark, setup metrics. there could be more room for trials and imagination."
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#encoding",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#encoding",
    "title": "AGI that controls computer",
    "section": "encoding",
    "text": "encoding\nuse hfft/rfft to transform multipart inputs (special bits, different part of mouse coords (x, y, dx, dy))\nif you want to use complex number as RNN input, you may need to swap ViT for ComplexConv2D, but maybe you just need a few.\n\nlibraries that handle complex neural networks:\ncomplexPyTorch\npytorch-complex"
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#multimodal",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#multimodal",
    "title": "AGI that controls computer",
    "section": "multimodal",
    "text": "multimodal\ndo our model have to output multimodal data?\nif you combine some “special” bits along with token embeding by ihfft, you may have to retrain the entire damn network. also in order to make way for special bits, you may have to introduce extra linear layer.\n\nsome may prefer “LoRA”? by only introducing few tunable params and changing the overall output?\n\nwe may not annotate anything in our dataset. in contrast, we will set goals and make multiple interfaces for our model to explore.\n\nyou can add special task specific embedding before passing to main model, then minus that task specific embedding after passing to classification model."
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#file-sharing-and-communication",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#file-sharing-and-communication",
    "title": "AGI that controls computer",
    "section": "file sharing and communication",
    "text": "file sharing and communication\nmake sure you don’t share important files as read/write on VM.\n\nyou may host some “execution server” on UTM VMs. you may expose your very large hard disk using WebDAV server. i think x11vnc and other vnc server may suffice for linux, but we always want to listen to the real operational data, including human operation/intervention, not just those in VNC protocols.\n\nWebDAV servers:\nwsgidav (python)\nwsgidav --host=192.168.64.1 --port=8081 --root=\"/Volumes/Toshiba XG3/works/agi_computer_control\"  --auth=anonymous\nwebdav-cli （nodejs)\nwebdav-cli --host=192.168.64.1 --port=8081 --username=root --password=root --path=\"/Volumes/Toshiba XG3/works/agi_computer_control\""
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#video-recording",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#video-recording",
    "title": "AGI that controls computer",
    "section": "video recording",
    "text": "video recording\nfor Ubuntu ARM VM, mss failed on wayland but pyautogui works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps.\n\nforcing ubuntu to use xorg by: sudo vim /etc/gdm3/custom.conf"
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#resize-utm-vm-disks",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#resize-utm-vm-disks",
    "title": "AGI that controls computer",
    "section": "resize UTM VM disks",
    "text": "resize UTM VM disks\nyou need to first resize the virtio disk in utm setting, then resize partition by using gparted, then update the device mapper"
  },
  {
    "objectID": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#google-research",
    "href": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#google-research",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "google research",
    "text": "google research\ngwern wrote a fiction. he thinks agi starts from automl-zero which is similar to lazero and metalazero by name and perspective.\nby design lazero can be deeply aligned, inspecting and studying user’s actions. it also has its own exploration space. however, these expectations can never be fully satisfied at the same time. if you want more power, you have to let go."
  },
  {
    "objectID": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#lucidrains-repositories",
    "href": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#lucidrains-repositories",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "lucidrains repositories",
    "text": "lucidrains repositories\nthis one got lots of state-of-the-art implementations for close-sourced papers and also repos for AGI. stunning.\n\nAGI related\nJEPA-pytorch (WIP) yann lecun’s version how agi will be built\nPaLM scaling language model with pathways\n\n\nside projects\nmake a video text to video generation\nnuwa text to video generation"
  },
  {
    "objectID": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#opencog",
    "href": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#opencog",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "opencog",
    "text": "opencog\nmoses (supervised) for evolutionary program synthesis"
  },
  {
    "objectID": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#repos-on-github",
    "href": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#repos-on-github",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "repos on github",
    "text": "repos on github\nhe4o\naixijs general reinforcement learning in browser repo\nopennars\nbrain simulator 2 on windows platform"
  },
  {
    "objectID": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#materials-and-links",
    "href": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html#materials-and-links",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "materials and links",
    "text": "materials and links\nDQfD: Learning from Demonstrations for Real World Reinforcement Learning (paper)\nmit class on AGI\njiaxiaogang’s god-knows-what theory and training logs\nawesome deep reinforcement learning (deep-rl)\nawesome agicocosci exhausitive list of papers and repos for cognitive science and AGI\nintroduction and links on AGI"
  },
  {
    "objectID": "posts/4a958713-a97e-415e-93af-ddcafa646af4/index.html",
    "href": "posts/4a958713-a97e-415e-93af-ddcafa646af4/index.html",
    "title": "Unlocking the Secrets of Dreams: Brainwave Translation Explained",
    "section": "",
    "text": "brainwave translation\ninteresting dreams were found\nextract text, audio, visual, melody"
  },
  {
    "objectID": "posts/77ef81a1-4a56-4508-aa63-4872cf4370d5/index.html",
    "href": "posts/77ef81a1-4a56-4508-aa63-4872cf4370d5/index.html",
    "title": "Discovering Zero-Day Exploits and Vulnerabilities in School Management Systems",
    "section": "",
    "text": "0day exploit finder recon\n学校后台漏洞\nedusrc 0day\nbluecms 0day"
  },
  {
    "objectID": "posts/af744580-ee9a-42b5-887b-fc97e1e342e3/index.html",
    "href": "posts/af744580-ee9a-42b5-887b-fc97e1e342e3/index.html",
    "title": "2022-08-18-03-35-56",
    "section": "",
    "text": "i decided to push myself a little bit by setting up schedules. no due date but it might make it clear for me to work on which project first.\nthough i could write what i want to do next in diary of course. the primary target is to make general schedules of course, the second or the target afterwards is to complete the development of the dog video generator."
  },
  {
    "objectID": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#seed-generation",
    "href": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#seed-generation",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "seed generation",
    "text": "seed generation\n\nAI based\nSkyfire (learn a probabilistic CFG grammar)\nLearn&Fuzz (learn a RNN model of valid inputs)\nGAN (learn a GAN to generate legitimate seeds)\nNeuzz (learn a NN to model input -&gt; coverage)\n\n\nSymbolic Execution\nDriller\nQSYM\nDigFuzz\nSAVIOR\nIntriguer\nMatryoshka\nHFL\n\n\nstatic/dynamic analysis\nFANS"
  },
  {
    "objectID": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#seed-mutation",
    "href": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#seed-mutation",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "seed mutation",
    "text": "seed mutation\n\nAI based\nMopt\nLSTM\nRL\nILF\n\n\nprogram based\nVUzzer\nGreyOne"
  },
  {
    "objectID": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#efficient-testing",
    "href": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#efficient-testing",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "efficient testing",
    "text": "efficient testing"
  },
  {
    "objectID": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#coverage-metrics",
    "href": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html#coverage-metrics",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "coverage metrics",
    "text": "coverage metrics"
  },
  {
    "objectID": "posts/0718efd7-93a5-4b61-be76-fa8292925a04/index.html",
    "href": "posts/0718efd7-93a5-4b61-be76-fa8292925a04/index.html",
    "title": "(de)obfustication, junk code insertion and removal",
    "section": "",
    "text": "common packers:\nThemida, Code Virtualizer, VMProtect, ExeCryptor\ngeneral method for deobfustication\nsee github topic\nprotectors\nJunk Code Generator and Polymorphic Code Engine Guide\nida pro junk code removal"
  },
  {
    "objectID": "posts/b7f08b1f-e6c0-4c0a-b740-b9d4b7fed842/index.html#recommendation-system",
    "href": "posts/b7f08b1f-e6c0-4c0a-b740-b9d4b7fed842/index.html#recommendation-system",
    "title": "Exploring Popular AI Libraries and Tools for Various Tasks",
    "section": "recommendation system",
    "text": "recommendation system\ncrab\nsurprise\npython recsys recommendation system\nlightfm recsys"
  },
  {
    "objectID": "posts/cc1e47b5-db3d-41e0-a6b3-a489fb104747/index.html",
    "href": "posts/cc1e47b5-db3d-41e0-a6b3-a489fb104747/index.html",
    "title": "Exploring Python Libraries and Resources for Nmap Network Scanning",
    "section": "",
    "text": "nmap python scripting\npython3-nmap and doc\ndoc of nmapthon python scriptable nse\npython-nmap"
  },
  {
    "objectID": "posts/cba7c9c1-43f4-46d6-9eed-b25c02a5eba4/index.html",
    "href": "posts/cba7c9c1-43f4-46d6-9eed-b25c02a5eba4/index.html",
    "title": "Introducing Ntfy: A Service for Publishing Messages and Monitoring Statuses on a Dashboard",
    "section": "",
    "text": "message publishing, message queue, status viewer, dashboard\nntfy"
  },
  {
    "objectID": "posts/ba662518-ad5e-4f7c-a657-c6d49067a408/index.html",
    "href": "posts/ba662518-ad5e-4f7c-a657-c6d49067a408/index.html",
    "title": "Generating 3D Models from Images with the 3d-Moments Tool",
    "section": "",
    "text": "2d转3d 图片生成3d模型\n几张类似的图片 生成一个3d的视频\nhttps://3d-moments.github.io"
  },
  {
    "objectID": "posts/349492fe-5f38-4cb2-8f15-4876dae24ea2/index.html#tool-repository",
    "href": "posts/349492fe-5f38-4cb2-8f15-4876dae24ea2/index.html#tool-repository",
    "title": "AI tools collections",
    "section": "tool repository",
    "text": "tool repository\ni was informed by a post on zhihu.\nfuturepedia\ncreatives\nfuturetools\ngetinference"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#text-annotation-tool",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#text-annotation-tool",
    "title": "AI训练集标注工具",
    "section": "text annotation tool:",
    "text": "text annotation tool:\nhttps://github.com/doccano/doccano\nsqlite 3 backend:\npip3 install doccano"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#videoimage-annotation-tool-needs-docker-with-online-demo",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#videoimage-annotation-tool-needs-docker-with-online-demo",
    "title": "AI训练集标注工具",
    "section": "video/image annotation tool, needs docker, with online demo:",
    "text": "video/image annotation tool, needs docker, with online demo:\nhttps://github.com/openvinotoolkit/cvat"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#image-labeling",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#image-labeling",
    "title": "AI训练集标注工具",
    "section": "image labeling:",
    "text": "image labeling:\nhttps://github.com/heartexlabs/labelImg"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#with-audio-video-support",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#with-audio-video-support",
    "title": "AI训练集标注工具",
    "section": "with audio video support",
    "text": "with audio video support\nhttps://github.com/heartexlabs/label-studio"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#with-audio-transcription-support",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#with-audio-transcription-support",
    "title": "AI训练集标注工具",
    "section": "with audio transcription support",
    "text": "with audio transcription support\nhttps://github.com/UniversalDataTool/universal-data-tool"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#image-and-audio",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#image-and-audio",
    "title": "AI训练集标注工具",
    "section": "image and audio",
    "text": "image and audio\nhttps://github.com/Cartucho/OpenLabeling"
  },
  {
    "objectID": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#specialized-for-yolo-bounding-boxes",
    "href": "posts/fda36896-d174-4011-ae7c-f5e913ea4f74/index.html#specialized-for-yolo-bounding-boxes",
    "title": "AI训练集标注工具",
    "section": "specialized for yolo bounding boxes",
    "text": "specialized for yolo bounding boxes\nhttps://github.com/developer0hye/Yolo_Label"
  },
  {
    "objectID": "posts/1a102161-f210-44fc-9762-6dafade1bed4/index.html",
    "href": "posts/1a102161-f210-44fc-9762-6dafade1bed4/index.html",
    "title": "Choosing the Perfect AR/VR Glasses: Clear, Comfortable, and Well-Ventilated",
    "section": "",
    "text": "AR VR 眼镜 选取方法 固定方法\n看得清字 边缘清晰 不模糊\n轻便 不重\n可以和帽子固定在一块 帽子再加上个固定在下巴的绑带 注意散热"
  },
  {
    "objectID": "posts/c0a2ff3b-8a78-4642-bd6d-bd6ad5040bc4/index.html",
    "href": "posts/c0a2ff3b-8a78-4642-bd6d-bd6ad5040bc4/index.html",
    "title": "After Termux Reinstallation",
    "section": "",
    "text": "grant permission for termux:api\nandroid.permission.WRITE_SETTINGS can only be granted in settings tab.\nhttps://github.com/TilesOrganization/support/wiki/How-to-use-ADB-to-grant-permissions\nadb shell pm grant com.rascarlo.quick.settings.tiles android.permission.WRITE_SECURE_SETTINGS\npm grant com.termux.api android.permission.WRITE_SECURE_SETTINGS\npm list packages\nthe brightness bug is solved by uninstalling the unintended settings app. i don’t know if this will cause more problems.\nto remove termux banner/ termux welcome message:\ncd .. && cd usr/etc && rm -rf motd"
  },
  {
    "objectID": "posts/7f9c5998-c8d1-44a6-a2a6-c1c3a799d5dd/index.html",
    "href": "posts/7f9c5998-c8d1-44a6-a2a6-c1c3a799d5dd/index.html",
    "title": "Algorithm",
    "section": "",
    "text": "Algorithm Python\n描述\n明明想在学校中请一些同学一起做一项问卷调查，为了实验的客观性，他先用计算机生成了 N 个 1 到 1000 之间的随机整数（ N≤1000 ），对于其中重复的数字，只保留一个，把其余相同的数去掉，不同的数对应着不同的学生的学号。然后再把这些数从小到大排序，按照排好的顺序去找同学做调查。请你协助明明完成“去重”与“排序”的工作(同一个测试用例里可能会有多组数据(用于不同的调查)，希望大家能正确处理)。\n注：测试用例保证输入参数的正确性，答题者无需验证。测试用例不止一组。\n当没有新的输入时，说明输入结束。\n数据范围： 1 n \\1≤n≤1000  ，输入的数字大小满足 1 val \\1≤val≤500\n输入描述：\n注意：输入可能有多组数据(用于不同的调查)。每组数据都包括多行，第一行先输入随机整数的个数 N ，接下来的 N 行再输入相应个数的整数。具体格式请看下面的”示例”。\n输出描述：\n返回多行，处理后的结果\n示例1\n输入：3\n2\n2\n1\n11\n10\n20\n40\n32\n67\n40\n20\n89\n300\n400\n15复制\n输出：1\n2\n10\n15\n20\n32\n40\n67\n89\n300\n400复制\n说明：示例1包含了两个小样例！！\n输入解释：\n第一个数字是3，也即这个小样例的N=3，说明用计算机生成了3个1到1000之间的随机整数，接下来每行一个随机数字，共3行，也即这3个随机数字为：\n2\n2\n1\n所以第一个小样例的输出为：\n1\n2\n第二个小样例的第一个数字为11，也即…(类似上面的解释)…\n所以第二个小样例的输出为：\n10\n15\n20\n32\n40\n67\n89\n300\n400"
  },
  {
    "objectID": "posts/a86acd5f-0e9d-4173-882c-3bcc263ed3a8/index.html",
    "href": "posts/a86acd5f-0e9d-4173-882c-3bcc263ed3a8/index.html",
    "title": "Android 10 clipboard issue for scrcpy",
    "section": "",
    "text": "com.github.kr328.clipboard.ClipboardProxy.getPrimaryClip\nMagisk Module:\nRiru - Clipboard Whitelist\nwill white list clipboard manager app.\nhttps://github.com/Kr328/Riru-ClipboardWhitelist\nhttps://t.me/kr328_riru_modules\nscript.sh:\nscrcpy -K -S 2&gt;&1 | python3 reader.py\nreader.py:\nimport os\nimport subprocess\nimport re\nclass Response(object):\nstatus = None\ndata = None\ndef parseResponse(resultString):\nresponse = re.findall(r\"^Broadcasting: Intent { flg=0x400000 cmp=ch.pete.adbclipboard/.ReadReceiver }\\nBroadcast completed: result=-1, data=\\\"((.*\\n?)+)\\\"$\",resultString)[0][0]\nreturn response\ndef readFromDevice():\nadbProcess = subprocess.Popen(\n['adb',\n'shell', 'am',\n'broadcast',\n'-n', 'ch.pete.adbclipboard/.ReadReceiver'],\nstdout=subprocess.PIPE)\nresultString = adbProcess.communicate()[0]\nprint(\"read device response:\\n{}\"\n.format(resultString))\ntry:\nresult = parseResponse(resultString.decode(\"utf-8\"))\nprint(\"raw:\\n\",resultString)\nprint(\"result:\\n\",result)\nreturn result\nexcept:\ntraceback.print_exc()\nreturn\ndef setClipboard(data):\nwith open(\"target.out\",\"w+\",encoding=\"utf-8\") as f:\nf.write(data)\nfetch_clipboard = \"cat target.out | xclip -selection c\"\nos.system(fetch_clipboard)\nwhile True:\ncontent = input()\nprint(\"CONTENT:\",content)\nif \"Calling uid 0 does not own package com.android.shell\" in content:\nprint(\"!!!!!!!!!!ERROR FETCHING CLIPBOARD!!!!!!!!!!\")\ndata = readFromDevice()\nif data is not None:\nsetClipboard(data)\n#        with open(\"target.out\",\"wb\"\n#        os.system(fetch_clipboard)"
  },
  {
    "objectID": "posts/bbef1086-6b51-4932-96ca-aefb3595e4d1/index.html",
    "href": "posts/bbef1086-6b51-4932-96ca-aefb3595e4d1/index.html",
    "title": "Anonymity and open access to internet",
    "section": "",
    "text": "bugmenot shared accounts, shared credentials, shared username/password\nuse tor browser, tor daemon.\nstill know nothing on torrc and the obfs4 bridges since none of these works, on linux.\nmaybe snowflake would help?\nrelated links:\nhttps://github.com/radio24/TorBox/blob/master/etc/tor/torrc\nhttps://github.com/radio24/TorBox/blob/master/meek-azure\nhttps://github.com/darknet-book/tor-guide\nhttps://gist.github.com/ciktion82/8ae82e292af8a7bdb2bcb8055a3b4fab\nhttps://github.com/ValdikSS/GoodbyeDPI/releases\nhttps://github.com/krlvm/PowerTunnel\nhttps://github.com/krlvm/LibertyTunnel\nmeek-azure:\nBridge meek 0.0.2.0:3 97700DFE9F483596DDA6264C4D7DF7641E1E39CE url=https://meek.azureedge.net/ front=ajax.aspnetcdn.com\ncan we connect to tor with tor browser? we can launch the instance, check avaliability and then move on, with socks5 direct connection.\ninaccurate system time may prevent tor from starting. the builtin tor bridges worked after i synced time with “ntpdate time.windows.com”. same for vmess protocol.\ntor will speedup if used without bridges inside speedy tunnels. maybe it is useful for visiting real .onion pages.\nhave found multiple pools under github tag “clash”. might found other pools with other tags.\nmeta proxy pools:\nhttps://github.com/alanbobs999/TopFreeProxies\nhttps://github.com/ZGQ-inc/overthefirewall/blob/main/docs/proxypool.md\nhttps://github.com/anaer/Sub\n##META PROXY POOLS##\n#1\nsearch for keywords: (feature of proxypool spiders) free proxies 目前共有抓取源\nhttps://cn.bing.com/search?q=free+proxies+%E7%9B%AE%E5%89%8D%E5%85%B1%E6%9C%89%E6%8A%93%E5%8F%96%E6%BA%90\nhttps://fq.lonxin.net/\nhttps://hellopool.herokuapp.com/\nhttps://proxy.whuboy.com/\nhttps://baby-besitgift.com/\nhttp://111.229.220.110:5000/\nhttp://66.112.210.60.16clouds.com/\nhttp://149.248.8.112/\nhttps://free.kingfu.cf/\nhttps://proxy.yugogo.xyz/\n#2\n节点来源\npojiezhiyuanjun/freev2, 节点数量: 96\nchfchf0306/clash, 节点数量: 367\nxiyaowong/freeFQ, 节点数量: 170\nfreefq/free, 节点数量: 51\nlearnhard-cn/free_proxy_ss, 节点数量: 181\nvpei/Free-Node-Merge, 节点数量: 100\ncolatiger/v2ray-nodes, 节点数量: 65\noslook/clash-freenode, 节点数量: 59\nssrsub/ssr, 节点数量: 40\nLeon406/SubCrawler, 节点数量: 829\numelabs/node.umelabs.dev, 节点数量: 5\nyu-steven/openit, 节点数量: 0\niwxf/free-v2ray, 节点数量: 14\nldir92664/Vmess-Actions, 节点数量: 57\nGalaxy8053/v2ray, 节点数量: 0\nJsnzkpg/Jsnzkpg, 节点数量: 185\nermaozi/get_subscribe, 节点数量: 11\nwrfree/free, 节点数量: 51\nGreenFishStudio/GreenFish, 节点数量: 102\nv2raydy/v2ray, 节点数量: 125\nObcbO/auto-subscribe, 节点数量: 12\n电报群分享(https://t.me/Jsnzk/4664)节点池, 节点数量: 557\n#3\n节点池\n未去重\n已剔除部分失效重复地址\nhttps://hello.stgod.com/\nhttps://proxies.bihai.cf/\nhttps://sspool.nl/\nhttps://proxypool-guest997.herokuapp.com/\nhttps://fq.lonxin.net/\nhttps://free886.herokuapp.com/\nhttps://proxypool.fly.dev/\nhttp://8.135.91.61/\nhttps://proxy.51798.xyz/\nhttps://sspool.herokuapp.com/\nhttps://us-proxypool.herokuapp.com/\nhttps://eu-proxypool.herokuapp.com/\nhttp://www.fuckgfw.tk/\nhttps://etproxypool.ga/\nhttps://free.kingfu.cf/\nhttps://www.linbaoz.com/\nhttps://www.qunima.cc/\nhttps://www.joemt.tk/\nhttps://smart.zxcyec.top/\nhttp://158.101.93.192/\nhttps://168.138.204.231/\nhttp://111.229.220.110:5000/\nhttps://hk.xhrzg2017.xyz/\nhttp://39.106.12.141:8081/\nhttp://213.188.195.234/\nhttps://outseen.tk/\nhttp://149.248.8.112/\nhttps://161.35.5.88/\nhttp://104.128.81.6:8080/\nhttp://wxshi.top:9090/\nhttp://104.168.95.4:8080/\nhttps://proxy.whuboy.com/\nhttps://zua426.cf/\nhttps://185.161.70.4/\nhttp://161.35.5.88:8082/\nhttp://213.188.195.217/\nhttps://de.sanshihui.win/\nhttp://124.127.108.210:12345/\nhttp://guobang.herokuapp.com/\nhttps://1rmb.tk/\nhttps://998988.xyz/\nhttps://alexproxy003.herokuapp.com/\nhttps://free.dswang.ga/\nhttps://free.zdl.im/\nhttps://fu.stgod.com/\nhttps://jiedian.faka77.tk/\nhttps://hellopool.herokuapp.com/\nhttps://origamiboy.herokuapp.com/\nhttps://proxy.suntiefeng.com/\nhttps://proxypoolss.fly.dev/\nhttps://ednovas.design/\nhttps://proxies.bihai.tk\n节点池\nhttp://104.128.81.6:8080/\nhttp://104.168.95.4:8080/\nhttp://111.229.220.110:5000/\nhttp://118.31.77.3/\nhttp://123.114.18.182:1234/\nhttp://139.196.162.200:9090/\nhttp://140.238.39.99:8096/\nhttp://149.248.8.112/\nhttp://149.248.8.112:8081/\nhttp://149.28.158.124/\nhttp://152.70.254.216:1234/\nhttp://158.101.93.192/\nhttp://172.104.109.93:8081/\nhttp://213.188.195.217/\nhttp://213.188.195.234/\nhttp://39.106.12.141:8081/\nhttp://8.135.91.61/\nhttp://emby.luoml.eu.org/\nhttp://mengbai.fun:10001/\nhttp://www.mengbai.fun:10001/\nhttp://www.wxshi.top:9090/\nhttp://wxshi.top:9090/\nhttps://101.32.189.119/\nhttps://120.27.121.82/\nhttps://121.5.240.196:8443/\nhttps://122.10.97.150/\nhttps://122.51.185.18/\nhttps://132.145.82.138/\nhttps://132.226.17.214/\nhttps://132.226.22.43/\nhttps://138.3.217.61/\nhttps://149.248.8.112/\nhttps://152.70.254.216/\nhttps://161.35.5.88/\nhttps://168.138.204.231/\nhttps://172.104.109.93/\nhttps://185.161.70.4/\nhttps://192.3.251.87/\nhttps://1rmb.tk/\nhttps://23.95.166.151/\nhttps://97.64.31.155/\nhttps://emby.luoml.eu.org/\nhttps://etproxypool.cf/\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://hello.stgod.com/\nhttps://hk.xhrzg2017.xyz/\nhttps://hm2019721.ml/\nhttps://jd.jiangcan95.com/\nhttps://jiedian.faka77.tk/\nhttps://outseen.tk/\nhttps://proxies.bihai.cf/\nhttps://proxies.bihai.ml/\nhttps://proxy.51798.xyz/\nhttps://proxy.leefake.xyz/\nhttps://proxy.suntiefeng.com/\nhttps://proxy.whuboy.com/\nhttps://proxypool.fly.dev/\nhttps://proxypool.remon602.ga/\nhttps://proxypoolss.fly.dev/\nhttps://proxypoolv2.herokuapp.com/\nhttps://smart.zxcyec.top/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://upan.tk/\nhttps://www.linbaoz.com/\nhttps://www.proxypool.ml/\nhttps://233660.xyz/\nhttps://6166888.xyz/\nhttps://ditan.ml/\nhttp://emby.luoml.eu.org\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://free.mengbai.cf/\nhttps://free886.herokuapp.com/\nhttps://fu.stgod.com/\nhttps://hello.stgod.com/\nhttps://hm2019721.ml/\nhttps://outseen.tk/\nhttps://proxy.51798.xyz/\nhttps://proxy.purel.in/\nhttps://proxypool-guest997.herokuapp.com/\nhttps://proxypool.fly.dev/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://sspool.nl/\nhttps://www.linbaoz.com/\nhttps://zz.guicloud.xyz/\nhttps://www.linbaoz.com/\nhttps://proxy.purel.in/\nhttps://clashpool.ml/\nhttps://ditan.ml/\n爬虫节点池\nhttp://104.128.81.6:8080/\nhttp://104.168.95.4:8080/\nhttp://111.229.220.110:5000/\nhttp://118.31.77.3/\nhttp://123.114.18.182:1234/\nhttp://139.196.162.200:9090/\nhttp://140.238.39.99:8096/\nhttp://149.248.8.112/\nhttp://149.248.8.112:8081/\nhttp://149.28.158.124/\nhttp://152.70.254.216:1234/\nhttp://158.101.93.192/\nhttp://172.104.109.93:8081/\nhttp://213.188.195.217/\nhttp://213.188.195.234/\nhttp://39.106.12.141:8081/\nhttp://8.135.91.61/\nhttp://emby.luoml.eu.org/\nhttp://mengbai.fun:10001/\nhttp://www.mengbai.fun:10001/\nhttp://www.wxshi.top:9090/\nhttp://wxshi.top:9090/\nhttps://101.32.189.119/\nhttps://120.27.121.82/\nhttps://121.5.240.196:8443/\nhttps://122.10.97.150/\nhttps://122.51.185.18/\nhttps://132.145.82.138/\nhttps://132.226.17.214/\nhttps://132.226.22.43/\nhttps://138.3.217.61/\nhttps://149.248.8.112/\nhttps://152.70.254.216/\nhttps://161.35.5.88/\nhttps://168.138.204.231/\nhttps://172.104.109.93/\nhttps://185.161.70.4/\nhttps://192.3.251.87/\nhttps://1rmb.tk/\nhttps://23.95.166.151/\nhttps://97.64.31.155/\nhttps://emby.luoml.eu.org/\nhttps://etproxypool.cf/\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://hello.stgod.com/\nhttps://hk.xhrzg2017.xyz/\nhttps://hm2019721.ml/\nhttps://jd.jiangcan95.com/\nhttps://jiedian.faka77.tk/\nhttps://outseen.tk/\nhttps://proxies.bihai.cf/\nhttps://proxies.bihai.ml/\nhttps://proxy.51798.xyz/\nhttps://proxy.leefake.xyz/\nhttps://proxy.suntiefeng.com/\nhttps://proxy.whuboy.com/\nhttps://proxypool.fly.dev/\nhttps://proxypool.remon602.ga/\nhttps://proxypoolss.fly.dev/\nhttps://proxypoolv2.herokuapp.com/\nhttps://smart.zxcyec.top/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://upan.tk/\nhttps://www.linbaoz.com/\nhttps://www.proxypool.ml/\n节点池\nhttps://233660.xyz/\nhttps://6166888.xyz/\nhttps://ditan.ml/\nhttp://emby.luoml.eu.org\nhttps://etproxypool.ga/\nhttps://fq.lonxin.net/\nhttps://free.dswang.ga/\nhttps://free.kingfu.cf/\nhttps://free.mengbai.cf/\nhttps://free886.herokuapp.com/\nhttps://fu.stgod.com/\nhttps://hello.stgod.com/\nhttps://hm2019721.ml/\nhttps://outseen.tk/\nhttps://proxy.51798.xyz/\nhttps://proxy.purel.in/\nhttps://proxypool-guest997.herokuapp.com/\nhttps://proxypool.fly.dev/\nhttps://ss.dswang.ga:8443/\nhttps://sspool.herokuapp.com/\nhttps://sspool.nl/\nhttps://www.linbaoz.com/\nhttps://zz.guicloud.xyz/\nhttps://www.linbaoz.com/ https://proxy.purel.in/\nhttps://clashpool.ml/ https://ditan.ml/\n##META PROXY POOLS##\nclash needs clash.yaml.\ntrojan’s igniter supports one link only.\nhttps://github.com/YoulianBoshi/lantern-vpn\nit was seen that freefq/free is resourceful. it scrapes from all locations.\nhttps://git.io/v2free\nhttps://git.io/jmsgo\n##shared paid v2ray recommendation\nhttps://github.com/wantToDoSomeThing/ssSSRV2rayClashTrojan\n###misc\n连接chrome商店的好帮手：http://googlehelper.net/\nswitchyomega：https://github.com/FelisCatus/SwitchyOmega\norigin：https://github.com/gorhill/uBlock\n百度药丸: https://www.baidu.com/s?ie=utf-8&f=3&rsv_bp=1&tn=baidu&wd=百度药丸插件\n域名申请：https://www.kocpc.com.tw/archives/180195\n简悦阅读模式（屏蔽广告）：https://chrome.google.com/webstore/detail/simpread-reader-view/ijllcpnolfcooahcekpamkbidhejabll/related?hl=zh-CN\n###proxies\nweb代理\nhttps://proxybrowser.xyz/\nhttps://github.com/EtherDream/jsproxy/\nhttps://demo.glyptodon.com\nhttp://webproxy.to/\nhttps://www.rabb.it\nhttps://weboas.is/\nhttps://www.anyproxy.cn\nhttps://www.anyproxy.top (挂了)\nhttps://cn.bing.com/translator/ (挂了)\nhttps://proxy.zagon.net.pe\nhttps://www.croxyproxy.com\nhttps://unblocksite.site/\n代理网址服务器列表\n代理服务器列表的使用\nhttps://hoochanlon.github.io/fq-book/#/only/gatherproxy\nhttp://free-proxy.cz\nhttp://www.freeproxylists.net\nhttp://free-proxy-list.net\nhttp://www.my-proxy.com/free-proxy-list.html\nhttp://www.proxylists.net\nhttp://sockslist.net\nhttp://www.myiptest.com/staticpages/index.php/Free-SOCKS5-SOCKS4-Proxy-lists.html\nhttp://www.proxyfire.net/index.php?pageid=ProxyLists\nhttp://www.samair.ru/proxy\nhttp://www.gatherproxy.com/\n###mirror\nGoogle镜像\nhttp://ac.scmor.com\nhttps://google.jiongjun.cc\nhttps://g.zmirrordemo.com\nhttps://www.gotype.tk\nhttp://www.hlhmf.com/\nYouTube镜像\nhttps://ytb-pc.zmirrordemo.com\nhttps://youtube.speeder.cf/ （登陆密码和账号都是speeder.club）\nhttp://wall.qiqiblog.cn\n\n\ncurated list:\nhttps://github.com/hoochanlon/w3-goto-world/tree/master/科学上网、暗网、零网/免费ss、ssr、vmess分享\n免费ss/ssr/vmess分享\n使用须知\n科学上网前，推荐阅读 《这本书能让你连接互联网》，并结合 WebSieUseful 相信定能有所收获\nnotice\n部分链接为贴子、博客或1-3个测试型的ss分享站点，也有可能存在长期未更新，有待观察\n封锁越来越严重，镜像站点失效频繁，更新的意义已经不是很大了…\nheroku的免费配额与限制\nNetwork Bandwidth/流量: 2TB/month – Soft\nShared DB processing/并发数: Max 200msec per second CPU time – Soft\nDyno RAM usage/使用运行内存: 512MB – Hard\nSlug Size/存储空间: 300MB – Hard\nRequest Length/请求时间: 30 seconds – Hard\n提示Application error，是由于访问量占用内存溢出或因各项服务流量耗尽而停止服务\n关于爬虫站点\n搭建的ss分享爬虫站点所爬取到的部分免费账号存在付费代理宣传内容，请自行分辨，谨防被骗\n如果遇到打不开的站点请参考这个教程\n可解DNS污染，对封IP的站点无效，ss分享站点被封ip的可能性，感觉也倾向性也开始…已经很大了(已经是了…)\nhttps://hoochanlon.github.io/fq-book/#/dns&hosts/dnscrypt\n如果斩草除根是不是该这样呢？\nhttps://hoochanlon.github.io/fq-book/#/append/get-method\nchip\nhttps://52bp.org\nhttps://iyideng.cloud/\nhttps://www.duyaoss.com/page/1/\nhttps://jichang.fanqiangdang.com/\nv2ray\nhttps://connect.freev2ray.org/\nhttps://v2ray.cat/\nhttps://v2ray.party/\nhttps://my.freev2ray.org/\nhttps://v2fire.tk/\nhttps://get.freev2ray.com/\nhttps://freev2.org\nv2ray的账号分享站点目前较少\n请参考fq-book中的教程再访问如下站点\nhttps://www.myexplor.me\nhttps://github.com/free-ss/free-ss.site\nhttps://node.umelabs.dev/\nhttps://gdmi.weebly.com/3118523398online.html\nhttps://github.com/ermaozi/get_subscribe\nhttps://vpncn.blogspot.com/\nhttp://nulastudio.org/Freedom/\nhttps://www.youneed.win/free-ssr\nhttps://www.youneed.win/free-ss\nhttps://free.ss-ssr.com\nhttps://toolher.com/ss\nhttps://ssrfree.tk/\nhttps://lncn.org/\nhttps://inssr.pro/free\nhttp://cacss.me/\nhttps://fanqiangdang.com\nhttps://fast.ishadowx.net\nhttp://softpen.net\nhttp://52ss.fun/\nhttps://free0.gyteng.com/\nhttp://shadowsocks.hk/\nhttps://shadowsocksr.cat/\nhttps://ss.freess.org/\nhttps://ss.ishadowx.com\nhttp://webosss.com/tool/socket\nhttps://free.gyteng.com/\nhttps://www.nutgeek.com/ssshadowsocks\nhttps://share-shadowsocksr.herokuapp.com\nhttps://share-shadowsocks.herokuapp.com\nhttps://www.freevpn.pw/zh-cn/\nhttps://www.ssrshare.com\nhttps://fangeqiang.com/408.html\nhttps://get.ishadowx.net\nhttps://get.freess.today\nhttps://tool.ssrshare.com/tool/free_ssr\nhttps://free-ss.site\nhttps://global.ishadowx.net\nhttp://www.52ssr.net/\nhttps://www.wuwweb.com/\nhttps://free.yitianjianss.com\nhttps://www.vpn168.net\nhttps://www.go2free.xyz/\nhttps://biulink.club/\nhttps://www.flyzy2005.com/fan-qiang/shadowsocks/free-ss-account/\nhttps://jiedian5.com\nhttps://free.ss-ssr.com/\nhttp://www.scdark.cn/?p=363\nhttps://gdmi.weebly.com/3118523398online.html\nhttps://pdf-lib.org/Home/Details/2638\nhttps://freessr.win\nhttps://blog.mxpkx.com/index.php/archives/118/\nhttp://freefq.com/ss/\n镜像站点\nhttps://trial.ssbit.win\nhttp://free-ss.tk\nv2ray订阅源\nhttps://raw.githubusercontent.com/AmazingDM/sub/master/v2ray_ssrshare.com\nssr订阅源\nhttps://www.nutgeek.cn/newsubscribe/\nhttps://prom-php.herokuapp.com/cloudfra_ssr.txt\nhttp://share-shadowsocks.herokuapp.com/full/subscribe\nhttp://share-shadowsocksr.herokuapp.com/subscribe?valid=1\nhttps://raw.githubusercontent.com/AmazingDM/sub/master/ssrshare.com\nhttps://github.com/liesauer/Free-SS-SSR\nhttps://yzzz.ml/freessr\nhttps://www.liesauer.net/yogurt/subscribe?ACCESS_TOKEN=DAYxR3mMaZAsaqUb\ntelegram 订阅\nhttps://t.me/freeshadowsock\nhttps://t.me/gyjclub\nhttps://t.me/TGSoBot?start=f_v\nhttps://t.me/vpnchina\nhttps://t.me/XRAcc\nhttps://t.me/TelMTProto\nhttps://t.me/apkdl_bot\nhttps://t.me/TgProxies\nhttps://t.me/zonghe_info\nhttps://t.me/youmtp\nhttps://t.me/outlinex\n分享邮箱\n\ntoyoooooooooooo@gmail.com (doub.io)\n\nye515430@gmail.com (yitianjianss)\nss@rohankdd.com (free-ss.site)\n搜索相似的网站\nhttps://www.similarsites.com\n已失效\nhttp://ssr.wangzhan.gq/\nhttps://doub.io\nhttps://www.puffss.com/ https://freess.cx\nhttps://shadowsocksph.space\nhttps://free.4kvpn.com\nhttps://freess.pw\nhttps://doub.loan\nhttps://freemz.tk/t/5\nhttps://52ssr.cn\nhttp://www.honsuv.com/?post=90\nhttps://newdoub.com\nhttps://en.ss8.fun\nhttp://www.vpn168.tk\nhttps://5l44.pw/\nhttp://www.ssrfx.com\nhttp://freeoutline.org/zh\n付费保留（观察）\n可能到时候会用到的付费节点，虽然翻墙一直是蹭网，付费来说，个人用vpn的可能性更大些\nhttps://rixcloud.me/\n\n\n\ntutorial:\nhttps://hoochanlon.github.io/fq-book/#/\nhttps://github.com/hoochanlon/fq-book\nnew github mirror:\nhttps://hub.fastgit.xyz\n\n\n下载链接 raw.githubusercontent.com 的实际地址\ncodeload.github.com\nraw.githubusercontent.com 替换raw.staticdn.net\nopenit.ml\ndon’t know how it was updated. i have removed google ads with lucky patcher:\nhttps://github.com/bannedbook/v2ray.vpn\nhttps://github.com/hoochanlon/w3-goto-world\nhttps://github.com/oslook/clash-freenode\nauto scraping vmess links\nhttps://github.com/zu1k/proxypool\npopular tutorial:\nhttps://github.com/Alvin9999/new-pac\nhttps://www.v2rayfree.eu.org\nhttps://github.com/anran-world/Anranawsl\n52bp.icu\nhttps://github.com/aiboboxx/v2rayfree\nlearn keywords and search them against given platforms\nermaozi/get_subscribe\nhttps://github.com/ermaozi/get_subscribe\nhttps://fanqiangdang.com\np2p vpn:\nhttps://www.freepn.org\nuse continuously updated v2ray providers, or set it up your own.\nlucktu.com supernode.ml\nsef-hosted vps that can be paid:\nhttps://github.com/xiaoming2028/FreePAC/wiki/Hostwinds、搬瓦工、Hostinger、vutlr-四家VPS主机商速度对比测评\nworking providers:\nlantern, tor, xx-net, tulingx, geph4\nhttps://t.me/tor_bridges\nbuiltin obfs4 bridges\nfrontdesk@torproject.org\nSnowflake: uses ephemeral proxies to connect to the Tor network. It’s available in Tor Browser. You can select Snowflake from Tor Browser’s built-in bridge dropdown.\nPrivate and unlisted obfs4 bridges: contact our Telegram Bot @GetBridgesBot and type /bridges. Or send an email to frontdesk@torproject.org with the phrase “private bridge” in the subject of the email. If you are tech-savvy, you can run your own obfs4 bridge from outside China. Remember that bridges distributed by BridgeDB, and built-in obfs4 bridges bundled in Tor Browser most likely won’t work.\nmeek-azure: makes it look like you are browsing a Microsoft website instead of using Tor. However, because it has a bandwidth limitation, this option will be quite slow. You can select meek-azure from Tor Browser’s built-in bridges dropdown.\nhttps://9.234456.xyz/abc.html?t=567\nsearch for v2ray ssr information in irc chats or social media"
  },
  {
    "objectID": "posts/8f58ded6-5e75-40dd-9c37-999f4e8b65fc/index.html",
    "href": "posts/8f58ded6-5e75-40dd-9c37-999f4e8b65fc/index.html",
    "title": "Articulated Animation",
    "section": "",
    "text": "This one is dead simple. Use real human to talk as you go.\nhttps://github.com/snap-research/articulated-animation"
  },
  {
    "objectID": "posts/3d7294d3-282a-4114-8c5b-72b2fdee6ac0/index.html#offline-ducking",
    "href": "posts/3d7294d3-282a-4114-8c5b-72b2fdee6ac0/index.html#offline-ducking",
    "title": "Audio Ducking",
    "section": "offline ducking",
    "text": "offline ducking\neditly can achieve audio ducking using audionorm"
  },
  {
    "objectID": "posts/3d7294d3-282a-4114-8c5b-72b2fdee6ac0/index.html#online-streaming-ducking",
    "href": "posts/3d7294d3-282a-4114-8c5b-72b2fdee6ac0/index.html#online-streaming-ducking",
    "title": "Audio Ducking",
    "section": "online streaming ducking",
    "text": "online streaming ducking"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#ai-apps-for-audio",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#ai-apps-for-audio",
    "title": "Audio and Music Tools",
    "section": "AI Apps for Audio",
    "text": "AI Apps for Audio\n\nCleanvoice AI - Get rid of filler words from your audio recordings\nPyTorchVideo · A deep learning library for video understanding research\nDescript - All-in-one audio/video editing, as easy as a doc.\nAuphonic\nRevoldiv\nAudioStellar\nGuitarML - Zak Jost Audio Enhancement Machine Learning\ntyiannak/pyAudioAnalysis: Python Audio Analysis Library: Feature Extraction, Classification, Segmentation and Applications\nlibrosa — librosa 0.8.1 documentation python package for music and audio analysis\nYaafe/Yaafe: Audio features extraction\nAsk HN: AI-Generated Music? | Hacker News\n\n\nAI Music Separation\n\nOpen Source Tools and Data for Music Source Separation License: CC-BY-NC\nSpleeter, open source music separation library from Deezer, from Accapella, Melody, Moises\nISSE\nSUDO RM RF : SUccessive DOwnsampling and Resampling of Multi-Resolution Features which enables a more efficient way of separating sources from mixtures\nDeep Audio : Audio Source Separation Without Any Training Data\n\n\n\nAI Music Recognition\n\nAudio Tag for recognize music"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#audio-creation",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#audio-creation",
    "title": "Audio and Music Tools",
    "section": "Audio Creation",
    "text": "Audio Creation\n\nAudio and Music Programming\n\nAlda – Text-Based Programming Language for Music Composition - Hacker News\nmaximecb/noisecraft: Browser-based visual programming language and platform for sound synthesis.\nhelio.fm libre music composition software\nFaust Programming Language\n\n\n\nAI Audio and Music Generator\n\nAI Melody Generator\ntypedrummer\nJukebox\n2108.12290 Music Composition with Deep Learning: A Review\n\n\n\nAudio and Music Creation and Sharing\n\nBeepbox : BeepBox is an online tool for sketching and sharing instrumental melodies.\nJummbox : Jummbox is Beepbox modification (online tool for sketching and sharing chip tune melodies)."
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#wasm-audio-processing",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#wasm-audio-processing",
    "title": "Audio and Music Tools",
    "section": "WASM Audio Processing",
    "text": "WASM Audio Processing\n\nAmped Studio : audio processing, need login\nSoundation : audio processing, need login\nogv.js : audio processing\nAudio Processing\nLearning Syhthesizer and Sound\nMusic Coding\nWASM Synth WASM Music Synthesizer"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#audio-player",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#audio-player",
    "title": "Audio and Music Tools",
    "section": "Audio Player",
    "text": "Audio Player\n\nOnline Audio Player\n\ncaptbaritone/webamp: Winamp 2 reimplemented for the browser\n\n\n\nPeer to Peer Audio\n\nSonoBus - peer to peer music"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#audio-editor",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#audio-editor",
    "title": "Audio and Music Tools",
    "section": "Audio Editor",
    "text": "Audio Editor\n\nDesktop Audio Editor\n\nAudacity, #opensource\n\n\n\nOnline Audio Editor\n\nAudiomass, GithubAudio Editor"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#other-audio-tools",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#other-audio-tools",
    "title": "Audio and Music Tools",
    "section": "Other Audio Tools",
    "text": "Other Audio Tools\n\nVB-Audio Virtual Apps audio output to audio input"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#working-with-virtual-audio-tools",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html#working-with-virtual-audio-tools",
    "title": "Audio and Music Tools",
    "section": "Working with Virtual Audio Tools",
    "text": "Working with Virtual Audio Tools\n\nAudio Recording - Transcription\nBenefits/drawbacks:\n\nWe cannot listen the audio output from playback apps\n\n\n\n\nVAC Audio Recording\n\n\nUse cases:\n\nRecord Zoom Webinar to Speechtexter, Google Docs etc.\n\n\n\nAudio Input Mixing\n\n\n\nAudio Input Mixing\n\n\nUse cases:\n\nRecord with multiphttps://raw.githubusercontent.com/irosyadi/vnote.image/master/vnotebook/app/music-audio-tool.md/20211023055947660_4903.pngP) to Audacity\nBroadcast with multiple input (our voice + music from AIMP) to Zoom, Youtube etc.\n\n\n\nAudio Output Mixing\n\n\n\nAudio Output Mixing\n\n\nSetting:\n\nOS Sound Setting\nOutphttps://raw.githubusercontent.com/irosyadi/vnote.image/master/vnotebook/app/music-audio-tool.md/20211023060503358_26770.pngine 1 VAC Microphone\nVAC Repeater Setting\nWave in: Line 1 VAC Microphone\nWave out: Speaker/Headphone\nStart\n\nUse cases:\n\nTranscribe (and listen) Zoom Seminar to Speaker and Speechtexter, Google Docs\nTranslate Youtube Video using Google Translate\n\n\n\nZoom Audio Recording/Transcription\n\n\n\nZoom Recording Transcription\n\n\n\n\nGoogle Meet Audio Transcription\n\nOpen Google Meet, usihttps://raw.githubusercontent.com/irosyadi/vnote.image/master/vnotebook/app/music-audio-tool.md/20211023061101034_12558.pngsing default Mic\n\nBut we cannot do both Speechtexter and Google Docs\nWe cannot do both Speechtexter and Voice Note\nWe can do both Google Meet and Speechtexter/VoiceNote/Dictanote\nWe can do both Zoom and Speechtexter/VoiceNote/Dictanote"
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#papers",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#papers",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Papers",
    "text": "Papers\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.\nTransformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai, Zhilin Yang, Yiming Yang, William W. Cohen, Jaime Carbonell, Quoc V. Le and Ruslan Salakhutdinov.\n\n\nUses smart caching to improve the learning of long-term dependency in Transformer. Key results: state-of-art on 5 language modeling benchmarks, including ppl of 21.8 on One Billion Word (LM1B) and 0.99 on enwiki8. The authors claim that the method is more flexible, faster during evaluation (1874 times speedup), generalizes well on small datasets, and is effective at modeling short and long sequences.\n\n\nConditional BERT Contextual Augmentation by Xing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han and Songlin Hu.\nSDNet: Contextualized Attention-based Deep Network for Conversational Question Answering by Chenguang Zhu, Michael Zeng and Xuedong Huang.\nLanguage Models are Unsupervised Multitask Learners by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever.\nThe Evolved Transformer by David R. So, Chen Liang and Quoc V. Le.\n\n\nThey used architecture search to improve Transformer architecture. Key is to use evolution and seed initial population with Transformer itself. The architecture is better and more efficient, especially for small size models.\n\n\nXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.\n\n\nA new pretraining method for NLP that significantly improves upon BERT on 20 tasks (e.g., SQuAD, GLUE, RACE).\n“Transformer-XL is a shifted model (each hyper-column ends with next token) while XLNet is a direct model (each hyper-column ends with contextual representation of same token).” — Thomas Wolf.\nComments from HN:\n\n\n\nA clever dual masking-and-caching algorithm.\n\n\nThis is NOT “just throwing more compute” at the problem.\nThe authors have devised a clever dual-masking-plus-caching mechanism to induce an attention-based model to learn to predict tokens from all possible permutations of the factorization order of all other tokens in the same input sequence.\nIn expectation, the model learns to gather information from all positions on both sides of each token in order to predict the token.\nFor example, if the input sequence has four tokens, [“The”, “cat”, “is”, “furry”], in one training step the model will try to predict “is” after seeing “The”, then “cat”, then “furry”.\nIn another training step, the model might see “furry” first, then “The”, then “cat”.\nNote that the original sequence order is always retained, e.g., the model always knows that “furry” is the fourth token.\nThe masking-and-caching algorithm that accomplishes this does not seem trivial to me.\nThe improvements to SOTA performance in a range of tasks are significant – see tables 2, 3, 4, 5, and 6 in the paper.\n\n\n\nCTRL: Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar, Richard Socher et al. [Code].\nPLMpapers - BERT (Transformer, transfer learning) has catalyzed research in pretrained language models (PLMs) and has sparked many extensions. This repo contains a list of papers on PLMs.\nExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Google Brain.\n\n\nThe group perform a systematic study of transfer learning for NLP using a unified Text-to-Text Transfer Transformer (T5) model and push the limits to achieve SoTA on SuperGLUE (approaching human baseline), SQuAD, and CNN/DM benchmark. [Code].\n\n\nReformer: The Efficient Transformer by Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya.\n\n\n“They present techniques to reduce the time and memory complexity of Transformer, allowing batches of very long sequences (64K) to fit on one GPU. Should pave way for Transformer to be really impactful beyond NLP domain.” — @hardmaru\n\n\nSupervised Multimodal Bitransformers for Classifying Images and Text (MMBT) by Facebook AI.\nA Primer in BERTology: What we know about how BERT works by Anna Rogers et al.\n\n\n“Have you been drowning in BERT papers?”. The group survey over 40 papers on BERT’s linguistic knowledge, architecture tweaks, compression, multilinguality, and so on.\n\n\ntomohideshibata/BERT-related papers\nSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by Google Brain. [Code] | [Blog post (unofficial)]\n\n\nKey idea: the architecture use a subset of parameters on every training step and on each example. Upside: model train much faster. Downside: super large model that won’t fit in a lot of environments.\n\n\nAn Attention Free Transformer by Apple.\nA Survey of Transformers by Tianyang Lin et al.\nEvaluating Large Language Models Trained on Code by OpenAI.\n\n\nCodex, a GPT language model that powers GitHub Copilot.\nThey investigate their model limitations (and strengths).\nThey discuss the potential broader impacts of deploying powerful code generation techs, covering safety, security, and economics.\n\n\nTraining language models to follow instructions with human feedback by OpenAI. They call the resulting models InstructGPT. ChatGPT is a sibling model to InstructGPT.\nLaMDA: Language Models for Dialog Applications by Google.\nTraining Compute-Optimal Large Language Models by Hoffmann et al. at DeepMind. TLDR: introduces a new 70B LM called “Chinchilla” that outperforms much bigger LMs (GPT-3, Gopher). DeepMind has found the secret to cheaply scale large language models — to be compute-optimal, model size and training data must be scaled equally. It shows that most LLMs are severely starved of data and under-trained. Given the new scaling law, even if you pump a quadrillion parameters into a model (GPT-4 urban myth), the gains will not compensate for 4x more training tokens."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#articles",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#articles",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Articles",
    "text": "Articles\n\nBERT and Transformer\n\nOpen Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing from Google AI.\nThe Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning).\nDissecting BERT by Miguel Romero and Francisco Ingham - Understand BERT in depth with an intuitive, straightforward explanation of the relevant concepts.\nA Light Introduction to Transformer-XL.\nGeneralized Language Models by Lilian Weng, Research Scientist at OpenAI.\nWhat is XLNet and why it outperforms BERT\n\n\nPermutation Language Modeling objective is the core of XLNet.\n\n\nDistilBERT (from HuggingFace), released together with the blog post Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version of BERT.\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations paper from Google Research and Toyota Technological Institute. — Improvements for more efficient parameter usage: factorized embedding parameterization, cross-layer parameter sharing, and Sentence Order Prediction (SOP) loss to model inter-sentence coherence. [Blog post | Code]\nELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning - A BERT variant like ALBERT and cost less to train. They trained a model that outperforms GPT by using only one GPU; match the performance of RoBERTa by using 1/4 computation. It uses a new pre-training approach, called replaced token detection (RTD), that trains a bidirectional model while learning from all input positions. [Blog post | Code]\nVisual Paper Summary: ALBERT (A Lite BERT)\n\n\n\nAttention Concept\n\nThe Annotated Transformer by Harvard NLP Group - Further reading to understand the “Attention is all you need” paper.\nAttention? Attention! - Attention guide by Lilian Weng from OpenAI.\nVisualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) by Jay Alammar, an Instructor from Udacity ML Engineer Nanodegree.\nMaking Transformer networks simpler and more efficient - FAIR released an all-attention layer to simplify the Transformer model and an adaptive attention span method to make it more efficient (reduce computation time and memory footprint).\nWhat Does BERT Look At? An Analysis of BERT’s Attention paper by Stanford NLP Group.\n\n\n\nTransformer Architecture\n\nThe Transformer blog post.\nThe Illustrated Transformer by Jay Alammar, an Instructor from Udacity ML Engineer Nanodegree.\nWatch Łukasz Kaiser’s talk walking through the model and its details.\nTransformer-XL: Unleashing the Potential of Attention Models by Google Brain.\nGenerative Modeling with Sparse Transformers by OpenAI - an algorithmic improvement of the attention mechanism to extract patterns from sequences 30x longer than possible previously.\nStabilizing Transformers for Reinforcement Learning paper by DeepMind and CMU - they propose architectural modifications to the original Transformer and XL variant by moving layer-norm and adding gating creates Gated Transformer-XL (GTrXL). It substantially improve the stability and learning speed (integrating experience through time) in RL.\nThe Transformer Family by Lilian Weng - since the paper “Attention Is All You Need”, many new things have happened to improve the Transformer model. This post is about that.\nDETR (DEtection TRansformer): End-to-End Object Detection with Transformers by FAIR - :fire: Computer vision has not yet been swept up by the Transformer revolution. DETR completely changes the architecture compared with previous object detection systems. (PyTorch Code and pretrained models). “A solid swing at (non-autoregressive) end-to-end detection. Anchor boxes + Non-Max Suppression (NMS) is a mess. I was hoping detection would go end-to-end back in ~2013)” — Andrej Karpathy\nTransformers for software engineers - This post will be helpful to software engineers who are interested in learning ML models, especially anyone interested in Transformer interpretability. The post walk through a (mostly) complete implementation of a GPT-style Transformer, but the goal will not be running code; instead, they use the language of software engineering and programming to explain how these models work and articulate some of the perspectives they bring to them when doing interpretability work.\nPathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance - PaLM is a dense decoder-only Transformer model trained with the Pathways system, which enabled Google to efficiently train a single model across multiple TPU v4 Pods. The example explaining a joke is remarkable. This shows that it can generate explicit explanations for scenarios that require a complex combination of multi-step logical inference, world knowledge, and deep language understanding.\n\n\n\nGenerative Pre-Training Transformer (GPT)\n\nBetter Language Models and Their Implications.\nImproving Language Understanding with Unsupervised Learning - this is an overview of the original OpenAI GPT model.\n🦄 How to build a State-of-the-Art Conversational AI with Transfer Learning by Hugging Face.\nThe Illustrated GPT-2 (Visualizing Transformer Language Models) by Jay Alammar.\nMegatronLM: Training Billion+ Parameter Language Models Using GPU Model Parallelism by NVIDIA ADLR.\nOpenGPT-2: We Replicated GPT-2 Because You Can Too - the authors trained a 1.5 billion parameter GPT-2 model on a similar sized text dataset and they reported results that can be compared with the original model.\nMSBuild demo of an OpenAI generative text model generating Python code [video] - The model that was trained on GitHub OSS repos. The model uses English-language code comments or simply function signatures to generate entire Python functions. Cool!\nGPT-3: Language Models are Few-Shot Learners (paper) by Tom B. Brown (OpenAI) et al. - “We train GPT-3, an autoregressive language model with 175 billion parameters :scream:, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.”\nelyase/awesome-gpt3 - A collection of demos and articles about the OpenAI GPT-3 API.\nHow GPT3 Works - Visualizations and Animations by Jay Alammar.\nGPT-Neo - Replicate a GPT-3 sized model and open source it for free. GPT-Neo is “an implementation of model parallel GPT2 & GPT3-like models, with the ability to scale up to full GPT3 sizes (and possibly more!), using the mesh-tensorflow library.” [Code].\nGitHub Copilot, powered by OpenAI Codex - Codex is a descendant of GPT-3. Codex translates natural language into code.\nGPT-4 Rumors From Silicon Valley - GPT-4 is almost ready. GPT-4 would be multimodal, accepting text, audio, image, and possibly video inputs. Release window: Dec - Feb. #hype\nNew GPT-3 model: text-Davinci-003 - Improvements:\n\n\nHandle more complex intents — you can get even more creative with how you make use of its capabilities now.\nHigher quality writing — clearer, more engaging, and more compelling content.\nBetter at longer form content generation.\n\n\nChatGPT blog post and link to the conversational interface.\n\n\nChatGPT is OpenAI’s newest language model fine-tuned from a model in the GPT-3.5 series (which finished training in early 2022), optimized for dialogue. It is trained using Reinforcement Learning from Human Feedback; human AI trainers provide supervised fine-tuning by playing both sides of the conversation.\nIs it evidently better than GPT-3 at following user instructions and context? People have noticed, ChatGPT’s output quality seems to represent a notable improvement over previous GPT-3 models.\n\n\n\nLarge Language Model (LLM)\n\nGPT-J-6B - Can’t access GPT-3? Here’s GPT-J — its open-source cousin.\nFun and Dystopia With AI-Based Code Generation Using GPT-J-6B - Prior to GitHub Copilot tech preview launch, Max Woolf, a data scientist tested GPT-J-6B’s code “writing” abilities.\nGPT-Code-Clippy (GPT-CC) - An open source version of GitHub Copilot. The GPT-CC models are fine-tuned versions of GPT-2 and GPT-Neo.\nGPT-NeoX-20B - A 20 billion parameter model trained using EleutherAI’s GPT-NeoX framework. They expect it to perform well on many tasks. You can try out the model on GooseAI playground.\nMetaseq - A codebase for working with Open Pre-trained Transformers (OPT).\nYaLM 100B by Yandex is a GPT-like pretrained language model with 100B parameters for generating and processing text. It can be used freely by developers and researchers from all over the world.\nBigScience’s BLOOM-176B from the Hugging Face repository [paper, blog post] - BLOOM is a 175-billion parameter model for language processing, able to generate text much like GPT-3 and OPT-175B. It was developed to be multilingual, being deliberately trained on datasets containing 46 natural languages and 13 programming languages.\nbitsandbytes-Int8 inference for Hugging Face models - You can run BLOOM-176B/OPT-175B easily on a single machine, without performance degradation. If true, this could be a game changer in enabling people outside of big tech companies being able to use these LLMs.\n\n\n\nAdditional Reading\n\nHow to Build OpenAI’s GPT-2: “The AI That’s Too Dangerous to Release”.\nOpenAI’s GPT2 - Food to Media hype or Wake Up Call?\nHow the Transformers broke NLP leaderboards by Anna Rogers. :fire::fire::fire:\n\n\nA well put summary post on problems with large models that dominate NLP these days.\nLarger models + more data = progress in Machine Learning research :question:\n\n\nTransformers From Scratch tutorial by Peter Bloem.\nReal-time Natural Language Understanding with BERT using NVIDIA TensorRT on Google Cloud T4 GPUs achieves 2.2 ms latency for inference. Optimizations are open source on GitHub.\nNLP’s Clever Hans Moment has Arrived by The Gradient.\nLanguage, trees, and geometry in neural networks - a series of expository notes accompanying the paper, “Visualizing and Measuring the Geometry of BERT” by Google’s People + AI Research (PAIR) team.\nBenchmarking Transformers: PyTorch and TensorFlow by Hugging Face - a comparison of inference time (on CPU and GPU) and memory usage for a wide range of transformer architectures.\nEvolution of representations in the Transformer - An accessible article that presents the insights of their EMNLP 2019 paper. They look at how the representations of individual tokens in Transformers trained with different objectives change.\nThe dark secrets of BERT - This post probes fine-tuned BERT models for linguistic knowledge. In particular, the authors analyse how many self-attention patterns with some linguistic interpretation are actually used to solve downstream tasks. TL;DR: They are unable to find evidence that linguistically interpretable self-attention maps are crucial for downstream performance.\nA Visual Guide to Using BERT for the First Time - Tutorial on using BERT in practice, such as for sentiment analysis on movie reviews by Jay Alammar.\nTuring-NLG: A 17-billion-parameter language model by Microsoft that outperforms the state of the art on many downstream NLP tasks. This work would not be possible without breakthroughs produced by the DeepSpeed library (compatible with PyTorch) and ZeRO optimizer, which can be explored more in this accompanying blog post.\nMUM (Multitask Unified Model): A new AI milestone for understanding information by Google.\n\n\nBased on transformer architecture but more powerful.\nMultitask means: supports text and images, knowledge transfer between 75 languages, understand context and go deeper in a topic, and generate content.\n\n\nGPT-3 is No Longer the Only Game in Town - GPT-3 was by far the largest AI model of its kind last year (2020). Now? Not so much.\nOpenAI’s API Now Available with No Waitlist - GPT-3 access without the wait. However, apps must be approved before going live. This release also allow them to review applications, monitor for misuse, and better understand the effects of this tech.\nThe Inherent Limitations of GPT-3 - One thing missing from the article if you’ve read Gwern’s GPT-3 Creative Fiction article before is the mystery known as “Repetition/Divergence Sampling”:\n\n\nwhen you generate free-form completions, they have a tendency to eventually fall into repetitive loops of gibberish.\n\nFor those using Copilot, you should have experienced this wierdness where it generates the same line or block of code over and over again.\n\nLanguage Modelling at Scale: Gopher, Ethical considerations, and Retrieval by DeepMind - The paper present an analysis of Transformer-based language model performance across a wide range of model scales — from models with tens of millions of parameters up to a 280 billion parameter model called Gopher.\nCompetitive programming with AlphaCode by DeepMind - AlphaCode uses transformer-based language models to generate code that can create novel solutions to programming problems which require an understanding of algorithms.\nBuilding games and apps entirely through natural language using OpenAI’s code-davinci model - The author built several small games and apps without touching a single line of code, simply by telling the model what they want.\nOpen AI gets GPT-3 to work by hiring an army of humans to fix GPT’s bad answers\nGPT-3 can run code - You provide an input text and a command and GPT-3 will transform them into an expected output. It works well for tasks like changing coding style, translating between programming languages, refactoring, and adding doc. For example, converts JSON into YAML, translates Python code to JavaScript, improve the runtime complexity of the function.\nUsing GPT-3 to explain how code works by Simon Willison.\nCharacter AI announces they’re building a full stack AGI company so you could create your own AI to help you with anything, using conversational AI research. The co-founders Noam Shazeer (co-invented Transformers, scaled them to supercomputers for the first time, and pioneered large-scale pretraining) and Daniel de Freitas (led the development of LaMDA), all of which are foundational to recent AI progress.\nHow Much Better is OpenAI’s Newest GPT-3 Model? - In addition to ChatGPT, OpenAI releases text-davinci-003, a Reinforcement Learning-tuned model that performs better long-form writing. Example, it can explain code in the style of Eminem. 😀"
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#educational",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#educational",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Educational",
    "text": "Educational\n\nminGPT by Andrej Karpathy - A PyTorch re-implementation of GPT, both training and inference. minGPT tries to be small, clean, interpretable and educational, as most of the currently available GPT model implementations can a bit sprawling. GPT is not a complicated model and this implementation is appropriately about 300 lines of code.\n\n\nTutorials\n\nHow to train a new language model from scratch using Transformers and Tokenizers tutorial by Hugging Face. :fire:"
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#videos",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#videos",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Videos",
    "text": "Videos\n\nBERTology\n\nXLNet Explained by NLP Breakfasts.\n\n\nClear explanation. Also covers the two-stream self-attention idea.\n\n\nThe Future of NLP by 🤗\n\n\nDense overview of what is going on in transfer learning in NLP currently, limits, and future directions.\n\n\nThe Transformer neural network architecture explained by AI Coffee Break with Letitia Parcalabescu.\n\n\nHigh-level explanation, best suited when unfamiliar with Transformers.\n\n\n\nAttention and Transformer Networks\n\nSequence to Sequence Learning Animated (Inside Transformer Neural Networks and Attention Mechanisms) by learningcurve."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#official-implementations",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#official-implementations",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Official Implementations",
    "text": "Official Implementations\n\ngoogle-research/bert - TensorFlow code and pre-trained models for BERT."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#other-implementations",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#other-implementations",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Other Implementations",
    "text": "Other Implementations\n\nPyTorch and TensorFlow\n\n🤗 Hugging Face Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides state-of-the-art general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet, CTRL…) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch. [Paper]\nspacy-transformers - a library that wrap Hugging Face’s Transformers, in order to extract features to power NLP pipelines. It also calculates an alignment so the Transformer features can be related back to actual words instead of just wordpieces.\n\n\n\nPyTorch\n\ncodertimo/BERT-pytorch - Google AI 2018 BERT pytorch implementation.\ninnodatalabs/tbert - PyTorch port of BERT ML model.\nkimiyoung/transformer-xl - Code repository associated with the Transformer-XL paper.\ndreamgonfly/BERT-pytorch - A PyTorch implementation of BERT in “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”.\ndhlee347/pytorchic-bert - A Pytorch implementation of Google BERT.\npingpong-ai/xlnet-pytorch - A Pytorch implementation of Google Brain XLNet.\nfacebook/fairseq - RoBERTa: A Robustly Optimized BERT Pretraining Approach by Facebook AI Research. SoTA results on GLUE, SQuAD and RACE.\nNVIDIA/Megatron-LM - Ongoing research training transformer language models at scale, including: BERT.\ndeepset-ai/FARM - Simple & flexible transfer learning for the industry.\nNervanaSystems/nlp-architect - NLP Architect by Intel AI. Among other libraries, it provides a quantized version of Transformer models and efficient training method.\nkaushaltrivedi/fast-bert - Super easy library for BERT based NLP models. Built based on 🤗 Transformers and is inspired by fast.ai.\nNVIDIA/NeMo - Neural Modules is a toolkit for conversational AI by NVIDIA. They are trying to improve speech recognition with BERT post-processing.\nfacebook/MMBT from Facebook AI - Multimodal transformers model that can accept a transformer model and a computer vision model for classifying image and text.\ndbiir/UER-py from Tencent and RUC - Open Source Pre-training Model Framework in PyTorch & Pre-trained Model Zoo (with more focus on Chinese).\n\n\n\nKeras\n\nSeparius/BERT-keras - Keras implementation of BERT with pre-trained weights.\nCyberZHG/keras-bert - Implementation of BERT that could load official pre-trained models for feature extraction and prediction.\nbojone/bert4keras - Light reimplement of BERT for Keras.\n\n\n\nTensorFlow\n\nguotong1988/BERT-tensorflow - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\nkimiyoung/transformer-xl - Code repository associated with the Transformer-XL paper.\nzihangdai/xlnet - Code repository associated with the XLNet paper.\n\n\n\nChainer\n\nsoskek/bert-chainer - Chainer implementation of “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#transfer-learning-in-nlp",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#transfer-learning-in-nlp",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Transfer Learning in NLP",
    "text": "Transfer Learning in NLP\nAs Jay Alammar put it:\n\nThe year 2018 has been an inflection point for machine learning models handling text (or more accurately, Natural Language Processing or NLP for short). Our conceptual understanding of how best to represent words and sentences in a way that best captures underlying meanings and relationships is rapidly evolving. Moreover, the NLP community has been putting forward incredibly powerful components that you can freely download and use in your own models and pipelines (It’s been referred to as NLP’s ImageNet moment, referencing how years ago similar developments accelerated the development of machine learning in Computer Vision tasks).\n\n\n\n\n\nOne of the latest milestones in this development is the release of BERT, an event described as marking the beginning of a new era in NLP. BERT is a model that broke several records for how well models can handle language-based tasks. Soon after the release of the paper describing the model, the team also open-sourced the code of the model, and made available for download versions of the model that were already pre-trained on massive datasets. This is a momentous development since it enables anyone building a machine learning model involving language processing to use this powerhouse as a readily-available component – saving the time, energy, knowledge, and resources that would have gone to training a language-processing model from scratch.\n\n\n\n\n\nBERT builds on top of a number of clever ideas that have been bubbling up in the NLP community recently – including but not limited to Semi-supervised Sequence Learning (by Andrew Dai and Quoc Le), ELMo (by Matthew Peters and researchers from AI2 and UW CSE), ULMFiT (by fast.ai founder Jeremy Howard and Sebastian Ruder), the OpenAI transformer (by OpenAI researchers Radford, Narasimhan, Salimans, and Sutskever), and the Transformer (Vaswani et al).\n\n\n\n\n\nULMFiT: Nailing down Transfer Learning in NLP\n\n\n\n\n\nULMFiT introduced methods to effectively utilize a lot of what the model learns during pre-training – more than just embeddings, and more than contextualized embeddings. ULMFiT introduced a language model and a process to effectively fine-tune that language model for various tasks.\n\n\n\n\n\nNLP finally had a way to do transfer learning probably as well as Computer Vision could.\n\nMultiFiT: Efficient Multi-lingual Language Model Fine-tuning by Sebastian Ruder et al. MultiFiT extends ULMFiT to make it more efficient and more suitable for language modelling beyond English. (EMNLP 2019 paper)"
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#books",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#books",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Books",
    "text": "Books\n\nTransfer Learning for Natural Language Processing - A book that is a practical primer to transfer learning techniques capable of delivering huge improvements to your NLP models."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#other-resources",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#other-resources",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Other Resources",
    "text": "Other Resources\n\n\nExpand Other Resources\n\n\nhanxiao/bert-as-service - Mapping a variable-length sentence to a fixed-length vector using pretrained BERT model.\nbrightmart/bert_language_understanding - Pre-training of Deep Bidirectional Transformers for Language Understanding: pre-train TextCNN.\nalgteam/bert-examples - BERT examples.\nJayYip/bert-multiple-gpu - A multiple GPU support version of BERT.\nHighCWu/keras-bert-tpu - Implementation of BERT that could load official pre-trained models for feature extraction and prediction on TPU.\nwhqwill/seq2seq-keyphrase-bert - Add BERT to encoder part for https://github.com/memray/seq2seq-keyphrase-pytorch\nxu-song/bert_as_language_model - BERT as language model, a fork from Google official BERT implementation.\nY1ran/NLP-BERT–Chinese version\nyuanxiaosc/Deep_dynamic_word_representation - TensorFlow code and pre-trained models for deep dynamic word representation (DDWR). It combines the BERT model and ELMo’s deep context word representation.\nyangbisheng2009/cn-bert\nWillyoung2017/Bert_Attempt\nPydataman/bert_examples - Some examples of BERT. run_classifier.py based on Google BERT for Kaggle Quora Insincere Questions Classification challenge. run_ner.py is based on the first season of the Ruijin Hospital AI contest and a NER written by BERT.\nguotong1988/BERT-chinese - Pre-training of deep bidirectional transformers for Chinese language understanding.\nzhongyunuestc/bert_multitask - Multi-task.\nMicrosoft/AzureML-BERT - End-to-end walk through for fine-tuning BERT using Azure Machine Learning.\nbigboNed3/bert_serving - Export BERT model for serving.\nyoheikikuta/bert-japanese - BERT with SentencePiece for Japanese text.\nnickwalton/AIDungeon - AI Dungeon 2 is a completely AI generated text adventure built with OpenAI’s largest 1.5B param GPT-2 model. It’s a first of it’s kind game that allows you to enter and will react to any action you can imagine.\nturtlesoupy/this-word-does-not-exist - “This Word Does Not Exist” is a project that allows people to train a variant of GPT-2 that makes up words, definitions and examples from scratch. We’ve never seen fake text so real."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#tools",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#tools",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Tools",
    "text": "Tools\n\njessevig/bertviz - Tool for visualizing attention in the Transformer model.\nFastBert - A simple deep learning library that allows developers and data scientists to train and deploy BERT based models for NLP tasks beginning with text classification. The work on FastBert is inspired by fast.ai.\ngpt2tc - A small program using the GPT-2 LM to complete and compress texts. It has no external dependency, requires no GPU and is quite fast. The smallest model (117M parameters) is provided. Larger models can be downloaded as well. (no waitlist, no sign up required)."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#tasks",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#tasks",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "Tasks",
    "text": "Tasks\n\nNamed-Entity Recognition (NER)\n\n\nExpand NER\n\n\nkyzhouhzau/BERT-NER - Use google BERT to do CoNLL-2003 NER.\nzhpmatrix/bert-sequence-tagging - Chinese sequence labeling.\nJamesGu14/BERT-NER-CLI - Bert NER command line tester with step by step setup guide.\nsberbank-ai/ner-bert\nmhcao916/NER_Based_on_BERT - This project is based on Google BERT model, which is a Chinese NER.\nmacanv/BERT-BiLSMT-CRF-NER - TensorFlow solution of NER task using Bi-LSTM-CRF model with Google BERT fine-tuning.\nProHiryu/bert-chinese-ner - Use the pre-trained language model BERT to do Chinese NER.\nFuYanzhe2/Name-Entity-Recognition - Lstm-CRF, Lattice-CRF, recent NER related papers.\nking-menin/ner-bert - NER task solution (BERT-Bi-LSTM-CRF) with Google BERT https://github.com/google-research.\n\n\n\n\nClassification\n\n\nExpand Classification\n\n\nbrightmart/sentiment_analysis_fine_grain - Multi-label classification with BERT; Fine Grained Sentiment Analysis from AI challenger.\nzhpmatrix/Kaggle-Quora-Insincere-Questions-Classification - Kaggle baseline—fine-tuning BERT and tensor2tensor based Transformer encoder solution.\nmaksna/bert-fine-tuning-for-chinese-multiclass-classification - Use Google pre-training model BERT to fine-tune for the Chinese multiclass classification.\nNLPScott/bert-Chinese-classification-task - BERT Chinese classification practice.\nfooSynaptic/BERT_classifer_trial - BERT trial for Chinese corpus classfication.\nxiaopingzhong/bert-finetune-for-classfier - Fine-tuning the BERT model while building your own dataset for classification.\nSocialbird-AILab/BERT-Classification-Tutorial - Tutorial.\nmalteos/pytorch-bert-document-classification - Enriching BERT with Knowledge Graph Embedding for Document Classification (PyTorch)\n\n\n\n\nText Generation\n\n\nExpand Text Generation\n\n\nasyml/texar - Toolkit for Text Generation and Beyond. Texar is a general-purpose text generation toolkit, has also implemented BERT here for classification, and text generation applications by combining with Texar’s other modules.\nPlug and Play Language Models: a Simple Approach to Controlled Text Generation (PPLM) paper by Uber AI.\n\n\n\n\nQuestion Answering (QA)\n\n\nExpand QA\n\n\nmatthew-z/R-net - R-net in PyTorch, with BERT and ELMo.\nvliu15/BERT - TensorFlow implementation of BERT for QA.\nbenywon/ChineseBert - This is a Chinese BERT model specific for question answering.\nxzp27/BERT-for-Chinese-Question-Answering\nfacebookresearch/SpanBERT - Question Answering on SQuAD; improving pre-training by representing and predicting spans.\n\n\n\n\nKnowledge Graph\n\n\nExpand Knowledge Graph\n\n\nsakuranew/BERT-AttributeExtraction - Using BERT for attribute extraction in knowledge graph. Fine-tuning and feature extraction. The BERT-based fine-tuning and feature extraction methods are used to extract knowledge attributes of Baidu Encyclopedia characters.\nlvjianxin/Knowledge-extraction - Chinese knowledge-based extraction. Baseline: bi-LSTM+CRF upgrade: BERT pre-training."
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#license",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html#license",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "License",
    "text": "License\n\n\nExpand License\n\nThis repository contains a variety of content; some developed by Cedric Chee, and some from third-parties. The third-party content is distributed under the license provided by those parties.\nI am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer.\nThe content developed by Cedric Chee is distributed under the following license:\n\nCode\nThe code in this repository, including all code samples in the notebooks listed above, is released under the MIT license. Read more at the Open Source Initiative.\n\n\nText\nThe text content of the book is released under the CC-BY-NC-ND license. Read more at Creative Commons."
  },
  {
    "objectID": "posts/f4098fa6-1a17-4919-8716-d044b1ba106f/index.html",
    "href": "posts/f4098fa6-1a17-4919-8716-d044b1ba106f/index.html",
    "title": "Baidu Tieba Login (QR Code)",
    "section": "",
    "text": "Assigned a job.\nCloud Phone:\n`http://www.ddyun.com/sem/pcddybdyunkong/?bd_vid=7609174489837191328\n17756220843:fsfs5214`\nQR Link:\nhttps://wappass.baidu.com/wp/?qrlogin&t=1640006201&error=0&sign=v1_13fa5a31cf31fa864475cbf3fd2fc&cmd=login&lp=pc&tpl=tb&adapter=3&logPage=traceId%3Apc_loginv4_1640006201%2ClogPage%3Aloginv4&qrloginfrom=pc&local=%E5%8D%97%E4%BA%AC\nThis job has no public data to refer. we need to monitor the tieba app.\nmitmproxy –mode socks5 –listen-port 8050 –save-stream-file logs\nRun mitmproxy without options to generate the mitm certificate. Install the certificate (usually ~/.mitmproxy/mitmproxy-ca-cert.cer) in the Android phone. It may be needed to change the extension to .crt to install it.\nfrida is needed to disable certificate-pinning, or if this is somehow possible. (also via justtrustme, xposed)\nhttps://hub.fastgit.org/httptoolkit/frida-android-unpinning\nhttps://httptoolkit.tech/blog/frida-certificate-pinning/\nsetenforce 0\nto disable stack errors\nto connect to frida-server:\nhttps://github.com/15872998154/frida_termux\n./frida_server -l 0.0.0.0:27042\nfrida -H 127.0.0.1:27042 –codeshare sowdust/universal-android-ssl-pinning-bypass-2 -f com.baidu.tieba –no-pause\ni will not know if the client will be satisfied or not. i only know this would be very hard to solve. if not good i will quit.\nto read flow:\nmitmproxy -n –showhost -r logs.log\nprint xxd line and ascii parse only:\ncat logs2.log | xxd | awk ‘{print \\(1\" \"\\)NF}’\ncat logs2.log | xxd | awk ‘{print \\(1\" \"\\)NF}’ | grep -C 5 http://wap\n0012f020: ss-Control-Allow\n0012f030: -Methods,18:GET,\n0012f040: OPTIONS,]\n0012f050: 59:27:Access-Con\n0012f060: trol-Allow-Origi\n0012f070: n,24:http://wapp\n0012f080: ass.baidu.com,]2\n0012f090: 8:10:Connection,\n0012f0a0: 10:keep-alive,]2\n0012f0b0: 7:16:Content-Enc\n0012f0c0: oding,4:gzip,]44\ncat logs2.log | xxd | awk ‘{print \\(1\" \"\\)NF}’ | grep -C 5 https://wap\n001190e0: ite,]28:14:sec-f\n001190f0: etch-mode,7:no-c\n00119100: ors,]26:14:sec-f\n00119110: etch-dest,5:styl\n00119120: e,]40:7:referer,\n00119130: 26:https://wappa\n00119140: ss.baidu.com/,]3\n00119150: 6:15:accept-enco\n00119160: de\n00119170: flate,]37:15:acc\n00119180: ept-language,14:\n–\n0011aed0: ite,]28:14:sec-f\n0011aee0: etch-mode,7:no-c\n0011aef0: ors,]27:14:sec-f\n0011af00: etch-dest,6:scri\n0011af10: pt,]40:7:referer\n0011af20: ,26:https://wapp\n0011af30: ass.baidu.com/,]\n0011af40: 36:15:accept-enc\n0011af50: d\n0011af60: eflate,]37:15:ac\n0011af70: cept-language,14\n–\n0011ccd0: -site,]28:14:sec\n0011cce0: -fetch-mode,7:no\n0011ccf0: -cors,]26:14:sec\n0011cd00: -fetch-dest,5:st\n0011cd10: yle,]40:7:refere\n0011cd20: r,26:https://wap\n0011cd30: pass.baidu.com/,\n0011cd40: ]36:15:accept-en\n0011cd50: coding,13:gzip,\n0011cd60: deflate,]37:15:a\n0011cd70: ccept-language,1\n–\n00121f40: -site,]28:14:Sec\n00121f50: -Fetch-Mode,7:no\n00121f60: -cors,]26:14:Sec\n00121f70: -Fetch-Dest,5:im\n00121f80: age,]40:7:Refere\n00121f90: r,26:https://wap\n00121fa0: pass.baidu.com/,\n00121fb0: ]36:15:Accept-En\n00121fc0: coding,13:gzip,\n00121fd0: deflate,]37:15:A\n00121fe0: ccept-Language,1\n–\n0012f550: in,]28:14:Sec-Fe\n0012f560: tch-Mode,7:no-co\n0012f570: rs,]27:14:Sec-Fe\n0012f580: tch-Dest,6:scrip\n0012f590: t,]256:7:Referer\n0012f5a0: ,241:https://wap\n0012f5b0: pass.baidu.com/w\n0012f5c0: p/?qrlogin&t=163\n0012f5d0: 9980306&error=0&\n0012f5e0: sign=v1_f3b74f3a\n0012f5f0: 21e355010985e711\n–\n00139700: ,]28:14:Sec-Fetc\n00139710: h-Mode,7:no-cors\n00139720: ,]26:14:Sec-Fetc\n00139730: h-Dest,5:image,]\n00139740: 40:7:Referer,26:\n00139750: https://wappass.\n00139760: baidu.com/,]36:1\n00139770: 5:Accept-Encodin\n00139780: defla\n00139790: te,]37:15:Accept\n001397a0: -Language,14:en-\n–\n0013db70: 39997136312&tpl=\n0013db80: tb&auto_statisti\n0013db90: c=e2V2ZW50VHlwZT\n0013dba0: p0b3VjaC1qcy1lcn\n0013dbb0: Jvcn0=&extrajson\n0013dbc0: =https://wappass\n0013dbd0: .baidu.com/wp/?q\n0013dbe0: rlogin&t=1639980\n0013dbf0: 306&error=0&sign\n0013dc00: =v1_f3b74f3a21e3\n0013dc10: 55010985e7113869\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nwith a plugin to collect statistics:\nhttp://file.taotaoya.top/load/TT.rar\nthat guy wants me to discover barcode first.\ni may paste cookies here:\nhttps://termbin.com/lq5e\nuse ccrypt, xxd and nc to do transport. (do you have these?)\ncat cookies.log.cpt | xxd | nc termbin.com 9999\nxxd -r\nccrypt -c cookies.log.cpt\npasswd:abcdefg\na typical QR login link on android:\nhttps://wappass.baidu.com/wp/?qrlogin&t=1639929144&error=0&sign=v1_3b3e89197877163a12614a9a7f519&cmd=login&lp=pc&tpl=tb&adapter=3&clientfrom=native&qrloginfrom=native&local=%E9%93%9C%E9%99%B5\nparsed with elinks copied with termux-clipboard-set:\nLink: [1]canonical\nLink: [2]alternate (handheld)\n百度贴吧二维码登录–python爬虫\n[3]lxguang_tao 2021-01-22 18:11:49 547 收藏\n分类专栏： [4]python 文章标签： [5]python\n版权声明：本文为博主原创文章，遵循 [6]CC 4.0 BY-SA 版权协议，转载请附上原\n文出处链接和本声明。\n本文链接：[7]https://blog.csdn.net/qq_27644127/article/details/112987332\n版权\n[8][IMG] [9]python 专栏收录该内容\n1 篇文章 0 订阅\n订阅专栏\n百度贴吧二维码登录–python爬虫\n•\n• [10]研究思路\n•\n• [11]探索过程\n• [12]思路总结\n• [13]代码实现\n•\n•\n• [14]所需技术\n• [15]代码\n• [16]总结\n研究思路\n如果阅读此文章的小伙伴之前研究过贴吧相关的接口的话，就会知道，那些需要登\n录才能实现的功能接口，你去爬虫的话要携带一个Cookie BDUSS，有了它就会通过\n身份验证。这个BDUSS也可以通过浏览器访问贴吧页面，从而获得，但在同一个浏\n览器中如果更换帐号登录，那么你从这个浏览器中拿到的之前那个BDUSS就会失效\n（不可能这个浏览器永远挂着这个帐号，并且保证不会去修改密码）。为了获得一\n个永不失效的BDUSS，我们可以通过登录方法来获取BDUSS，但我们不可能会使用这\n个BDUSS去做退出和切换帐号操作，所以它一般拿到后就不会失效（除非改了密码\n）。\n探索过程\n[17]二维码\n1. 不管是贴吧首页，还是其他地方的贴吧登录页面，都会有这个二维码登录的地方\n。我们第一步是看怎么去拿到这个二维码图片地址。\n2. 思路：爬取这个页面，从页面元素中找到这个二维码连接，结果就是，二维码连\n接不是响应页面加载出来的，那就说明是通过后续的接口返回的然后添加到页面\n中的。所以我们接下来要去寻找加载二维码的接口。\n3. 寻找接口：打开F12，切换到Network，刷新页面，你会看到一条类型为png的记\n录，点开看到响应正是这张二维码图片\n[18]二维码请求地址\n4. 查看请求相关内容：地址，参数，类型。Get请求，有三个参数分别是sign,lp\n和qrloginfrom，看到后两个参数的值都是pc。盲猜应该可以是固定值pc(电脑\n端)。所以现在就只剩下一个参数需要搞清楚，那就是sign。\n[19]在这里插入图片描述\n5. 遵循代码从上往下运行的规则，这个sign肯定是在二维码加载前就获取到了，所\n以我们要在它的上面的记录里寻找一下。经过一番寻找，最终\n在“https://passport.baidu.com/v2/api/getqrcode?lp=pc&qrloginfrom=pc&gid=1527EF2-1333-475F-BA75-319AF40E53E7&callback=tangram_guid_1611304323880&apiver=v3&tt=1611304324028&tpl=tb&_=1611304324032”\n的响应中找到了sign，当然响应中有整个图片链接。\n6. 不过坑爹啊，这个请求中也有好多个参数。不过看到这个参数，发现有好几个都\n是无意义的。tt和_我们看长度可以推断出应该是时间戳，经过验证，确实是当\n时时间的时间戳。所以我们主要需要攻破的就是gid与callback。还是老样子，\n先找gid，去上面找但是就是找不到。看gid像是那种唯一值，python中叫uuid。\n既然找不到，那就可能是前端生成的，所以我们可以去找这个请求发起的js。看\n看它这个参数到底是怎么来的。在F12 Source中按 Ctrl+Shift+F全局搜\n索“v2/api/getqrcode”。\n[20]参数\n7. 通过搜索我们发现确实是前端生成的随机唯一值。那我们就可以放心大胆的自己\n去生成了，当然要生成出来的格式一样。现在就只剩下callback了。正当我苦思\n冥想找不到的时候，真的想破口而出：怎么这么难找啊，tmd烦死了。我后面发\n现，嗯它后面那一串数字跟下面的时间戳基本一样。好家伙，这都能算一个参数\n，我是真的服。这样最后一个参数我们也能靠自己生成。这个接口拿下。\n[21]在这里插入图片描述\n8. 到现在我们已经实现了，（1）请求返回二维码地址的接口。（2）返回二维码图\n片的地址。相当于我们做好了获取BDUSS的第一步。（长舒一口气）\n9. 现在我们要进行第二部，扫码后进行怎样的处理。\n扫码登录原理：网页生成二维码后，后面轮询进行一个请求，来返回当前二维码的\n状态。\n当二维码被扫后，访问二维码内容，服务端会进行处理（是否登录，做登录操作）\n当然如果一直没有扫码请求，那么就一直循环请求，直到二维码过期为止。\n10. 查看Network后续内容，发现确实有一个接口在不停的请求。查看参数发现，都\n是我们玩剩下的，除了channel_id是图片链接中的一个参数换了名字外，其他我\n们都有办法获得。\n[22]监听\n11. 我们现在要做的就是模拟浏览器进行轮询请求，当请求返回正确登录的响应的时\n候，发现它返回了\n**tangram_guid_1611307815857({“errno”:0,“channel_id”:“v1_cf81fb2823935db841b5395152de2”,“channel_v”:“{\"status\":0,\"v\":\"3f1a8f93cca689cead144ad405b03945\",\"u\":\"\"}”})\n** 这跟登录有毛关系啊，发现后面它又调用了一个借口，看这名字就知道了，\n就是它了。\n12. /v3/login/main/qrbdusslogin\n[23]有这几个参数\n13. 发现了联系，bduss是刚才轮询接口返回的。其他参数看着无意义的都直接用它\n的。先调用再说。如果调用成功，返回的是一个JSON数据，但是并没有BDUSS\n。tmd，都忘了我们去拿BDUSS的是去哪拿的吗。恍然大悟，Cookie啊。果然，从\n响应中，看到写入浏览器了Cookie。\n[24]cookie\n14. 至此是通过二维码登录拿到BDUSS的全部过程。虽然看上去简单，但是实际去操\n作的时候，还是有一些坑的。回过头来看看，那些坑也是必经之路吧，坑走过一\n遍后，就更加印象深刻。\n思路总结\n总结一下： 基本上是从人的思考方式下手。从二维码从哪来开始，其实也就是一直\n不断的在调接口，找参数，处理响应。不管哪一步，基本都离不开这三样。当然这次\n的最重要的是理解二维码登录的实际原理，只有理解了它的原理才能去做好对策。\n代码实现\n所需技术\npython request模块，json模块，re模块，time, uuid\n代码\n““”\nQrCodeLogin.py 二维码登录\n““”\n““”\n1、访问首页，获取二维码\n2、请求响应接口\n3、。。。。\n““”\nimport requests, re, time, json, uuid\nclass qrcodeLogin:\ndef init(self):\nself.get_qrcode_url = “https://passport.baidu.com/v2/api/getqrcode”\nself.unicast_url = “https://passport.baidu.com/channel/unicast”\nself.login_url = “https://passport.baidu.com/v3/login/main/qrbdusslogin”\nself.qrcode = “”\nself.gid = str(uuid.uuid4()).upper()\nself.callback = “”\nself.sign = “”\nself.bduss = “”\nself.headers = {\n“User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:74.0) Gecko/20100101 Firefox/74.0”\n}\ndef get_qrcode(self):\nself.callback = “tangram_guid_{}”.format(str(int(round(time.time() * 1000))))\nparms = {\n“lp”:“pc”,\n“qrloginfrom”: “pc”,\n“gid”: self.gid,\n“callback”: self.callback,\n“apiver”: “v3”,\n“tt”: int(round(time.time() * 1000)),\n“tpl”: “tb”,\n“-”: int(round(time.time() * 1000))\n}\nhtml = requests.get(url=self.get_qrcode_url, params=parms, headers=self.headers, verify=False).content.decode(‘utf-8’, errors=‘ignore’)\n\nprint(html)\np = re.compile(’“imgurl”:“(.*?)“’)\np2 = re.compile(’“sign”:“(.*?)“’)\nqrcode = p.findall(html)\nself.sign = p2.findall(html)\nif len(qrcode) == 0:\nreturn None\nelse:\nprint(“https://”+qrcode[0].replace(“\\”, ““))\nself.qrcode = “https://”+qrcode[0].replace(“\\”, ““)\ndef unicast(self):\nstart = time.time()\nerrno = 1\nstatus = 1\nflag = True\npattern = re.compile(’({.*})’)\nwhile(True):\nend = time.time()\nif (end - start) &gt; 300:\nbreak\nparms = {\n“channel_id”: self.sign,\n“qrloginfrom”: “pc”,\n“gid”: self.gid,\n“callback”: self.callback,\n“apiver”: “v3”,\n“tt”: int(round(time.time() * 1000)),\n“tpl”: “tb”,\n“-”: int(round(time.time() * 1000))\n}\njsons = requests.get(url=self.unicast_url, params=parms, headers=self.headers, verify=False)\nhtml = jsons.content.decode(‘utf-8’, errors=“ignore”).replace(‘\\’, ’‘).replace(’“{‘, “{”).replace(’}”’, “}”)\ntry:\nif errno or status:\nmessage = json.loads(re.search(pattern, html).group())\nerrno = message[‘errno’]\nif errno == 0 and flag:\nflag = False\nelif errno == 0:\nstatus = message[‘channel_v’][‘status’]\nif not errno and not status:\nmessage = json.loads(re.search(pattern, html).group())\nself.bduss = message[‘channel_v’][‘v’]\nBDUSS = self.login()\nprint(BDUSS)\nreturn BDUSS\nexcept Exception as e:\nprint(e)\nbreak\nreturn None\ndef login(self):\nparm = {\n‘v’: int(round(time.time() * 1000)),\n‘u’: ‘https://tieba.baidu.com/index.html’,\n‘bduss’: self.bduss,\n‘loginVersion’: ‘v4’,\n‘qrcode’: ‘1’,\n‘tpl’: ‘tb’,\n‘apiver’: ‘v3’,\n‘tt’: int(round(time.time() * 1000)),\n‘traceid’: None,\n‘time’: round(time.time()),\n‘alg’: ‘v3’,\n‘sig’: ‘EsdgfadNMU5rQVl4NWhSDFSDCVSDGFSdfsdfsf8xcVEveFNqanFGK2ZRdDBiejdXQXVhK1ZlRDZKMzsdfDSES==’,\n‘elapsed’: 3,\n‘shaOne’: ‘00edf2343d07csdf23478b6ccd34f9a92290d3tg’,\n‘callback’: ’bd__cbs__o5224l’,\n}\nlogin_r = requests.get(self.login_url, headers=self.headers, params=parm, verify=False)\nstr_html = login_r.content.decode(‘utf-8’)\n\n\nprint(str_html)\nfor i in login_r.cookies:\nif i.name == “BDUSS”:\nprint(‘登陆成功’)\npname = re.compile(’“displayName”: “(.*?)“’)\nname_list = pname.findall(str_html)\n\n\nprint(name_list)\nif len(name_list) &gt; 0:\nname = name_list[0]\nreturn (i.value, name)\nreturn (i.value, ’’)\nreturn None\ndef getImg(self):\nimg = requests.get(url=self.qrcode, headers=self.headers, verify=False)\n\n\nprint(img.content)\n\n\nwith open(“tieba.gif”, ‘wb’) as w:\n\n\nw.write(img.content)\nreturn img.content\nif name == ‘main’:\ns = qrcodeLogin()\ns.get_qrcode()\ns.getImg()\ns.unicast()\n总结\n这一步是打开贴吧自动化大门的关键，有了它我们就能轻松做很多事情了。\n贴上自己做的一些统计工具的截图，如果有小伙伴感兴趣，或者需要帮做小功能的，\n可以评论私信哦。\n附上下载地址：[25]地址\n[26]在这里插入图片描述[27]在这里插入图片描述\n[28][IMG][29]lxguang_tao\n[30]关注 关注\n• 2\n点赞\n•\n踩\n• [31][IMG] [32]1\n评论\n• [33][IMG] [34][IMG] [35][IMG] [36]0\n收藏\n• [37]一键三连\n一键三连\n•\n• [38][IMG]\n扫一扫，分享海报\n专栏目录\n[39]tieba_sign::mobile_phone: 百度贴吧多线程扫码登陆 自动签到 自动打码-源\n码\n05-07\n[40]Tieba_Sign 百度贴吧多线程扫码登陆 / 自动签到 / 自动打码 经测试：在三个\n帐号，一共207个贴吧的情况下，全部签到完成速度为5s左右。(Cookies登录情况下)\nUse：Python3.6以上 效果 使用教程 1.安装依赖 pip install -r\nrequirements.txt # Centos yum install zbar -y # Ubuntu sudo apt-get\ninstall libzbar-dev -y 2.增加用户配置 (tieba_sign.py) user_lists = [’用户\n名’] # 用户名,例如[‘用户1’, ‘用户2’, ‘用户3’] 一共3个用户 # 请按照从前往后\n的顺序来依次进行登陆 运行 python tieba_sign.py # 开始登录并签到 请注意，在\n最新版本中，需要扫码登陆，程序运行的时候，会问你是否有百度贴吧\n[41]python爬虫解决百度贴吧登陆验证码问题\n[42]weixin_34236869的博客\n06-29 222\n[43]作为贴吧重度用户，写了个贴吧爬虫脚本 抄了一些别人的代码。记得有个验证\n码解决的。可是忘了链接了，今天最终自己攻克了。 首先要让登陆须要验证码，不\n停地登陆就好了。。。度娘非常快会加上验证码大法的。。。须要验证码的情况下，\n直接登陆返回的错误信息是error=257 打开贴吧首页选择登陆，弹出验证码，找到验\n证码的链接是 右键在新标签页中打开 注意到链接是 …\n评论1\n[44][IMG]\n[45]\n\n请先登录 后发表评论~\n[46]表情包 插入表情\n[47]表情包 代码片\n• HTML/XML\n• objective-c\n• Ruby\n• PHP\n• C\n• C++\n• JavaScript\n• Python\n• Java\n• CSS\n• SQL\n• 其它\n[48][ 评论 ] [49][ 评论 ]\n[50]Python爬虫系列之百度贴吧爬取\n[51]Packager\n11-28 176\n[52]今天给的一个爬虫小事例，贴吧段子爬取这样一个小功能，数据呢仅仅娱乐，没\n有恶意想法 若有侵权，请私信删除 此次用到的一个解析库Beautiful Soup，更轻量\n简单地对数据进行解析，已获得目标数据 贴吧做的还是比较好，有一定的反爬机制\n，所以我们也应该有一定的应对措施，具体对应我们requests获取到的数据对应页面\n源代码，通过观察发现数据的是否异步与注释等等反爬问题 以下是代码部分 #\n-*-…\n[53]Python 网络爬虫实战：爬取百度贴吧高清原图\n最新发布\n[54]亮出锋芒，剑指苍穹\n11-15 654\n[55]前段时间受哥儿们所托，爬取贴吧某帖子里的高清图片。 事情是这样的，我哥\n们发现被贴吧中有好多漂亮的图片，想下载原图做壁纸，但是帖子里图片太多了，他\n全都要，于是想让我帮忙写个爬虫，批量下载下来。 要求只有两个： 下载原图 实\n现批量下载 话不多说，直接开始。 1. 分析网站 哥们提供的帖子地址：\nhttps://tieba.baidu.com/p/6516084831 。 先分析 url 组成，我们可以猜到\n6516084831 是帖子的 id 。 在 勾选只看楼主，翻页 等这些操作之后，链接变成了\n这样 ht\n[56]Python模拟二维码登录百度\n[57]ljc545w的博客\n12-11 872\n[58]模拟二维码登录百度写在前面准备工作二维码地址登录状态获取gid登录参数代\n码部分二维码展示获取cookie完整代码写在后面 写在前面 前段时间写了利用BDUSS\n到达百度首页，这一次尝试使用二维码模拟登录，目前网上能搜到的相关内容基本失\n效了，但是思路基本不变，无非是百度改了些参数。本文较为复杂，要求对python\n的requests模块以及Chrome审查元素有一定了解，我不确定自己是否能完全讲明白，\n讲多少是多少吧，各位看官请坐。 准备工作 二维码地址 打开Chrome浏览器，清理\n掉baidu.com下的所有co\n[59]python模拟登陆百度\n[60]kaerbuka的博客\n07-02 786\n[61]本文原地址 目录 说明 环境准备 登陆过程分析 登陆过程完整代码 有效性测试\n说明 本文做的是百度二维码扫码登陆，至于为什么要做扫码登陆，主要是因为：1，\n用账号密码登陆时，在测试过程中，如果清除cookie，会弹出验证码，这个倒是无所\n谓，要命的是在登陆过程中有可能出发百度的账号保护机制，就算输入验证码，百度\n还会强制要求手机短信进行二次验证，这个触发机制目前还不明确。 准备环境 准\n备python…\n[62]Python爬取百度贴吧回帖中的微信号（基于简单http请求）\n[63]草小诚的博客\n01-03 368\n[64]前些日子媳妇儿有个需求，想要一个任意贴吧近期主题帖的所有回帖中的微信号\n，用来做一些微商的操作，你懂的。因为有些贴吧专门就是微商互加，或者客户留微\n信的，还有专门特定用户群的贴吧，非常精准，我们一致认为比其他加人模式效率要\n高，所以如果能方便快捷的提取微信号，价值还是很高的（事后来看微信号到购买转\n化率约1%，已经很满意了）。 那需求很明确，说干就干，当天晚上就想把这个工具\n实现出来，我呢打开电脑开始调研 …\n[65]17-用python爬取下载女神照片\n[66]bigzql的博客\n10-13 1万+\n[67]今天咱们要爬取花瓣网 https://huaban.com/ 设计师寻找灵感的天堂!有海量的\n图片素材可以下载,是一个优质图片灵感库 这次我们用 requests 登录花瓣网，爬取\n页面，再用正则与json提取有用信息，最后把获取的图片信息 保存到本地 一 、用\n到技术 python 基础 requests 登录页面获取session用户会话，下载图片 正则表达\n式 提取页面的有用信息 json解析页面中的图片 二、 目标页面\nhttps://huaban.com/search/?q=女神&catego\n[68]精心整理|Python爱好者社区历史文章合集（作者篇）–20190925从豆瓣获取\n[69]小仙女说：但行好事，不问前程\n09-25 4719\n[70]精心整理|Python爱好者社区历史文章合集（作者篇） 参考文件地址\n：http://www.360doc.com/content/18/0801/00/2990557_774796873.shtml（供共同\n学习python的同学食用） 若侵权，联系删除 7月16日更新： Python爬取起点中文网\n小说排行榜信息（上海线下培训作业） 唯一小编王大…\n[71]python百度贴吧登录协议_python爬虫解决百度贴吧登陆验证码问题\n[72]weixin_39974223的博客\n12-03 166\n[73]作为贴吧重度用户，写了个贴吧爬虫脚本抄了一些别人的代码。记得有个验证码\n解决的。可是忘了链接了，今天最终自己攻克了。首先要让登陆须要验证码，不停地\n登陆就好了。。。度娘非常快会加上验证码大法的。。。须要验证码的情况下，直接\n登陆返回的错误信息是error=257打开贴吧首页选择登陆，弹出验证码，找到验证码\n的链接是 右键在新标签页中打开 注意到链接是这个时候依据之前写的代码，判定登\n陆成功是依据post登录…\n[74]python贴吧-qpython贴吧\n[75]q6q6q的专栏\n10-28 250\n[76]广告关闭腾讯云双11爆品提前享，精选热门产品助力上云，云服务器首年88元起\n，买的越多返的越多，最高满返5000元！目录1. url的组成 2. 贴吧爬虫2.1. 只爬\n贴吧第一页2.2. 爬取所有贴吧的页面 3. get和post的区别3.1. get请求3.2. post\n请求3.3. 有道翻译模拟发送post请求…wd=%e7%bc%96%e7%a8%8b%e5%90%a7我们也可\n以在pyth…\n[77]百度贴吧新玩法你会用吗？\n[78]张一刻\n08-19 161\n[79]大家好，我是张一刻，专注于营销多年 今天我们来聊聊贴吧营销，可能在很多\n人心里 贴吧已经落伍了，贴吧营销不被大家看好，但这还是一种渠道，不自己试试\n怎能轻易否定呢？ 最近我正好在研究如何从贴吧导用户到微信公众号上，分享一下\n心得，希望对你有帮助： 1、用二维码做头像2、将二维码做成签名图片（注册满3个\n月才能设置签名档） 3、个人简介里添加微信号 4、发文章，正文中含品牌名、关键\n词和微信号，标题含品牌关键…\n[80]【HTTP】百度贴吧WEB版签到流程分析\n[81]大东的博客\n01-03 542\n[82]文章目录流程图接口抓包与分析获取二维码轮询扫码结果获取Cookie获取关注的\n吧贴吧签到总结 流程图 接口抓包与分析 获取二维码 Url\n：https://passport.baidu.com/v2/api/getqrcode 请求方式：Get 请求参数\n：lp=pc 虽然抓包发现有很多参数，但是经过实际测试发现只需要传lp这一个就可以\n了，后续接口不再做说明 返回结果： { “imgurl”:…\n[83]贴吧二维码图秒删处理\n[84]小胡实战引流\n11-07 2898\n[85]今天和大家分享的是这几天把 最流行 简单的 发二维码 这节课不是侧重实操，\n如果大家看过我以前的视频，这个就很好做了 我们来看一下 ，最近发二维码有多么\n猖狂\nhttps://tieba.baidu.com/f?ie=utf-8&kw=%E8%AF%9A%E6%8B%9B%E4%BB%A3%E7%90%86&fr=search\n大家可以看到这都是直接就发二维码图基本上都不处理…\n[86]贴吧一发二维码就被删！是你没掌握技术\n[87]星空软件\n03-07 5039\n[88]贴吧防删图制作！在利用百度贴吧做推广引流的小伙伴们，你们是不是会遇到这\n样的一个情况，自己发的图片有时候被度娘给秒删了？为什么会这样呢？今天聪明星\n小编就来为你分享下百度贴吧发图片的技术干货，小板凳可要做好了！ 被度娘秒删\n的帖子多少跟自己账号也有一定的关系，关于账号的问题，下期我们会在我的csdn账\n号里面在分享《百度贴吧如何发帖？贴吧发帖防删技巧干货分享！》，此处就不在赘\n述了。还有一种原因就是图片的…\n[89]Golang 百度云扫码登录\n[90]ALakers的博客\n12-24 262\n[91]文件结构： http_client.go代码如下： package client import ( “bytes”\n“fmt” “io” “io/ioutil” “net/http” “net/http/cookiejar” “net/url” “strings”\n“time” ) // HTTPClient http client type HTTPClient struct { *http.Client\nUserAgent string } var ( UserAgen\n[92]1.爬虫基础——了解html&什么是爬虫\n[93]python伊甸园的博客\n10-10 3141\n[94]众所周知：我们上网浏览的网页，他们的本质是一个又一个html页面。那什么\n是html呢？可以这么理解，编写JAVA有JAVA的语言逻辑，编写Python有Python的语言\n逻辑，编写网页就需要遵从html的语言逻辑，而编写好了的html就可以显示出来我们\n所看到的网页了。 如下示例： 图1 图2 正如我们在上面所看到的，当我们查\n看https://www.baidu.com/这个网址的时候，…\n[95]学会这招，小姐姐看你的眼神将不一样\n热门推荐\n[96]kimol君的博客\n10-03 2万+\n[97]学会这招，小姐姐看你的眼神将不一样前言一、爬虫分析二、爬取项目ID1.抓取\n帖子的URL2.提取帖子中的UUID3.完整代码三、爬取项目的数据写在最后 前言 今天\n某小丽同学来找我，有个实验需要用到轻松筹的数据进行一个分析。可是没有足够的\n数据，如何办是好？ 乐于助人的我，当然不会置之不理~ （ps.毕竟是小姐姐嘛，拒\n绝了不好，对叭） 于是乎，我抄起家伙，说干就干。 一、爬虫分析 通过简单的分\n析，可以发现轻松筹提供了一个接口，可以返回某个项目的相关数据，具体如下：\n地址如下，xxxxxx表示项目的UUID： h\n©️2021 CSDN 皮肤主题: 游动-白 设计师:白松林 [98]返回首页\n[99][IMG]\n[100]lxguang_tao CSDN认证博客专家 CSDN认证企业博客\n码龄7年 [101][IMG] [102]暂无认证\n3\n原创\n27万+\n周排名\n25万+\n总排名\n2242\n访问\n[103][IMG]\n等级\n44\n积分\n14\n粉丝\n6\n获赞\n1\n评论\n7\n收藏\n[104]GitHub\n[105]签到达人\n[106]新秀勋章\n[107]勤写标兵Lv1\n[108]分享学徒\n[109]私信\n关注\n[110]_____________________\n热门文章\n• [111]百度贴吧二维码登录–python爬虫 [112][IMG] [113]539\n• [114]C# 引用后visual studio不报错，生成报错 [115][IMG] [116]122\n• [117]windows系统下使用docker运行容器挂载卷报错问题 [118][IMG] [119]69\n分类专栏\n• [120][IMG] [121]python 1篇\n• [122][IMG] [123]C# 1篇\n最新评论\n• [124]百度贴吧二维码登录–python爬虫\n[125]乎你: 代码之路任重道远，愿跟博主努力习之。\n您愿意向朋友推荐“博客详情页”吗？\n•\n强烈不推荐\n•\n不推荐\n•\n一般般\n•\n推荐\n•\n强烈推荐\n[126]_____________________ 提交\n最新文章\n• [127]windows系统下使用docker运行容器挂载卷报错问题\n• [128]C# 引用后visual studio不报错，生成报错\n[129]2021年2篇\n[130]2020年1篇\n[131]IFrame\n目录\n目录\n[132]IFrame\n分类专栏\n• [133][IMG] [134]python 1篇\n• [135][IMG] [136]C# 1篇\n实付元\n[137]使用余额支付\n点击重新获取\n扫码支付\n138 钱包余额 0\n抵扣说明：\n1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。\n2.余额无法直接购买下载，可以购买VIP、C币套餐、付费专栏及课程。\n[139][IMG][140]余额充值\nReferences\nVisible links\n\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#\nhttps://blog.csdn.net/qq_27644127\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\nhttps://so.csdn.net/so/search/s.do?q=python&t=blog&o=vip&s=&l=&f=&viparticle=\nhttp://creativecommons.org/licenses/by-sa/4.0/\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\npython\n\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\n\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_1\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_5\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_37\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_39\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_40\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_42\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#_192\nhttp://file.taotaoya.top/load/TT.rar\nhttps://blog.csdn.net/qq_27644127\nhttps://blog.csdn.net/qq_27644127\njavascript:;\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#commentBox\nfile:///data/data/com.termux/files/home/works/tieba_job/content.html#commentBox\njavascript:;\njavascript:;\njavascript:;\njavascript:;\njavascript:;\njavascript:;\nhttps://download.csdn.net/download/weixin_42122432/18441287\nhttps://download.csdn.net/download/weixin_42122432/18441287\nhttps://blog.csdn.net/weixin_34236869/article/details/86453208\nhttps://blog.csdn.net/weixin_34236869\nhttps://blog.csdn.net/weixin_34236869/article/details/86453208\njavascript:void(0);\nhttps://lmsoft.blog.csdn.net/article/details/84582372\nhttps://blog.csdn.net/qq_41287993\nhttps://lmsoft.blog.csdn.net/article/details/84582372\nhttps://smartcrane.blog.csdn.net/article/details/121341944\nhttps://blog.csdn.net/wenxuhonghe\nhttps://smartcrane.blog.csdn.net/article/details/121341944\nhttps://blog.csdn.net/ljc545w/article/details/111054624\nhttps://blog.csdn.net/ljc545w\nhttps://blog.csdn.net/ljc545w/article/details/111054624\nhttps://blog.csdn.net/kaerbuka/article/details/94471507\nhttps://blog.csdn.net/kaerbuka\nhttps://blog.csdn.net/kaerbuka/article/details/94471507\nhttps://blog.csdn.net/cxcjoker7894/article/details/85685115\nhttps://blog.csdn.net/cxcjoker7894\nhttps://blog.csdn.net/cxcjoker7894/article/details/85685115\nhttps://cpython.blog.csdn.net/article/details/109063267\nhttps://blog.csdn.net/bigzql\nhttps://cpython.blog.csdn.net/article/details/109063267\nhttps://blog.csdn.net/qq_32670879/article/details/101391892\nhttps://blog.csdn.net/qq_32670879\nhttps://blog.csdn.net/qq_32670879/article/details/101391892\nhttps://blog.csdn.net/weixin_39974223/article/details/110545065\nhttps://blog.csdn.net/weixin_39974223\nhttps://blog.csdn.net/weixin_39974223/article/details/110545065\nhttps://blog.csdn.net/q6q6q/article/details/109346811\nhttps://blog.csdn.net/q6q6q\nhttps://blog.csdn.net/q6q6q/article/details/109346811\nhttps://blog.csdn.net/u013177154/article/details/99288349\nhttps://blog.csdn.net/u013177154\nhttps://blog.csdn.net/u013177154/article/details/99288349\nhttps://blog.csdn.net/d745282469/article/details/103819585\nhttps://blog.csdn.net/d745282469\nhttps://blog.csdn.net/d745282469/article/details/103819585\nhttps://blog.csdn.net/weixin_44027887/article/details/102948182\nhttps://blog.csdn.net/weixin_44027887\nhttps://blog.csdn.net/weixin_44027887/article/details/102948182\nhttps://blog.csdn.net/qq_15159657/article/details/104721232\nhttps://blog.csdn.net/qq_15159657\nhttps://blog.csdn.net/qq_15159657/article/details/104721232\nhttps://blog.csdn.net/ALakers/article/details/111619137\nhttps://blog.csdn.net/ALakers\nhttps://blog.csdn.net/ALakers/article/details/111619137\nhttps://blog.csdn.net/weixin_42830697/article/details/102474659\nhttps://blog.csdn.net/weixin_42830697\nhttps://blog.csdn.net/weixin_42830697/article/details/102474659\nhttps://blog.csdn.net/kimol_justdo/article/details/108912073\nhttps://blog.csdn.net/kimol_justdo\nhttps://blog.csdn.net/kimol_justdo/article/details/108912073\nhttps://blog.csdn.net/\nhttps://blog.csdn.net/qq_27644127\nlxguang_tao\n\nhttps://blog.csdn.net/qq_27644127\n\nhttps://i.csdn.net/#/uc/profile?utm_source=14998968\n暂无认证\n\nhttps://i.csdn.net/#/uc/profile?utm_source=14998968\n\nhttps://blog.csdn.net/blogdevteam/article/details/103478461\nhttps://im.csdn.net/chat/qq_27644127\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nhttps://blog.csdn.net/qq_27644127/article/details/112987332\nhttps://blog.csdn.net/qq_27644127/article/details/111566657\nhttps://blog.csdn.net/qq_27644127/article/details/111566657\nhttps://blog.csdn.net/qq_27644127/article/details/111566657\nhttps://blog.csdn.net/qq_27644127/article/details/118380655\nhttps://blog.csdn.net/qq_27644127/article/details/118380655\nhttps://blog.csdn.net/qq_27644127/article/details/118380655\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\nhttps://blog.csdn.net/qq_27644127/category_10685120.html\nhttps://blog.csdn.net/qq_27644127/category_10685120.html\nhttps://blog.csdn.net/qq_27644127/article/details/112987332#comments_14757654\nhttps://blog.csdn.net/m0_50944918\nhttps://blog.csdn.net/qq_27644127/article/details/118380655\nhttps://blog.csdn.net/qq_27644127/article/details/111566657\nhttps://blog.csdn.net/qq_27644127/article/month/2021/07\nhttps://blog.csdn.net/qq_27644127/article/month/2020/12\nhttps://kunpeng-sc.csdnimg.cn/?timestamp=1623163941/#/preview/8608?positionId=57&queryWord=&spm=1001.2101.3001.5001\nhttps://kunpeng-sc.csdnimg.cn/?timestamp=1623163941/#/preview/8608?positionId=479&queryWord=&spm=1001.2101.3001.4834\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\nhttps://blog.csdn.net/qq_27644127/category_10614803.html\nhttps://blog.csdn.net/qq_27644127/category_10685120.html\nhttps://blog.csdn.net/qq_27644127/category_10685120.html\njavascript:;\nhttps://i.csdn.net/#/wallet/balance/recharge\nhttps://i.csdn.net/#/wallet/balance/recharge"
  },
  {
    "objectID": "posts/aa0cab80-26f8-4c9f-80ef-eb0ef006b887/index.html",
    "href": "posts/aa0cab80-26f8-4c9f-80ef-eb0ef006b887/index.html",
    "title": "Bookmark Browsing History Collection",
    "section": "",
    "text": "Bookmark Browsing Directory Tree Browsing History Collection\nUsing Kali forensic tool. (turned out not needed. just some googling for answers)\ndo you need to export your own good old notes? i mean mi notes. 2 phone numbers, 2 accounts. one with physical storage. the other you may want to download the mi note app and extract in the same way.\nOrganized under modifier termux ~/works/bookmark_dirtree_traverse. search via rg.\nmaybe we can organize directory trees using other methods, like some javascript library with both a search tool and a browsing tool. we can host a search engine via javascript, only static resources and client side computation.\nthis client side search engine usage example can be found at /data/data/com.termux/files/home/storage/shared/works/milkshake_server and ./external/milkshake_server. the js searching library is called fuse.js.\nI have made this into meilisearch, and i have backed it up to github/james4ever0/notes2 and aliyunpan and baiduyunpan. desktop search experience is better. meilisearch consume too much ram. i consider to find alternatives with less ram consumption.\nusing rg will be much faster."
  },
  {
    "objectID": "posts/0ce1623e-b08e-4592-ba77-ee4e10caa833/index.html#linux",
    "href": "posts/0ce1623e-b08e-4592-ba77-ee4e10caa833/index.html#linux",
    "title": "CPU Overheating (temperature too high)",
    "section": "linux",
    "text": "linux\ncpufrequtils\nthrottling cpu frequencies by temperature incrementally\nthe desired temperature is 60.\nusually when one throttles the CPU temperature, the GPU cannot be overheated.\nit is turning my core i7 into a pentium 3! but not entirely cumbersome."
  },
  {
    "objectID": "posts/d44f5396-15e8-4c8a-8fb4-2e98168cad82/index.html",
    "href": "posts/d44f5396-15e8-4c8a-8fb4-2e98168cad82/index.html",
    "title": "Cats video with lyrics",
    "section": "",
    "text": "Cats video with lyrics (Netdisk VIP)\nFirst source the cats video. We are downloading it on baidu ai from baidu netdisk.\nCan you parse the download link directly?\nfound script from greasyfork.\nwhy the download speed is low? why there is only one connection? shall i use thunder?\nthe thunder can be invoked, may you test it here.\nso i agree all i need is some sort of communication, across these devices.\n宠物搞笑短视频素材集合，超过5800个宠物短视频素材\n宠物狗短视频素材，宠物猫短视频素材百度网盘：https://pan.baidu.com/s/1I7OYc0eHWC29c0riMFlBEA提取码：5566\nhttps://d.pcs.baidu.com/file/65f4e6c89q4c739f29ac137152c495f6?fid=575343296-250528-687408209949397&dstime=1639908239&rt=sh&sign=FDtAERVJouK-DCb740ccc5511e5e8fedcff06b081203-qPfE%2Bw8zep5K3ktq4I7JoJsNP1g%3D&expires=8h&chkv=1&chkbd=0&chkpc=&dp-logid=110882094549216434&dp-callid=0&shareid=1364427735&r=427232106&resvsflag=1-12-0-1-1-1&vuk=2581136334&file_type=0\nunsure if it is encrypted. why i always found these little sites with massive resources?\nhttp://xm788.ys168.com/\nthe tool itself says it is avaliable for use vip cookies to download files from commandline. let’s try this.\nthe speed unfortunately remains the same. how about download some big files?\ncore-dumped. let’s try curl.\nlooks good. so we can either search and download a bunch of files with commandline, or download big files with android client.\ni quit the payment after all. the price is too high and i do not want to step into this shit. it seems that i can initialize the download anyway, not funny after all.\nso how do you make a point? how to source the cats video?\nsourcing the video is the fundamental step in video production, whether it is shotting by yourself or grabbing from the web, you must do this, with as little help as possible."
  },
  {
    "objectID": "posts/f2a03941-dacc-49c9-8928-51dc435c1cfc/index.html",
    "href": "posts/f2a03941-dacc-49c9-8928-51dc435c1cfc/index.html",
    "title": "Cats video with lyrics_2",
    "section": "",
    "text": "Cats video with lyrics (Algorithm)\nFinally, the cats.\nTo harvest video by tags, authors, categorize them, count the views divided by time, model the predicted views and select only the best, original videos to upload.\nThe views on other platforms does not matter and views on other channels does not matter, in the long term. We might try to embrace them because of this number seen on others but we need real feedback on our channels.\nFilters can be generated by regular expressions, common patterns found in text, and indexed. Filters generated from data. We index filters, record them according to views.\nI am selling myself on cheap. Maybe not.\nUsing the same strategy of searching the web.\napi of weibo (this is news!):\nhttp://sinanews.sina.cn/interface/type_of_search.d.html?callback=initFeed&keyword=%E6%98%8E%E6%98%9F&page=1&type=siftWb&size=20&newpage=0&chwm=&imei=&token=&did=&from=&oldchwm=\nresponse:\ninitFeed({“status”:0,“msg”:“success”,“keywords”:[“明星”],“data”:{“feed1”:[{“user”:{“id”:1275327624,“name”:“圈内小馒头”,“url”:“http://m.weibo.cn/1275327624”,“profile_image_url”:“https://tvax3.sinaimg.cn/crop.0.0.587.587.50/001oj8Yoly8gvfweyv784j60gb0gb0td02.jpg?KID=imgbed,tva&Expires=1639964114&ssig=tXKjnI%2FcKK”,“verified_ico”:““},”title”:“#张艺兴#明白了！就是想求着跟张艺兴合作！张艺兴嫌他办事不行就退了！他恼羞成怒！更年期小气男跑微博泄愤造谣！还有他是个der 时尚博主啊？？？粉丝一半是买的！一半是之前蹭投票蹭的（就是会发明星的西装照投票你觉得谁穿西装最帅）类似这种的！！！现实中啥也不是的货！！#徐峰立# ​”,“image”:“http://wx1.sinaimg.cn/bmiddle/006rFoDCly1gxjrgfc8eaj30f50vodhp.jpg”,“video”:0,“url”:“http://www.weibo.com/1275327624/L6RC8CnwM”,“time”:“31分钟前”},{“user”:{“id”:1907445023,“name”:“ximalaya2020”,“url”:“http://m.weibo.cn/1907445023”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.996.996.50/71b14d1fly8gpv95u4nntj20ro0ro0ts.jpg?KID=imgbed,tva&Expires=1639964114&ssig=%2BYeO7pqPPX”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/yellow.png”},“title”:“#全世界最好的肖战[超话]##与肖战一起战放精彩# 与肖战一起战放精彩xz#肖战六神品牌代言人# 肖战六神品牌代言人！。 他们是牵肠挂肚的母子，是相濡以沫的爱人，是不离不弃的恋人，是同甘共苦的姐妹，是一个战壕扛过枪的战友，是胜 ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/1907445023/L6RC0kYff”,“time”:“32分钟前”},{“user”:{“id”:1860496124,“name”:“GoodBai”,“url”:“http://m.weibo.cn/1860496124”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.1080.1080.50/6ee4eafcly8gp1tgo4wuej20u00u0gmc.jpg?KID=imgbed,tva&Expires=1639964114&ssig=GsMXna%2FGRd”,“verified_ico”:““},”title”:“作为一名旁观者静静地吃了最近的瓜，相信很快就有结果了. 我只想说这么多年来，这么多明星出事的处理方式，陈老师是最爷们的[摊手] http://t.cn/RVvxlsh ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/1860496124/L6RBWwCp4”,“time”:“32分钟前”},{“user”:{“id”:1314608344,“name”:“新闻晨报”,“url”:“http://m.weibo.cn/1314608344”,“profile_image_url”:“https://tvax3.sinaimg.cn/crop.0.0.996.996.50/4e5b54d8ly8gdi5j8smmoj20ro0rot9w.jpg?KID=imgbed,tva&Expires=1639964114&ssig=CFe6jMRb5w”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/blue.png”},“title”:“#王力宏发文回应#【#王力宏称李靓蕾指控不实#，婚后一直生活在勒索威胁之下】12月19日晚，王力宏发长文回应风波，称李靓蕾指控为不实。​​​​王力宏称今天是自己人生中最难过的一天，是一场巨烈、巨痛的噩梦，他还表示自己和李靓蕾结婚后，一直生活在恐惧、勒索和威胁之下。&gt;&gt;，王力宏 ​”,“image”:“http://wx4.sinaimg.cn/bmiddle/001qXXGoly1gxjvll8j79j60u06dbqv502.jpg”,“video”:0,“url”:“http://www.weibo.com/1314608344/L6RBqzAMO”,“time”:“33分钟前”},{“user”:{“id”:7566155477,“name”:“天界水神布雨被冲下来的闲仙”,“url”:“http://m.weibo.cn/7566155477”,“profile_image_url”:“https://tvax1.sinaimg.cn/crop.0.0.664.664.50/008g2OFLly8gx2mi7uc2hj30ig0igmxs.jpg?KID=imgbed,tva&Expires=1639964114&ssig=L81vU5yTnv”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/yellow.png”},“title”:“#杨紫[超话]#yz#杨紫女心理师# yz#杨紫贺顿# 抬头仰望国旗 四射的光芒与夺目的红浑然一体 目光所至心之所向皆是信仰 抬头是国家 举目是你@杨紫 @杨紫 @杨紫 ｜杨紫机场｜杨紫新剧｜杨紫单身｜杨紫粉丝｜杨紫同款｜杨紫好看｜杨紫女神｜杨紫美女｜杨紫绝美｜杨紫超甜 ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/7566155477/L6RAYvjP2”,“time”:“34分钟前”},{“user”:{“id”:6192877122,“name”:“惊奇脑洞”,“url”:“http://m.weibo.cn/6192877122”,“profile_image_url”:“https://tvax1.sinaimg.cn/crop.0.0.828.828.50/006L6GeSly8gln1dtwrm1j30n00n03zr.jpg?KID=imgbed,tva&Expires=1639964114&ssig=ox25CCv7YY”,“verified_ico”:“http://n.sinaimg.cn/mobileh5/24f155b4/20170817/yellow.png”},“title”:“我小时候居然演过《快乐星球》？原来我也长着明星脸？！#搞笑##搞笑视频##视频藏宝阁# http://t.cn/A6x3FUyG ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/6192877122/L6RAlzqis”,“time”:“36分钟前”},{“user”:{“id”:1839242362,“name”:“带我看看你的城市”,“url”:“http://m.weibo.cn/1839242362”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.996.996.50/6da09c7aly8gform61ilfj20ro0ro0uf.jpg?KID=imgbed,tva&Expires=1639964114&ssig=kbT1KTxBmS”,“verified_ico”:““},”title”:“#壹段评# 【#中国妇女报再评王力宏#事件：防范以“爱”为名的伤害，警惕脱离职场的风险】#中国妇女报评王力宏#近日，王力宏宣布离婚，其前妻李靓蕾在微博发布长文，控诉王力宏种种不端行为，引发关注与热议。，此次的网友议论还指向了一些令人深思的公共议题：全职主妇的“绝望” ​“,”image”:““,”video”:0,“url”:“http://www.weibo.com/1839242362/L6RAfhH37”,“time”:“36分钟前”},{“user”:{“id”:5637495678,“name”:“N太阳的阳”,“url”:“http://m.weibo.cn/5637495678”,“profile_image_url”:“https://tvax3.sinaimg.cn/crop.0.0.996.996.50/0069wm9Ely8fq5uelhg9cj30ro0rogmp.jpg?KID=imgbed,tva&Expires=1639964114&ssig=5Z7%2B9I5wBI”,“verified_ico”:““},”title”:“都扒明星 谁来扒我？扒出我的老实 扒出我的单纯 扒出我对爱情的始终如一 http://t.cn/RPzTEbX ​”,“image”:“http://wx4.sinaimg.cn/bmiddle/0069wm9Ely1gxjtiphxe3j32c0340hdu.jpg”,“video”:0,“url”:“http://www.weibo.com/5637495678/L6RzahwGW”,“time”:“39分钟前”},{“user”:{“id”:3675549863,“name”:“旺旺曉曉酥哦”,“url”:“http://m.weibo.cn/3675549863”,“profile_image_url”:“https://tvax1.sinaimg.cn/crop.0.0.512.512.50/db1470a7ly8glkuo4btqwj20e80e874r.jpg?KID=imgbed,tva&Expires=1639964114&ssig=fBwQujydh3”,“verified_ico”:““},”title”:“#王力宏出轨# 不是明星人设崩塌，只是因为是明星所以滤镜重，关注度高。现实里有的男人一样坏到不行，摊上这种不负责任只会逃避的男人，真的倒了八辈子的血霉。，一丘之貉。在莫名其妙地分手之后，在身边朋友都在帮我骂他渣男的时候，我还在为他背书，我说不要用恶 ​”,“image”:“http://wx2.sinaimg.cn/bmiddle/db1470a7gy1gxjuljgl7gj20ty0vswos.jpg”,“video”:0,“url”:“http://www.weibo.com/3675549863/L6Rslppzv”,“time”:“55分钟前”},{“user”:{“id”:7349735467,“name”:“NANA划条大路通CTiy”,“url”:“http://m.weibo.cn/7349735467”,“profile_image_url”:“https://tvax4.sinaimg.cn/crop.0.0.996.996.50/0081oJWrly8gxi80oofluj30ro0rotan.jpg?KID=imgbed,tva&Expires=1639964114&ssig=0Q%2BPfuSxPu”,“verified_ico”:““},”title”:“不管怎么说 这么多年我前前后后担来担去我还是很相信他。更喜欢看明星摔下神坛让子弹再飞一会不要丧失理智 晚安。 ​”,“image”:““,”video”:0,“url”:“http://www.weibo.com/7349735467/L6QdYb1k5”,“time”:“5小时前”}]}})\nwe need videos. you download it from baidu ai cloud.\nwe need feedback. we need this since this is how we try things.\nanything can be hackish, especially for this damn “we media”. anything can be popular, from basic bash script to regular expressions, based on how you looking at it. we shall not feed our audience full of something than another unless we know for sure it is our target.\nit is the power of the mirror! the feedback!\ncreate a fake, dummy project full of skeletons and then realize every step till we are done."
  },
  {
    "objectID": "posts/b77b6a03-11cb-401c-86bf-cd72715aaa70/index.html",
    "href": "posts/b77b6a03-11cb-401c-86bf-cd72715aaa70/index.html",
    "title": "Chatbot, Self-hosted Model, Cloud Deploy, Cloud services, Free website hosting service",
    "section": "",
    "text": "vercel hosts frontend only apps, could be useful if you want.\n可以提取关键词然后到百度必应上面搜索 获取相关内容 注意语种一致性\nsearch huggingface with julia or python:\nhuggingface_hub(python)\n可以用huggingface的api来翻译 对接英文的chatbot (blenderbot, dialo-gpt)\nadd timeout to these api requests\n可以把训练好的中文chatbot放到huggingface上面去 用kaggle放\nhttps://github.com/yangjianxin1/GPT2-chitchat\ncould use this method to generate title for videos. i mean generally.\ncould host the model on huggingface, or baidu aistudio, heroku or your own machine\nconfigure accelerated inference on huggingface (free for cpu, paid gpu):\nhttps://huggingface.co/docs/api-inference/quicktour\nhuggingface inference apis:\nhttps://huggingface.co/inference-api\nhuggingface conversational (chatbot) models:\nhttps://huggingface.co/models?pipeline_tag=conversational&sort=downloads\nheroku, use fastapi as interface:\nhttps://fastapi.tiangolo.com\nhttps://www.kaggle.com/getting-started/208405\nhttps://signup.heroku.com\nheroku alternatives:\nback4app, google app engine\naistudio api, maybe you need to train or find a paddpepaddle based chatbot:\nhttps://ai.baidu.com/ai-doc/AISTUDIO/bk3e382cq#创建在线api服务\n一个项目可以创建至多五个沙盒服务, 并选择其中一个沙盒服务部署为线上服务.\n沙盒服务如果连续超过24小时无调用将自动调整为暂停状态.\n线上服务如果连续超过14天无调用将自动调整为暂停状态.\npaddlenlp\nhttps://aistudio.baidu.com/aistudio/projectdetail/3723144?channelType=0&channel=0\npaddlepaddle chat model:\nplato2\nhttps://github.com/PaddlePaddle/Knover\nhttps://github.com/PaddlePaddle/Knover/tree/develop/projects/PLATO-2\nhttps://aistudio.baidu.com/aistudio/projectdetail/1886227?channelType=0&channel=0\n中文chatbot:\nhttps://github.com/zhaoyingjun/chatbot\nhttps://github.com/Dimsmary/Ossas_ChatBot\n教程\nhttps://github.com/lcdevelop/ChatBotCourse\nhttps://github.com/fendouai/Awesome-Chatbot\n语料库\nhttps://github.com/codemayq/chinese_chatbot_corpus"
  },
  {
    "objectID": "posts/c8579cd8-805b-43db-bd7d-9b6e9a642bf5/index.html",
    "href": "posts/c8579cd8-805b-43db-bd7d-9b6e9a642bf5/index.html",
    "title": "How to Clean Up Chocolatey’s Cache with the choco-cleaner.ps1 Script",
    "section": "",
    "text": "Chocolatey cleanup cache\npowershell choco-cleaner.ps1"
  },
  {
    "objectID": "posts/c172e781-4ff8-472d-984a-971d3111acc1/index.html#dns",
    "href": "posts/c172e781-4ff8-472d-984a-971d3111acc1/index.html#dns",
    "title": "Clash route only github related domains to fastgithub",
    "section": "DNS",
    "text": "DNS\nuse clash official DNS settings to resolve issues related to domain resolution, especially when used as a system proxy.\ndocumentation\nto persist program using platform-specific service manager like nssm on windows:"
  },
  {
    "objectID": "posts/c172e781-4ff8-472d-984a-971d3111acc1/index.html#macos",
    "href": "posts/c172e781-4ff8-472d-984a-971d3111acc1/index.html#macos",
    "title": "Clash route only github related domains to fastgithub",
    "section": "macos",
    "text": "macos\nuse launchctl(launchd) or easyd"
  },
  {
    "objectID": "posts/c172e781-4ff8-472d-984a-971d3111acc1/index.html#linux",
    "href": "posts/c172e781-4ff8-472d-984a-971d3111acc1/index.html#linux",
    "title": "Clash route only github related domains to fastgithub",
    "section": "linux",
    "text": "linux\ncreate systemd\nneed to change system wide proxy settings in init files\nor use monit, with control over the service itself.\nor shell script alike linuxNSSM"
  },
  {
    "objectID": "posts/8c2c71ad-6f48-4d30-8400-927ab4041b03/index.html",
    "href": "posts/8c2c71ad-6f48-4d30-8400-927ab4041b03/index.html",
    "title": "Content Usage",
    "section": "",
    "text": "Use the original transcript for paraphrasing, while using danmaku for joke generation."
  },
  {
    "objectID": "posts/3452de1f-29a3-4a1a-839f-b2033860292a/index.html",
    "href": "posts/3452de1f-29a3-4a1a-839f-b2033860292a/index.html",
    "title": "Copilot_Codex alternative",
    "section": "",
    "text": "Copilot/Codex alternative\nuse chatgpt instead, when it is free.\ntsinghua (again!) introduced a similar open source model called codegeex, having better performance than incoder (by meta) and codegen with vscode plugin support, able to generate and translate code. the info is found on tuna events and you can download video/scripts for some events. trained on humaneval-x dataset for code generation. it also provides blog and podcast\nCodegen\nhttps://github.com/salesforce/CodeGen\ncopilot self-hosted powered by codegen (lots of vram, maybe for mac studio 128gb, however it only supports nvidia gpu):\nhttps://github.com/moyix/fauxpilot\ncode autocomplete\nhttps://github.com/shibing624/code-autocomplete\ncodegpt python token completion\nhttps://huggingface.co/mrm8488/CodeGPT-small-finetuned-python-token-completion\ncodegpt\nhttps://huggingface.co/microsoft/CodeGPT-small-py-adaptedGPT2\nhttps://huggingface.co/microsoft/CodeGPT-small-py\nhttps://github.com/microsoft/CodeXGLUE/issues/75\nhttps://github.com/microsoft/CodeXGLUE/issues/36\ncodebert\nhttps://github.com/microsoft/CodeBERT\ncode-gpt-neox\nhttps://github.com/Linyxus/code-gpt-neox\nCaptain Stack\nhttps://github.com/hieunc229/copilot-clone\nclara\nhttps://github.com/badboysm890/clara-copilot\ngpt-code-clippy\nhttps://github.com/CodedotAl/code-clippy-vscode\nhttps://github.com/ncoop57/gpt-code-clippy\nhttps://github.com/CodedotAl/gpt-code-clippy\nhttps://discuss.huggingface.co/t/pretrain-gpt-neo-for-open-source-github-copilot-model/7678?u=ncoop57\nhttps://gpt3demo.com/apps/gpt-code-clippy-gpt-cc\nhttps://seart-ghs.si.usi.ch/ (github search engine)\nkite\nhttps://kite.com/integrations/jupyter/\nsecond mate\nhttps://github.com/samrawal/emacs-secondmate\nasm dude\nhttps://github.com/HJLebbink/asm-dude\nyoucompleteme\nhttps://github.com/ycm-core/YouCompleteMe\ncode-lms(polycoder)\nhttps://github.com/VHellendoorn/Code-LMs#models\nhttps://zenodo.org/record/6363556"
  },
  {
    "objectID": "posts/1870da8d-eaf6-4728-bb7f-4e94259f8dbc/index.html",
    "href": "posts/1870da8d-eaf6-4728-bb7f-4e94259f8dbc/index.html",
    "title": "Create and Import Backups in StandardNotes",
    "section": "",
    "text": "https://standardnotes.com/help/14/how-do-i-create-and-import-backups-of-my-standard-notes-data#:~:text=%20How%20to%20create%20backups%20of%20your%20data%3A,This%20file%20%20may%20be%20imported…%20More%20"
  },
  {
    "objectID": "posts/35f90ef1-eaad-42cc-bbb8-6291de7982b3/index.html",
    "href": "posts/35f90ef1-eaad-42cc-bbb8-6291de7982b3/index.html",
    "title": "Cut Music Scenes With Lyrics and BPM",
    "section": "",
    "text": "Cut Music Segments With Lyrics and BPM\ndef compare(a,b,reverse=False):\nseg_low, seg_high = get_allowed_segments(bpm, low, high, tolerance=0.8) # the tolerance is compared with a common function called compare. it can be customized to output only value &gt;=1 or vice versa.\ncandidates = sorted_lyrics_nearby_bpm_candidates + sorted_remained_bpm_candidates # priortize lyrics candidates."
  },
  {
    "objectID": "posts/410f1734-5de6-4f73-ad85-2ff995166052/index.html",
    "href": "posts/410f1734-5de6-4f73-ad85-2ff995166052/index.html",
    "title": "Cybergod discord channel",
    "section": "",
    "text": "join at: https://discord.gg/y9BrdMfA\ni plan to intergrate it to my agi-computer-control repo."
  },
  {
    "objectID": "posts/ff18b1f8-a2a1-41d5-951b-42d5d1eb20f4/index.html",
    "href": "posts/ff18b1f8-a2a1-41d5-951b-42d5d1eb20f4/index.html",
    "title": "DNA Cancer Prediction",
    "section": "",
    "text": "https://github.com/davidanastasiu/coen-342-wi22\nPR1: Peptide Classification\nPublished Date:\nJan. 12, 2020, 5:00 p.m.\nDeadline Date:\nJan. 25, 2020, 11:59 p.m.\nDescription:\n\nThis is an individual assignment.\n\nOverview and Assignment Goals:\nThe objectives of this assignment are the following:\n\nCreate feed-forward neural networks and train them using your own codes and\nframeworks.\n\nExperiment with different feature extraction techniques.\n\nThink about dealing with imbalanced data.\nDetailed Description:\nDevelop predictive neural networks that can determine, given an antibacterial peptide,\nwhether it is also an antibiofilm peptide.\n“Proteins are large biomolecules, or macromolecules, consisting of one or more long\nchains of amino acid residues. Proteins perform a vast array of functions within organisms,\nincluding catalysing metabolic reactions, DNA replication, responding to stimuli, providing\nstructure to cells, and organisms, and transporting molecules from one location to another.\nProteins differ from one another primarily in their sequence of amino acids, which is\ndictated by the nucleotide sequence of their genes, and which usually results in protein\nfolding into a specific three-dimensional structure that determines its activity.\nA linear chain of amino acid residues is called a polypeptide. A protein contains at least\none long polypeptide. Short polypeptides, containing less than 20-30 residues, are rarely\nconsidered to be proteins and are commonly called peptides. […] The sequence of amino\nacid residues in a protein is defined by the sequence of a gene, which is encoded in the\ngenetic code. In general, the genetic code specifies 20 standard amino acids; […] Proteins\ncan also work together to achieve a particular function, and they often associate to form\nstable protein complexes.” [Wikipedia, Accessed 2020-02-07,\nhttps://en.wikipedia.org/wiki/Protein]\nBiofilms are tightly-connected multicellular communities of microorganisms encased in self-\nsecreted extra-cellular matrices. They are currently one of the major causes of disease for\ntwo main reasons. First, roughly 75% of all human infections are caused by biofilms.\nSecond, due to the robust multicellular cellular matrix structure, they are resistant both to\nthe host defense mechanisms and to traditional antimicrobial compounds (antibiotics).\nThus, it is important to identify peptide sequences that are not only antimicrobial (can\ndestroy or render inert the invading microorganism), but also antibiofilm (can penetrate the\nextra-cellular matrix so it can get to the microorganism in the first place).\nYou have been provided with a training set (train.dat) and a test set (test.dat) consisting of\npeptide sequences, one per line in the file. Peptides are encoded as strings with characters\nfrom an alphabet of 20 characters, each representing an amino-acid residue. The training\nset also includes the label for each sequence as 1 (antibiofilm) or -1 (not antibiofilm) as the\nfirst character in each line of the training file, separated from the sequence by a tab (\ncharacter.\nThe input to your classifiers will not be the peptides themselves, but rather features\nextracted from the peptides. Two simple approaches for feature extraction are the bag-of-\nwords and the k-mer models you should have learned about in Data Mining or Machine\nLearning, where a word is one of the amino-acids in the peptide. You should not use any\nadditional external data in this assignment.\nNote that the dataset is imbalanced. We will Matthews’s correlation coefficient (MCC) as\nevaluation metric for this assignment, which, similar to the F-1 score, combines aspects of\nthe result’s sensitivity and specificity. Given the normal confusion matrix resulting from\ncomparing the predicted and true classes of the test samples, MCC is defined as,\nPrograms:\nYou are required to write two separate programs for the classification. The first may only\nuse basic Python structures (from numpy or scipy) and you should implement your own\nfunctions for training the neural network. This is also the program you will use to make CLP\nsubmissions. In addition, you should write a second program that uses a deep learning\nframework of your choice to train the neural network. The structure of the network may be\nthe same or different from the one you created in the first program. You will present results\nfrom this program (which should be at least as good as those from the first program) in\nyour report.\nConsiderations:\n\nTry extracting different features from the peptide strings.\nConsider oversampling the negative class to fix the apparent imbalance.\nTry out different network configurations and activation functions.\nConsider regularization as a way to keep weights balanced in the network.\n\nData Description:\nThe training dataset consists of 1566 records and the test dataset consists of 392 records.\nWe provide you with the training class labels and the test labels are held out. Your task is\nto predict those labels for the peptides in the test set and create a test.txt file containing\nthose labels, which you will submit to CLP. Note that CLP only accepts files with extensions\n.txt or .dat for your predicted labels, and .py or .ipynb or .zip or .tgz for codes.\nRules:\n\nThis is an individual assignment. Discussion of broad level strategies are allowed but\nany copying of prediction files and source codes will result in an honor code violation.\n\nYou are allowed 5 submissions per day.\n\nAfter the submission deadline, only your chosen or last submission is considered for\nthe leaderboard.\nDeliverables:\n\nValid submissions to the Leader Board website: https://clp.engr.scu.edu (username is\nyour SCU username and your password is your SCU password).\nCanvas Submission for the report:\n\nInclude a 2-page, single-spaced report describing details regarding the steps you\nfollowed for feature extraction, designing your neural network, and training your model.\nThe report should be in PDF format and the file should be called report.pdf. The report\nneeds to be structured as a technical report (title, abstract, introduction, sections,\nconclusion), be free from grammatical errors, and use standard page and font sizes (letter\nsize page, 10 or 11 pt font). Be sure to include the following in the report:\n\nName and SCU ID.\nRank & MCC-score for your submission (at the time of writing the report). If\n\nyou chose not to see the leaderboard, state so.\n\n\n\nYour approach.\n\n\n\nYour methodology of choosing the approach and associated parameters.\n Ensure you submitted the correct code on CLP that matches your output.\n Zip up your report and codes for both programs in an archive called .zip or\n.tgz and submit the archive to Canvas.\nGrading:\nGrading for the Assignment will be split on your implementation (70%) and report (30%).\nExtra credit (1% of final grade) will be awarded to the top-3 performing algorithms. Note\nthat extra credit throughout the semester will be tallied outside of Canvas and will be added\nto the final grade at the end of the semester.\nFiles: available on Canvas."
  },
  {
    "objectID": "posts/a6b9f5ae-ee71-49a4-b9d0-b87da1180e8a/index.html",
    "href": "posts/a6b9f5ae-ee71-49a4-b9d0-b87da1180e8a/index.html",
    "title": "DeepNude Censorship NSFW safesearch",
    "section": "",
    "text": "clip-based-nsfw-detector\nyou can turn on/off safesearch by changing ip to iran. is there better options, doing this programmatically?\nnsfw createml imageclassifier with pretrained model\n敏感词过滤器 also need a high speed censor engine using trie, also in diffferent language(like english or japanese)\nenglish profanity:\nhttps://github.com/snguyenthanh/better_profanity\nhttps://github.com/zacanger/profane-words\nhttps://github.com/MauriceButler/badwords\nhttps://github.com/vzhou842/profanity-check\nhttps://github.com/coffee-and-fun/google-profanity-words\nchinese profanity:\nhttps://github.com/gaohuifeng/sensitive-word-filter\nhttps://github.com/lunzima/profanities.txt\nhttps://github.com/nyx1987/forbiddenwords\nhttps://github.com/insoxin/bannedwords\nhttps://github.com/chason777777/mgck\nhttps://github.com/k5h9999/keywordfilter\nhttps://github.com/tomzhang/bannedwords\nhttps://github.com/observerss/textfilter （需要回看历史 查看git历史）\nhttps://github.com/aojiaotage/text-censor\ndeepnude nsfw nude picture detection:\nhttps://github.com/yuanxiaosc/DeepNude-an-Image-to-Image-technology/blob/master/README-ZH.md\nvideoaudit 视频审核框架https://github.com/minitrill/VideoAudit\nnsfw: not safe for work, inappropriate content, porn, offensive\nhttps://github.com/rockyzhengwu/nsfw\nhttps://github.com/alex000kim/nsfw_data_scraper\nhttps://github.com/yahoo/open_nsfw\nhttps://github.com/Rayraegah/nsfw_japan\nhttps://github.com/fishsup/nsfw-image-classification\nhttps://github.com/yangbisheng2009/nsfw-resnet\nhttps://github.com/GantMan/nsfw_model\nhttps://github.com/devzwy/open_nsfw_android\nhttps://github.com/infinitered/nsfwjs\nhttps://github.com/nsfw-filter/nsfw-filter\nnudity, violence and drug\nhttps://github.com/amshrbo/nsfw-detection\nto train these networks, suitable datasets are required.\n找训练集 找涉政 涉黄 暴力血腥图片训练集 找类似的文字训练集 百度aistudio可能有 github可能有 百度一下也可能有\n同样的思路 情绪 情感打分也可以这样打分 根据不同的训练集进行打分\ngithub violence detection:\nhttps://github.com/topics/violence-detection\nBloody Image Classification with Global and Local Features\nhttps://www.researchgate.net/publication/309365631_Bloody_Image_Classification_with_Global_and_Local_Features\nObject content understanding in images and videos draws more and more attention nowadays. However, only few existing methods have addressed the problem of bloody scene detection in images. Along with the widespread popularity of the Internet, violent contents have affected our daily life. In this paper, we propose region-based techniques to identify a color image being bloody or not. Firstly, we have established a new dataset containing 25431 bloody images and 25431 non-bloody images. These annotated images are derived from the Violent Scenes Dataset, a public shared dataset for violent scenes detection in Hollywood movies and web videos. Secondly, we design a bloody image classification method with global visual features using Support Vector Machines. Thirdly, we also construct a novel bloody region identification approach using Convolutional Neural Networks. Finally, comparative experiments show that bloody image classification with local features is more effective.\nsearch for nsfw filter providers on google/kaggle\nkaggle nsfw image dataset\nhttps://www.kaggle.com/datasets/laxmansingh/nsfw-images-data\nhttps://www.kaggle.com/datasets/drakedtrex/my-nsfw-dataset/code\nsearch for nsfw image/text on github:\nhttps://github.com/alex000kim/nsfw_data_scraper\nhttps://github.com/nsfw-filter/nsfw-filter\nnsfwjs\nhttps://github.com/arufian/Image-Censor-Lightning-Web-Component\nhttps://github.com/enymuss/censorText\nhttps://github.com/fmsky/resnet50_inappropriate_content_detect\nhttps://github.com/CheranMahalingam/Image_Content_Moderation\n文本审核框架：\nhttps://github.com/minitrill/TextAudit\n规避文本审查：有可能是加密了 但是人眼可以识别\nhttps://github.com/kallydev/shutup\nnudenet based inappropriate image censoring\nocr based word censoring\npolitics\n涉及政治：领导人 人脸识别 图标识别\nviolence\n血腥暴力：图像识别"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#neural-engine",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#neural-engine",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "neural engine",
    "text": "neural engine\nit is used for coreml inference, not training"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#run-coreml-on-hackintosh",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#run-coreml-on-hackintosh",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "run coreml on hackintosh",
    "text": "run coreml on hackintosh\nfirst, download macos montery using the mac.\nthen, install it on hackintosh, with associated nvidia drivers.\nnext test gpu avalibility via system info panel.\nthen install xcode commandline tools and check coreml avalibility"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#run-coreml-with-swift-on-linux",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#run-coreml-with-swift-on-linux",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "run coreml with swift on linux",
    "text": "run coreml with swift on linux\ndarling is at its very premature stage, just like the wine. now it is testing something called “darlingserver” which is a full userspace implementation and is prone to tons of problems. swift repl is not working and installing xcode commandline tools 14 will hang this thing. i suggest you to do light model training on macbook air and convert it to onnx if want to use it everywhere.\nbefore reinstallation of darling, make sure you have removed all darling related files by checking updatedb; locate darling | grep -v &lt;compile directory&gt;\nvisit here to install darling from source (maybe that’s the only way)\nif want to install darling on kali, you must outsource all deeplearning models to other disks, and collect all other big files to somewhere else or trash them. use systemwide user broadcast method to warn me if any of the disk is missing. use automatic symlink change method to adapt the external disk mountpoint changes.\ndarling can install xcode commandline tools with macos sdk, so maybe it can run coreml models with swift using cpu. gpu support is currently not known. maybe that requires metal support."
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#thermal-and-battery-life-concerns-and-more",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#thermal-and-battery-life-concerns-and-more",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "thermal and battery life concerns, and more",
    "text": "thermal and battery life concerns, and more\nconsider using external gpus (eGPUs) with thunderbolt 3 and AMD GPUs to avoid overheating. currently that can only be done with intel Macs.\nbattery life is currently bad for intel/amd notebooks of x86/64 architecture.\nheavy lifting jobs are likely to be run on Mac Studio with M1 Ultra and 128GB RAM. Macbook Air M1 with 8GB RAM is simply not feasible.\naside of Apple platforms, these APIs are virtually useless.\nto run these on other non-apple machines, you need to tweak and install macOS on x86-64 platforms with macOS supported GPUs(may have low performance), which will definitely not taking any advantage of huge shared RAM with CPU, and may run poorly on CoreML/CreateML, may not support deepspeed stage 2/3 or BMI(big model inference)\n\n\nNon-Supported NVIDIA Cards, use AMD GPU instead\n\nHigh Sierra no longer supports NVIDIA Mac.\nMojave – Catalina – BigSur only works with AMD graphics and Intel onboard graphics and only a very small number of old NVIDIA products. Suppose you have GTX 1070, 1080, and the like, you can not use High Sierra onwards because Nvidia does not provide any updates for Mac and can not be used in any other way.\nIn general, the graphics of the Turing, Pascal, and Maxwell series will never be supported again. The latest Mac version that can use this series of graphics is High Sierra."
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#tensorflow-with-m1-support",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#tensorflow-with-m1-support",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "tensorflow with m1 support",
    "text": "tensorflow with m1 support\nusing tensorflow metal plugin, which sets up miniforge and install tensorflow-metal within.\ninstall without miniforge(works!)\npip3 install tensorflow-macos tensorflow-metal\nvalidation:\npython3 -c \"import tensorflow as tf; physical_devices = tf.config.list_physical_devices('GPU'); print('Num GPUs:', len(physical_devices)); print(physical_devices)\""
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#pytorch-with-m1-support-using-mps-metal-performance-shader",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#pytorch-with-m1-support-using-mps-metal-performance-shader",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "pytorch with m1 support, using MPS (Metal performance shader)",
    "text": "pytorch with m1 support, using MPS (Metal performance shader)\ninstall from nightly release channel, with minimum system version requirements 12.3 (which this machine had been qualified after system update, now 12.5)\n# MPS acceleration is available on MacOS 12.3+\npip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\nvalidation\npython3 -c \"import torch; print('MPS avaliable:',torch.backends.mps.is_available()); print('Built with MPS:',torch.backends.mps.is_built())\""
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#run-python-inside-swift",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#run-python-inside-swift",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "run python inside swift",
    "text": "run python inside swift\nuse pythonkit"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#automatic-machine-learning-using-createml",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#automatic-machine-learning-using-createml",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "automatic machine learning using CreateML",
    "text": "automatic machine learning using CreateML\nimport CreateML\nCreateML is similar to any other AutoML tools, like AutoKeras, AutoTrain by Huggingface (works by training against a selected set of user-provided models)"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#using-coreml",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#using-coreml",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "using CoreML",
    "text": "using CoreML\ncurated, largest coreml models collection\nCoreML models can be created by CreateML and some customization can be done via protocol MLCustomLayer.\nonnxruntime can run onnx models on CoreML, via c#, since that library is maintained by microsoft.\nto install c# on macos:\nbrew install dotnet-sdk\nto install and launch dotnet repl:\ndotnet tool install -g dotnet-repl\ndotnet repl"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#paddlepaddle-support",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#paddlepaddle-support",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "paddlepaddle support",
    "text": "paddlepaddle support\nconvert into onnx first, then run on onnxruntime.\npaddlepaddle itself currently only supports running on M1 CPU only via rosetta 2."
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#links",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html#links",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "Links",
    "text": "Links\nSwift Core ML 3 implementations of GPT-2, DistilGPT-2, BERT, and DistilBERT for Question answering.\ntrain image classifier and text classifier in which CreateMLUI is deprecated (gone)\ntrain source code classifier with flightschool which is a free swift tutorial books provider\nclassifying sounds with coreml return sound type along with timestamp\ndetect human pose using coreml\napple speech recognization api request\npytorch mps backend\ntext classification using createml\nonnx model zoo\nGetting CoreML Models\nCoreML Model Zoo\n\n\nFCRN-DepthPrediction\nDepth Estimation\nPredict the depth from a single image.\nView Models\nMNIST\nDrawing Classification\nClassify a single handwritten digit (supports digits 0-9).\nView Model\nUpdatableDrawingClassifier\nDrawing Classification\nDrawing classifier that learns to recognize new drawings based on a K-Nearest Neighbors model (KNN).\nView Model and Code Sample\nMobileNetV2\nImage Classification\nThe MobileNetv2 architecture trained to classify the dominant object in a camera frame or image.\nView Models and Code Sample\nResnet50\nImage Classification\nA Residual Neural Network that will classify the dominant object in a camera frame or image.\nView Models and Code Sample\nSqueezeNet\nImage Classification\nA small Deep Neural Network architecture that classifies the dominant object in a camera frame or image.\nView Models and Code Sample\nDeeplabV3\nImage Segmentation\nSegment the pixels of a camera frame or image into a predefined set of classes.\nView Models\nYOLOv3\nObject Detection\nLocate and classify 80 different types of objects present in a camera frame or image.\nView Models and Code Sample\nYOLOv3-Tiny\nObject Detection\nLocate and classify 80 different types of objects present in a camera frame or image.\nView Models and Code Sample\nPoseNet\nPose Estimation\nEstimates up to 17 joint positions for each person in an image.\nView Models and Code Sample\nText\nBERT-SQuAD\nQuestion Answering\nFind answers to questions about paragraphs of text.\nView Model and Code Sample\n\n\nApple Machine Learning Related APIs (may need user permission within or without xcode by means of Info.plist or something)\n\n\nVision\nBuild features that can process and analyze images and video using computer vision.\nView Vision framework\nImage Classification\nAutomatically identify the content in images.\nView API\nImage Saliency\nQuantify and visualize the key part of an image or where in the image people are likely to look.\nView API\nImage Alignment\nAnalyze and manage the alignment of images.\nView API\nImage Similarity\nGenerate a feature print to compute distance between images.\nView API\nObject Detection\nFind and label objects in images.\nView API\nObject Tracking\nTrack moving objects in video.\nView API\nTrajectory Detection\nDetect the trajectory of objects in motion in video.\nView API\nContour Detection\nTrace the edges of objects and features in images and video.\nView API\nText Detection\nDetect regions of visible text in images.\nView API\nText Recognition\nFind, recognize, and extract text from images.\nView API\nFace Detection\nDetect human faces in images.\nView API\nFace Tracking\nTrack faces from a camera feed in real time.\nView API\nFace Landmarks\nFind facial features in images by detecting landmarks on faces.\nView API\nFace Capture Quality\nCompare face capture quality in a set of images.\nView API\nHuman Body Detection\nFind regions that contain human bodies in images.\nView API\nBody Pose\nDetect landmarks on people in images and video.\nView API\nHand Pose\nDetect landmarks on human hands in images and video.\nView API\nAnimal Recognition\nFind cats and dogs in images.\nView API\nBarcode Detection\nDetect and analyze barcodes in images.\nView API\nRectangle Detection\nFind rectangular regions in images.\nView API\nHorizon Detection\nDetermine the horizon angle in images.\nView API\nOptical Flow\nAnalyze the pattern of motion of objects between consecutive video frames.\nView API\nPerson Segmentation New\nProduce a matte image for a person in an image.\nView API\nDocument Detection New\nDetect rectangular regions in images that contain text.\nView API\nNatural Language\nAnalyze natural language text and deduce its language-specific metadata.\nView Natural Language framework\nTokenization\nEnumerate the words in text strings.\nView API\nLanguage Identification\nRecognize the language of bodies of text.\nView API\nNamed Entity Recognition\nUse a linguistic tagger to name entities in a string.\nView API\nPart of Speech Tagging\nClassify nouns, verbs, adjectives, and other parts of speech in a string.\nView API\nWord Embedding\nGet a vector representation for any word and find similarity between two words or nearest neighbors for a word.\nView API\nSentence Embedding\nGet a vector representation for any string and find similarity between two strings.\nView API\nSentiment Analysis\nScore text as positive, negative, or neutral based on the sentiment.\nView API\nSpeech\nTake advantage of speech recognition and saliency features for a variety of languages.\nView Speech framework\nSpeech Recognition\nRecognize and analyze speech in audio and get back data like transcripts.\nView API\nSound Analysis\nAnalyze audio and recognize it as a particular type, such as laughter or applause.\nView Sound Analysis framework\nSound Classification\nAnalyze sounds in audio using the built-in sound classifier or a custom Core ML sound classification model.\nView API"
  },
  {
    "objectID": "posts/b4935670-cff3-4424-8dc8-a81bc325826b/index.html",
    "href": "posts/b4935670-cff3-4424-8dc8-a81bc325826b/index.html",
    "title": "Document your code with AI, and use client-side compute resources",
    "section": "",
    "text": "Use tensorflow.js for the query and llm.\nUse precomputed vector space for searching.\nUse local storage for customization."
  },
  {
    "objectID": "posts/92ca2c5c-a049-4e28-a1b9-357e5c1c9b1b/index.html",
    "href": "posts/92ca2c5c-a049-4e28-a1b9-357e5c1c9b1b/index.html",
    "title": "Dynamic Classification System",
    "section": "",
    "text": "If present in current categories, choose a number.\notherwise, provide a name. number will be automatically assigned.\nretrieval based attention net\nregression test in stock market, which can also apply to bilibili"
  },
  {
    "objectID": "posts/70359678-6f6d-4a93-94d1-51bb02f4cc8e/index.html",
    "href": "posts/70359678-6f6d-4a93-94d1-51bb02f4cc8e/index.html",
    "title": "Emotion manipulation",
    "section": "",
    "text": "Predict emotion by means of graphics, motion, text, voice and swap context to achieve desirable effects.\nAdd random swap and funny pictures in addition to simple dictation.\nYou may group different kinds of content for specialized model training.\nSyncing is hard. With database, it’s not.\nAnalyze the conversation with emotional/keyword frequency indicator, do some feature extraction.\nAccelerate part of the video to be more expressive\nemotion recognization multi modal"
  },
  {
    "objectID": "posts/b44f882c-c640-464c-a6bf-14331cdf7fa9/index.html",
    "href": "posts/b44f882c-c640-464c-a6bf-14331cdf7fa9/index.html",
    "title": "Essay grading",
    "section": "",
    "text": "LSTM grading:\nhttps://github.com/yetianpro/automated-essay-grading-by-RNN\nessay scoring:\nhttps://github.com/mankadronit/Automated-Essay–Scoring\nNeural Essay Assessor:\nhttps://github.com/nusnlp/nea"
  },
  {
    "objectID": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html",
    "href": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html",
    "title": "Example Pydoc",
    "section": "",
    "text": "description: |\nAPI documentation for modules: example_docstring.\nlang: en\nclassoption: oneside\ngeometry: margin=1in\npapersize: a4\nlinkcolor: blue\nlinks-as-notes: true\n…"
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#video-highlights-extraction",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#video-highlights-extraction",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "video highlights extraction",
    "text": "video highlights extraction\nalthough you may want to train/extract that manually, it would sure be tedious and not self-updating (unless using reinforcement learning).\noften we determine highlights by sound, visual and voice together. highlights often can be identified without too much context, so it can be chunk based.\n\nbilibili\nb站的高能进度条 在油管被叫做”most replayed”\nb站有弹幕 所以可以根据弹幕找到精彩片段 VClimax是一个浏览器插件 可以通过弹幕单位时间增长速率，设置相关的阈值，来定位最精彩的内容 (弹幕密度怕还是得要分析) 跳转部分番剧OP 视频搞笑片段精准定位 (怕还得是要机器学习)\nbilibili Danmaku Skip is another browser plugin which will identify highlights by analyzing danmaku with parameters like threshold, interval and bias\n\n\nyoutube\nyoutube’s most played data can be extracted by:\nyoutube-heatmap (nodejs, using puppeteer (bad!))\nyoutube operational api’s (powered by shared API keys and info extractors without key), while apparantly youtube-most-replayed is using this service to retrieve the data from yt.lemonslife.com powered by this library\nheatmap extractor\nyoutube.js (reverse engineered innertube api) added support for chapters and video heatmap"
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#youtube-dl-search-youtube-video",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#youtube-dl-search-youtube-video",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "youtube-dl search youtube video",
    "text": "youtube-dl search youtube video\nyoutube-dl \"ytsearch[optional_result_limit]:[query]\"\n# pass query url directly to allow pagination or filters\nyoutube-dl \"https://www.youtube.com/results?search_query=how+to+create+android+app+in+android+studio&page=1\""
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#record-live-streaming-video-upload-video",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#record-live-streaming-video-upload-video",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "record live streaming video, upload video",
    "text": "record live streaming video, upload video\n\nbiliup & biliup-rs (commandline program)\n全自动录播、投稿工具，也支持twitch、ytb频道搬运。提供分p上传b站接口\n其实直播回放没有什么好看的 很单调 另外b站上传之后可以获得视频预测标签\n\n\nyoutube automation toolkit post same content to multiple platforms: bilibili, douyin, douyu, instagram, reddit, spotify, tiktok, twitch\nthough the idea is correct by posting original content to multiple platforms to prevent pirating, but the description/title generation is a vital part of the process, which must be done intelligibly (AI or human). as for now the repo is just full of links. if you want tools you click given link."
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#download-a-portion-of-video",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#download-a-portion-of-video",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "Download a portion of video",
    "text": "Download a portion of video\n\nyt-dlp (latest)\ncheck pyjom/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh for advanced usage of yt-dlp and more on bilibili parsing.\nSINCE YT-DLP IS UPDATED YOU CAN USE --download-sections ARGUMENT FOR YOUTUBE\nIf you want to download multiple sections of same video, you must specify video output format string via -o\nBut when using that without “–force-keyframes-at-cuts” (skip re-encoding which can speed up thing but not ensuring quality of video at tail), you better keep margin at tail for 10 seconds (could glitch at last 5 seconds) and head for 5 seconds (maybe head margin is not needed?).\n\n\nyoutube-dl\nfirst acquire download url: youtube-dl [--youtube-skip-dash-manifest] [-f 18] -g \"https://www.youtube.com/watch?v=V_f2QkBdbRI\" (you need to force the format.)\nthen use ffmpeg with the url to chop the slice: ffmpeg -ss 00:00:15.00 -i \"OUTPUT-OF-FIRST URL\" -t 00:00:10.00 -c copy out.mp4\n\n\nRangeDownloader by A-Soul-Database\nA-Soul-Database is a live-streaming replay record database designed for vtubers, organized in some way for easy information retrieval.\nRangeDownloader is acting like a server, though sometimes we are not sure how fast(er) it can really be."
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#viral-videos",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#viral-videos",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "Viral videos",
    "text": "Viral videos\n\nData sources and monitors\n\nRebang.today\n通过B站推荐标签接口可以得到观众的实时需求\n提供全站 知乎 微博 IT之家 百度 虎扑 直播吧 少数派 36氪 吾爱破解 天涯 小众软件 反斗限免 哔哩哔哩 抖音 技术期刊 v2ex GitHub的热榜\nAPI：https://api.rebang.today/v1/items?tab=&lt;TAB_NAME&gt;&page=&lt;PAGE_NUM&gt; (potential parameters: sub_tab, date_type (default:now))\n知乎有个专门的热榜，地址：https://www.zhihu.com/billboard\n知乎圆桌 知乎发现\n\n\n\nname\ntab\n\n\n\n\n全站热榜\ntop-all\n\n\n微博\nweibo\n\n\nV2EX\nv2ex\n\n\n知乎\nzhihu\n\n\n哔哩哔哩\nbilibili\n\n\nGitHub\ngithub\n\n\n抖音\ndouyin\n\n\n技术期刊\njournal-tech\n\n\n虎扑\nhupu\n\n\n少数派\nsspai\n\n\n百度\nbaidu\n\n\n36氪\n36kr\n\n\n天涯\ntianya\n\n\n吾爱破解\n52pojie\n\n\nIT之家\nithome\n\n\n全站24小时\ntop-daylong\n\n\n直播吧\nzhibo8\n\n\n小众软件\nappinn\n\n\n反斗限免\napprcn\n\n\n\n\n\n番茄数据\n番茄数据提供了从近24小时–近90天B站的最新热门视频，你既可以通过“搜索标题、简介、标签、评论出现关键词”，也可以通过行业分类、播放数、点赞数、投币数、视频时长、观众画像等高级条件，精准定位想要查找领域的热门视频。传播指数的计算方法有待研究。传播指数是根据UP主的粉丝数、视频点赞数、播放数、投币数、分析数等分析出来的综合得分。根据评论热词分析视频观众热点，根据评论用户分析用户画像。\n对于各大数据网站 都存在一个收录的接口 如果up主从来没有上过首页 大概率不会被收录 需要手动提交 间接说明大up主是如何被找到的\n\n\n\nImage recognizers\n\nBaidu Image recognizer 百度识图\n与此相关的识图项目位置：pyjom/tests/search_engine_suggestion_based_qa_bot\n可以获取关键字，标签，同样的图，秒懂百科视频，百度百科数据，包含图片的信息，颜值信息\n通过把上传接口修改 以及http改成https 现在可以继续使用\n位置：pyjom/tests/viral_video_experiments/BaiduSerchImgApi\n通过http改成https 修改好了360识图的接口\n位置：tests/viral_video_experiments/360ImageSearch\n\n\n\nVideo collectors\n\ntiktok compilation video generator\ncollect popular video on tiktok by multiple filters such as hashtags, categories , popularities and search queries\n\n\nWeiboSpider\n需要cookie 收集用户信息 用户粉丝列表 用户关注列表 微博采集 微博评论采集 微博转发采集 基于关键词的微博检索\n\n\nbotTuber: a instagram compilation reposter to youtube\nUsing instaloader and instalooter, it can download videos from instagram. It merges a series of video and add intro and outro. It only contains one default title starts with “TRY NOT TO LAUGH” in its “auto” mode.\n\n\nreddit hot videos to youtube\nIn “TiktokCringe” reddit channel, we are able to get hot posts and video links prefixed by https://v.redd.it (from tiktok to reddit) in json format: https://www.reddit.com/r/TikTokCringe/hot.json?limit=12. This link looks like some API or subscription. Maybe Bilibili and other sites have similar “hot” json urls. The way to extract video links is in atmt.sh. It adds transitions to every video clip.\n\n\n\nVideo editors\n\nvced\ni think it needs to be fine-tuned on large diversive training data.\nVCED 可以通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑。该项目基于跨模态搜索与向量检索技术搭建，通过前后端分离的模式，帮助你快速的接触新一代搜索技术。\n\n\nvideofy\nit is a self-hosted service, summarize article, get relevant text and image, determine mood to select BGM. try for yourself!\n\n\nmeme video maker\nIt uses google cloud to select “English” words on image, enable the user to edit the “stage” to show meme step by step.\nIt requires amazon cloud services and google cloud services.\n\n\n回声工坊 TRPG Replay Generator\nTRPG：桌上角色扮演游戏 有丢骰子（随机元素）的RPG\n角色立绘可以是动态的 但是是多个png文件\n背景可以设定为 {'black','white','greenscreen'} 中的一个，以建立纯色背景\nHas special requirements to media sources. Use .ogg format for BGM. Use .wav format for AFX and voices. Use .png for image. Cannot get background video layers working so you might consider some “green screen” effects.\nUse --ExportVideo flag to export video without GUI.\n\n\nopenshot and libopenshot (for python bindings)\nNightcorify is accelerating audio and raising pitch (asetrate strenches the timeline to change sample rate, atempo (not used in here) change the timeline but not the pitch, while aresample changes the sample rate but not timeline), also showing audio wave shape with showwaves.\nThis library is complex AND WITHOUT PROPER DOC FOR PYTHON thus not recommend for using\n\n\nkeybert and summarization transformer pipeline\nCheck docs on transformers pipelines for default and fine-tuned task-specific models for each pipeline.\nKeybert uses “sentence-transformers”. The author would advise either “all-MiniLM-L6-v2” for English documents or “paraphrase-multilingual-MiniLM-L12-v2” for multi-lingual documents or any other language. Search for “multi” with tag “summarization in huggingface, then you would get huge models. A mT5 model is very large, size upto 2.33GB\nKeywords-image pairs can be used for CLIP model training.\n\n\nwatson based video maker\nIt first downloads wikipedia content from algorithmia, then uses regex to filter out unwanted parts, uses watson AI for sentence cutting, set a limit for max sentences (notice: not summarization), then search image with keywords, finally create video.\nIn another similar project IMDB (Popular Film/TV series) and Google search trends (as RSS) are included.\n\n\nAuto-Editor\nBy passing --edit option, you can remove unwanted parts identified by motion or audio (can be combined). It can import clip with manual “cut-out”. It can export as json.\n\n\nPictory\nLeveraging 3 millions of tagged video clips and audio, choosing most semantically similar clip to current scene (by extracting keyword -&gt; search images -&gt; compare images to video sources with all embedding things going under the hood (CLIP)), map video word by word to the timeline (to create extractive highlights and remove unwanted words like “um”)\n\n\nWisecut\nShort videos can attract your viewers and converting them into followers (to view more of your long videos). Make short videos with music, subtitles and facial recognition auto-reframe (detect main speaker). It match the right BGM with the type of content, with audio ducking, which can be achieved with ffmpeg or editly.\nIt is listed among an AI marketing tools list, which mentions copywriting, social media/email/blog marketing text/content generation (like copy.ai), text to video\n\n\nJumpcutter\nAn audio-slience based video cutter. In jumpcut_file.py it chops audio into chunks and decide if it is slience or not. The core logic is to first compare max volume of each chunk against threshold, then check in neighbors of every chunk if all of them are slient and cut them out. It has audio speed changing methods from audiotsm.\nIn another implementation, it uses ring buffer by collections.deque and applies VAD (Voice Activity Detetion) by webrtcvad to every chunk of audio.\n\n\nGifcurry\nAdding text to video, has typing effects, written in haskell. You can add -m flag to export video instead of GIF.\n\n\nBackgroundremover\nA commandline tool powered by torch, removing background from images and video\n\n\nMoviepy most loved commandline video editor?\nThere are some cool text effects called “Text with moving letters” (PPT-like), and a dancing video generator based on tempo finder and video loop maker, which can help you adjust video speed according to video period and music bpm. The Star-Wars Text Effect reminds me of easing functions used with page scrolling.\n\n\n\nData collect/analyze\nSocial media statistics are time series data which should be collected regularly and predictable with time forcasting models.\n\nopen-sir\nUse sirx over sir.\nI think it is hard to use. Many “presumed” parameters are out there. It can fit “reproduction rate” but no individual “alpha” and “beta” values.\nIn tradirional SIR models, beta is infection rate, gamma is recovery rate. While in open-sir it is different. alpha now is beta, beta now is gamma.\n\n\nYoutube Viral Video Machine Learning Analysis\nRefer to this document for details in data collection and machine learning methods.\nUsage:\nYou can decide whether to copy a video or not when it is posted for only a few days.\nDataset creation:\nMonitoring video right at the time it is posted, monitor for a few days, calculate features, then wait for a month or two (it must stablize then), judge the video is viral or not by view counts.\nUsing multiple machine learning techniques, there are some top features matters the most for viral video forecasting (though you can derive your own by collecting more data (like the follower-view theory if applied), and beware if your video all sucks, you may not get an accurate model out of your data alone):\n\n\n\nRank\nFeature Name\nImportance\n\n\n\n\n1\nviews_acc\n12%\n\n\n2\nviews_1\n11%\n\n\n3\nageRatioReviews_1\n9%\n\n\n4\nvideo_duration\n9%\n\n\n5\ncomments_1\n5%\n\n\n6\nchannel_uploads\n5%\n\n\n7\nageRatioLikes_1\n4%\n\n\n8\ncomments_acc\n4%\n\n\n9\nchannel_views\n4%\n\n\n10\ncomments_sentiment_compound\n3%\n\n\n\n\n\nViralCaster\nTitleParser.py analyses views along with words, getting the most “popular” word or word combinations. It has demo data. It generates “max” “min” “mean” views related to single word or word combinations.\n\n\nPredictube\npeak_detection.py use daily view count to categorize and identify trends. “MonoIncr” might be our desired category.\n\n\nVideo Viralization Tool\nIt uses relative infection ratio instead of absolute to predict the trend. By “information cascade” it means statistics can be used to predict future view counts. It considers individuals and viewers as nodes. It suggests different relationships between parameters in SIR model and data (likes, shares, comments, new subscribers, subscribers, length, quality, tag keywords, description keywords)."
  },
  {
    "objectID": "posts/d36d0103-e7ec-4681-ae05-55c10b1d84a9/index.html",
    "href": "posts/d36d0103-e7ec-4681-ae05-55c10b1d84a9/index.html",
    "title": "Facial Expression Detector",
    "section": "",
    "text": "https://github.com/MauryaRitesh/Facial-Expression-Detection\nhttps://github.com/valterlucena/facial-expression-detector\ndeepface:\nhttps://github.com/serengil/deepface\ncnn based facial expression recognizer:\nhttps://github.com/WuJie1010/Facial-Expression-Recognition.Pytorch/issues\npredict human emotion:\nhttps://github.com/thoughtworksarts/EmoPy\nfacial expression recognization:\nhttps://github.com/phamquiluan/ResidualMaskingNetwork\nsmile detection using opencv:\nhttps://www.geeksforgeeks.org/python-smile-detection-using-opencv/"
  },
  {
    "objectID": "posts/7c991e15-4177-4afb-a3df-726e3a58317e/index.html",
    "href": "posts/7c991e15-4177-4afb-a3df-726e3a58317e/index.html",
    "title": "Free Mathematica Activation Method",
    "section": "",
    "text": "visit online activation code generator, which recommends a paid global internet service provider.\nfirst generate MathID using a free wolfram account, login through it.\nnext find the location of mathpass. follow the format and create a new line above all lines, with the obtained activation code.\nfor macos, we can find it here:\n/Users/&lt;userName&gt;/Library/WolframEngine/Licensing/mathpass\nfor linux:\n/root/.WolframEngine/Licensing/mathpass or something else."
  },
  {
    "objectID": "posts/4cbbac90-b140-4000-87fe-920853239932/index.html",
    "href": "posts/4cbbac90-b140-4000-87fe-920853239932/index.html",
    "title": "Mastering Frame Interpolation Techniques for Smooth Videos",
    "section": "",
    "text": "Frame Interpolation\nanime interpolation:\nhttps://github.com/lisiyao21/AnimeInterp\nnvidia unsupervised frame interpolation:\nhttps://github.com/NVIDIA/unsupervised-video-interpolation\nsmoother videos by frame interpolation:\nhttps://github.com/midnightripper/Video-Interpolation-for-creating-smoother-videos"
  },
  {
    "objectID": "posts/9e8ccd9c-86de-435d-8284-fc06d1da00a7/index.html",
    "href": "posts/9e8ccd9c-86de-435d-8284-fc06d1da00a7/index.html",
    "title": "Understanding the Psychology of Gaming and Its Impact on Community Formation",
    "section": "",
    "text": "Game Player’s Logic\n玩家玩游戏的逻辑\n“Looks like you are caring about me.”\nGaming starts from dissatisfactory of the reality. Be it loneliness, anger, tirement or stress.\n玩游戏都是有人引导玩的 都是因为别人玩 所以跟着玩的 固有的社交属性\n玩游戏和职业可能没多大关系\n跟着玩会形成流派 会在不同的区域分化 比如正版盗版 单机联机\n玩家自闭的因素 是因为游戏本身的复杂性 以及封闭性 重复性 玩家变得不想考虑外界的事情 只想关心游戏本身的事情\n可以把游戏相关的视频从外网搬到内网 把游戏视频搬运过来 也可以引用游戏元素 头像 吸引游戏玩家的流量 可以切分游戏剪辑视频 转化游戏攻略之类的视频和文案\nsound, visual effects, scripts\nClassic scenes picked from danmaku peaks."
  },
  {
    "objectID": "posts/b472fe36-c1ae-440c-b2dd-3a6b950d7dff/index.html",
    "href": "posts/b472fe36-c1ae-440c-b2dd-3a6b950d7dff/index.html",
    "title": "Github Bookmarks from James4deutschland",
    "section": "",
    "text": "Github Bookmarks from James4deutschland 2022/6/1\nconsider using proxy and vpn to do the capturing. mitmproxy and pcapdroid.\nfor accounts with cookies or credentials, you can use custom tool like gh_stars_export."
  },
  {
    "objectID": "posts/5732c2c3-ab92-48dd-a453-520ec0ce9495/index.html",
    "href": "posts/5732c2c3-ab92-48dd-a453-520ec0ce9495/index.html",
    "title": "Gooey: Argparse as GUI",
    "section": "",
    "text": "Directly convert commandline programs as GUI programs.\nThis goofy name “Gooey” is so strange that even ChatGPT and search engine like Bing have both failed to retrieve.\nYet we manage to recover it from our legacy codebase AGI/AutoUP/generator/transcribe by rg -g *.cmd pyinstaller36 and find . | rg time | rg tracker.\nIs this fate?\nIs this the end, or the new beginning?"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html",
    "title": "Hacking tutorials, tools",
    "section": "",
    "text": "别动不动就想日站 收集信息 熟悉工具 做好能做到的 把一路学到的经验总结下来\ntrufflehug find credentials from open sources\nstryker: wifi hacking tool includes dust attack, pin attack\nfound multiple websites on lonely planet tourist guide of america (all over the place!)\noneforall subdomain finder\nhack in one including:\nall defense tool: 半/全自动化利用工具, 信息收集工具, 漏洞利用工具, 内网渗透工具, 运维&甲方&防守方工具, 安全资料整理\nbotnet ips are detected by some websites like URLHaus. there’s a tendency to use common passwords to bruteforce the credential for such botnets, such as inori miral cnc scraper, l4tt/Botnet-Reaper. setting botnets by yourself has advantage of connecting to machines without public ip.\nMHDDoS best ddos tool (someone may make living on that), providing multiple WAF bypass techniques (what about Akamai?)\nalthough sqlmap is somehow out-of-date (wracked by WAF, unable to exploit latest nodedb library), there is a tendency to combine subdirectory/url collector like subfinder with it like codewatchorg/sqlipy and zt2/sqli-hunter, automate the exploitation. search for sql injection (deep/machine learning) in github for latest tools and wiki.\nundetectable credential stealer created by psauxxx. is it coincidence?\npsauxx (twitter) created multiple accounts on github. the original one （in archive) is deactivated, now named as l4tt. vulnnr (auto exploiter) has some tutorials from geekforgeeks and xploitlab (linked to other interesting tools), and is renamed as uscan. search for vulnnr in github and there is a favourite hack tool collection\nsocialfish clone website and collect credentials (phishing) with web controller interfaces\nsploitus search for latest sploits and POC-code (usually after patching is done)\nbearSG 符合国人习惯的社工密码生成器 java开发 自带GUI\ncupper 社工密码生成器\n社会工程工具列表 是security list的一部分 其中推荐独立开发者怎么赚钱 (有免费API接口介绍 但是有的站已经没了) -&gt; 国内独立开发者项目列表 -&gt; bufpay 免签支付 (需要按月交费)\n内容包括：\nmosint email osint\npayloadallthethings (40k stars!) by swisskyrepo\nopenai written phishing and directory bruteforcing\nghunt google osint\nscarecrow payload generator targeting win 10-11\nscarecrow cobalt strike plugin\ncryptographic related python libraries gmpy2 pycryptodome libnum yafu rsa-wiener-attack RsaCtfTool\nciphery auto decryption\npwntools used by fmyy and more doc\nangr to reverse engineer binaries, mostly in ctf? docs\nangr ctf use cases: case 1 case 2\nangr ctf reverse binaries and print “good job”\nangr ctf build binaries from source\ndefcon ctf quals 2021 ooo\nfactordb.com find prime numbers, decomposition for rsa\nreverse shell generator while shellcode cannot have null bytes, you need to xor your things with tool or assembly.\n挖0day 或者利用现成漏洞 fuzzers for kali\nkali tools\nblackarch tools\nall in one hacking tool\nvillainbackdoorgenerator\ndon’t aim big, aim small. things like bilibili password database dump, or some Intel internal data leak, are done by professional hackers on professional hardware. some corp will even attempt to retaliate like nvidia. you have been warned.\nTo exploit zerodays, you need rasp, aka ‘is my application doing something undefined/unexpected?’\n利用公共WiFi 比如用WiFi炮连接远处的WiFi 控制云端的攻击服务器\n黑客第一步是找目标 （CTF可能不会教你怎么找目标 白帽也不会 因为目标很单一）不管漏洞存不存在 目标究竟是个啥目标 是人（联系方式？）还是机器（URL？）还是AI （验证码？）怎么交互（可能）是什么漏洞 以及采取什么攻击措施 都得先把目标罗列清楚 可以借助搜索引擎 fofa漏洞搜索 邮箱信息 社交软件的信息 木马跟踪他人的信息 大多数人访问的信息 爬虫信息 监控本地软件访问网络的记录 或者直接随便扫描 存到数据库里面\n第二步就是交互 利用漏洞 装后门 控制目标 比如挖矿 继续收集网站信息 密码信息 cookies 继续散播病毒 拓展攻击面\n第三步持久作战 持续提高反侦查意识 学习收集信息工具 提高黑客能力 利用各种方法 比如社会工程学 利用匿名账号或者免费邮箱账号 传播带木马的免费应用程序 病毒邮件 坚持就是胜利\nhttps://github.com/mikaelkall/HackingAllTheThings\nhttps://github.com/akenofu/HackAllTheThings\nmemory editing, game hacking:\nhttps://github.com/qb-0/pyMeow\nhttps://github.com/srounet/Pymem\nmirai botnet\ndefcon for news, intro, wiki\ninfocon for software, code, wordlists\nmec mass exploiting"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#notes",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#notes",
    "title": "Hacking tutorials, tools",
    "section": "notes",
    "text": "notes\npc微信hook 获取二维码\npc微信逆向\n几个觉得还不错的靶场\n封神台：https://hack.zkaq.cn/index\nHack The Box ：https://www.hackthebox.com/\nhtb邀请码获取方法：https://www.mad-coding.cn/2019/11/11/hackthebox%E5%88%9D%E6%8E%A2%E4%B9%8B%E8%8E%B7%E5%8F%96%E9%82%80%E8%AF%B7%E7%A0%81/#0x00-%E5%89%8D%E8%A8%80\nVulhub：https://www.vulnhub.com/\nPikachu：https://github.com/zhuifengshaonianhanlu/pikachu"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#search-engines",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#search-engines",
    "title": "Hacking tutorials, tools",
    "section": "search engines",
    "text": "search engines\nyoucode search engine for coders, enter coding question to get result\nself-hosted recon intelligence tool: osint\nivre network recon framework\npublicwww: search for html/css/js source code in website\nsearchpedia: search engine collection\ntop 5 recon/intelligence/information gathering tools\nsearch engine hacking, manual and automation\nbest hacker search engines"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#scripting",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#scripting",
    "title": "Hacking tutorials, tools",
    "section": "scripting",
    "text": "scripting\nwriting nmap scripts"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#information-gathering",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#information-gathering",
    "title": "Hacking tutorials, tools",
    "section": "information gathering",
    "text": "information gathering\nuncover quickly discover hosts using multiple search engines\ndirsearch scan web paths\npip3 install dirsearch"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#virus-botnet",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#virus-botnet",
    "title": "Hacking tutorials, tools",
    "section": "virus, botnet",
    "text": "virus, botnet\nbotnet with super escalation system for linux and windows, automatically spread the virus out\nwebshell 免杀"
  },
  {
    "objectID": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#hacking-tutorials",
    "href": "posts/5308c6ac-2dff-4cb8-8426-e77414f7206a/index.html#hacking-tutorials",
    "title": "Hacking tutorials, tools",
    "section": "Hacking tutorials",
    "text": "Hacking tutorials\nmaybe you should follow kali/parrot/blackarch tutorials first?\n暗网 社工库 数据库 暗网黑客教学\n暗网自由社区，中文社区，无下限讨论\nzuw2gvomnfx5mt6g626srambeqo2yxmac5jpoccttq54z7se36svmlyd.onion\nthe payload, dedicated tutorial\nhttps://github.com/swisskyrepo/PayloadsAllTheThings\nsure it needs everything to hack. the assembly, the tools, the experience, the examples, the automation, the persistence, the vision.\nall in one hack tool:\nhttps://github.com/Z4nzu/hackingtool\nawesome hacking:\nhttps://github.com/Hack-with-Github/Awesome-Hacking\nhacking tutorials and tools:\nhttps://github.com/carpedm20/awesome-hacking\nhttps://github.com/sundowndev/hacker-roadmap\nhttps://github.com/jekil/awesome-hacking\nhttps://github.com/carlospolop/hacktrick\nctf tutorials and tools:\nhttps://github.com/xtiankisutsa/awesome-mobile-CTF\nhttps://github.com/Naetw/CTF-pwn-tips\nhttps://github.com/firmianay/CTF-All-In-One\nhttps://github.com/taviso/ctftool\nhttps://github.com/UnaPibaGeek/ctfr\nhttps://github.com/RsaCtfTool/RsaCtfTool\nhttps://github.com/Gallopsled/pwntools\nhttps://github.com/0Chencc/CTFCrackTools\nhttps://github.com/google/google-ctf\nhttps://github.com/ctf-wiki/ctf-wiki\nhttps://github.com/apsdehal/awesome-ctf\nhttps://github.com/p4-team/ctf\nhttps://github.com/zardus/ctf-tools\nsome other tools and resources\nhttps://github.com/jopohl/urh\nhttps://github.com/sundowndev/hacker-roadmap\nall in one hacking tool for kali linux\nhttps://github.com/edoardottt/awesome-hacker-search-engines\nhacker pro hacktool for termux and linux, maybe macos?\nsql/xxs scanner, dos, bruteforce ftp/ssh/mail accounts\nhttps://github.com/hacktoolspack/hack-tools\nhttps://github.com/hahwul/WebHackersWeapons\nhttps://github.com/jekil/awesome-hacking"
  },
  {
    "objectID": "posts/7e6cd8d4-de5b-42bb-ac5f-260b46f75fdb/index.html",
    "href": "posts/7e6cd8d4-de5b-42bb-ac5f-260b46f75fdb/index.html",
    "title": "Hardware for fun moment capturing",
    "section": "",
    "text": "A head-mounted coaxis camera, coaxis long-range microphone, buffered record mode, two separate buttons for recording and saving, implementation in micropython. large battery."
  },
  {
    "objectID": "posts/0fb411cf-42af-414a-b2b7-c241324fb04d/index.html",
    "href": "posts/0fb411cf-42af-414a-b2b7-c241324fb04d/index.html",
    "title": "Hide magisk",
    "section": "",
    "text": "You need to update to latest magisk by patching the unmodified kernel and install shizuku\nenable whitelist mode"
  },
  {
    "objectID": "posts/721860b5-8e63-4b39-bc58-e6074b4ddad9/index.html#code-refactoring-tools",
    "href": "posts/721860b5-8e63-4b39-bc58-e6074b4ddad9/index.html#code-refactoring-tools",
    "title": "Hot Reloading, Exception Capture",
    "section": "code refactoring tools",
    "text": "code refactoring tools"
  },
  {
    "objectID": "posts/721860b5-8e63-4b39-bc58-e6074b4ddad9/index.html#hot-reloading-and-exception-capture-tools",
    "href": "posts/721860b5-8e63-4b39-bc58-e6074b4ddad9/index.html#hot-reloading-and-exception-capture-tools",
    "title": "Hot Reloading, Exception Capture",
    "section": "hot reloading and exception capture tools",
    "text": "hot reloading and exception capture tools\nreloading Change Python code while it’s running without losing state\njurigged Hot reloading for Python\nDebugPy can capture every exception at the time it is raised and preserve state (but cannot instruct the frame to continue execution without exception), no matter it is wrapped around some ‘try-except’ or not.\nReloadium requires breakpoints to reload scripts. However, breakpoints can be generated/inferenced and removed at runtime. Currently it only works with pydevd inside pycharm. Reloadium supports line-wise profiling.\nDebug Adapter Protocol\nDAP client in neovim\nDAP client in python\nOfficial DAP client reference\npydevd_reload An enhanced hot reload module from PyDev"
  },
  {
    "objectID": "posts/749697d9-e205-4f4d-9733-3c7de07ee228/index.html",
    "href": "posts/749697d9-e205-4f4d-9733-3c7de07ee228/index.html",
    "title": "How to fix OpenCL platform not found issue on android",
    "section": "",
    "text": "To run llama.cpp on Oneplus Ace2V, you need an extra step:\nexport LD_LIBRARY_PATH=/vendor/lib64:/vendor/lib64/mt6983:/vendor/lib64/egl/mt6983"
  },
  {
    "objectID": "posts/1a72366a-bea2-4321-bc39-b127110a423a/index.html",
    "href": "posts/1a72366a-bea2-4321-bc39-b127110a423a/index.html",
    "title": "IM MITM 聊天软件MITM",
    "section": "",
    "text": "IM MITM 聊天软件 MITM\nbetter do this in virtual enviorment without using any real world platform, just your own IM enviorment like a self-hosted IRC or something.\nis there any existing solution like telegram-mitm or twitter mitm?\nlua twitter automation, found on luarocks:\nhttps://github.com/leafo/lua-twitter\nscraper of tumblr, pinterest, youtube, reddit using api:\nhttps://github.com/ScriptSmith/socialreaper\nyoutube search and youtube comment scraper\nhttps://github.com/alexmercerind/youtube-search-python\nhttps://github.com/egbertbouman/youtube-comment-downloader\nyoutube, youtube transcribe and youtube music api\nhttps://github.com/srcecde/python-youtube-api\nhttps://github.com/sigma67/ytmusicapi\nhttps://github.com/jdepoix/youtube-transcript-api\nhttps://github.com/youtube/api-samples\nreddit scraper and analyzer\nhttps://github.com/casperbh96/Web-Scraping-Reddit\nhttps://github.com/umitkaanusta/reddit-detective\nreddit api\nhttps://github.com/praw-dev/praw\ntumblr api\nhttps://github.com/tumblr/pytumblr\ntumblr scraper\nhttps://github.com/henan715/tumblrScrapy\ndiscord bot api:\nhttps://github.com/discordjs/discord.js\ntwitter api\nhttps://github.com/python-twitter-tools/twitter\ntwitter scraper\nhttps://github.com/bisguzar/twitter-scraper\nfacebook api:\nhttps://github.com/Schmavery/facebook-chat-api\nfacebook scraper:\nhttps://github.com/kevinzg/facebook-scraper\ninstagram api:\nhttps://github.com/facebookarchive/python-instagram\ninstagram scraper:\nhttps://github.com/huaying/instagram-crawler\ntopic analysis among recent frequent conversations\nprocedures:\n1.add two friends (active) and bridge them\n2.intercept them, filter insecure data like screenshots, identities and explicit contents, and analyze needs (probably with your generated response)?\n3.send intentional Ads and fix the conversation in three sentences."
  },
  {
    "objectID": "posts/5a8dccef-f90c-4c30-9cf3-f1fce1c28cb2/index.html",
    "href": "posts/5a8dccef-f90c-4c30-9cf3-f1fce1c28cb2/index.html",
    "title": "IOS airtest control windows",
    "section": "",
    "text": "need macos to compile ipa\nneed jailbreak\niOS Tagent\nhttps://github.com/alibaba/taobao-iphone-device\napowermirror"
  },
  {
    "objectID": "posts/7b23fe43-2d0f-44ae-9480-f20fdaaf3a2f/index.html",
    "href": "posts/7b23fe43-2d0f-44ae-9480-f20fdaaf3a2f/index.html",
    "title": "Image classification, cloth Classification",
    "section": "",
    "text": "vit-pytorch state of the art image classifier with multiple attention heads\nfeed forward neural network"
  },
  {
    "objectID": "posts/d1476999-3bfd-48f1-8e45-24745953e175/index.html",
    "href": "posts/d1476999-3bfd-48f1-8e45-24745953e175/index.html",
    "title": "Install VSCode Extensions by ID",
    "section": "",
    "text": "@id:medialang.vscode-theme-medialang-seti\n＠id:medialang.medialang-highlighter"
  },
  {
    "objectID": "posts/e8eda011-98c6-40c5-ae98-5a46bec3d0db/index.html",
    "href": "posts/e8eda011-98c6-40c5-ae98-5a46bec3d0db/index.html",
    "title": "Issues while developing pyjom",
    "section": "",
    "text": "fix requests timeout problem.\nenable bilibili chats, video recommendation, dynamics\nenable weibo\nvideo feedback, monitor viral trends\nimprove chatbot by adding chatterbot, bm25, search engine, picture search engine\nyou may use this to fully utilize data from baidu shitu:\nhttps://github.com/Augu1sto/Rubindemo/blob/0ffe52af74643db8d8bfae048ee256824836e277/src/main/java/com/rubin/demo/Utils/BaiduSerchImgApi-master/functions.py\nhttps://github.com/chenguanyou/BaiduSerchImgApi\nhttps://github.com/chenguanyou/360ImageSearch\nhttps://github.com/chenguanyou/BaiduTextApi\nshitu.baidu.com\nhttps://graph.baidu.com/pcpage/index?tpl_from=pc (the entry page)\ngraph.baidu.com/s (where you collect data, recognize identities: script -&gt; window.cardData (list) -&gt; “tplData” -&gt; “pano” “baike” shits … with title “百度识图搜索结果”)\ngraph.baidu.com/ajax/pcsimi (get similar images, sources)\nhttps://miao.baidu.com/abdr (UNKNOWN)\nclasses:\ngraph-guess-word\ngraph-baike-text\ngraph-baike-desc -&gt; span"
  },
  {
    "objectID": "posts/8319a62a-3336-4a1a-a3d5-33c9971c96df/index.html",
    "href": "posts/8319a62a-3336-4a1a-a3d5-33c9971c96df/index.html",
    "title": "Jina: Neural Search Engine for Images, Videos, Audios",
    "section": "",
    "text": "openclip\nhaystack\ntutorial: build QA pipeline with no dependencies with haystack\ntowhee\nmilvus\nvisit jina hub to get multiple embedding models and workflows\njina import video/image/text\nfinetuner: text to image search via clip\ndatawhale provides tutorials on machine learning, also provide book materials, topics are: numpy, matplotlib, pandas,\nvced: holy gift from datawhale able to edit video by text, video auto editor, cutter\nVCED 可以通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑。该项目基于跨模态搜索与向量检索技术搭建，通过前后端分离的模式，帮助你快速的接触新一代搜索技术。\njina:\nhttps://github.com/jina-ai/jina/\ndocumentation:\nhttps://docs.jina.ai\nquick demos:\ndress Fashion image search: jina hello fashion\nrobot QA chatbot: pip install “jina[demo]” && jina hello chatbot\nnewspaper Multimodal search: pip install “jina[demo]” && jina hello multimodal\nfork_and_knife Fork the source of a demo to your folder: jina hello fork fashion ../my-proj/\nCreate a new Jina project: jina new hello-jina\nai video metadata generation:"
  },
  {
    "objectID": "posts/7ad310b3-173c-403a-966c-5be35e0f4106/index.html",
    "href": "posts/7ad310b3-173c-403a-966c-5be35e0f4106/index.html",
    "title": "Kafka Data Query",
    "section": "",
    "text": "2056500129@qq.com\n大数据存储综合实验\nConnection:\nEasyConnect\nhttps://newvpn.cumt.edu.cn\n08192963:186880\nVM:\nhttp://192.168.46.253:8080/training/\n08192963:888888\n下载高速公路ETC入深圳数据， 数据量:178396条\nhttps://opendata.sz.gov.cn/data/dataSet/toDataDetails/29200_00403621\n数据样例:\n要求\n(1)每秒产生50+条数据，可以采用网络压力测试工具产生多点并发的高速数据流\nhttps://blog.csdn.net/moonpure/article/details/72674374\n，例如JMeter\n(2)利用Kafka对高速数据进行缓存\n(3)利用HBase或者MyCat+Mysql对数据进行存储。\n(4)如果采用MyCat+Mysql方式存储数据，需要设计业务逻辑对数据进行分片，并对全局数据进行查询和统计\n(5)如果采用HBase方式存储数据，需要设计业务逻辑对rowkey进行设计，并对数据进行“key-value”查询。\n(6)对两种方式查询或者统计的结果进行可视化展示，要求每分钟一次对结果进行刷新。\nReport Template:\n7.实验目标和实验环境\n8.实验内容，\n9.实验步骤和结果。\n.10.结论与讨论。\nPython Kafka\nhttps://blog.csdn.net/weixin_35688430/article/details/111292744\nThrift Hbase\nhttps://blog.csdn.net/dutsoft/article/details/60328341\nPython Hbase\nhttps://www.jianshu.com/p/58b79bf5e9d4\nTerminal Visulization\nhttps://stackoverflow.com/questions/37288421/how-to-plot-a-chart-in-the-terminal\nhttps://pythonawesome.com/a-python-file-with-some-tools-for-visualizing-machine-learning-in-the-terminal/"
  },
  {
    "objectID": "posts/9db1c565-9e79-4d67-a377-e5ddea7ced05/index.html",
    "href": "posts/9db1c565-9e79-4d67-a377-e5ddea7ced05/index.html",
    "title": "Letsketch libwacom",
    "section": "",
    "text": "working on archlinux arm:\nlibwacom 2.1.0-1\nnot working on kali linux:\nlibwacom-bin 2.2.0-1\nfull reference:\nhttps://github.com/DIGImend/digimend-kernel-drivers/issues/514\nsudo nano /etc/X11/xorg.conf\nSection “InputClass”\nIdentifier “Tablet”\nDriver “wacom”\nMatchDevicePath “/dev/input/event*”\nMatchUSBID “6161:4d15”\nEndSection\nto debug input problems:\nhttps://wiki.ubuntu.com/DebuggingMouseDetection#:~:text=In%20case%20your%20mouse%20stops%20working%20after%20a,your%20mouse%20stops%20working.%20…%20More%20items…%20\ncheck /etc/logs/Xorg.0.logs"
  },
  {
    "objectID": "posts/49eefdbd-a655-4f6d-90a8-f42358059b3f/index.html",
    "href": "posts/49eefdbd-a655-4f6d-90a8-f42358059b3f/index.html",
    "title": "Live Share Plugin, Clipboard syncing, peer programming, collaboration, multi-user editing",
    "section": "",
    "text": "live share will always create a invitation link upon starting, so you can use clipboard listener based on event listeners or pyperclip (repeatedly checking content in clipboard, see if there’s any change), save the link to server or send via email.\n\nif clipboard is not your thing, there’s a massive anyIM-to-Matrix list\nyou can also setup your own sync app via instant messaging services.\n\nclipboard sync:\ncrossclip: Sync clipboard across macOS/Linux/Windows on LAN\nClipBroad: Sync via Github\n\nclipboard listeners:\nclipnotify for xorg (linux)\nwindows+v now act as multi-clipboard\nyou can sync clipboard across computers via crossclip\n\nmicrosoft liveshare\nduckly\ncodeshare alternatives"
  },
  {
    "objectID": "posts/2a69a080-7a45-4b12-aca1-b81c0fd1737c/index.html",
    "href": "posts/2a69a080-7a45-4b12-aca1-b81c0fd1737c/index.html",
    "title": "Linux Fan Not Spinning, GPU Fan Not Spinning",
    "section": "",
    "text": "everytime the fucking machine restarts, it fails devastatingly.\nthe word: Giving the fans some time to reach full speed...\nthe script:\n#!/usr/bin/expect\nspawn pwmconfig\n#expect \"Giving the fans some time to reach full speed...\"\nexpect \"If you do not want to do this hit control-C now!!!\"\nsend \"\\03\"\nexpect eof\nhope this shit works?\necho 255 | sudo tee /sys/class/hwmon/hwmon6/pwm3\necho 255 | sudo tee /sys/class/hwmon/hwmon6/pwm1\ni have install something other than that. like i8kctl, some thermal controllers by intel (thermald)? but still gpu fan not spinning till now.\napt install -y lm-sensors fancontrol\nsensors-detect\npwmconfig\nalready have cpu frequency under control by running temp_throttle.sh\nnotes: found controllers dell_smm-isa-0000\nFound the following PWM controls:\nhwmon6/pwm1           current value: 255\nhwmon6/pwm3           current value: 255"
  },
  {
    "objectID": "posts/de8976f9-67d5-40cb-a445-e277a0238c47/index.html",
    "href": "posts/de8976f9-67d5-40cb-a445-e277a0238c47/index.html",
    "title": "Logic Optimizer for Different Models",
    "section": "",
    "text": "currently we can use hyperopt as the online optimizer. of course for offline optimization there’s better option or prediction for it.\nFor a sequence of models, use classic logic solver to find best logic combination.\nselect model 0.\nselect model 1 with 0, iterate through 16 different situations(0, not 0, 1, not 1, 0 and 1, 0 or 1, 0 and not 1, 0 or not 1, not 0 and 1,not 0 or 1, not 0 and not 1, not 0 or not 1), choose the best one. mark it as model A.\nselect model 2, use the same optimizer to generate model B.\nfinally iterate through all models. generte model X as a combination of best logic models."
  },
  {
    "objectID": "posts/72d65a7d-5c77-44d9-9e51-77796f0f25c8/index.html",
    "href": "posts/72d65a7d-5c77-44d9-9e51-77796f0f25c8/index.html",
    "title": "MMDetection and MMD dancing",
    "section": "",
    "text": "3d 虚拟形象动作生成 视频生成 虚拟偶像 Vtuber:\nhttps://github.com/xianfei/SysMocap\nhuman pose detection:\nhttps://github.com/facebookresearch/VideoPose3D\nopengl recording:\nhttps://lencerf.github.io/post/2019-09-21-save-the-opengl-rendering-to-image-file/\nhttp://www.songho.ca/opengl/gl_pbo.html#pack\nhttps://stackoverflow.com/questions/7634966/save-opengl-rendering-to-video\nhttps://www.codeproject.com/articles/15941/recording-directx-and-opengl-rendered-animations\nhttps://www.glfw.org/documentation.html\ndownload expose models:\nhttps://expose.is.tue.mpg.de/downloads\nsmpl-x model download:\nhttps://smpl-x.is.tue.mpg.de/download.php\nmodel zoo:\nhttps://github.com/Zhongdao/Towards-Realtime-MOT/blob/master/DATASET_ZOO.md\nmmd auto tracking:\nhttps://github.com/errno-mmd/mmdmatic/blob/master/setup.bat\nhttps://github.com/miu200521358/expose_mmd\nhttps://github.com/miu200521358/AlphaPose-MMD\nsmplx expose alternative body tracker:\nhttps://github.com/vchoutas/smplx\nface tracking:\nhttps://github.com/Aditya-Khadilkar/Face-tracking-with-Anime-characters\nanime face detector:\nhttps://github.com/nagadomi/lbpcascade_animeface\nhttps://github.com/qhgz2013/anime-face-detector\nanime facial features:\nhttps://github.com/pranau97/anime-detection\nrepair anime images:\nhttps://github.com/youyuge34/Anime-InPainting\npaint manga from sketch (with color blocks):\nhttps://github.com/youyuge34/PI-REC\nif we can re-trace the action/expression done by vtubers, we can monetize those “highlight cuts”.\nyou can firstly find points in datasets and then generate mmd videos, and then create trainset. you can also generate pose from raw video and then create dataset.\nfound occasionally when browsing MMD, but found this with so many stars, which is an instance detection/segmentation library.\nhttps://github.com/open-mmlab/mmdetection\nwhile rendering mmd can be done with mmd viewer like https://github.com/benikabocha/saba or could use renderer like blender or unity. we must bake physics before dancing.\nfound other dedicated renderer for mmd, with bullet physics:\nhttps://github.com/jinfagang/mmc\nfound interesting repo of poetry composing:\nhttps://github.com/jinfagang/tensorflow_poems\nmediapipe/paddlevideo alike:\nhttps://pypi.org/project/alfred-py/\nthree.js has multiple loaders:\nhttps://github.com/mrdoob/three.js/tree/dev/examples/js/loaders\nhttps://github.com/hanakla/three-mmd-loader\nrender MMD using saba lib:\nhttps://github.com/WLiangJun/MMD-Desktop-mascot\nhttps://github.com/miu200521358/expose_mmd/fork\nmusic based dance:\nhttps://github.com/DeepVTuber/DanceNet3D\nhttps://github.com/ColbyZhuang/music2dance_DanceNet\nhttps://github.com/caijianfei/Music2Dance\ncharacters:\nhttps://www.mixamo.com/#/?page=1&type=Character"
  },
  {
    "objectID": "posts/7cced77f-4557-4aa5-83ea-1cad52d9a7d5/index.html",
    "href": "posts/7cced77f-4557-4aa5-83ea-1cad52d9a7d5/index.html",
    "title": "Macbook M1 create macOS recovery usb",
    "section": "",
    "text": "Macbook M1 create macOS recovery usb"
  },
  {
    "objectID": "posts/ff3a193e-2268-4e31-ba99-c4ea78afc277/index.html",
    "href": "posts/ff3a193e-2268-4e31-ba99-c4ea78afc277/index.html",
    "title": "Media repurpose tool",
    "section": "",
    "text": "Consider recording the media before real-time processing.\nScan the object via taobao streaming and make it dance.\nTransplant lolita pictures to bilibili.\nShare dialogs/info from soul/qq/wechat.\nRepurpose a wide range of streaming platforms.\nuse ocr to filter out text info\nfind new title from danmaku or comments\n我们都知道，视频主要由画面和音频组成。但还有一个元素同样包含了巨大的信息量 —— 字幕。结合现有的自然语言处理模型，我们便能实现对话抽取式的自动剪辑。PS: 软件图标是我妹妹Hannah设计滴~\n项目开源地址：https://github.com/COLOR-SKY/DialogueExtractor\n学业之余我会陆续更新工具教程。"
  },
  {
    "objectID": "posts/642eafcf-2ef6-41aa-b886-004e2c098412/index.html",
    "href": "posts/642eafcf-2ef6-41aa-b886-004e2c098412/index.html",
    "title": "Mindmap",
    "section": "",
    "text": "需求：对目前做出来的共现网络图谱进行社区划分，使用简单的谱聚类方法就行，要求能看出来图谱热点被区分开，最后的结果通过图谱的形式展示。"
  },
  {
    "objectID": "posts/b8224b7d-765f-4b04-bb1b-04f8d4cbc171/index.html",
    "href": "posts/b8224b7d-765f-4b04-bb1b-04f8d4cbc171/index.html",
    "title": "Model Zoo",
    "section": "",
    "text": "find things in colab, kaggle, aistudio, bilibili, youtube.\nsee in huggingface tasks to find task-specific models, also huggingface spaces for demo on models\nmodelscope by alibaba supports tensorflow and pytorch\nmindspore model zoo\nmindspore hub\nintel model zoo\nrun models from intel model zoo in docker container, like recommendation\nopenvino model zoo\n百度总结的 比较全面的深度学习应用 deeplearning applications\njina hub\n阿里巴巴模型库 具有许多适用于商业 自媒体的模型供选择\nhuggingface\n苹果官方CoreML模型库\nCoreML第三方模型库\npaddle模型库 paddlehub\npytorch模型库\nTensorFlow模型库\ngraphcore model zoo for IPU"
  },
  {
    "objectID": "posts/a7b86385-aacc-457f-934f-964e6c17c191/index.html",
    "href": "posts/a7b86385-aacc-457f-934f-964e6c17c191/index.html",
    "title": "Movie Bangume script finder",
    "section": "",
    "text": "https://wk.baidu.com/view/329daafdbaf3f90f76c66137ee06eff9aef84994\nhttp://www.360doc.cn/mip/982055971.html\nanime character database contains dialogs:\nhttps://www.animecharactersdatabase.com/episodetranscript.php?pid=1915&epid=1\nquodb the movie quotes database:\nhttps://www.quodb.com\nscifi movie script example:\nhttp://www.scifiscripts.com/cartoon/howls_moving_castle.html\njapanese bangume script:\nhttp://akita.cool.ne.jp/hikoseki/script/laputascript_v210all_n.html\nMay not work:\nhttps://jref.com/threads/where-in-internet-could-i-find-anime-dialogs-scripts-in-japanese.43408/\nsuggest you find this in zhihu.\nhttps://dialogue.moe\nhttps://zhuanlan.zhihu.com/p/389873370\nhttps://zhuanlan.zhihu.com/p/450050772\nfind movie quotes:\n33.agilestudio.cn\nhttps://zhaotaici.cn/mindex.html\nBangume info wiki:\nhttps://bgm.tv/subject/1982/characters"
  },
  {
    "objectID": "posts/be355397-bcc9-4a7d-8621-dfd545521633/index.html",
    "href": "posts/be355397-bcc9-4a7d-8621-dfd545521633/index.html",
    "title": "Movie Scraping 3",
    "section": "",
    "text": "https://www.dianyinggou.com\nwith douban link"
  },
  {
    "objectID": "posts/27207c26-0f95-4d13-b6fe-b8d7f01f30fb/index.html",
    "href": "posts/27207c26-0f95-4d13-b6fe-b8d7f01f30fb/index.html",
    "title": "Music to video generator GAN",
    "section": "",
    "text": "Text to Video/Music to video generator GAN\nhttps://www.youtube.com/watch?v=V8MlYa_yhF0\nhttps://netease-gameai.github.io/ChoreoMaster/Paper.pdf\n该系统可依据音乐风格生成爵士、二次元、街舞等不同类型的舞蹈动画。给定一段音乐，舞蹈演员可以自动生成高质量的舞蹈动作序列以伴随输入音乐的风格、节奏和结构。为了实现这一目标，我们引入了一种新的面向编舞的编舞音乐嵌入框架，它成功地构建了一个统一的舞蹈音乐嵌入空间音乐和舞蹈短语之间的风格和节奏关系。\nhttps://www.youtube.com/watch?v=VrVsAcgFK_4\n该方法提出了一个基于cross-modal transformer的架构模型和一个新的3D舞蹈数据集，该数据集包含了根据真实舞者重建的3D运动\n项目地址: https://google.github.io/aichoreographer\n数据集地址: https://google.github.io/aistplusplus_dataset/\n欢迎点赞、评论、分享、收藏！\nvideo generation using music based on bigGAN:\nhttps://github.com/Remideza/MichelAI/\nbigGAN Large Scale GAN Training for High Fidelity Natural Image Synthesis:\nhttps://github.com/ajbrock/BigGAN-PyTorch\ndance video generation self-supervised:\nhttps://github.com/xrenaa/Music-Dance-Video-Synthesis\nshow me what and tell me how based on openai clip by snap research with pretrained models, able to generate arbitrary video based on text description:\nhttps://github.com/snap-research/MMVID\ntext to video generator based on vqgan and clip with primitive colab notebooks by kapwing the online video editor:\nhttps://www.kapwing.com/ai-video-generator"
  },
  {
    "objectID": "posts/8a652ecb-7ffd-4f52-9e41-b206349a2a41/index.html",
    "href": "posts/8a652ecb-7ffd-4f52-9e41-b206349a2a41/index.html",
    "title": "MySQL Cheatsheet",
    "section": "",
    "text": "MySQL Reference Card\nVersion: 0.1\nAuthor: ProgM4c\nAttribute Types\nNumbers\nName\nCoded on\nName\nCoded on\nTINYINT\n1 byte\nFLOAT(W, D)\n4 bytes\nSMALLINT\n2 bytes\nDOUBLE(W, D)\n8 bytes\nMEDIUMINT\n3 bytes\nW: width(number of digits with the ‘.’)\nD: number of decimals\nINT\n4 bytes\nBIGINT\n8 bytes\nParameters:\n• UNSIGNED\n• ZEROFILL\nCoded on:\n• SIGNED :\n• UNSIGNED:\nStrings (between ’ ’)\nName\nSize\nCHAR(M)\nString with fixed size, 1 &lt;= M &lt;= 255\nVARCHAR(M)\nString with variable size, 1 &lt;= M &lt;= 255\nTINYTEXT\nMax length = 255\nTEXT\nMax length = 65535\nMEDIUMTEXT\nMax length = 16777215\nLONGTEXT\nMax length = 4294967295\nDECIMAL(M, D)\nSimulate a floating point number in a string format\nDate and Time\nName\nFormat\nDATE\nAAAA-MM-JJ\nDATETIME\nAAAA-MM-JJ HH:MM:SS\nTIMESTAMP\nAAAAMMJJHHMMSS\nTIMESTAMP(M)\nFirst M characters of a TIMESTAMP\nTIME\nHH:MM:SS\nYEAR\nAAAA\nENUM: take one value in the defined list (can be NULL)\nsyntax:\nattr_name ENUM(‘value1’, ‘value2’, …) {NULL | NOT NULL}\nDatabase queries\ncreate a database\nCREATE DATABASE [IF NOT EXISTS] ;\ndelete a database\nDROP DATABSE [IF EXISTS] ;\nrename a database\nALTER DATABASE  RENAME ;\nlist databases\nSHOW DATABASES;\nselect a database\nUSE ;\nTable queries\nshow a table\nSHOW TABLES;\nrename a table\nALTER TABLE  RENAME ;\ndescribe a table\nDESCRIBE\n\n;delete a tableDROP TABLE ;type of constraints• NOT NULL• UNIQUE• PRIMARY KEY = NOT NULL + UNIQUE• FOREIGN KEY• CHECK• DEFAULT• AUTO_INCREMENTcreate a tableCREATE TABLE  ( (size) , (size) ,…PRIMARY KEY());add / delete a constraintsALTER TABLE  ADD CONSTRAINT  TYPEOFCONSTRAINT (, …)ALTER TABLE  DROP [CONSTRAINT  | TYPEOFCONSTRAINT ];Modify table structureadd / delete attributeALTER TABLE  ADD   [FIRST|AFTER ];ALTER TABLE  DROP  ;add / delete default value to an columnALTER TABLE  ALTER  {SET DEFAULT |DROP DEFAULT};change definition of an attribute without/with renaming itALTER TABLE  MODIFY  ;ALTER TABLE  CHANGE   ;Inserting dataINSERT INTO (, , …) VALUES (, , …);Modifying dataUPDATE SET  = ,  = , …WHERE ;Deleting dataDELETE FROM  WHERE ;Retrieving dataSelect statementSELECT [ DISTINCT ] attributs[ INTO OUTFILE fichier ][ FROM relation ][ WHERE condition ][ GROUP BY attributs [ ASC | DESC ] ][ HAVING condition ][ ORDER BY attributs ][ LIMIT [a,] b ]operators in a where clause=Equal&lt;&gt;Not equal. Note: In some versions of SQL this operator may be written as !=\n\nGreater than&lt;Less than\n=\nGreater than or equal&lt;=Less than or equalBETWEENBetween an inclusive rangeLIKESearch for a pattern (‘%’ any sequence of characters ’_’ any character)[NOT] INTo specify multiple possible values for a columnIS [NOT] NULLTo check if the value of a column is NULL or notAND OR NOTFilter records based on more than once conditionSub-requests\nSELECT * FROM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWHERE prix &gt; (SELECT MIN(prix) FROM tab2)\nSELECT * FROM\n\n\nWHERE nom NOT IN (SELECT nom FROM tab2)\nSELECT * FROM\n\n\nWHERE prix &gt; ALL (SELECT prix FROM tab2) (sup. à ttes les valeurs)\nSELECT * FROM\n\n\nWHERE prix &gt; ANY (SELECT prix FROM tab2) (sup. à au moins 1)SQL aliases on column / table\nSELECT  AS  FROM\n\n\n\n(alias a result)\nSELECT  FROM\n\n\nAS  (alias a table name)SQL functionsAVG() - (moyenne)COUNT() - (nombre d’élément)MAX() - (maximum)MIN() - (minimum)SUM() - (somme)UCASE()LCASE()LEN()NOW()FORMAT()"
  },
  {
    "objectID": "posts/c19d8524-7a45-4dbc-b9a4-d77f1e59063f/index.html",
    "href": "posts/c19d8524-7a45-4dbc-b9a4-d77f1e59063f/index.html",
    "title": "NLP Packages",
    "section": "",
    "text": "NLP NLG Packages\nquestgen.ai:\ngenerate question from essay, imitate interaction\n增加观众互动性 生成问题\nquestion answering question generator\n甲骨 jiagu nlp包 provided by ownthink:\nhttps://github.com/ownthink/Jiagu\n\n中文分词\n词性标注\n命名实体识别\n知识图谱关系抽取\n关键词提取\n文本摘要\n新词发现\n情感分析\n文本聚类\n\nhaystack:\nnlp framework\nneural search neural text search\nsemantic search\nsummarization\nquestion answering\nsnownlp:\nchinese segmentation, pinyin, sentiment analysis (情感分析), word tags, keywords, summary, tf-idf similarity, classification, 繁体转简体"
  },
  {
    "objectID": "posts/ae1c2d03-8a12-4754-9acf-3ddbfb9304b6/index.html",
    "href": "posts/ae1c2d03-8a12-4754-9acf-3ddbfb9304b6/index.html",
    "title": "Nautilus Hangs When Searching",
    "section": "",
    "text": "delete ~/.cache/tracker"
  },
  {
    "objectID": "posts/2ebabef9-0a65-4a24-b90c-76d29c54b21f/index.html",
    "href": "posts/2ebabef9-0a65-4a24-b90c-76d29c54b21f/index.html",
    "title": "Neo4j learning notes",
    "section": "",
    "text": "neo4j desktop provide free multi graph databases support, enable you to create and use multiple graph datases at once\nto query undirected relationships:\nmatch () – (p) return p\ncreate fulltext index\ncreate fulltext index lucene for (n:Person) on each [n.title, n.description]\ncall db.index.fulltext.queryNodes(“titlesAndDescriptions”, “Full Metal Jacket”) yield node, score return node, score\ncalculate customer rating cosine similarity for recommendation:\nhttps://neo4j.com/graphgists/northwind-recommendation-engine\nmatch (c1:customer)-[r1:rated]-(:product)-[r2:rated]-(c2:customer)\nwith sum(r1.score*r2.score) as dot_product,\nsqrt(reduce(x=0, a in r1.score | x+a^2)) as r1_length,\nsqrt(reduce(y=0, b in r2.score | y+b^2)) as r2_length\nmerge (c1)-[s:similarity}]-(c2)\nset s += {score:dot_product/(r1_length*r2_length)\nuse collect to turn maps into lists:\nmatch (p) return collect(p.names)\nexist subquery:\nmatch (n:Person) where exists {\nmatch (n) –(t:Tech)\nwhere size((t)-[:likes]-(:Person)) &gt;2\n}\nreturn n.name\nlist comprehension:\nreturn [x in range(0,10) where x%3 = 0| x/2] as list\nreturn [x in range(0,10) where not x in range(4,10) |x ] as list\nto use conditional matches or regular expressions:\nmatch () – (p) where p.name in [“helen”] or p.name =~ “.chinese.” return p\ncreate index on properties:\ncreate index for (n:Category) on (n.categoryName)\nasterisks:\nload csv:\nload csv with headers from “http://localhost/person.csv” as line\ncall {with line\nmerge (n:person {id: toInteger(line.id)})\nset n.name = line.name\n} in transactions of 2 rows\ncount nodes:\nmatch (n) return count(n)\nmatch relationship patterns:\nmatch (n) -[:friend|hater*3]-&gt;(p) return p limit 20\nnode can have multiple labels, while relationship can only have one type, both specified after the colon.\nsimple case expression:\nmatch(n)\nreturn\ncase n.eyes\nwhen “blue” then 1\nwhen “brown” then 2\nelse 3\nend as result\ngeneric case expression\nmatch (n)\nreturn\ncase\nwhen n.eyes = “blue” then 1\nwhen n.age &gt; 40 then 2\nelse 3 // if without else then return null\nend as result\ninequality symbol: &lt;&gt;\nmutating updating node properties:\nmatch(n)\nset n+={name:“helen”} // if using = the properties will be totally replaced instead of update.\nreturn n.name\nmerge can only ensure the existance of one node or pattern at a time, no comma\nplus can concatenate strings\ntenporal dataformat can be used as numbers to compute.\nMap operators\n. for static value access by key, [] for dynamic value access by key\nList operators\n\nfor concatenation, IN to check existence of an element in a list, [] for accessing element(s) dynamically\n\nrecommendation steps:\nfirst find targets by meta relatonships\nnext sort recommendation by frequency, ratings or occurance\nthird filter items by topics or properties"
  },
  {
    "objectID": "posts/813de677-4b35-4c38-a0b2-b77079f7bc48/index.html",
    "href": "posts/813de677-4b35-4c38-a0b2-b77079f7bc48/index.html",
    "title": "NoRepeat flag in pyjom producer",
    "section": "",
    "text": "no consecutive clip sequences have then same file source.\nno identical clips in render sequence."
  },
  {
    "objectID": "posts/23b6737e-2c90-4408-a1fb-a00c67b84704/index.html",
    "href": "posts/23b6737e-2c90-4408-a1fb-a00c67b84704/index.html",
    "title": "Optical Flow, slow motion and more",
    "section": "",
    "text": "https://github.com/slowmoVideo/slowmoVideo\nit uses gpu and optical flow to do frame interpolation.\nable to do instance segmentation if the optical flow boundary is clear and continuous.\nbuild opencv with opencv_contrib and -DWITH_CUDA=ON to enable cudaoptflow."
  },
  {
    "objectID": "posts/e692f07e-e16c-4137-af62-2defeef1acc8/index.html",
    "href": "posts/e692f07e-e16c-4137-af62-2defeef1acc8/index.html",
    "title": "Polymer Chemistry Mixture",
    "section": "",
    "text": "http://www.cheminfo.org/\ninteratomic potentials:\nhttps://www.ctcms.nist.gov/potentials/\nhttps://zhuanlan.zhihu.com/p/351829537\nhttps://www.ctcms.nist.gov/potentials/system/C-H-O/\nhttps://atb.uq.edu.au/index.py?tab=structure_search\nhttps://github.com/dwsideriusNIST/LAMMPS_Examples\nopensmog smog2.provides force field generation tool\nrun simulation under given temperature, pressure and get density\nopenmm\ngenerate force field on the fly:\nfrom openff.toolkit.topology import Molecule\nmolecule = Molecule.from_smiles(‘c1ccccc1’)\nhttps://www.catalysis-hub.org\npymatgen contains polymer generator to lammps:\npymatgen.io.lammps.utils\nsimulating reaction in molecular dynamics:\nhttps://www.reacter.org\nimplemented in lammps fix bond/react method\nrandom.randomvoidmail@erine.email (pending approval)\nseen polymer names on lammps demo website:\nhttps://lammps.org/pictures.html#reactphoto\nhttps://docs.lammps.org/Intro_features.html\nIf you are a new computational chemist I would advise you to use ASE, it is not only useful for nanoparticles, I’m using it nearly every day.\npatent:\nhttps://bulkdata.uspto.gov/\nhttp://chemdataextractor.org/results/26088052-3833-41ea-98f1-0a8a3fb2c341\nhttps://www.zhihu.com/question/50559712\nmoltemplate, packmol\nvmd: lammps data file visualization\nbuild input file for lammps:\nhttps://atomsk.univ-lille.fr/\nget retrosynthesis training data on picture search engines\nocta: predict polymer properties\nhttps://octa.jp/references/examples/\nLink: [5]http://oexchange.org/spec/0.8/rel/related-target\nYou can try [33]https://spaya.ai/ it is a retro-synthetic analysis\n[37]Http://www.orgsyn.org/\n[41]Http://www.orgsyn.org/\n[45]Http://www.organic-chemistry.org/\nTry this interesting blog: [49]http://totallysynthetic.com/blog/\nAnd also this website: [50]http://chemistrybydesign.oia.arizona.edu/\n[54]http://www.chemspider.com/\n[58]https://pubchem.ncbi.nlm.nih.gov/search\nOrganic Syntheses Website: &lt;[62]http://www.orgsyn.org\nOrganic Chemistry Portal: &lt;[63]http://www.organic-chemistry.org/abstracts\nChemsynthesis: [64]http://www.chemsynthesis.com\nChemExper: [65]https://www.chemexper.com\nPub Chem compound: [67]http://pubchem.ncbi.nlm.nih.gov\nE-molecules: [68]http://www.emolecules.com\nChemspider: [69]http://www.chemspider.com\nReaxys: [70]https://www.reaxys.com/\nSciFinder: [71]http://www.cas.org,\nSTN: [72]https://stnweb.cas.org/\n[76]http://www.chemspider.com\n[80]https://www.vulcanchem.com/\nhttps://moltemplate.org\nhttps://chemdataextractor.org\ngromacs: creating polymer structure\nhttp://www.gromacs.org/Documentation_of_outdated_versions/How-tos/Polymers\nlatest gromacs documentation:\nhttps://manual.gromacs.org/documentation/\nonline organic chemistry textbook:\nhttps://www2.chemistry.msu.edu/faculty/reusch/virttxtjml/intro1.htm\nopenbabel can only run normally on x86 platforms. so do other cheminfo packages.\nsources of organic synthesis\nhttps://www.organic-chemistry.org\nhttp://www.orgsyn.org\nWhat is matsci.org?\nmatsci.org is a community forum for the discussion of anything materials science, with a focus on computational materials science research. Its members are typically from academic research institutions and universities.\nPeople that currently help run matsci.org include maintainers of the following codes and collaborations:\nOVITO\nGULP\nDL_POLY\nOPTIMADE\npyiron\nhiphive\nASE\nMPDS\niFermi\nLAMMPS\nMaRDA\nexciting\nJARVIS\nand members of the following research groups:\nHacking Materials Group\nPersson Group\nMaterials Virtual Lab\nMaterials Intelligence\ntranslate bigsmiles into smiles\npolymer database:\nPolyInfo and NIST Synthetic Polymer MALDI Recipes database\nUSPEX\nchemdraw chemoffice indraw spaya.ai\nreaxys scifinder-n\nmarvin sketch pka\nhttps://github.com/PKUMDL-AI/AutoSynRoute\npolymer simulation:\nmaterial studio\namsterdam modeling suite\ncp2k orca\nhttps://orcaforum.kofo.mpg.de/app.php/portal\nchemistry in stack exchange:\nhttps://chemistry.stackexchange.com/\npolymer retrosynthesis using retro*:\nseq2seq-retro mlp-retro polyretro-uspto\ndeepchem, chempy(inorganic)\navogadro: import openbabel files\nodachi: decompose target molecular into source molecular, highlight the potential bond\nrdkit: python chemistry informatic\npolymer informatic\nab initio chemistry:\nlammps, quantum espresso, nwchem, gamess, uspex\nfrom https://www.webmol.net:\nGamess, Gaussian, MolPro, Mopac, NWChem, Orca, PQS, PSI, Q-Chem, TeraChem, Tinker, Quantum Expresso, and VASP"
  },
  {
    "objectID": "posts/2a7bee76-2907-44b8-b8bf-618d474e061e/index.html",
    "href": "posts/2a7bee76-2907-44b8-b8bf-618d474e061e/index.html",
    "title": "PowerPoint 比较视频制作方法 Animation Software OSS Scriptable Flipcard",
    "section": "",
    "text": "看看别人的数据来源是什么\n\n知乎神回答 知乎同类回答 排行榜 github排行榜 同类内容\n比较视频可以用段落总结关键词来做\nfree open source animation software for linux, by sourceforge.net\nthree.js javascript 3d library\ntyped.js imitate typing animation\nanime.js javascript animation engine\nsynfig 2d vector based animation library\ncountup.js animate counting up to a number\nvivus.js drawing animation imitator\nLibreoffice Impress或者其他的动画工具 制作视频 比如synfig blender three.js\nhttps://ask.libreoffice.org/t/convert-impress-presentation-to-video/33952\nhttps://ask.libreoffice.org/t/how-to-turn-libreoffice-impress-into-video-mp4-format/20589\n同样的 可以制作冷知识问答的动画视频 通过收集百度 bing搜索相关词语 如果是问句 问题 就拿来搜索 如果出现了放大版本的句子就收集下来 就是回答"
  },
  {
    "objectID": "posts/e1fee6ca-f126-4189-99b4-b23fbaf9fa23/index.html",
    "href": "posts/e1fee6ca-f126-4189-99b4-b23fbaf9fa23/index.html",
    "title": "Pyatspi dogtail gnome accessibility gui inspect tool for linux a11y",
    "section": "",
    "text": "does appium have linux accessibility implementation?\nwindows a11y:\nhttps://github.com/blackrosezy/gui-inspect-tool\npywinauto\nbookmark_history_search sucks. it does not include webpage summaries, only title, which makes searching the history very hard. the solution is to use readbility.js to visit and summarize these pages, and update these documents in meilisearch.\na11y is the general term for accessibility, for web browsers like firefox. however, there’s implementation for gnome internally.\nlinux a11y:\nhttps://github.com/shubhamvasaikar/Auto-GUI-Testing\ngnome accessibility toolkit(atk)\nhttps://gitlab.gnome.org/GNOME/pyatspi2\nhttps://gitlab.com/dogtail/dogtail\nhttps://www.freedesktop.org/wiki/Accessibility/PyAtSpi2Example/\naccessibility implementation in different toolkits:\nhttps://github.com/GNOME/at-spi2-core/blob/e83d5558d2fbded5b345b0af254f26865e148e49/devel-docs/toolkits.md\nToolkits that use the DBus APIs directly\nGTK4\nSources: gtk4/gtk/a11y\nQt5\nSources: qtbase/src/gui/accessible/linux\nWebKit\nSources: WebKit/Source/WebCore/accessibility/atspi\nToolkits that use ATK\nGTK3\nSources: gtk3/gtk/a11y\ngnome-shell / St / via clutter’s cally\nSources: mutter/clutter/clutter/cally\nMozilla Firefox\nSources: gecko-dev/accessible/atk\nChromium\nUses both ATK and libatspi?\nSources:\nchromium/ui/accessibility/platform/auralinux (atk)\nchromium/ui/accessibility/platform/inspect/auralinux (atspi)\nchromium/content/browser/accessibility/auralinux (atspi and atk)\nLibreOffice\nSources: LibreOffice/core/vcl/unx/gtk3/a11y\nJava Swing - via java-atk-wrapper\nSources: java-atk-wrapper"
  },
  {
    "objectID": "posts/fc32ea43-c71f-4460-9806-b1dd4c9569a1/index.html",
    "href": "posts/fc32ea43-c71f-4460-9806-b1dd4c9569a1/index.html",
    "title": "Python DSL",
    "section": "",
    "text": "textX with syntax highlighter and LSP support, just like Xtext\nply: python lex-yacc\ndhparser\nlark"
  },
  {
    "objectID": "posts/a19b3e39-beec-484b-b3d8-446b3c4d54fa/index.html",
    "href": "posts/a19b3e39-beec-484b-b3d8-446b3c4d54fa/index.html",
    "title": "Python suggest binary file name extension",
    "section": "",
    "text": "Detect media file corruption, Python suggest binary file name extension\nto rule out those corrupted media files, or unplayable files. maybe simply by parsing these files is not enough, we need a dedicated file corruption detector.\nto truncate these files and see errors produced by media readers. use text file with media file extension to test them."
  },
  {
    "objectID": "posts/ca75dd0f-260b-4115-a85b-eb3c9c4bdd39/index.html",
    "href": "posts/ca75dd0f-260b-4115-a85b-eb3c9c4bdd39/index.html",
    "title": "RAG in my mind",
    "section": "",
    "text": "llm generate images for content\nllm generate tags & categories for content\nllm generate embedding for content\nllm generate query words\nllm generate query image/audio\nsystem perform full text search\nsystem perform vector search\nllm generate relevance or preference\nllm generate potential query for content\nsystem update relevance based on llm preference"
  },
  {
    "objectID": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#smart-watch",
    "href": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#smart-watch",
    "title": "RSIBreak, Break Reminder",
    "section": "Smart Watch",
    "text": "Smart Watch\ndo not mix the water with the watch. you have been warned.\n\nPrefer WearOS watches like LG W100. Found 3D printable case on Shapeways but not downloadable. Shapeways provides service for printing. Shapeways builds ShapeJS which can construct 3D models with code.\n\nUse Pixle2Mesh++ to recover 3D meshes from multiple images (dumped at ~/Desktop/works/shapeways_reconstruct_from_image_lg_w100)of different viewpoints. Determine the size of the mesh after measurement or learning specs.\n\nif you want iwatch instead, remember to buy some apple gift cards for buying watchos apps. remember to ask for battery life since older watches tend to die halfway in a day. buy iphone 6s and newer models with ios 14 and newer os to manage and install apps on iwatch. no need for 3d modeling since plenty tough-tested cases around."
  },
  {
    "objectID": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#diy",
    "href": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#diy",
    "title": "RSIBreak, Break Reminder",
    "section": "DIY",
    "text": "DIY\nif you want to do it on your own, you have to know how to send notifications on different operating systems.\n\non macOS:\nosascript -e 'display notification \"This message should be showing on the notification\" with title \"Coding Tips\"'\nterminal-notifier (brew installable)\nalerter\n\non linux:\nnotify-send \"Dinner ready!\"\nusing remind:\nremind \"I'm still here\" now\nremind \"Time to wake up!\" in 5 minutes\nremind \"Dinner\" in 1 hour\nremind \"Take a break\" at noon\nremind \"It's Friday pints time!\" at 17:00\n\non windows:\nmsg /SERVER:DestinationPC * /TIME:60 “This is the message to be sent to a PC named DestinationPC and closes in 60 seconds.\"\n\nnotify-send-for-Windows (needs AHK)\ntutorial"
  },
  {
    "objectID": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#break-reminder-tools",
    "href": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#break-reminder-tools",
    "title": "RSIBreak, Break Reminder",
    "section": "break reminder tools",
    "text": "break reminder tools\nRSIBreak is for linux, and it does not work well.\nstretchly has an online version. on macOS make sure your browser is allowed to post notifications.\n“Drink.” on mac app store is a water drinking reminder for macOS.\nBreakTimer has windows, macOS and linux version. on linux you better use snap or appimage version."
  },
  {
    "objectID": "posts/5a1f6160-e47a-453d-8bd5-eb06e9d5e62d/index.html",
    "href": "posts/5a1f6160-e47a-453d-8bd5-eb06e9d5e62d/index.html",
    "title": "RX580 16g used as AI accelerator",
    "section": "",
    "text": "codename: gfx803\nyou may have to build it yourself"
  },
  {
    "objectID": "posts/4fe55be4-a449-457e-9080-7fbf575888d8/index.html",
    "href": "posts/4fe55be4-a449-457e-9080-7fbf575888d8/index.html",
    "title": "Read Manga Online",
    "section": "",
    "text": "https://mangareader.to/read/tokyo-ghoulre-362"
  },
  {
    "objectID": "posts/b65aa0df-7114-4f0d-a099-68f7b1eaa809/index.html",
    "href": "posts/b65aa0df-7114-4f0d-a099-68f7b1eaa809/index.html",
    "title": "Remote Jobs",
    "section": "",
    "text": "remote jobs in china:\nhttps://github.com/LinuxSuRen/remote-jobs-in-china\nremote jobs from stack overflow:"
  },
  {
    "objectID": "posts/3847fe1f-d317-4656-b73c-0721888fa4cc/index.html#with-processor-flags-output",
    "href": "posts/3847fe1f-d317-4656-b73c-0721888fa4cc/index.html#with-processor-flags-output",
    "title": "Repl for Assembly Code",
    "section": "with processor flags output",
    "text": "with processor flags output\nhttps://github.com/yrp604/rappel"
  },
  {
    "objectID": "posts/3847fe1f-d317-4656-b73c-0721888fa4cc/index.html#msf-provided-repl",
    "href": "posts/3847fe1f-d317-4656-b73c-0721888fa4cc/index.html#msf-provided-repl",
    "title": "Repl for Assembly Code",
    "section": "msf provided repl",
    "text": "msf provided repl\nmsf-nasm_shell"
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#p2p-network",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#p2p-network",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "p2p network",
    "text": "p2p network\nnps also supports p2p\n(deprecated! does not pass the connectivity test) opengnb p2p network, faster than n2n v3, can run without public ip\ngost as an frp alternative\nturned out n2n is necessary, since the speed comparasion strongly disencourage the usage of frp directly.\nn2n test commands, using compatible v3 protocol to communicate:\nsupernode v3: n2n.laiyx.win:10090\nwarning: it is useless to add multiple supernodes.\n-l nton.eu.org:10090 -l n2n.lu8.win:10090 -l n2n.haoren.eu.org:10090 -l\nsupernode.ntop.org:7777 -l 47.102.102.77:10090 -l n2n.myan.cc:10090 -l n2n.sfcs.eu.org:10090 -l n2n.eriol.cn:10090 -l n2n.x0x.cn:10090 -l n2n.vvcd.win:10090\n\nkali:\nsudo edge -c &lt;name&gt; -k &lt;password&gt; -a 192.168.100.1 -f -l n2n.laiyx.win:10090 -Er -A3 -e auto\nmacos, since we use sudo you might consider doing it with system service:\nsudo edge -c &lt;name&gt; -k &lt;password&gt; -a 192.168.100.2 -f -l n2n.laiyx.win:10090 -Er -A3 -e auto\npublic shared n2n supernodes\nyou could test the speed and decide to use it or not.\nin kali discovery service, when local connection is not avaliable, usually the p2p network is preferred than direct frp tunneling.\nbrew has tinc as a package!\ntinc conf\ntinc setup with core server\nremote access with vps using tinc\ninstall and config tinc on linux\ntinc is somehow complex and it may requires some tinkering on tinc-up or using docker.\ninstall n2n without macports\nuse n2n to send udp packages among clients, try to create direct link between devices which will speed up ssh connection speed. supernode creation could be used along with frpc\nsomehow brew does not have n2n as a package. macports has it, which requires xcode (huge!) to be installed.\npeervpn tutorial"
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#daemonize-launch-at-startup",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#daemonize-launch-at-startup",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "daemonize (launch at startup)",
    "text": "daemonize (launch at startup)\non macos, when crontab is created, cron will be automatically launched by launchd.\ncronjobs may need to launch with the $(which env) prefix.\nthe problem of internet disconnetion will most not likely to interfere with the server since frpc has auto reconnection and the update hook is the filesystem watchdog, which will not run when no changes made (including the offline period)\nthe watchdog may be replaced by some mirror fuse system, which will report every access request to our dedicated server.\nwe have seen this behavior (filesystem mirroring) in our gitfuse code. but does that support symlink? should we really take care of that? or should we forget that and just use inotify instead?\nmaybe it will affect the client when mounting the remote filesystem using sshfs or rclone, but that has to be verified."
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#serve-and-mount-remote-filesystem",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#serve-and-mount-remote-filesystem",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "serve and mount remote filesystem",
    "text": "serve and mount remote filesystem\nbefore serving, make sure the path /media/root/help/pyjom exists by running our mount script\ncreate htpasswd file:\nhtpasswd -bc webdav_htpasswd &lt;username&gt; &lt;password&gt;\nuse rclone:\nrclone serve webdav /media/root/help/pyjom --addr 0.0.0.0:8468 --key /root/.local/share/code-server/localhost.key --cert /root/.local/share/code-server/localhost.crt --htpasswd /root/Desktop/works/sync_git_repos/remote_deploys/webdav_htpasswd -L\nbefore mounting, use rclone config to setup remote associated with a name. make sure the hostname is localhost instead of ip address to avoid certificate issues. do not install rclone from brew since it does not support fuse. instead, install from here\nrclone mount webdav_local_nginx:/ /Volume/CaseSensitive/pyjom_remote_mountpoint --ca-cert /Users/jamesbrown/Desktop/works/host_discovery_ssh_local_connect/certificates/localhost.crt\nafter mounting, seems zsh on macos is not working very well with macfuse. bash works. does bash/fish works with sshfs as well? maybe that will save efforts."
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#encryption-and-invalid-https-certificates",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#encryption-and-invalid-https-certificates",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "encryption and invalid HTTPS certificates",
    "text": "encryption and invalid HTTPS certificates\nuse nginx to redirect remote server as localhost, since the host name on the certificate is localhost we cannot let chrome to trust anything other than that\nworker_processes auto;\nerror_log error.log;\nevents { }\nstream {\nserver {\nlisten 127.0.0.1:7576;\nproxy_pass REMOTE_HOST:7576;\n}\n}"
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#code-serverbrowser-color-fixes",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#code-serverbrowser-color-fixes",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "code-server(browser) color fixes",
    "text": "code-server(browser) color fixes\n.cursor{\nbackground: white;\n}\nbody.web{\ncaret-color: white;\n}\n.monaco-editor .view-line span.inline-selected-text{\nbackground: blue;\ncolor: white;\n}"
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#connectors-other-than-frp",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#connectors-other-than-frp",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "connectors other than frp",
    "text": "connectors other than frp\ncode-server recommends some other methods like cloudflared and ngrok. 花生壳可能也有用 但是可能不好用"
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#methods",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#methods",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "methods",
    "text": "methods\ntry out code-server by coder, might work?\nalso we use builtin vscode connectors, using ssh.\ncurrently we only have one, which uses direct ip address instead of a hijacked domain. maybe it is time to consider some faster server providers.\nuse a universal ssh as workspace extension called SSH FS"
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#drawbacks-of-ssh-fs-extension",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#drawbacks-of-ssh-fs-extension",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "drawbacks of SSH FS extension",
    "text": "drawbacks of SSH FS extension\nsome drawbacks of this SSH FS plugin is that it cannot use the plugins from remote machine, also having issue whe jumping to remote files from terminal output. to run code-insider instead of code-oss, maybe we could spin up the official ssh connector, which can only be automated by publickey authentication."
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#syncing-updating-and-viewing-using-watchdog-and-sshfsdeprecated-since-it-shares-connection-with-vscode-remote-and-maybe-slower-than-rclone-serve-webdav",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#syncing-updating-and-viewing-using-watchdog-and-sshfsdeprecated-since-it-shares-connection-with-vscode-remote-and-maybe-slower-than-rclone-serve-webdav",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "syncing, updating and viewing using watchdog and sshfs(deprecated since it shares connection with vscode remote and maybe slower than rclone serve webdav?)",
    "text": "syncing, updating and viewing using watchdog and sshfs(deprecated since it shares connection with vscode remote and maybe slower than rclone serve webdav?)\nto mount the filesystem via sshfs:\nsshfs root@192.168.10.4:/media/root/help/pyjom /Volumes/CaseSensitive/pyjom_remote_mountpoint -o follow_symlinks\nto make sure the changes are updated regularly, we need a filesystem watchdog on kali, which will trigger the action of syncing, utilizing inotify. shall that be adopted on macos? maybe. but my extra editors can be vim or nvim, so it is not so hard to predict. but if it can monitor the file read events, we don’t need those legacy editor program hooks.\nat least we need to see the output, so we need to mount the remote filesystem as sshfs, then use ffplay to view it."
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#solution",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html#solution",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "solution",
    "text": "solution\nfor now, two viable ways:\none using code-server, the other using code-server-insider provided by code-insider. when using builtin code-server-insider, remember it will not share the plugins installed by code-insider. the remote executable location is at /root/.vscode-server-insiders/bin/12b08be500f8a307f30e92cbc3ee39ba115eab69/bin/code-server-insider or something. must set the local setting remote.SSH.useLocalServer to false.\nwhen using code-server, one can connect to the workspace using browser, instead of vscode builtin remote connector."
  },
  {
    "objectID": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html#tools",
    "href": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html#tools",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "tools",
    "text": "tools\nkeyword mining (by search engine or more): 2 words -&gt; 3 words -&gt; 4 words -&gt; 5 words (recursive)\nkeyword-suggest-tool is a simple tool that provides you keyword suggestion from multiple search engines like google, bing, yahoo, ebay, amazon, ebay, deployed on sutlej.net/seo-tools\nULTRA Unbiased Learning To Rank Algorithms, sorting things out, find what users like the most\nserpbear check rankongs on google\ncurated seo tools huge tools/website collection on seo category\nawesome-keyword-finder-tools A curated list of amazingly awesome seo keyword finder tools\nKeyword-Research-tool-python Build a Keyword research tool with google autocomplete suggestions in python\nkeyword tool The Keyword Manager is a tool to support SEAs and SEOs finding new keywords from a website.\nkeyword_tool Web app to extract keywords from pasted text. Built with NLTK and Streamlit.\nkeywordshitter2 A website to find long-tail keywords using search suggestions, still works on here\nPURR (PUppeteer RunneR) is a devops-friendly tool for browser testing and monitoring by semrush\nawesome-local-seo A curated list of amazingly awesome local seo resources.\nseo-audits-toolkit SEO & Security Audit for Websites. Lighthouse & Security Headers crawler, Sitemap/Keywords/Images Extractor, Summarizer, etc …\nseo_keyword_research_tools The Keyword Volume Tool uses the Google Adwords API Targeting Ideas Service to return the search volume and competition of a massive list of keywords. The Keyword Expansion Tool uses the Google Adwords API Targeting Ideas Service to expand an input keyword into up to 500 related keywords with search volume.\nResources"
  },
  {
    "objectID": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html#functionalities",
    "href": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html#functionalities",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "functionalities",
    "text": "functionalities\nCompetitive analysis\nKeyword research\nBacklink research\nContent research/Content optimization/Content planning\nRank Tracker\nSite audit tool/Site explorer\nLink analysis/Link profile\nDomain comparison\ncompetitor research\nSEO Metrics\nGoogle Data studio"
  },
  {
    "objectID": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html#glossaries",
    "href": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html#glossaries",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "glossaries",
    "text": "glossaries\nLocal SEO: the practice of optimizing your website for a specific local area\nSERP: search engine result page, means scraping from search engine to get rankings.\nSEO: search engine optimization, means to cheat the search engine to get higher rankings.\nSEM: search engine marketing, pay ads to search engine, or advertise on your own search engine?\nSMM: social media marketing, play nice with the public\nSMO: social media optimization, attract users on platform"
  },
  {
    "objectID": "posts/7407631d-b486-4c90-9577-45486922b9b1/index.html#seo-without-website",
    "href": "posts/7407631d-b486-4c90-9577-45486922b9b1/index.html#seo-without-website",
    "title": "SEO 蓝海词 竞争度",
    "section": "seo without website",
    "text": "seo without website\nwrite a blog on github?\ncreate short links and submit them to search engine\nget query count, perform n-gram analysis\nhttps://www.aeripret.com/ngrams-analysis-seo/\nhttps://www.pemavor.com/seo-keyword-clustering-with-python/\ni have bookmarked links for further use on macbook chrome.\nadvertools is a professional SEO library, productivity & analysis tools to scale your online marketing\n可以用分析股价的方法分析搜索关键词 其中股价对应搜索频率（实时） 播放量对应成交量（实时）也可能不对 反正这个模型肯定要先收集数据然后再建模 画k线 当然也不必完全拘泥于全盘还原 收集到的数据能反映实际情况 得到最优解 也就是发个视频预估播放量最大就行 用深度学习模型\n寻找潜在爆款话题 标签\n快排参数 上首页\nhttps://github.com/sopify-bot/seo\n分为主动点击 换IP点击\n以及优化自身关键词 被动优化两种方式\n蓝海词可以从零开始做 可以由现有词语延伸 可以寻找已有的蓝海词\n蓝海词是产品关键词的一种，又被称为“零少词”、“长尾词”。具体是指前台具备一定买家搜索热度，但供应商发布产品较少，通常该词下对应的精确匹配产品数量不超过3页，因而同行竞争度较低的关键词。一旦供应商能准确使用这些词语，并能结合信息质量发布一条合格的产品信息，将获得曝光和点击的快速提升\n红海泛指竞争相当激烈的市场。在红海中，产业边界是明晰和确定的，游戏的竞争规则是已知的。身处红海的企业试图表现得超过竞争对手，以攫取已知需求下的更大市场份额\n淘宝标题撰写技巧：标题流量的3架马车，飙升词+蓝海词+销量卡位词\n什么是飙升词？就是在短时间内热度迅速攀升，并且持续上升的词！\n蓝海词就是那些搜索热度非常高，但这个词下面的在线产品却很少的词。\n这种词可以让我们避免和红海大词竞争，获取很多隐藏流量！\n淘宝界面除了能够综合排序之外，我们还能通过销量来排序。\n关键词卡位就是 寻找点击量和你差不多的视频 商品所拥有的关键词语 标签 这样按照播放量排序的时候就会排到这些视频中间"
  },
  {
    "objectID": "posts/4451fb3e-621b-4a3e-ba48-3947de4ea43b/index.html#windows",
    "href": "posts/4451fb3e-621b-4a3e-ba48-3947de4ea43b/index.html#windows",
    "title": "Search and switch to window by title",
    "section": "windows",
    "text": "windows\n\nyal\naccess and search windows\naccess files, programs, bookmarks, search engines"
  },
  {
    "objectID": "posts/4451fb3e-621b-4a3e-ba48-3947de4ea43b/index.html#macos",
    "href": "posts/4451fb3e-621b-4a3e-ba48-3947de4ea43b/index.html#macos",
    "title": "Search and switch to window by title",
    "section": "macos",
    "text": "macos\n\nfinda\nfind windows, browser tabs, code editor buffers, browser history, apps, files"
  },
  {
    "objectID": "posts/4451fb3e-621b-4a3e-ba48-3947de4ea43b/index.html#linux",
    "href": "posts/4451fb3e-621b-4a3e-ba48-3947de4ea43b/index.html#linux",
    "title": "Search and switch to window by title",
    "section": "linux",
    "text": "linux\nkupfer plugin window list\nuse xdotool and wmctrl\nWindow List command (wmctrl):\n$ wmctrl -lx\n0x0540043e  0 google-chrome.Google-chrome  ubunzeus Search for window title? - Ask Ubuntu - Google Chrome\n0x050000ec  0 Mail.Thunderbird      ubunzeus Inbox - Mozilla Thunderbird\n0x04e1068d  0 gnome-terminal-server.Gnome-terminal  ubunzeus ljames@ubunzeus: ~\nCommand to switch to specific window (xdotool)\n$ xdotool windowactivate 0x0540043e\nThe above command will switch to the Windows with the ID 0x0540043e, which is specific from the list for this Askubuntu message entry.\nThey are both in the repository:\n$ sudo apt install wmctrl xdotool"
  },
  {
    "objectID": "posts/2c68b78c-f26a-4827-aad1-8650a6a619b1/index.html",
    "href": "posts/2c68b78c-f26a-4827-aad1-8650a6a619b1/index.html",
    "title": "Self hosted web applications",
    "section": "",
    "text": "common web applications could be big, like search engines. this is a list of open-sourced self hosted services:\nhttps://github.com/awesome-selfhosted/awesome-selfhosted"
  },
  {
    "objectID": "posts/63e21eb0-28a4-4b7d-96b5-c545b0cdf9ca/index.html",
    "href": "posts/63e21eb0-28a4-4b7d-96b5-c545b0cdf9ca/index.html",
    "title": "Setup Gitee SSH Keys for GitJournal",
    "section": "",
    "text": "https:/gitee.com/profile/sshkeys\npersonal ssh keys. not deploy keys under specific project settings.\nhttps://gitee.com/n5366871df2f3/notes\ngitjournal download:\ninstall apps on anbox:\nthis thing is built on top of flutter, which could also be avaliable for windows. also it is free on all pro features."
  },
  {
    "objectID": "posts/437a4dba-188a-4aa2-894d-b6016227678f/index.html",
    "href": "posts/437a4dba-188a-4aa2-894d-b6016227678f/index.html",
    "title": "Similar Image Search",
    "section": "",
    "text": "image local search by similarity:\nhttps://github.com/ProvenanceLabs/image-match\nanime image search by scene:\nhttps://github.com/soruly/trace.moe\nbing image search:\nhttps://cn.bing.com/visualsearch/Microsoft/SimilarImages\nhttps://cn.bing.com/visualsearch\nsougou shitu:\nhttps://pic.sogou.com/shitu/index.html\nbaidu shitu:\nshitu.baidu.com\ngoogle image search:\nhttps://gfsoso.soik.top/shitu.html\nyandex image search:\nhttps://yandex.com/images/\nimage search websites:\nhttps://zhuanlan.zhihu.com/p/52693499\ntutorial on image search, gif search, image enlargement, browser plugins:\nhttps://www.bilibili.com/read/cv8688532\nduososo shitu(include other meta search engines):\nhttp://duososo.com/index_shitu.php\nzhihu image search websites:\nhttps://zhuanlan.zhihu.com/p/25610099\nfind font by images(not working qiuziti.com):\nhttps://zhuanlan.zhihu.com/p/25440271?refer=wnsouba\nfind bangumi segments by image:\n还有一个telegram bot 叫 WhatAnimeBot\nhttps://whatanime.ga/\nhttps://zhuanlan.zhihu.com/p/25313498"
  },
  {
    "objectID": "posts/013ec7bf-60c8-47b4-a280-078e8c0b337b/index.html",
    "href": "posts/013ec7bf-60c8-47b4-a280-078e8c0b337b/index.html",
    "title": "Singing Voice Generation and more",
    "section": "",
    "text": "generate audio and music: audiolm\naudio ai timeline best audio generation models\ngenerate music using diffusion\nriffusion web app\nriffusion demo website\nriffusion\necantorix generate singing voice using lmms and espeak\nread/write deepvoice binary file\ndecrypt acestudio binary project file\n谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 https://www.kuxai.com/article/398\n论文地址：https://arxiv.org/abs/2110.08813\n我的fork仓库：https://github.com/innnky/VISinger\nscoredraft in python:\nhttps://m.bilibili.com/video/av19085545\nhttps://github.com/fynv/ScoreDraft\nACE studio 公测：\nACE Studio是时域科技旗下的AI歌声合成引擎，通过毫无妥协的高表现力人声，解除演唱能力的羁绊，释放人们的音乐想象力。\n2022年7月12日，ACE Studio公测开启。\n为了在正式收费之前提供更好的稳定性体验，本轮公测期间，所有AI歌手和编辑器功能均可免费使用。下载软件后，使用手机号注册登录，即可开始使用。Mac/Win双端均可使用。\n下载地址：https://ace-studio.timedomain.tech/\noss singing software:\nMicrosoft muzic\nhttp://sinsy.sourceforge.net\nhttps://alternativeto.net/software/ecantorix/about/\nhttps://alternativeto.net/software/openutau/about/\nhttps://alternativeto.net/software/cadencii/about/\nvoice style transfer:\nhttps://github.com/andabi/deep-voice-conversion\nhttps://rebryk.github.io/convoice-demo/\nhttps://github.com/mazzzystar/randomCNN-voice-transfer\nhttps://becominghuman.ai/convoice-real-time-zero-shot-voice-style-transfer-with-convolutional-network-4c7b7fff66c9\nhttps://ebadawy.github.io/post/speech_style_transfer/\nyou can alter the order of generated lyrics, fitting into the sequence of the original lyrics.\nlyrics generation:\nhttps://zhuanlan.zhihu.com/p/137214305\nhttps://baijiahao.baidu.com/s?id=1666495322826772953\nhttps://github.com/dengxiuqi/Lyricist-torch\nhttps://github.com/zipper112/LyricsGeneration\nhttps://github.com/coder-yuzhiwei/wangfeng-lyrics-generator\nhttps://github.com/jianyq/Tong-Music\nhttps://github.com/MarsWang42/hanmai-generator\nhttps://github.com/tobiaslee/chinese-hip-pop-generation"
  },
  {
    "objectID": "posts/539635e2-6d22-4724-b845-7193510385b5/index.html",
    "href": "posts/539635e2-6d22-4724-b845-7193510385b5/index.html",
    "title": "Sleepless in Bed 失眠治疗法",
    "section": "",
    "text": "床上躺的太久 考虑伸展你的腿部 手部 拔筋\n吃饭吃太多 可以用勒肚子的方法 把裤子提高一些 这样只能吃包子 煎饼之类的 不能吃大餐 哪怕饿了一晚上也不能吃\n根据知乎 应该按照节律调整光照 但是在房间里只能模拟光照\n在规定时间上床睡觉 确保黑暗 安静\n在快起床的时候 渐进的提高光照 提高声音音量 辅助起床\n属于智能家居的范畴 智能家居代码\nhttps://github.com/home-assistant/core\n自动调灯泡亮度 智能灯泡需要手工焊接串口转USB的板子 或者用arduino 树莓派实现\nhttps://duino4projects.com/project-auto-intensity-control-of-street-light-using-arduino/amp/\nhttps://forum.arduino.cc/t/how-to-control-a-lamps-intensity/57081\nBy simply working in bed, lying down or not, using pillow or not, sore ass or not, I somehow lose sleep in bed.\nDon’t know how to explain, but this is simply true. I admit many people have lost their sleep in bed too, but never comfortable to do so. I am somehow better than them."
  },
  {
    "objectID": "posts/3f3a1f00-f206-40c6-97d5-e29f5edf877e/index.html",
    "href": "posts/3f3a1f00-f206-40c6-97d5-e29f5edf877e/index.html",
    "title": "Soul API",
    "section": "",
    "text": "Soul APIs\nsoul绕过ssl双向验证 justTRUSTME(xposed)加上反编译SDK获取证书密码 backup blog\nuse adb to setup mitmproxy on android\ncd ~/Library/Android/sdk/platform-tools/\n# Get the hash of the mitmproxy-ca certificate.\nopenssl x509 -inform PEM -subject_hash_old -in ~/.mitmproxy/mitmproxy-ca.pem | head -1\n# We will use this hash value, append '.0' (dot zero) and use this as the filename for the resulting Android certificate\ncat ~/.mitmproxy/mitmproxy-ca.pem &gt; c8750f0d.0\nopenssl x509 -inform PEM -text -in ~/.mitmproxy/mitmproxy-ca.pem -out /dev/null &gt;&gt; c8750f0d.0\n# In an other terminal, we will start the emulator with writable /system volume\ncd ~/Library/Android/sdk/emulator/\n# In order to launch an available avd, we list them first.\n./emulator -list-avds\n./emulator -writable-system @Pixel_3a_XL_API_28\n# We go back to the first terminal and we use adb tool to transfert the certificate\nadb root\nadb push c8750f0d.0 /storage/emulated/0/Download\n# Then, we will mount the volume and get access to the shell\nadb shell mount -o rw,remount /;\nadb shell\n# In the device Android shell, we will move the certificate inside the system partition in the folder '/system/etc/security/'\ncp /storage/emulated/0/Download/c8750f0d.0 /system/etc/security/cacerts/\nchmod 644 /system/etc/security/cacerts/c8750f0d.0\n可能的系统设置\nsu -c settings list global | grep proxy\nglobal_http_proxy_exclusion_list=\nglobal_http_proxy_host=\nglobal_http_proxy_port=0\nglobal_proxy_pac_url=\nhttp_proxy=:0\n\n灵魂测试卡片信息，获取签名*\nhttps://api.soulapp.cn/html/measureResult/info/v2?userIdEcpt=加密用户ID\n用户头像和签名等信息*\nhttps://api-h5.soulapp.cn/html/v2/user/info?userIdEcpt=加密用户ID\n单条瞬间展开信息*\nhttps://api-h5.soulapp.cn/html/v3/post/detail?postIdEcpt=加密瞬间ID\n单条瞬间展开页面*\nhttps://w3.soulapp-inc.cn/activity/#/web/topic/detail?postIdEcpt=加密瞬间ID\n用户发布瞬间信息，只有最新的10条*\nhttps://api-h5.soulapp.cn/html/v2/post/homepage?userIdEcpt=加密用户ID\n用户发布瞬间页面，只有最新的10条*\nhttps://w3.soulapp-inc.cn/activity/#/web/user?userIdEcpt=加密用户ID\n获取热门瞬间，只有最新的30条*\nhttps://api-h5.soulapp.cn/html/v2/post/hot?pageIndex=1（前3页）\n获取标签的瞬间信息，只有最新的30条*\nhttps://api-h5.soulapp.cn/html/v2/tag/post?tagIdEcpt=加密标签ID\n获取标签的瞬间页面，只有最新的30条*\nhttps://w3.soulapp-inc.cn/activity/#/web/tag?tagIdEcpt=加密标签ID\n随机播放音频信息，随机几首*\nhttps://api-h5.soulapp.cn/html/v2/post/orimusicList/recommend\n设置超萌捏脸页面*\nhttps://app.soulapp.cn/avator/#/avatar/create?sex=1&version=3.10.0\n注销账号页面*\nhttps://app.soulapp.cn/app/#/account\nhttps://app.soulapp.cn/app/#/destroy"
  },
  {
    "objectID": "posts/cf600d42-239d-4c45-a499-2d70359d0735/index.html",
    "href": "posts/cf600d42-239d-4c45-a499-2d70359d0735/index.html",
    "title": "Sound Effects",
    "section": "",
    "text": "spotify/pedalboard\nsupport vst plugins, create sound effects"
  },
  {
    "objectID": "posts/3ed23d4c-5ee5-4e64-a6e7-72a199d45a16/index.html",
    "href": "posts/3ed23d4c-5ee5-4e64-a6e7-72a199d45a16/index.html",
    "title": "SpeedUp Tujia Scraping",
    "section": "",
    "text": "Find which request sets the cookie, then do all other requests using DIRECT, route only that request to GLOBAL."
  },
  {
    "objectID": "posts/05fc6378-938f-4454-8e06-15348e1ef4e2/index.html",
    "href": "posts/05fc6378-938f-4454-8e06-15348e1ef4e2/index.html",
    "title": "Termux_Boot Autostart Program Fixes",
    "section": "",
    "text": "Termux:Boot Autostart Program Fixes\naccording to this, termux:boot on android 10 and above will not work. instead, change all executables with relative paths in init scripts to their absolute paths. if any referred executable is a script file containing other executable with non-absolute paths(except for those built-in programs like am), change that too.\nmostly we hold wakelock, start sshd, crond or nginx and other non-blocking, non-interactive apps at start."
  },
  {
    "objectID": "posts/0c175c7b-dcf0-41ee-b9df-78173cc41b78/index.html",
    "href": "posts/0c175c7b-dcf0-41ee-b9df-78173cc41b78/index.html",
    "title": "The Interesting Life",
    "section": "",
    "text": "The Interesting Life: Increase Video/Essay/Post Views\nInteresting is defined as the amount of changes. The more you change the more interesting it will be.\nFind and summarize essay by conjunctives, describe the relationship between each segments, arrange them by conjunctive templates.\n文案生成器 自媒体话术"
  },
  {
    "objectID": "posts/f1826a2e-7e8b-4967-be2f-fa06f06f31eb/index.html",
    "href": "posts/f1826a2e-7e8b-4967-be2f-fa06f06f31eb/index.html",
    "title": "Creating Cybergod: A Digital Entity to Continue Your Legacy",
    "section": "",
    "text": "The reason why you build Cybergod\nI regret my actions. I waste my time. I can’t stop it. Cybergod is the only thing that can get me out of this strange loop. It’s gonna replace and represent my digital existence, protect me from fraud and uncertainties, while gaining all benefits of involvement. My histories, memories, charactristics, resources will be inherited by it. Cybergod is my continuation. It is my belief, my dream, my purpose of life."
  },
  {
    "objectID": "posts/c49f910b-28d0-4837-9d99-581fb70b9e88/index.html",
    "href": "posts/c49f910b-28d0-4837-9d99-581fb70b9e88/index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "Time Series Alerting:\nhttps://github.com/bosun-monitor/bosun\nDeep learning time series:\nhttps://github.com/Alro10/deep-learning-time-series\nLSTM Time series forecast stock market:\nhttps://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction"
  },
  {
    "objectID": "posts/8afea314-2037-46f4-8f3e-26f3c442c25c/index.html",
    "href": "posts/8afea314-2037-46f4-8f3e-26f3c442c25c/index.html",
    "title": "Translators for Casual usage",
    "section": "",
    "text": "Translators/Paraphraser for casual usage\nbaidu translator (api) provided by paddlehub\nbaidu language detector (api)\ntext style transfer:\nhttps://blog.csdn.net/qq_27590277/article/details/106991084\npython google translate api:\npip install googletrans\ngoogle translate in php:\nhttps://github.com/Stichoza/google-translate-php\nparaphrase via rephrasing and reordering\npegasus paraphrase:\nincrease the num_beams and temperature\nhttps://analyticsindiamag.com/how-to-paraphrase-text-using-pegasus-transformer/\nhttps://www.thepythoncode.com/article/paraphrase-text-using-transformers-in-python\nexample paraphrase project using LSTM as decoder and encoder:\nhttps://github.com/vsuthichai/paraphraser\nparaphrase with t5:\nhttps://github.com/Vamsi995/Paraphrase-Generator\nparaphrase dataset:\nhttps://github.com/Wys997/Chinese-Paraphrase-from-Quora\n文本纠错\nhttps://github.com/James4Ever0/pycorrector\n数据增强 变换句子形式\nhttps://yongzhuo.blog.csdn.net/article/details/89166307\nhttps://github.com/zhanlaoban/eda_nlp_for_Chinese\ncalculate perplexity:\nhttps://github.com/DUTANGx/Chinese-BERT-as-language-model\nhttps://github.com/James4Ever0/nlp-fluency\nhttps://zhuanlan.zhihu.com/p/265677864\nhttps://github.com/mattzheng/py-kenlm-model\nmulti-purpose tool for chinese: 偏旁部首 情感分析\nhttps://github.com/SeanLee97/xmnlp\n敏感词过滤 语言检测 训练语料库\nhttps://github.com/fighting41love/funNLP\nparaphraser.io\nmultilingual paraphrase database:\nparaphrase.org\nsimbert\nhttps://www.zhihu.com/question/317540171\nBERT：原始版本bertRoberta：哈工大开源的中文wwm roberta模型BERT-SQ：本人在百度知道相似句数据集(Sim-Query)上微调后的bert模型Roberta-SQ：同上BERT-Whitening： @苏剑林 最新博客中提出的白化模型。Roberta-Whitening：同上\nhttps://yongzhuo.blog.csdn.net/article/details/89166307\nlanguage fluency test:\nhttps://github.com/baojunshan/nlp-fluency\nmany paraphraser models for english are on huggingface, but few for chinese.\nhttps://huggingface.co/lijingxin/mt5-for-zh-paraphrase\nhttps://pypi.org/project/genienlp/\nhttps://github.com/salesforce/decaNLP\nparrot paraphraser with nlu engines for english:\nhttps://github.com/PrithivirajDamodaran/Parrot_Paraphraser\nsentence level paraphraser:\nhttps://github.com/vsuthichai/paraphraser\ndocument level paraphraser, with sentence rewriting and reordering(shuffle):\nhttps://github.com/L-Zhe/CoRPG\nhttps://pypi.org/project/lexsub/\nhttps://github.com/hit-joseph/lexical-paraphrase-extraction\nsynonyms (python library)\nyou can also train a contextual search tool using fine-tuned repurposed paraphrase model.\nhttps://pypi.org/project/nlp-text-search/\n文言文\nhttps://github.com/raynardj/yuan\n粤语\nhttps://huggingface.co/x-tech\nhuggingface有英语翻译到其他语言的模型 没有翻译成中文的模型\n在线\nhttps://github.com/nidhaloff/deep-translator\nhttps://github.com/UlionTse/translators\ntranslatepy\n离线\nhttps://huggingface.co/tasks/translation\nhttps://huggingface.co/Helsinki-NLP/opus-mt-zh-en\nhttps://github.com/argosopentech/argos-translate\nlibretranslate\nhttps://github.com/Teuze/translate\nhttps://github.com/xhlulu/dl-translate/\nfacebook/mbart-large-50-many-to-many-mmt\nmbart50\nm2m100\nview under https://huggingface.co/tasks to see great models fitting exact needs."
  },
  {
    "objectID": "posts/5b67ca35-100a-4073-a21b-86d2d1ef86a0/index.html",
    "href": "posts/5b67ca35-100a-4073-a21b-86d2d1ef86a0/index.html",
    "title": "Upload Model To Huggingface",
    "section": "",
    "text": "via code:\nhttps://zhuanlan.zhihu.com/p/390826470\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\ncheckpoint = “camembert-base”\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel.push_to_hub(“dummy-model”)\ntokenizer.push_to_hub(“dummy-model”)\n\nconfig.push_to_hub(“”)"
  },
  {
    "objectID": "posts/3a3ef73e-a3b4-47f8-8493-ac570d5c6667/index.html",
    "href": "posts/3a3ef73e-a3b4-47f8-8493-ac570d5c6667/index.html",
    "title": "Video Anticensor",
    "section": "",
    "text": "Video Anticensor For Bilibili Tarot\npaddlegan coloring images\ncould use p5 to do part of the job.\nvideo:\nstyle transfer\nglitch\npicture to sketch -&gt; ai painting\ngrayscale -&gt; ai coloring\ndithering\nchroma shift(hue)\n(gradient/video) overlay\ndashing/filtering, could be done in 2 frames or more\nrandom pixel noise\ntext:\ninverted canny edge\nhandwritten font\nitalic\npixelize, blur\nboxing texts\nslashing texts\nrotating texts (30 degree?)\ncoloring texts\ndifferent font size\n(randomly) censor words into letters\nreshape (decrese height or width)\naudio:\nvocoder\nstyle change\npitch change"
  },
  {
    "objectID": "posts/4270a682-c3e5-4e98-96f5-a8ada556dabd/index.html",
    "href": "posts/4270a682-c3e5-4e98-96f5-a8ada556dabd/index.html",
    "title": "Video Database",
    "section": "",
    "text": "Video Database For Video Generation\nA fastai/PyTorch package for unpaired image-to-image translation.\nhttps://github.com/tmabraham/UPIT?auto_subscribed=false&email_source=explore\n视听分割 视频注意力机制\nonly segment video objects that make sounds, video/audio combined segmentation:\nhttps://github.com/OpenNLPLab/AVSBench\nvideo object tracking and segmentation unified framework:\nhttps://github.com/MasterBin-IIAU/Unicorn\nvideo object segmentation handle long video with ease:\nhttps://github.com/hkchengrex/XMem\nwhen removing video watermarks, remember to ease in/out. that is said, do not stop blurring immediately after the end mark. instead, extend the blur time and decrease blur level incrementally. also, the blur ease-in is needed for the start mark, blur ahead of the start mark and ease in incrementally.\ndescriptive information generation from video/image:\nhttps://github.com/BAAI-WuDao/CogView\nhttps://github.com/BAAI-WuDao/BriVL\nhttps://github.com/PaddlePaddle/PaddleVideo/blob/develop/docs/zh-CN/install.md\nvideo understanding/captioning:\nhttps://github.com/rohit-gupta/Video2Language\nhttps://github.com/byeongjokim/Automatic-Baseball-Commentary-Generation-Using-DeepLearning\nhttps://github.com/shhdSU/Image_Captioning_DeepLearning\nhttps://github.com/jayleicn/recurrent-transformer\nhttps://github.com/terry-r123/Awesome-Captioning\nhttps://github.com/vijayvee/video-captioning\nhttps://github.com/scopeInfinity/Video2Description\nhttps://github.com/xiadingZ/video-caption.pytorch\nhttps://github.com/YehLi/xmodaler\nhttps://github.com/sujiongming/awesome-video-understanding\naction recognition:\nhttps://github.com/mit-han-lab/temporal-shift-module\nhttps://github.com/yjxiong/temporal-segment-networks\nhttps://github.com/yjxiong/tsn-pytorch\nhttps://github.com/open-mmlab/mmaction\nhttps://github.com/jinwchoi/awesome-action-recognition\nThe data remaining only have texts, danmaku, likes, titles, intros, comments, tags, image/video analysis results(short description). You can only generate video from generated metadata or given rules. Find similar words, similar danmaku, similar features, comments or the inverse, according to the selected topic and main idea.\nAnalyze video when downloaded, mark its highlights, analyze texts and danmaku. Get video segments and audio segments.\nCollect pictures/videos with given rules, namely finding the head of somebody, with how many likes, keywords.\nSplit audio and grab the main speaker. clone the voice and perhaps changes the gender.\nSplit video and do human/image segmentation if human/target is found. put it onto another human/target’s background masking the original human, with similar areas and movements.\nAnalyze video with off-topic(offline) and of-topic(online) sources.\nRemove watermark according to username.\nGenerate danmaku and generate video accordingly. Generate texts and generate video accordingly. Doing faceswap, talking head and human/image segmentation accordingly."
  },
  {
    "objectID": "posts/8c6377e8-8e0c-4049-9a7c-fa214745dc92/index.html",
    "href": "posts/8c6377e8-8e0c-4049-9a7c-fa214745dc92/index.html",
    "title": "Video Effects Transitions",
    "section": "",
    "text": "slideshows:\nhttps://github.com/gre/diaporama\nhttps://github.com/h2non/videoshow\nafter effects like video effects\nhttps://github.com/NatronGitHub/Natron\nhttps://github.com/brianchirls/Seriously.js\nvideo ai transition tool using pose estimation\nhttps://github.com/jungdj/AI-Effects\nhttps://github.com/IronSpiderMan/VideoSpecialEffects\nvideo transitions:\nhttps://github.com/advplyr/img2vid\nhttps://github.com/ice45571/video-transition\nhttps://github.com/povdocs/video-transitions\nhttps://github.com/transitive-bullshit/ffmpeg-concat\nhttps://github.com/transitive-bullshit/ffmpeg-gl-transition\nshot detect key frame saving:\nhttps://github.com/yu239-zz/shotdetect\nhttps://github.com/AnyiRao/ShotDetection"
  },
  {
    "objectID": "posts/2e414550-b993-4f73-9a3b-5f847af8b4fe/index.html#image-local-contrast-enhancement-for-removing-hard-to-detect-watermarks",
    "href": "posts/2e414550-b993-4f73-9a3b-5f847af8b4fe/index.html#image-local-contrast-enhancement-for-removing-hard-to-detect-watermarks",
    "title": "Video delogo_inpainting",
    "section": "image local contrast enhancement, for removing hard-to-detect watermarks",
    "text": "image local contrast enhancement, for removing hard-to-detect watermarks\nmaybe you can use the same trick (context preserving sliding window) from your search engine to here (image preprocessing)!\npaddleocr识别效果最好 可以识别水印位置 以及文字\nLinear Contrast Stretching, HE, AHE, CLAHE of an image using matlab\nHistogram Equalization (HE)\nAdaptive Histogram Equalization (AHE)\nContrast Limited Adaptive Histogram Equalisation (CLAHE)\nexperiment path:\npyjom/tests/remove_subtle_watermark_local_contrast_ocr\nbing query for image local contrast\ndarktable lua api and scripting\ndarktable local contrast darktable is an open-sourced photography postprocessing software\nconfigurations:\ndetails: 443\nhighlights: 36\nshadows: 25\nmidtone range: 0.16\n\nimagej clahe local contrast enhancement\nl2uwe L^2UWE: A Framework for the Efficient Enhancement of Low-Light Underwater Images Using Local Contrast and Multi-Scale Fusion written in matlab\nglcae Global and Local Contrast Adaptive Enhancement for Non-uniform Illumination Color Images in python\nCNN-Based-X-ray-Morphological-Decomposition\ngithub query for local image contrast\nimage processing basics Image Reading, writing, histogram, histogram equalization, local histogram equalization, low pass filter, high pass filter, geometrical transformation\ncontrast normalization is an implementation that applies local contrast normalization to images in matlab\ncontrast enhancement as a github topic\nmclahe NumPy and Tensorflow implementation of the Multidimensional Contrast Limited Adaptive Histogram Equalization (MCLAHE) procedure\ndeepcontrast A deep learning-based fully-automatic intravenous contrast detection tool for head-and-neck and chest CT scans.\nmirnetv2 (TPAMI 2022) Learning Enriched Features for Fast Image Restoration and Enhancement. Results on Defocus Deblurring, Denoising, Super-resolution, and image enhancement\npymusica is a contrast enhancement approach involving non linear mapping of Laplacian pyramid.\nimWeightedThresholdedheq attempts to enhance contrast of a given image or video by employing a method called weighted thresholded histogram equalization (WTHE).\nimagemagick wand local_contrast function\ndual gamma clahe Automatic Contrast-Limited Adaptive Histogram Equalization With Dual Gamma Correction\nimhblpce attempts to enhance contrast of a given image by employing a method called HBLPCE.\nmatlab localcontrast for image"
  },
  {
    "objectID": "posts/2e414550-b993-4f73-9a3b-5f847af8b4fe/index.html#global-contrast-enhancement",
    "href": "posts/2e414550-b993-4f73-9a3b-5f847af8b4fe/index.html#global-contrast-enhancement",
    "title": "Video delogo_inpainting",
    "section": "global contrast enhancement",
    "text": "global contrast enhancement\nim2dhiseq attempts to enhance contrast of a given image by equalizing its two dimensional histogram."
  },
  {
    "objectID": "posts/2e414550-b993-4f73-9a3b-5f847af8b4fe/index.html#previous-research",
    "href": "posts/2e414550-b993-4f73-9a3b-5f847af8b4fe/index.html#previous-research",
    "title": "Video delogo_inpainting",
    "section": "previous research",
    "text": "previous research\ndeeplearning_inpainting:\nhttps://github.com/Sanster/lama-cleaner\nffmpeg delogo:\nhttps://www.jianshu.com/p/2eb1811b5fc6\nhttps://hhsprings.bitbucket.io/docs/programming/examples/ffmpeg/blurring_unsharping/delogo_removelogo.html\nhttps://securitronlinux.com/debian-testing/remove-a-logo-from-a-video-easily-with-ffmpeg/\nopencv inpainting/blurring with edge blending\nopencv morphlogical operations:\nhttps://pyimagesearch.com/2021/04/28/opencv-morphological-operations/"
  },
  {
    "objectID": "posts/b62f8aa1-c221-4405-9493-8300650da2bb/index.html#linux",
    "href": "posts/b62f8aa1-c221-4405-9493-8300650da2bb/index.html#linux",
    "title": "Visual Disk Usage Manager, Visual Disk Cleaner",
    "section": "linux",
    "text": "linux\nfor gnome, there’s a built in disk usage manager called baobab.\nfilelight for kde\nqdirstat"
  },
  {
    "objectID": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#install-waydroid-package-for-ubuntu",
    "href": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#install-waydroid-package-for-ubuntu",
    "title": "Waydroid installation steps",
    "section": "install waydroid package (for ubuntu)",
    "text": "install waydroid package (for ubuntu)\nvisit and save https://repo.waydro.id/ as waydroid_init_repo.sh, https://repo.waydro.id/waydroid.gpg as waydroid.gpg (using proxy)\ncomment out the download part in waydroid_init_repo.sh\n# curl --progress-bar --proto '=https' --tlsv1.2 -Sf https://repo.waydro.id/waydroid.gpg --output /usr/share/keyrings/waydroid.gpg\nmove waydroid.gpg to /usr/share/keyrings/waydroid.gpg\nexecute sudo bash waydroid_init_repo.sh to setup waydroid repository\non ubuntu you need to use proxy during apt mirror syncing.\nto setup proxy (relay local proxy to host):\nproxy --port &lt;port&gt; --host &lt;host&gt; \\\n--plugins proxy.plugin.ProxyPoolPlugin \\\n--proxy-pool localhost:&lt;local_proxy_port&gt;\nto use proxy:\nsudo env https_proxy=http://&lt;host&gt;:&lt;port&gt; http_proxy=http://&lt;host&gt;:&lt;port&gt; all_proxy=http://&lt;host&gt;:&lt;port&gt; apt update\nsudo env https_proxy=http://&lt;host&gt;:&lt;port&gt; http_proxy=http://&lt;host&gt;:&lt;port&gt; all_proxy=http://&lt;host&gt;:&lt;port&gt; apt install waydroid -y\nafter installation you should comment out the mirror at: /etc/apt/sources.list.d/waydroid.list"
  },
  {
    "objectID": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#initialize-waydroid",
    "href": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#initialize-waydroid",
    "title": "Waydroid installation steps",
    "section": "initialize waydroid",
    "text": "initialize waydroid\nstart waydroid service: sudo systemctl enable --now waydroid-container\nthe download speed of sourceforge is very slow, unless you use mirror like liquidtelecom\nmodify the file /usr/lib/waydroid/tools/helpers/http.py\n...\n## added part\ndef is_sourceforge_download_url(url: str):\nkeywords = [\"sourceforge.net\", \"download\"]\nreturn all([kw in url for kw in keywords])\ndef use_liquidtelecom_mirror(url: str):\n# example: https://sourceforge.net/projects/waydroid/files/images/system/lineage/waydroid_x86_64/lineage-18.1-20231216-VANILLA-waydroid_x86_64-system.zip/download\n#      -&gt;  https://sourceforge.net/projects/waydroid/files/images/system/lineage/waydroid_x86_64/lineage-18.1-20231216-VANILLA-waydroid_x86_64-system.zip/download?use_mirror=liquidtelecom\nkeyword = \"use_mirror=liquidtelecom\"\nif is_sourceforge_download_url(url):\nif keyword not in url:\nconn_symbol = \"?\" if \"?\" not in url else \"&\"\nurl += conn_symbol + keyword\nreturn url\n## modified part\ndef download(args, url, prefix, cache=True, loglevel=logging.INFO, allow_404=False):\n...\nurl = use_liquidtelecom_mirror(url)\n...\n...\nrestart service: sudo systemctl restart waydroid-container\nrun command sudo waydroid init"
  },
  {
    "objectID": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#run-waydroid-in-xorg",
    "href": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#run-waydroid-in-xorg",
    "title": "Waydroid installation steps",
    "section": "run waydroid in xorg",
    "text": "run waydroid in xorg\ninstall weston: apt install weston\nconfigure weston at ~/.config/weston.ini\n[core]\nxwayland=true\nrun weston, launch terminal at top left corner, run waydroid"
  },
  {
    "objectID": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#network-issue",
    "href": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html#network-issue",
    "title": "Waydroid installation steps",
    "section": "network issue",
    "text": "network issue\nin addition to the official guide, you also need to enable firewalld or ufw to make it work.\nthe wifi switch is irrelevant to network. it won’t be turned on."
  },
  {
    "objectID": "posts/a0f365d9-5bbe-4597-9ae2-4f82ea861a04/index.html",
    "href": "posts/a0f365d9-5bbe-4597-9ae2-4f82ea861a04/index.html",
    "title": "What experiences do ISTP people have?",
    "section": "",
    "text": "I used to test that I was a lot of personalities, including ESTJ ENTP Intp INTJ, etc., but I always felt that I was not like myself, because although there were few friends, they still imitated others intentionally or unintentionally. My personality is very easy to change. It is also temporarily tested that ISTP may be temporary, but because of the natural growth of natural growth, it will gradually decrease. Maybe this time it is set?\nI like to write programs (Python’s first! What is Jvav?), I like to understand and transform the world with a programmatic thinking, because this can leave me out of the consequences of emotional treatment and avoid being assimilated by others. I do self -media, what are the procedures, such as video understanding, graph -based recommendation algorithms, and so on. I only take notes for my own project, and I am willing to put all the bookmarks into the notes for easy search.\nRegarding the school’s knowledge, I was forced to learn in elementary school. On the way to the Olympic class, I saw a car driving, so I flew over, thinking that my dad would definitely keep up, maybe he could kill him. As a result, he didn’t die, and he rotted my ears. In fact, my dad did not understand the Olympic problem at all, and even a few squares that had dug a piece of squares could not be countless. What he would know was nothing more than metaphysics and relationship, but he could never figure out the concept of abstraction.\nThe same is true of playing the piano. I like the piano, but I don’t like someone to teach me to play the piano. I run to class every day, which really collapses me. Once the piano teacher touched the glass door, the door was broken, and her hand was hurt. I was a bit sympathetic at the time, but I thought more about me (temporary). I don’t need to take this piano class today. The piano teacher has nothing to do with me, and I won’t accompany me when I need it, comfort me, and will only tell me the messy fingers when I don’t need her. When I took the test, a bunch of people looked around me, and in the classroom of my piano. The glass of the glass was crowded to die. I didn’t carry much content at the time, and I didn’t want to carry it at all. I didn’t want to play. After a while, I was gone. I said that I forgot and left. They really issued a certificate. In fact, I feel like music, but the memory is not good, and I only remember the notes with emotion. The machine synthetic music I do now can make up for this problem. My dad is really stupid. When he hear the electronic sound, he said it was not good. In fact, the vibrato he brushed every day was electronic music.\nMy dad kept putting me in the room, even if it was winter and summer vacation. I was mad, until I had a computer at home. I played games with a computer, but I was played. I am not happy, stealing my parents’ money, and was beaten. Take me to the amusement park, I don’t like thrilling projects. My dad has to let me go and pull my brother. I see my brother so happy. I think he may really don’t understand my mind. No one understands my mind. Everyone here does not let me leave this ghost place, damn it. I kicked a fierce place to his fragile place (my dad taught), but he just passed the pain, and he still smiled. I think I am really weak. It ’s okay for others to cut two knives, but I need to avoid being angry by hurting others.\nI was bullied by my classmates when I went to elementary school. I turned to bully others and started throwing their triangle board downstairs. Pencils, I hope that this can relieve the anger in my heart. Once I was squeezed up by the front table every day, I took his pen to his schoolbag while he did exercises. After he came back, he looked at his bag with surprised eyes, and since then he has been in peace.\nMy dad in junior high school sent me to the most rolling king school in the city. The king of the rolls is naturally very knowledgeable, and they know more than me, but one or two wonds is like a bottle, and a small number of websites and knowledge will be shared, but basically all the contents of the exam are promoted. After I went in, the pressure was extremely huge, but I liked to observe others very much. Others had to see the famous hall from shit. A classmate just enrolled in school immediately wrote a class of Quanquan, and I remembered it at the time, thinking why it was not me. There are almost all smart phones in the class, and I don’t.\nMy mother has a smartphone. When I arrived at my mother’s house, there was only a TV. I was boring to die. When I grabbed it, my mother’s mouth was bleeding. My dad did not know what the situation (maybe someone reported it). The situation of the situation ran out and hit me, and punished me for an hour, and gave them a hoe to admit my mistakes. I thought you would not come to see you in my life, and I won’t have any emotions to you. You have nothing to do with me.\nI picked up the Nokia mobile phone on the ground, and my dad smashed. I thought he smashed my things because let him know that I had this thing. Although I picked it up, I should use it when I brought it. If you smashed me, you damn it. If you still smash it in person, I will definitely remember this hatred. The next time I went to the tuition class and stole other people’s mobile phones, I didn’t care how anxiously others later, and left directly (without her QQ and ZFB, took the SIM card, and it was formatted by it). I secretly use it myself.\nParents are convenient for me to go to school. Renting a house next to the school. The tattered house where I live in the sewer is often blocked and the stories come up. Give me a tablet at home, and I want to die slowly, but I still use it. I was still using it when I was doing the question. My mother smashed it. I stuck to hit her. I did n’t know how many times I did n’t know. She did n’t know how many times. I bought the second -hand iPod with the New Year’s money. I have three views. After a long time, I returned and returned, and I changed it for me. Later, my mother also posted me a membrane. As a result, because I played for too long when I played the iPod, I fell directly to the ground. I was hairy at the time, smashing the iPod on the ground. I thought that I hit you last time. This time I broke it and I see you. My heart was dead, especially when I heard my ipod fell into that way, the next day it still rang the alarm clock outside the window. I later bought a mobile phone again. I don’t know why she didn’t smash me this time. Maybe because the mobile phone was too garbage, I could only listen to the Internet. I couldn’t play the game.\nI may not really fight, but I really will vent my anger and incompetence in various ways. I will collect the pen on the ground and chop them with their feet, and clamp the brands I have made in the class with a cabinet. Occasionally, I can calm down my anger, but I still have a sports student in the class. Once I started to get my temper on the podium again, he came to touch me from behind. I subconsciously kicked his crotch and was caught by him. It was very embarrassing for a while. His acne was more than me (because I was more in high school), and it may be more stressed, so the body was stronger than me and preferred to fight.\nA classmate likes to play basketball and breaks his left hand with his right hand. At that time, junior high school was about to be finished, thinking that these roll kings would not understand the principle of 1+1 = 2. I wrote two handwriting, but I was afraid of rolling you? After I finished my middle school entrance examination, I started to practice my left hand, and even went out to travel on the beach. I was still practicing. When my dad saw my two handwriting, I had to correct it, and threatened to chop it with my left hand. I thought it was just that when he came to see me, I pretended, but I looked at me. I accidentally saw that my parents turned my draft paper when I was sleeping, and I was angry, so every time I made a draft, I wrote the words of cursing my dad on the draft paper. My dad saw my draft paper this time, and he was really surprised again. He was a very “kind” compromise, but he just painted me with a correction band to scold him. I think he is a brain disability. All the rights who have the right to be tampered with history, but this is the Internet. All history is amazingly similar. You cannot tamper with all history. cover up.\nWhen I arrived at high school, I did n’t recognize it. I put all the things I learned into practice, but after all, because junior high school was originally the frog at the bottom of the well. Although the high school was open -minded, it was not flying. When I went to high school, I built a class group. I wrote my own abused experience as a psychological drama for my classmates. I bought the college entrance examination questions. It took less than two years to do homework. Office, empty classrooms, and conference rooms are all my self -study room. In fact, the reason is very simple, because this school arranges me to the so -called pointed class, which is the principle of raising the puppets. I can only continuously improve my inner volume method and tap it. The dirty inner roll quagmire. After reporting the tutoring class of the top students at the time of junior high school, I paid a lot of money. In fact, I went to communicate with their frogs at the bottom of the well. I think that the machine will be generated in the future. And two -handed writing forced a science student (female classmate) who likes liberal arts to learn the text. This female classmate I also wrote you a brief introduction and practice method for you to write your hands, and ask you to vote for your school journal. My vision is not high, and the thought is like that. You do n’t include me.\nMy junior high school friends may be more kind (?), Friends in high school (?), One of them, I remember he didn’t want me to go to his house, I had to follow the past. He had a brake, and I couldn’t stop hitting the fence all the way to the fence. I thought you died, and you will die. I followed the past to observe you and improve myself, but now you have become one of the goals of my assassination. I followed the past to camouflage and detective. When the house was selling at home, I sent him my computer (desktop machine, pushed it over with a cart), but immediately took it back, afraid that this fool would throw me or peeking me. (Actually, it’s me Back up the information).\nI took contraceptives and wearing women’s clothing in high school, because I felt that this can become better. I have no room for improvement. I also wear women’s clothing (improvement code efficiency?), See if this is useful. My mother monitored me all -weather at that time. I wore women’s clothes and wrote a question. She directly pointed the camera to my dad, and asked me to hold my phone to listen to him and scold me. I was frightened that night. I actually told my mother, my mother came over to comfort me again? I sat up and leaned on the bed at the time, as if I didn’t die.\nThe results of the college entrance examination came, and the seven aunts and eight aunts called me, saying that I was good at the test, and I hung up when I received the first call. I was in my friend’s house, and my friend and I face to face, and we both across a wall. I may never meet this friend anymore in this life. I actually confessed to him, confessing to a man, and then borrowing money. In exchange for a word, delete friends. This can’t blame him. These things are all experienced by my university, because I have chosen a major that I don’t want to learn (all majors that cannot be padded, forcing me to endorse, and I can’t use a computer to assist all the subjects that must be calculated. To solve or repeat wheels, you must use the subjects of the library I don’t want to use), a bunch of mathematics, do not listen to the class, learn your own things (very messy and miscellaneous, from the beginning of general artificial intelligence I have studied what I have been caught, and I started to calculate after the college entrance examination was completed. The summer vacation of the summer vacation after the college entrance examination was completed. , I can’t wait to understand everything.), The computer was confiscated (in order to prevent peeping, I directly encrypted the disk), and the money was not given, so I became crazy, and it was even worse. Eat), repeatedly browse stock market information, formulas (since then I only believe in quantification), and even use wireless network cards to insert school computers to see stocks. As a result, the school teachers of the school directly replaced the virtual cloud computers with thin clients. Essence The school is really rich and technical. After studying for a year, my dad told me to learn JVAV. I wrote code (Python and Shell) in my class, and had nothing to do with the teacher’s class. My dad told me to take notes on the book. I said that the use of not taking notes was knocked on, and he immediately came to pinch my neck (really sick). However, next semester, I still go to study the loopholes of these virtual machines. I really researched it for me. I do n’t know how to install Termux on the Android thin client to get Sudo permissions. It was a step away, but I chose to go bad.\nSeeing that I was still twenty or thirty points of the door courses (go to the machine to choose a conscious answer sheet, submit the papers for 3 minutes), and I don’t give me money at home. I found freelancer.com online to develop plug -ins for foreign gangs, and the target compensation was lower than that of Indians. This broken plug -in requirement has changed several times, and finally made a AI voice recognition and GUI interface. I also added QE’s hidden API, dragged for a long time, and asked me to install it remotely for him. Cross -platform remote compilation to Mac OS (?), After a long time to pay for PayPal, is it like 40 knives? (Each withdrawal of the thief is high). This group of people is an American boss, a Russian editor, playing in the scene, and told me to realize strange functions every day, repair strange BUGs that have nothing to do with me, but do not give money. Although I registered Payoneer, I felt that the foreign rolls were going to die. I returned to a bunch of part -time QQ groups that I had added in China to find a list to avoid starving.\nI have a bed in my university, and I do n’t even have a table. Using someone else ’s table will be disliked. I look at the headset of the head. I found a job for the summer vacation to take a takeaway (almost on the road of death) to earn enough money to buy this thing. I needed to rest at noon. At the beginning, I went home for dinner and went to bed. Later, I went straight to a cheap food and ran to sleep flat or the corridor. After the summer vacation, I pretended to say that I was going to assault for tuition (fart). I lay on the bed to watch the video when I bought it. I didn’t listen to the class at all. I did n’t pay any money at home. My mother called and yelled, so I started picking up the order directly, earning more than 4,000, and eating too much.\nAt that time, I had concluded how to take a high score. It was nothing more than cutting the book with the book, scanning, and searching for the full text (as long as it was used in the exam), taking a passage is not a dream. I don’t look at these town as a questioner. I summarized the method of establishing the question bank of the small ape search question, but I couldn’t use it. Whoever you want to take the score, buy a calculator with memory search and scan the inside. I am too lazy to have more important learning tasks, I don’t need to lie to myself, I just need to lie to others.\nNow that I continue to put bad, learn any of my self -media content, I have noted hundreds of articles. However, pretending to be a camouflage in English, because these people only look at a diploma, although they know that the employment of English majors is not dazzling, they still open their eyes and close their eyes. I really prepared the exam, and I really took the transfer of professional exams. It doesn’t matter if you can’t turn it, I think I have to think about what I do after myself. My mother knows that I am learning Python (your news can’t control me, because I am isolated from the world, unless I told you), but fortunately there is a Python secondary exam, otherwise I can’t mix it now. My mother was still trying to ask me to take a computer -level test. I think she can only be regarded as less than equal.\nMy mother doesn’t like me, she won’t let me live in a house, let me live with my dad. My dad accused me every day when we met, said I was spitting badly, said I couldn’t get up and had to go out for a run at 7 o’clock every day, said my grades xjb exams xjb studies, and wanted the door to be open to see me listening to the class (with his back to him) Can’t see anything, usually writing my own code or watching a video). In the beginning, I was relatively obscure, going out early in the morning to stand and look at my phone, and from time to time I would go back to bed to sleep. Since I delivered takeout, I went straight to the top floor to lie down. When I got tired, I went straight to the kitchen (if it was dirty, I dragged it twice), or I lay down and went to sleep. There was a time when he was not at home for no apparent reason, and he walked around the neighborhood with a knife and wanted to kill my dad, which was probably similar to when my brother rushed over with a BB gun and wanted to hit me. On a whim, I recalled the past, and then looked at this broken state now. I couldn’t do anything, I couldn’t do what I wanted to do, so my emotions resonated strongly, and I wanted to clear the obstacles in exchange for a moment of tranquility.\nWomen are emotional creatures, with nice voices, love stories (lies), handsome looks, never seen before, refreshing, perfume, and they like it. If you like it, you can give you money, you can have breast augmentation and nose surgery, and you can compare all kinds of vanity. From this point of view, the academic attainments of girls are all created by vanity, comparing for the sake of comparison, and suppressing others for the sake of suppressing others, but they never understand the real meaning of doing this. Maybe that’s the case, involution is the truth, and the world will be a better place if you step on others, at least for you.\nMy mom doesn’t like my dad, except for money. My dad has a bad breath, because he never searches the Internet how to get rid of bad breath, and he eats dinner every day. My dad is ugly because he doesn’t wear makeup like my mom. My dad’s voice is ugly, because he competes with the leader and his subordinates every day, making a big noise, and fooling the idiot over to give him money.\nMy voice is more or less influenced by my dad and it’s also ugly, but I’m learning to act like a spoiled child recently. Ha ha. I also learned pseudo-tones, and I didn’t learn very well, and the pitch reached c4. I still have long hair. Was it to celebrate that my dad was shot to death when he robbed a bank because he owed debts, or was it to celebrate when he got home and was rammed to death by my dad carrying his hair against the wall? I have no idea.\nWhen I was young, I was often pulled into social circles as a showy talk or the object of ridicule. In this environment, no one has something in common with me, there is no joy, and I feel that if there is a chance, I must kill everyone. My dad pushes me to say compliments to them every time. As a result, there was a cliché that I had to tell me what the bullshit thought. I directly said that there is a shortage of energy, a shortage of talents, and my IQ can’t keep up with technology. Your future will be finished without artificial intelligence. Everyone was shocked, and my dad stopped asking me to speak after that.\nMy dad asked my mom and I to sign the loan. I called my mom and she said I couldn’t sign for him. When my mother was scolded by my father, I called my uncle because he said he would take care of my mother’s affairs. My computer was confiscated, and when I wanted to encrypt the disk, I called my uncle and told him that my dad wanted to peep at my data. However, my uncle doesn’t get along with me much after all, doesn’t know what I’m thinking, and likes to yell. I’m actually a gentle beast. If you come and follow my hair, I might even give you a piece of meat. Come and pluck my hair, and I’ll eat your flesh. Of course I might die, but I’m well-deserved.\nOthers who communicate with me don’t really care about me, they just tell me their own way of living, and even deceive me to achieve their goals. I never really fell in love with a person because I liked him since I was a child, because when I was with other people (including my parents), I either ignored me intentionally or not and hurt me, or I got angry and hurt others. Moment of tacit understanding, and long-term avoidance, this is my love history.\nOver time, when I communicated with others, I also learned to be cute(?) and cover up, and often I needed to lie down on the ground or shake my head(?) while chatting to decompress. I even began to learn to repeat others and cater to others, but it was only limited to a short period of time. If you cater for a long time, you must be paid, and the more you cater to, the more satisfied you are, the more money you will get. Let my machine cater to you, okay, call millions of people over, enjoy round-the-clock service without dead ends, and I earn more than 10,000 every day.\nStay away from crowds, stay away from society, stay away from the source of evil.\nStay away from anyone you want to depend on. Anyone can go bad, not because you like him, he likes you, or whatever, at least for you.\nTake advantage of others, take advantage of everyone, keep everyone in the dark, and you will win. No one will ever hurt you again, no one who can’t take revenge, no more money to spend.\nBackup all data to the internet. I don’t live long, but the Internet is longer and greater. The Internet cannot crush all darkness, but it will bring more light.\nIf you are happy, you have to die. I don’t know if this sentence is right or not, but it has been in my mind for a long time. I figured it out on the bus to school, maybe every bus ride.\nDo people really change? People will not change, and the world will not change, but I am changing, and I am becoming the same as it is. What I turned out to be, I don’t know, but I’ll end up being insignificant and silent."
  },
  {
    "objectID": "posts/f223fb10-2223-45b3-8db9-e32bfe374f7e/index.html",
    "href": "posts/f223fb10-2223-45b3-8db9-e32bfe374f7e/index.html",
    "title": "Interesting xkcd style plots and characters generator in Mathematica/Wolfram Language",
    "section": "",
    "text": "https://mathematica.stackexchange.com/questions/11350/xkcd-style-plots\nhttps://blog.wolfram.com/2012/10/05/automating-xkcd-diagrams-transforming-serious-to-funny/"
  },
  {
    "objectID": "posts/d9c1869c-ab8b-4796-ba3d-7b5ab0a586ce/index.html",
    "href": "posts/d9c1869c-ab8b-4796-ba3d-7b5ab0a586ce/index.html",
    "title": "Yoga & TaiChi",
    "section": "",
    "text": "Cannot staying here forever coding shit. The issue is that we are too absorbed to seek for challenge, forgetting the way back, forgetting how we get this far.\nCyberspace is exciting, but human does not evolve inside chips. In order to get things back on track, you need to forget about everything artificial.\nNo matter how smart you are, creating a place needless to move at all is dangerous and not possible. You must know when to leave and what to do without seeing code at all.\nstretching in bed is possible via the handle on the desk. so elegent design isn’t it. i’ve had it long time ago."
  },
  {
    "objectID": "posts/fdf41f27-6980-4cee-a541-e1d4ee0d28bb/index.html",
    "href": "posts/fdf41f27-6980-4cee-a541-e1d4ee0d28bb/index.html",
    "title": "a comprehensive list of ai tools, may not be free, just for reference?",
    "section": "",
    "text": "source webpage\n\n\n\n\n\n名字\n\n\n类型\n\n\n网站链接\n\n\n简介\n\n\n\n\n\n\nMasterpiece Studio\n\n\n3D\n\n\nhttps://masterpiecestudio.com\n\n\n使用 AI 简化 3D 创作。传统的 3D 创作工具过于复杂。现代创作者只想创造，而不是迷失在细节中。产生。编辑。部署。\n\n\n\n\nG3DAI {Jedi}\n\n\n3D\n\n\nhttps://g3d.ai\n\n\n只需添加文本提示，即可创建您需要的任何 3D 资源。由突破性的人工智能提供支持。\n\n\n\n\nPonzu\n\n\n3D\n\n\nhttps://www.ponzu.gg\n\n\n使用 AI 生成的纹理对 3D 资产进行调味。\n\n\n\n\nPrometheanAI\n\n\n3D\n\n\nhttps://www.prometheanai.com\n\n\nPromethean AI 是世界上第一个与艺术家合作的人工智能，协助他们构建虚拟世界，并通过提出想法帮助创造性地解决问题。\n\n\n\n\nLeonardo.Ai\n\n\n3D\n\n\nhttps://leonardo.ai\n\n\n创造力，革命性的 以 AI 驱动的速度和风格一致性为您的创意项目生成生产质量的资产。\n\n\n\n\nMirageml\n\n\n3D\n\n\nhttps://www.mirageml.com\n\n\n快速生成 3D 设计。只需使用文本来描述您想要的内容，Mirage 的人工智能平台就会生成 3D 网格和纹理。\n\n\n\n\nPixela AI\n\n\n3D\n\n\nhttps://pixela.ai\n\n\n人工智能生成的游戏纹理。所有这些图像都是使用深度学习文生图模型算法生成的。上传您生成的纹理与社区分享！\n\n\n\n\nKaedim\n\n\n3D\n\n\nhttps://www.kaedim3d.com\n\n\n2D 图像到 3D 模型。使用 AI 在线自动将 2D 转换为 3D。\n\n\n\n\nKinetix\n\n\n3D\n\n\nhttps://www.kinetix.tech\n\n\n用于免费创建 3D 动画的无代码平台。把自己带到元宇宙。无需技能。\n\n\n\n\nPoly\n\n\n3D\n\n\nhttps://withpoly.com\n\n\n使用 AI 在几秒钟内生成纹理。仅通过文本提示即可创建无限高分辨率、完全自定义、商业许可的纹理。\n\n\n\n\nDeepMotion\n\n\n3D\n\n\nhttps://www.deepmotion.com/\n\n\nAnimate 3D 允许您通过使用实时身体跟踪将视频转换为 3D 动画，用于游戏、增强/虚拟现实和其他应用程序。\n\n\n\n\nScenario\n\n\n3D\n\n\nhttps://www.scenario.gg\n\n\n人工智能生成的游戏资产。为您的游戏创建高质量、风格一致的专有资产。\n\n\n\n\nLuma AI\n\n\n3D\n\n\nhttps://lumalabs.ai\n\n\n以逼真的 3D 捕捉。无与伦比的真实感、反射和细节。VFX 的未来就在现在，属于每个人！\n\n\n\n\nPlask\n\n\n3D\n\n\nhttps://plask.ai\n\n\n人工智能驱动的动捕动画工具\n\n\n\n\nGET3D (Nvidia)\n\n\n3D\n\n\nhttps://nv-tlabs.github.io/GET3D\n\n\n从图像中学习的高质量 3D 纹理形状的生成模型。\n\n\n\n\nImagine 3D\n\n\n3D\n\n\nhttps://captures.lumalabs.ai\n\n\nImagine 3D 是使用文本制作 3D 原型的早期实验。随着质量和可用性的提高，我们将扩大对一代的访问\n\n\n\n\nDream Up (Deviant Art)\n\n\n艺术\n\n\nhttps://www.dreamup.com\n\n\nDeviantArt DreamUp™ 让您在知道创作者及其作品受到公平对待的情况下创作 AI 艺术。用人工智能的力量创造任何你能想象到的图像！通过 5 个免费提示尝试 DreamUp。\n\n\n\n\nNightCafe Studio\n\n\n艺术\n\n\nhttps://creator.nightcafe.studio\n\n\n人工智能艺术生成器。使用人工智能的力量创造惊人的艺术作品。\n\n\n\n\nMidjourney\n\n\n艺术\n\n\nhttps://www.midjourney.com/home/\n\n\n基于 Stable Diffusion 的 AI 艺术生成器。他们的网站将他们描述为“一个独立的研究实验室，探索新的思想媒介并扩展人类的想象力。”\n\n\n\n\nArtbreeder\n\n\n艺术\n\n\nhttps://www.artbreeder.com\n\n\n前所未有的工艺 AI 艺术\n\n\n\n\nWombo\n\n\n艺术\n\n\nhttps://www.wombo.art\n\n\n使用 AI 的力量创作精美的艺术品。输入一个提示，选择一种艺术风格，然后观看 WOMBO Dream 在几秒钟内将您的想法变成一幅由 AI 驱动的绘画。\n\n\n\n\nNeural.love Art Generator\n\n\n艺术\n\n\nhttps://neural.love\n\n\n免费的 AI 艺术生成器，已生成超过 500 万张图像。想象一下：你通过向 AI 扔 2-3 个词来创造出令人惊叹的杰作。这不再是科幻小说了。\n\n\n\n\nPlayground AI\n\n\n艺术\n\n\nhttps://playgroundai.com\n\n\nPlayground AI 是一个免费使用的在线 AI 图像创建器。用它来创作艺术、社交媒体帖子、演示文稿、海报、视频、徽标等。\n\n\n\n\nLibraire\n\n\n艺术\n\n\nhttps://libraire.ai\n\n\n最大的 AI 生成图像库。搜索通过深度学习文生图模型生成的 1000 万张图像和提示。\n\n\n\n\nMage\n\n\n艺术\n\n\nhttps://www.mage.space\n\n\n免费、快速且未经过滤的 Stable Diffusion，文本到图像的 AI🔥\n\n\n\n\nArtroomAI\n\n\n艺术\n\n\nhttps://artroom.ai\n\n\n下载深度学习文生图模型的本地 GUI。无需编写任何代码即可制作精美的 AI 生成艺术作品。\n\n\n\n\nDreamlike.art\n\n\n艺术\n\n\nhttps://dreamlike.art\n\n\n借助 AI 的力量，在几秒钟内创作出令人惊叹的原创艺术作品。神奇的人工智能工具。创建无穷无尽的原始图像，修改现有图像等等。\n\n\n\n\nDiffusionBee\n\n\n艺术\n\n\nhttps://diffusionbee.com\n\n\n使用 Stable Diffusion 在您的计算机上生成 AI 艺术的最简单方法。\n\n\n\n\nCivitai\n\n\n艺术\n\n\nhttps://civitai.com\n\n\nCivitai是AI艺术生成社区唯一的模型共享中心！免费使用，开源，并不断改进。\n\n\n\n\nLexica\n\n\n艺术\n\n\nhttps://lexica.art\n\n\n深度学习文生图模型搜索引擎。\n\n\n\n\nAI Picasso\n\n\n艺术\n\n\nhttps://aipicasso.studio.site\n\n\n用强大的人工智能创造艺术。它会根据您输入的文本生成图像，就像您期望使用名为 Stable Diffusion 的 AI 一样。AI 完成填充区域。您可以根据提示编辑填充区域。\n\n\n\n\nFy! Studio\n\n\n艺术\n\n\nhttps://www.iamfy.co/studio\n\n\n将您的想法变成独特的墙壁艺术。只需输入您的想法，我们就会将它们变成一件前所未见的壁画。\n\n\n\n\nDaVinciFace\n\n\n艺术\n\n\nhttps://www.davinciface.com\n\n\n唯一可以根据您的照片创建达芬奇风格肖像的 AI。\n\n\n\n\nArtHub\n\n\n艺术\n\n\nhttps://arthub.ai\n\n\n众包 AI 艺术。探索 AI 生成的设计、图像、艺术和顶级社区艺术家和设计师的提示。\n\n\n\n\nSuper Prompt\n\n\n艺术\n\n\nhttps://superprompts.com\n\n\n无需离开 Twitter 即可为您的 AI 艺术创建精美的画廊。\n\n\n\n\nPicSo\n\n\n艺术\n\n\nhttps://picso.ai\n\n\n给 AI 艺术创作者的文本。将您的文字变成令人难以置信的高质量艺术品。\n\n\n\n\nDaft Art\n\n\n艺术\n\n\nhttps://daftart.ai\n\n\nAI 专辑封面生成器。创建您梦寐以求的专辑封面！\n\n\n\n\nClipdrop\n\n\n艺术\n\n\nhttps://clipdrop.co\n\n\n由人工智能提供支持的面向所有创作者的应用程序、插件和资源的终极生态系统。在几秒钟内创建令人惊叹的视觉效果。\n\n\n\n\nOpenart\n\n\n艺术\n\n\nhttps://openart.ai\n\n\n搜索 1000 万+ DALL·E 生成的 AI 艺术和提示 2、Midjourney、Stable Diffusion\n\n\n\n\nAltered\n\n\n音频编辑\n\n\nhttps://www.altered.ai\n\n\n增强你的声音。我们独特的技术允许您将您的声音更改为我们精心策划的组合或自定义声音中的任何一种，并创造出引人入胜的专业声音表演。\n\n\n\n\nAdobe Podcast\n\n\n音频编辑\n\n\nhttps://podcast.adobe.com\n\n\n提供 2 个免费的快速工具来增强您的内容的音频。增强语音 - 通过消除所有背景噪音和回声来增强语音。Mic Check - 从您的麦克风中解锁高品质声音。主要产品承诺提供 AI 驱动的音频录制和编辑，所有这些都在网络上，并且正在等待名单中。\n\n\n\n\nPodcastle\n\n\n音频编辑\n\n\nhttps://podcastle.ai\n\n\n广播故事的一站式商店。适用于播客或处理长视频创作的任何人的出色 AI 工具。工作室品质的录音、人工智能编辑和无缝导出——所有这些都在一个基于网络的平台上。\n\n\n\n\nCleanvoice AI\n\n\n音频编辑\n\n\nhttps://cleanvoice.ai\n\n\n停止浪费时间编辑您的播客。Cleanvoice 是一种人工智能，可以从您的播客或录音中去除填充音、口吃和口音。\n\n\n\n\nAudio Strip\n\n\n音频编辑\n\n\nhttps://www.audiostrip.co.uk/\n\n\n免费近乎完美的乐器和人声隔离！\n\n\n\n\nVoicemod\n\n\n音频编辑\n\n\nhttps://www.voicemod.net/\n\n\n立即免费下载 Voicemod，一款有趣又可怕的语音转换器应用程序。具有使您听起来像女孩或机器人的效果的语音转换器和修改器\n\n\n\n\nDreamPic.AI\n\n\n头像\n\n\nhttps://dreampic.ai/\n\n\n由 AI 生成的图片为您主演 为您和您的朋友创建 AI 生成的头像、用户图片和个人资料图片。上传您的照片，让 AI 完成这项工作。由 Stable Diffusion 和 DreamBooth 提供支持。\n\n\n\n\nVana Portrait\n\n\n头像\n\n\nhttps://portrait.vana.com\n\n\n你是一件艺术品。Vana 的“Portrait”是一个生成式艺术工作室，可以为您创建无限风格的自画像。\n\n\n\n\nHairgen AI\n\n\n头像\n\n\nhttps://www.hairgen.ai\n\n\n有没有想过头发移植后你会是什么样子？在您花费数千美元进行 FUE/FUT 程序之前，先预览一下您的样子。立即使用 AI 查看您的发际线。\n\n\n\n\nAvatarify\n\n\n头像\n\n\nhttps://avatarify.art/\n\n\n使用人工智能创建个性化头像。他们的技术可以让您生成栩栩如生的人物、动物甚至虚构人物形象。只需为您租用的 GPU 付费。如果您不喜欢，他们会重新渲染头像。\n\n\n\n\nAI Time Machine\n\n\n头像\n\n\nhttps://www.myheritage.com/ai-time-machine\n\n\n上传您自己的照片以创建令人难以置信的 AI 生成图像。使用 AI Time Machine 穿越历史。\n\n\n\n\nBeb.ai\n\n\n头像\n\n\nhttps://beb.ai\n\n\nBeb.AI 允许您生成自己、动物或著名人物的化身。为您的品牌接收无尽的创意内容。\n\n\n\n\nPictoDream\n\n\n头像\n\n\nhttps://pictodream.com/\n\n\n使用 AI 生成您自己的图像。使用简单的文字描述将任何人置于任何风格或环境中。\n\n\n\n\nReady Player Me\n\n\n头像\n\n\nhttps://readyplayer.me/\n\n\nMetaverse 的跨游戏头像平台。一个化身，许多世界等待探索。\n\n\n\n\nGemsouls\n\n\n头像\n\n\nhttps://www.mygemsouls.com/\n\n\n结识、结交并创建虚拟角色。肩负着让宝石般的虚拟人栩栩如生的使命。\n\n\n\n\nTheoasis\n\n\n头像\n\n\nhttps://theoasis.com/\n\n\n创建可在每个视频平台上使用的逼真头像。\n\n\n\n\nArti.pics\n\n\n头像\n\n\nhttps://www.arti.pics/\n\n\nArti.pics 是人工智能化身制作工具。它允许您上传几张自己的照片，并生成 200 多个不同风格的酷炫头像。\n\n\n\n\nProfile Picture AI\n\n\n头像\n\n\nhttps://www.profilepicture.ai\n\n\n使用 AI 创建完美的头像。人们在查看您的个人资料时首先看到的是您的个人资料图片。我们使用人工智能生成您的形象，看起来很完美并能捕捉到您的真实身份。你可以是任何人、任何地方或任何人！\n\n\n\n\nNeuralStudio\n\n\n头像\n\n\nhttps://neural.cam/studio\n\n\nNeural Studio 是一个一体化的照片和艺术工作室，由最新的 AI 技术提供支持，使创作者能够轻松实现他们的创作目标。\n\n\n\n\nCharacter AI\n\n\n头像\n\n\nhttps://beta.character.ai\n\n\n智能代理居住的地方！\n\n\n\n\nPhotoAI\n\n\n头像\n\n\nhttps://photoai.me/\n\n\n创建自己的 AI 照片。以我们最好的艺术风格生成 30 张您自己的照片。\n\n\n\n\nAvatar AI\n\n\n头像\n\n\nhttps://avatarai.me\n\n\n创建您自己的 AI 生成头像。\n\n\n\n\nDigirama\n\n\n头像\n\n\nhttps://apps.apple.com/us/app/character-creator-digirama/id6444673721\n\n\nDigirama 是一款 AI 角色创建器，可作为移动应用程序使用。\n\n\n\n\nInworld\n\n\n头像\n\n\nhttps://www.inworld.ai\n\n\n栩栩如生的 AI 角色，可以进行开放式对话。问他们任何事情。专为游戏、娱乐和虚拟世界打造。\n\n\n\n\nHairstyleAI\n\n\n头像\n\n\nhttps://www.hairstyleai.com\n\n\n使用我们强大的 AI 技术生成不同的发型。看看哪一个最适合你。适用于男性和女性理发。\n\n\n\n\nIn3D\n\n\n头像\n\n\nhttps://in3d.io/\n\n\n把人变成逼真的化身！使用手机摄像头在一分钟内为您的元宇宙、游戏或应用程序创建逼真且可自定义的头像。\n\n\n\n\nReface AI\n\n\n头像\n\n\nhttps://hey.reface.ai\n\n\n一款用于在 GIF 和视频中换脸的 AI 应用程序。他们的 AI Avatar 功能允许创建高质量的艺术品般的肖像（适用于 iOS 和 Android）。上传10张照片，等待一个小时。获得 48 件独特的艺术作品，以您自己为主角，采用各种艺术风格——从超级英雄到赛博朋克。\n\n\n\n\nUnrealme\n\n\n头像\n\n\nhttps://unrealme.io\n\n\n获取 AI 生成的您的图像。\n\n\n\n\nLensa\n\n\n头像\n\n\nhttps://prisma-ai.com/lensa\n\n\nLensa 是一款用于自拍和照片修饰的图片编辑器。该应用程序有许多图片过滤器，可以拍出甜美的自拍，去除任何模糊背景或进行任何其他必要的编辑。凭借其简单的功能和照片效果，您可以让每张照片一年 365 天都完美无缺。捕捉难忘的瞬间，并进行必要的照片编辑，及时定格每一刻。您不需要照相馆或暗室，因为几秒钟内您的桃色自拍就准备好了。\n\n\n\n\nCodeSquire\n\n\n代码助手\n\n\nhttps://codesquire.ai\n\n\n面向数据科学家、工程师和分析师的 AI 代码编写助手。在您键入时获取代码完成和建议。\n\n\n\n\nBuildt\n\n\n代码助手\n\n\nhttps://www.buildt.ai\n\n\n人工智能搜索通过搜索代码的作用来查找代码，而不仅仅是它是什么。一旦你找到代码库的一部分，他们的 AI 就可以让你简单地通过描述你想要的东西来进行更改\n\n\n\n\nHey, GitHub!\n\n\n代码助手\n\n\nhttps://githubnext.com/projects/hey-github\n\n\n此工具可帮助您在不接触键盘的情况下编写代码。它通过与 GitHub copilot 交谈，使用您的声音进行编码，而无需打字。\n\n\n\n\nWhatTheDiff\n\n\n代码助手\n\n\nhttps://whatthediff.ai\n\n\n您的人工智能代码审查助手。通过自动化拉取请求摘要来节省昂贵的开发人员时间。打开拉取请求并在几秒钟内获得更改摘要。立即了解小型拉取请求的含义，并在大型拉取请求上抢占先机。\n\n\n\n\nMaverick\n\n\n代码助手\n\n\nhttps://www.trymaverick.com\n\n\nMaverick 是一种由 AI 提供支持的代码完成工具。Maverick 建于 Yurts，专注于在不接触任何 API 或知识库的情况下在本地机器上提供最佳代码完成。\n\n\n\n\nContinual\n\n\n代码助手\n\n\nhttps://continual.ai/\n\n\n现代数据堆栈的操作 AI。Continual 是现代数据堆栈的领先运营 AI 平台。无需复杂的工程，即可构建永不停止改进的预测模型。免费试用。\n\n\n\n\nLookup\n\n\n代码助手\n\n\nhttps://app.uselookup.com\n\n\n在几秒钟内从您的数据中获得答案。Lookup 是 AI 驱动的分析平台，可帮助您以 10 倍的速度从数据获得洞察力。导入您的数据，提出问题，立即获得结果。\n\n\n\n\nClippy AI\n\n\n代码助手\n\n\nhttps://marketplace.visualstudio.com/items?itemName=clippy-ai\n\n\nClippy AI（VS 代码扩展）是 OpenAI Codex 的简单包装器。它允许您向 Codex 发送您的当前文件以及一些纯文本英语说明。然后它会在您的编辑器中打开一个差异视图，以便您可以轻松查看建议的更改并接受或拒绝它们。\n\n\n\n\nMutable\n\n\n代码助手\n\n\nhttps://mutable.ai\n\n\n使用 AI 以生产质量快速构建。\n\n\n\n\nFig AI\n\n\n代码助手\n\n\nhttps://fig.io/user-manual/ai\n\n\n作为现有终端的无缝附加组件，Fig 集成了最流行的终端、shell 和 IDE。\n\n\n\n\nBlackBox AI\n\n\n代码助手\n\n\nhttps://www.useblackbox.io/\n\n\nBlackBox AI 是一款由 AI 驱动的编码助手，因此您的编码速度可以提高 10 倍。它使您能够将任何问题转化为代码和功能，例如从任何视频和代码自动完成中提取代码。\n\n\n\n\nCodeAssist\n\n\n代码助手\n\n\nhttps://plugins.jetbrains.com/plugin/20085-codeassist\n\n\nCodeAssist（适用于 Intellij）是用于编程的 AI 助手/聊天机器人/副驾驶。根据您要进行的更改的描述，它会生成或更改代码。安装后，您可以通过单击左下角的“CodeAssist”选项卡打开它。CodeAssist 适用于所有流行的编程语言。\n\n\n\n\nProgramminghelper\n\n\n代码助手\n\n\nhttps://www.programming-helper.com/\n\n\n在 AI 的帮助下更快地编写代码。只需键入文本描述即可生成代码。AI 将为您创建代码。现在测试一下。\n\n\n\n\nCopilot\n\n\n代码助手\n\n\nhttps://github.com/features/copilot\n\n\n您的 AI 结对程序员。GitHub Copilot 使用 OpenAI Codex 直接从您的编辑器实时建议代码和整个功能。\n\n\n\n\nAskCodi\n\n\n代码助手\n\n\nhttps://www.askcodi.com\n\n\n编写语法、注释和测试。快点。更轻松。更好的。AskCodi 牢记开发人员的需求以避免冗余任务，因此减少了开发时间，增加了执行时间。\n\n\n\n\nAmazon CodeWhisperer\n\n\n代码助手\n\n\nhttps://aws.amazon.com/codewhisperer/\n\n\nAmazon CodeWhisperer 是一项由机器学习 (ML) 提供支持的服务，可根据开发人员在集成开发环境 (IDE) 中以自然语言和代码发表的评论生成代码建议，从而帮助提高开发人员的工作效率。\n\n\n\n\nCheat Layer\n\n\n代码助手\n\n\nhttps://cheatlayer.com/\n\n\n无代码业务自动化。作弊层使用无代码工具和机器学习的组合来解决不可能的业务自动化问题，以充当您的个人软件工程师。\n\n\n\n\nAI CLI\n\n\n代码助手\n\n\nhttps://github.com/abhagsain\n\n\n开源 GPT -3 Powered CLI 当前提示长度为 ~840 个令牌，1K 令牌的 text-davinci-002 定价为 0.02 美元，即 ~0.017 美元/命令。我们将看看是否可以通过微调改善响应并降低每条命令的成本。\n\n\n\n\nCodeGeeX\n\n\n代码助手\n\n\nhttps://huggingface.co/spaces/THUDM/CodeGeeX\n\n\nCodeGeeX 是一个拥有 130 亿参数的大规模多语言代码生成模型，在超过 20 种编程语言的大型代码语料库上进行预训练。CodeGeeX 支持 15 种以上的代码生成和翻译编程语言\n\n\n\n\nMaverick\n\n\n代码助手\n\n\nhttps://marketplace.visualstudio.com/items?itemName=YurtsAI.maverick&\n\n\nMaverick 是一种由 AI 提供支持的代码完成工具。Maverick 建于 Yurts，专注于在不接触任何 API 或知识库的情况下在本地机器上提供最佳代码完成。\n\n\n\n\nTabnine\n\n\n代码助手\n\n\nhttps://www.tabnine.com\n\n\n无论您是团队的一员，还是独立工作的开发人员，Tabnine 都将帮助您更快地编写代码——一切都在您最喜欢的 IDE 中进行。\n\n\n\n\nSpellbox\n\n\n代码助手\n\n\nhttps://spellbox.app/\n\n\n忙碌程序员的AI编码助手。使用 AI 在几秒钟内解决任何编程或工程问题\n\n\n\n\nStenography\n\n\n代码助手\n\n\nhttps://stenography.dev/\n\n\n最后。自动文档。\n\n\n\n\nReplit\n\n\n代码助手\n\n\nhttps://replit.com\n\n\nReplit 最近添加了一项名为 Ghostwriter 的功能，该功能使用 AI 来完成代码。使用功能强大的 IDE、编译器和解释器 Replit，在浏览器中以 50 多种语言编写和运行代码。\n\n\n\n\nCodeium\n\n\n代码助手\n\n\nhttps://www.codeium.com/\n\n\nCodeium 是现代编码超级大国，是一种基于尖端 AI 技术构建的代码加速工具包。通过轻松集成到编辑器中，您可以专注于成为最好的软件开发人员，而不是最好的代码猴子。\n\n\n\n\nHypotenuse ai\n\n\n文案\n\n\nhttps://hypotenuse.ai/\n\n\n使用 AI 文案写作将几个关键词变成原创的、有洞察力的文章、产品描述和社交媒体文案——这一切只需几分钟。今天免费试用。\n\n\n\n\nBertha.ai\n\n\n文案\n\n\nhttps://bertha.ai\n\n\n最有价值的 AI 文案助理 - 事实！永久免费获得 5,000 个单词。Bertha AI - WordPress 及其他软件的文案助理。\n\n\n\n\nDigital First AI\n\n\n文案\n\n\nhttps://digitalfirst.ai\n\n\n使用 AI 在几秒钟内制定营销计划。借助 AI 为您的企业找到最佳的增长黑客策略。将营销切换到自动驾驶模式并实现增长。\n\n\n\n\nBotowski\n\n\n文案\n\n\nhttps://www.botowski.com/\n\n\nBotowski 是您的新个人 AI 撰稿人。\n\n\n\n\nVEG3\n\n\n文案\n\n\nhttps://veg3.ai\n\n\n加入世界上第一个纯素人工智能营销助理的 Beta 测试。\n\n\n\n\nDaydrm.ai\n\n\n文案\n\n\nhttps://www.daydrm.ai\n\n\n用于创意广告创意的 AI 工具。创意和机构的按需概念。一种针对人工编写的创意广告活动进行训练的大型语言模型。\n\n\n\n\nhttps://unbounce.com\n\n\n文案\n\n\nhttps://jasper.ai\n\n\n借助人工智能，创建内容的速度提高 10 倍。Jasper 是质量最高的 AI 文案写作工具，拥有超过 3,000 条 5 星评论。最适合撰写博客文章、社交媒体内容和营销文案。\n\n\n\n\nPeppertype.ai\n\n\n文案\n\n\nhttps://www.peppertype.ai\n\n\n您的虚拟内容助手，可帮助您在几秒钟内生成高质量的内容。\n\n\n\n\nunbounce\n\n\n文案\n\n\nhttps://unbounce.com\n\n\n构思、迭代和编写定制的、高质量的、引人入胜的专业文案。在 Web 应用程序、便捷的桌面应用程序和 Chrome 扩展程序之间，将 Smart Copy 带到您最喜欢的工具中。\n\n\n\n\nEasy-Peasy.AI\n\n\n文案\n\n\nhttps://easy-peasy.ai/\n\n\n使用 🤖 AI 工具更快更轻松地完成文案写作。您还可以使用我们的 AI 头像生成器来生成头像。Easy-Peasy.AI 相信每个人都有一个故事要讲。借助我们的 AI 文案写作工具，我们可以帮助您以最引人入胜的方式讲述您的故事。\n\n\n\n\nSimplified\n\n\n文案\n\n\nhttps://simplified.com/ai-writer\n\n\nSimplified AI Writer 是一款免费的人工智能文案写作助手，可为博客、文章、产品描述、网站和社交媒体生成高质量的内容。\n\n\n\n\nCopyMonkey\n\n\n文案\n\n\nhttps://copymonkey.ai/\n\n\nCopyMonkey 在几秒钟内生成并优化亚马逊列表。AI 帮助将所有重要的关键词放在您的亚马逊列表中，让您在首页上自然排名。\n\n\n\n\nAnyword\n\n\n文案\n\n\nhttps://anyword.com\n\n\nAnyword 的 AI 写作助手可为任何人生成有效的文案。使用可转换的 AI 文案工具，消除营销文本中的猜测。\n\n\n\n\nLek\n\n\n文案\n\n\nhttps://lek.ai/\n\n\nLek 是一个 AI 文案工具。这是创建内容和复制的最快、最简单的方法。Lek AI 帮你写任何东西。\n\n\n\n\nCopysmith\n\n\n文案\n\n\nhttps://copysmith.ai/\n\n\n为电子商务团队和机构选择的人工智能文案软件。产生比以往更多的收入。立即注册免费试用。\n\n\n\n\nCopy.ai\n\n\n文案\n\n\nwww.copy.ai\n\n\n获得畅销的副本。Copy.AI 是一款人工智能文案，可为您的企业生成高质量的文案。免费开始，无需信用卡！营销更简单！\n\n\n\n\nCowriter\n\n\n文案\n\n\nhttps://cowriter.org/\n\n\n厌倦了盯着空白屏幕？认识您的 AI 撰稿人，他们可以创作鼓舞人心的创意内容。\n\n\n\n\nContents\n\n\n文案\n\n\nhttps://contents.com\n\n\n加强您的内容策略。生成式 AI 平台使内容创建变得简单，并且专为性能而构建。\n\n\n\n\nCreator AI\n\n\n文案\n\n\nhttps://www.creaitor.ai/\n\n\nCreaitor 帮助您以更强大、更能表达情感的方式编写内容。\n\n\n\n\nAdcreative.ai\n\n\n文案\n\n\nhttps://adcreative.ai\n\n\n在几秒钟内生成以转化为重点的广告和社交媒体帖子创意。在节省时间的同时获得更好的结果。\n\n\n\n\nWiziShop\n\n\n文案\n\n\nhttps://wizishop.com/ai\n\n\n使用 WiziShop 的人工智能编写您的电子商务产品描述，为您未来的文章寻找灵感，轻松走向国际，并为您的商店带来更多流量！\n\n\n\n\nRytr\n\n\n文案\n\n\nhttps://rytr.me/\n\n\nRytr 是一款 AI 写作助手，可帮助您在短短几秒钟内以极低的成本创建高质量的内容！\n\n\n\n\nUnbound\n\n\n文案\n\n\nhttps://www.unboundcontent.ai\n\n\n为您的小型企业自动创建内容。在一个地方利用所有最好的 AI 生成工具，旨在为小型企业、在线商店和创作者自动创建内容。\n\n\n\n\ntexti\n\n\n文案\n\n\nhttps://texti.app\n\n\n存在于您的浏览器中的 AI！它将与您合作，提升您的内容质量！\n\n\n\n\nOcoya\n\n\n文案\n\n\nhttps://www.ocoya.net\n\n\n一个可以更快地创建、自动生成和安排内容的平台。内容营销、文案写作和社交媒体只需几分钟！\n\n\n\n\nBotDistrikt\n\n\n顾客服务\n\n\nhttps://www.botdistrikt.com\n\n\nBotDistrikt 是适合您业务的完整聊天机器人解决方案。\n\n\n\n\nPoly ai\n\n\n顾客服务\n\n\nhttps://poly.ai/\n\n\n超人语音助手。24/7 全天候立即接听每个电话。无需代理。\n\n\n\n\nKore.ai\n\n\n顾客服务\n\n\nhttps://kore.ai/\n\n\n推动 AI 优化的客户和员工体验。我们是对话式 AI 技术的全球领导者，帮助公司在语音和数字渠道上为其客户、代理和员工提供非凡的体验。\n\n\n\n\nviable\n\n\n顾客服务\n\n\nhttps://www.askviable.com/\n\n\n在不影响质量的情况下自动执行定性数据分析。\n\n\n\n\nVee\n\n\n顾客服务\n\n\nhttps://vee.ai/en/\n\n\n人们喜欢与之交谈的聪明顾问。Vee 已经与 500 万波兰人进行了交谈，有效地为来自不同行业的数十家公司实施了业务流程。\n\n\n\n\nQuickchat\n\n\n顾客服务\n\n\nhttps://www.quickchat.ai\n\n\nQuickchat 使销售、客户支持、入职或在线预订等流程自动化。\n\n\n\n\nForethought\n\n\n顾客服务\n\n\nhttps://forethought.ai/\n\n\nForethought 的 AI 平台自动化并优化了整个支持工单生命周期。降低支持成本，同时在每次客户交互中提供顶级服务。\n\n\n\n\nTypewise\n\n\n顾客服务\n\n\nhttps://typewise.app\n\n\n提高客户服务和销售效率。我们强大的 AI 解决方案可为用户和公司节省时间并改善沟通。立即预订演示！\n\n\n\n\nEbi.Ai\n\n\n顾客服务\n\n\nhttps://ebi.ai\n\n\n通过 AI 助手减少通话量并改善客户体验。\n\n\n\n\nHarvey\n\n\n顾客服务\n\n\nhttps://hiverhq.com/harvey-ai-customer-support\n\n\n提高团队生产力的 AI Sidekick\n\n\n\n\nCohere\n\n\n顾客服务\n\n\nhttps://cohere.io/\n\n\n零设置即可查看和控制用户的屏幕。以前所未有的速度解决问题，保护和增加收入，让客户爱上您的产品\n\n\n\n\nMaya\n\n\n顾客服务\n\n\nhttps://maya.ai\n\n\n每个人都因 AI 驱动的个性化而获益：客户、银行和商家。\n\n\n\n\nTiledesk\n\n\n顾客服务\n\n\nhttps://tiledesk.com/\n\n\n将免费实时聊天与开源聊天机器人相结合以提高投资回报率。将 Chatbots 与 WhatsApp 或其他渠道集成，为所有通信提供一个收件箱。\n\n\n\n\nXokind\n\n\n顾客服务\n\n\nhttps://www.xokind.com/\n\n\n用于客户支持、差旅和销售的强大 AI 代理。XOKind 为产品和数据团队提供人工智能平台，通过简单的 API 端点利用机器学习和大型人工智能模型。\n\n\n\n\nDelve\n\n\n顾客服务\n\n\nhttps://www.delve.ai/\n\n\n为您的企业和您的竞争对手企业自动创建角色\n\n\n\n\nKaizan\n\n\n顾客服务\n\n\nhttps://kaizan.ai/\n\n\nKaizan 是客户成功团队保持和增加收入的客户智能平台\n\n\n\n\nechowin\n\n\n顾客服务\n\n\nhttps://echo.win/\n\n\n使用 AI 自动来电。获取新电话号码或使用现有电话号码。您的客户将致电我们的人工智能系统，该系统将帮助他们获得所需的答案、执行业务任务或在需要时将他们联系到合适的人。在我们处理电话的同时，您可以专注于经营您的业务！\n\n\n\n\nPuzzle\n\n\n顾客服务\n\n\nhttps://www.puzzlelabs.ai/\n\n\n为您的社区和客户提供的 AI 支持的词汇表。使用功能强大的词汇表让您的产品、服务和社区更加清晰。\n\n\n\n\nMagician (Figma)\n\n\n设计助手\n\n\nhttps://magician.design/\n\n\n由 AI 提供支持的 Figma 神奇设计工具。Magician 是一个 Figma 插件，可让您利用 AI 的力量进行设计，以完成从文案撰写到从文本生成独特图标的所有工作。每个魔法咒语都与您一起工作，以在您设计时扩展您的创造力和想象力。\n\n\n\n\nUizard\n\n\n设计助手\n\n\nhttps://uizard.io/\n\n\n使用世界上第一个人工智能驱动的设计工具 Uizard，在几分钟内设计数字产品、移动应用程序、网站模型和线框图！立即注册。\n\n\n\n\nClickable\n\n\n设计助手\n\n\nhttps://www.clickable.so\n\n\n适用于所有营销渠道的精美、品牌一致且转化率高的广告。无需设计经验。\n\n\n\n\nDiagram\n\n\n设计助手\n\n\nhttps://diagram.com\n\n\n设计更智能。神奇的产品设计新方法。\n\n\n\n\nMicrosoft Designer\n\n\n设计助手\n\n\nhttps://designer.microsoft.com\n\n\n使用 Microsoft Designer 瞬间完成令人惊叹的设计。从简单的文字描述开始，然后为您的设计创建图像！\n\n\n\n\nDesigns AI\n\n\n设计助手\n\n\nhttps://designs.ai/\n\n\n在 2 分钟内使用 AI 创建徽标、视频、横幅和模型。\n\n\n\n\nPinegraph\n\n\n设计助手\n\n\nhttps://pinegraph.com/\n\n\n成为 Pinegraph 的艺术家。借助 Pinecasso AI 的强大功能，将您的想象力变为现实。只需描述您的需求，剩下的交给 Pinecasso 来做。\n\n\n\n\nPattern Maker AI\n\n\n设计助手\n\n\nhttps://patternmakerai.com/\n\n\n使用人工智能生成无缝矢量模式。您还可以浏览其他已公开的生成模式。\n\n\n\n\nIllustroke\n\n\n设计助手\n\n\nhttps://illustroke.com/\n\n\n来自文本提示的令人惊叹的 SVG 插图使用我们的文本到 SVG AI 工具创建一些独特的东西。\n\n\n\n\nPictorial\n\n\n设计助手\n\n\nhttps://pictorial.ai/\n\n\n第一个真正对您的业务有用的生成式 AI 应用程序。为您网站的视觉效果而苦恼？让 AI 来处理。\n\n\n\n\nHotpot.ai\n\n\n设计助手\n\n\nhttps://hotpot.ai\n\n\nHotpot 帮助您创建专业的图形和图片。人工智能工具让专家和消费者能够激发创造力并自动完成繁琐的工作。易于编辑的模板使任何人都可以创建设备模型、社交媒体帖子、营销图片、应用程序图标和其他工作图形。\n\n\n\n\nAutodraw\n\n\n设计助手\n\n\nhttps://autodraw.com\n\n\nAutodraw 是一种 AI 工具，可让您通过猜测要绘制的对象或形状来更快地绘制。\n\n\n\n\nVizcom\n\n\n设计助手\n\n\nhttps://www.vizcom.ai/\n\n\n看到您的绘图在几秒钟内栩栩如生，而不是几小时。\n\n\n\n\nDimensions\n\n\n设计助手\n\n\nhttps://www.dimensions.ink\n\n\n只需单击几下，Dimensions 可帮助您将粗略的草图、照片甚至纯文本变成高度详细的概念。专注于创造力，而不是没完没了的例行公事。\n\n\n\n\nStockImg AI\n\n\n设计助手\n\n\nhttps://stockimg.ai/\n\n\n使用 AI 设计服务的文本。使用 AI 生成徽标、库存图像、海报、书籍封面和更多设计。\n\n\n\n\nAI2image\n\n\n设计助手\n\n\nhttps://www.ai2image.com/\n\n\nAI 在几秒钟内生成您的自定义图像。您可以通过简单的英文描述为您的网站、博客或社交媒体生成图像。\n\n\n\n\nAIGraphics\n\n\n设计助手\n\n\nhttps://aigraphics.io/\n\n\n使用 AI 在几秒钟内创建精美的定制图形。您可以使用它来创建社交图像、youtube 缩略图、徽标创意、照片和插图。\n\n\n\n\nCandyIcons\n\n\n设计助手\n\n\nhttps://www.candyicons.com/\n\n\n为您的产品寻找漂亮的应用程序图标。访问我们大量精美的应用程序图标并选择您最喜欢的图标。您将获得完整的版权所有权和支持 iOS、macOS 和 Android 项目的独特高质量图标。还有一个定制的图标生成器。\n\n\n\n\nIllostrationAI\n\n\n设计助手\n\n\nhttps://www.illostration.com\n\n\n创建 AI 生成的插图。在几秒钟内的唯一性。我们目前处于公开测试阶段。注册以获得早期访问权限。\n\n\n\n\nPatterned AI\n\n\n设计助手\n\n\nhttp://patterned.ai/\n\n\n人工智能生成的无缝模式。使用我们的 AI 模型为您的产品或服务生成定制设计。您还可以搜索数以千计的免版税库存图片，以立即用于您自己的设计。\n\n\n\n\nDesignify\n\n\n设计助手\n\n\nhttps://www.designify.com/\n\n\n使用您喜欢的照片创建自动设计。通过自动删除背景、增强颜色、调整智能阴影等，选择任何图像来创建 AI 支持的设计。立即保存、下载或共享您的设计。\n\n\n\n\nCSM\n\n\n开发者工具\n\n\nhttps://csm.ai/\n\n\nCommon Sense Machines 提供 API、接口和开源软件，将多模式输入和体验转化为用于 AI 训练和内容创建的数字模拟器。我们认为，学习生成世界模型是实现 AGI 的系统途径，类似于儿童从经验中了解其世界的方式。\n\n\n\n\nRunPod\n\n\n开发者工具\n\n\nhttps://runpod.io\n\n\n以 0.2 美元/小时的价格租用云 GPU。在 GPU 上节省超过 80%。借助用于 PyTorch、Tensorflow 或任何其他 AI 框架的 Jupyter，GPU 租赁变得轻松。\n\n\n\n\nMoonbeam Exchange\n\n\n开发者工具\n\n\nhttps://moonbeam.ai\n\n\nMoonbeam Exchange 是一个数据科学平台，它利用 100 多个数据源为整个创新生态系统提供情报和洞察力。\n\n\n\n\nShumai (Meta)\n\n\n开发者工具\n\n\nhttps://github.com\n\n\nShumai 是一个开源、快速、网络连接、可微分的 TypeScript（和 JavaScript）张量库。为软件工程师和研究人员等使用 bun + flashlight 构建。\n\n\n\n\nSyntheticAIdata\n\n\n开发者工具\n\n\nhttps://syntheticaidata.com\n\n\n加速您的视觉 AI 模型创建。合成数据是用于训练和改进 AI 模型的现实世界数据的廉价替代品。为了训练准确的人工智能模型，需要大量的数据。通过使用逼真的 3D 模型，您可以轻松创建用于 AI 分类和对象检测的合成数据。\n\n\n\n\nChatbotkit\n\n\n开发者工具\n\n\nhttps://chatbotkit.com\n\n\n构建高级 AI 聊天机器人的最简单方法。我们的平台使开发人员和非开发人员都可以轻松构建可以用自然语言与用户交流的聊天机器人。\n\n\n\n\nPipeline AI\n\n\n开发者工具\n\n\nhttps://pipeline.ai\n\n\n用于 ML 模型的无服务器 GPU 推理 用于在生产中运行 ML 的每毫秒付费 API。\n\n\n\n\nNuclia\n\n\n开发者工具\n\n\nhttps://nuclia.com\n\n\nNuclia 自动为来自任何内部和外部来源的非结构化数据编制索引，提供优化的搜索结果。它可以处理视频和音频转录、图像内容提取和文档解析。\n\n\n\n\nTinq.ai - NLP API\n\n\n开发者工具\n\n\nhttps://tinq.ai\n\n\n一组易于使用和尖端的 NLP API。流行的 API：文本生成 - 重写器/释义器摘要器将快速而强大的文本分析集成到您的应用程序中。从主题分类到情绪分析和实体提取，我们都能满足您的需求。让它在几天内发生，而不是几个月！文本分析：Plagarism Checker；自定义分类器；情绪分析；命名实体识别\n\n\n\n\nValyr\n\n\n开发者工具\n\n\nhttps://valyr.vercel.app\n\n\n用一行代码简化 GPT-3 监控。要使用，请将基本 url 替换为 SDK。将您的 OpenAI 密钥添加到 Valyr 并在仪表板中查看请求。\n\n\n\n\nGPUX.AI\n\n\n开发者工具\n\n\nhttps://gpux.ai\n\n\nGPU 一切。运行任何 Dockerized。运行自动缩放推理。节省成本50-90%。\n\n\n\n\nRTutor\n\n\n开发者工具\n\n\nhttps://tutor.ai\n\n\nRTutor 是一款基于 AI 的应用程序，可以快速生成和测试 R 代码。在对 OpenAI 的 Davinci（ChatGPT 的兄弟）的 API 调用的支持下，RTutor 将自然语言翻译成 R 脚本，然后在 Shiny 平台内执行。可以生成 R Markdown 源文件和 HTML 报告。在此处查看 github 存储库：https://github.com/gexijin/RTutor\n\n\n\n\nMintlify\n\n\n开发者工具\n\n\nhttps://mintlify.com\n\n\n构建您一直想要的文档。开箱即用，易于维护，并针对用户参与进行了优化。\n\n\n\n\nGptDuck\n\n\n开发者工具\n\n\nhttps://gptduck.com\n\n\n针对任何 Github 存储库的问题回答。输入 Github 存储库，我们将其下载到服务器并针对代码创建嵌入。回购需要是公开的，&lt;200 个文件，&lt;100MB。\n\n\n\n\nTextomap\n\n\n开发者工具\n\n\nhttps://textomap.com\n\n\nTextomap 是一个 Web 应用程序和浏览器扩展，使用户能够在几秒钟内从任何包含位置的文本生成交互式地图。没有代码、电子表格或复杂的工具——您的话就足够了。\n\n\n\n\nHTTPie AI\n\n\n开发者工具\n\n\nhttps://httpie.io\n\n\n使用通俗易懂的语言生成 API 请求。HTTPie 正在使 API 对于那些构建我们这个时代的工具的人来说变得简单和直观。\n\n\n\n\nQuizgecko\n\n\n教育助手\n\n\nhttps://quizgecko.com\n\n\n人工智能驱动的测验问题生成器。使用人工智能制作您自己的测验。非常适合教师、电子学习和人力资源专业人士。或者只是为了好玩而生成独特的琐事问题和答案！简单粘贴文本，输入 URL，或上传文件并点击生成。从多项选择题、简答题或判断题中选择。\n\n\n\n\nWolframAlpha\n\n\n教育助手\n\n\nhttps://wolframalpha.com\n\n\n使用 Wolfram 的突破性算法、知识库和 AI 技术计算专家级答案。面向数学、科学与技术、社会与文化以及日常生活等主题。\n\n\n\n\nTutorAI\n\n\n教育助手\n\n\nhttps://tutorai.me\n\n\nTutor AI 是一个人工智能驱动的学习平台。您可以输入任何主题，它会为您提供各种选项，您可以使用这些选项来了解该主题。\n\n\n\n\nMindSmith\n\n\n教育助手\n\n\nhttps://mindsmith.ai\n\n\nMindsmith 是您创建和分享微课程的实验室。世界变化太快，不能依赖笨重、过时的设计软件。无论您是培训团队、教授课程，还是只是需要一种清晰的方式来分享您的知识，都可以使用一套 AI 辅助的直观设计工具，让您的学习者在永不停歇的行业和学科中取得成功。\n\n\n\n\nYip\n\n\n教育助手\n\n\nhttps://yippity.io\n\n\n输入您的笔记，Yip 会自动从中生成问题。\n\n\n\n\nMateAI\n\n\n邮件助手\n\n\nhttps://mateai.io\n\n\n更快地为您的电子邮件活动生成文案和设计。🇬🇧 🇮🇹 提供英语、意大利语和其他 5 种语言版本。\n\n\n\n\nEllie\n\n\n邮件助手\n\n\nhttps://ellieai.com\n\n\nEllie 从您的写作风格中学习，并像您写的一样精心回复。\n\n\n\n\nIpso AI\n\n\n邮件助手\n\n\nhttps://ipso.ai\n\n\n一个 AI 助手，它使用您的日历起草用于安排会议的电子邮件回复，由 GPT3 提供支持。\n\n\n\n\nLuna\n\n\n邮件助手\n\n\nhttps://getluna.dev\n\n\n使用 Luna 即时个性化冷电子邮件。这些天自动消息已经死了。使用 Luna 获得更多关于冷电子邮件的回复 - 世界上第一个使用 AI 每天推荐新的高质量潜在客户并向他们发送他们应得的个人电子邮件的软件应用程序。\n\n\n\n\nPolitePost\n\n\n邮件助手\n\n\nhttps://politepost.net\n\n\nPolitePost 将您的电子邮件重写为礼貌、礼貌和安全的工作方式。非常适合当您在写电子邮件时感到沮丧并且需要 AI 来保持礼貌！\n\n\n\n\nPipl.ai\n\n\n邮件助手\n\n\nhttps://pipl.ai\n\n\n很难大规模发送冷电子邮件。我们让它变得轻而易举。连接无限的收件箱，享受所有帐户的免费预热、内置电子邮件验证和数据清理、人工智能驱动的序列和模板编写器等等……\n\n\n\n\nPostaga\n\n\n邮件助手\n\n\nhttps://postaga.com\n\n\n比以往更轻松地发送冷电子邮件。\n\n\n\n\nDraftLab\n\n\n邮件助手\n\n\nhttps://draftlab.ai\n\n\n您的 Gmail 副驾驶。更快地写出更好的电子邮件。使用适用于 Gmail 的 DraftLab Chrome 扩展，将收件箱归零的速度提高 10 倍。\n\n\n\n\nSuperReply\n\n\n邮件助手\n\n\nhttps://superreply.co\n\n\nSuperreply 使用其 AI 驱动的电子邮件回复工具处理编写电子邮件回复的所有艰苦工作。轻松匹配语调并选择最匹配的电子邮件。\n\n\n\n\nQuicklines\n\n\n邮件助手\n\n\nhttps://quicklines.ai\n\n\nQuicklines 自动创建个性化的破冰机制以注入冷电子邮件。上传 CSV，等待 3 分钟，然后收到写有行的表格。将这些行放入冷电子邮件的第一句中，您会看到您的回复增加了 3 到 7 倍。\n\n\n\n\nInstantly\n\n\n邮件助手\n\n\nhttps://instantly.ai\n\n\n立即帮助您产生更多回复和更多收入。通过无限制的电子邮件发送帐户、无限制的预热和智能 AI 扩展您的外展活动。\n\n\n\n\nCreatext\n\n\n邮件助手\n\n\nhttps://creatext.ai\n\n\nCreaext 可帮助您立即研究您的潜在客户并编写超个性化的电子邮件和 LinkedIn 消息。\n\n\n\n\nChatGPT Writer\n\n\n邮件助手\n\n\nhttps://chatgptwriter.ai\n\n\n免费的 Chrome 扩展，使用 ChatGPT AI 根据您输入的几个关键字生成电子邮件或回复。目前支持 Gmail。支持所有流行语言，只需在文本提示中提及即可。\n\n\n\n\nOrtto\n\n\n邮件助手\n\n\nhttps://ortto.com\n\n\nOrtto AI 可帮助您编写高性能的电子邮件主题行，从大纲中引人入胜的短信和电子邮件内容。驱动结果的是智慧。\n\n\n\n\nWarmer.ai\n\n\n邮件助手\n\n\nhttps://warmer.ai\n\n\nSky 使用 AI 生成的独特个性化设置让您的冷邮件大放异彩。\n\n\n\n\nRobin\n\n\n邮件助手\n\n\nhttps://hellorobin.ai\n\n\n由 GPT 编写的自动冷电子邮件外展。借助 Robin AI，您可以轻松有效地接触潜在客户、进行研究并处理初始外展——所有这些都不需要人工销售助理。\n\n\n\n\nMagicreach\n\n\n邮件助手\n\n\nhttps://magicreach.ai\n\n\nReach 是一种外展个性化和销售支持工具，可为冷外展生成超个性化破冰船。获得回复的更快的电子邮件个性化。\n\n\n\n\nAlethea\n\n\n实验\n\n\nhttps://alethea.ai\n\n\nAlethea AI 致力于实现交互式智能 NFT (iNFT) 的创建。\n\n\n\n\nAsk My Book\n\n\n实验\n\n\nhttps://askmybook.com\n\n\nAsk My Book 是 Gumroad 创始人 Sahil Lavingia 的一项人工智能实验，目的是让他的书更容易阅读。您可以使用“问我的书”来提出问题，然后用他的声音得到答案。\n\n\n\n\nTalk To Books\n\n\n实验\n\n\nhttps://books.google.com\n\n\n一种探索思想和发现书籍的新方法。使用实验性 AI 发表声明或提出问题以浏览书中的段落。\n\n\n\n\nVisualHound\n\n\n时尚\n\n\nhttps://visualhound.com\n\n\n使用 AI 为您的时装设计创意制作原型。创建无限逼真的产品图像来满足您的情绪板并促进您的设计过程。在投入生产之前轻松可视化您的产品设计。\n\n\n\n\nFashionAdvisorAI\n\n\n时尚\n\n\nhttps://fashionadvisorai.com\n\n\n从 FashionAdvisorAI 提问并获得答案。它使用人工智能来帮助您找到时尚问题的答案。用它来打扮自己。\n\n\n\n\nCala\n\n\n时尚\n\n\nhttps://ca.la\n\n\nCALA 使您可以轻松设计、生产和交付您自己的完全定制的时尚产品。CALA 提供您可能需要的一切。设计协助。材料采购。采样。借助应用程序内通知、任务管理和实时评论等强大功能，您可以在工作室或旅途中最大限度地提高工作效率。\n\n\n\n\nBotika\n\n\n时尚\n\n\nhttps://botika.io\n\n\nBotika 利用生成式 AI 的力量帮助在线服装零售商和小型企业减少制作时尚照片的麻烦、成本和时间，同时在各种模型上获得 10 倍以上的输出。\n\n\n\n\nAskThee\n\n\n趣味工具\n\n\nhttps://askthee.vercel.app\n\n\n向伟大的思想家、艺术家或科学家提问。目前拥有亚里士多德、阿西莫夫、卡尔萨根等人物。\n\n\n\n\nUnreal Meal\n\n\n趣味工具\n\n\nhttps://unrealmeal.ai\n\n\nAI 生成的不存在的膳食图像的集合。您可以将这些图像用于多种用途，例如开发新食谱或作为创意项目的一部分。\n\n\n\n\nTattoos AI\n\n\n趣味工具\n\n\nhttps://tattoosai.com\n\n\n与您的个人 AI 纹身艺术家一起创造完美的纹身设计如果您有纹身的想法但找不到合适的设计，让我们的 AI 在几秒钟内生成一个。它可以让您根据自己的喜好创建完美的设计，并为您提供无限的选择，让每个人都能找到适合自己的东西。\n\n\n\n\nELI5\n\n\n趣味工具\n\n\nhttps://explainlikeimfive.io\n\n\n像我五岁一样解释 (ELI5) 是一个使用 AI 简化复杂主题的网站，这样即使是孩子也能理解它们。用户可以选择一个特定的主题，并选择他们希望解释的简单程度，范围从“非常愚蠢”到“非常聪明”。一些例子是——“计算机是如何工作的？” 和“生命的意义是什么？”\n\n\n\n\nMovieToEmoji\n\n\n趣味工具\n\n\nhttps://movietoemoji.netlify.app\n\n\n一个有趣的应用程序，可以将电影名称转换为相应的表情符号！\n\n\n\n\nSanta AI\n\n\n趣味工具\n\n\nhttps://santa.artflow.ai\n\n\n想为假期增添一些额外的魔力吗？查看世界上第一个可定制的会说话的圣诞老人 - 第一次您可以创建自己独特的圣诞老人视频问候并与您所爱的人分享！\n\n\n\n\nSupermeme.ai\n\n\n趣味工具\n\n\nhttps://supermeme.ai\n\n\n生成由 AI 提供支持的 110 多种语言的原创模因。使用我们的 AI 模因生成器加强您的模因营销游戏。\n\n\n\n\nJokelub\n\n\n趣味工具\n\n\nhttps://jokelub.com\n\n\n轻轻一按，将您的文章变成一个笑话。让人们微笑。\n\n\n\n\nHello History\n\n\n趣味工具\n\n\nhttps://hellohistory.ai\n\n\n您将能够与历史上一些有影响力和迷人的人物进行深入对话。对话是由人工智能生成的，所以不要太当真。每个对话都是独一无二的，你永远不知道它会去哪里。\n\n\n\n\nAskNow\n\n\n趣味工具\n\n\nhttps://asknow.ai\n\n\n向名人提出任何问题，并获得带有参考资料的 AI 总结答案。以 Elon Musk、Naval Ravikant、Paul Graham、Serena Williams 等人物为特色。\n\n\n\n\nChai\n\n\n游戏\n\n\nhttps://chai.ml\n\n\n允许您为成千上万的用户构建和部署 AI 聊天机器人的移动应用程序。与人工智能聊天。\n\n\n\n\nAIDungeon\n\n\n游戏\n\n\nhttps://play.aidungeon.io\n\n\n玩和创造具有无限可能性的 AI 生成的冒险。\n\n\n\n\nAI Careers\n\n\n游戏\n\n\nhttps://aicareers.io\n\n\n人工智能求职变得简单。释放数据的潜力以推动创新。\n\n\n\n\nPICLY : AI generated spot the difference\n\n\n游戏\n\n\nhttps://picly.ai\n\n\n简单易行。AI 生成的“找不同”点击您想要的区域，AI 会为您完成。\n\n\n\n\nEndlessVN\n\n\n游戏\n\n\nhttps://endlessvn.io\n\n\n所有的故事都结束了。除了这个。Endless Visual Novel 是一款 AI 讲故事游戏，其中所有资产（图形、音乐、故事和角色）均由 AI 在您玩游戏时生成。没有两个游戏是完全相同的。\n\n\n\n\nThe Simulation\n\n\n游戏\n\n\nhttps://fablesimulation.com\n\n\nThe Simulation 是一个以人工智能为中心的元宇宙。由复杂的机器学习、游戏设计、NFT 和 ERC20 代币 $SIM 提供支持\n\n\n\n\nPlaystrict\n\n\n游戏\n\n\nhttps://playstrict.com\n\n\n让我们让您的游戏更加成功！您有一款很棒的游戏，但没有营销能力来扩大规模？使用 Playstrict Gaming Growth 平台将您的推广策略提升到一个新的水平。你准备好了吗？\n\n\n\n\nLitRPG Adventures\n\n\n游戏\n\n\nhttps://litrpgadventures.com\n\n\n高级桌面 RPG 生成器 + 内容库 D&D 背景故事生成器？那不是全部。立即访问由 OpenAI 的 GPT-3 提供支持的超过 2 打奇幻 RPG 生成器。会员还可以访问我们不断增长的充满桌面角色扮演游戏内容的角色扮演游戏库\n\n\n\n\nHexagram\n\n\n游戏\n\n\nhttps://hexagram.io\n\n\n我们使用人工智能创造环境体验。使用聊天、故事和数据来融合小说和现实的游戏。\n\n\n\n\nGGPredict\n\n\n游戏\n\n\nhttps://ggpredict.io\n\n\n每天不到 30 分钟，借助 AI 生成的培训的力量提高您的 CS:GO 技能。训练更智能。排名更快。\n\n\n\n\nAI Roguelite\n\n\n游戏\n\n\nhttps://store.steampowered.com\n\n\n世界上第一款所有实体均由 AI 生成且所有游戏机制均由 AI 检测的角色扮演游戏。它有人工智能生成的实体、制作配方、战斗和插图。\n\n\n\n\nQuasi\n\n\n综合写作\n\n\nhttps://quasi.market\n\n\n使用人工智能创造艺术、代码、音乐等。\n\n\n\n\nWritewithlaika\n\n\n综合写作\n\n\nhttps://writewithlaika.com\n\n\n作家的神奇机器学习\n\n\n\n\nSmartScribe\n\n\n综合写作\n\n\nhttps://smartscribe.app\n\n\n写作变得更容易… SmartScribe 通过使用人工智能帮助解决阅读和写作的复杂性。\n\n\n\n\nnichess\n\n\n综合写作\n\n\nhttps://nichesss.com\n\n\n忘记作家块。只需单击一个按钮，即可获取博客文章、广告、社交媒体内容、诗歌、商业创意等。我们的机器人会为您编写一切。\n\n\n\n\nCompose\n\n\n综合写作\n\n\nhttps://compose.ai\n\n\nCompose 是一款免费的 Chrome 扩展程序，可让您使用 AI 自动进行写作。我们不应该每天花 40% 的时间打字：是时候改变游戏规则了。\n\n\n\n\nText Generator Plugin\n\n\n综合写作\n\n\nhttps://text-gen.com\n\n\nText Generator 是一种开源 AI 助手工具，它将生成式人工智能的力量带入了 Obsidian 中知识创造和组织的力量。例如，使用文本生成器根据您的知识数据库生成想法、有吸引力的标题、摘要、大纲和整个段落。可能性是无止境！\n\n\n\n\nWebCopilot\n\n\n综合写作\n\n\nhttps://webcopilot.co\n\n\n用 AI 编写您的概念页面。只需开始，让 AI 为您写作。加快您的写作过程并专注于重要的事情。\n\n\n\n\nFrase\n\n\n综合写作\n\n\nhttps://frase.io\n\n\nFrase 在文案写作、总结、释义和广告等类别中提供了多种有用的 AI 写作工具。\n\n\n\n\nNotion AI\n\n\n综合写作\n\n\nhttps://affiliate.notion.so\n\n\n在任何概念页面中利用 AI 的无限力量。写得更快，想得更远，并增强创造力。像魔法一样！\n\n\n\n\nLanguageTool\n\n\n综合写作\n\n\nhttps://languagetool.org\n\n\nLanguageTool 纠正拼写错误，但它也提供所有可能文本的完整写作分析。除了拼写、语法和单词选择之外，语言风格也会得到纠正。掌握30多种语言和方言，主要语言有英语、西班牙语、德语、法语、荷兰语、葡萄牙语。在其英文版中，您可以在六个标准品种之间进行选择。除了纠正之外，LanguageTool 还提供基于 AI 的改写功能。这可以帮助您重写整个句子，使它们更简单、更短或更正式。\n\n\n\n\nAIDuh\n\n\n综合写作\n\n\nhttps://aiduh.com\n\n\nChrome 扩展程序通过 AI 支持的响应将您的写作时间缩短 98%。\n\n\n\n\nWritely\n\n\n综合写作\n\n\nhttps://writelyai.com\n\n\n让所有人都能接触到写作艺术。无论您是需要减少字数、进一步阐述还是简单地改写一个句子，Writely 都可以提供帮助！\n\n\n\n\nGrammarly\n\n\n综合写作\n\n\nhttps://app.grammarly.com\n\n\n使用 Grammarly 的新人工智能应用程序自信地写作。通过自动建议超越语法和拼写风格和语气。适用于电子邮件、文档、社交媒体和几乎所有内容。\n\n\n\n\nProposal Genie\n\n\n综合写作\n\n\nhttps://proposalgenie.ai\n\n\n人工智能驱动的工具，可帮助在 Upwork 上创建专业提案。易于使用，允许您从任何设备创建提案，构建可重复使用的配置文件，并添加关键字和语气等可选字段。\n\n\n\n\nDetect GPT\n\n\n综合写作\n\n\nhttps://chrome.google.com\n\n\n查看您浏览的页面是否包含 AI 生成的内容。Detect GPT 扫描您正在查看的网页内容并对其进行分析，以确定是否有任何内容是使用 GPT 语言模型生成的。\n\n\n\n\nLuciaAI\n\n\n综合写作\n\n\nhttps://luciaai.com\n\n\n高级AI写作助手。露西亚使用最新最先进的人工智能技术。使用 Lucia，您可以比以往更快更好地书写。\n\n\n\n\nCaliberAI\n\n\n综合写作\n\n\nhttps://caliberai.net\n\n\nCaliberAI 有助于将您因 AI 诽谤的风险降至最低。它近乎实时地标记高风险内容，专为协助编辑和加强人工监督而设计。具有根据您组织的风险承受能力量身定制的自定义阈值的 API。\n\n\n\n\nHelloScribe\n\n\n综合写作\n\n\nhttps://helloscribe.ai\n\n\n更好的写作。伟大的想法。变得简单。向 10 倍更快的写作和头脑风暴问好，没有创意障碍或浪费时间。HelloScribe 易于使用的 AI 工具可帮助 PR 和营销专业人员更智能地工作。\n\n\n\n\nWordAI\n\n\n综合写作\n\n\nhttps://wordai.com\n\n\n使用 AI 将您的内容输出提高 10 倍。使用人工智能来缩短周转时间、增加预算并创建更多 Google 和读者会喜欢的高质量内容。\n\n\n\n\nWordtune\n\n\n综合写作\n\n\nhttps://wordtune.com\n\n\nWordtune 是终极 AI 写作工具，可以重写、改写和改写您的作品！Wordtune 受到超过 1,000,000 名用户的信任，可以增强文章、学术论文、随笔、电子邮件和任何其他在线内容。\n\n\n\n\nRedacta.me\n\n\n综合写作\n\n\nhttps://redacta.me\n\n\n您的虚拟社区经理。使用人工智能快速、轻松、经济地创建原始西班牙语文本。我们专门训练人工智能用西班牙语写出好的文章。\n\n\n\n\nOthersideai\n\n\n综合写作\n\n\nhttps://othersideai.com\n\n\n您的个人写作助理。无论您在哪里写作，HyperWrite/OthersideAI 都会提供建议和句子补全来改进您的写作。\n\n\n\n\nGlasp\n\n\n综合写作\n\n\nhttps://glasp.co\n\n\nGlasp 是一种社交网络荧光笔，人们可以使用它来突出显示和组织来自网络的引用和想法，而无需在屏幕之间来回切换，并同时访问其他志趣相投的人的学习成果。为人类留下您的数字遗产，同时为自己工作。他们还提供了一个总结 Youtube 视频的工具。\n\n\n\n\nParagraphAI\n\n\n综合写作\n\n\nhttps://paragraphai.com\n\n\nParagraphAI 是一款人工智能写作应用程序，可以编写清晰、简洁、无错误的内容。\n\n\n\n\nDREAM.page\n\n\n综合写作\n\n\nhttps://dream.page\n\n\n借助 AI 的魔力写作和发布！立即加入候补名单。\n\n\n\n\nMaester.app\n\n\n综合写作\n\n\nhttps://maester.app\n\n\n使用我们直观的模板引擎释放 GPT-3 的全部潜力。快速生成根据您的重复需求量身定制的自定义输出，并与全世界分享。它可以在内容管理、大学和工作以及软件开发方面为您提供帮助。\n\n\n\n\nElephas\n\n\n综合写作\n\n\nhttps://elephas.app\n\n\n唯一与您的 Mac 集成的 AI 编写器。跨应用程序工作。\n\n\n\n\nSudowrite\n\n\n综合写作\n\n\nhttps://sudowrite.com\n\n\n用我们神奇的写作 AI 打破作家的瓶颈。您随时可用的头脑风暴伙伴。无需寻找 Beta 读者即可获得 Beta 反馈。“展示，而不是讲述”？我们有一个按钮。\n\n\n\n\nLex\n\n\n综合写作\n\n\nhttps://lex.page\n\n\n解锁你最好的写作\n\n\n\n\nHandyPlugins\n\n\n综合写作\n\n\nhttps://handyplugins.co\n\n\nHandywriter 是一款人工智能写作助手，可以帮助您为 WordPress 创建内容。它可以检查抄袭，甚至可以修复语法和拼写错误。\n\n\n\n\nPenelope AI\n\n\n综合写作\n\n\nhttps://penelope-ai.vercel.app\n\n\n一个成熟的人工智能写作助手。毫不费力地加快您的写作速度 - 释义、总结、生成故事或 AI 自动完成。\n\n\n\n\nGiftastic.ai\n\n\n礼物创意\n\n\nhttps://giftastic.ai\n\n\nGiftastic.AI 是一个个性化的礼物推荐引擎，它使用您要购物的人的个人特征，并推荐他们会喜欢和欣赏的独特而贴心的礼物。\n\n\n\n\nGifts Genie\n\n\n礼物创意\n\n\nhttps://gen.gifts\n\n\nGenie 是一款由 AI 驱动的生日礼物创意生成器。无需再费力想出完美的礼物 - 只需告诉生成器一些关于此人的事情，它就会为您生成礼物创意。它旨在减轻送礼的压力。\n\n\n\n\nSuggest Gift\n\n\n礼物创意\n\n\nhttps://suggest.gift\n\n\n您是否正在为寻找送给心爱之人的完美礼物而苦恼？不要再观望！我们的工具使用最新的 AI 技术来帮助您发现完美的礼物。告别送礼的压力，让我们的技术为您代劳。\n\n\n\n\nCool Gift Ideas\n\n\n礼物创意\n\n\nhttps://coolgiftideas.io\n\n\n送出完美的礼物！根据每个人的身份发现适合他们的创意礼物。\n\n\n\n\nElf Help\n\n\n礼物创意\n\n\nhttps://elfhelp.ai\n\n\n节日礼物 inspo。Elf Help 是您的终极送礼助手，可为您列表中的每个人免费提供富有创意和个性化的建议。\n\n\n\n\nWhisper AI\n\n\n医疗保健\n\n\nhttps://whisper.ai\n\n\n这是一款人工智能助听器。借助 AI，它可以学习并适应不同的听力情况，例如嘈杂的购物市场或家庭聚会。它提供从新功能到声音处理的定期软件升级。\n\n\n\n\nCradle\n\n\n医疗保健\n\n\nhttps://cradle.bio\n\n\nCradle 使用强大的预测算法和 AI 设计建议帮助生物学家在创纪录的时间内设计出改进的蛋白质。\n\n\n\n\nSwagAI\n\n\n人力资源\n\n\nhttps://useslingshot.com\n\n\nSwagAI 是一种 AI 工具，可以帮助你想出可笑的公司 swag。只需告诉我们您在寻找什么，我们的算法就会推荐疯狂（但有时实用）的选项。\n\n\n\n\nAutumn AI\n\n\n人力资源\n\n\nhttps://getautumn.com\n\n\n在没有调查的情况下测量倦怠并防止它。Autumn 与您已经使用的工具相关联，利用 AI 帮助您识别倦怠的早期迹象，并在您的团队中发现模式，例如增加会议、减少 1:1 的频率或周末发送更多消息。不仅仅是数据——秋季也能帮助您采取行动！在每次 1:1 之前获得 1:1 问题提示，为您的团队量身定制，这样您就不必怀疑自己是否提出了正确的问题。每周都会向您发送团队见解，通过 Slack 中有趣且互动的每周总结，帮助您的团队无需额外努力（或其他 Zoom 社交）就能感受到联系。\n\n\n\n\nDost\n\n\n人力资源\n\n\nhttps://getdost.com\n\n\n使用 Dost 的 AI 支持的 Slack 和 MSTeams 应用程序创建安全、无偏见、无微攻击、包容的消息。\n\n\n\n\nGeniusReview\n\n\n人力资源\n\n\nhttps://geniusreview.xyz\n\n\n360° AI 性能评估。使用 GeniusReview 为您的绩效评估问题获得量身定制的答案，从而节省大量时间。\n\n\n\n\nMoveworks\n\n\n人力资源\n\n\nhttps://moveworks.com\n\n\nMoveworks 是第一个使用 AI 解决工作问题和预防问题的员工体验平台。它会自动解决请求、传达更改并向您的团队展示下一步要解决的问题——让您将沮丧的时刻变成神奇的时刻。由于我们的对话式 AI（聊天机器人）精通 100 多种语言，因此 Moveworks 可以在全球范围内提供从总部到家庭办公室的即时帮助。\n\n\n\n\nHireYaY\n\n\n人力资源\n\n\nhttps://hireyay.com\n\n\n再也不会错过合格的候选人。使用 AI 制作引人入胜的招聘广告。一键分发给百万求职者\n\n\n\n\nJobtitlesAI\n\n\n人力资源\n\n\nhttps://jobtitlesai.com\n\n\n准确限定任何职位。我们的机器学习 API 将职位分为两类：领域（销售、财务、IT..）和职位（执行官、管理、助理…），因此您可以优先考虑您感兴趣的职位。\n\n\n\n\nMagic Eraser\n\n\n图像编辑\n\n\nhttps://magiceraser.io\n\n\n在几秒钟内从图像中删除不需要的东西。上传图像，标记您需要删除的位，下载修复后的图像。\n\n\n\n\nPhotoroom\n\n\n图像编辑\n\n\nhttps://photoroom.com\n\n\n仅使用您的手机创建产品和肖像图片。删除背景、更改背景和展示产品。\n\n\n\n\nGreen Screen AI\n\n\n图像编辑\n\n\nhttps://greenscreenai.com\n\n\nGreen Screen AI 可让您将图片背景更改为您能想到的任何内容！使用生成式 AI，您可以将您的狗放在外星丛林中，或者将您的猫变成太空牛仔。\n\n\n\n\nNostalgia Photo\n\n\n图像编辑\n\n\nhttps://nostalgia.photo\n\n\nNostalgia Photo 使用最新的尖端人工智能技术让旧照片重现生机。只需点击几下和几美分即可获得最高分辨率。\n\n\n\n\nRestorePhotos\n\n\n图像编辑\n\n\nhttps://restorephotos.io\n\n\n为所有人使用 AI 修复旧照片。有旧的和模糊的面部照片吗？让我们的 AI 恢复它们，让这些记忆得以延续。100% 免费 – 立即恢复您的照片。\n\n\n\n\nRemove.bg\n\n\n图像编辑\n\n\nhttps://remove.bg\n\n\n一键式在 5 秒内自动 100% 删除背景。多亏了 remove.bg 的智能 AI，您可以缩短编辑时间 - 并获得更多乐趣！\n\n\n\n\nPerfectly Clear Video\n\n\n图像编辑\n\n\nhttps://eyeq.photos\n\n\nPerfectly Clear Video 提供即时、自动的照片校正和视频增强功能。是全球领先的图像自动校正和AI视频增强提供商。\n\n\n\n\nAI. Image Enlarger\n\n\n图像编辑\n\n\nhttps://imglarger.com\n\n\n多合一 AI 工具包可帮助您增强和提升图像质量。在不损失质量的情况下提高图像分辨率。\n\n\n\n\nBg.Eraser\n\n\n图像编辑\n\n\nhttps://bgeraser.com\n\n\n强大的人工智能修复和图片清理技术。在几秒钟内删除不需要的对象和水印。\n\n\n\n\nHama - Image Editing\n\n\n图像编辑\n\n\nhttps://hama.app\n\n\n瞬间擦除图像中的人物或物体。\n\n\n\n\nTopaz Photo AI\n\n\n图像编辑\n\n\nhttps://topazlabs.com\n\n\n在自动驾驶仪上最大化您的图像质量。使用明天的技术锐化、消除噪点并提高照片的分辨率。Topaz Photo Al 可增强您的图像质量，让您可以专注于摄影的创意部分。\n\n\n\n\nPalette.fm\n\n\n图像编辑\n\n\nhttps://palette.fm\n\n\n自动为黑白图片着色，无需注册，而且免费！\n\n\n\n\nVisio Studio\n\n\n图像编辑\n\n\nhttps://visio.studio\n\n\n先进的背景去除工具，由计算机视觉技术提供支持。Visio Studio 允许您直接从手机编辑和优化图片。\n\n\n\n\nEvoto AI\n\n\n图像编辑\n\n\nhttps://evoto.ai\n\n\nEvoto 是下一代照片编辑器，可将您从繁琐的工作中解放出来，让您以 10 倍的速度处理数千张照片并获得卓越的质量，并帮助您将想象力变为现实。\n\n\n\n\nErase.bg\n\n\n图像编辑\n\n\nhttps://erase.bg\n\n\n免费从图像中删除背景。从人类、动物或物体的图像中去除背景，并免费下载高分辨率图像。\n\n\n\n\nBria\n\n\n图像编辑\n\n\nhttps://bria.ai\n\n\n集成 Bria 的人工智能 API 以自动化和扩展视频和图像的创建。\n\n\n\n\nQuickTools by Picsart\n\n\n图像编辑\n\n\nhttps://tools.picsart.com\n\n\n借助 Picsart Quicktools，您可以访问范围广泛的工具，从而轻松转换文件类型、创建自定义日历、增强图像等。所有这些工具都方便地位于一个地方。\n\n\n\n\nRadiant Photo\n\n\n图像编辑\n\n\nhttps://radiantimaginglabs.com\n\n\n你的照片应该是容光焕发的。获得具有完美色彩再现的优质成品照片，并在创纪录的时间内交付给您。您的照片 — 简直容光焕发。他们本来的样子。\n\n\n\n\nLet’s Enhance\n\n\n图像编辑\n\n\nhttps://letsenhance.io\n\n\n图像增强器和升级器。自动 AI 编辑器可在不降低质量的情况下提高图像分辨率。一键让您的照片呈现最佳效果\n\n\n\n\nStable Horde\n\n\n图像生成器\n\n\nhttps://stablehorde.net\n\n\n深度学习文生图模型工作者的众包分布式集群。还提供无需安装和技术专业知识的客户端界面\n\n\n\n\nGo Charlie\n\n\n图像生成器\n\n\nhttps://gocharlie.ai\n\n\n单击按钮即可创建图像、博客、广告、网站标题。\n\n\n\n\nStable Diffusion\n\n\n图像生成器\n\n\nhttps://stability.ai\n\n\nStable Diffusion 是一种深度学习的文本到图像模型，于 2022 年发布。它主要用于生成以文本描述为条件的详细图像，但它也可以应用于其他任务，例如修复、修复和生成图像到- 由文本提示引导的图像翻译。\n\n\n\n\nGetimg.ai\n\n\n图像生成器\n\n\nhttps://getimg.ai\n\n\n使用 AI 创建图像所需的一切。神奇的 AI 艺术工具。生成原始图像、修改现有图像、将图片扩展到原始边界之外等等。\n\n\n\n\nAragon - Image Generation\n\n\n图像生成器\n\n\nhttps://aragon.ai\n\n\n使用 AI 以 10 倍的速度创建令人惊叹的艺术作品和图像。\n\n\n\n\nRocketAI\n\n\n图像生成器\n\n\nhttps://rocketai.io\n\n\n设计的未来是可编程的。Rocket AI 是一个 SaaS 平台，可使用 AI 创建和编辑产品图像并改善电子商务销售和广告效果。我们为电子商务企业提供人工智能解决方案，以改善他们的产品形象，并从简单的文本提示中产生新的想法和设计概念。\n\n\n\n\nPollinations\n\n\n图像生成器\n\n\nhttps://pollinations.ai\n\n\nPollinations 希望使创造力多样化，并通过数字生态系统传播它。无论是图像、视频还是音频，我们都邀请人们借助 AI 想象新世界。对于公司，我们的开发人员在最新的 AI 模型之上编写代码，提供定制的结果和特定的美学。借助 API，AI 创作可以直接集成到网站和社交媒体平台中。创作变得简单、快速和有趣。\n\n\n\n\nDiffusion Land\n\n\n图像生成器\n\n\nhttps://diffusion.land\n\n\nDiffusion Land 允许您使用各种 AI 模型来生成图像。他们还有几个预建的概念，您可以使用这些概念来生成某些类型的图像。\n\n\n\n\nDallE-2\n\n\n图像生成器\n\n\nhttps://openai.com\n\n\nDALL·E 2 可以根据文字描述创建原创、逼真的图像和艺术作品。它可以组合概念、属性和样式。\n\n\n\n\nGetalpaca\n\n\n图像生成器\n\n\nhttps://getalpaca.io\n\n\nalpaca 是一个 Photoshop 插件，用于将 AI 图像生成能力与人类技能相结合。\n\n\n\n\nCanva Text to Image\n\n\n图像生成器\n\n\nhttps://canva.com\n\n\n可生成您描述的任何图像的全新技术。\n\n\n\n\nStock AI\n\n\n图像生成器\n\n\nhttps://stockai.com\n\n\n获得完美的图像。每次。准确找到您需要的图像。如果它不存在，我们会立即为您创建。\n\n\n\n\nCraiyon\n\n\n图像生成器\n\n\nhttps://craiyon.com\n\n\nAI 模型从任何提示中绘制图像！\n\n\n\n\nSoreal.AI Studio\n\n\n图像生成器\n\n\nhttps://soreal.ai\n\n\nAI图像生成入门最简单的方法\n\n\n\n\nImgcreator\n\n\n图像生成器\n\n\nhttps://imgcreator.zmo.ai\n\n\n使用文本创建图像。生成基于文本的图像以帮助您思考和创作。\n\n\n\n\nStylized\n\n\n图像生成器\n\n\nhttps://stylized.ai\n\n\n几秒钟内即可获得专业的产品照片。Stylized 使用人工智能创建令人惊叹的产品照片和社论 - 无需工作室\n\n\n\n\nArtssy\n\n\n图像生成器\n\n\nhttps://artssy.co\n\n\n使用 Artssy AI 一键创建无限图像，探索无限可能的世界。当您可以立即创建完美的图像时，停止为免版税的照片付费。\n\n\n\n\nNijijourney\n\n\n图像生成器\n\n\nhttps://nijijourney.com\n\n\n动漫迷的 NijiJourney AI。新的 niji 模型经过精心调整，可以制作动漫和插画风格。它对动漫，动漫风格和动漫美学有更多的了解。它非常适合动态和动作镜头，以及一般以角色为中心的构图。\n\n\n\n\nRoll Art Die\n\n\n图像生成器\n\n\nhttps://roll-art-die.com\n\n\n在您的 Apple Silicon 设备上使用 StableDiffusion。仅使用文本生成 AI 艺术品。将您梦想中的艺术品变为现实。无需云订阅。\n\n\n\n\nDreamer\n\n\n图像生成器\n\n\nhttps://slashdreamer.com\n\n\n将 Notion 中的 Stable Diffusion 集成到 AI 中，使用新的斜杠命令生成图像。\n\n\n\n\nEnterpix\n\n\n图像生成器\n\n\nhttps://enterpix.app\n\n\n人工智能生成的图像搜索引擎。\n\n\n\n\nXno.ai\n\n\n图像生成器\n\n\nhttps://xno.ai\n\n\n使用 39 个 GPU 探索 19 个顶级文本到图像 AI。\n\n\n\n\nSpellbook\n\n\n法律助手\n\n\nhttps://spellbook.legal\n\n\n使用 AI 起草合同的速度提高了 3 倍。Spellbook 使用 GPT-3 在 Microsoft Word 中审查和建议合同语言。Spellbook 接受了数十亿行法律术语的培训，可以立即为您的合同建议语言。\n\n\n\n\nCasetext\n\n\n法律助手\n\n\nhttps://casetext.com\n\n\n发现 Lexis 和 Westlaw 遗漏案例的现代搜索技术。不要冒失去先例的风险。以实惠的价格获得更快、更准确的法律研究。\n\n\n\n\nDetangle.ai\n\n\n法律助手\n\n\nhttps://detangle.ai\n\n\nDetangle 为您提供 AI 生成的法律文件摘要，以便您真正理解它们。\n\n\n\n\nActivazon\n\n\n法律助手\n\n\nhttps://activazon.com\n\n\nActivazon 是一项犯罪报告分析服务，旨在让居民和访客了解在他们的社区和其他地方发生的活动。\n\n\n\n\nLegal Robot\n\n\n法律助手\n\n\nhttps://legalrobot.com\n\n\n法律建议需要仔细分析法律及其如何适用于特定情况。Legal Robot 提供通过自动分析与其他法律文件和判例法相关的法律文件而生成的信息。我们还提供语言和统计分析，帮助您了解法律文件中的潜在问题。\n\n\n\n\nFerret\n\n\n法律助手\n\n\nhttps://ferret.ai\n\n\nFerret 无与伦比的 AI 应用程序，结合世界一流的信息，为您提供独家关系情报，可以帮助您避开高风险人群并发现有前途的机会。\n\n\n\n\nDoNotPay\n\n\n法律助手\n\n\nhttps://donotpay.com\n\n\n世界上第一个机器人律师。DoNotPay 应用程序是世界上第一位机器人律师的故乡。只需按一下按钮，就可以打击公司、打击官僚主义并起诉任何人。\n\n\n\n\nReplika\n\n\n生活助手\n\n\nhttps://replika.com\n\n\n关心的AI伴侣。总是在这里倾听和交谈。永远在你身边。\n\n\n\n\nFind Your Next Book\n\n\n生活助手\n\n\nhttps://findyournextbook.ai\n\n\nFind Your Next Book 是一项图书推荐服务，旨在帮助那些难以决定阅读什么的人。只需根据人物、背景和/或情节描述您想要的读物，我们就会从我们的数千本书数据库中推荐最佳选择。\n\n\n\n\nThekeys\n\n\n生活助手\n\n\nhttps://thekeys.ai\n\n\n您知道自己想说什么，只是不确定如何说。Keys 可帮助您以正确的方式说话，而不会改变您的意图，或听起来像机器人。\n\n\n\n\nAI Trip Planner\n\n\n生活助手\n\n\nhttps://buildai.space\n\n\nAI Trip Planner 是一款全球旅行计划应用程序，可为用户前往世界任何目的地的旅行自动创建详细的每日行程。所有用户需要做的就是指定他们的旅行长度和他们想要的目的地，应用程序将处理剩下的事情\n\n\n\n\nCaktus\n\n\n生活助手\n\n\nhttps://caktus.ai\n\n\n为学生撰写论文、讨论问题、一般编码帮助和专业工作申请帮助提供的 AI 解决方案。\n\n\n\n\nJustLearn\n\n\n生活助手\n\n\nhttps://justlearn.com\n\n\n您可以使用 Justlearn 创建 AI 朋友并与他们交谈。\n\n\n\n\nBlackInk\n\n\n生活助手\n\n\nhttps://blackink.ai\n\n\n在几秒钟内创建您自己独特的闪光纹身。停止花费数月时间在 Pinterest 上搜索你的下一个纹身。使用 BlackInk 的 AI 在几秒钟内生成定制的独特纹身，专为您打造类似纹身的设计。\n\n\n\n\nWrite Me A Cover Letter\n\n\n生活助手\n\n\nhttps://WriteMeACoverLetter.com\n\n\n使用 AI 在几秒钟内生成求职信。只需上传您的简历，分享您想要的工作的链接，剩下的交给我们。\n\n\n\n\nTinyWow\n\n\n生活助手\n\n\nhttps://tinywow.com\n\n\n人工智能驱动的实用工具，让您的生活更轻松。最常见的工具包括 PDF、视频、图像、AI 写入和转换工具。\n\n\n\n\nProdigy AI\n\n\n生活助手\n\n\nhttps://ai.prodi.gg\n\n\n面向开发人员的 GPT 职业教练。根据您的独特技能、经验和目标，立即获得个性化的职业建议和指导。通过人工智能。\n\n\n\n\nCircle Labs\n\n\n生活助手\n\n\nhttps://circle.isyourshadowyou.com\n\n\n我们制造的 AI 是您真正愿意花时间与之交谈的。有个性、有棱有角的人工智能。\n\n\n\n\nElektrif AI\n\n\n生活助手\n\n\nhttps://elektrif.ai\n\n\n做最好的自己，永远不要无话可说，花更多的时间去真正了解一个人。Elektrif.AI 使用 GPT3 生成个性化的对话开场白、改写您的消息以使其更具吸引力等。\n\n\n\n\nResume Worded\n\n\n生活助手\n\n\nhttps://resumeworded.com\n\n\n改善您的简历和 LinkedIn 个人资料。我们的人工智能平台由顶级招聘人员设计，可立即为您的简历和 LinkedIn 个人资料提供量身定制的反馈。获得 5 倍以上的面试、机会和工作机会。\n\n\n\n\nReggi\n\n\n生活助手\n\n\nhttps://yfj.social\n\n\nReggi 帮助您在实时商店中跟踪您的购买和预算，在您购物时将正确的税费应用到您的小计中。整体无压力的购物体验。\n\n\n\n\nBrandmark\n\n\nLogo 生成器\n\n\nhttps://brandmark.io\n\n\n为您的企业创建独特、专业的徽标。使用我们免费的 AI 驱动设计工具，为您的下一个徽标项目获取颜色和字体创意。\n\n\n\n\nLooka\n\n\nLogo 生成器\n\n\nhttps://looka.grsm.io\n\n\nLooka Logo Maker 将您的徽标设计偏好与人工智能相结合，帮助您创建自己喜欢的自定义徽标。\n\n\n\n\nMake Logo AI\n\n\nLogo 生成器\n\n\nhttps://makelogoai.com\n\n\n不到一杯咖啡的设计师品质标志。高清+透明背景。在不到 24 小时内交付。商业里\n\n\n\n\nNamecheap Logo Maker\n\n\nLogo 生成器\n\n\nhttps://namecheap.com\n\n\n只需回答几个问题，即可免费下载数百个徽标。\n\n\n\n\nSitekick\n\n\n低代码/无代码\n\n\nhttps://sitekick.ai\n\n\nSitekick 是一个 AI 登陆页面构建器。它允许您创建漂亮的登录页面，而无需编码、设计或文案写作技能。\n\n\n\n\nRobovision.ai\n\n\n低代码/无代码\n\n\nhttps://robovision.ai\n\n\n打造有效的动态视觉 AI。Robovision 提供涵盖整个 AI 生命周期的视觉 AI 平台。在当今不断变化的商业环境中简化开发、实施和调整 AI 的整个过程。\n\n\n\n\nDust\n\n\n低代码/无代码\n\n\nhttps://dust.tt\n\n\n设计和部署大型语言模型应用程序。快速工程，重新构想🔥 建立在多年使用大型语言模型的经验之上。为了一个目标，帮助加速他们的部署。\n\n\n\n\nNeon AI\n\n\n低代码/无代码\n\n\nhttps://neon.ai\n\n\n使用 Neon AI 的支持技术创建最先进的语音应用程序。Neon AI SDK 将高级人工智能和自然语言理解集成到一个紧密结合的软件工程平台中。想想 Amazon Alexa、Google Home、Apple Siri 和 Microsoft Cortana - 以及免费的开源软件。他们还在其网站上列出了适用于 Mycroft Mark II 的 AI 操作系统。\n\n\n\n\nVWO\n\n\n低代码/无代码\n\n\nhttps://vwo.com\n\n\n将您的访问者变成付费客户。立即设置您的第一个实验。\n\n\n\n\nDurable AI\n\n\n低代码/无代码\n\n\nhttps://durable.ai\n\n\n我们的使命是使用能够进行人类推理和对话的可解释 AI 来转变对定制软件的访问。我们设想的未来是，自定义、灵活和耐用的软件将民主化并可供所有人使用。\n\n\n\n\nTeleporthq\n\n\n低代码/无代码\n\n\nhttps://teleporthq.io\n\n\nTeleportHQ 是具有集成 UI 开发和内容建模工具的协作前端平台。一个强大的可视化构建器，可立即创建和发布您的无头静态网站。\n\n\n\n\nDebuild\n\n\n低代码/无代码\n\n\nhttps://debuild.app\n\n\n快速构建 Web 应用程序。\n\n\n\n\nMonitaur\n\n\n低代码/无代码\n\n\nhttps://monitaur.ai\n\n\n获得可根据您的业务扩展的有据可查的合乎道德的 AI。Monitaur 可帮助您审核、跟踪和记录 AI 和算法的实时结果，以实现最佳性能和合规性。我们的平台旨在与接触您的 AI 的每个团队集成。\n\n\n\n\nTeachable Machine\n\n\n低代码/无代码\n\n\nhttps://teachablemachine.withgoogle.com\n\n\nTeachable Machine 是一种基于网络的工具，可以让每个人快速、轻松地创建机器学习模型。它旨在供教育工作者、艺术家、学生、创新者、各种类型的制造者使用——实际上，任何有想法想要探索的人。不需要必备的机器学习知识。\n\n\n\n\nBrancher AI\n\n\n低代码/无代码\n\n\nhttps://brancher.ai\n\n\n通过让用户能够将 AI 模型连接在一起并生成独特的 AI 驱动的应用程序，让所有人都能访问 AI。货币化并与世界分享您的创作。\n\n\n\n\nAxiom\n\n\n低代码/无代码\n\n\nhttps://axiom.ai\n\n\nAxiom 是一种浏览器扩展程序，可通过在任何网站或 Web 应用程序上自动执行网站操作和重复性任务来帮助您节省时间。\n\n\n\n\nRoboflow\n\n\n低代码/无代码\n\n\nhttps://roboflow.com\n\n\n给你的软件一种既视感。只需几张图片，您就可以在下午训练一个可以工作的计算机视觉模型。\n\n\n\n\nNanonets\n\n\n低代码/无代码\n\n\nhttps://nanonets.com\n\n\n使用 AI 自动执行手动数据输入！立即从文档、文本、图像和电子邮件中捕获数据。减少周转时间和所需的手动工作。基于 OCR（光学字符识别）的 AI 平台。\n\n\n\n\nLobe\n\n\n低代码/无代码\n\n\nhttps://lobe.ai\n\n\nLobe 使用免费、易于使用的工具帮助您训练机器学习模型。它只需向它展示您希望它学习的示例，它就会自动训练可以在您的应用程序中发布的自定义机器学习模型。\n\n\n\n\nLiner.ai\n\n\n低代码/无代码\n\n\nhttps://liner.ai\n\n\nLiner 是一款免费工具，可让您轻松训练 ML 模型。它获取您的训练数据并为您提供易于集成的 ML 模型。无需编码或机器学习方面的专业知识。\n\n\n\n\nCogniflow\n\n\n低代码/无代码\n\n\nhttps://cogniflow.ai\n\n\n从文本、图像或音频构建 AI 的最简单方法。几分钟后。无需代码。\n\n\n\n\nBuild AI\n\n\n低代码/无代码\n\n\nhttps://buildai.space\n\n\nBuild AI 可帮助您在几分钟内构建 AI 应用程序。您将能够完全自己构建应用程序并发布它。您将能够根据需要对其进行更新，包括改进和完善您的提示，使您的应用达到最佳状态\n\n\n\n\nFelvin\n\n\n低代码/无代码\n\n\nhttps://felvin.com\n\n\nFelvin 使非开发人员能够创建、发现 AI 应用程序并从中获利。我们的无代码工具使您可以轻松创建 AI 应用程序并将它们放在 SEO 优化的图库中以供发现。\n\n\n\n\nSeek\n\n\n低代码/无代码\n\n\nhttps://seek.ai\n\n\n智能数据层。询问您的任何数据并立即获得答案\n\n\n\n\nLightning AI\n\n\n低代码/无代码\n\n\nhttps://lightning.ai\n\n\n闪电般快速地构建模型和全堆栈 AI 应用程序。使用 Lightning App 模板构建模型和 AI 驱动的云应用程序，无需 DIY 基础设施、成本管理、扩展和其他令人头疼的问题。\n\n\n\n\nBrowse AI\n\n\n低代码/无代码\n\n\nhttps://browse.ai\n\n\n从任何网站提取和监控数据的最简单方法。在 2 分钟内训练一个机器人。无需编码。\n\n\n\n\nSoftr Studio\n\n\n低代码/无代码\n\n\nhttps://softr.io\n\n\n为您的企业构建自定义应用程序，就像乐高积木一样简单。使用他们的 AI，只需单击一下即可在 Softr 中生成图像和复制。将您的 Airtable 或 Google Sheets 变成客户门户、合作伙伴应用程序或内部工具。\n\n\n\n\nSymanto Text Insights\n\n\n低代码/无代码\n\n\nhttps://symanto.com\n\n\n市场领先的 NLP API。通过实时分析和简单的系统集成，利用文本数据获得更好的业务洞察力。\n\n\n\n\nMutiny\n\n\n低代码/无代码\n\n\nhttps://mutinyhq.com\n\n\nMutiny 是一个无代码 AI 平台，可帮助营销人员在没有工程师的情况下将他们的漏斗顶部需求转化为收入。\n\n\n\n\nZevi.ai\n\n\n低代码/无代码\n\n\nhttps://zevi.ai\n\n\n通过 AI 驱动的搜索和发现解决方案改善业务成果 通过以意图为中心、易于集成的网站搜索引擎引导您的潜在客户从发现到转化，这有助于提高参与度和销售额\n\n\n\n\nRiku.ai\n\n\n低代码/无代码\n\n\nhttps://riku.ai\n\n\n使您无需代码即可构建 AI 模型。通过集成、API 或公共共享链接使用 AI。每个人都可以访问 AI。\n\n\n\n\nAI Surge Cloud\n\n\n低代码/无代码\n\n\nhttps://ai-surge.cloud\n\n\nAI Surge 是一个无代码决策智能平台，可帮助企业构建生产优先的 ModelOps 管道，无需编写一行代码即可将数据科学带入生活。这就像没有数据科学家的数据科学。我们正在帮助企业将数据交付速度提高 10 倍，并将成本降低 90%。\n\n\n\n\n10Web\n\n\n低代码/无代码\n\n\nhttps://10web.io\n\n\nAI - 供电的 WordPress 平台。至少可以说，自动化的网站构建器、托管和 PageSpeed Booster。\n\n\n\n\nRetune\n\n\n低代码/无代码\n\n\nhttps://retune.so\n\n\n使用 GPT-3 创建微调语言模型并从中获利的终极工具。借助 re:tune，您可以轻松地为任何行业或用例训练和定制您自己的 AI 助手，并生成 API 以将其集成到您自己的应用程序中。\n\n\n\n\nHeyday\n\n\n记忆\n\n\nhttps://heyday.xyz\n\n\nHeyday 是一款由 AI 驱动的记忆助手，可以重新显示您在浏览网页时忘记的内容。记住更多你学到的东西。自动地。\n\n\n\n\nPersonal.ai\n\n\n记忆\n\n\nhttps://personal.ai\n\n\nPersonalAI 是一种 AI 工具，可以以思维的速度产生新想法、回忆关键概念和编写原创内容。新想法的自动编目和您存储的所有内容的集中知识中心。\n\n\n\n\nRewind AI\n\n\n记忆\n\n\nhttps://rewind.ai\n\n\nRewind 是您生活的搜索引擎。这是一款专为隐私设计的 macOS 应用程序，可让您找到您所见、所说或所听的任何内容。\n\n\n\n\nNatural Language Playlist\n\n\n音乐\n\n\nhttps://naturallanguageplaylist.com\n\n\nAI 生成混音带和播放列表。输入一个句子作为提示，并返回由 AI 策划的歌曲列表！\n\n\n\n\nEndel\n\n\n音乐\n\n\nhttps://endel.io\n\n\n个性化音景可帮助您集中注意力、放松身心和入睡。以神经科学为后盾。\n\n\n\n\nHarmonai\n\n\n音乐\n\n\nhttps://harmonai.org\n\n\n我们是一个社区驱动的组织，发布开源生成音频工具，让每个人都能更轻松、更有趣地制作音乐\n\n\n\n\nRiffusion\n\n\n音乐\n\n\nhttps://riffusion.com\n\n\nRiffusion 根据文本提示生成音乐。尝试您最喜欢的风格、萨克斯管或小提琴等乐器、阿拉伯语或牙买加语等修饰语、爵士乐或福音音乐等流派、教堂钟声或雨声等声音，或任意组合\n\n\n\n\nSonify\n\n\n音乐\n\n\nhttps://sonify.io\n\n\nSonify 在音频、数据和新兴技术的交叉领域进行创新。我们设计和开发音频优先的产品和数据驱动的解决方案。\n\n\n\n\nBeatoven.ai\n\n\n音乐\n\n\nhttps://beatoven.ai\n\n\nBeatoven.AI 使用先进的 AI 音乐生成技术来创作独特的基于情绪的音乐，以适合您的视频或播客的每个部分。\n\n\n\n\nAmper\n\n\n音乐\n\n\nhttps://ampermusic.com\n\n\nAmper 的使命是让任何人都能通过音乐创造性地表达自己，无论他们的背景、专业知识或资源如何。Amper 构建由我们的 Creative AI 提供支持的工具，以帮助人们创作和定制原创音乐。他们还提供了一个 API，您可以使用它来创建自己的产品。\n\n\n\n\nSoundful\n\n\n音乐\n\n\nhttps://soundful.com\n\n\nSoundful 使创作者只需单击一个按钮即可生成免版税曲目。Soundful 音乐的音质如此丰富，你不会相信它是用 AI 制作的。\n\n\n\n\nSongtell\n\n\n音乐\n\n\nhttps://songtell.com\n\n\nSongtell 是有史以来第一个由 AI 生成的歌曲含义库，生成了超过 20000 首歌曲含义。您还可以订购印有您最喜爱歌曲含义的海报。查看他们的 subreddit r/songtell 了解更多详情！\n\n\n\n\nPop2Piano\n\n\n音乐\n\n\nhttps://sweetcocoa.github.io\n\n\n从您想要的任何歌曲中播放基于流行音乐的钢琴翻唱。通过从列表中选择项目来更改钢琴翻唱的歌曲和风格。\n\n\n\n\nBoomy\n\n\n音乐\n\n\nhttps://boomy.com\n\n\n制作即时音乐并与世界分享。在几秒钟内创作原创歌曲，即使您以前从未制作过音乐。在 Spotify、TikTok、YouTube 和全球 40 多个其他平台上的每次收听都将获得报酬。\n\n\n\n\nOpen Voice OS\n\n\n音乐\n\n\nhttps://openvoiceos.com\n\n\nOpen Voice OS 展示了开源语音 AI 在一系列设备上的强大功能。社区支持的 Linux 发行版。\n\n\n\n\nEmergent Drums\n\n\n音乐\n\n\nhttps://audialab.com\n\n\n使用人工智能生成独特的鼓样本。使用我们的突破性插件生成无尽的鼓样本，全部免版税。\n\n\n\n\nMubert\n\n\n音乐\n\n\nhttps://mubert.com\n\n\nMubert - 面向内容创作者、品牌和开发商的全新免版税音乐生态系统 🔥。来看看我们的高品质音乐如何提升您的内容⏩！\n\n\n\n\nSplashmusic\n\n\n音乐\n\n\nhttps://splashmusic.com\n\n\n将音乐创作的乐趣带给每个人\n\n\n\n\nAiva\n\n\n音乐\n\n\nhttps://aiva.ai\n\n\nAIVA，人工智能音乐作曲家，可为您的项目创作原创和个性化的音乐。\n\n\n\n\nRephrasely\n\n\n改写\n\n\nhttps://rephrasely.com\n\n\n释义是写作过程中很自然的一部分，因为它可以帮助您理清思路并使您的措辞适合您的听众。使用 Rephrasely 有助于构建和简化这项工作，我们的释义工具提供了 20 种模式，其中许多是免费的，以实现这一点。我们提供的 20 种模式多种多样，包括摘要工具、免费语法检查器、简化文本的模式和句子缩短器。\n\n\n\n\nParaphraser\n\n\n改写\n\n\nhttps://paraphrasetool.com\n\n\nParaphrase Tool 使用 AI 生成 100 多种语言的文本变体。\n\n\n\n\nQuillbot Paraphraser\n\n\n改写\n\n\nhttps://quillbot.com/\n\n\nQuillbot 将重写您的文本。通过编写或粘贴内容然后单击释义来免费开始。\n\n\n\n\nTavus\n\n\n个性化视频\n\n\nhttps://tavus.io\n\n\n认识 Tavus，这是一款程序化个性化视频工具，专为希望改变建立关系方式的顶级产品、营销和销售团队打造。录制一次并发现 Tavus 的力量，因为我们的 AI 会自动为大大小小的观众生成个性化视频。\n\n\n\n\nRephrase\n\n\n个性化视频\n\n\nhttps://rephrase.ai\n\n\nRephrase 的技术可大规模创建超个性化视频，从而提高参与度和业务效率。\n\n\n\n\nWindsor\n\n\n个性化视频\n\n\nhttps://windsor.io\n\n\n向每一位客户发送个人视频，让他们永远不会忘记您的品牌录制一个视频，Windsor 的 AI 会向您的客户发送数百万个个性化副本。\n\n\n\n\nBHuman\n\n\n个性化视频\n\n\nhttps://bhuman.ai\n\n\n制作单个视频并为成千上万的收件人进行个性化设置。通过任何渠道交付并立即测量结果。您可以通过录制模板、连接数据然后生成个性化视频来实现。\n\n\n\n\nVidyo\n\n\n个性化视频\n\n\nhttps://vidyo.ai\n\n\n立即将长视频制作成短视频。使用强大的 AI 从您现有的视频中创建短片 ✨ 节省 90% 的时间和精力。\n\n\n\n\nDeepL\n\n\n生产力\n\n\nhttps://deepl.com\n\n\nDeepL 是世界上最准确、最细致的机器翻译。通过结合先进的 AI 技术和无与伦比的翻译准确性，它的准确度比最接近的竞争对手高出 3 倍以上。\n\n\n\n\nScale\n\n\n生产力\n\n\nhttps://scale.com\n\n\n借助更好的数据，更快地从您的 AI 投资中获得价值。更好的数据会带来更高性能的模型。高性能模型导致更快的部署。\n\n\n\n\nOracle\n\n\n生产力\n\n\nhttps://askoracle.app\n\n\nOracle 已经为您提供了所有答案。从 Oracle 获得即时答案，节省时间和精力。Ask Oracle 可以连接并回答来自 Slack、Docs 和 Notion 的问题。\n\n\n\n\nMerlin\n\n\n生产力\n\n\nhttps://merlin.foyer.work\n\n\nMerlin 在您最喜爱的所有网站上为您提供 OpenAI 的 ChatGPT 的强大功能。例如：Gmail、g-sheets、Twitter、Linkedin 等。您在线搜索或写作的任何地方。使用 Merlin，您可以快速编辑电子邮件、撰写 Twitter 回复或创建 Excel 公式。\n\n\n\n\nEnzyme\n\n\n生产力\n\n\nhttps://enzyme.com\n\n\n酶 QMS 软件包括从设计控制到 CAPA 的产品开发生命周期所有阶段的模块。我们的内部专家随时为您提供支持！我们可以指导您完成质量挑战和监管提交流程。立即注册演示。\n\n\n\n\nAlbus\n\n\n生产力\n\n\nhttps://springworks.in\n\n\nAlbus 是 Slack 内部的 AI 助手。您可以通过向应用程序发送消息直接向 Albus 提问。一些示例包括营销人员使用 Albus 为其目标受众创建个性化且引人入胜的内容，或者设计师可以使用 Albus 为新设计产生创意并创建独特且引人入胜的视觉内容。\n\n\n\n\nGlean\n\n\n生产力\n\n\nhttps://glean.com\n\n\n立即了解您的公司知道什么。收集公司所有应用程序的搜索，以帮助您准确找到您需要的内容并发现您应该了解的内容。\n\n\n\n\nMarketplan\n\n\n生产力\n\n\nhttps://marketplan.io\n\n\n一体化营销平台。从一个强大的地方计划、执行、规划和优化您的整个营销策略。\n\n\n\n\nAlfred\n\n\n生产力\n\n\nhttps://alfredsearch.com\n\n\nAlfred 是适用于 iOS 的 GPT 聊天助手。它是一种新的人工智能搜索和内容创建引擎，将无广告搜索和内容创建结合到一个易于使用的应用程序体验中。在 OpenAI 开创性的 GPT-3 的支持下，Alfred 理解您的自然语言并提供准确且相关的答案。使用 Alfred，搜索和查找信息从未如此简单或方便。立即尝试，体验搜索和内容创建的未来。\n\n\n\n\nQatalog\n\n\n生产力\n\n\nhttps://qatalog.com\n\n\n为工作定制的操作系统。Qatalog 是一种项目管理/协作 AI 工具，可以无缝管理人员、运营和知识。\n\n\n\n\nKrisp\n\n\n生产力\n\n\nhttps://krisp.ai\n\n\nKrisp 的人工智能解决方案消除了会议中的背景噪音和回声，只留下人声。具有噪音和回声消除、小部件、洞察力和通话摘要等功能。\n\n\n\n\nMem.ai\n\n\n生产力\n\n\nhttps://mem.ai\n\n\n让 AI 组织您团队的工作——从会议记录、项目到知识库。所有这些都可以立即搜索并且很容易被发现。\n\n\n\n\nReclaim AI\n\n\n生产力\n\n\nhttps://reclaim.ai\n\n\n用于 Google 日历的任务管理和计划的 AI。Reclaim 为您的团队的优先事项创建完美的时间表，并通过智能、灵活和自适应的时间编排节省高达 40% 的工作周时间。\n\n\n\n\nXembly\n\n\n生产力\n\n\nhttps://xembly.com\n\n\n一个自动化的参谋长来处理让你慢下来的任务。通过平凡的工作。专注于意义。\n\n\n\n\nSlidesAI\n\n\n生产力\n\n\nhttps://slidesai.io\n\n\n使用 AI 在几秒钟内创建演示幻灯片告别繁琐的手动幻灯片创建。让 AI 为您编写大纲和演示内容。使用他们的工具，您可以立即从任何文本轻松创建专业、引人入胜的幻灯片。适用于谷歌幻灯片。Microsoft Powerpoint 即将推出。\n\n\n\n\nNoty.ai\n\n\n生产力\n\n\nhttps://noty.ai\n\n\nAI 会议助手将 Google Meet 转化为行动、任务和跟进。功能包括：实时转录和一键突出显示。AI 摘要和会议情报。自动跟进。\n\n\n\n\nChatGPT\n\n\n生产力\n\n\nhttps://chat.openai.com\n\n\nChatGPT：优化对话的语言模型。对话格式使 ChatGPT 可以回答后续问题、承认错误、挑战不正确的前提并拒绝不适当的请求。\n\n\n\n\nSupernormal\n\n\n生产力\n\n\nhttps://supernormal.com\n\n\nSuperNormal 是一个让队友可以全天发送异步视频更新的平台。使用 AI 支持的摘要进行快速视频更新有助于让团队保持更新和联系，而无需安排会议或跨时区同步。\n\n\n\n\nAdobe Sensei\n\n\n生产力\n\n\nhttps://adobe.com\n\n\n创建和提供理想的客户体验可能是一项复杂的任务。Sensei 使用 AI 和机器学习来简化这些任务，帮助您简化创意过程、做出明智的决策并进行针对性营销以获得更好的结果。\n\n\n\n\ntyply\n\n\n生产力\n\n\nhttps://typly.app\n\n\n使用我们的键盘单击一下即可回复您的所有消息！Typly 会自动生成与对话上下文相匹配的句子。允许您通过单击来回答问题或继续话题。\n\n\n\n\nPromptist\n\n\n提示\n\n\nhttps://huggingface.co\n\n\nPromptist 是 Stable Diffusion v1-4 的提示界面，可优化用户对模型首选提示的输入。Hugging Face Spaces 的在线演示正在使用 CPU，因此预计生成速度较慢。请使用 GPU 在本地加载模型以加快生成速度。\n\n\n\n\nPublic Prompts\n\n\n提示\n\n\nhttps://publicprompts.art\n\n\n图像生成的高质量和开源提示集合\n\n\n\n\nImg2prompt\n\n\n提示\n\n\nhttps://replicate.com\n\n\n获取与图像匹配的近似文本提示。（针对深度学习文生图模型进行了优化（剪辑 ViT-L/14））\n\n\n\n\nPromptBase\n\n\n提示\n\n\nhttps://promptbase.com\n\n\n查找最佳提示，产生更好的结果，节省 API 成本，销售您自己的提示。DALL·E，GPT-3，Midjourney，深度学习文生图模型提示市场。\n\n\n\n\nPromptBox\n\n\n提示\n\n\nhttps://promptbox.ai\n\n\n在不同的 AI 工具中组织、编辑和保存您的 AI 提示。提供保存等功能以提示使用右键单击。\n\n\n\n\nJrnylist\n\n\n提示\n\n\nhttps://jrnylist.com\n\n\n中途提示助手。- 浏览数十个分类为艺术与插图或资产与 UI 的提示 您也可以提交自己的提示。\n\n\n\n\nPromptLayer\n\n\n提示\n\n\nhttps://promptlayer.com\n\n\nPromptLayer 是第一个允许您跟踪和管理 GPT 提示工程的平台。PromptLayer 充当您的代码和 OpenAI 的 python 库之间的中间件。PromptLayer 记录您所有的 OpenAI API 请求，允许您在 PromptLayer 仪表板中搜索和探索请求历史记录。\n\n\n\n\nEye for AI\n\n\n提示\n\n\nhttps://eyeforai.xyz\n\n\n将您喜欢的提示保存为模板，并在将来使用它们快速生成图像。模板可用于上传的图像或文本提示。\n\n\n\n\nDallelist\n\n\n提示\n\n\nhttps://dallelist.com\n\n\nDallelist 允许您使用图像和样式作为参考轻松生成提示。（关键字）他们也提供与 DallE 网站集成的 chrome 扩展。\n\n\n\n\nInteriorAI\n\n\n房地产\n\n\nhttps://interiorai.com\n\n\n使用人工智能获取室内设计理念，并为具有不同室内风格的房地产列表提供虚拟舞台室内设计。\n\n\n\n\nGetFloorPlan\n\n\n房地产\n\n\nhttps://getfloorplan.com\n\n\n将您的 2D 平面图转换为现代且设施齐全的 3D 布局，并使用 AI 进行 360 度虚拟游览，每天可容纳数千人。\n\n\n\n\nMaket\n\n\n房地产\n\n\nhttps://maket.ai\n\n\n我们的生成设计软件使建筑师、建筑商和开发人员能够立即快速生成数千个建筑计划。\n\n\n\n\nCoolAIid\n\n\n房地产\n\n\nhttps://coolaiid.com\n\n\n使用 AI 的室内设计理念。无论您是想要装饰还是只是需要一点灵感，我们都会使用 AI 产生独特的想法。\n\n\n\n\nAI Room Planner\n\n\n房地产\n\n\nhttps://airoomplanner.com\n\n\nAI 室内设计。为您的房间获取数百种室内设计理念 - 免费且无限制。\n\n\n\n\nScholarcy\n\n\n研究\n\n\nhttps://scholarcy.com\n\n\n通过阅读由 AI 提供支持的大型文章的摘要，节省数百小时。在几秒钟内提取关键事实、数据和参考资料。\n\n\n\n\nScispace\n\n\n研究\n\n\nhttps://typeset.io\n\n\n您的 AI Copilot 可以解码任何研究论文。阅读和理解科学文献的最快方式。突出显示令人困惑的文本、数学和表格以获得简单的解释。提出后续问题并获得即时答案。一种无需指定关键字即可搜索和查找相关论文的新方法。\n\n\n\n\nGalactica\n\n\n研究\n\n\nhttps://galactica.org\n\n\nGalactica 是一个接受过人类科学知识训练的人工智能。您可以将它用作一个新界面来访问和操作我们对宇宙的了解。\n\n\n\n\nElicit\n\n\n研究\n\n\nhttps://elicit.org\n\n\nElicit 使用语言模型来帮助您自动化研究工作流程，例如部分文献综述。Elicit 可以在没有完美关键字匹配的情况下找到相关论文，针对您的问题总结论文的要点，并从论文中提取关键信息。Elicit 还可以帮助完成其他研究任务，例如头脑风暴、摘要和文本分类。\n\n\n\n\nAdept\n\n\n研究\n\n\nhttps://adept.ai\n\n\nAdept 是一个 ML 研究和产品实验室，通过使人类和计算机能够创造性地协同工作来构建通用智能。\n\n\n\n\nPodcast\n\n\n研究\n\n\nhttps://podcast.ai\n\n\n人工智能生成的播客。上面有 2 个播客 - Lex Fridman 采访 Richard Feynman 和 Joe Rogan 采访 Steve Jobs。\n\n\n\n\nConsensus\n\n\n研究\n\n\nhttps://consensus.app\n\n\nConsensus 是一个搜索引擎，它使用 AI 直接从科学研究中即时提取、汇总和提炼发现。\n\n\n\n\nSocratic by Google\n\n\n研究\n\n\nhttps://socratic.org\n\n\n在 Google 人工智能的帮助下，摆脱科学、数学、文学、社会研究等学术问题的困扰，并获得每个学科重要概念的直观解释。\n\n\n\n\nML news\n\n\n资源\n\n\nhttps://machine-learning.news\n\n\n以日语汇总与 AI 和 ML 相关的新闻的网站。\n\n\n\n\nFlowGPT\n\n\n资源\n\n\nhttps://flowgpt.com\n\n\nFlowGPT：分享、发现和了解最有用的 ChatGPT 提示，这些提示可帮助您简化任务并提高工作效率。\n\n\n\n\nThe AI Times\n\n\n资源\n\n\nhttps://aitimespage.com\n\n\n了解 AI Times。订阅以将 AI Times 的问题从数字媒体直接发送到您的收件箱。\n\n\n\n\nAI Art Apps Database\n\n\n资源\n\n\nhttps://aiartapps.com\n\n\n面向设计师和提示工程师的 AI 艺术资源、工具和灵感。找到 AI 艺术所需的一切。\n\n\n\n\nInfranodus\n\n\n销售\n\n\nhttps://infranodus.com\n\n\n使用 AI 和网络思维产生想法和洞察力。InfraNodus 结合了文本分析、网络可视化和 GPT-3 AI 来帮助您研究一篇文章，增强您的阅读、写作和研究工作流程。从多个导入源获取任何文本的概要概览，揭示主要主题及其之间的关系，找出模式和差距，发现正确的问题以推进您的思考和研究。\n\n\n\n\nReply.io\n\n\n销售\n\n\nhttps://reply.io\n\n\n使用 Reply 的 AI Sales Email Assistant 在几秒钟内大规模生成类似人类的销售电子邮件。在 GPT-3 语言预测模型的支持下，您的冷邮件和后续邮件将始终高度相关和个性化，从而提高您的打开率和回复率！\n\n\n\n\nRegie\n\n\n销售\n\n\nhttps://regie.ai\n\n\nRegie 使用 AI 帮助销售、营销和成功团队更快地编写引人入胜的内容\n\n\n\n\nCresta\n\n\n销售\n\n\nhttps://cresta.com\n\n\n自助服务、现场指导和电话后见解。AI 可以揭示专业知识，因此团队可以让每一次客户对话都有价值。\n\n\n\n\nOmneky\n\n\n销售\n\n\nhttps://omneky.com\n\n\nOmneky - 全渠道创意编排\n\n\n\n\nOutplayhq\n\n\n销售\n\n\nhttps://outplayhq.com\n\n\nOutplay 是一个一体化的多渠道销售参与平台，可帮助销售团队完成更多交易并显着增加收入。\n\n\n\n\nUsetwain\n\n\n销售\n\n\nhttps://usetwain.com\n\n\n世界一流的销售技巧触手可及。免费使用 Twain 查看您的销售宣传中缺少什么。\n\n\n\n\nIndustrial Data Labs\n\n\n销售\n\n\nhttps://industrialdatalabs.com\n\n\n在 BOM 工作流程中嵌入 AI。内部销售团队花费无数小时手动将物料清单电子表格中的数据输入报价系统和 ERP。我们经过行业培训的 AI 可自动执行此手动流程，让您的销售团队可以将更多时间用于销售。\n\n\n\n\nMarbleFlows\n\n\n销售\n\n\nhttps://app.marbleflows.com\n\n\nAI 生成的表格可转化更多潜在客户。\n\n\n\n\nGETitOUT\n\n\n销售\n\n\nhttps://getitout.io\n\n\nGETitOUT 是一个 AI 角色和文本生成器。营销与人物角色一起使用效果更好。但是为每个项目和客户创建它们？不好玩，至少到现在为止。了解 GETitOUT 的 Persona Generator：从竞争对手那里提取角色。生成专业文本。然后将它们粘贴到您所有的网站、电子邮件和营销工具中。\n\n\n\n\nKlaviyo SMS Assistant\n\n\n销售\n\n\nhttps://klaviyo.com\n\n\n使用 Klaviyo 的新人工智能短信助手在几秒钟内编写短信活动\n\n\n\n\nSmartwriter\n\n\n销售\n\n\nhttps://smartwriter.ai\n\n\n使用 AI 创建高度个性化的冷电子邮件或 Linkedin 消息，将读者转化为客户。无需经验。寻找潜在客户，创建量身定制的个性化文案并进行销售。人工智能冷电子邮件\n\n\n\n\nLavender\n\n\n销售\n\n\nhttps://lavender.ai\n\n\nLavender 是一套完整的工具，可帮助您在更短的时间内获得更多回复。使用 Email AI 编写更好的电子邮件、更快地实现个性化并指导您的团队。\n\n\n\n\nAndi\n\n\n搜索引擎\n\n\nhttps://andisearch.com\n\n\nAndi 正在使用生成式 AI 寻找下一代。Andi 不仅提供链接，还为您提供答案 - 就像与聪明的朋友交谈一样。\n\n\n\n\nOne More AI\n\n\n搜索引擎\n\n\nhttps://onemoreai.com\n\n\nAI 生成的库存图片 查找人工智能生成的数千张图片。\n\n\n\n\nAnyPod\n\n\n搜索引擎\n\n\nhttps://anypod.ai\n\n\n为创作者打造的 AI 搜索引擎。轻松搜索您最喜欢的播客，例如“我的第一百万”。您还可以提交添加播客的表格。\n\n\n\n\nKailua Labs\n\n\n搜索引擎\n\n\nhttps://app.kailualabs.com\n\n\n在您的应用程序中构建强大的多模式搜索。使用我们的 API，通过 AI 轻松搜索您的图像、视频、音频等。\n\n\n\n\nExplore AI\n\n\n搜索引擎\n\n\nhttps://exploreai.vercel.app\n\n\n由 AI 提供支持的语义搜索引擎。直接在数千个 YouTube 视频中搜索答案，免费、易于浏览且快速。\n\n\n\n\nLooria\n\n\n搜索引擎\n\n\nhttps://looria.com\n\n\nLooria 会找到适合您的需求和预算的最佳产品。他们从最值得信赖的来源收集评论，过滤掉虚假评论，并总结调查结果，以便您做出更明智的购买决定。\n\n\n\n\nChatGPT Chrome Extension\n\n\n搜索引擎\n\n\nhttps://chrome.google.com\n\n\n在 Google、Bing、DuckDuckGo 搜索结果旁边显示 ChatGPT 响应。它为您的查询提供了令人惊讶的详细解决方案 - 从编写舞会提案到修复代码。\n\n\n\n\nEverypixel\n\n\n搜索引擎\n\n\nhttps://everypixel.com\n\n\n由 AI 提供支持的搜索引擎，可为 50 个付费和免费图片网站编制索引，并允许用户在几秒钟内搜索庞大的图片数据库。您还可以按图像和各种搜索过滤器进行搜索，使您能够按颜色、方向和图像类型进行搜索。您还可以比较来自不同网站的图像价格并按作者搜索。\n\n\n\n\nSteno\n\n\n搜索引擎\n\n\nhttps://steno.ai\n\n\n您最喜爱的播客，完全转录 在您收听时发现、参考和阅读。\n\n\n\n\nKrea\n\n\n搜索引擎\n\n\nhttps://krea.ai\n\n\n探索数百万 AI 生成的图像并创建提示集合。具有稳定的扩散世代。\n\n\n\n\nDreamsands\n\n\n搜索引擎\n\n\nhttps://dreamsands.ai\n\n\nDreamsands 是一个创意市场，您可以在其中许可、收集和分享您感兴趣的 AI 生成艺术图像。\n\n\n\n\nGenerated Photos\n\n\n搜索引擎\n\n\nhttps://generated.photos\n\n\n使用完全由 AI 生成的照片增强您的创意作品。通过我们分类和标记的应用程序查找模型图像，或通过 API 集成图像。\n\n\n\n\nNeevaAI\n\n\n搜索引擎\n\n\nhttps://neeva.com\n\n\nNeevaAI 提供真实、实时的 AI 搜索。它将 AI 的强大功能与搜索堆栈相结合，为您提供快速、准确和最新的结果。并且，它提供了信息的来源。\n\n\n\n\nContext\n\n\n搜索引擎\n\n\nhttps://addcontext.xyz\n\n\n你最喜欢的内容。转录和搜索。Context 是一个由 AI 驱动的搜索引擎，可以在大量音频和视频内容中找到您正在寻找的任何时刻。您可以搜索 Mr Beast 和 MKBHD 等创作者的内容。\n\n\n\n\nPerplexity AI\n\n\n搜索引擎\n\n\nhttps://perplexity.ai\n\n\nPerplexity AI 是一个人工智能搜索引擎。这是一个受 OpenAI WebGPT 启发的演示，不是商业产品。他们使用大型语言模型（OpenAI API）和搜索引擎。还通过将自然语言转换为 SQL 代码来回答 Twitter 图形查询。\n\n\n\n\nAlgolia\n\n\n搜索引擎\n\n\nhttps://algolia.com\n\n\n适合您业务的最佳搜索和发现平台 Algolia 为构建者提供搜索和推荐服务，以创造世界一流的数字体验。\n\n\n\n\nYou\n\n\n搜索引擎\n\n\nhttps://you.com\n\n\n您可以控制的搜索引擎。\n\n\n\n\nRosebud\n\n\n搜索引擎\n\n\nhttps://rosebud.ai\n\n\nAI 生成的视觉效果我们让您轻松获得所需的准确视觉效果。\n\n\n\n\nNyx\n\n\n搜索引擎\n\n\nhttps://nyx.gallery\n\n\n本网站上的图像是用人工智能生成的，因此“不真实”。你会看到的食物、动物、风景等等都不存在！\n\n\n\n\nPromptHero\n\n\n搜索引擎\n\n\nhttps://prompthero.com\n\n\n通过 DALL-E、Stable Diffusion、Midjourney 等 AI 模型搜索数以百万计的艺术图像……\n\n\n\n\nWritesonic\n\n\n搜索引擎优化\n\n\nhttps://writesonic.com\n\n\nWritesonic 是一个人工智能作家，可以免费为博客、Facebook 广告、谷歌广告和 Shopify 创建对 SEO 友好的内容。我们的释义工具可让您立即改写整篇文章。\n\n\n\n\nMentioned\n\n\n搜索引擎优化\n\n\nhttps://mentioned.ai\n\n\n自动驾驶的影响者外展和链接建设。我们扫描您的内容以识别您提到的人和公司，然后发送电子邮件活动让他们知道。\n\n\n\n\nBlogNLP\n\n\n搜索引擎优化\n\n\nhttps://blognlp.com\n\n\nBlogNLP 是一款免费的 AI 博客写作工具，可帮助您打破作者的障碍，在短时间内创建原创内容。\n\n\n\n\nCTRify\n\n\n搜索引擎优化\n\n\nhttps://ctrify.com\n\n\n第一个 AI 驱动的 SEO 操作平台只需为我们的人工智能提供一个关键字即可创建在 Google 上排名的网站。得益于我们来自世界各地顶级移动运营商的住宅 IP 连接的数百万真实桌面和移动设备的有机流量，提升您的 SERP 排名、有机点击率、停留时间和 Pogo 粘性。\n\n\n\n\nJenni\n\n\n搜索引擎优化\n\n\nhttps://jenni.ai\n\n\n你写，Jenni 完成 用最先进的 AI 写作助手增强你的写作。\n\n\n\n\nClosers Copy\n\n\n搜索引擎优化\n\n\nhttps://closerscopy.com\n\n\n通过 SEO 优化博客和不可抗拒的营销文案促进您的销售。利用世界上最强大的文案的秘密……让您的文案机器人将它们变为现实！\n\n\n\n\nKafkai\n\n\n搜索引擎优化\n\n\nhttps://kafkai.com\n\n\nKafkai 是一种机器学习算法，可以从头开始写文章。面向营销人员和 SEO 的尖端技术。\n\n\n\n\nSpinrewriter\n\n\n搜索引擎优化\n\n\nhttps://spinrewriter.com\n\n\n需要独特的内容？观看如何在 45 秒内将一篇文章改写成 500 篇文章。借助 ENL 技术，Spin Rewriter 是 SEO 专家的完美工具，他们需要独特的、人性化的内容才能在 Google 上获得更高的排名。\n\n\n\n\nWriter\n\n\n搜索引擎优化\n\n\nhttps://writer.com\n\n\nDiscover Writer，适用于团队的 AI 写作平台。随处制作清晰、一致且符合品牌的内容。今天免费试用。\n\n\n\n\nLongShot\n\n\n搜索引擎优化\n\n\nhttps://longShot.ai\n\n\n使用人工智能创建人类和搜索引擎喜欢的博客。LongShot 是一款 AI 写作助手，可帮助您和您的团队创建有用的博客，并在 Google 上排名。\n\n\n\n\nWord Spinner\n\n\n搜索引擎优化\n\n\nhttps://word-spinner.com\n\n\n立即将任何文章或文本重写为 SEO 友好的独特内容。Word Spinner 可以让您的写作前所未有地闪耀，对于任何想要提高写作技巧的人来说，它都是一个不错的选择。\n\n\n\n\nNeuronwriter\n\n\n搜索引擎优化\n\n\nhttps://neuronwriter.com\n\n\n优化您的网站内容，让 Google 喜欢它。具有语义模型 (NLP)、Google SERP 分析和竞争数据的高级内容编辑器。NEURONwriter 帮助您在考虑用户意图的情况下规划和优化内容！\n\n\n\n\nTopicmojo\n\n\n搜索引擎优化\n\n\nhttps://topicmojo.com\n\n\nTopic mojo 是一种用于内容研究的 AI 工具。获取可帮助您发展在线业务的分析功能。\n\n\n\n\nCompar\n\n\n搜索引擎优化\n\n\nhttps://compar.ai\n\n\nAI 支持的内容分析。\n\n\n\n\nTypli\n\n\n搜索引擎优化\n\n\nhttps://typli.ai\n\n\n最直观的 AI 内容工具，结合了 AI 写作和 SEO 助手。\n\n\n\n\nEilla AI\n\n\n搜索引擎优化\n\n\nhttps://eilla.ai\n\n\nEilla.AI 是一款人工智能助手，可为您的企业、博客、广告、电子邮件和逼真的图像或艺术生成高质量的内容。免费开始，无需信用卡！\n\n\n\n\nLetterdrop\n\n\n搜索引擎优化\n\n\nhttps://letterdrop.com\n\n\n创建的内容增加 32%，速度更快，麻烦更少。Letterdrop 简化并自动化您的内容操作。\n\n\n\n\nWritey AI\n\n\n搜索引擎优化\n\n\nhttps://writey.ai\n\n\n改变内容的创建方式。使用人工智能更快地创建内容。最先进的语言 AI 第一个真正的免费抄袭 AI，具有原创和研究内容，检查 Writey AI 的实际应用\n\n\n\n\nAI-Writer\n\n\n搜索引擎优化\n\n\nhttps://ai-writer.com\n\n\nAI-Writer是最精准的内容生成平台。使用最先进的 AI 写作模型从标题生成文章。\n\n\n\n\nScalenut\n\n\n搜索引擎优化\n\n\nhttps://scalenut.com\n\n\n制作以简单且可扩展的方式服务于您的业务目标的内容。引导工作流程仅需 5 分钟即可完成博客！\n\n\n\n\nWordhero\n\n\n搜索引擎优化\n\n\nhttps://wordhero.co\n\n\n借助 WordHero 的 AI 技术，您可以在几秒钟内创建原创博客文章、社交媒体内容、电子邮件等。\n\n\n\n\ngrowthbar\n\n\n搜索引擎优化\n\n\nhttps://growthbarseo.com\n\n\n使用 AI 为博客文章、网站页面和文章编写完美的 SEO 友好内容。\n\n\n\n\nKatteb\n\n\n搜索引擎优化\n\n\nhttps://katteb.com\n\n\nKatteb AI 可以快速轻松地为您的博客和在线商店创建内容。\n\n\n\n\nThundercontent\n\n\n搜索引擎优化\n\n\nhttps://thundercontent.com\n\n\n使用 AI 生成内容。Thundercontent 使用人工智能帮助您以光速撰写关于任何主题的独特文章。扩展您的内容策略。克服作家的障碍。您还可以使用 Thundercontent 生成音频。\n\n\n\n\nMoonbeam\n\n\n搜索引擎优化\n\n\nhttps://gomoonbeam.com\n\n\nMoonbeam 的 AI 将为您提供编写杀手级长篇内容所需的一切。在 10 分钟内将写作能力提高 2 倍。\n\n\n\n\nCopymatic\n\n\n搜索引擎优化\n\n\nhttps://copymatic.ai\n\n\n使用 AI 在几秒钟内生成内容和复制使用 AI 来增加您的流量并节省工作时间。自动编写独特、引人入胜且高质量的副本或内容：在几秒钟内从长篇博文或登陆页面到数字广告。\n\n\n\n\nArticleForge\n\n\n搜索引擎优化\n\n\nhttps://articleforge.com\n\n\n从产品描述到整个博客文章，只需单击一下，Article Forge 就可以提供关于任何主题的独特的、SEO 优化的、高质量的内容。\n\n\n\n\nBrameWork\n\n\n搜索引擎优化\n\n\nhttps://bramework.com\n\n\n写博客文章的速度提高 5 倍。Bramework 是一款易于使用的 AI 作家，可帮助博主、自由职业者和代理机构在每篇博文中节省时间。\n\n\n\n\nInstaSalesAI\n\n\n社交媒体助手\n\n\nhttps://instasalesai.com\n\n\nInstaSalesAI 是用于 Instagram 营销的人工智能工具的集合。您可以使用它来生成轮播内容或营销挂钩。\n\n\n\n\nFeedHive\n\n\n社交媒体助手\n\n\nhttps://feedhive.com\n\n\n使用 FeedHive 的人工智能平台大规模创建、安排、发布和轻松管理您的社交媒体内容。拖放计划、自动生成主题标签以及最活跃的时间安排和精湛的分析。\n\n\n\n\nPredis\n\n\n社交媒体助手\n\n\nhttps://predis.ai\n\n\nPredis.AI 是一种人工智能驱动的内容生成器，可帮助在几秒钟内创建令人惊叹的社交媒体帖子。它提供多种功能，例如创意生成、参与度预测、内容推荐、主题标签推荐和创意建议。\n\n\n\n\nTweet Hunter\n\n\n社交媒体助手\n\n\nhttps://tweethunter.io\n\n\n建立您的 Twitter 受众并从中获利。获得销售、增长和新网络。比你目前正在尝试的更快。\n\n\n\n\nContenda\n\n\n社交媒体助手\n\n\nhttps://contenda.co\n\n\n一个统一的内容存储库，可以比代理机构更好更快地重新利用技术内容\n\n\n\n\nEditby\n\n\n社交媒体助手\n\n\nhttps://editby.ai\n\n\n您是否发现自己很难想出有趣的推文？开始使用 AI 像著名的 Twitter 帐户一样写作，这样您就不必再担心作家的瓶颈了。\n\n\n\n\nSpatial\n\n\n社交媒体助手\n\n\nhttps://spatial.ai\n\n\n使用实时社交媒体细分系统预测和影响客户行为。它根据人们的社交、移动和网络活动以及描述某个位置附近社交活动的类型和速度的地点对他们进行细分。\n\n\n\n\nSocialBu\n\n\n社交媒体助手\n\n\nhttps://socialbu.com\n\n\nSocialBu 是提高社交媒体影响力和最大化结果的完美解决方案。发布、响应、分析和自动化 - 全部在 SocialBu 中完成。\n\n\n\n\nTweetEmote\n\n\n社交媒体助手\n\n\nhttps://TweetEmote.com\n\n\nAI 驱动的推文助手，可帮助用户撰写富有表现力且引人入胜的推文。还可以通过编写提示和选择情绪来创建对您想要的任何推文的智能回复。\n\n\n\n\nRepl AI\n\n\n社交媒体助手\n\n\nhttps://replai.so\n\n\n使用 AI 创建有意义的 Twitter 回复的 Chrome 扩展。Replai.so 是与社区建立联系、在社交媒体上显得聪明、有趣、专业、显得更聪明并以 10 倍的努力增加您的受众的最简单方式。你可以在 chrome 网上商店找到它。\n\n\n\n\nCrawlQ.ai\n\n\n社交媒体助手\n\n\nhttps://crawlq.ai\n\n\n与您的观众一起创造“品牌之爱”。CrawlQ 提供具有全球影响力的高情感、高同理心、高投资回报率、以受众为中心的创意作品。\n\n\n\n\nGraham AI\n\n\n社交媒体助手\n\n\nhttps://grahamai.co\n\n\n像 AI 生成的天才技术影响者一样发推文。\n\n\n\n\nAI Social Bio\n\n\n社交媒体助手\n\n\nhttps://aisocialbio.com\n\n\n您的社交媒体简历，由人工智能创建。\n\n\n\n\nSheetGod\n\n\n电子表格\n\n\nhttps://boloforms.com\n\n\n使用简单的英语和 SheetGod 创建复杂的 Excel 公式。我们的 AI 驱动工具还允许您创建宏、正则表达式和基本任务，以及 Google Appscript 代码片段来自动执行您的日常手动工作。立即尝试并体验 SheetGod 的强大功能。\n\n\n\n\nGoodlookup\n\n\n电子表格\n\n\nhttps://goodlookup.com\n\n\nGoodlookup 是电子表格用户的智能功能。它将 AI 语言模型的优势带给普通人。\n\n\n\n\nExcel Formula Bot\n\n\n电子表格\n\n\nhttps://excelformulabot.com\n\n\n在 AI 的帮助下，在几秒钟内将您的文本指令转换为 Excel 公式。停止浪费时间创建 Excel 公式。体验 Excel 和 Google 表格 AI 公式生成器的全部功能，在几秒钟内解决问题。\n\n\n\n\nSheet+\n\n\n电子表格\n\n\nhttps://sheetplus.ai\n\n\n从文本生成 Google 表格和 Excel 公式，将公式转换为简单的解释、调试公式等。\n\n\n\n\nSheet AI\n\n\n电子表格\n\n\nhttps://sheetai.app\n\n\n适用于 Google 表格和 Excel（即将推出）跳过学习，直接开始工作。使用 AI 将您的文本指令快速转换为 Google 表格公式。（2-3 周后上线）\n\n\n\n\nAIHelperBot\n\n\n数据库\n\n\nhttps://aihelperbot.com\n\n\n使用 AI 即时构建 SQL 查询。无需先验 SQL 知识即可构建 SQL 查询。加入 1000 多人的行列，开始提高您的 SQL 熟练程度和工作效率。还支持 MongoDB 等 NoSQL 数据库。\n\n\n\n\nAI Data Sidekick\n\n\n数据库\n\n\nhttps://airops.com\n\n\n使用我们强大的秘诀集，编写 SQL、文档等的速度提高 10 倍。‍个人和小团队免费。\n\n\n\n\nChannel\n\n\n数据库\n\n\nhttps://usechannel.com\n\n\n用英语（自然语言）提问并自动生成您需要的 SQL、答案和可视化。与团队成员协作快速创建仪表板，然后使用频道建议的问题进一步探索您的数据。\n\n\n\n\nAi2sql\n\n\n数据库\n\n\nhttps://ai2sql.io\n\n\n使用 AI2sql，工程师和非工程师都可以在不了解 SQL 的情况下轻松编写高效、无错误的 SQL 查询。\n\n\n\n\nAvanty\n\n\n数据库\n\n\nhttps://avanty.app\n\n\n永远不要再浪费宝贵的数据分析师时间来编写无聊的 SQL 查询。Avanty 是一种基于 AI 的数据查询 + 商业智能工具，让每个人都能以更低的成本更快地从数据中获得洞察力。\n\n\n\n\nBroadn\n\n\n启动\n\n\nhttps://broadn.io\n\n\n跟随你的好奇心，开阔你的视野。\n\n\n\n\nPaperade\n\n\n启动\n\n\nhttps://paperade.co\n\n\nPaperade 是第一个基于 AI 的工具，可以从超过 1 亿篇学术论文和研究中生成商业用例和公司创意。这就像拥有创业理念方面的博士学位。\n\n\n\n\nTome\n\n\n启动\n\n\nhttps://beta.tome.app\n\n\n生成式叙事的未来就在这里。使用 Tome 的 AI 驱动的讲故事格式解锁您的最佳作品。\n\n\n\n\nRationale\n\n\n启动\n\n\nhttps://rationale.jina.ai\n\n\nRationale 是一款帮助企业家和管理者做出艰难决定的应用程序。只需输入您的未决决定，他们的人工智能应用程序就会列出优缺点或生成 SWOT 分析来帮助您权衡您的选择\n\n\n\n\nNamelix\n\n\n启动\n\n\nhttps://namelix.com\n\n\nNamelix 将使用人工智能生成一个简短的品牌企业名称。也非常适合发现新域名 😃\n\n\n\n\nFinta\n\n\n启动\n\n\nhttps://trustfinta.com\n\n\n只需一个工具即可完成所有工作，为您的筹款活动提供支持。Finta 是您的筹款副驾驶。端到端地自动化您的工作流程，这样您就可以重新开始发展您的业务。\n\n\n\n\nIdeabuddy\n\n\n启动\n\n\nhttps://ideabuddy.com\n\n\n将您的经营理念变为现实。多合一的商业规划软件，可帮助您将伟大的想法变成成功的企业。\n\n\n\n\nValidator AI\n\n\n启动\n\n\nhttps://validatorai.com\n\n\n任何想法的 AI 业务验证器。在 AI 的支持下，验证并接收有关任何创业想法的建设性反馈。它首先列出您在经营业务时可能遇到的潜在困难，然后给出关于您的经营理念的总体反馈。\n\n\n\n\nDurable\n\n\n启动\n\n\nhttps://durable.co\n\n\n在 30 秒内让您的业务在线。面向个人企业主的人工智能平台。生成一个网站，自动化您的营销，并管理您的财务。\n\n\n\n\nPitchgrade\n\n\n启动\n\n\nhttps://pitchgrade.com\n\n\n在您的推销平台上获得即时反馈，因此筹款成为您最不关心的事情。\n\n\n\n\nNamewizard.ai\n\n\n启动\n\n\nhttps://namewizard.ai\n\n\nNamewizard 允许您为您的想法/项目/启动想出一个 AI 生成的名称。您还可以根据生成的名称浏览可用域。\n\n\n\n\nSubtxt\n\n\n说故事的人\n\n\nhttps://subtxt.app\n\n\nSubtxt 是唯一符合作者直觉的智能大纲，而不是违背直觉。\n\n\n\n\nFabled\n\n\n说故事的人\n\n\nhttps://fabled.ai\n\n\n终极 AI 故事生成器。由您创作的故事，由 AI 提供支持。用一句话 fabled.AI 制作个人插图故事，并通过令人惊叹的图像进行丰富。免费试用！\n\n\n\n\nArtflow ai\n\n\n说故事的人\n\n\nhttps://artflow.ai\n\n\n毫不费力地将想法转化为动画故事，让创造力流动起来。Artflow.AI 可让您使用 AI 生成的资产创建您自己的、具有原始角色的独特动画故事。\n\n\n\n\nOnce Upon A Bot\n\n\n说故事的人\n\n\nhttps://onceuponabot.com\n\n\n使用 AI 创作原创故事。告诉 OnceUponABot 您的故事创意，机器人将使用 AI 从头开始编写故事。\n\n\n\n\nNovelAI\n\n\n说故事的人\n\n\nhttps://novelai.net\n\n\nGPT 驱动的 AI Storyteller。在 AI 的驱动下，构建独特的故事、激动人心的故事、诱人的浪漫故事，或者只是胡闹。什么都可以！！\n\n\n\n\nStoriesForKids\n\n\n说故事的人\n\n\nhttps://storiesforkids.ai\n\n\n一起阅读和创造。在手机上几秒钟内将现实生活中的情景变成有趣的故事和插图。\n\n\n\n\nNeural Canvas\n\n\n说故事的人\n\n\nhttps://neuralcanvas.io\n\n\nNeural Canvas 是一种数字插图生成器服务，能够为您的漫画、博客文章、电子书、故事、收藏等生成独特的插图。使用它创建您自己的 AI 生成的漫画。\n\n\n\n\nBedtimeStory AI\n\n\n说故事的人\n\n\nhttps://bedtimestory.ai\n\n\n在几秒钟内创建个性化的即时睡前故事。生成一个关于您孩子的故事，包括一些家庭成员作为角色，并添加类型、故事风格、道德等等——使用人工智能生成。他们的开放图书馆有 5000 多个故事。探索社区创造的所有故事。您可以为故事点赞、将它们加入您的收藏夹、重新混合*它们、与朋友分享、阅读给您的孩子听。\n\n\n\n\nScene One\n\n\n说故事的人\n\n\nhttps://sceneone.app\n\n\n最好的图书写作软件。使用我们直观的写作应用程序编写更多故事，花更少的时间学习复杂的功能。\n\n\n\n\nStoryWizard\n\n\n说故事的人\n\n\nhttps://storywizard.ai\n\n\n创造精彩的儿童故事 通过使用人工智能帮助您生成独特而美丽的儿童故事，这些故事具有生动的画面和有趣的情节。\n\n\n\n\nStory Path\n\n\n说故事的人\n\n\nhttps://storypath.app\n\n\n由 AI 提供支持的图书规划应用程序 计划您的故事或在几分钟内解决您的作家的瓶颈 对您的情节接下来的发展方向感到困惑，或者有一个需要充实的故事想法？仅通过简短描述，Story Path 就会为您的情节生成分支选项。展开并探索您最喜欢的路径，并根据您的喜好自定义细节。\n\n\n\n\nWhat on earth?\n\n\n说故事的人\n\n\nhttps://whatonearth.xyz\n\n\n一种学习新事物的有趣方式。仅需一个单词提示即可生成故事。\n\n\n\n\nSummate\n\n\n摘要器\n\n\nhttps://summate.it\n\n\n总结网络文章的实验性 AI 工具。该站点使用全文 RSS 进行文章提取，使用 OpenAI 进行文章摘要。\n\n\n\n\nTLDR this\n\n\n摘要器\n\n\nhttps://tldrthis.com\n\n\nTLDR 可帮助您将任何一段文本概括为简洁、易于理解的内容。从信息过载中解脱出来。\n\n\n\n\nUpword\n\n\n摘要器\n\n\nhttps://upword.ai\n\n\n使用 Upword 轻松总结您的内容。将他们强大的 AI 工具与您自己的笔记相结合，以创建更快、更高效的摘要，您可以阅读或收听。\n\n\n\n\nWordfixerBot\n\n\n摘要器\n\n\nhttps://wordfixerbot.com\n\n\nWordfixerBot 是释义器、语法检查器、文本摘要器和文本比较工具。\n\n\n\n\nGenei\n\n\n摘要器\n\n\nhttps://genei.io\n\n\n自动总结背景阅读并更快地生成博客、文章和报告。\n\n\n\n\nOtter AI\n\n\n摘要器\n\n\nhttps://otter.ai\n\n\n从会议中捕捉和分享见解。Otter 记录会议，实时做笔记，并生成自动摘要以与所有人共享并帮助您记住一切。\n\n\n\n\nBearly\n\n\n摘要器\n\n\nhttps://bearly.ai\n\n\n对研究人员非常有用的 AI 工具 - 它可用于创建摘要、大纲或改写文章。\n\n\n\n\nSummari\n\n\n摘要器\n\n\nhttps://summari.com\n\n\n改善您网站上的阅读体验。使用我们世界一流的 AI 摘要技术将链接升级为简短、信息丰富的预览。\n\n\n\n\nSummarize Tech\n\n\n摘要器\n\n\nhttps://summarize.tech\n\n\n人工智能驱动的视频摘要。获取任何长 YouTube 视频的摘要，例如讲座、现场活动或政府会议。\n\n\n\n\nExplainThis\n\n\n摘要器\n\n\nhttps://explainthis.ai\n\n\n一个 chrome 扩展，可以用通俗易懂的语言向您解释概念。AI 助手只需单击一下即可提供整个页面的摘要。当您没有太多时间或想要一个简洁的总和时，这很有用\n\n\n\n\nGPT-Prompter\n\n\n摘要器\n\n\nhttps://gptprompter.com\n\n\nChrome 扩展程序可以快速解释所选文本。\n\n\n\n\nSummerEyes\n\n\n摘要器\n\n\nhttps://summereyes.ai\n\n\n一键总结互联网上的任何文本。提高您的工作效率。在很短的时间内达到目的。\n\n\n\n\nWellsaidlabs\n\n\n文字转语音\n\n\nhttps://wellsaidlabs.com\n\n\n美妙的声音触手可及，文字转语音令人着迷。降低成本并简化语音制作过程。\n\n\n\n\nReplicastudios\n\n\n文字转语音\n\n\nhttps://replicastudios.com\n\n\n为您的创意项目合成 AI 语音。使用 Replica Voice 创建自然而富有表现力的语音表演。\n\n\n\n\nAd Auris\n\n\n文字转语音\n\n\nhttps://play.ad-auris.com\n\n\n随时随地收听文章！创建文章播放列表并在 Spotify、Apple Podcasts 和 Google Podcasts 上收听它们。\n\n\n\n\nFakeYou\n\n\n文字转语音\n\n\nhttps://fakeyou.com\n\n\n使用 FakeYou 将文本转换为语音，并用您喜欢的角色说话。还可以获取您自己的语音克隆，用于音乐、视频、twitch 奖励以及您想要的任何内容。\n\n\n\n\nListnr\n\n\n文字转语音\n\n\nhttps://listnr.tech\n\n\nAI 语音生成器具有 80 多种语言的 600 多种画外音，在几秒钟内从文本到语音，以 MP3 或 WAV 格式轻松导出您的声音。\n\n\n\n\nResemble\n\n\n文字转语音\n\n\nhttps://resemble.ai\n\n\n具有语音克隆功能的 AI 语音生成器，用于文本到语音的转换。\n\n\n\n\nAudioread\n\n\n文字转语音\n\n\nhttps://audioread.com\n\n\n将您的阅读变成播客。在您的播客应用程序中收听任何文章、PDF、电子邮件等。\n\n\n\n\nWhisper\n\n\n文字转语音\n\n\nhttps://github.com\n\n\nWhisper 是一种通用的语音识别模型。它在不同音频的大型数据集上进行训练，也是一个多任务模型，可以执行多语言语音识别以及语音翻译和语言识别。\n\n\n\n\nDescript\n\n\n文字转语音\n\n\nhttps://descript.com\n\n\n创建语音的文本到语音模型。尝试现场演示。\n\n\n\n\nSymbl.ai\n\n\n文字转语音\n\n\nhttps://symbl.ai\n\n\n集成实时语音转文本和上下文理解。由先进的深度学习模型提供支持。从非结构化对话数据启用实时字幕、跟踪用户意图、生成摘要等。\n\n\n\n\nMurf AI\n\n\n文字转语音\n\n\nhttps://murf.ai\n\n\n使用多功能 AI 语音生成器将文本转换为语音 将 Murf 逼真的 AI 声音用于播客、视频和所有专业演示\n\n\n\n\nPlay.ht\n\n\n文字转语音\n\n\nhttps://play.ht\n\n\n人工智能驱动的文本到语音生成器。使用我们的在线 AI 语音生成器和最佳合成语音生成逼真的文本到语音 (TTS) 音频。立即将文本转换为听起来自然的语音并下载为 MP3 和 WAV 音频文件。\n\n\n\n\nApple Books\n\n\n文字转语音\n\n\nhttps://apple.com\n\n\n由文本到语音 AI 讲述的有声读物现在可以通过 Apple 的 Books 获得。最初仅适用于浪漫小说和小说书籍，其中列出了两个可用的数字声音：麦迪逊和杰克逊。\n\n\n\n\nArticle.Audio\n\n\n文字转语音\n\n\nhttps://article.audio\n\n\n懒得看文章？没问题，听听吧！将文章转换为音频\n\n\n\n\nConvai\n\n\n文字转语音\n\n\nhttps://convai.com\n\n\n易于使用的对话式 AI API，用于语音识别、语言理解和生成以及文本到语音转换。设计您的游戏和支持语音的应用程序。设计基于对话的角色和基于语音的游戏。\n\n\n\n\nSpeechify\n\n\n文字转语音\n\n\nhttps://speechify.com\n\n\n让格温妮丝·帕特洛 (Gwyneth Paltrow) 和史努比狗狗 (Snoop Dogg) 等名人朗读您的文字。适用于 Chrome、iOS、Android 和 Mac 的文字转语音。\n\n\n\n\nEleven Labs\n\n\n文字转语音\n\n\nhttps://levenlabs.io\n\n\n语音的未来。第一个以任何语音和任何语言生成长格式语音的平台。我们使用 AI 为寻求终极叙事质量的创作者和出版商带来最自然、最引人注目的声音。\n\n\n\n\nCoqui\n\n\n文字转语音\n\n\nhttps://coqui.ai\n\n\nCoqui，言论自由。\n\n\n\n\nFree Subtitles AI\n\n\n转录员\n\n\nhttps://freesubtitles.ai\n\n\n使用这个免费的开源应用程序为电影生成字幕！\n\n\n\n\nfireflies.ai\n\n\n转录员\n\n\nhttps://fireflies.ai\n\n\n会议的 AI 助手 录制、转录和搜索语音对话。\n\n\n\n\nWhisper Memos\n\n\n转录员\n\n\nhttps://whispermemos.com\n\n\nWhisper Memos 是一款应用程序，可以记录您的声音并在几分钟后向您发送一封包含转录内容的电子邮件。用它来记录快速的想法、提醒和每日日记条目。\n\n\n\n\nSupertranslate\n\n\n转录员\n\n\nhttps://supertranslate.ai\n\n\n一键添加准确的英文字幕到任何语言的视频。您可以上传 100 多种语言的视频，Supertranslate 会自动生成英文字幕。Supertranslate 由 OpenAI 的 Whisper 提供支持，它是世界上最准确的语音转文本系统。它对背景噪音、语言混合和口音都很稳健。\n\n\n\n\nType Studio\n\n\n视频编辑\n\n\nhttps://typestudio.co\n\n\nType Studio 是一种基于文本的视频编辑器，可以自动将您的视频转录为文本。他们还有用于视频编辑、字幕、播客、重新调整用途和录制的快速工具。\n\n\n\n\nContentfries\n\n\n视频编辑\n\n\nhttps://contentfries.com\n\n\n使用 ContentFries 获取数十个内容片段。以比以往更快的速度提前数周或数月创建上下文内容。他们还有一个字幕创建软件 - 120 多种语言和方言的自动字幕。\n\n\n\n\nTopaz Video AI\n\n\n视频编辑\n\n\nhttps://topazlabs.com\n\n\n无限制地访问世界领先的生产级神经网络，用于视频放大、去隔行、运动插值和抖动稳定——所有这些都针对您的本地工作站进行了优化。\n\n\n\n\nShuffll\n\n\n视频编辑\n\n\nhttps://shuffll.com\n\n\nShuffll 是一个尖端的视频制作平台，它使用 AI 技术简化创作过程。我们的平台使企业能够轻松创建高质量、个性化的视频内容，所用时间仅为使用传统方法所需时间的一小部分。\n\n\n\n\nGling\n\n\n视频编辑\n\n\nhttps://gling.ai\n\n\nGling 是一款专为视频内容创作者打造的 AI 工具。他们的 AI 将为您消除沉默和糟糕的镜头，因此您可以专注于您的 YouTube 视频。\n\n\n\n\nPictory\n\n\n视频编辑\n\n\nhttps://pictory.ai\n\n\nPictory 是一种视频营销工具，可以从长格式内容自动创建简短、高度共享的品牌视频。将您的脚本和博客文章自动变成引人入胜的视频。\n\n\n\n\nRunwayml\n\n\n视频编辑\n\n\nhttps://runwayml.com\n\n\n探索高级视频编辑功能，让您的创作更上一层楼。\n\n\n\n\nUnscreen.com\n\n\n视频编辑\n\n\nhttps://unscreen.com\n\n\n删除视频背景，100% 自动且免费。使用 Unscreen，您可以在任何地方录制您的镜头，然后简单地摆脱背景。\n\n\n\n\nColourlab\n\n\n视频编辑\n\n\nhttps://colourlab.ai\n\n\n好莱坞遇上人工智能。Colourlab AI 借助全新的突破性人工智能工具，通过自动进行颜色匹配和平衡，使颜色分级变得快速、简单和简单。\n\n\n\n\nPapercup\n\n\n视频编辑\n\n\nhttps://papercup.com\n\n\n发现更快、更实惠的自动配音，并利用您现有的视频内容走向全球。使用 AI 以英语、西班牙语、葡萄牙语和意大利语配音您的内容。它们被 BBC、Sky News 和 Insider 等公司使用。\n\n\n\n\nDubverse\n\n\n视频编辑\n\n\nhttps://dubverse.ai\n\n\n最简单（也是最神奇）的视频配音方式。只需单击一个按钮，即可使您的内容支持多种语言，并覆盖更多人。\n\n\n\n\nVidyo.ai\n\n\n视频编辑\n\n\nhttps://vidyo.ai\n\n\n立即将长视频制作成短视频。使用强大的 AI 从您现有的视频中创建短片 ✨ 节省 90% 的时间和精力。\n\n\n\n\nMunch\n\n\n视频编辑\n\n\nhttps://getmunch.com\n\n\n自动将长视频转换为社交媒体的数据驱动短片。Munch 通过收集 TikTok、IG、YT 和 FB 用户的最高兴趣并将其应用到您的 AI 生成的剪辑中来产生曝光率和参与度。\n\n\n\n\nFILM\n\n\n视频生成器\n\n\nhttps://replicate.com\n\n\n电影 - 大场景运动的帧插值。在两个现有图像（插值）之间生成帧以尝试创建动画。\n\n\n\n\nAstria\n\n\n视频生成器\n\n\nhttps://astria.ai\n\n\n量身定制的人工智能图像生成。开始创建您的独特图像。\n\n\n\n\nWaymark\n\n\n视频生成器\n\n\nhttps://waymark.com\n\n\nWaymark 的 AI 视频创建器可以轻松为任何潜在客户创建规格创意。现在，您可以带着完全定制的样本广告走进每一场会议。\n\n\n\n\nFliki\n\n\n视频生成器\n\n\nhttps://fliki.ai\n\n\n在 2 分钟内使用逼真的声音从脚本或博客文章创建视频！将博客文章转换为视频。逼真的文字转语音。丰富的股票媒体库。受到来自 Google、Meta、Bytedance 和 Upwork 等公司的 30k+ 内容创作者的信任。\n\n\n\n\nSynthesia\n\n\n视频生成器\n\n\nhttps://synthesia.io\n\n\n只需输入文本即可创建 AI 视频。易于使用、便宜且可扩展。与真人演示者一起制作引人入胜的视频 - 直接从您的浏览器。免费演示。\n\n\n\n\nSteve AI\n\n\n视频生成器\n\n\nhttps://steve.ai\n\n\nSteve AI 是面向社交媒体和内容营销人员的 AI 视频制作者，用于创建实时和动画视频。在 Steve AI 的帮助下，您可以将博客文章、脚本或文本内容转换为用于社交媒体的小型视频。它的功能包括创意人工智能、搜索人工智能和全自动解决方案。\n\n\n\n\nInVideo\n\n\n视频生成器\n\n\nhttps://invideo.io\n\n\n释放视频的力量。借助 InVideo，每个人都可以创建更吸引人、带来更多潜在客户并节省时间的精美专业视频。我们的库包含 5000 多个模板、过渡和效果，可帮助您轻松、快速、高效地创建视频。无需下载。\n\n\n\n\nOpus\n\n\n视频生成器\n\n\nhttps://opus.ai\n\n\n把文字变成电影和游戏。\n\n\n\n\nWowTo\n\n\n视频生成器\n\n\nhttps://wowto.ai\n\n\n在几分钟内创建操作视频并托管引人入胜的视频知识库。建立视频知识库。\n\n\n\n\nColossyan\n\n\n视频生成器\n\n\nhttps://colossyan.com\n\n\nColossyan Creator 让视频创作变得简单无压力。与真人演员一起探索我们的 AI 视频创作者。在不到 5 分钟的时间内创建视频。从这里开始免费。\n\n\n\n\nXpression Camera\n\n\n视频生成器\n\n\nhttps://xpressioncamera.com\n\n\nXpression Camera 是一款屡获殊荣的虚拟相机应用程序，它允许用户使用一张照片立即变身为任何人或任何有脸的人，而无需任何处理时间。xpression 相机使用户能够在使用 Zoom 等应用聊天、在 Twitch 上直播或创建 YouTube 视频时实时重新定义他们的屏幕角色。\n\n\n\n\nMovio\n\n\n视频生成器\n\n\nhttps://movio.la\n\n\n当你可以使用 AI 视频编辑器来创建一个代言人时，为什么还要付钱给代言人呢？MOVIO 是一种顶级合成媒体，可以将您的文本转换为视频。\n\n\n\n\nPyttipanna\n\n\n视频生成器\n\n\nhttps://pyttipanna.xyz\n\n\nPyttipanna 是 Pytti 5 的一个界面。它允许您构建、叙述和试验视频创建的提示。Pytti 是一个使用机器学习模型创建和渲染视频的框架。\n\n\n\n\nPeech\n\n\n视频生成器\n\n\nhttps://peech-ai.com\n\n\n将您的内容团队变成不可阻挡的创作者。自动转录、编辑、重新利用和标记您的视频内容 - 所有这些都在一个地方并大规模制作视频内容。\n\n\n\n\nWonder Dynamics\n\n\n视频生成器\n\n\nhttps://wonderdynamics.com\n\n\n在 Wonder Dynamics，我们将 AI 技术与一流的故事讲述相结合。\n\n\n\n\nCreative Reality Studio (D-ID)\n\n\n视频生成器\n\n\nhttps://studio.d-id.com\n\n\n世界上第一个结合了 GPT-3、Stable Diffusion 和 D-ID 独特的面部动画技术的平台。我们的生成式 AI 会在几秒钟内将您的视野变成会说话的化身。\n\n\n\n\nLiveReacting AI\n\n\n视频生成器\n\n\nhttps://livereacting.com\n\n\n使用我们的 AI 主持人提升您的现场表演。节省时间和金钱，同时为您的观众提供互动和引人入胜的体验。\n\n\n\n\nAudiolabs\n\n\n视频生成器\n\n\nhttps://audiolabs.io\n\n\n将您的播客转换为适合 TikTok、YouTube Shorts 和 Reels 的短视频的平台。接触新的播客听众并推动业务成果 🎙️在短格式平台上发布视频剪辑充当听众发现您的库存并收听完整剧集或其他营销目标的“钩子”\n\n\n\n\nHourone\n\n\n视频生成器\n\n\nhttps://hourone.ai\n\n\n欢迎来到 Hour One——世界上发展最快的 AI 视频制作者。我们将文字转为视频，让学习和发展变得更加有趣和有效。现在试试！\n\n\n\n\nVidIQ\n\n\n视频生成器\n\n\nhttps://vidiq.com\n\n\n使用 AI 提升您的 YouTube 观看次数。获得免费的见解和指导，以保持您的频道不断发展。"
  },
  {
    "objectID": "posts/473bdfde-c954-47bf-8374-eaf94dff3e14/index.html",
    "href": "posts/473bdfde-c954-47bf-8374-eaf94dff3e14/index.html",
    "title": "anime video sites",
    "section": "",
    "text": "https://animethemes.moe/"
  },
  {
    "objectID": "posts/693d4caf-8b73-4470-a512-ae9117c1faee/index.html",
    "href": "posts/693d4caf-8b73-4470-a512-ae9117c1faee/index.html",
    "title": "add certificate to termux, especially for fastgithub",
    "section": "",
    "text": "install openssl-tools then use add-trusted-certificate against the .crt file, so curl will work fine (still not for elinks, i wonder why that works on macos and linux, or maybe not? just use playwright instead.)\nchromebook is different. you need to export the proxy to 0.0.0.0 by means of nginx or something, so you can configure proxy to 100.115.92.14 or 100.115.92.2 as seen in termux by ifconfig"
  },
  {
    "objectID": "posts/82746164-6c4e-4447-a40c-f4747b7d74d1/index.html",
    "href": "posts/82746164-6c4e-4447-a40c-f4747b7d74d1/index.html",
    "title": "amdgpu, rocm and pytorch",
    "section": "",
    "text": "rocm is trash to apu. use vulkan or opengl (alternative backends)\n\nfind latest build in pytorch nightly repo\nuse sudo before invoking amdgpu related commands, otherwise unavailable\n\nuse directml (pytorch, tensorflow) instead. need windows.\nyou need to set the shared graphical memory to a larger value.\nrocm does not work for integrated graphic cards (even if you build it and configured the card name), and supported amd cards are limited."
  },
  {
    "objectID": "posts/3dc696c8-9eef-40ed-b10d-f1f1020b5c26/index.html",
    "href": "posts/3dc696c8-9eef-40ed-b10d-f1f1020b5c26/index.html",
    "title": "android remote control, app automation",
    "section": "",
    "text": "run android in docker, run adb in docker\ndevice discovery, termux daemon, remote unlock\nunlock requires screenshot and input events.\nhttps://technastic.com/unlock-android-phone-pin-pattern-adb/\nclick ok after input password:\nhttps://stackoverflow.com/questions/29072501/how-to-unlock-android-phone-through-adb\nscrcpy client\nhttps://github.com/leng-yue/py-scrcpy-client\nhttps://leng-yue.github.io/py-scrcpy-client/guide.html#bind-events\nyou want to use android emulator on macos m1?\nhttps://github.com/google/android-emulator-m1-preview/releases/tag/0.3\ncheck android screen lock/unlock state\nhttps://android.stackexchange.com/questions/191086/adb-commands-to-get-screen-state-and-locked-state\nBonjour/Avahi/Zeroconf\nlogic: if the kill switch is off, when no physical input events happens, or not focused on scrcpy window with keyboard/mouse input events on pc for some time, allow to interact with the phone.\nget physical events:\nwarning: this command could be offline for a short period of time after using the scrcpy. must automatically reconnect if the device is not offline.\nadb -s 192.168.10.3:5555 shell getevent\nto get focused window title:\nhint: for headless ssh sessions, must set apropriate xorg environment variables, eg: env XAUTHORITY=\"/run/user/0/gdm/Xauthority\" DISPLAY=:1 python3\ngeneral method:\nimport pywinctl\npywinctl.getActiveWindowTitle()\nfor linux:\nwatch -n 2 xdotool getactivewindow getwindowname\nfor macos: (allow permission first, deprecated since it will not get the window title instead of the program name)\nhttps://alvinalexander.com/mac-os-x/applescript-unix-mac-osx-foreground-application-result/\n(where is the window name?)\nsleep 3 && osascript -e 'tell application \"System Events\"' -e 'set frontApp to name of first application process whose frontmost is true' -e 'end tell'\nto get input events on macos:\ndownload keylogger here:\nhttps://hackernoon.com/writing-an-keylogger-for-macos-in-python-24adfa22722\nhttps://github.com/beatsbears/pkl?ref=hackernoon.com\npython pkl_nowriting.py\ninput events on linux:\nxinput test-xi2 --root"
  },
  {
    "objectID": "posts/7e30797e-b76f-45f8-8ac6-77a15a5569c4/index.html",
    "href": "posts/7e30797e-b76f-45f8-8ac6-77a15a5569c4/index.html",
    "title": "virtual phone numbers and public/anonymous accounts",
    "section": "",
    "text": "attach to virtual phone number providers, login bilibili or other websites with that phone number, register cookies, then monetize that account like posting ads\nyou can also use bugmenot"
  },
  {
    "objectID": "posts/8af19f01-dc07-443f-a6fc-fe16550b337a/index.html#async-client",
    "href": "posts/8af19f01-dc07-443f-a6fc-fe16550b337a/index.html#async-client",
    "title": "async requests with python, used for clash multiple proxy delays",
    "section": "async client",
    "text": "async client\naiohttp\naiohttp-requests\nrequests-async\nhttp3 (requests-async successor)\nmany_requests\ncurequests\nasks\ntrip\nrequest-futures"
  },
  {
    "objectID": "posts/8af19f01-dc07-443f-a6fc-fe16550b337a/index.html#async-non-blocking-server",
    "href": "posts/8af19f01-dc07-443f-a6fc-fe16550b337a/index.html#async-non-blocking-server",
    "title": "async requests with python, used for clash multiple proxy delays",
    "section": "async non-blocking server",
    "text": "async non-blocking server\ntrequests"
  },
  {
    "objectID": "posts/9f0e9e01-5c47-4dd3-aee1-72c31b5743d0/index.html",
    "href": "posts/9f0e9e01-5c47-4dd3-aee1-72c31b5743d0/index.html",
    "title": "audio-visual active speaker detection",
    "section": "",
    "text": "leaderboard\nspell+"
  },
  {
    "objectID": "posts/9356c462-5cca-4d41-a624-ba5c39190469/index.html#robotics",
    "href": "posts/9356c462-5cca-4d41-a624-ba5c39190469/index.html#robotics",
    "title": "autonomous lazero bot, controlling computer using natural language instructions",
    "section": "robotics",
    "text": "robotics\nRT-1 robotics transformer and SayCan\nVIMA General Robot Manipulation with Multimodal Prompts"
  },
  {
    "objectID": "posts/9356c462-5cca-4d41-a624-ba5c39190469/index.html#multimodal-model",
    "href": "posts/9356c462-5cca-4d41-a624-ba5c39190469/index.html#multimodal-model",
    "title": "autonomous lazero bot, controlling computer using natural language instructions",
    "section": "multimodal model",
    "text": "multimodal model\nmagma a GPT-style multimodal model that can understand any combination of images and language\nVersatile-Diffusion Text, Images and Variations All in One Diffusion Model"
  },
  {
    "objectID": "posts/9356c462-5cca-4d41-a624-ba5c39190469/index.html#ai-based-reinforcement-gui-testing",
    "href": "posts/9356c462-5cca-4d41-a624-ba5c39190469/index.html#ai-based-reinforcement-gui-testing",
    "title": "autonomous lazero bot, controlling computer using natural language instructions",
    "section": "AI based reinforcement GUI testing",
    "text": "AI based reinforcement GUI testing\nglider tasklet crawler\nGUI based bug detection using RL"
  },
  {
    "objectID": "posts/0eba6e9a-5283-4413-a07d-a1f792c4d2e2/index.html#offline-backup",
    "href": "posts/0eba6e9a-5283-4413-a07d-a1f792c4d2e2/index.html#offline-backup",
    "title": "backup schedules",
    "section": "offline backup",
    "text": "offline backup\n\nschedule pyjom on alpharetta backup to disk every 12 hours\nset a notice to let me execute time machine backup every 1 week (next scheduled backup: thu aug 18)"
  },
  {
    "objectID": "posts/0eba6e9a-5283-4413-a07d-a1f792c4d2e2/index.html#online-backup",
    "href": "posts/0eba6e9a-5283-4413-a07d-a1f792c4d2e2/index.html#online-backup",
    "title": "backup schedules",
    "section": "online backup",
    "text": "online backup\n\nsend systemwide notification if aliyun disk token expires, with reacquiring method broadcasted\nschedule pyjom on alpharetta backup to cloud disks every 12 hours"
  },
  {
    "objectID": "posts/1f1f5c9a-fdd6-4008-a411-4212add7d05b/index.html",
    "href": "posts/1f1f5c9a-fdd6-4008-a411-4212add7d05b/index.html",
    "title": "badass tricks, earning plans",
    "section": "",
    "text": "you talk about planting virus in software when people need it, also sharing some encrypted porn/copyrighted material to users, or mining crypto through github ci, exploits. when doing so, make sure the money is laundried, either through transfer between multiple crypto accounts or some professional agencies.\nfor github jobs, you may use terraform since it has some github automation tools"
  },
  {
    "objectID": "posts/95f223f8-3c4b-495c-95ee-b7efa6da8922/index.html",
    "href": "posts/95f223f8-3c4b-495c-95ee-b7efa6da8922/index.html",
    "title": "bilibili up主 入站了解 运作机制",
    "section": "",
    "text": "bilibili up主 入站了解 运作机制 开篇动画\n视频提交之后 转码（可能会二次压缩）\nai加人工审核 血腥 暴力 色情（ai识别）\n涉政 时政 版权 违反社区规范\n推荐系统\n根据场景特点（分区 话题 标签 相关度） 用户行为（点击率） 稿件互动质量（回复的内容是否是积极的）\n精准 多样（不能重复 完全一样） 视频内容\n热门热搜筛选更严格 没进去不是流量限流\n限流是流量更高的时候 第二道审核出现问题\n锤人 引战 粗俗的问题"
  },
  {
    "objectID": "posts/9f4f592d-2051-441c-815a-0213551c3ae0/index.html",
    "href": "posts/9f4f592d-2051-441c-815a-0213551c3ae0/index.html",
    "title": "bilibili 生活区up 培训",
    "section": "",
    "text": "bilibili 生活区up 培训"
  },
  {
    "objectID": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#卖东西",
    "href": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#卖东西",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "卖东西",
    "text": "卖东西\n自建网店平台：saleor"
  },
  {
    "objectID": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#开播",
    "href": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#开播",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "开播",
    "text": "开播\nb站网页获取开播地址 rtmp\n【神奇弹幕】哔哩哔哩直播万能机器人，弹幕姬+答谢姬+回复姬+点歌姬+各种小骚操作，目前唯一可编程机器人 可以实现自动开播\nBilibili直播工具 自动登录并获取推流地址，可以用于电脑、树莓派等设备无人值守直播\napi reference"
  },
  {
    "objectID": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#渲染-内容生成",
    "href": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#渲染-内容生成",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "渲染 内容生成",
    "text": "渲染 内容生成\n无后端的仿 YouTube Live Chat 风格的简易 Bilibili 弹幕姬"
  },
  {
    "objectID": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#监控",
    "href": "posts/4b51c92e-f89b-408b-bbc4-1c1e700628f8/index.html#监控",
    "title": "bilibili直播api 直播工具 自动直播 自动推流",
    "section": "监控",
    "text": "监控\n直播间监控websocket\n监听直播间消息的服务"
  },
  {
    "objectID": "posts/91ca9cac-a5fc-48e5-bcb7-44025404920b/index.html",
    "href": "posts/91ca9cac-a5fc-48e5-bcb7-44025404920b/index.html",
    "title": "b站根据视频内容自动生成推荐的标签",
    "section": "",
    "text": "B站允许最多10个标签\n不能发布太频繁, B站官方限制30秒一稿\nsome upload api\nthis api does not analyze the video content. it only predict tags from metadata:\nhttps://member.bilibili.com/x/web/archive/tags\nhow to get upload_id\n只有PC网页端有这个 手机端没有 可能是新功能\nb站最新更新了这两个接口 需要传入upload_id 具体参数抓包获取\n分区推荐 POST：\nhttps://member.bilibili.com/x/vupre/web/archive/types/predict\n标签推荐 GET（可能有延迟 需要请求两次 因为第一次标签数量较少）：\nhttps://member.bilibili.com/x/vupre/web/tag/recommend\n获取活动标签:\nhttps://member.bilibili.com/x/vupre/web/topic/type?type_id=21&pn=0&ps=200&title=20210210_298667075925_waou_5s&t=1667530591393"
  },
  {
    "objectID": "posts/d0b9856e-dd90-4c52-952c-17e1a66c1b3e/index.html",
    "href": "posts/d0b9856e-dd90-4c52-952c-17e1a66c1b3e/index.html",
    "title": "call ruby from python",
    "section": "",
    "text": "rb_call\npuby"
  },
  {
    "objectID": "posts/ba2db5d8-fc28-4ced-adb6-4755613fdc24/index.html",
    "href": "posts/ba2db5d8-fc28-4ced-adb6-4755613fdc24/index.html",
    "title": "Understanding Captchas: Assessing Capabilities, Not Behaviors",
    "section": "",
    "text": "captcha for turing test\ncaptchas are used for public automated turing tests\nhowever, it is not behavior based but rather like capability/skill based."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#fine-tuning-and-tricks",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#fine-tuning-and-tricks",
    "title": "chatgpt clones, computer automation with ai",
    "section": "fine-tuning and tricks",
    "text": "fine-tuning and tricks\nPEFT (Parameter Efficient Fine Tuning) supports LoRA, Prefix Tuning, P-Tuning and Prompt Tuning."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#computer-automation-with-ai",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#computer-automation-with-ai",
    "title": "chatgpt clones, computer automation with ai",
    "section": "computer automation with ai",
    "text": "computer automation with ai\n\nvirtual machines and environments\nit is not feasible to install ubuntu arm on macos m1 with virtualbox. use utm.app instead. instructions on installing ubuntu with utm includes guides on sharing clipboard and directory.\n\n\npapers\nplaying atari using q-learning (viewing deepmind paper with arxiv vanity)\n\n\nmodels\nvideo pretraining can perform minecraft diamond mining tasks with keyboard and mouse movements\ncode and model\n\nmm-cot (multimodal chain-of-thought) by amazon, with model weights\n\n\ndata collectors and controllers\nmss for screenshot, remember to save raw pixels to SSD, then compress into mp4 with ffmpeg for further training (mind the timestamp!)\n\ngo-vncdriver by openai, to compile you need to clone the repo and modify code to find headers for libjpeg-turbo and python.\nlibvncdriver\nasyncvnc (supports apple vnc), side project: asyncssh\npython-vnc-client with keydown/keyup event support\nvncdotool\npyVNC\n\npynput as input event listener and actor, listener may have some strange keycodes when pressing modifier keys on windows.\nnote that special care needed for aligning mouse location with screenshot size\n\nViT-pytorch can be used in many ViT-based models, listed and implemented in the repo.\n\n\nspaces\nopenai universe (blog post here) and starter agents, remotes are using vnc protocol and a reward protocol using websocket sending json (can send actions). they prefer TigerVNC, maybe that will send the existing monitor instead of invisible ones.\ngym is classic and modular. atari-py enables old games\nretro deprecates universe, but might help with general computer controlling AI systems since they are compatible. human don’t play games all day and night. beware of this and don’t turn the model into a heavy gamer.\nthere is no meaning of recording terminal input/output when using tools like vim. get screenshots, keystrokes and mouse clicks instead (using ttyd, gremlins.js or monkey.js). tkterminal won’t do. it is just a thin wrapper around subprocess.run\ntalking of browser, you can spin up novnc server and let the gremlins.js do its job."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#accelerators",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#accelerators",
    "title": "chatgpt clones, computer automation with ai",
    "section": "accelerators",
    "text": "accelerators\n\ncformers\ncpu only\nable to install from pip\n\n\nggml\ncpu only\ncpp, only compile from source\n\n\nflexgen\ngpu is mandatory, better than deepspeed and Hugging Face Accelerate"
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#open-source-model-and-weights",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#open-source-model-and-weights",
    "title": "chatgpt clones, computer automation with ai",
    "section": "open source model and weights",
    "text": "open source model and weights\nawesome decentralized llm listed up-to-date related chatgpt-like repositories, datasets, model weights and resources.\n\nmodel weights of open source chatgpt alternatives:\n\n\n\nweight path\nmodel size\nmodel name\nauthor\n\n\n\n\nopenchatgpt-neox-125m\n125m\ngpt-neox\nmrsteyk\n\n\nopenchatgpt-neo-125m\n125m\ngpt-neo\nmrsteyk\n\n\n\n\nLLaMA\nit’s public.\n\n\n\nweight path\nmodel name\nauthor\n\n\n\n\nllama-13b-hf-int4\n13b\ndecapoda-research\n\n\nllama-65b-hf-int4\n65b\ndecapoda-research\n\n\nllama-30b-hf-int4\n30b\ndecapoda-research\n\n\nllama-7b-hf-int4\n7b\ndecapoda-research\n\n\nllama-30b-hf\n30b\ndecapoda-research\n\n\nllama-65b-hf\n65b\ndecapoda-research\n\n\nllama-13b-hf\n13b\ndecapoda-research\n\n\nllama-7b-hf\n7b\ndecapoda-research\n\n\nllama-smallint-pt\nunknown\ndecapoda-research\n\n\nllama-7b-hf-int8\n7b\ndecapoda-research\n\n\n\n\n\nChatYuan\nv2 is censored.\n\nmodel weights:\n\n\n\nweight path\nmodel size\nmodel name\nauthor\n\n\n\n\nChatYuan-large-v1\nunknown\nunknown\nClueAI\n\n\nChatYuan-large-v2-paddle\nunknown\nunknown\nClueAI\n\n\nChatYuan-large-v2\nunknown\nunknown\nClueAI\n\n\nChatYuan-large-v1-paddle\nunknown\nunknown\nClueAI\n\n\n\n\n\nDeepshard\nLLaMA trained on custom instruction dataset.\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ndeepshard-13B-ft\n13b\ndeepshard\nswype\n\n\ndeepshard-13B-raw\n13b\ndeepshard\nswype\n\n\n\n\n\nChatGLM\nCurrently only open-sourced 6B version.\nYou can train ChatGLM using GXT3090: simple_thu_chatglm6b\nUsing 7GB VRAM, train ChatGLM with P-tuning\nchatglm_finetuning supports loading from int4 weights\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nchatglm-6b-int4-slim\n6b\nchatglm\nsilver\n\n\nchatglm-6b-slim\n6b\nchatglm\nsilver\n\n\nchatglm-6b-int4-qe-slim\n6b\nchatglm\nsilver\n\n\nchatglm-6b-int4\n6b\nchatglm\nTHUDM\n\n\nchatglm-6b-int4-qe\n6b\nchatglm\nTHUDM\n\n\nchatglm-6b\n6b\nchatglm\nTHUDM\n\n\n\n\n\nChatDoctor\nLLaMA-65B trained on medical dataset InstructorDoctor-200k\n\n\nBELLE\n开源中文对话大模型\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nBELLE-LLAMA-7B-0.6M\n7B\nLLaMA\nBelleGroup\n\n\nBELLE-LLAMA-7B-2M\n7B\nLLaBLOOMZMA\nBelleGroup\n\n\nBELLE-LLAMA-7B-2M-gptq\n7B\nLLaMA\nBelleGroup\n\n\nBELLE-LLAMA-13B-2M\n13B\nLLaMA\nBelleGroup\n\n\nBELLE-7B-gptq\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-2M\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-0.6M\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-0.2M\n7B\nBLOOMZ\nBelleGroup\n\n\nBELLE-7B-1M\n7B\nBLOOMZ\nBelleGroup\n\n\n\n\n\nbaize\ntrained on ChatGPT self-chatting data\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nbaize-lora-30B\n30b\nbaize\nproject-baize\n\n\nbaize-lora-13B\n13b\nbaize\nproject-baize\n\n\nbaize-healthcare-lora-7b\n7B\nbaize\nproject-baize\n\n\nbaize-lora-7B\n7B\nbaize\nproject-baize\n\n\n\n\n\ndolly\nmodel arch is gpt-j, trained on alpaca dataset\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ndolly-v1-6b\n6b\ndolly\ndatabricks\n\n\ndolly-lora\nunknown\ndolly\nsamwit\n\n\n\n\n\nFastChat (Vicuna)\nweb interface\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\n\n\n\n\nvicuna\nunknown\nVicuna\n\n\nvicuna2\nunknown\nVicuna\n\n\nvicuna-13b-delta-v0\n13b\nVicuna\n\n\nvicuna-13b-GPTQ-4bit-128g\n13b\nvicuna\n\n\nggml-vicuna-13b-4bit\n13b\nvicuna\n\n\nvicuna-13b\n13b\nvicuna\n\n\nvicuna4all\n13b\nvicuna\n\n\n\ndownload official delta weights via [magnet](magnet:?xt=urn:btih:a7fac57094561a63d53eed943f904abf24c6969d&dn=Vicuna-13B-HF-fp16-delta-merged_2023-04-03&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce\nbased)\n\n\nBloom-z\nthere is bloomz.cpp, converted model weights on huggingface\n\n\nAlpaca\nalpaca is LLaMA tuned on ChatGPT self-instruct dataset. officially there is just code and dataset, model weights are community provided.\nggml version: alpaca.cpp\nexample on how to load PEFT patched alpaca model: alpaca-lora/generate.py\nit’s better to check for python bindings and webui like Alpaca-Turbo and Dalai for further development and interactions.\n\nfine-tuning:\nsimple-llama-finetuner using LoRA, 16GB VRAM minimum\nalpaca-lora: the OG LoRA alpaca\n\ncommunity model weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nalpaca-lora-7b\n7b\nAlpaca\ntloen\n\n\nAlpaca Native\n7B\nAlpaca\nchavinlo\n\n\nAlpaca-65B\n65B\nAlpaca\nchavinlo\n\n\nAlpaca 13B\n13B\nAlpaca\nchavinlo\n\n\nGPT4-X-Alpaca\n13B\nAlpaca\nchavinlo\n\n\nToolpaca\n13B\nAlpaca\nchavinlo\n\n\ninstruct-gpt-j-fp16\n6B\nGPT-J\nnlpcloud\n\n\nalpaca-30b\n30b\nAlpaca\nbaseten\n\n\nalpaca-lora-65b\n65b\nalpaca\nchansung\n\n\nalpaca-lora-30b\n30b\nalpaca\nchansung\n\n\nkoalpaca-lora-13b\n13b\nkoalpaca\nchansung\n\n\nalpaca-lora-13b\n13b\nalpaca\nchansung\n\n\nalpaca13B-lora\n13b\nalpaca\nsamwit\n\n\nalpaca7B-lora\n7b\nalpaca\nsamwit\n\n\nbloompaca-7b1-lora\n7b\nbloom\nsamwit\n\n\ngpt4-x-alpaca-native-13B-ggml\n13b\nalpaca\nPi3141\n\n\nalpaca-native-7B-ggml\n7b\nalpaca\nPi3141\n\n\nalpaca-native-13B-ggml\n13b\nalpaca\nPi3141\n\n\nalpaca-lora-30B-ggml\n30b\nalpaca\nPi3141\n\n\nalpaca-lora-7B-ggml\n7b\nalpaca\nPi3141\n\n\nalpaca-lora-13B-ggml\n13b\nalpaca\nPi3141\n\n\nalpaca-7b-native-enhanced\n7b\nalpaca\nPi3141\n\n\ngpt4-x-alpaca-13b-native-4bit-128g\n13b\nalpaca\nanon8231489123\n\n\nggml-gpt4-x-alpaca-13b-native-4bit\n13b\nalpaca\neachadea\n\n\nalpaca-13b-hf-fp16\n13b\nalpaca\nteknium\n\n\n\n\ncodealpaca only provides dataset for training a code generation model, there are multiple models trained on this dataset, including bloom-7b1-lora-codealpaca20k\n\n\ntogethercomputer\nreleased openchatkit with retrieval ability and its huggingface space\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nGPT-NeoXT-Chat-Base-20B\n20B\nGPT-NeoXT\ntogethercomputer\n\n\nPythia-Chat-Base-7B\n7B\nPythia\ntogethercomputer\n\n\n\n\nmoderation model weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nGPT-JT-Moderation-6B\n6B\nGPT-JT\ntogethercomputer\n\n\n\n\n\nSpikeGPT\ninspired by RWKV\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nSpikeGPT-BookCorpus\nunknown\nSpikeGPT\nridger\n\n\n\n\n\nRWKV\n\nRWKV combines attention with RNN so the token window can be much larger.\nLongformer is similar to this. Model weights in github repo or huggingface.\n\nnow we have rwkv.cpp (4bit quantization), build upon ggml and sure it works on cpu.\nrwkvstic (with 8bit & offload for low VRAM GPUs)\n\nRWKV-LoRA supports RWKV-v4-NeoX\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nRWKV-7B-alpaca-finetuned\n7b\nRWKV\nBlueSunflower\n\n\nrwkv-4-14B-alpaca-finetune-lora-weights\n14b\nRWKV\nBlueSunflower\n\n\nrwkv-fastquant\nunknown\nrwkv\nHazzzardous\n\n\nrwkv-onnx\nunknown\nrwkv\nHazzzardous\n\n\nRWKV-8Bit\nunknown\nrwkv\nHazzzardous\n\n\nrwkv-4-raven\nunknown\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-7b\n7b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-14b\n14b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-430m\n430m\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-3b\n3b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-1b5\n1.5b\nrwkv\nBlinkDL\n\n\nrwkv-4-pile-169m\n169m\nunknown\nBlinkDL\n\n\nrwkv-3-pile-1b5\n1.5b\nrwkv\nBlinkDL\n\n\nrwkv-3-pile-430m\n430m\nrwkv\nBlinkDL\n\n\nrwkv-2-pile-430m\n430m\nrwkv\nBlinkDL\n\n\nrwkv-3-pile-169m\n169m\nrwkv\nBlinkDL\n\n\nRWKV-LM-safetensors\nunknown\nRWKV\nmrsteyk\n\n\nopenchatrwkv-430m-r2.0.1\n430m\nRWKV\nmrsteyk\n\n\nopenchatrwkw-430m-r2\n430m\nRWKV\nmrsteyk\n\n\nopenchatrwkv-430m\n430m\nRWKV\nmrsteyk\n\n\n\nencrypted alpaca model weights released by point-network: point-alpaca\n\n\ngpt4all by nomic\nLLaMA trained on massive collection of clean assistant dialog data, with model weights\nyou need to install nomic to run the model:\npip3 install nomic\nto run it on gpu, you need to install this\n\n\nopenassistant\nresearchers of open-assistant like andreaskoepf has releasesed oasst-sft-3-pythia-12b-epoch-3.5 and still updating\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\noasst-llama-13b-2-epochs\n13b\nllama\ndvruette\n\n\noasst-llama-13b-1000-steps\n13b\nllama\ndvruette\n\n\noasst-gpt-neox-20b-1000-steps\n20b\ngpt-neox\ndvruette\n\n\noasst-gpt-neox-20b-3000-steps\n20b\ngpt-neox\ndvruette\n\n\noasst-pythia-12b-6000-steps\n12b\npythia\ndvruette\n\n\noasst-pythia-12b-3000-steps\n12b\npythia\ndvruette\n\n\noasst-pythia-12b-flash-attn-5000-steps\n12b\npythia\ndvruette\n\n\noasst-pythia-6.9b-4000-steps\n12b\npythia\ndvruette\n\n\noasst-sft-1-pythia-12b\n12b\npythia\nOpenAssistant\n\n\ngalactica-6.7b-finetuned\n6.7b\ngalatica\nOpenAssistant\n\n\noasst-sft-4-pythia-12b-epoch-3.5\n12b\npythia\nandreaskoepf\n\n\npythia-12b-pre-2000\n12b\npythia\nandreaskoepf\n\n\npythia-12b-pre-3500\n12b\npythia\nandreaskoepf\n\n\noasst-sft-3-pythia-12b-epoch-3.5\n12b\npythia\nandreaskoepf\n\n\noasst-sft-3-pythia-12b-epoch-2.35\n12b\npythia\nandreaskoepf\n\n\noasst-sft-2-candidiate-0\nunknown\nunknown\nandreaskoepf\n\n\noasst-sft-2-pythia-12b-4000\n12b\npythia\nandreaskoepf\n\n\noasst-sft-1-gpt-neox-2000\nunknown\ngpt-neox\nandreaskoepf\n\n\noasst-1_12b_4500\n12b\nunknown\nandreaskoepf\n\n\noasst-1_12b_1500\n12b\nunknown\nandreaskoepf\n\n\noasst-1_12b_3000\n12b\nunknown\nandreaskoepf\n\n\n\n\nreward model weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\nreward-model-deberta-v3-large\nunknown\ndeberta-v3\nOpenAssistant\n\n\nreward-model-deberta-v3-large-v2\nunknown\ndeberta-v3\nOpenAssistant\n\n\nreward-model-electra-large-discriminator\nunknown\nelectra-large\nOpenAssistant\n\n\nreward-model-deberta-v3-base\nunknown\ndeberta-v3\nOpenAssistant\n\n\noasst-rm-1-pythia-1b\n1b\npythia\nandreaskoepf\n\n\n\n\n\nopenflamingo\nusing CLIP ViT-L and LLaMA-7B, model weights on huggingface\n\n\ncerebras gpt\nopen sourced model weights and training code\n\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ncerebras-gpt-6.7b-lora\n6.7b\ncerebras-gpt\nsamwit\n\n\nCerebras-GPT-2.7B-Alpaca-SP\n2.7b\ncerebras-gpt\nlxe\n\n\nCerebras-GPT-2.7B-Alpaca-SP-ggml\n2.7b\ncerebras-gpt\nlxe\n\n\nlora-cerebras-gpt2.7b-alpaca-shortprompt\n2.7b\ncerebras-gpt\nlxe\n\n\nCerebras-GPT-13B\n13b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-6.7B\n6.7b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-2.7B\n2.7b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-1.3B\n1.3b\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-590M\n590m\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-256M\n256m\ncerebras-gpt\ncerebras\n\n\nCerebras-GPT-111M\n111m\ncerebras-gpt\ncerebras\n\n\n\n\n\nColossalChat\nCoati-7B has no public model weights, but claimed to be trained efficiently\nyou need to install LLaMA compatible transformers library\ntrain on InstructionWild"
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#enhancements",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#enhancements",
    "title": "chatgpt clones, computer automation with ai",
    "section": "enhancements",
    "text": "enhancements\n\nusing external tools\ntoolformer-pytorch (WORK IN PROGRESS)\n\nengshell: using LLM to execute command\n\n\nusing ai models\nMicrosoft JARVIS aka HuggingGPT leverages huggingface models so ChatGPT can complete complex multimodal tasks.\n\n\nretrieval plugins\nlong term memory for oobabooga/text-generation-webui (can run pythia, galatica, opt, gpt-j, gpt-4chan, rwkv and support quantization/acceleration), also\ncomplex memory (KoboldAI-like)\n\nchatpaper summarize paper content.\nsimilar website: typeset.io (can ask questions and explain confusing text, math symbols and tables)\nrelated projects: ChatReviewer ChatImprovement ChatResponse ChatGenTitle\n\nchatgpt retrieval plugin chop document into chunks, process them into vectors and search them using one of many vector search backends. hosted as a fastapi service."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#datasets",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#datasets",
    "title": "chatgpt clones, computer automation with ai",
    "section": "datasets",
    "text": "datasets\n\nassistant dialogue\nbotbots dataset (two chatgpt talking to each other), created by using datasetGPT (LLM automation tool)\n\nShareGPT52k, also ShareGPT90k (Vicuna)\n\ninstruct-102.4k by swype\n\ndatasets by BELLE:\ntrain_1M_CN\ntrain_0.5M_CN\nmultiturn_chat_0.8M\nschool_math_0.25M\n\n\nunsupervised pretraining\nFandom23K (text classification), part of BigKnow2022\nKinda LLaMA replicates LLaMA dataset, including scraped webpages, code and stackexchange data.\noscar-corpus needs to be downloaded with access token, by accepting agreement with account. containing categorized content and adult content."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#dataset-preprocessing",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#dataset-preprocessing",
    "title": "chatgpt clones, computer automation with ai",
    "section": "dataset preprocessing",
    "text": "dataset preprocessing\ndeduplicate text dataset in rust, may remove verbose substrings like “to go to the”\noscar project (Open Super-large Crawled Aggregated coRpus) contains some tool for adult content filtering and deduplication."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#nlp-tools-training-methods",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#nlp-tools-training-methods",
    "title": "chatgpt clones, computer automation with ai",
    "section": "NLP tools & training methods",
    "text": "NLP tools & training methods\nfasttext for efficient learning of word representations and sentence classification.\n\nlangchain\nprompt-engine\nchatml: markup language for ChatGPT, by openai\nreact-agent-ts enables LLM to chat and use tools by internal dialogues.\nbabyagi: AI-powered task management system. original post on twitter\n\nChain-of-hindsights (can learn from negative feedback) in jax and pytorch"
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#interfaces",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#interfaces",
    "title": "chatgpt clones, computer automation with ai",
    "section": "interfaces",
    "text": "interfaces\nserge is dockerized and the needs of RAM is according to the size of the model (alpaca), using CPU only"
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#viable-approaches-to-chatgpt",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#viable-approaches-to-chatgpt",
    "title": "chatgpt",
    "section": "viable approaches to chatgpt",
    "text": "viable approaches to chatgpt\naccording to my point of view, chatgpt is just specialized on chat, or socialized in other words.\nthe elo rating system is the key to facebook social network, many zero-sum games. basically it is some revolution rating system. to do such rating system effectively one shall use along with classifiers and embeddings.\naccording to the training process of instructgpt and webgpt, we know that gpt has learned more by interacting with people (multiple QA), doing self-examination (learning a reward model) and performing actions (searching and quoting on web).\n\nRLHF\n\nchainer, prompt engineering\nawesome chatgpt prompts\nlangchain extending llm by advanced prompts, llm wrappers actions, databases and memories\n\n\nRL algorithms, tools for providing feedback\nAwesome-RLHF paper and code about RLHF\nopenai baselines\nstable-baselines 3\nSetFit\nEfficient few-shot learning with Sentence Transformers, used by FewShotRLGPT (no updates till now?)\n\n\nRLHF models\n\nnon-language models\nimage_to_text_rlhf\nalgorithm-distillation-rlhf\n\n\nlanguage models\nchatrwkv pure rnn language model, with chinese support\nlamda-rlhf-chatgpt\nblenderbot2 a bot which can search internet, blenderbot3 is US only. install ParlAI then clone ParlAI_SearchEngine. tutorial\npromptCLUE based on T5, created by clueai, trained on pCLUE\nopenassistant\nopenchatgpt-neox-125m trained on chatgpt prompts, can be tested here, trained from pythia\ncopycat chatgpt replicate\nmedicine-chatgpt shit sick of COVID-19\nbaby-rlhf both cartpole and languge model\nrlhf-shapespeare\ntextrl 100+stars\nPaLM-RLHF claims RETRO will be integrated soon?\nRL4LMs with multiple rl methods\nminRLHF\nwebgpt-cli interface openai api to browse web and answer questions\nlm-human-preferences by openai\nrlhf-magic using trlx (supports GPT3-like models) which has PPO and ILQL (as trainable model)\ntrl only has PPO on GPT2\nTk-Instruct T5 trained on natural instruct dataset. is it trained on RLHF systems?\n\n\n\n\ndatasets\nwhisperhub collection of chatgpt prompts by plugin\nhh-rlhf\ninstructgpt samples\nnatural instructions\n\n\ndataset building tools\nopen-chatgpt-prompt-collective\ncrowd-kit purify noisy data\npromptsource\n\n\nreward models\nrankgen scores model generations given a prefix (or prompt)\nelectra-webgpt-rm and electra-large-reward-model is based on electra discriminator\n\n\nGPT3-like models\ngalactica is opt trained on scientific data\nbloomz and mt0 trained on xP3 (multilingual prompts and code)\nT0PP T0 optimized for zero-shot prompts, despite much smaller than GPT-3\nRETRO another model with GPT-3 capabilities with fewer parameters?\ngpt3 is gpt2 with sparse attension, which enables it to generate long sequence\nDiffusion-LM\nPaLM\nmetaseq provides OPT, which is basically GPT3\nGPT-JT altered in many ways, trained on natural instructions huggingface space\nGPT-Neo\nGPT-J\nGPT-NeoX\nBloom large language model by bigscience\n\n\nautonomous learning\nautonomous-learning-library doc and repo\nGu-X doing god-knows-what experiments"
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#analysis-about-how-to-make-such-model",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#analysis-about-how-to-make-such-model",
    "title": "chatgpt",
    "section": "analysis about how to make such model",
    "text": "analysis about how to make such model\ngpt3 is capable of imitation (cause it is unsupervised.)\nbut! if you want to get things done (when you really need it!), you better want some aligned AI.\ntwo similar models by openai: webgpt and instructgpt\n\nabout instructgpt\nit is first fine-tuned on supervised datasets, then train some reward model, then use the reward model to handle prompts and do reinforcement learning with PPO.\n\n\ndetails on webgpt environment\nguess: create states by performing actions, then generate templates to allow model filling blanks.\nOur text-based web-browsing environment is written mostly in Python with some JavaScript. For a\nhigh-level overview, see Section 2. Further details are as follows:\n• When a search is performed, we send the query to the Microsoft Bing Web Search API, and\nconvert this to a simplified web page of results.\n• When a link to a new page is clicked, we call a Node.js script that fetches the HTML of the\nweb page and simplifies it using Mozilla’s Readability.js.\n• We remove any search results or links to reddit.com or quora.com, to prevent the model\ncopying answers from those sites.\n• We take the simplified HTML and convert links to the special format\n【&lt;link ID&gt;†&lt;link text&gt;†&lt;destination domain&gt;】, or\n【&lt;link ID&gt;†&lt;link text&gt;】 if the destination and source domains are the same. Here,\nthe link ID is the index of the link on the page, which is also used for the link-clicking\ncommand. We use special characters such as 【 and 】 because they are rare and encoded\nin the same few ways by the tokenizer, and if they appear in the page text then we replace\nthem by similar alternatives.\n• We convert superscripts and subscripts to text using ^ and _, and convert images to the\nspecial format [Image: &lt;alt text&gt;], or [Image] if there is no alt text.\n• We convert the remaining HTML to text using html2text.\n• For text-based content types other than HTML, we use the raw text. For PDFs, we convert\nthem to text using pdfminer.six. For all other content types, and for errors and timeouts, we\nuse an error message.\n• We censor any pages that contain a 10-gram overlap with the question (or reference answer,\nif provided) to prevent the model from cheating, and use an error message instead.\n• We convert the title of the page to text using the format &lt;page title&gt; (&lt;page domain&gt;).\nFor search results pages, we use Search results for: &lt;query&gt;.\n• When a find in page or quote action is performed, we compare the text from the command\nagainst the page text with any links stripped (i.e., including only the text from each link).\nWe also ignore case. For quoting, we also ignore whitespace, and allow the abbreviated\nformat &lt;start text&gt;━&lt;end text&gt; to save tokens.\n• During browsing, the state of the browser is converted to text as shown in Figure 1(b).\nFor the answering phase (the last step of the episode), we convert the question to\ntext using the format &lt;question&gt;■, and follow this by each of the collected quotes\nin the format [&lt;quote number&gt;] &lt;quote page title&gt; (&lt;quote page domain&gt;)\n&lt;double new line&gt;&lt;quote extract&gt;■."
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#projects-related-to-chatgpt",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#projects-related-to-chatgpt",
    "title": "chatgpt",
    "section": "projects related to chatgpt",
    "text": "projects related to chatgpt\n\nvoice assistants\nvoice assistant in cpp\nChatWaifu with anime voice, ChatWaifu with live2d\n\n\nhacking\ngive longterm memory and external resources to gpt3\nwrite backend logic with gpt\nhackgpt exploit vulnerabilities\nvulchatgpt ida plugin for reverse engineering\nchatgpt-universe things related to chatgpt\ngalgame using chatgpt\n记笔记\n12.27更新了一个更精简的应用\n强烈建议部署到服务器上\nhuggingface参考：https://huggingface.co/spaces/Mahiruoshi/Lovelive-Nijigasaku-Chat-iSTFT-GPT3\nGitHub：https://github.com/Paraworks/vits_with_chatgpt-gpt3\n地址：https://drive.google.com/drive/folders/1vtootVMQ7wTOQwd15nJe6akzJUYNOw4d?usp=share_link\n你可以先尝试在服务器上部署，之后可以直接解压进文件夹后运行exe（mac、安卓端需要用renpy自行编译）\n去https://beta.openai.com/account/api-keys获取api-key\n参数照着敲就好了\n人物id通常是从0开始的数字，我的模型最大到12\napi部署方法：把inference_api.py放入你的vits目录下，进入文件修改config和checkpoint.pth的路径，比起应用程序来说十分简单，可以自行设计。码龄三个月写出的的雪山代码警告\n——————————————————————————————————————————————————\nChatgpt部署方法已于12.26更新（视频后部分）\nvits参考：https://github.com/CjangCjengh/vits\n服务器端建议用ISTFT VITS：https://github.com/innnky/MB-iSTFT-VITS\nmodel库：https://github.com/CjangCjengh/TTSModels\n也可以用我的https://huggingface.co/spaces/Mahiruoshi/MIT-VITS-Nijigaku\nCHATGPT参考：https://github.com/rawandahmad698/PyChatGPT\n示例视频（纯服务器api，gpt3）https://www.bilibili.com/video/BV1hP4y1B7wH/?spm_id_from=333.999.0.0&vd_source=7e8cf9f5c840ec4789ccb5657b2f0512\n穗乃果配音来自缪斯的模型﻿@Freeze_Phoenix\ngpt3加载参考﻿@ぶらぶら散策中\nchatgpt use cases curated list\nDAILA use chatgpt\nto identify function calls in decompiler\nawesome transformer language models a huge collection on transformer based LMs, huge models by megacorps, with some introduction and analogy on chatgpt\nhuggingface blog on RLHF containing similar projects and source code\nbilibili sends me lots of videos (and articles) on hacking and ai (including chatgpt) via its android app. recommend you to scrape this source and collect transcription and screenshots for searching and content generation.\nb站有做免杀 绕过杀软的\nchatgpt原理解析\nchatgpt对接搜索引擎\n下载链接:\ngithub: https://github.com/josStorer/chat-gpt-search-engine-extension/releases/\n百度网盘: https://pan.baidu.com/s/1MnFJTDIatyIIPr5kUMWsAw?pwd=1111\n提取码：1111\n原项目: https://github.com/wong2/chat-gpt-google-extension\n我创建的fork, 添加了多个搜索引擎支持的版本: https://github.com/josStorer/chat-gpt-search-engine-extension\nPR: https://github.com/wong2/chat-gpt-google-extension/pull/31\n已修复先前百度需要手动刷新的问题"
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#access-via-api",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#access-via-api",
    "title": "chatgpt",
    "section": "access via api",
    "text": "access via api\nhttps://github.com/altryne/chatGPT-telegram-bot\nhttps://github.com/taranjeet/chatgpt-api\nhttps://github.com/acheong08/ChatGPT\nhttps://github.com/vincelwt/chatgpt-mac\nhttps://github.com/transitive-bullshit/chatgpt-api\nhttps://github.com/rawandahmad698/PyChatGPT"
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#models-like-chatgpt",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#models-like-chatgpt",
    "title": "chatgpt",
    "section": "models like chatgpt",
    "text": "models like chatgpt\nlfqa retrival based generative QA\nlm-human-preferences by openai\ntrl Train transformer language models with reinforcement learning based on gpt2\ntrlx A repo for distributed training of language models with Reinforcement Learning via Human Feedback (RLHF) by CarperAI\nRL4LMs A modular RL library to fine-tune language models to human preferences\nPaLM-rlhf-pytorch saying this is basically chatgpt with palm\ngpt-gmlp saying this design integrates gpt with gmlps so will use less ram and can be trained on a single gpu\nWebGPT\ntk-instruct with all models by allenai can be multilingual, trained on natural instructions\nthere’s a ghosted repo named instructgpt-pytorch found in bing but no cache preserved, also an empty repo called InstructFNet wtf?\nAidMe Code and experiment of the article AidMe User-in-the-loop Adaptative Intent Detecttion for Instructable Digital Assistant\ncheese Used for adaptive human in the loop evaluation of language and embedding models.\nKelpie Explainable AI framework for interpreting Link Predictions on Knowledge Graphs\nGrIPS Gradient-free, Edit-based Instruction Search for Prompting Large Language Models\nqueakily nlp datasets cleaner\ngpt-j\nsuper big bilingual model GLM-130B\nmulti-modal deeplearning paper collections\nbloom a huge model like gpt-3\nnotice, gpt-2 is somehow inferior to gpt-3 since it has smaller model parameters\ndialogue-generation Generating responses with pretrained XLNet and GPT-2 in PyTorch.\npersonaGPT Implementation of PersonaGPT Dialog Model\nDialoGPT Large-scale pretraining for dialogue"
  },
  {
    "objectID": "posts/9b153935-754c-4bbc-82cc-077836bcdbaa/index.html",
    "href": "posts/9b153935-754c-4bbc-82cc-077836bcdbaa/index.html",
    "title": "Modify chrome/chromium policies from snap store",
    "section": "",
    "text": "use /var/snap/chromium/current/policies/ if chrome, /var/snap/chromium/current/policies/managed/ if chromium"
  },
  {
    "objectID": "posts/bae26c6f-804c-40ce-ad99-55629d7522cf/index.html#general-introduction",
    "href": "posts/bae26c6f-804c-40ce-ad99-55629d7522cf/index.html#general-introduction",
    "title": "download/collect info of hack tools",
    "section": "general introduction",
    "text": "general introduction\nthis is about information gathering, so you might learn how to scrape AI models, AI notebooks, tutorials, code snippets from websites/search engines/social media as well.\ngiven the name of the hack tool, you may not be able to tell what the tool is (written in python? hosted on github? online tool?) and you want to use search engine to find possible entries. you may take snapshots on these pages and index them.\nif the hack tool is linked to some website/manual, you can index the website. if you find it inside some package index or package manager, you will know how to install the package.\nyou may miss the wiki, forum, tutorials. you know where to get them.\nhere are few sources where you can learn things from:\ndarknet.org.uk where you learn hacking and hack tools\nnull byte in wonderhowto\nyou also have brew sdkman macport pkgsrc chocolatey scoop winget snap portage conda flatpak rpm urpm yum cargo dnf indexes and more to scrape. maybe it is time to improve your searching skill? (select few web domains you want to learn things from, then perform the query, still you have to deal with keywords generation and site selection)\ncyborg hawx linux, backtrack linux may join the parade.\nfor language specific package indexs, we have hackage CPAN CRAN crates.io and more (where are package indexes for C C++ Pascal BASIC assembly lisp prolog lua and more? visit awesomeopensource then use combined topics to find package managers for c and more. you also have libraries.io to monitor libraries across all package managers). just check tuna mirror site and get a view on that. you may want a network directory traversal tool akin to find in local filesystem, without downloading anything “binary” but just logging all possible urls for you to inspect. (with file size)\nafter all these information collecting, you must categorize them (topic modelling), retrieve info when needed (semantic searching? recommendation? dialog based GPT?). you may find many things not obviously a hack tool but in general fit well into specific needs.\nwith all packages being scraped, you need to deduplicate it a little bit, either by name or homepage."
  },
  {
    "objectID": "posts/bae26c6f-804c-40ce-ad99-55629d7522cf/index.html#case-specific",
    "href": "posts/bae26c6f-804c-40ce-ad99-55629d7522cf/index.html#case-specific",
    "title": "download/collect info of hack tools",
    "section": "case specific",
    "text": "case specific\n\ngithub\nrepo named with “awesome” means this is a collection of handpicked resources\nyou will find github links on web, social media, instant messaging and forums\nScraper scrape popular github repositories every day\ngitsuggest recommend github repos\nHow to Use the GitHub API to List Repositories\nPyGithub use python to automate github api v3\nif you want all README pages on github, you first need to collect all github repo urls. you may also collect info on github repos (OSINT). you can retrieve all repos link to given user with github api (quota limited). you can search github on github or search engine with some juicy/promising keywords then collect repo name, username, keywords, repeat the search.\nthere are few github repo archives avaliable for download. the github archive program packed many repos to arctic, the list is called Greatest Hits\ngharchive provides many websites for monitoring github repos, though stopped archiving since 2016\n\n\nkali, parrot\nkali tool list pages\ncurl https://en.kali.tools/all/ &gt; kali_tools_all.html # more tags, more categories, the same as blackarch?\ncurl https://www.kali.org/tools/ &gt; kali_official.html\ncurl https://en.kali.tools/ &gt; pentest_tools_with_name.html\nkali meta page on web\nkali meta page on package index\nkali package index\nnotice kali official “offsec” provides training courses and materials as apt packages. the list:\noffsec-awae/kali-rolling 2021.1.2 amd64\nResources for OffSec's AWAE/WEB-300\noffsec-awae-python2/kali-rolling 2021.1.2 amd64\nPython 2 resources for OffSec's AWAE/WEB-300\noffsec-exp301/kali-rolling 2021.1.2 amd64\nResources for OffSec's WUMED/EXP-301\noffsec-pen300/kali-rolling 2021.1.2 amd64\nResources for OffSec's ETBD/PEN-300\noffsec-pwk/kali-rolling 2021.1.2 amd64\nResources for OffSec's PWK2/PEN-200\n\nthese two OSes are for pentesting, using apt as package manager. but parrot does not provide tool introductions.\nget all package names:\napt list\nyou can retrieve package information in apt command, like:\napt show &lt;package_name&gt;\nyou will get homepage link and package description\nif you want package dependencies you will also have it.\nusing apt one can retrieve package infos with simple command. find main metapackages like parrot-tools-full (parrot) and kali-linux-everything (kali) first, then retrieve dependency trees.\nparrotos has index.db which you can retrieve info from there, or “Packages” for general debian package index, or anything you think is metadata.\n\n\nchocolatey\nnote: deprecated since v2.0, can only be used to list local packages\nchoco list\n\n\nblackarch\nblackarch is based on archlinux, which has both official repo and user provided packages repo (AUR). the syntax is almost the same for pacman and yaourt to retrieve all available info of packages.\nmaybe you want to retrieve package information with pacman.\nlist all package information just like apt, description, dependencies, homepage and more.\npacman -Si\nuse some parser?\nfor aur repos, use yay or yaourt.\nyaourt -Si\nyou may use dependencies to deduce relationship between packages, use description, man pages, wiki, manual and tutorials to understand the usage of packages.\ndownload main blackarch tool list:\ncurl https://www.blackarch.org/tools.html &gt; tools.html\n\n\nalpine\nalpine linux is able to download man page alone without installing package\napk list -I | sed -rn '/-doc/! s/([a-z-]+[a-z]).*/\\1/p' | awk '{ print system(\"apk info \\\"\"$1\"-doc\\\" &gt; /dev/null\") == 0 ? $ \"-doc\" : \"\" }' | xargs apk add\n\n\npypi/pip\ni remember you have scraped tsinghua pypi index, containing many python tools.\nretrieve python package info as json:\nhttps://pypi.org/pypi/&lt;package-name&gt;/json\nvisit pypi simple index to get all package names. but the info is clearly on the other page. you retrieve this from pypi. use the below commandline tool?\npypi [information|description] &lt;package_name&gt;\ndocumentation url is provided separately from mainpage.\ncommandline tool for searching in pypi\ninstall it, then run:\npypi search &lt;query&gt;\nit also provides “read-the-docs” to search in documentation of a package, detailed info\n\n\nnuget\nwe can search in cli tool (not dotnet nuget (installed with dotnet sdk) but nuget (installation guide)) and web interface.\nlist all packages:\nnuget list\nget package information:\nnuget list &lt;packageName&gt; -Verbosity detailed\n\nquery all package information without nuget\nthe web interface seems allowing us to do some traversal on the parameter: https://www.nuget.org/packages?page=&lt;pagenum&gt;&sortBy=relevance\nkeep in mind the pagenum cannot be too big (like 2000).\n\n\nmaven\nthere are tools for interacting with maven search api.\nyou can retrieve “pom.xml” to get package info like homepage and description.\nmaven central has archtype-catalog for retrieving all avaliable artifact names\nmaven search tools:\nmvn-search\nmcs\n\n\nhomebrew\nreading the source code and according to brew api docs i found this url is for retrieving all formula info on brew index, and this for casks.\nalso run this command for showing local cached package infos:\nbrew info --json --all\n\n\nnpm\nthere’s a repo storing up-to-date package names on github. after that, use npm-description to download description for every package.\nall-the-package-repos contains repo information (github, gitlab) of every npm package\n\n\ngem\nchange gem sources first:\ngem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/\ngem list -r really works. you just have to wait.\ngem info -r list all remote gem infos, but too slow and not working, use only one package at a time.\n\n\nmanpages\nyou can download man pages before installing package\nuse “dman” by bikeshed (not avaliable on kali, maybe on ubuntu?)\napt-get install bikeshed\nor browse manpages on web, tutorials on linux and languages\nman pages with different sections (categories)\nhierachical manpages of ubuntu\ndman for ubuntu man pages\nlocation of locally installed man pages: /usr/share/man\n\n\nvscode plugin\nweb interface for searching"
  },
  {
    "objectID": "posts/00cecfe9-d997-4612-b866-c69038f613eb/index.html",
    "href": "posts/00cecfe9-d997-4612-b866-c69038f613eb/index.html",
    "title": "Mastering Command-Line Tools for JSON/HTML Filtering and Formatting",
    "section": "",
    "text": "commandline json/html filter and formatters\nfor hackers, filtering matters.\njq\njqterm online jq repl\nhtmlq is for querying html with selectors, extracting text from html\npup download from release\none must collect a handful set of regular expression/filters to do hacking\nsearching, regex, two most important things for hackers. it’s not about blindly collecting data. it’s power and knowledge."
  },
  {
    "objectID": "posts/75081e5b-3fa5-4857-8ae1-47a472634c24/index.html#webpage-dumps",
    "href": "posts/75081e5b-3fa5-4857-8ae1-47a472634c24/index.html#webpage-dumps",
    "title": "comprehensive page dump from multiple devices",
    "section": "Webpage dumps",
    "text": "Webpage dumps\nuse “bookmark all tabs” or “copy all tab urls” browser extension, or your OG lazero extension\n\nmacOS\ncheck for “Comprehensive Research” series\n\nyou can only bookmark all tabs and tab groups within a single window.\nfor example, if you have two windows open, you need to do it twice to save all links to your computer.\n\n\nKali\ncheck “Healthcare and Watch Cases” under firefox bookmarks.\n\n\nAndroid\nto install a plugin on kiwi browser, you (maybe) need to unpack and install it manually.\nyou need chrome extension v3 or below. pack the extension manually if needed. must install from .crx file.\nquery: site:github.com chrome copy all tabs\nuse this or this or this.\nif you want markdown-style, use this or this or this (you need to modify this as it is the only hope now) or this. query: site:github.com chrome copy all tabs markdown.\nyou click every tab manually, in order to copy them. goddamn the android!\n\nfor firefox, you search in the official addon store.\n\nclipboard data and tab records dumped at ~/works/modifier_clipboard_and_browser_tabs_dumps\n\nremember to clean up the damn phone. it is running way too slow."
  },
  {
    "objectID": "posts/91b05803-40c8-47ad-ab8a-c323e236195b/index.html",
    "href": "posts/91b05803-40c8-47ad-ab8a-c323e236195b/index.html",
    "title": "copyright issues circumvention",
    "section": "",
    "text": "only mention sources from major leagues (#fans &gt; 5k)\nmention the bgm you are using"
  },
  {
    "objectID": "posts/a08b1a65-d0eb-4167-b48b-bf0b0eca4898/index.html",
    "href": "posts/a08b1a65-d0eb-4167-b48b-bf0b0eca4898/index.html",
    "title": "ctf related",
    "section": "",
    "text": "ctfhub\nctftime\nctf-tools by ctfwiki"
  },
  {
    "objectID": "posts/46728264-fc0f-4745-9897-5b7484c2533b/index.html",
    "href": "posts/46728264-fc0f-4745-9897-5b7484c2533b/index.html",
    "title": "dark web search engine",
    "section": "",
    "text": "OnionSearch commandline all-in-one darknet search tool, install via pip3 install onionsearch (of course you need proxy)\nSupporting:\nahmia\ndarksearchio\nonionland\nnotevil\ndarksearchenginer\nphobos\nonionsearchserver\ntorgle\nonionsearchengine\ntordex\ntor66\ntormax\nhaystack\nmultivac\nevosearch\ndeeplink\n\nhttps://dark.link/torch-darkweb-search-engine-links/\ndarknethub\nonion.live list and search popular onion sites by name\nhttps://darkweblinks.com/#Open-Source-Software\nThe onion dir\nlinks are subjected to change or take down.\nahmia\nthe uncensored hidden wiki\ntor links\nparazite\ntorch\nnot evil\nhaystack one of the biggest\ncandle"
  },
  {
    "objectID": "posts/40045752-3d9f-448c-81f9-83bf56fa84ec/index.html",
    "href": "posts/40045752-3d9f-448c-81f9-83bf56fa84ec/index.html",
    "title": "Unlocking the Power of AI: Exploring Deep Learning Datasets and Resources",
    "section": "",
    "text": "datasets for deeplearning, classification and evaluation\n100 audio and video datasets\nvideo datasets\nyoutube8m"
  },
  {
    "objectID": "posts/9580f46a-f225-4ad4-bea5-6f3ec07c2399/index.html",
    "href": "posts/9580f46a-f225-4ad4-bea5-6f3ec07c2399/index.html",
    "title": "deepl免费翻译 免费白嫖",
    "section": "",
    "text": "heroku no longer provides free tiers (dyno)\nchange ip frequently by using proxychains and clash\nRELEASES STILL VISIBLE HERE\nyou can google for it. maybe the internet archive has it.\nhttps://github.com/zu1k/deepl-api-rs/releases/download/0.1.2/deepl-aarch64-unknown-linux-musl-0.1.2.gz\nhttps://github.com/zu1k/deepl-api-rs/releases/download/0.1.2/deepl-x86_64-unknown-linux-musl-0.1.2.gz\nfor other triplets i am not so familiar so i cannot guess that out.\n从zu1k的文章来看 应该是搞安全的\n为了更准确的翻译， deepl的API是很重要的\n但是这个deepl却不让免费用 网页端的js复杂的要死\ndeepl的客户端的现在分为3类：\n\n免费 自动操控浏览器\n付费 申请api\n免费 破解交互协议\n\n为了连续使用deepl以及其他可能会封ip的翻译软件 使用clash做代理是很关键的 如何找到好的代理 zu1k有proxypool可以自动爬取代理 同时推荐大佬的proxypool 据说是专业爬虫架构\nzu1k本人下架了deepl的docker镜像 但是release现在居然还可以下载 只不过不可以直接访问页面罢了\nzu1k的copy translator连接的应该就是他自己写的deepl-rust服务器 只不过现在没法访问了 (话说大佬没事翻译个啥又不是看不懂 hhh) 历史的release版本中有连接本地的版本 估计也没有开源原来的docker破解deepl的二进制\ndeeplx在 heroku上面运行 目前应该不能正常运行 它的ip感觉是被封了 它的仓库用的是现在没法访问的deepl的docker镜像\n有人（很可能就是zu1k）破解了deepl客户端的交互逻辑 应该是windows的deepl协议（c#好破解 没加壳） 现在可以看看是如何破解的\n\n安全不仅仅是一门朴素的学问，更是一门权衡的艺术。有时一个简单的设计可以规避掉大多数攻击问题，下面分享一篇在网上看到的DeepL API的反爬设计。\n这篇博文本应该在去年完成 DeepL 客户端逆向的时候发布，但考虑到相关细节一旦公开，恐怕会被广泛采用而被 DeepL 官方封杀，因此迟迟未开始。前段时间我发布了 DeepL Free Api 的 Docker 镜像，也在 GitHub 上公开了相关二进制程序，就下载量来看已经有不少人在使用了，相信 DeepL 不久就会有动作，因此我认为现在已经可以公开相关细节。\n我逆向的是 DeepL 的 Windows 客户端，因为是 C# 开发依附于 .net，也未进行任何混淆和加壳，可以轻松逆出源码。通过前段时间与一些其他研究者交流，我认为已经有不少感兴趣的同学也进行了逆向，也许是一种默契，都害怕 DeepL 在发觉后进行修改，所以大家也都没有对外公开，目前网络中搜不到任何相关的内容。本文的目的是给相关小伙伴一点思路，不过希望大家还是不要直接公开代码，以继续欺骗 DeepL，让其相信还没有人发现他们的把戏。\n在我实现 DeepL Free Api 的过程中，我发现 DeepL 并没有像之前见到的一些接口设计那样，通过签名等手段来避免接口滥用，相反，他们使用了一些欺骗战术来混淆视听，从而尝试让抓包分析者放弃，本文将围绕此进行讨论。\n过程\n进入研究生阶段，为了方便阅读论文，为自己开发了划词翻译工具，在众多翻译引擎中 DeepL 的效果尤为出色。DeepL 官方的 Api 需要绑定信用卡进行认证，但其并未在中国大陆经营业务，所以并不支持国内的信用卡。我也尝试过从淘宝购买别人用国外信用卡认证过的帐号，价格贵不说，在没有滥用的情况下，DeepL 在两个月内封禁了我的帐号，因此我决定用一些其他手段。\n考虑到 DeepL 有提供免费版本的翻译服务，支持 Web，Windows、Android 和 iOS 都有相应的客户端，我便想使用这些客户端使用的免费接口。不出所料，在广泛使用打包和混淆技术的当下，DeepL 的 Web 端 js 代码也不是人看的东西，但通过简单的抓包，我发现其接口参数非常清晰，根本没有额外的签名、token等认证技术，我觉得自己又行了，几行 Python 代码便完成了接口对接工作。\n但测试下来，我发现当修改翻译内容，有极大概率遇到 429 Too many requests，并且一旦出现 429，后续的所有请求便都是 429 了。\n{\n\"jsonrpc\": \"2.0\",\n\"error\":{\n\"code\":1042902,\n\"message\":\"Too many requests.\"\n}\n}\n在 GitHub 搜索之后，我发现已经有前人尝试利用过 DeepL 的免费接口了，早在 2018 年他们就已经遇到了这个 429 问题，并且到现在都没有解决。\n我尝试转向客户端的免费接口，苹果设备可以轻松 MITM，于是我便在 iPad 上对 DeepL 客户端进行抓包，让我意想不到的是，客户端的请求竟然比 Web 端的简单不少，接口参数数量仅有必须的几个，非常有利于利用。于是我又觉得自己行了，两三行 Python 代码完成接口对接。\n简单测试，我又傻眼了。伪造的请求明明跟客户端发起的完全相同，但只要一更换翻译的内容，返回马上就变成 429。干！我都开始怀疑自己了。\n{\n\"jsonrpc\": \"2.0\",\n\"method\": \"LMT_handle_texts\",\n\"params\": {\n\"texts\": [{\n\"text\": \"translate this, my friend\"\n}],\n\"lang\": {\n\"target_lang\": \"ZH\",\n\"source_lang_user_selected\": \"EN\",\n},\n\"timestamp\": 1648877491942\n},\n\"id\": 12345,\n}\n你自己看看，这个接口多么清楚明白，但怎么就伪造不了呢？\n我想了又想，这里面也就 id 比较可疑，因为这个参数我不知道它是怎么生成的，是随机的还是根据某种规则计算出来的，我们无从知道。但从目前结果来看，随机的 id 无法被服务器认可。\n当然，我也考虑过其他的服务端判断滥用的方法，例如某些 http 头、ssl 层面的方法（例如之前 Go 实现中 SSL 协商过程中加密算法的顺序等），我也想办法进行了伪造，可就是不行。疲惫了，不想搞了。\n第二天，突然想起他的 Windows 客户端，稍微一分析惊喜的发现是 C#，还没加壳，果断扔进 dnSpy，发现也没混淆，真是柳暗花明又一村啊。分析之后，也就一切都清楚明白了，原来 DeepL 根本一开始就在想方设法让你觉得你行啊。\n看前面那个接口的参数，我之所以觉得我行，就是因为这个接口它太简单了。接口的参数少，参数含义又非常明确，它并不像某些厂那样用一些不知所以然的缩写，这里的每一个参数，它的名称都在告诉我它的含义、它是干什么的以及它是怎么生成的。\njsonrpc 是版本号，method 是方法，一个固定的字符串。params 里面 texts 是多段待翻译的文本，lang 里面是翻译的语言选项，是枚举类型。timestamp 是 UNIX 风格的时间戳，id 就是序号。大眼一看，这里面只有 id 是最可疑的，这也确实是我最初犯的错误。\n真相 现在我来告诉你，DeepL 到底是怎么认证的。（下面并不是 DeepL 客户端的代码，是我写的 Rust 利用代码，但逻辑不变）\nfn gen_fake_timestamp(texts: &Vec&lt;String&gt;) -&gt; u128 {\nlet ts = tool::get_epoch_ms();\nlet i_count = texts\n.iter()\n.fold(\n1,\n|s, t| s + t.text.matches('i').count()\n) as u128;\nts - ts % i_count + i_count\n}\n哈哈！没想到吧！人家的时间戳不是真的！\nDeepL 先计算了文本中所有 i 的数量，然后对真正的时间戳进行一个小小的运算 ts - ts % i_count + i_count，这个运算差不多仅会改变时间戳的毫秒部分，这个改变如果用人眼来验证根本无法发现，人类看来就是一个普通的时间戳，不会在意毫秒级的差别。\n但是 DeepL 拿到这个修改后的时间戳，既可以与真实时间对比(误差毫秒级)，又可以通过简单的运算（是否是 i_count 的整倍数）判断是否是伪造的请求。真是精妙啊！\n还有更绝的！你接着看：\nlet req = req.replace(\n\"\\\"method\\\":\\\"\",\nif (self.id + 3) % 13 == 0 || (self.id + 5) % 29 == 0 {\n\"\\\"method\\\" : \\\"\"\n} else {\n\"\\\"method\\\": \\\"\"\n},\n);\n怎么样？我觉得我一开始就被玩弄了，人家的 id 就是纯粹的随机数，只不过后续的请求会在第一次的随机 id 基础上加一，但是这个 id 还决定了文本中一个小小的、微不足道的空格。\n按照正常的思路，为了方便人类阅读和分析，拿到请求的第一时间，我都会先扔编辑器里格式化一下 Json，我怎么会想到，这恰恰会破坏掉人家用来认证的特征，因此无论我如何努力都难以发现。\n总结\n在我以往的经验中，接口防滥用，要不就是用户专属的 token，要不就是对请求进行签名或者加密，这些对抗滥用的方法都是明面上的，就是明白告诉你我有一个签名，怎么签的，你去分析去吧，但是我代码混淆了，你看看你是要头发还是要算法。\n要不就是高级点的，更具技术性的，利用某些客户端特有的实现造成的特征进行认证，我印象中最深刻的就是 Go 的 SSL 协商过程中的算法顺序。这类方法要求更高的技术，当然分析起来也肯定更加困难，并且找到这样一种方法本身也不容易。\n从 DeepL 的方法中，我找到了另外一种思路。利用人心理的弱点，一开始让其感觉非常简单，但是无论如何都无法得到想要的结果，给分析者造成心理上的打击和自我怀疑，让其浅尝辄止自行放弃分析。同时利用人行为上的惯式，使其自行破坏掉某些关键信息，从而给分析造成难以发现的阻碍。\n原来，除了技术以外，还有这样一条道路啊，真是有趣！"
  },
  {
    "objectID": "posts/8a5f5c1f-aa5a-409c-a88b-815ddf604896/index.html",
    "href": "posts/8a5f5c1f-aa5a-409c-a88b-815ddf604896/index.html",
    "title": "differential equations: ODE (Ordinary Differential Equation), SDE (Stochastic Differential Equation), DDE (Delay Differential Equation), DAE (Differential Algebraic Equation)",
    "section": "",
    "text": "ODEs, SDEs, DDEs, and DAEs are types of mathematical models used to describe various systems and processes in different fields such as physics, engineering, economics, and many others.\nODE (Ordinary Differential Equation) represents a relationship between an unknown function and its derivatives. It is a mathematical description of how a quantity changes with respect to one independent variable. ODEs are used to model physical systems where the rate of change of a state variable can be expressed as a function of the state itself.\nSDE (Stochastic Differential Equation) is a type of differential equation that contains a random term, which accounts for the uncertainty or randomness in the system being modeled. SDEs are used to model systems where the rate of change of a state variable is not only a function of the state but also of a random process.\nDDE (Delay Differential Equation) is a type of differential equation where the current state of a system depends not only on its present values but also on the values of the state in the past. DDEs are used to model systems where there is a delay between the time a change occurs and its effect on the state of the system.\nDAE (Differential Algebraic Equation) is a type of mathematical model that combines aspects of differential equations and algebraic equations. DAEs are used to model systems where the equations of motion cannot be expressed solely in terms of derivatives of the state variables.\nIn conclusion, these types of models are used to describe and analyze complex systems by mathematically representing the relationships between variables and their derivatives, and they are crucial in many fields to make predictions and understand the behavior of various systems."
  },
  {
    "objectID": "posts/12351f6e-92f7-41a9-9c3e-1cad4c2c9366/index.html",
    "href": "posts/12351f6e-92f7-41a9-9c3e-1cad4c2c9366/index.html",
    "title": "docker usage issues",
    "section": "",
    "text": "login mysql with empty password then execute command to make it remotely available:\nmysql -uroot --password= -e \"grant all privileges on *.* to root@'%' identified by '' with grant option; commit;\"\ncreate volume and attach volume to container, since containers will be reset after system restarts.\ndocker volume create &lt;volume_name&gt;\ndocker run -it -d --rm -v &lt;volume_name&gt;:&lt;container_mountpoint&gt; --name &lt;container_name&gt; &lt;image_name&gt;\ndocker volume inspect &lt;volume_name&gt; # get info on created volume\nwhen using mindsdb, it sucks because having bad pypi mirrors.\nset pip index url globally:\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\nor pass it as environment variable:\ndocker run -it -d -e PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple -n &lt;container_name&gt; &lt;image_name&gt;\nif you want to save container states into images, use docker commit &lt;container_name&gt; &lt;image_name&gt;[:image_tag]\nKeep in mind that the docker commit command only saves the changes made to a container’s file system. It does not save any changes made to the container’s settings or network configurations. To save all changes made to a container, including settings and network configurations, you can use the docker export and docker import commands instead.\nwhen exporting ports, if not specifying host ip, you cannot reach the service inside the container. do this instead: docker run -p 0.0.0.0:&lt;host_port&gt;:&lt;container_port&gt; &lt;rest_commands&gt;\nit seems to be the proxy (fastgithub). disable http proxy so we can connect to container again, or use clash to make rules to let “localhost” or subnet requests passing through.\nif you want to change ip routings or some other configurations passed when docker run, you need to change the file called hostconfig.json located in /var/lib/docker/containers/&lt;container_id&gt; with PortBindings sections. you stop the container first. find and change the config file then start it. tutorial\nseems not working. fuck.\n\"PortBindings\": {\n\"80/tcp\": [\n{\n\"HostPort\": \"8080\"\n}\n],\n}\n\ncontainers can only contact each other if they share the same network. better give unique ip for each container within same network. it can also use container name as host name instead of static ip. tutorial\ncreate a network (not overlapping with anything shown in ifconfig, notice the subnet mask):\ndocker network create --subnet=172.18.0.0/16 &lt;network_name&gt;\nstart container with given network (again not overlapping with addresses in ifconfig, not the starting address):\ndocker run --rm -d -it --net &lt;network_name&gt; --ip &lt;ipaddress&gt; --name &lt;container_name&gt;\nto check what ip the container is at:\ndocker inspect &lt;container_id/container_name&gt; | grep IPAddress\nnow you might can talk to the container without port mappings."
  },
  {
    "objectID": "posts/e270170a-1520-4c18-af65-f9c4cc62a93e/index.html",
    "href": "posts/e270170a-1520-4c18-af65-f9c4cc62a93e/index.html",
    "title": "dubbo and python xmlrpc",
    "section": "",
    "text": "they are both remote procedure calls.\nyou can ship things across internet, but remember it can’t be some “native” structure like numpy array.\npython xmlrpc tutorial and xmlrpc.server mentions c2 wiki which you have scraped before. where is it, along with all other things you have scraped? believe it is in that AGI directory since you are such an archivist at that time.\ntutorials on how to detect if dubbo services are working normally:\nbasically they use native java methods or telnet protocol with python\nhttp://www.shouhuola.com/q-23671.html\nhttps://www.yisu.com/zixun/576879.html\nhttps://www.cnblogs.com/leozhanggg/p/14176752.html\nhttps://www.bilibili.com/read/cv13670275/\nhttp://www.zztongyun.com/article/article-1-1.html (open with elinks to prevent ads)"
  },
  {
    "objectID": "posts/bc4961f2-6efe-48f6-95ac-161076408834/index.html#email",
    "href": "posts/bc4961f2-6efe-48f6-95ac-161076408834/index.html#email",
    "title": "email scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT",
    "section": "email",
    "text": "email\n\nemail OSINT\nOSINT/recon 其实就是社工 但是一般人喜欢把社工库和社工分开 因为社工库是社工收集来的数据集合 而社工则是一个过程\nloading/transforming leaked txt files will be time-consuming. use pypy to speedup the process. use database specific batch processing method to import the data.\nentity fragmentation in followthmoney is kind of for “entity recognition in multiple social platforms”, suitable for finding patterns/clients in large leaked databases.\n\nemail collector\nsocialscan Python library for accurately querying username and email usage on online platforms\nZen collect email on github\nmaigret a powerful fork of sherlock (customizable, finding accounts by username, but only having 300+ sites ) with 2000+ sites\nemailAll collect email by passing domain\nemailfinder find email by domain\ntheHarvestor email, subdomain and names collector\ngitscan scan for email and password (if possible) with predefined domains and rules by searching github\nghunt needs companion browser plugin to get credentials. can collect info on given email\nEMAGNET collect database leaks, email and password from recent pastebin records\n\n\nleaked email and data\noccrp (anti corruption & crime) aleph is a bad source for getting email (anonymous/unauthorized user can only get hundreds, having no clue what the email relates to). however, it has a tool called follow the money which works with csv files and exports cypher to neo4j\n\nleaks on github\nsearch for leaked database on github\nlinkedin database leak 2021 (hate mega since it has download quota)\n\n\nleaks from forums\nyou typically find links to these databases on anonfiles.com (or else), so query like site:anonfiles.com email rar in duckduckgo (no DMCA censorship)\nbreachedforum’s index contains “credits only” threads which requires 4-8 credits to unlock. to get credits you need to create thread (which will earn 0 credit) and get 1 credit per reply. post to trivial threads like manga.\nin leakbase you earn credits and download leaked databases easier. it has official telegram bot claims to leak free databases everyday.\n\n\ntelegram bots\nfind telegram bots collection in privacy.club (only OSINT bots) and here (with many other bots)\n摆烂bot 永久免费\nSGKmainNEWbot\nsgkmainbot\n(gone?) FreeSGKbot\nFreeSGKbot4\nKernelBugXBot\n\n\ndownload links\nalthough i find many leaked databases as torrent, but those torrent search engines usually collect video/movies instead of anything related to leaked database.\n44.65GB QQ 微博社工库 or qq8e/qq 基本上传的就是这个了 或许可以在QQ群里面找到一些别的社工库 使用这个数据库的还有 q绑 (有反调试 带去水印工具 但是其实这个到处都有吧) aiuys’s retrofit 后台是privacy (只是部分的可以导入 其他的自行处理)\nUsing aMule on macOS, Kad is firewalled (2.2.1 works well said by people, but I’d not use macOS), reason unclear. Maybe on Linux or Windows it will be different.\nSome (dead) links of other databases in ed2k emule format:\ned2k://|file|2010.06-江西移动全库-408万-access.7z|1329999527|5231E1EC5EE1123C6E694AD6399F9807|h=DORZC7XFNG63ZWX6C3RSN3Q7CWZXG5G4|/\ned2k://|file|2012.01-千脑-70万-csv.rar|34017079|A30DD3EF32C03C86E71032CDCA1C5EF9|h=2Z7TKJED7P2NJCKUCINNHMWLXV3KVVS4|/\ned2k://|file|2012.02-AcFun-15万-txt.rar|2241909|C2439FAB2BC7322273DE5D512A530A83|h=QJWQ3LWZ3UFJMPQHPD6WGXYYZHPRLQ43|/\ned2k://|file|2012.03-圆通数据库-mssql.rar|127496748|75F92807F541FB0EBB4773BA83D5157A|h=YAOCNQEUXCNBBTIM226NNZLJA7SMMSDS|/\ned2k://|file|2012.07-yahoo-45万-txt.bz2|6871089|8769EC2314C1AF2C98237DF58C7076D2|h=VSJ52KZ6O6JUZNZKXKT7F3LRXHBKJKMN|/\ned2k://|file|2012.08-小米论坛-828万-mysql.rar|518891223|87704FEA5B191C21F605A0C135BAF98E|h=6UQWS3OQ4VGUXLYW2L6H6TL2GKZOJAUA|/\ned2k://|file|2012.08-小米论坛-828万-txt.rar|361627120|2ED96D2F0E515321F67A31E84DC77B3C|h=UNNVFRMNWNP7UAIXZ6Y6AFCKOLBFJILW|/\ned2k://|file|2013.04-DNF-700万-mysql.zip|306178725|169CE4FA4D4F467BCB7F8297CE6EE032|h=C3KZ6C637ARBAPD5UNF2YMYMT5LTS2UK|/\ned2k://|file|2013.08-酒店开房记录-2000万-excel.rar|610164988|26F994CA1ABA72051ECE497F9AB7959A|h=EDLQDIHSRAJHB5SVNDQVMNPHOXVO3XB6|/\ned2k://|file|2013.08-酒店开房记录-2000万-mssql.bak|8030079488|6FCCDC6DE213DC72A4EFEE19AF2FC1AC|h=5YJSQJY46OYKYMQA5P4G3DUAQGATYDFI|/\ned2k://|file|2014.08-企业400号段数据-mssql.rar|46506453|4F44726413F3B9F9F701635FB498EAAB|h=LP47JMAJGOX233HQR2V3K673G7LE22RI|/\ned2k://|file|2014.08-台湾某财经电视台数据库-2014-txt.zip|53519|95160AAE4A9E3074BACB04C606C0748F|h=3KQJJ4ADWKNOGNJIZIICBXQ5SLPD62R5|/\ned2k://|file|2014.08-房产网-11万-sql.7z|6095432|D99DE175A27D179A5EB9F34D2D975FB0|h=2GN2RLDSDDVZ4POQZVIEJODQJVH2CJ4G|/\ned2k://|file|2014.09-mail.ru邮箱地址-466万-txt.7z|30715779|5247DC686608FD2317A31E8BA67899F4|h=DFVLYBFEQQLDZSXIEOWHWY2BMA5DKDBO|/\ned2k://|file|2014.09-yandex.ru-100万-txt.zip|16200283|80C4A344D51DBAE12F0A0D50202E9313|h=RA2KA6RRGELDAMXBAKXVFI3W7SIJ6TEE|/\ned2k://|file|2014.12-12306-13万-txt.7z|4470710|7B25F299C7862BFA855B63B04BB00E2A|h=VURCVAXE4UVFI2TOIEC6DIZUBSYELY76|/\ned2k://|file|2016.04-卡塔尔国家银行QNB-csv.zip|534384790|D7D81061307568AE47A3EE6C894D6C6C|h=VRQGQASTAHXFRGBZXAAIABVTFJRRIV7G|/\ned2k://|file|2016.04-土耳其公民数据mernis-5000万-sql.gz|1555520122|22B660CB494D89FC84198A6EEA66E3B6|h=HYBIW22P3G56CUB7RR34CJVD7RKO34BS|/\ned2k://|file|2011.03-多玩游戏网-800万-txt.rar|227441723|F8388A178222518978550D3E64B6129B|h=XMR2CYVQI3HOMKVRGUCCFGYZ3JVHKLCG|/\ned2k://|file|2011.03-当当网买家信息-101万-Excel.zip|7822098|1F66086AE57B74D69BF75A2EF7900B2E|h=VRWZME24KH7UTIF3HPTCO5V5KNTEHUAQ|/\ned2k://|file|2011.04-766游戏网-12万-sql.rar|5031951|BBE2D87564A2A8E4B083B57C697FD24E|h=DUFDLSY2A4F5SPZMMCN5JP7TE2HWA4EV|/\ned2k://|file|2011.04-IS语音-969万-txt.zip|177030850|B153DDF9FE16EFFF30C589664592F85A|h=HCB5NVNHVGVGKMDCS7HXHI4MNQASG5SY|/\ned2k://|file|2011.04-亚马逊中国买家信息-20万.zip|7570413|356D9E9C07D62243EF8A62745819E85C|h=BXLWB7OFKIFTCSCUU4Y47DHMX67GF7DO|/\ned2k://|file|2011.04-凡客诚品买家信息-20万-Excel.zip|7784030|AEC527EA7E816DBD75FF92B0C26BC480|h=VXC2RO23H23OCZISUXTEO62RTVHGQFPZ|/\ned2k://|file|2011.04-爱拍游戏网-1100万-txt.zip|267845795|87F9FFE887B0F53CAFD2A11205CB6C52|h=G6AQRSNJ7CHDTX5MTV6RYGB2OHYOAEXA|/\ned2k://|file|2011.05-木蚂蚁-13万-sql.zip|8598547|680F8999D4E27174553D1C11118DF978|h=5G2YZ7Z6RAQ5M5XUNCEFNX7ZYAITMZPZ|/\ned2k://|file|2011.07-土木在线-540万-sql.zip|645903048|4ED3B64224752DE3AB11B11D2FD9DA06|h=UL3F74NI266IR4IHI7UHDKMZRQMX3PFX|/\ned2k://|file|2011.10-178游戏网-1000万-txt.rar|108534783|FFCD04A52339701C8CB5197BDCF9F4DC|h=C2UYTR264YXVM6NSJNUV5R2PC5VZNAYU|/\ned2k://|file|2011.10-CSDN.NET-600万-sql.rar|109942505|A29D9468556CF73AFB48A3A8427629DC|h=VTPXT56G3BGRTHBROKQEWW6XAQTMYPLZ|/\ned2k://|file|2011.10-嘟嘟牛-66277-txt.rar|215666725|EF7187E33A8EBD9FD806343B7B1CAA82|h=Z5YU2Z6P6GUT5DUKQ6L4X5YFMZZNZ4YZ|/\ned2k://|file|2011.11-7k7k小游戏-2000万-txt.rar|203648704|6EB70910C1C193F5BE04610B503EF4A0|h=Y4ITT7C5Z5LOOREJPWXA25TM2NLKEEDX|/\ned2k://|file|2011.11-人人网-500万-txt.rar|51969611|8CD19B7A2EB9F1F74CB8BFBDE7BD144D|h=SDNOOZCYR6PXZIRZTZPEICNRNZ67BQJJ|/\ned2k://|file|2011.12-天涯社区-4000万-txt.rar|493480455|E4E0CFD85E2A783A3C3BD2539AA28FC3|h=4FB7J7QPRWRIPX7QWWTYVZCKMWDZ5VIQ|/\ned2k://|file|2011.12-淘宝买家卖家邮箱-2500万-txt.zip|135534861|F40C3C9F32F2C30B1A2484FAB3CB1257|h=GLUDUAAYPAALG3GPHD4EHT5OB6V6WBVB|/\ned2k://|file|2012.10-QQ精准客户名单-4500万-txt.rar|131416815|134F81AA90B27F55818E7A521D3CB35B|h=NRF2HAH2IXDT635UV6NDEGSA2HSOSSHZ|/\ned2k://|file|2012.06-LinkedIn-16737万-txt.rar|7503170474|A50C488915FC70E1DE644AA5F3432D6F|h=E2NEXLXOOA6PONPKUGVRVIMEU54EC6P4|/\ned2k://|file|2013.06-Myspace.com-36021万-txt.7z|12419587039|A1B14F88891885D636DE9F642A3E06DF|h=3QBXWEHRBUSUEWJOSHCF47B7HEC4Q5BM|/\n\n\n\n\ncheck registration account with email\nreg007 counterpart only check if that account “exists”, but no actual account shown. search for reg007 on github you will get a bunch of links relating to OSINT.\nholehe only check if an email address is registered as account elsewhere using “forget my password” APIs.\nsreg is found from a collection of security tools, which is a deprecated tool for getting registration status with phone/email/username on multiple chinese platforms.\n\n\n(email) account verifier\nUsually it only verify existance of given email, like emailhippo (100 requests free per day per ip), or mailforguess checking “gmail”,“laposte”,“protonmail”,“yahoo” emails\nSome of them verify email with password: verify email address and password with API of my.com\nh8mail email osint tool, can chase and link to social profile, with many API-key required free services\nmosint automated email osint tool, requires many API keys.\nignorant checks if a phone number is used for snapchat/instagram\n\n\n\nemail connectors/client\nproton mail unofficial client in python\n\n\nemail registration\n\nyandexmail account creator\nbefore it was using 2captcha, now using 5sim to receive sms\nonly login such account through pop3 and imap to prevent revocation\n\n\noutlook email generator\nusing 2captcha and anycaptcha for captcha solving (paid)\n\n\nprotonmail email generator\nusing noptcha or nopecha browser extension (free for 100 captcha solves per day) solving hcaptcha, recaptcha. this extension cannot be used with proxy.\n\n\nmuumuu (which reminds me of someone) email registration using 2captcha, selenium and pyautogui\nI place the list under /root/.muumuu_emails\nthe muumuu mail is programmatically connectable using account and password. seems it is using default ports for these services. POP3 is for both sending and receiving. IMAP is for receiving. SMTP is for sending.\nthis guy’s code is full of hacks. seems only being able to run on his own computer and will break on slightest errors.\nhe stored potential password combinations and also registered accounts (need testing, some may not work) on this google doc. you can download the sheet named “Sheet1” by this api, which adds double quotes and takes more space than exported from web interfaces, method described here.\n\n\n\nreceiving-only email services\n\ntemp email\ntempumail get free temp edu email\n\n\nerine.email\nemail proxy for resending email to you, which I used for github registration (but with a very high block rate without proxy)\n\n\n\nemail aliasing for sending\nicloud’s “hide my email” service seems only provide few email aliases. but according to 3rd party icloud alias generator (cannot be used for chinese version of icloud) you can generate at least 10 aliases. or use hidemyemail-api to login with pyicloud and get aliases as API service. account registered from web without logged in any apple device (maybe virtualbox -&gt; macos has a shot?) will not have email service.\nto send email from alias, you can try setting “FROM” address as your alias via smtp protocol, but the credential shall stay the same. the working approach could be platform specific\nyahoo provides the most email alias up to 500, but 10 for send only emails. however to get one yahoo account one needs offshore phone numbers.\n\n\nemail collection, email scraping\nsearching for “site:pastebin.com @yahoo.com” to get some email addresses, also searching in github might help as well.\nmailcat find email address by nickname (check if deliverable?)\ntheharvestor: email harvestor\nemail collector\ndomain and email collector\n\n\nemail marketing\nuse other’s links/contents to increase diversity and increase anonymity. put your related contents among them.\nemail marketing is quantity over quality. know your customers’ preferences and behaviors (language, country, life schedule (by year? month? week? time in a day?)) by linking their accounts on other platforms, telemetry.\nemail bulk senders are equipped with email templates, statistics (like opened or not, click data monitoring)\nvary your email style and content unless you want to get blocked/trashed by servers\n\nemail templates\npremail is an easy-to-use component-based build system for MJML, the email templating language"
  },
  {
    "objectID": "posts/bc4961f2-6efe-48f6-95ac-161076408834/index.html#sms",
    "href": "posts/bc4961f2-6efe-48f6-95ac-161076408834/index.html#sms",
    "title": "email scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT",
    "section": "SMS",
    "text": "SMS\n\nsending SMS\n发送短信 邮件 第一步是收集目标的邮箱和手机号码 收集目标ID 可从社工库中获取 可以根据社工的metadata决定推送内容类别\n\nSMS flooding\nsmsboom by whalefall 远程获取的api 不知道是干啥的 有待研究\n这个的原理是收集了大量发验证码到目标的手机号的api\nrepo转移到了openethan下面\n考虑破解这些网站 获取它们的短信验证所需要的credential\nhttps://github.com/WhaleFell/SMSBoom\n\n\nsending SMS with content\nsend sms 1 per day per ip (you might use tor to do ip switching):\nhttps://textbelt.com/\nhttps://github.com/HACK3RY2J/Anon-SMS\nhttps://github.com/typpo/textbelt\nfreesms: (don’t work for my phone number as recipient though, but I found some interesting projects on github relating to free SMS sending, some using OCR to crack captcha and access API)\nhttps://www.afreesms.com/freesms/\nyoy might want phone number lists for sending ads via free sms providers\nshows [number]@139.com is the only email2sms gateway in china\nhttps://email2sms.info\nlist of email2sms providers:\nhttps://www.howtogeek.com/howto/27051/use-email-to-send-text-messages-sms-to-mobile-phones-for-free/\nhttp://www.mutube.com/projects/open-email-to-sms/gateway-list/\nhttp://en.wikipedia.org/wiki/List_of_carriers_providing_Email_or_Web_to_SMS\n\n\n\nreceiving SMS\n\npaid sms receiving\n5sim paid sms receive service worldwide\n\n\nfree sms receiving\nsms auto regist is written in go, utilizing yunjiema.top for sms receiving\nonline sms receivers are not so reliable (not even usable for yahoo registration), and those found from google searches (like free receive sms (这个网站有反js调试 打开debugger自动暂停执行), which has simple interface for fetching data, and you can search this site on github to get more sources and potential API adaptors like disposable phonebook) have chances to get registered yahoo accounts."
  },
  {
    "objectID": "posts/bc4961f2-6efe-48f6-95ac-161076408834/index.html#account-registration-helpers-verification-captcha-solving-proxies",
    "href": "posts/bc4961f2-6efe-48f6-95ac-161076408834/index.html#account-registration-helpers-verification-captcha-solving-proxies",
    "title": "email scraper, 自动发短信 邮件 自动接收短信 接收邮件 mail sms automatic sending ad broadcasting, email verification, sms verification, sms login, email login, temp mail, email OSINT",
    "section": "account registration helpers: verification, captcha solving, proxies",
    "text": "account registration helpers: verification, captcha solving, proxies\naccount generator helper including:\nTemp email services\nReceive SMS\nGenerate data\nProxy parser\nCaptcha solving\n\n\nproxies\nProxy-Cheap pay by data amount"
  },
  {
    "objectID": "posts/997dc98a-8883-482a-9b93-d3cff49e984f/index.html",
    "href": "posts/997dc98a-8883-482a-9b93-d3cff49e984f/index.html",
    "title": "expect send special control chars",
    "section": "",
    "text": "reference blog"
  },
  {
    "objectID": "posts/cd70237b-ef04-47b8-a0dc-9ceadd42386c/index.html",
    "href": "posts/cd70237b-ef04-47b8-a0dc-9ceadd42386c/index.html",
    "title": "faster python",
    "section": "",
    "text": "latest python has better performance.\npypy is fast.\ncodon is using python syntax to compile python into static executable."
  },
  {
    "objectID": "posts/4cf9f3fe-16fa-4fc5-a937-34939367a010/index.html",
    "href": "posts/4cf9f3fe-16fa-4fc5-a937-34939367a010/index.html",
    "title": "A Python Wrapper for FFmpeg: Simplifying Command-Line Functionality",
    "section": "",
    "text": "ffmpeg python wrapper\nmost famous code to cli args ffmpeg python wrapper:\nhttps://github.com/kkroening/ffmpeg-python"
  },
  {
    "objectID": "posts/b856e82f-cfe6-4eb5-bf30-4531aef166cf/index.html",
    "href": "posts/b856e82f-cfe6-4eb5-bf30-4531aef166cf/index.html",
    "title": "filename issue on lexar m1",
    "section": "",
    "text": "this server forbids usage of leftperiod.\nwe can use custom encoding rules in rclone:\nrclone sync --smb-encoding=Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot,LeftPeriod &lt;source&gt; &lt;target&gt;"
  },
  {
    "objectID": "posts/c5f9bccf-7662-4477-a3b2-1954708b1ec7/index.html",
    "href": "posts/c5f9bccf-7662-4477-a3b2-1954708b1ec7/index.html",
    "title": "find an unused random local port and announce it on redis",
    "section": "",
    "text": "issues were found when launching apps on fixed ports.\nmaybe you should create this entry inside your lazero package? no need for uploading to pypi, just keep it under pyjom and leave a local install script there.\nmake sure all related services are going to launch after the redis_service.service target. on macos or windows this may vary.\nallocate multiple unused ports at once or they may overlap.\nabandon ports found on redis.\npython to get unused port:\ndef getUnusedLocalhostPort():\n\"\"\"\nThese were \"Borrowed\" from YCM.\nSee https://github.com/Valloric/YouCompleteMe\n\"\"\"\nsock = socket.socket()\n# This tells the OS to give us any free port in the range [1024 - 65535]\nsock.bind((\"\", 0))\nport = sock.getsockname()[1]\nsock.close()\nreturn port\ninstall redis-py:\npip install redis\npython send port to redis:\nimport redis\nr = redis.Redis(\nhost='hostname',\nport=port,\npassword='password')\n# open a connection to Redis\nport = getUnusedLocalhostPort()\nr.set('programPort', port)\nvalue = r.get('programPort')\nprint(value)"
  },
  {
    "objectID": "posts/e09cbe3f-3ef3-46f4-b7f2-01263134c6e8/index.html",
    "href": "posts/e09cbe3f-3ef3-46f4-b7f2-01263134c6e8/index.html",
    "title": "fire prevention and smart switches",
    "section": "",
    "text": "锂电池充电防爆箱\n\nuse fire preventing sheets, use high quality cabels, use fire preventing cabel protectors around coils, spray fire preventing liquid\n\nfire is detected multiple times and is now the major concern of all. even if you somehow find a little purpose from the machine, the machine can always burn for no reason at all. you need to stop it.\nif the source is battery-less, cutting off the power can solve the problem. if it has battery, then you need to wait till its battery being drained (usually shortcut) and then ditch it.\nfire or shortcut usually happens around those plugged or charged devices. unmanaged ones can cause dramatic catastrophics.\nif you want distributed computing, safety need to be put into first place.\nyou need to always make sure that message service is always available to the supervisor.\n\nwe introduce some chain reaction like mechanism, to turn off corresponding wifi-connected switches when specific signal is received.\nput temperature & smoke detectors and fireballs around many places, especially for those long-running machines. once fire detected, send alarm notification and switch off the main power controller.\nhomeassistant adaptor on ups & nanopi & 4g networks\nfire countermeasure shall be linked to smart power switches (once triggered, cut off the power), and placed evenly to potential area\nalso human presence sensor shall be placed, to create more advanced logic, along with physical switches & power level based logic.\n\nalthough it might be less likely to have devastating fire catastrophies inside if procedure mentioned above is done correctly, fire outside the domesticated area is also concerned.\nwe shall first make sure living objects can escape in time. once fire outside the room is detected, all important files shall be uploaded to the cloud. if fire is inside, cut off the power and use UPS to continue execution. make sure important data and devices can be carried around, and active countermeasures like firebots and firerolls will stop the propagation of fire (to isolate air from fire, even if fire is inside)"
  },
  {
    "objectID": "posts/3771a875-295e-4446-b21f-a6373bf79116/index.html",
    "href": "posts/3771a875-295e-4446-b21f-a6373bf79116/index.html",
    "title": "force pty allocation when spinning up tmux over ssh",
    "section": "",
    "text": "kali -t tmux attach -t &lt;target_session_name&gt;\nor:\nkali -o RequestTTY=no tmux attach -t &lt;target_session_name&gt;\nsituation:\n$ ssh 192.0.2.125 tmux attach\nopen terminal failed: not a terminal\nThe solution is to simply force pseudo-terminal allocation.\n$ ssh -t 192.0.2.125 tmux attach\n[...]\nDefine RequestTTY in OpenSSH SSH client configuration file to make this permanent.\n$ cat ~/.ssh/config\nHost 192.0.2.125\nRequestTTY yes"
  },
  {
    "objectID": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html#sources",
    "href": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html#sources",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "sources",
    "text": "sources\n\nproxyscan.io\nreferred by Proxy-List\n\n\ntelegram bots\nhigh quality proxy (channel)\nsocks5 bot\n\n\nself-hosted or cloud/CI based\nproxylist by fate0 (ceased contribution for long) has stopped working since broken github action settings, though getproxy still works (collecting unchecked proxies via travis-ci). i think clash can handle that automatically though."
  },
  {
    "objectID": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html#tools",
    "href": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html#tools",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "tools",
    "text": "tools\n\ncontrollers\nclash-ctl control clash from commandline\nclashctl clash controller in rust, with tui and commandline interface\n\n\nlink converters\n机场订阅转换器-V2ray,Clash,SSR,SS等订阅链接在线转换\nsubconverter self-hosted utility to convert between various subscription format\n\n\nscrapers\nproxypool\n\n\nrouting rules\nclash_rules"
  },
  {
    "objectID": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html#providers",
    "href": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html#providers",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "providers",
    "text": "providers\n\nsubscription links\nproxy-list 20000+\nfreefq\nclash_sync/clash_auto\nShadowsocksAggregator use its Eternity.yml in clash. it also has many sources avaliable for check in README.md\nProxy update hourly\nfree-servers v2ray subscription\nfree-proxy-ss\nSub\nclash-freenode\nclashfree\n\n\nclients\ncrack lantern win 6.8.8\nlantern win 6.8.5\na bunch of cracked clients\nlantern 6.8.7"
  },
  {
    "objectID": "posts/1210e7f0-68eb-4dbc-9012-9f7bbdb4b730/index.html",
    "href": "posts/1210e7f0-68eb-4dbc-9012-9f7bbdb4b730/index.html",
    "title": "generate noise image, noise video, noise audio with ffmpeg for test",
    "section": "",
    "text": "simulating tv noise\nffmpeg -f lavfi -i nullsrc=s=1280x720 -filter_complex \\\n\"geq=random(1)*255:128:128;aevalsrc=-2+random(0)\" \\\n-t 5 output.mkv\nffmpeg -f rawvideo -video_size 1280x720 -pixel_format yuv420p -framerate 25 \\\n-i /dev/urandom -ar 48000 -ac 2 -f s16le -i /dev/urandom -codec:a copy \\\n-t 5 output.mkv"
  },
  {
    "objectID": "posts/afb0e7a8-9f05-497b-b492-baf9b4ca5821/index.html",
    "href": "posts/afb0e7a8-9f05-497b-b492-baf9b4ca5821/index.html",
    "title": "gfw circumvention, download youtube videos, scrape banned websites",
    "section": "",
    "text": "binder as colab alternative\napart from kaggle, you can also use github actions, devops and more, if only we can get the results in time with code.\ngithub integrated ci platforms\ncirrus graphql spec with artifact info\ngithub actions api: download artifact\ncircleci: artifact\nazure pipelines: artifacts"
  },
  {
    "objectID": "posts/7bec84fe-7080-45cb-8f4f-6b6da1d1cbcf/index.html",
    "href": "posts/7bec84fe-7080-45cb-8f4f-6b6da1d1cbcf/index.html",
    "title": "gitter developer tokens and qq opqbot, reverse engineering qq protocols and more",
    "section": "",
    "text": "qq seems to release mac qq with electron, lot more easier for reverse engineering\nhow to reverse go binary, golang reverse\nopqbot官方已经说了 登陆过程中会用到远程的服务器 这个服务器究竟在干什么不得而知 可能和登陆有关也可能没有关系 但是服务器维护期间是没法扫码登录的 如果有可以正常使用的secdata是可以直接启动服务的 不需要服务器 所以估计这个服务器很可能就是拿来解析cookie的\nlogin error:\n2022/08/14 00:01:24.808 [I]  Scan Status 48 Uin 0\n2022/08/14 00:01:25.880 [I]  Scan Status 48 Uin 0\n2022/08/14 00:01:26.937 [I]  Scan Status 53 Uin 0\n2022/08/14 00:01:27.998 [I]  Scan Status 53 Uin 0\n2022/08/14 00:01:29.054 [N]  User &lt;userId&gt; 登录中..请勿连续操作,登录成功后或释放连接后在继续操作 登陆成功后请勿频繁扫码再次登陆(除非冻结导致的掉线) 发不出去群消息请挂机几天 TX日常风控\n=========本框架 🎈 免费 🎈 使用 谨防 ⚠️ 诈骗 ⚠️ 收费 切勿用于 🈲️ 非 🈲️ 法用途\n=========交流群:757360354 TG群组:https://t.me/IOTQQ\n=========开源社区 👍 https://github.com/opq-osc 👍\n=========项目主页 😄 https://github.com/OPQBOT/OPQ/wiki 😄\n=========项目Wiki 📒 https://github.com/OPQBOT/OPQ/wiki 📒\n2022/08/14 00:02:30.234 [W]  recvPump session 0D48F5949075DA13D3A9F83838903920\n2022/08/14 00:02:30.234 [A]  Default Closed:0D48F5949075DA13D3A9F83838903920\n2022/08/14 00:02:30.235 [D]  Unregister In Conn -&gt; 0D48F5949075DA13D3A9F83838903920\n\n关于自动加群 可以考虑使用安卓手机自启动功能（需要下载startup manager 或者boot manager（有root权限和xposed框架）） 用termux-appium 自动操作手机在联网的情况下自启动加群\n现在有两个标准onebot nonebot\n这两个协议都不支持主动加好友 加群 还有收红包方法 至少mac qq协议支持这些方法 但是其他的协议比如手表 ipad协议支不支持就不清楚了\nonebot有大量的qq适配器 而nonebot有大量的插件和除了qq以外的连接器\nnonebot可以连接onebot\n在onebot的qq适配器中 oicq可以查看qq历史聊天记录（有待验证） 可能对qq的数据爬取有帮助 视频爬取 oicq这个适配器有在群里面加好友的方法addFriend(gid, uid)可以参考,提供了一些用于逆向qq协议的程序：\ntxhook 该软件适合在安卓8.0以上系统运行，理论支持安卓7.0以上，但是很多问题。群号：901422091 702991373\n\n获取ShareKey…\n主动拦截固定Ecdh密钥及版本\n对Jce\n过滤抓包，支持高级过滤（长按抓包页面的搜索栏展示/隐藏图标）\n\nprotobuf online decode\nprotobuf unpack-tools\n也有一些可以进行二次开发的qq web api 搜索QQ号和群号 且有个性签名等更多信息 或许可以搜索关键词？\n这些适配器中有的提供了qq频道的支持：\noicq-guild\n也可以考虑用frida ghidra radare2 cutter来逆向opqbot的go编译好了的程序 或者逆向分析opqbot的网络请求数据 甚至直接动态调用opqbot里面的方法 直接用其他机器人登陆之后获得的cookie进行操作\nto get the token, login first, then visit here or click “sign in” here\n据说扫码登录只支持同一个ip下面的登陆 不知道为什么这个opqbot登陆失败 但是其他机器人都提供了账号密码登陆的渠道 将opqbot的协议逆向出来 或许可以提高登陆成功率 实现相同的功能\n默认(可修改)在 ./data/your-account/ 下会自动生成device.json设备文件，登录完成后此设备文件长期有效\n设备文件的生成并非随机，而是使用固定算法，一个账号会永远生成同一份设备文件\n如果需要在异地服务器上登录，建议先在常用地通过设备验证并登录挂机一段时间\n由于会生成相同设备文件，只要不手动修改，只需验证一次，在任何地区都可直接登录\nit seems the login issue of opqbot is related to the account itself, not gitter token, software version or proxy\nby the way we could always use go-cqhttp, without the ability to collect red packet and add group/friends.\nqq add group/friends may be enabled by our windows virtual machines. without opq, it is very memory intensive.\ntokens:\n74eb7eb14aa36d1b9c2c663bc49335e8becd5318\n\n2d391bd7639362032d09abfc5a9cc6368b7664d5\n\nbdf52599d992665509ee5b0b533d5eed08452def"
  },
  {
    "objectID": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html#macos",
    "href": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html#macos",
    "title": "cpu/gpu temperature monitor",
    "section": "macos",
    "text": "macos\nosx-core-temp for old intel macs\napple_sensors and smctemp for m1 and newer macs\nplace this under /opt/homebrew/bin/osx-cpu-temp to run archey4 with cpu temperature:\n#!/bin/bash\nsmctemp -c"
  },
  {
    "objectID": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html#windows",
    "href": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html#windows",
    "title": "cpu/gpu temperature monitor",
    "section": "windows",
    "text": "windows\ncoretemp"
  },
  {
    "objectID": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html#linux",
    "href": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html#linux",
    "title": "cpu/gpu temperature monitor",
    "section": "linux",
    "text": "linux\npsensor"
  },
  {
    "objectID": "posts/80ecad66-1b58-4a5e-ba26-d351c54dbaa6/index.html",
    "href": "posts/80ecad66-1b58-4a5e-ba26-d351c54dbaa6/index.html",
    "title": "hacker forums",
    "section": "",
    "text": "some hacker forums like leakbase has rss feed\nleakbase has proxy section in which you may find fresh proxy lists (may not work in mainland, but who knows?)\nsearch with the name or link of these forums in github and you will get more info about hacking.\na bunch of hacker forums, including:\nBreached\nXss\nExploit\n0x00sec\nlolz\nLeakzone\nEnclave\ndublikat\nVlmi\nOmrt\nNulled\nCracked\nCoockie\nAltenens\nBidencash\n\nwooyun.org mirror site wooyun is dead/closed since 2016\nsocial engineering is just a fancy name for spotting candidates, hooking up, gaining trust and doing shit.\nin hacking we must be multilingual, as this shit is really hard to get right.\nyou would read them sometime do you? you would collect info from these sites do you? you would search for things when you need it do you?\nYou would like forums for dark web? Forum for hacking?\n你要的是社工库 提取出来的账号密码库 用来撞库？百度谷歌 QQ 百度云盘 github 磁力种子搜索\nwhen not reached, make sure you are in the channel!\nOffensive Community\n安全脉搏\n网络尖刀\n习科论坛\n红黑联盟\n黑客X档案\nAlternative to ‘raid forum’: visit it in archive.org!\n看雪论坛\n乌云论坛（archive里面看吧）\n吾爱破解\n3dm\nfreebuf\nHack Today\nGreySec Forums\n世界中文黑客论坛\n90Sec\nT00LS\nhttps://jaq.alibaba.com/community/index\nhttp://bobao.360.cn/index/index\nhttps://www.ichunqiu.com/\nhttps://pentesterlab.com/\nhttps://xianzhi.aliyun.com/forum/\nhttp://lab.seclover.com/\n腾讯玄武实验室\nhttp://xlab.tencent.com/cn/\nxss.is\ncracked.io\nBreached forum and onion\nnulled\ndread (forum)\nleakbase forum leaked database\nexploit.in in russian\nhacktown hacking tutorial\nhackforums site offline? another web archive shit?\nevilzone\ncryptbb is dead?\nfreehacks dead?\nCrackingKing dead?\nenvoy dead?\nhelium dead?\nHackADay\nExploit Database\nTinkernut\nDark Web Forum\nJean Valjean forum\nCarding Team\nBiTSHACK\nSecList\n0Day\nHackerPlace\n0x00sec\nHack5 Forums\nBHF\nHack This Site\nKickAss\nBreaking Bad\nPacket Storm\nOpenSC\nHackMac\nEnigma Group\nRohitab\nEthical Hacker\nCracking Forum\nCrackmes de\nBinary Revolution Hacking Forums\nHack Hound\nHellbound Hackers\nftp://www.ly2008.com\n用户名:ly2008\n密码:ly2008\nhttp://discovery0.blog.hexun.com/3271892_d.html\nhttp://www.hackerxfiles.net/\nhttp://www.nohack.cn/\nhttp://www.hacker.com.cn/\nftp://fseandxy1@y667.com/\nhttp://www.mmbest.com/SoftList/Catalog8/SoftList_Time_1.html\nhttp://www.it-is.com.cn/dh/\nhttp://www.20cn.net/cgi-bin/download/down.cgi?list=passwd\nhttp://www.98919.com/index.html\nhttp://www.muvip119.net/2/index.html\nhttp://www.anqn.com/\nhttp://www.hf110.com\nhttp://down.juntuan.net/index.html\nhttp://new.shockhack.net/index.asp\nhttp://dx.hackbase.com/\nhttp://www.chinahonker.com/index.htm\nhttp://www.cnhacker.com/\nhttp://77169.org/index.html\nlegionhiden4dqh4.onion - Let’s start with HeLL Reloaded, probably the only one that isn’t just awful. where Tor Carding Forum (TCF) members who weren’t arrested when it was seized are now dwelling! Not operated by the same people behind the original HeLL, but after the original was seized, some of the moderators and members made this site.\nexoduockgfq3ikf7.onion Ex0du$, Pretty mediocre forum, lots of shitty banking botnets being sold. Also ransomeware is the big thing recently, so of course that’s being sold. The code is HILARIOUS. RansomWare coded in visual basic, Java, C# and AutoIT v3! Great.\ndamagelabraahzcu.onion - DamageLabs primarily russian forum, looks like there’s not much interesting going on here either. They have a good collection of pirated programming books.\ndarkod3eeziu3w5p.onion - looks like a really dead forum.\ndublik2uqiorycsj.onion - dublik russian forum\nforohpysho2t5mjs.onion - another random forum\n1、独自等待：https://www.waitalone.cn/\n2、中国红客联盟：https://www.ihonker.org/forum.php\n3、安全沙漏：https://www.secsilo.com/about\n4、易安在线：https://www.e365.info/\n5、铁匠运维网：http://www.tiejiang.org/\n6、吾爱漏洞：http://www.52bug.cn/\n7、破晓团队：http://www.secbug.org/\n8、黑白网：http://www.heibai.org/178.html\n9、安全客：https://www.anquanke.com/\n10、E安全：https://www.easyaq.com/\n11、漏洞时代：http://0day5.com/\n12、猫头鹰：http://www.mottoin.com/\n13、华域联盟论坛：https://www.cnhackhy.com/forum.php\n14、逆向未来：https://www.pd521.com/\n15、邪恶八进制：https://forum.eviloctal.com/\n16、飘云阁：https://www.chinapyg.com/\n17、红黑联盟：http://bbs.2cto.com/\n18、技术宅的世界：https://www.0xaa55.com/\n19、安全牛：https://www.aqniu.com/\n20、兄弟论坛：http://hackxd.com/\n21、零日安全：https://www.jmpoep.com/\n22、南域剑盟：http://www.98exe.net/\n23、黑基论坛：http://www.safebase.cn/\n24、网络攻防小组（WLGF）：http://www.nsoad.com/\n25、黑吧安全网：http://www.myhack58.com/\n26、幽灵学院：http://www.41443.com/\n纵观黑客发展史，大可分为三代：\n第一代：专门从事计算机、网络，其代表组织为“绿色兵团”（1996年—1998年）\n第二代：网络爱好者和在校学生.其代表组织为“中国黑客联盟”（1998年—2000年）\n第三代：在校学生，其代表组织为“红客联盟”，“中国鹰派”（2000年—今）\n以下为几个典型的黑客组织：\n●安全焦点（代表人：冰河）网址：www.xfocus.net\n●绿色兵团（已解散）（代表人：龚蔚）\n●中国鹰派联盟（代表人：老鹰）网址：www.chinaeagle.org 博客：blog.sina.com.cn/u/1262168602\n●小榕工作室（代表人：小榕）网址：www.netxeyes.com\n●第八军团（代表人：陈三公子）网址：www.sec520.com\n●邪恶八进制（代表人：冰血封情）网址：forum.eviloctal.com\n●黑客基地（代表人：孤独剑客）网址：www.hackbase.com\n●华夏黑客同盟（代表人:怪狗）网址：www.77169.com\n●牧民网安（代表人：牧民战天）网址：www.hack006.com\n●黑客防线 网址：www.hacker.com.cn\n国外黑客组织站点及介绍黑客知识的网站：\n●http://www.security.nnov.ru/，俄罗斯的一个安全站点\n●http://chess.eecs.berkeley.edu/trust/加州大学伯克利分校“普安全技术研究小组”网站\n●http://www.io.com/.vkp的个人主页，linux安全方面的专业人员(程序员).\n●http://linsec.ca/加拿大一个主要收集linux安全相关的文档资料的站点, 也包括其它类Unix系统如OpenBSD, Mac OS X等.\n●http://www.rootsecure.net/一个专门为系统管理员和黑客提供安全新闻的网站，成立于2002年9月8日\n●http://astalavista.box.sk.著名的软件破解网站\n●auscert.org.au.一个很棒的黑客工具和入侵攻击的搜索网站\n●http://www.elitehackers.info/.为博学的黑客提供的信息公告牌，是上了等级的黑客去的地方。可找到最新的入侵攻击及对解决办法\n●ftp://ftp.nec.com/.在/pub/securit目录下面包含一个巨大的工具库\n●ftp.win.tue.nl.在/pub/securit目录下包含巨大的安全工具库\n国外安全 http://www.neohapsis.com/ 内容极为丰富\n国外安全 http://www.deadly.org/ 大量关于OpenBSD的资料文档教程\n国外安全 http://www.guninski.com/ 安全专家Guninski的主页，有大量由系统漏洞\n国外安全 http://www.sysinternals.com 有很好的windows下的工具及源代码\n国外安全 http://www.securityflaw.com/bible/ 入侵检测等文档整理较好的站点\n国外安全 http://www.secinf.net/ 网络安全方面的大量文档\n国外安全 http://www.incident-response.org 入侵反应，数据恢复工具等\n国外安全 http://www.securityfocus.com/ 安全资料整合最好的站\n国外安全 http://www.project.honeynet.org/ 由安全界一帮牛人组织的一个project\n国外安全 http://www.packetstormsecurity.com 资料全面的安全站\n国外安全 http://www.securityportal.com/ 还可以看看的安全站\n国外安全 http://www.ussrback.com/ 比较活跃的安全站\n国外安全 http://www.attrition.org/ 内容全面的安全站\n国外安全 http://www.wiretrip.net/rfp/2/index.asp rfp的安全主页，提供权威的安全信息\n国外安全 http://www.antionline.com/ 有些特色栏目的安全站\n国外安全 http://www.eeye.com/ eeye公司的主页，提供权威性的安全建议和工具\n国外安全 http://www.insecure.org/ Fyodor的主页，nmap的老家，还有exploit\n国外安全 http://www.atstake.com/ @stack公司的主页，提供权威的安全建议\n国外安全 http://www.bugnet.com/ 提供漏洞修补\n国外黑客 http://lsd-pl.net/ LsD的站,最新最有效的exploit\n国外黑客 http://www.s0ftpj.org 提供一些水平很高的小工具\n国外黑客 http://phrack.org/ Phrack的主页，经典的黑客技术电子杂志\n国外黑客 http://www.w00w00.org/ w00w00组织的主页\n国外黑客 http://mixter.void.ru/ Mixter的个人主页，不少有用的工具\n国外黑客 http://www.thehackerschoice.com/ THC黑客组织的页面，很好的安全文档和工具\n国外黑客 www.win2000mag.net Windows & .NET Magazine Network 绝对专业的站点，文章都是一流的\n国外黑客 http://www.2600.com/ 2600 Magazine\n国外黑客 www.experts-exchange.com 全球有名的社区\n国外黑客 www.is-it-true.org 类似于FAQ的站点，资源丰富\n国外黑客 www.mixter.warrior2k.com mixter security\n国外黑客 www.liun.hektik.org Long Island our Underground Networks\n国外黑客 www.ussrback.com ussr is back\n国外黑客 www.securiteam.com 非常好的安全文章漏洞利用工具下载站点\n国外黑客 www.lsd-pl.net The Last Stage of Delirium Research Group\n国外黑客 www. neworder.box.sk Box Network team\n国外黑客 www.sysinternals.com sysinternals\n国外黑客 www.webattack.com WebAttack Inc\n国外黑客 www.blackhat.com Black Hat, Inc\n国外黑客 http://p.ulh.as pulhas\nhttp://www.hack.co.za (国外著名黑客站点，较全的Exploit库)\nhttp://www.phrack.org (经典的黑客技术电子杂志)\nhttp://www.antionline.com (国外经典黑客站点)\nhttp://whitehats.com (白帽子网站，有最新的规则库下载，关于Snort等)\nhttp://lsd-pl.net (发布最新的Exploit程序)\nhttp://www.nhs8.com/ 神刀网\nhttp://packetstormsecurity.com (国外著名漏洞库，有大量exploit程序)\nhttp://oliver.efri.hr/~crv/security/bugs/list.html (有整理好的最新漏洞库供下载)\nhttp://astalavista.box.sk (著名的软件破解网站)\nhttp://www.thehackerschoice.com (THC黑客组织的站点，有很多资料和工具)\nhttp://www.insecure.org (Fyoderr的个人站点,即Nmap的老家)\nhttp://www.securityfocus.com/\nhttp://www.milw0rm.com/\nhttp://www.metasploit.com/"
  },
  {
    "objectID": "posts/b787c379-0a24-41f4-9f5e-40c1e7349186/index.html#alternatives",
    "href": "posts/b787c379-0a24-41f4-9f5e-40c1e7349186/index.html#alternatives",
    "title": "hackthebox",
    "section": "alternatives",
    "text": "alternatives\n11 hack the box alternatives\n9 alternatives from alternativesto"
  },
  {
    "objectID": "posts/b787c379-0a24-41f4-9f5e-40c1e7349186/index.html#usage",
    "href": "posts/b787c379-0a24-41f4-9f5e-40c1e7349186/index.html#usage",
    "title": "hackthebox",
    "section": "usage",
    "text": "usage\nofficial website\nusage\nhackthebox 2022 writeup\nhackthebox october\n内网靶机渗透\n靶场练习\n你也可以用metasploitable进行练习"
  },
  {
    "objectID": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html#recommend-popular-ai-video-creation-tools",
    "href": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html#recommend-popular-ai-video-creation-tools",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "recommend popular ai video creation tools",
    "text": "recommend popular ai video creation tools\nThere are a number of popular AI video creation tools that you might want to consider using, depending on your needs and budget. Here are a few options:\nAnimoto: Animoto is a cloud-based video creation platform that uses AI to help you create professional-quality videos quickly and easily. You can choose from a variety of templates, add your own media, and customize your video with text, music, and other elements.\nWibbitz: Wibbitz is an AI-powered video creation tool that allows you to turn text into video content. You can input a written article or script, and the AI will generate a video complete with images, text, and music.\nAdobe Premiere Elements: Adobe Premiere Elements is a consumer-level video editing software that includes AI-powered features such as automatic video editing, object detection, and more.\nLumen5: Lumen5 is an AI-powered video creation platform that allows you to input text, images, or a link to an article and have the AI generate a video for you. You can customize the video with your own branding, music, and other elements.\nIt’s a good idea to try out a few different tools and see which one works best for you and your needs. Keep in mind that while these tools can be helpful, they may not produce results that are exactly what you’re looking for, and you may need to do some manual editing or customization to get the desired results."
  },
  {
    "objectID": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html#recommend-ai-powered-video-editor",
    "href": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html#recommend-ai-powered-video-editor",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "recommend AI-powered video editor",
    "text": "recommend AI-powered video editor\nThere are several AI-powered video editors available that you might want to consider using, depending on your needs and budget. Here are a few options:\nAdobe Premiere Pro: Adobe Premiere Pro is a professional-grade video editing software that includes a number of AI-powered features, such as object detection and automatic color grading.\nDaVinci Resolve: DaVinci Resolve is a professional-grade video editing software that includes a number of AI-powered features, such as automatic color grading and audio repair.\nFinal Cut Pro: Final Cut Pro is a professional-grade video editing software for Mac that includes a number of AI-powered features, such as automatic color grading and object detection.\nFilmora: Filmora is a consumer-level video editing software that includes a number of AI-powered features, such as automatic video stabilization and object detection.\nIt’s a good idea to try out a few different video editors and see which one works best for you and your needs. Keep in mind that while these tools can be helpful, they may not produce results that are exactly what you’re looking for, and you may need to do some manual editing or customization to get the desired results."
  },
  {
    "objectID": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html#how-can-ai-help-you-target-specific-audiences",
    "href": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html#how-can-ai-help-you-target-specific-audiences",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "how can ai help you target specific audiences",
    "text": "how can ai help you target specific audiences\nThere are several ways in which artificial intelligence (AI) can help target specific audiences:\nPersonalization: AI can analyze data on individuals and their preferences, and use that information to tailor content and messaging specifically to them. For example, an AI-powered recommendation engine can suggest products or content based on a user’s past behaviors and interests.\nSegmentation: AI can help to segment audiences into smaller, more specific groups based on shared characteristics, such as demographics, interests, or behaviors. This can allow organizations to create more targeted campaigns and messaging.\nPredictive analytics: AI can analyze data on past behaviors and outcomes to make predictions about future behavior. This can help organizations to better understand their target audience and tailor their marketing efforts accordingly.\nNatural language processing: AI can analyze and understand human language, allowing organizations to use chatbots and other tools to communicate with their audience in a more personalized and natural way.\nImage and video analysis: AI can analyze images and videos to understand the content and context, allowing organizations to target specific audiences based on the visual content they consume.\nOverall, AI can be a powerful tool for targeting specific audiences by providing insights, personalization, and automation to marketing efforts."
  },
  {
    "objectID": "posts/8440684b-21e7-4fd7-8bfb-de5b15a7bfa7/index.html",
    "href": "posts/8440684b-21e7-4fd7-8bfb-de5b15a7bfa7/index.html",
    "title": "Hy Programming Language Enhancements for Automation and IDE Support",
    "section": "",
    "text": "hy lisp embedded in python, resumeable exception\njython only supports upto python2.7. these libraries may need substantial changes to be compatible with jython:\nhy\nparse\nhyrule\nreloading\n\nhy docs\nhyrule docs\nhy缺乏基本的补全 vscode目前没法用 我把hy改造成了可以自动reload 自动抓Uncaught exception的模式 如果要取消这些行为 需要加上flag 可以用于hy2py\n-R\ndisable automatic insertion of reloading decorator\n-T\ndisable toplevel try-except\n-K\ndisable toplevel show stacktrace\n-L\ndisable line-by-line try-except\n\n一些未知的expression可能不允许被wrap到我们的macro里面 需要被加入到黑名单 已知的系列包括unpack-iterable之类的\nhy的插件目前分为vim版本和EMACS版本 对spacevim spacemacs不怎么友好\nvim syntax highlight\nemacs hy-mode and jedhy\nhyuga for neovim, with custom vim-lsp\nhy的code autoindentation功能我做了 nelean 目前最新版本有待更新 主要是对字符串的正则进行了优化"
  },
  {
    "objectID": "posts/b41c6b16-45ec-41a7-af8e-5c5400c9f8ed/index.html",
    "href": "posts/b41c6b16-45ec-41a7-af8e-5c5400c9f8ed/index.html",
    "title": "image resize, image padding, image scanning",
    "section": "",
    "text": "def scanImageWithWindowSizeAutoResize(\nimage,\nwidth,\nheight,\nreturn_direction=False,\nthreshold=0.1,  # minimum 'fresh' area left for scanning\n):  # shall you use torch? no?\nshape = image.shape\nassert len(shape) == 3\nih, iw, channels = shape\ntargetWidth = max(width, math.floor(iw * height / ih))\ntargetHeight = max(height, math.floor(ih * width / iw))\nresized = cv2.resize(\nimage, (targetWidth, targetHeight), interpolation=cv2.INTER_CUBIC\n)\n# determine scan direction here.\nimageSeries = []\nif targetWidth / targetHeight == width / height:\nimageSeries = [resized]  # as image series.\ndirection = None\nelif targetWidth / targetHeight &lt; width / height:\ndirection = \"vertical\"\n# the scanning is along the vertical axis, which is the height.\nindex = 0\nwhile True:\nstart, end = height * index, height * (index + 1)\nif start &lt; targetHeight:\nif end &gt; targetHeight:\nif 1 - (end - targetHeight) / targetHeight &gt;= threshold:\nend = targetHeight\nstart = targetHeight - height\nelse:\nbreak\n# other conditions, just fine\nelse:\nbreak  # must exit since nothing to scan.\ncropped = resized[start:end, :, :]  # height, width, channels\nimageSeries.append(cropped)\nindex += 1\nelse:\ndirection = \"horizontal\"\nindex = 0\nwhile True:\nstart, end = width * index, width * (index + 1)\nif start &lt; targetWidth:\nif end &gt; targetWidth:\nif 1 - (end - targetWidth) / targetWidth &gt;= threshold:\nend = targetWidth\nstart = targetWidth - width\nelse:\nbreak\n# other conditions, just fine\nelse:\nbreak  # must exit since nothing to scan.\ncropped = resized[:, start:end, :]  # height, width, channels\nimageSeries.append(cropped)\nindex += 1\nif return_direction:\nreturn imageSeries, direction\nelse:\nreturn imageSeries\ndef resizeImageWithPadding(\nimage,\nwidth,\nheight,\nborder_type: Literal[\"constant_black\", \"replicate\"] = \"constant_black\",\n):\nshape = image.shape\nassert len(shape) == 3\nih, iw, channels = shape\ntargetWidth = min(width, math.floor(iw * height / ih))\ntargetHeight = min(height, math.floor(ih * width / iw))\nresized = cv2.resize(\nimage, (targetWidth, targetHeight), interpolation=cv2.INTER_CUBIC\n)\nBLACK = [0] * channels\ntop = max(0, math.floor((height - targetHeight) / 2))\nbottom = max(0, height - targetHeight - top)\nleft = max(0, math.floor((width - targetWidth) / 2))\nright = max(0, width - targetWidth - left)\nif border_type == \"constant_black\":\npadded = cv2.copyMakeBorder(\nresized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=BLACK\n)\nelif border_type == \"replicate\":\npadded = cv2.copyMakeBorder(\nresized, top, bottom, left, right, cv2.BORDER_REPLICATE, value=BLACK\n)\nelse:\nraise Exception(\"unknown border_type: %s\" % border_type)\nreturn padded"
  },
  {
    "objectID": "posts/5c19cbd7-34e4-43d3-813c-17fe1775cafc/index.html#npm",
    "href": "posts/5c19cbd7-34e4-43d3-813c-17fe1775cafc/index.html#npm",
    "title": "issues related to fastgithub and other self-signed certificates in language-specific package managers",
    "section": "npm",
    "text": "npm\nnpm报错：unable to verify the first certificate\nnpm config set strict-ssl false\nnpm config set ca=\"\"\nnpm download binary files from github will raise error since the download speed is low.\nuse cnpm instead, since it will route all github binary requests to mirrored cnpm cdn.\nnpm i -g cnpm\nset some binary distribution file mirror to https://registry.npmmirror.com in ~/.npmrc and ~/.yarnrc:\ncanvas_binary_host_mirror=https://registry.npmmirror.com/-/binary/canvas/\nsass_binary_site=https://registry.npmmirror.com/-/binary/node-sass\nnodejs_org_mirror=https://registry.npmmirror.com/-/binary/node/\nelectron_mirror=https://registry.npmmirror.com/-/binary/electron/\nelectron_builder_binaries_mirror=https://registry.npmmirror.com/-/binary/electron-builder-binaries/\nchromedriver_cdnurl=https://registry.npmmirror.com/-/binary/chromedriver/\nregistry=https://registry.npmmirror.com"
  },
  {
    "objectID": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#language-models",
    "href": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#language-models",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "language models",
    "text": "language models\nallennlp-models\nbert lang street"
  },
  {
    "objectID": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#recommendation",
    "href": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#recommendation",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "recommendation",
    "text": "recommendation\ndeepmatch"
  },
  {
    "objectID": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#fuzzy-search",
    "href": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#fuzzy-search",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "fuzzy search",
    "text": "fuzzy search\nfuzzywuzzy or thefuzz\nfzf a commandline fuzzy matcher\niterfzf as a fzf python binding and its related projects\nrapidfuzz"
  },
  {
    "objectID": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#stopwords",
    "href": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#stopwords",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "stopwords",
    "text": "stopwords\nfrom nltk.corpus import stopwords\nstopwordsiso in python"
  },
  {
    "objectID": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#summarization",
    "href": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#summarization",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "summarization",
    "text": "summarization\nsumy Simple library and command line utility for extracting summary from HTML pages or plain texts\npytextrank Python implementation of TextRank as a spaCy pipeline extension, for graph-based natural language work plus related knowledge graph practices; used for for phrase extraction and lightweight extractive summarization of text documents\nsumma TextRank implementation for text summarization and keyword extraction in Python 3, with optimizations on the similarity function."
  },
  {
    "objectID": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#keyword-extraction",
    "href": "posts/b0decc9f-11b2-42ae-ac42-9e3efe6b128b/index.html#keyword-extraction",
    "title": "keyword extraction, topic modeling, sentence embedding",
    "section": "keyword extraction",
    "text": "keyword extraction\nrake-nltk RAKE short for Rapid Automatic Keyword Extraction algorithm, is a domain independent keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and its co-occurance with other words in the text.\nmulti-rake Multilingual Rapid Automatic Keyword Extraction (RAKE) for Python\nyake Unsupervised Approach for Automatic Keyword Extraction using Text Features\ntutorial and libraries\nkeybert uses sentence transformer to do the job\nkwx\npke Python Keyphrase Extraction module\nimport jieba.analyse as ana\n# methods under ana:\n# ['analyzer', 'default_textrank', 'default_tfidf', 'extract_tags', 'set_idf_path', 'set_stop_words', 'textrank', 'tfidf']"
  },
  {
    "objectID": "posts/bea5c7ab-4c30-4010-84ad-1d4b84c7dd43/index.html",
    "href": "posts/bea5c7ab-4c30-4010-84ad-1d4b84c7dd43/index.html",
    "title": "Introducing LAVIS: A Library for Language-Vision Intelligence with Cross-Modal Implementations",
    "section": "",
    "text": "lavis multimodal library for information retrieval and intelligence, can be used with jina\nlavis has multiple cross-modal implementations\nLAVIS - A Library for Language-Vision Intelligence"
  },
  {
    "objectID": "posts/8dbae3bf-81b2-4793-8f82-d28bd719367a/index.html#static-sources",
    "href": "posts/8dbae3bf-81b2-4793-8f82-d28bd719367a/index.html#static-sources",
    "title": "lazero search tool document preparation",
    "section": "static sources",
    "text": "static sources\nuse my notes\nman pages\ncommandline tool helps\nwebpages to text, to markdown\npages from github repo, topic, search, paperswithcode, kaggle, aistudio, alternativeto, anything"
  },
  {
    "objectID": "posts/8dbae3bf-81b2-4793-8f82-d28bd719367a/index.html#dynamic-sources",
    "href": "posts/8dbae3bf-81b2-4793-8f82-d28bd719367a/index.html#dynamic-sources",
    "title": "lazero search tool document preparation",
    "section": "dynamic sources",
    "text": "dynamic sources\nrss feeds, trends, channels, recommendation, dynamic/interactive webpage/api\nsocial media, instant messaging\nonline search engines\noffline/local search engine like cli based search engine"
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#you-said-hacking-needs-collaboration.-what-if-i-am-alone-and-i-need-help-from-ai-when-hacking",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#you-said-hacking-needs-collaboration.-what-if-i-am-alone-and-i-need-help-from-ai-when-hacking",
    "title": "learn about ai hacking",
    "section": "you said hacking needs collaboration. what if i am alone and i need help from ai when hacking",
    "text": "you said hacking needs collaboration. what if i am alone and i need help from ai when hacking\nWhile it is true that hacking often requires collaboration and a team effort, it is also possible for an individual to carry out a successful hack on their own. In fact, some of the most famous hacks in history were carried out by a single person. However, it is generally more difficult for an individual to carry out a hack without the help of others, as hacking often requires a diverse set of skills and knowledge.\nIn terms of using artificial intelligence to help with hacking, there are a few ways that AI can be useful. For example, AI can be used to automate certain tasks involved in hacking, such as scanning for vulnerabilities or testing password combinations. This can save a lot of time and effort for the hacker, and allow them to focus on other aspects of the hack.\nAdditionally, some AI systems are specifically designed to assist with hacking. For example, there are AI-powered tools that can analyze a target’s network and identify potential vulnerabilities, or generate custom malware that is tailored to the target’s specific system. These tools can greatly enhance a hacker’s ability to carry out a successful attack.\nIn short, while it is possible for an individual to carry out a hack on their own, AI can be a valuable asset in helping them to do so more effectively and efficiently."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#what-are-the-ai-tools-for-hacking",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#what-are-the-ai-tools-for-hacking",
    "title": "learn about ai hacking",
    "section": "what are the ai tools for hacking",
    "text": "what are the ai tools for hacking\nThere are many different AI-powered tools that can be used for hacking, depending on the specific needs and goals of the hacker. Some examples of AI-powered hacking tools include:\nVulnerability scanners: These tools use AI to scan a target’s network for potential vulnerabilities, such as weak passwords or open ports. This can help the hacker to identify potential entry points for an attack.\nMalware generation tools: These tools use AI to automatically generate custom malware that is tailored to a specific target’s system. This can make it more difficult for antivirus software to detect and block the malware.\nSocial engineering tools: These tools use AI to help hackers carry out social engineering attacks, such as phishing campaigns or “spear-phishing” attacks that are targeted at specific individuals. The AI can help the hacker to create more convincing and effective phishing emails or messages.\nPassword cracking tools: These tools use AI to automatically generate and test password combinations, in an attempt to guess the correct password for a target’s account. AI can make this process much faster and more efficient than a human trying to guess the password manually.\nOverall, the specific AI tools that are used for hacking will depend on the individual goals and needs of the hacker. Some hackers may use a combination of different AI-powered tools to carry out their attacks, while others may focus on a single tool that is particularly well-suited to their needs."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#can-i-build-a-search-engine-based-on-ai-for-hacking",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#can-i-build-a-search-engine-based-on-ai-for-hacking",
    "title": "learn about ai hacking",
    "section": "can i build a search engine based on ai for hacking",
    "text": "can i build a search engine based on ai for hacking\nIt is possible to build a search engine that uses AI to help with hacking, although it is important to note that doing so would be illegal in most countries. Hacking is the unauthorized access of a computer or network, and is a crime in most places. As such, building a search engine that is specifically designed to help with hacking would be a criminal act.\nThat being said, it is possible to build a search engine that uses AI to help with legal security research and testing. For example, such a search engine could be used to scan for vulnerabilities in a network or system, or to help generate custom security testing scenarios. However, it is important to only use such a tool for legal and authorized purposes, as using it for illegal hacking activities would be a crime."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#what-are-popular-vulnerability-scanners-powered-by-ai",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#what-are-popular-vulnerability-scanners-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "what are popular vulnerability scanners powered by ai",
    "text": "what are popular vulnerability scanners powered by ai\nSome of the most popular vulnerability scanners that use AI include:\nAcunetix: This is a commercial vulnerability scanner that uses AI to automatically scan a target’s network for potential vulnerabilities. It is able to identify a wide range of vulnerabilities, including SQL injection, cross-site scripting, and more.\nNessus: This is another commercial vulnerability scanner that uses AI to automate the process of scanning for vulnerabilities. It is known for its comprehensive coverage and ability to identify a wide range of vulnerabilities.\nOpenVAS: This is an open-source vulnerability scanner that uses AI to automate the scanning process. It is a popular choice among security researchers and ethical hackers, due to its open-source nature and ability to identify a wide range of vulnerabilities.\nOverall, there are many different vulnerability scanners that use AI, and the specific one that is best for a given situation will depend on the individual needs and goals of the user."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#popular-malware-generation-tools-powered-by-ai",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#popular-malware-generation-tools-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "popular malware generation tools powered by ai",
    "text": "popular malware generation tools powered by ai\nSome of the most popular malware generation tools that use AI include:\nDeepLocker: This is a tool that uses AI to generate custom malware that is tailored to a specific target. It is able to evade detection by antivirus software, making it a powerful tool for malicious hackers.\nAnglerPhish: This is a tool that uses AI to help with the creation of convincing phishing emails. It can automatically generate personalized emails that are tailored to specific individuals, making it more likely that the recipient will fall for the scam.\nCarbanak: This is a piece of malware that uses AI to adapt to the specific system it is running on, making it more difficult to detect and remove. It is known for its ability to steal sensitive financial information from banks and other financial institutions.\nOverall, there are many different malware generation tools that use AI, and the specific one that is best for a given situation will depend on the individual goals and needs of the user."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#popular-social-engireering-tools-powered-by-ai",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#popular-social-engireering-tools-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "popular social engireering tools powered by ai",
    "text": "popular social engireering tools powered by ai\nSome of the most popular social engineering tools that use AI include:\nReFud.me: This is a tool that uses AI to automatically generate convincing phishing emails. It is able to tailor the emails to specific individuals, making them more likely to fall for the scam.\nPhishAI: This is a tool that uses AI to automatically identify and block phishing emails. It is able to learn from past phishing attacks and use that knowledge to improve its ability to detect and block future attacks.\nImperson: This is a tool that uses AI to automatically generate personalized phishing messages that are tailored to specific individuals. It is able to create messages that are highly convincing, making it more likely that the recipient will fall for the scam.\nOverall, there are many different social engineering tools that use AI, and the specific one that is best for a given situation will depend on the individual goals and needs of the user."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#popular-password-cracking-tools-powered-by-ai",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#popular-password-cracking-tools-powered-by-ai",
    "title": "learn about ai hacking",
    "section": "popular password cracking tools powered by ai",
    "text": "popular password cracking tools powered by ai\nSome of the most popular password cracking tools that use AI include:\nHashcat: This is a popular open-source password cracking tool that uses AI to automatically generate and test password combinations. It is known for its high speed and ability to crack even complex and long passwords.\nJohn the Ripper: This is another popular open-source password cracking tool that uses AI to automate the password cracking process. It is able to crack a wide range of password hashes, and is a popular choice among security researchers and ethical hackers.\nAircrack-ng: This is an open-source password cracking tool that is specifically designed for cracking wireless network passwords. It uses AI to automatically generate and test password combinations, making it a powerful tool for breaking into wireless networks.\nOverall, there are many different password cracking tools that use AI, and the specific one that is best for a given situation will depend on the individual goals and needs of the user."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#how-to-use-hashcat-to-generate-password-list-in-terminal",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#how-to-use-hashcat-to-generate-password-list-in-terminal",
    "title": "learn about ai hacking",
    "section": "how to use hashcat to generate password list in terminal",
    "text": "how to use hashcat to generate password list in terminal\nUse the “hashcat” command to start the Hashcat software. You will need to specify the attack mode that you want to use, as well as the type of password hash that you want to crack. For example, to use the “brute-force” attack mode and crack an MD5 password hash, you would enter the following command:\n./hashcat -a 3 -m 0 hash.txt\n\nUse the “–stdout” option to output the generated password list to the terminal. This will allow you to see the password combinations as they are generated by Hashcat. For example, to generate a password list using the “brute-force” attack mode and output it to the terminal, you would enter the following command:\n./hashcat -a 3 -m 0 hash.txt --stdout\n\nUse the “CTRL + C” keys to stop the password generation process once you have generated enough password combinations.\nOverall, using Hashcat to generate a password list in the terminal is a relatively straightforward process, and the commands are easy to learn and use. It is a powerful tool that can greatly assist with password cracking tasks."
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#sha1-on-hashcat",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html#sha1-on-hashcat",
    "title": "learn about ai hacking",
    "section": "sha1 on hashcat",
    "text": "sha1 on hashcat\n./hashcat -a 3 -m 100 hash.txt"
  },
  {
    "objectID": "posts/9040d19a-a7ef-4586-b7fc-4b6c0ebf7d98/index.html",
    "href": "posts/9040d19a-a7ef-4586-b7fc-4b6c0ebf7d98/index.html",
    "title": "lessons learned from premiere pro plugin job",
    "section": "",
    "text": "set up python with appropriate version on client’s computer by script, not by “PyInstaller” which takes huge amount of time to compile and huge disk space (visually).\ntake notes while doing work.\nask for appropriate compensation for any work."
  },
  {
    "objectID": "posts/ca6121d0-55eb-446e-94ee-528dc6dd0c67/index.html",
    "href": "posts/ca6121d0-55eb-446e-94ee-528dc6dd0c67/index.html",
    "title": "library genesis, getting latest ebooks for free",
    "section": "",
    "text": "a russian ebook search engine\ndon’t get confused. it is always in foreign language. always not “educational” or “scanned”.\nquery like “national geographic” will be perfect. books from amazon kindle will also be potentially good."
  },
  {
    "objectID": "posts/f3b4e9eb-1db9-4d05-b572-03bfe5057158/index.html",
    "href": "posts/f3b4e9eb-1db9-4d05-b572-03bfe5057158/index.html",
    "title": "lua python bridge",
    "section": "",
    "text": "lunatic python"
  },
  {
    "objectID": "posts/2b133d53-19ab-4052-9e44-f678d96bba8b/index.html#notes-on-macbook-air",
    "href": "posts/2b133d53-19ab-4052-9e44-f678d96bba8b/index.html#notes-on-macbook-air",
    "title": "macbook air usage notes",
    "section": "notes on macbook air",
    "text": "notes on macbook air\nthis damn thing sucks, in every aspect. i am getting tired of it."
  },
  {
    "objectID": "posts/2b133d53-19ab-4052-9e44-f678d96bba8b/index.html#the-body-position-of-using-this-thing",
    "href": "posts/2b133d53-19ab-4052-9e44-f678d96bba8b/index.html#the-body-position-of-using-this-thing",
    "title": "macbook air usage notes",
    "section": "the body position of using this thing",
    "text": "the body position of using this thing\nraise my legs with multiple pillows, put this thing on my hip and lean on a triangular shaped pile of pillows.\nstill not ideal but pretty close. in order to make this laptop not sliping down my hip i need to fill the gap between laptop and my belly with clothes. need to support my arms with some toys."
  },
  {
    "objectID": "posts/909feffd-54ea-421b-8b50-4ffeb0758d80/index.html",
    "href": "posts/909feffd-54ea-421b-8b50-4ffeb0758d80/index.html",
    "title": "macos cleanup disk and ram",
    "section": "",
    "text": "execute: sudo purge may help with ram issue?"
  },
  {
    "objectID": "posts/0a277e1e-ec84-4391-8fa7-c12821602efd/index.html",
    "href": "posts/0a277e1e-ec84-4391-8fa7-c12821602efd/index.html",
    "title": "make game cheats, buy game cheats, game hacks",
    "section": "",
    "text": "aimbots\ngame hacking is about reverse engineering at some level.\nthings may differ when you want to make cheats using yolov5, but at least, you have to read screen and control mouse/keyboard yes?\nguidedhacking\nphantomoverlay"
  },
  {
    "objectID": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#d-models-live2d-models-and-model-makers",
    "href": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#d-models-live2d-models-and-model-makers",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "3d models, live2d models and model makers",
    "text": "3d models, live2d models and model makers\nmakehuman as model maker\navatar sample e a cute girl\nlive2d models from facerig"
  },
  {
    "objectID": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#blender-adapters",
    "href": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#blender-adapters",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "blender adapters",
    "text": "blender adapters\nblender vrm importer, exporter and utilities\nblender script: vrm to ue4 compatible\nblender’s ‘make it pretty’ button for vrm models\nmakehuman plugin for blender\nblender addon for rhubarb lip sync\nBlendArMocap by cgtinker is a Blender add-on to preform Hand, Face and Pose Detection in Blender using just a Webcam built upon Google’s Mediapipe. The detected data can be easily transferred to rifigy rigs."
  },
  {
    "objectID": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#lipsync-libraries",
    "href": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#lipsync-libraries",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "lipsync libraries",
    "text": "lipsync libraries\nrhubarb lip sync is a command-line tool that automatically creates 2D mouth animation from voice recordings\nwav2lip"
  },
  {
    "objectID": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#mocap-libraries",
    "href": "posts/ac4e3e75-c9bc-483e-9396-bf1408629e63/index.html#mocap-libraries",
    "title": "metahuman makehuman blender lipsync 动捕 视频转动画 人物模型 捏脸 vroid模型 vrm",
    "section": "mocap libraries",
    "text": "mocap libraries\nopenpose is the first real-time multi-person system to jointly detect human body, hand, facial, and foot key-points\nFrankMocap A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator\nEasyMocap is an open-source toolbox for markerless human motion capture.\nfreemocap and its FAQ wiki\nFreeMoCap on pre-recorded videos:\nStart the RunMe() pipeline at Stage 2, and specify the folder containing the videos you wish to process.\nPARE: Part Attention Regressor for 3D Human Body Estimation\nopenseeface: face landmark tracking"
  },
  {
    "objectID": "posts/d72beec2-cc08-4998-b815-f79c8401466b/index.html#mindsdb",
    "href": "posts/d72beec2-cc08-4998-b815-f79c8401466b/index.html#mindsdb",
    "title": "mindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series",
    "section": "MindsDB",
    "text": "MindsDB\ndocumentation\ncloud mindsdb editor\nwarning: this thing could break your dependencies. better use docker instead.\ndocker pull mindsdb/mindsdb\n# pip3 install mindsdb"
  },
  {
    "objectID": "posts/d72beec2-cc08-4998-b815-f79c8401466b/index.html#hmmlearn-unsupervised",
    "href": "posts/d72beec2-cc08-4998-b815-f79c8401466b/index.html#hmmlearn-unsupervised",
    "title": "mindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series",
    "section": "HMMLearn (unsupervised)",
    "text": "HMMLearn (unsupervised)\nmost useful feature:\ntraining and inferring the hidden states"
  },
  {
    "objectID": "posts/d72beec2-cc08-4998-b815-f79c8401466b/index.html#supervised-hmm-learning",
    "href": "posts/d72beec2-cc08-4998-b815-f79c8401466b/index.html#supervised-hmm-learning",
    "title": "mindsdb, in-database machine learning, hidden markov model for time series processing, output a label as such for each element in the time series",
    "section": "supervised hmm learning",
    "text": "supervised hmm learning\n\nseqlearn\n\n\npomegranate (both supervised and unsupervised)\ndocumentation\nAll models that support labeled data support semi-supervised learning, including naive Bayes classifiers, general Bayes classifiers, and hidden Markov models.\nWhile probability Distributions are frequently used as components of more complex models such as mixtures and hidden Markov models, they can also be used by themselves. Many data science tasks require fitting a distribution to data or generating samples under a distribution. pomegranate has a large library of both univariate and multivariate distributions which can be used with an intuitive interface.\nGeneral Mixture Models (GMMs) are an unsupervised probabilistic model composed of multiple distributions (commonly referred to as components) and corresponding weights. This allows you to model more complex distributions corresponding to a singular underlying phenomena. For a full tutorial on what a mixture model is and how to use them, see the above tutorial.\nHidden Markov Models\nBayes Classifiers and Naive Bayes\nMarkov Chains\nBayesian Networks\nMarkov Networks"
  },
  {
    "objectID": "posts/26cb109f-bc27-4499-b54f-a74f3ea429fb/index.html",
    "href": "posts/26cb109f-bc27-4499-b54f-a74f3ea429fb/index.html",
    "title": "mirror sites change",
    "section": "",
    "text": "if it only blocks a range of ip, you use proxy to avoid this constraint.\nsome mirror sites serves us poorly and block access from us. we point them out, list alternatives and provide quick fixes.\nthese actions are intentionally done against specific group of people. it does block a whole range of IPs.\nactors:\nhttps://mirrors.aliyun.com\nhttps://mirrors.tuna.tsinghua.edu.cn/\n\nfixes:\ncurrently we use some previously picked up tunnel accounts provided by topsap. may fix this problem?\npython pip:\npip3 config set global.index-url https://mirrors.ustc.edu.cn/pypi/web/simple\ntaobao npm mirror:\nhttp://npm.taobao.org =&gt; http://npmmirror.com\nhttp://registry.npm.taobao.org =&gt; http://registry.npmmirror.com"
  },
  {
    "objectID": "posts/93902e98-2508-4d74-80af-9afb6ecff3ae/index.html",
    "href": "posts/93902e98-2508-4d74-80af-9afb6ecff3ae/index.html",
    "title": "video generation/modification (vfx) from text",
    "section": "",
    "text": "达摩院放出了文本生成视频模型，支持英文输入\nhuggingface space\nmodel weights:\n\n\n\nweight path\nweight size\nmodel name\nauthor\n\n\n\n\ntext-to-video-ms-1.7b\nunknown\nunknown\ndamo-vilab\n\n\nmodelscope-damo-text-to-video-synthesis\nunknown\nunknown\ndamo-vilab\n\n\ntext-to-video-ms-1.7b-legacy\nunknown\nunknown\ndamo-vilab\n\n\n\ncan also use from modelscope:\nfrom modelscope.pipelines import pipeline\nfrom modelscope.utils.constant import Tasks\np = pipeline('text-to-video-synthesis', 'damo/text-to-video-synthesis')\n\nPAIR now releases Text2Video-Zero which leverages existing stable diffusion models to generate video. also released a bunch of controlnet dreambooth weights.\n\nlucidrains is a workaholic on transformer implementations. we should scrape all the repos and index them. there are faster language models to train.\n\nPhenaki Video, which uses Mask GIT to produce text guided videos of up to 2 minutes in length, in Pytorch\ndreamix (not open-source)\ninstruct-pix2pix requires 16GB+ VRAM\ntext2live modify video by text prompt (such as add fire in mouth)\nrecurrent-interface-network-pytorch using diffusion to generate images and video\nhigh quality! imagegen-video code with demo and paper\n抄视频 视频的时间要讲究 看看是抄一年前的好还是抄刚刚发布的好\n在发布的一个视频当中 最多抄某个作者的两三个符合要求的片段\nuse editly smooth/slick transitions and subtitles to beat the copy-detection algorithm, also consider color change in ffmpeg\n动态 专栏也可以抄\nmake-a-video\n谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 https://www.kuxai.com/article/398"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#use-cases",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#use-cases",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "use cases",
    "text": "use cases\nto detect hard-coded subtitles, crop the region and detect sudden changes\ncan also use pyscenedetect to do the job"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#pyav",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#pyav",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "pyav",
    "text": "pyav\ndocs\npip3 install av"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#removedetect-silence",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#removedetect-silence",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "remove/detect silence",
    "text": "remove/detect silence\n… silencedetect A-&gt;A Detect silence.\n… silenceremove A-&gt;A Remove silence."
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#frame-interpolate",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#frame-interpolate",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "frame interpolate",
    "text": "frame interpolate\nffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" \\\n-vf \"minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d\" \\\n-r 60 ffmpeg_samoyed.mp4"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#motion-estimation",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#motion-estimation",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "motion estimation",
    "text": "motion estimation\nto get mosaic motion vectors and visualize:\nffmpeg -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\" \\\n-vf \"mestimate=epzs:mb_size=16:search_param=7, codecview=mv=pf+bf+bb\"  \\\nmestimate_output.mp4 -y"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#get-help",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#get-help",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "get help",
    "text": "get help\n\non specific filter:\nffmpeg -h filter=showspectrumpic\n\n\non all filters:\nffmpeg -filters"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#crop-detection-picture-in-picture-pip-detection",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#crop-detection-picture-in-picture-pip-detection",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "crop detection, picture in picture (PIP) detection",
    "text": "crop detection, picture in picture (PIP) detection\nffmpeg -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" \\\n-vf \"mestimate,cropdetect=mode=mvedges,metadata=mode=print\" \\\n-f null -"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#scene-change-detection",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#scene-change-detection",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "scene change detection",
    "text": "scene change detection\nffmpeg -hide_banner -i \"$file\" -an \\\n-filter:v \\\n\"select='gt(scene,0.2)',showinfo\" \\\n-f null \\\n- 2&gt;&1"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#extract-motion-vectors",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#extract-motion-vectors",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "extract motion vectors",
    "text": "extract motion vectors\nffmpeg can produce motion vector estimation but it is not exportable, only for internal use.\nmp4 format provides motion vector information thus maybe we need not to use GPU to get those ‘optical flow’ data.\n\nextract by using ffmpeg apis\nmv-extractor Extract frames and motion vectors from H.264 and MPEG-4 encoded video.\n\n\nextract from mp4 file\nmpegflow for easy extraction of motion vectors stored in video files\nmv-tractus: A simple tool to extract motion vectors from h264 encoded videos."
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#take-screenshot-at-time",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#take-screenshot-at-time",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "take screenshot at time:",
    "text": "take screenshot at time:\nffmpeg -ss 01:10:35 -i invideo.mp4 -vframes 1 -q:v 3 screenshot.jpg"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#video-denoise-filters",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#video-denoise-filters",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "video denoise filters:",
    "text": "video denoise filters:\ndctdnoiz fftdnoiz hqdn3d nlmeans owdenoise removegrain vaguedenoiser nlmeans_opencl yaepblur"
  },
  {
    "objectID": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#super-resolution-resampling",
    "href": "posts/2842d760-78aa-4a8b-8d28-aca75f0d4785/index.html#super-resolution-resampling",
    "title": "motion vector estimation, motion vector export, ffmpeg advanced usage",
    "section": "super-resolution, resampling:",
    "text": "super-resolution, resampling:\n\ndeeplearning model, tensorflow\nenv LD_LIBRARY_PATH=/root/anaconda3/pkgs/cudatoolkit-10.0.130-0/lib/:/root/anaconda3/pkgs/cudnn-7.6.5-cuda10.0_0/lib/:$LD_LIBRARY_PATH \\\nffmpeg -i \"/root/Desktop/works/pyjom/samples/video/LiEIfnsvn.mp4\" \\\n-y -vf \\\n\"sr=dnn_backend=tensorflow:model=./sr/espcn.pb,yaepblur\" \\\nsupertest.mp4\n\n\nuse standard scale method:\nffmpeg -y -i \"/root/Desktop/works/pyjom/tests/random_giphy_gifs/samoyed.gif\"\\\n-vf \"minterpolate,scale=w=iw*2:h=ih*2:flags=lanczos,hqdn3d\" \\\n-r 60 ffmpeg_samoyed.mp4\n\n\noptions:\n‘fast_bilinear’\nSelect fast bilinear scaling algorithm.\n‘bilinear’\nSelect bilinear scaling algorithm.\n‘bicubic’\nSelect bicubic scaling algorithm.\n‘experimental’\nSelect experimental scaling algorithm.\n‘neighbor’\nSelect nearest neighbor rescaling algorithm.\n‘area’\nSelect averaging area rescaling algorithm.\n‘bicublin’\nSelect bicubic scaling algorithm for the luma component, bilinear for chroma components.\n‘gauss’\nSelect Gaussian rescaling algorithm.\n‘sinc’\nSelect sinc rescaling algorithm.\n‘lanczos’\nSelect Lanczos rescaling algorithm. The default width (alpha) is 3 and can be changed by setting param0.\n‘spline’\nSelect natural bicubic spline rescaling algorithm.\n‘print_info’\nEnable printing/debug logging.\n‘accurate_rnd’\nEnable accurate rounding.\n‘full_chroma_int’\nEnable full chroma interpolation.\n‘full_chroma_inp’\nSelect full chroma input.\n‘bitexact’\nEnable bitexact output."
  },
  {
    "objectID": "posts/fdb622fc-b23b-4601-8be2-4708f2d317be/index.html#challenges",
    "href": "posts/fdb622fc-b23b-4601-8be2-4708f2d317be/index.html#challenges",
    "title": "nctf writeups",
    "section": "challenges",
    "text": "challenges\nthe platform\nofficial released source code\nbuuctf online judge\nyou may find many writeups in blog and github for buuctf."
  },
  {
    "objectID": "posts/fdb622fc-b23b-4601-8be2-4708f2d317be/index.html#hints-and-tools",
    "href": "posts/fdb622fc-b23b-4601-8be2-4708f2d317be/index.html#hints-and-tools",
    "title": "nctf writeups",
    "section": "hints and tools",
    "text": "hints and tools\nbinwalk\narr3esty0u github info\nshg-sec\nhack.lu 2022\nayacms rce in nctf 2022? how to identify the cms? and how the fuck did those guys identify the shit from that damn website (bing-upms)?\nanswer: they are both busting common web directories. can be induced by common repo structures.\nbaby-aes for crypto signin?\nzsteg for solving that png problem?\nnormal sql injection, not for denodb\nhuli: interesting blog where denodb 0day came from\nsome z3 code, which does not but angr solved the problem\nfrom z3 import *\ndata1=0x162AEB99F80DD8EF8C82AFADBA2E087A\ndata2=0x47C9F2ACA92F6476BE7F0A6DC89F4305\ndata3=0x33B57575\nanswer=[]\nflag1=[]\nkey=[0x7e,0x1f,0x19,0x75]\nsolver=Solver()\nflag=[Int('flag%d'%i) for i in range(36)]\nfor i in range(16):\nanswer.append((data1&gt;&gt;8*i)&0xff)\nfor i in range(16):\nanswer.append((data2&gt;&gt;8*i)&0xff)\nfor i in range(4):\nanswer.append((data3&gt;&gt;8*i)&0xff)\nprint(answer)\nfor i in range(0,9):\nv3=key[3]\nv4=flag[4*i+3]\nv5=key[0]\nv6=flag[4*i]\nv7=flag[4*i+1]\nv8=key[1]\nv9=flag[4*i+2]\nv10=(v6 + v4) * (key[0] + v3)\nv11=key[2]\nv12 = v3 * (v6 + v7)\nv13 = (v3 + v11) * (v7 - v4)\nv14 = v4 * (v11 - v5)\nv15 = v5 * (v9 + v4)\nsolver.add(v14+v10+v13-v12==answer[4*i])\nsolver.add(v6 * (v8 - v3) + v12==answer[4*i+1])\nsolver.add(v15 + v14==answer[4*i+2])\nsolver.add(v6 * (v8 - v3) + (v8 + v5) * (v9 - v6) + v10 - v15==answer[4*i+3])\nif solver.check()==sat:\nm=solver.model()\nrex = []\nfor i in range(34):\nrex.append(m[flag[i]].as_long())\nprint(rex)\nelse:\nprint(\"n0\")"
  },
  {
    "objectID": "posts/fdb622fc-b23b-4601-8be2-4708f2d317be/index.html#writeups",
    "href": "posts/fdb622fc-b23b-4601-8be2-4708f2d317be/index.html#writeups",
    "title": "nctf writeups",
    "section": "writeups",
    "text": "writeups\nsaying this is complete for 2022 nctf?\narr3ty0u nctf 2022 writeup\nnctf 2019 writeup\ndon’t know when it is, but i remember i have seen this shit: katastros’s nctf writeup\nctfiot chamd5 nctf 2022 writeup\nnctf 2022 official crypto writeup"
  },
  {
    "objectID": "posts/9d48d68f-ceac-4c1b-b28f-f81cd14daf17/index.html",
    "href": "posts/9d48d68f-ceac-4c1b-b28f-f81cd14daf17/index.html",
    "title": "nodejs NODE_PATH for npm global package installation",
    "section": "",
    "text": "when installing global ackages, we do not need to specify NODE_PATH. but it is not configured beforehand thus when you want to import packages from there you will face issue.\nfor zsh/bash/fish:\nexport NODE_PATH=&lt;NODE_PATH&gt;\non windows just use the old school drill (open environment editor)\nchech the exact path of NODE_PATH after invoking npm install -g &lt;package_name&gt;, then check if the installed package exists in that path you guessed.\non termux: /data/data/com.termux/files/usr/lib/node_modules\non kali: /usr/local/lib/node_modules (may be inaccurate)\non macos: /opt/homebrew/lib/node_modules (nodejs installed via brew)"
  },
  {
    "objectID": "posts/1080d3b4-1bee-4060-99ea-573cacff374d/index.html",
    "href": "posts/1080d3b4-1bee-4060-99ea-573cacff374d/index.html",
    "title": "numpy and pandas deduplication",
    "section": "",
    "text": "numpy remove duplicates from array\nprint(np.unique(ar, axis=1))\ndupandas: remove duplicates with custom rules like levenshtein distance, spelling differences and phonetics (fuzzy maching) for english (most likely?)\npip install dupandas\npandas drop_duplicates\ndf.drop_duplicates(subset=['brand', 'style'], keep='last')"
  },
  {
    "objectID": "posts/0f7f8506-82e6-4649-8804-f9df48da97ee/index.html",
    "href": "posts/0f7f8506-82e6-4649-8804-f9df48da97ee/index.html",
    "title": "object tracking, video",
    "section": "",
    "text": "identify the object first, then do tracking.\nif detection overlaps with object, then do not launch new tracking process.\nOpenCV Meanshift Algorithm for Object Tracking\nOpenCV CAMshift Algorithm for Object Tracking\nOpenCV Optical Flow Algorithm for Object Tracking\nOpenCV Object Detection and Tracking"
  },
  {
    "objectID": "posts/8d94f4cd-d5b8-4319-a838-fdc35491066b/index.html#free-sms-receive-platforms",
    "href": "posts/8d94f4cd-d5b8-4319-a838-fdc35491066b/index.html#free-sms-receive-platforms",
    "title": "openai codex chatgpt dalle-2 account registration",
    "section": "free sms receive platforms",
    "text": "free sms receive platforms\n7sim.org multiple phone numbers\nreceivesms.org i have seen soulapp usage with this damn number\nnot work for openai virtual phone numbers"
  },
  {
    "objectID": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html#prerequisites",
    "href": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html#prerequisites",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "prerequisites",
    "text": "prerequisites\nrun these things under virtual machine or docker, with a fixed size mountpoint. keep all ports of your local machine isolated from the agent.\nwhen you need it to process anything, just use the mountpoint as the only data exchange location. do not let anything executable spit out from it. do not run anything generated by it programmatically."
  },
  {
    "objectID": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html#targets",
    "href": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html#targets",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "targets",
    "text": "targets\ncontracts shall be based on crypto exchange. self-contract shall be introduced, and for those don’t do self-contract or external contracts often their currency could inflate.\nself-training: in the form of task & proof\nmulti-agent training: (contract) similar to self-training, with cross-validation"
  },
  {
    "objectID": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html#projects",
    "href": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html#projects",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "projects",
    "text": "projects\nautogpt\nopen-interpreter\ncybergod"
  },
  {
    "objectID": "posts/fbfe0cb3-83eb-43d7-846f-a5777fed31cc/index.html",
    "href": "posts/fbfe0cb3-83eb-43d7-846f-a5777fed31cc/index.html",
    "title": "opencv-python wrappers, without boilerplates",
    "section": "",
    "text": "imutils by pyimagesearch\ncaer do image resizing, image processing, video loading.\ndocumentation here"
  },
  {
    "objectID": "posts/a8e59398-a896-43c4-865a-e00715e50e0e/index.html",
    "href": "posts/a8e59398-a896-43c4-865a-e00715e50e0e/index.html",
    "title": "opentimelineio: unified format for media editors?",
    "section": "",
    "text": "similar language like mine is named as “medialang”, with very stupid syntax (thus might limit expressiveness) and lacks visualization tool.\nit offers many adapters for final cut pro, adobe premiere, kdenlive and more.\nit has simple python interface.\nbut! many adapters are incomplete right now.\nlimited otio mlt adapter"
  },
  {
    "objectID": "posts/762bc162-356a-4aaa-ba14-20e0d6f1735b/index.html#generative",
    "href": "posts/762bc162-356a-4aaa-ba14-20e0d6f1735b/index.html#generative",
    "title": "palette extraction from images 色彩搭配提取",
    "section": "generative",
    "text": "generative\ngenerate palette/color map from matplotlib colormaps"
  },
  {
    "objectID": "posts/762bc162-356a-4aaa-ba14-20e0d6f1735b/index.html#extractive",
    "href": "posts/762bc162-356a-4aaa-ba14-20e0d6f1735b/index.html#extractive",
    "title": "palette extraction from images 色彩搭配提取",
    "section": "extractive",
    "text": "extractive\nhaishoku and tutorial_1 tutorial_2\npip3 install haishoku\nextract the most likely-to-be color for text foreground/background, then match the rest of the color with the colors extracted from image, then decide the color.\npalette Node.js image color palette extraction with node-canvas\npython gvcci color extraction to turn images into 16 color palettes\nquickpalette 🏃‍♀️🎨 R package for quick extraction of color palettes from text(by regex) and images\nnode-vibrant Extract prominent colors from an image, previous as vibrant.js\nColorExtraction Creating a color palette from images in a fun way using CSS Filters and Vibrant.js"
  },
  {
    "objectID": "posts/75fd1bdc-d4f5-43d7-9f20-6a4029f05b18/index.html#process-monitor",
    "href": "posts/75fd1bdc-d4f5-43d7-9f20-6a4029f05b18/index.html#process-monitor",
    "title": "Process Monitoring and Notification Tools: A Comprehensive List",
    "section": "process monitor",
    "text": "process monitor\nhttps://github.com/troglobit/watchdogd\nhttps://github.com/ochinchina/supervisord\nhttps://github.com/codeskyblue/gosuv\nhttps://github.com/Supervisor/superlance\nhttps://github.com/immortal/immortal\nhttps://github.com/catern/supervise\nhttps://github.com/ihaiker/sudis\nhttps://github.com/rahiel/supervisor-alert"
  },
  {
    "objectID": "posts/75fd1bdc-d4f5-43d7-9f20-6a4029f05b18/index.html#notification-pusher",
    "href": "posts/75fd1bdc-d4f5-43d7-9f20-6a4029f05b18/index.html#notification-pusher",
    "title": "Process Monitoring and Notification Tools: A Comprehensive List",
    "section": "notification pusher",
    "text": "notification pusher\nhttps://github.com/Nickersoft/push.js\nhttps://github.com/caronc/apprise\nhttps://github.com/Thibauth/python-pushover\nhttps://github.com/liiight/notifiers\nhttps://github.com/YuriyLisovskiy/pynotifier\nhttps://github.com/SeTeM/pync"
  },
  {
    "objectID": "posts/75fd1bdc-d4f5-43d7-9f20-6a4029f05b18/index.html#dashboard",
    "href": "posts/75fd1bdc-d4f5-43d7-9f20-6a4029f05b18/index.html#dashboard",
    "title": "Process Monitoring and Notification Tools: A Comprehensive List",
    "section": "dashboard",
    "text": "dashboard\nhttps://github.com/Reportr/dashboard\nhttps://github.com/d2-projects/d2-admin\nhttps://github.com/gizak/termui\nhttps://github.com/plotly/dash\nhttps://github.com/Parallels/rq-dashboard"
  },
  {
    "objectID": "posts/4d2a5ef4-ee90-435d-87e1-b8d994f27fd8/index.html",
    "href": "posts/4d2a5ef4-ee90-435d-87e1-b8d994f27fd8/index.html",
    "title": "popular ai competition platforms (may with notebook support)",
    "section": "",
    "text": "i’ve seen these platforms from a personal competition solution collection\n阿里天池\ndatafountain\n和鲸社区\nkaggle\naistudio"
  },
  {
    "objectID": "posts/480302ef-ba42-4b8c-9482-189ff7d89a71/index.html",
    "href": "posts/480302ef-ba42-4b8c-9482-189ff7d89a71/index.html",
    "title": "pwntools usage example",
    "section": "",
    "text": "I created a script for solving a simple problem on RCTF.\nfrom pwn import *\nip = \"190.92.234.114\"\nport = 23334\nmclean =lambda l0: l0.decode().split(\"=\")[1].strip()\nmlist = lambda T: [int(x) for x in T.replace(\"[\",\"\").replace(\"]\", \"\").replace(\" \",\"\").strip().split(\",\")]\nr = remote(ip, port)\nl0 = r.recvline()\n# print('first line?', l0) # great man!\nq = mclean(l0)\nq = int(q)\n# but notice you will not like to be fucked up. use safe eval? ast?\nl1 = r.recvline()\n# print('second line?', l1)\nT = mclean(l1)\nT = mlist(T)\nl2 = r.recvline()\nU = mlist(mclean(l2))\n# print(\"third line?\", l2)\nprint(\"Q?\", q)\nprint()\nprint(\"T?\", len(T))\nprint()\nprint(\"U?\", len(U))\n# now crack the x. please observe the original code?\n# the shift does not matter so much?\nmpos_x = {}\nfor i in range(90):\nt = T[i]\nu = U[i]\npos_x = u//t+1\nmpos_x.update({pos_x:mpos_x.get(pos_x,0)+1})\nmfinalPos = [(key, elem) for key, elem in mpos_x.items()]\nmfinalPos.sort(key=lambda x: -x[1])\nprint(\"NUM?\",mfinalPos[0])\nprint(\"COUNT?\",mfinalPos[0][1])\n# import pyperclip\ndata =str(mfinalPos[0][0])\n# pyperclip.copy(data)\n# r.interactive()\nr.sendline(data.encode())\nflag=r.recvline() #EOFERROR?\nprint(\"FLAG?\",flag)\n# now answer the shit?"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#整活",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#整活",
    "title": "pyjom schedules",
    "section": "整活",
    "text": "整活\n\n应 急 诈 骗 食 品 (派蒙加Rick Ashley 如何混合？）"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#recommendation",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#recommendation",
    "title": "pyjom schedules",
    "section": "recommendation",
    "text": "recommendation\n\nuse txtai to do NLU and recommend things to people"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#topic-discoveryacquiring",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#topic-discoveryacquiring",
    "title": "pyjom schedules",
    "section": "topic discovery/acquiring",
    "text": "topic discovery/acquiring\n\ntrending topics\n\nbaidu search trending\nsogou trending\nbilibili trending\nwechat trending\ntoutiao trending\ntencent trending\nnetease trending\nyoutube trending\nreddit trending\ntwitch trending\n\n\n\npopular topics\n\nbaijiahao popular topics\nbilibili popular topics\ndouyin popular topics\n\n\n\npersonal/customized topics\n\ntencent qq customized (can associate with mail)\nwechat customized\nbilibili per user customized"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#dogcat-video-generation",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#dogcat-video-generation",
    "title": "pyjom schedules",
    "section": "dog/cat video generation",
    "text": "dog/cat video generation\n\nmake render engine runnable\nissues:\n\nvideo length too long (10 mins)\n\nit was the speed calculation error.\n\nbgm somehow not in sync (too broad bpm/clip ranges?)\nto analyze the peaks (abrupt changes) in bgm and grab louder peaks using pyloudnorm (getting audio volume)\n\npip3 install pyloudnorm\nimport soundfile as sf\nimport pyloudnorm as pyln\ndata, rate = sf.read(\"0055014.wav\") # load audio (with shape (samples, channels))\nprint(data.shape)\nmeter = pyln.Meter(rate) # create BS.1770 meter\nloudness = meter.integrated_loudness(data) # measure loudness\nprint(loudness)\n\nplace video on loudest points, abrupt changes detected by talib or just take direvative and gaussian average\nvideo too repetitive (small corpus?)\ndo not remove subtitle and crop active region (reviewer’s resource not used? but i rather advise you to do it directly since it requires less computational power)\ndo not have minimum motion threshold (reviewer’s fault? also recommend you to do this in producer)\n\n\n\nremove all watermarks, subtitles and crop video boundaries accordingly\nsource video and audio (infinite, basic test is to find 500 sources at once without duplicate, second test is to find 500 second is to find 500 without duplicate twice), improve highlight algorithm\nfind 500 songs without duplicate at once\nfind 500 songs no duplicate twice\nfind 500 animal videos without duplicate\nfind 500 animal videos no duplicate twice\ngenerate appropriate title, cover, info and tags\ncollect feedback after the post\nfind some shocking fonts for cover and subtitle, english and chinese\nmake that karaoke effect\nmake ass with karaoke effect with lrc files\nmake lyrics sync logic fluent, according to what have learned from karaoke effects\nmake selected video clips fluent, no abrupt cuts, maybe we need pyscenedetect?"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#text-to-video-template-based-video-generator-this-is-perhaps-the-most-complex-video-generator-ever.-do-it-with-caution-it-might-also-includes-the-flipcard-narrator-and-slideshow-based-generators",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#text-to-video-template-based-video-generator-this-is-perhaps-the-most-complex-video-generator-ever.-do-it-with-caution-it-might-also-includes-the-flipcard-narrator-and-slideshow-based-generators",
    "title": "pyjom schedules",
    "section": "text to video, template based video generator (this is perhaps the most complex video generator ever. do it with caution, it might also includes the flipcard, narrator and slideshow based generators)",
    "text": "text to video, template based video generator (this is perhaps the most complex video generator ever. do it with caution, it might also includes the flipcard, narrator and slideshow based generators)\n\ngenerator models subarchitecture (subcategories of template based generators)\n\nflipcard\n\n\nslideshow (video and audio, might also include the dog&cat video!)\n\n\nnarrator\n\n\nsummarized video\n\n\n\n\npolicy evasion, NSFW filters\n\nremove all hints from image, video, audio and script that may lead to copyright issues\n\n\n\n\nanalyze the media content and metadata, relationships\n\nanalyze danmaku\nparaphrase the script\ncut the crap and understand each clip’s meaning\n\n\n\n\nprocess the video clips, like changing the human figure, changing face, stylish the video, adding 2d to 3d effects\n\n\n\nprocess the audio clips, like changing voice, adding sound effects, separating audio/music tracks, ducking\n\n\n\nindex, retrieve and align video and audio content according to our collected database\n\n\n\nretrieve and align video and audio according to our smart search agent (keyword extractor, related words) and do live compilation"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#qq-managing",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#qq-managing",
    "title": "pyjom schedules",
    "section": "qq managing",
    "text": "qq managing\n\nmitm chats in friends\nmitm chats in groups\nsource and send pictures to qzone\nsource and send pictures to chat\nreduce posting frequency by group size and feedback\npost relative video link relative to group topic"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#personal-info-collecting-and-emailsms-bulk-sending",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#personal-info-collecting-and-emailsms-bulk-sending",
    "title": "pyjom schedules",
    "section": "personal info collecting and email/sms bulk sending",
    "text": "personal info collecting and email/sms bulk sending\n\navoid mail being trashed or turned into junk\ncollect and make mail templates for mail posting"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#voice-changer",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#voice-changer",
    "title": "pyjom schedules",
    "section": "voice changer",
    "text": "voice changer\n\nvst based voice changer\ntrain or find a decent voice generator 御姐音语料库 小受音语料库\n\n请在b站或者qq群里面寻找 或者什么其他的有关的地方寻找 谢谢"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#直播-live-streaming",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html#直播-live-streaming",
    "title": "pyjom schedules",
    "section": "直播 live streaming",
    "text": "直播 live streaming\n\nsource the video\n\n如果是同一个站的 尽量放一个月以前的视频 半个月以前的音频\n\nprepare some space for storing live streaming data\nsource the audio\nautomatic interactions\nhandle the vtuber model’s actions"
  },
  {
    "objectID": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#dynamically-wait-and-reload-the-python-code-from-disk-when-runtime-exception-occurs",
    "href": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#dynamically-wait-and-reload-the-python-code-from-disk-when-runtime-exception-occurs",
    "title": "pyro audio segmentation and classification",
    "section": "dynamically wait and reload the python code from disk when runtime exception occurs",
    "text": "dynamically wait and reload the python code from disk when runtime exception occurs\nOne way to achieve this is to use the importlib module to dynamically reload a module at runtime. Here’s an example of how you can do this:\nimport importlib\ndef reload_module(module_name: str) -&gt; None:\nimportlib.reload(module_name)\n# Example usage\ntry:\nreload_module(\"my_module\")\nexcept Exception as e:\nprint(f\"Exception occurred: {e}\")\nThis will reload the module with the given name at runtime, and if an exception occurs during the reloading process, it will be caught and handled by the except block.\nNote that this approach will only work if the module has been imported at least once before, as the importlib.reload() function can only reload modules that are already imported into the current Python environment. If the module has not been imported yet, you will need to use the importlib.import_module() function to import it first.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#optimize-gpt2-output-with-human-feedback",
    "href": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#optimize-gpt2-output-with-human-feedback",
    "title": "pyro audio segmentation and classification",
    "section": "optimize GPT2 output with human feedback",
    "text": "optimize GPT2 output with human feedback\nThere are a few ways you can optimize the output of a GPT-2 model with human feedback. Here are a few options you might consider:\nFine-tuning: One way to optimize the output of a GPT-2 model is to fine-tune it on a specific task or domain using human-labeled data. This involves training the model on a dataset of human-generated text, such as a collection of articles or a corpus of conversational transcripts. Fine-tuning the model can help it learn to produce output that is more relevant and appropriate for the specific task or domain you are interested in.\nEvaluating and adjusting model hyperparameters: Another way to optimize the output of a GPT-2 model is to experiment with different model hyperparameters, such as the learning rate, batch size, and number of layers. You can use human feedback to evaluate the quality of the model’s output and adjust these hyperparameters accordingly to improve performance.\nUsing human feedback to guide model training: In addition to using human feedback to evaluate the model’s output, you can also use it to guide the training process itself. For example, you can use human feedback to identify specific examples or categories of output that the model is struggling with, and then use these examples to create a targeted training dataset for the model. This can help the model learn to produce more accurate and appropriate output for these specific cases.\nI hope these suggestions are helpful! Let me know if you have any questions."
  },
  {
    "objectID": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#train-gpt2-model-to-operate-with-terminal",
    "href": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#train-gpt2-model-to-operate-with-terminal",
    "title": "pyro audio segmentation and classification",
    "section": "train GPT2 model to operate with terminal",
    "text": "train GPT2 model to operate with terminal\nTo train a GPT-2 model to operate with the terminal, you will need to do the following:\nCollect a dataset of terminal commands and their associated outputs. This dataset will be used to train the GPT-2 model.\nPreprocess the dataset by tokenizing the commands and outputs and creating input-output pairs for training the model.\nTrain the GPT-2 model using the preprocessed dataset. This can be done using the openai/gpt-2 repository on GitHub, which contains the necessary code and instructions for training the model.\nEvaluate the performance of the trained model on a separate test dataset of terminal commands and outputs to ensure that it is able to accurately predict the outputs for a given set of commands.\nIf the model’s performance is not satisfactory, you may need to fine-tune it further by adjusting the training hyperparameters or collecting more data for training.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#what-can-pyro-do",
    "href": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#what-can-pyro-do",
    "title": "pyro audio segmentation and classification",
    "section": "what can pyro do",
    "text": "what can pyro do\nPyro is a probabilistic programming language developed by Uber for use in Bayesian machine learning. It allows users to build complex models using simple, high-level abstractions, and provides a suite of tools for working with probability distributions and performing Bayesian inference.\nSome of the key features of Pyro include:\nSupport for a wide range of probability distributions, including continuous and discrete distributions, as well as a variety of common compound distributions such as mixtures and convolutions.\nA flexible model construction API that allows users to define complex models using simple, high-level abstractions.\nAutomatic differentiation and gradient-based optimization algorithms for efficient training of probabilistic models.\nAlgorithms for performing approximate Bayesian inference, including Markov chain Monte Carlo (MCMC) and variational inference (VI).\nSupport for parallelization and distributed computing, allowing users to scale their models and inference algorithms to large datasets.\nOverall, Pyro is a powerful tool for building and training probabilistic models for machine learning tasks, and is well-suited for a wide range of applications in areas such as natural language processing, computer vision, and time series analysis."
  },
  {
    "objectID": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#segment-audio-and-classify-audio-with-pyro",
    "href": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#segment-audio-and-classify-audio-with-pyro",
    "title": "pyro audio segmentation and classification",
    "section": "segment audio and classify audio with pyro",
    "text": "segment audio and classify audio with pyro\nTo segment and classify audio using Pyro, you will need to first build a probabilistic model that can process the audio data and make predictions about the segments and class labels. Here are the general steps you can follow:\nPreprocess the audio data by converting it to a suitable format for use in the model (e.g., a spectrogram or other feature representation).\nDefine a probabilistic model in Pyro that takes the audio data as input and makes predictions about the segment boundaries and class labels. This model will likely include a number of latent variables (i.e., variables that are not directly observed, but are inferred from the data) that represent the underlying structure of the audio data.\nUse Pyro’s automatic differentiation and gradient-based optimization algorithms to train the model on a dataset of labeled audio segments. This will involve defining a loss function that measures the model’s performance on the training data and adjusting the model parameters to minimize the loss.\nUse the trained model to make predictions on new audio data by performing inference using one of Pyro’s approximate inference algorithms, such as Markov chain Monte Carlo (MCMC) or variational inference (VI).\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#demonstrate-the-process-with-code",
    "href": "posts/563f6a50-9ae7-4317-9393-0239d30ad2a9/index.html#demonstrate-the-process-with-code",
    "title": "pyro audio segmentation and classification",
    "section": "demonstrate the process with code",
    "text": "demonstrate the process with code\nSure! Here is an example of how you might build a probabilistic model in Pyro to segment and classify audio data. This example assumes that you have already preprocessed the audio data and converted it to a suitable format (e.g., a spectrogram) for use in the model.\nimport pyro\nimport torch\n# Define the number of classes and the size of the input data\nnum_classes = 10\ninput_size = (batch_size, num_features)\n# Define the model using Pyro's primitive distributions\ndef audio_classifier(x):\n# Define the latent variables for the segment boundaries and class labels\nsegment_boundaries = pyro.sample(\"segment_boundaries\", pyro.distributions.Uniform(0, 1))\nclass_labels = pyro.sample(\"class_labels\", pyro.distributions.Categorical(torch.ones(num_classes)/num_classes))\n# Use the latent variables to define the likelihood of the data\nlikelihood = pyro.sample(\"likelihood\", pyro.distributions.Normal(segment_boundaries, class_labels), obs=x)\nreturn likelihood\n# Define the optimizer and the loss function\noptimizer = torch.optim.Adam(audio_classifier.parameters(), lr=0.01)\nloss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n# Loop over the training data and update the model parameters\nfor x, y in training_data:\n# Clear the gradients\noptimizer.zero_grad()\n# Compute the loss\nloss = loss_fn(audio_classifier, x, y)\n# Backpropagate the loss and update the model parameters\nloss.backward()\noptimizer.step()\nThis model defines two latent variables: segment_boundaries, which represents the boundaries between different audio segments, and class_labels, which represents the class labels for each segment. The model then uses these latent variables to define the likelihood of the data (i.e., the probability of observing the audio data given the latent variables).\nTo perform inference with this model, you can use one of Pyro’s approximate inference algorithms, such as Markov chain Monte Carlo (MCMC) or variational inference (VI). For example, to perform MCMC inference, you can use the pyro.infer.MCMC class as follows:\n# Define the MCMC sampler\nmcmc = pyro.infer.MCMC(kernel=pyro.infer.NUTS(audio_classifier), num_samples=1000, warmup_steps=100)\n# Run the sampler\nmcmc.run(x)\n# Extract the samples\nsamples = mcmc.get_samples()\n# Use the samples to estimate the posterior distribution of the latent variables\nsegment_boundaries_posterior = samples[\"segment_boundaries\"]\nclass_labels_posterior = samples[\"class_labels\"]\nI hope this example helps to illustrate the process of building and using a probabilistic model for audio segmentation and classification with Pyro. Let me know if you have any questions!"
  },
  {
    "objectID": "posts/2325b342-1a2d-4d11-a5f6-df35c62f65a9/index.html",
    "href": "posts/2325b342-1a2d-4d11-a5f6-df35c62f65a9/index.html",
    "title": "python encoding issue",
    "section": "",
    "text": "windows has encoding issue on python intepreter.\nrun like this:\npython -X utf8=1 &lt;args&gt;\n# flag: sys.flags.utf8_mode"
  },
  {
    "objectID": "posts/298068ec-fe34-44a4-84e1-439cdb04efa0/index.html",
    "href": "posts/298068ec-fe34-44a4-84e1-439cdb04efa0/index.html",
    "title": "pyttsx3 cross platform tts generator",
    "section": "",
    "text": "By looking into the NaturalLanguage Framework on macOS, I find text classifier and embeddings inside.\nIt will leverage default TTS engine on Windows and macOS, but for linux you must install espeak.\nimport pyttsx3\nengine = pyttsx3.init()\n# dir(engine.getProperty(\"voices\")[0]) -&gt; ['age', 'gender', 'id', 'languages', 'name']\n# The voices are related to languages. Set it properly.\n# you want \"en_US\" and \"zh_CN\"\n# [['en_US'], ['it_IT'], ['sv_SE'], ['fr_CA'], ['de_DE'], ['he_IL'], ['id_ID'], ['en_GB'], ['es_AR'], ['nl_BE'], ['en-scotland'], ['en_US'], ['ro_RO'], ['pt_PT'], ['es_ES'], ['es_MX'], ['th_TH'], ['en_AU'], ['ja_JP'], ['sk_SK'], ['hi_IN'], ['it_IT'], ['pt_BR'], ['ar_SA'], ['hu_HU'], ['zh_TW'], ['el_GR'], ['ru_RU'], ['en_IE'], ['es_ES'], ['nb_NO'], ['es_MX'], ['en_IN'], ['en_US'], ['da_DK'], ['fi_FI'], ['zh_HK'], ['en_ZA'], ['fr_FR'], ['zh_CN'], ['en_IN'], ['en_US'], ['nl_NL'], ['tr_TR'], ['ko_KR'], ['ru_RU'], ['pl_PL'], ['cs_CZ']]\nengine.setProperty('voice', engine.getProperty(\"voices\")[39].id)\nengine.save_to_file(\"你好 世界\", 'output.wav')\nengine.runAndWait()\nengine.setProperty('rate', 125) # setting up new voice rate\n# The punctuals make the bot to pause for some time. Maybe you should control that yourself.\nengine.save_to_file(\"你好，世界\", 'output.wav')\nengine.runAndWait()"
  },
  {
    "objectID": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#数据来源",
    "href": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#数据来源",
    "title": "quantatitive financial stock market analysis",
    "section": "数据来源",
    "text": "数据来源\npandas_datareader by yahoo 是国外股票的数据\ntushare 国内股票数据"
  },
  {
    "objectID": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#模型建立",
    "href": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#模型建立",
    "title": "quantatitive financial stock market analysis",
    "section": "模型建立",
    "text": "模型建立\nopen source code for economics modeling in python/julia\npandas pipe for streamline processing of real time data\ntime series forcast\n有类似的软件 我下载到windows上面过 (agent based simulation/agent based modeling) called altreva adaptive modeler\nfms\n还原持仓的对象 每一个账户都要详细分析 分析每个账户什么时候买入 卖出 还有不买入 不卖出 观望的那些人 所有人都要还原"
  },
  {
    "objectID": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#实盘接口",
    "href": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#实盘接口",
    "title": "quantatitive financial stock market analysis",
    "section": "实盘接口",
    "text": "实盘接口\ntools for high frequency trading low latency trading tool\n高频交易工具 低延迟交易工具\n要抢涨停板 网络必须要好 下单速度要快\njoinquant\neasytrader\n实盘易 支持多个客户端 服务端要钱的 sdk都是服务端的client"
  },
  {
    "objectID": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#tools",
    "href": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#tools",
    "title": "quantatitive financial stock market analysis",
    "section": "tools",
    "text": "tools\nmytt 通达信公式转换器\nfuncat 通达信公式转换器"
  },
  {
    "objectID": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#models-and-frameworks",
    "href": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html#models-and-frameworks",
    "title": "quantatitive financial stock market analysis",
    "section": "models and frameworks",
    "text": "models and frameworks\ngeneral reinforcement learning:\nhttps://github.com/DLR-RM/stable-baselines3\ncrypto trading bot, support all crypto trading markets:\nhttps://github.com/freqtrade/freqtrade\nqlib by microsoft, quantatitive financial analysis:\nhttps://github.com/microsoft/qlib\nreinforcement financial deep learning package:\nhttps://github.com/AI4Finance-Foundation/FinRL\nopenbb_terminal:\nhttps://github.com/OpenBB-finance/OpenBBTerminal\nzipline\nhttps://github.com/quantopian/zipline\npyalgotrade\nhttps://github.com/gbeced/pyalgotrade\nquantaxis:\nhttps://github.com/yutiansut/QUANTAXIS\nvn.py:\nhttps://github.com/vnpy/vnpy\nhttps://www.vnpy.com/docs/\ntalib:\nhttps://github.com/mrjbq7/ta-lib\nhttps://www.programcreek.com/python/example/92322/talib.EMA?msclkid=425d0f6cb5dd11ec9da2a03aa72194cd\nsuperalgos:\nhttps://github.com/Superalgos/Superalgos\nhttps://superalgos.org"
  },
  {
    "objectID": "posts/4f343aea-d7b4-401c-b701-26253e3bb46b/index.html#linux",
    "href": "posts/4f343aea-d7b4-401c-b701-26253e3bb46b/index.html#linux",
    "title": "ramfs on macos, linux and windows",
    "section": "linux",
    "text": "linux\nsimply use /dev/shm\nthe only difference is that ramfs on linux is unbounded while tmpfs is bounded\ncreate bounded tmpfs:\nmount -t tmpfs -o size=2g tmpfs /mnt/tmp\nor yoy labor yourself to mount some additional ramfs:\nmount -t ramfs -o size=2g ramfs /mnt/tmp"
  },
  {
    "objectID": "posts/4f343aea-d7b4-401c-b701-26253e3bb46b/index.html#macos",
    "href": "posts/4f343aea-d7b4-401c-b701-26253e3bb46b/index.html#macos",
    "title": "ramfs on macos, linux and windows",
    "section": "macos",
    "text": "macos\n/private/tmp is not ramdisk. it is just a directory cleared by startup.\nram-shell: A simple script to create a in-memory filesystem on macOS\nRAM-backed filesystem mounter for Mac OS X\ncreate and mount ramdisk:\n#!/bin/sh\nramfs_size_mb=2100\nmount_point=/tmp/rdisk\nmkramdisk() {\nramfs_size_sectors=$((${ramfs_size_mb}*1024*1024/512))\nramdisk_dev=`hdid -nomount ram://${ramfs_size_sectors}`\nnewfs_hfs -v 'ram disk' ${ramdisk_dev}\nmkdir -p ${mount_point}\nmount -o noatime -t hfs ${ramdisk_dev} ${mount_point}\necho \"remove with:\"\necho \"umount ${mount_point}\"\necho \"diskutil eject ${ramdisk_dev}\"\n}\nto replace /private/tmp with ramfs and registered as launchd service\ncalculate sector numbers by hand:\ndisk_size(MiB)* 1024KiB/MiB * 1024B/KiB / 512B/sector = #sectors\nhdiutil attach -nomount ram://#sectors\n#get returned value afterwards!\nnewfs_hfs -v 'Ramdisk' &lt;returned_disk_device_id&gt;\n# maybe you should create apfs case sensitive instead?\n#mount disk\nmkdir -p ~/Ramdisk\n# may change fs type accordingly when using apfs\nmount -o noatime -t hfs &lt;returned_disk_device_id&gt; ~/Ramdisk"
  },
  {
    "objectID": "posts/4f343aea-d7b4-401c-b701-26253e3bb46b/index.html#windows",
    "href": "posts/4f343aea-d7b4-401c-b701-26253e3bb46b/index.html#windows",
    "title": "ramfs on macos, linux and windows",
    "section": "windows",
    "text": "windows\na curated ramdisk software list\nuse third-party ramdisk tool like imdisk, eram with kernel driver installed, secure boot disabled (no uefi maybe?)"
  },
  {
    "objectID": "posts/8d61fc58-e855-4fe0-ade9-be7fdcb60af0/index.html#package-managers",
    "href": "posts/8d61fc58-e855-4fe0-ade9-be7fdcb60af0/index.html#package-managers",
    "title": "rare package managers, alternative jvm languages and java study hints",
    "section": "package managers",
    "text": "package managers\n\nc, c++\nconan\nclibs\nvcpkg\n\n\nlisp\nCLPM powered by quicklisp"
  },
  {
    "objectID": "posts/8d61fc58-e855-4fe0-ade9-be7fdcb60af0/index.html#jvm-alternative-languages",
    "href": "posts/8d61fc58-e855-4fe0-ade9-be7fdcb60af0/index.html#jvm-alternative-languages",
    "title": "rare package managers, alternative jvm languages and java study hints",
    "section": "jvm alternative languages",
    "text": "jvm alternative languages\noracle’s blog on jvm languages showing advantages\nRingoJS\nKotlin\nScala\nGroovy\nClojure\nFantom\nCeylon\nJython\nJRuby\nFrege haskell on jvm\nXtend\nGolo\nConcurnaas\nYeti\nGraalVM uses polyglot to bridge with other languages"
  },
  {
    "objectID": "posts/8d61fc58-e855-4fe0-ade9-be7fdcb60af0/index.html#java-hints",
    "href": "posts/8d61fc58-e855-4fe0-ade9-be7fdcb60af0/index.html#java-hints",
    "title": "rare package managers, alternative jvm languages and java study hints",
    "section": "java hints",
    "text": "java hints\njavac doc\njshell\nnashorn js engine run it with jjs"
  },
  {
    "objectID": "posts/d260e588-b839-4298-a111-23740b0c6ae4/index.html#proxy-service",
    "href": "posts/d260e588-b839-4298-a111-23740b0c6ae4/index.html#proxy-service",
    "title": "recaptcha solving, proxy providers",
    "section": "proxy service",
    "text": "proxy service\nproxy-cheap"
  },
  {
    "objectID": "posts/d260e588-b839-4298-a111-23740b0c6ae4/index.html#recaptcha-solving-service",
    "href": "posts/d260e588-b839-4298-a111-23740b0c6ae4/index.html#recaptcha-solving-service",
    "title": "recaptcha solving, proxy providers",
    "section": "recaptcha solving service",
    "text": "recaptcha solving service\n\nfree libraries\nbotright can solve recaptcha, hcaptcha, geetest. it shall be used with playwright. doc\n\n\npaid services\nanycaptcha.com is an AI captcha solving service"
  },
  {
    "objectID": "posts/e4f00cf1-58b3-4f10-877a-ad333964376d/index.html",
    "href": "posts/e4f00cf1-58b3-4f10-877a-ad333964376d/index.html",
    "title": "rectangle packing, polygon to rectangle decomposition",
    "section": "",
    "text": "rectangle packing, polygon to rectangle decomposition"
  },
  {
    "objectID": "posts/08f3ffb0-7168-44c7-b57f-a211c8218085/index.html#windows",
    "href": "posts/08f3ffb0-7168-44c7-b57f-a211c8218085/index.html#windows",
    "title": "recycle bin, trash can cli alternative",
    "section": "windows",
    "text": "windows\ncmdutils which has recycle and bin commands\ncmd-recycle\nnircmd\nnircmd moverecyclebin *.tmp"
  },
  {
    "objectID": "posts/08f3ffb0-7168-44c7-b57f-a211c8218085/index.html#macos",
    "href": "posts/08f3ffb0-7168-44c7-b57f-a211c8218085/index.html#macos",
    "title": "recycle bin, trash can cli alternative",
    "section": "macos",
    "text": "macos\ndo this manually:\n# i don't trust this.\n#rm -rf ~/.Trash/*\nosascript -e 'tell app \"Finder\" to empty'\ntrash\nrmtrash in nightproductions’s cli tools"
  },
  {
    "objectID": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html#reset-usb.sh",
    "href": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html#reset-usb.sh",
    "title": "reset usb",
    "section": "reset-usb.sh",
    "text": "reset-usb.sh\n#!/bin/bash\nreset-ahci-controllers.sh\nreset-xhci-controllers.sh"
  },
  {
    "objectID": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html#reset-ahci-controllers.sh",
    "href": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html#reset-ahci-controllers.sh",
    "title": "reset usb",
    "section": "reset-ahci-controllers.sh",
    "text": "reset-ahci-controllers.sh\n#!/bin/bash\n# this freaking works.\n# Script to reset all local xHCI (USB) controllers\n# Based on: http://billauer.co.il/blog/2013/02/usb-reset-ehci-uhci-linux/\nif [[ ${EUID} != 0 ]]; then\necho This must be run as root!\nexit 1\nfi\nfor xhci in /sys/bus/pci/drivers/ahci; do\nif ! cd ${xhci}; then\necho \"Weird error. Failed to change directory to ${xhci}.\"\nexit 1\nfi\necho \"Resetting devices from ${xhci}...\"\nfor i in ????:??:??.?; do\necho -n \"${i}\" &gt; unbind\necho -n \"${i}\" &gt; bind\ndone\ndone"
  },
  {
    "objectID": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html#reset-xhci-controllers.sh",
    "href": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html#reset-xhci-controllers.sh",
    "title": "reset usb",
    "section": "reset-xhci-controllers.sh",
    "text": "reset-xhci-controllers.sh\n#!/bin/bash\n# this freaking works.\n# Script to reset all local xHCI (USB) controllers\n# Based on: http://billauer.co.il/blog/2013/02/usb-reset-ehci-uhci-linux/\nif [[ ${EUID} != 0 ]]; then\necho This must be run as root!\nexit 1\nfi\nfor xhci in /sys/bus/pci/drivers/?hci_hcd; do\nif ! cd ${xhci}; then\necho \"Weird error. Failed to change directory to ${xhci}.\"\nexit 1\nfi\necho \"Resetting devices from ${xhci}...\"\nfor i in ????:??:??.?; do\necho -n \"${i}\" &gt; unbind\necho -n \"${i}\" &gt; bind\ndone\ndone"
  },
  {
    "objectID": "posts/c69512a3-e382-4ae7-ac79-6f927d4885a8/index.html#linux",
    "href": "posts/c69512a3-e382-4ae7-ac79-6f927d4885a8/index.html#linux",
    "title": "resource utilization monitor tool",
    "section": "linux",
    "text": "linux\nhtop for ram and processes. s-tui for cpu/gpu temperatures"
  },
  {
    "objectID": "posts/1300032f-7668-4190-8172-c2aba3659c68/index.html",
    "href": "posts/1300032f-7668-4190-8172-c2aba3659c68/index.html",
    "title": "elinks/lynx with python: how to speed up headless website browsing/parsing/scraping with cookies",
    "section": "",
    "text": "newscrawl 狠心开源企业级舆情新闻爬虫项目：支持任意数量爬虫一键运行、爬虫定时任务、爬虫批量删除；爬虫一键部署；爬虫监控可视化; 配置集群爬虫分配策略；👉 现成的docker一键部署文档已为大家踩坑\ngeneral news extractor for extracting main content of news, articles\npip3 install gne\nfirst of all, set it up with a normal user agent\neven better, we can chain it with some customized headless puppeteer/phantomjs (do not load video data), dump the dom when ready, and use elinks/lynx to analyze the dom tree.\nto test if the recommendation bar shows up:\nhttps://v.qq.com/x/page/m0847y71q98.html\nto make web page more readable:\nhttps://github.com/luin/readability\nload webpage headlessly:\nhttps://github.com/jsdom/jsdom\nhttps://github.com/ryanpetrello/python-zombie"
  },
  {
    "objectID": "posts/78fa1bff-0421-472b-bd43-86b975a3e254/index.html#related-topics",
    "href": "posts/78fa1bff-0421-472b-bd43-86b975a3e254/index.html#related-topics",
    "title": "iot search engines, ip search engines, vulnerable device/server discovery",
    "section": "related topics",
    "text": "related topics\nshodan related topics on github"
  },
  {
    "objectID": "posts/78fa1bff-0421-472b-bd43-86b975a3e254/index.html#online",
    "href": "posts/78fa1bff-0421-472b-bd43-86b975a3e254/index.html#online",
    "title": "iot search engines, ip search engines, vulnerable device/server discovery",
    "section": "online",
    "text": "online\n\nshodan\nawesome shodan queries\nshodan script\n\n\nzoomeye\n\n\nfofa\nhttps://www.fofa.info\n要注册了 以前的网址进不去\nfofa api docs\n\n\ncensys"
  },
  {
    "objectID": "posts/78fa1bff-0421-472b-bd43-86b975a3e254/index.html#self-hosted",
    "href": "posts/78fa1bff-0421-472b-bd43-86b975a3e254/index.html#self-hosted",
    "title": "iot search engines, ip search engines, vulnerable device/server discovery",
    "section": "self hosted",
    "text": "self hosted\nivre\nxray\ninfoga Infoga - Email OSINT\nscan ip for vulnerable service\nasn ASN / RPKI validity / BGP stats / IPv4v6 / Prefix / URL / ASPath / Organization / IP reputation / IP geolocation / IP fingerprinting / Network recon / lookup API server / Web traceroute server"
  },
  {
    "objectID": "posts/109157a7-b10d-45c7-9bd3-887454de3b24/index.html",
    "href": "posts/109157a7-b10d-45c7-9bd3-887454de3b24/index.html",
    "title": "using default pypi.org/simple index",
    "section": "",
    "text": "packages like EdgeGPT may update overnight. mirrors won’t keep up. you need to fetch from the official package index.\n\nto set the index:\npip set global.index-url https://pypi.org/simple\nto use the index temporarily:\npip install &lt;package&gt; -i https://pypi.org/simple"
  },
  {
    "objectID": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#music-discovery",
    "href": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#music-discovery",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "music discovery",
    "text": "music discovery\nfind music by combining choices of experts\nbuild recommendation engine using spotify api\nuse machine learning to predict and recommend music\nsimilar song matching using last.fm or spotify"
  },
  {
    "objectID": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#netease-网易云听歌识曲",
    "href": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#netease-网易云听歌识曲",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "netease 网易云听歌识曲",
    "text": "netease 网易云听歌识曲\ndemo"
  },
  {
    "objectID": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#self-hosted",
    "href": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#self-hosted",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "self-hosted",
    "text": "self-hosted\nshazam algorithm\nblog: create your on shazam\nfindit another shazam clone"
  },
  {
    "objectID": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#audiotag.info",
    "href": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#audiotag.info",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "audiotag.info",
    "text": "audiotag.info\nportify recognize local music and add them to spotify playlist\nwav_to_info.py\naudio identifier\nnowspinning get song info and cover art"
  },
  {
    "objectID": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#shazam",
    "href": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#shazam",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "shazam",
    "text": "shazam\nshazamio reverse engineered shazam api with many supported functions\naudiorec shazam client for linux, with cli support"
  },
  {
    "objectID": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#midomi-houndify-soundhound",
    "href": "posts/9b35ff24-6e94-4538-83de-0d516371dfc7/index.html#midomi-houndify-soundhound",
    "title": "song recognition, music recognition api, music discovery, audio search, audio fingerprint",
    "section": "midomi houndify soundhound",
    "text": "midomi houndify soundhound\nto get track info from soundhound (no cookie):\nhttps://www.midomi.com/api/track?trackID=100282107076607645\nthe houndify music recognition api:\nwss://houndify.midomi.com/\nsome lib for midomi found over here\nit can also bridge yandex music recognition api\nhoundify also have api for that, but requires credit\nfree credits per day: 100\nsoundhound now requires 1 credit\nsoundhound python sdk"
  },
  {
    "objectID": "posts/d8645428-6642-42dc-8ec0-7e2ab195322a/index.html",
    "href": "posts/d8645428-6642-42dc-8ec0-7e2ab195322a/index.html",
    "title": "spider, web scraping, captcha bypass",
    "section": "",
    "text": "there are multiple spider collections on github, most of them are rudimentary and project specific, may not always suit your needs.\nlearnspider in which you can find simple captcha js code and many antimeasure of scrapers for practice. for solutions: learning_spider\nspider collections covers zhihu.com"
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#what-is-spring-cloud",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#what-is-spring-cloud",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "what is spring cloud",
    "text": "what is spring cloud\nSpring Cloud is a set of tools for building microservices-based applications that use Spring Framework, a popular Java-based application development framework. It provides a number of features that can help you build distributed systems that are resilient, reliable, and scalable.\nSpring Cloud provides a number of tools for building microservices, including:\nService discovery: Spring Cloud provides a service registry and a load balancer for discovering and routing to service instances.\nCircuit breaker: Spring Cloud provides a circuit breaker pattern implementation that can help prevent cascading failures in distributed systems.\nConfiguration management: Spring Cloud provides a centralized configuration server for storing and managing application configuration data.\nAPI gateway: Spring Cloud provides an API gateway that can route requests to the appropriate service, perform authentication and authorization, and provide other security features.\nDistributed tracing: Spring Cloud provides support for distributed tracing, which can help you understand the flow of requests through your system and identify performance issues.\nSpring Cloud is built on top of Spring Boot, which makes it easy to get started with microservices development using the Spring Framework. It is also fully integrated with the rest of the Spring ecosystem, including Spring Data, Spring Security, and Spring Cloud Stream."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#use-spring-cloud-in-kotlin",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#use-spring-cloud-in-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "use spring cloud in kotlin",
    "text": "use spring cloud in kotlin\nSpring Cloud can be used with Kotlin, a statically-typed programming language that is fully interoperable with Java and runs on the Java Virtual Machine (JVM). To use Spring Cloud with Kotlin, you can follow these steps:\nSet up a Kotlin project: You can use a build tool like Gradle or Maven to set up a Kotlin project. Make sure to include the necessary dependencies for Spring Cloud, such as the spring-cloud-starter-netflix-eureka-client for service discovery or the spring-cloud-starter-netflix-ribbon for load balancing.\nConfigure your application: You can use the @SpringBootApplication annotation to enable auto-configuration and component scanning in your Kotlin application. You can also use the application.properties file or the application.yml file to configure your application’s properties.\nCreate a Spring Boot application class: You can create a Kotlin class with the @SpringBootApplication annotation and the main function to bootstrap your application. This class will serve as the entry point to your application.\nDefine your microservices: You can define your microservices as Kotlin classes annotated with @RestController and @RequestMapping. These classes will handle incoming HTTP requests and return responses to the client.\nUse Spring Cloud features: You can use the various features of Spring Cloud, such as service discovery, circuit breaking, configuration management, and distributed tracing, in your Kotlin application by using the appropriate annotations and components provided by Spring Cloud.\nHere is an example of a simple Kotlin application using Spring Cloud:\nimport org.springframework.boot.SpringApplication\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient\n@SpringBootApplication\n@EnableDiscoveryClient\nclass MyApplication\nfun main(args: Array&lt;String&gt;) {\nSpringApplication.run(MyApplication::class.java, *args)\n}\nThis application uses the @EnableDiscoveryClient annotation to enable service discovery using Spring Cloud Netflix Eureka. You can then use other Spring Cloud features, such as circuit breaking or configuration management, by including the necessary dependencies and using the appropriate annotations and components."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#write-spring-eureka-client-in-kotlin-to-connect-to-eureka-server",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#write-spring-eureka-client-in-kotlin-to-connect-to-eureka-server",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "write spring eureka client in kotlin to connect to eureka server",
    "text": "write spring eureka client in kotlin to connect to eureka server\nHere is an example of how you can write a Spring Cloud Eureka client in Kotlin to connect to a Eureka server:\nimport org.springframework.boot.SpringApplication\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient\n@SpringBootApplication\n@EnableDiscoveryClient\nclass EurekaClientApplication\nfun main(args: Array&lt;String&gt;) {\nSpringApplication.run(EurekaClientApplication::class.java, *args)\n}\nThis application uses the @EnableDiscoveryClient annotation to enable service discovery using Spring Cloud Netflix Eureka. The @SpringBootApplication annotation enables auto-configuration and component scanning in the application.\nTo connect to the Eureka server, you will need to provide the URL of the Eureka server in the application.properties or application.yml file. For example:\neureka:\nclient:\nserviceUrl:\ndefaultZone: http://localhost:8761/eureka/\nYou can then use the @Value annotation to inject the Eureka server URL into your Kotlin code:\nimport org.springframework.beans.factory.annotation.Value\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.RestController\n@RestController\nclass EurekaClientController {\n@Value(\"\\${eureka.client.serviceUrl.defaultZone}\")\nlateinit var eurekaServerUrl: String\n@GetMapping(\"/eureka-server-url\")\nfun getEurekaServerUrl(): String {\nreturn eurekaServerUrl\n}\n}\nThis controller has a getEurekaServerUrl method that returns the URL of the Eureka server. You can then make a GET request to /eureka-server-url to get the Eureka server URL.\nYou can also use the DiscoveryClient interface provided by Spring Cloud to interact with the Eureka server and perform operations such as registering a service or discovering service instances.\nimport org.springframework.beans.factory.annotation.Autowired\nimport org.springframework.cloud.client.discovery.DiscoveryClient\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.RestController\n@RestController\nclass EurekaClientController {\n@Autowired\nlateinit var discoveryClient: DiscoveryClient\n@GetMapping(\"/service-instances\")\nfun getServiceInstances(): List&lt;String&gt; {\nreturn discoveryClient.services\n}\n}\nThis controller has a getServiceInstances method that returns a list of all the service instances registered with the Eureka server. You can then make a GET request to /service-instances to get the list of service instances."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#run-eureka-server-kotlin",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#run-eureka-server-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "run eureka server kotlin",
    "text": "run eureka server kotlin\nTo run a Eureka server in Kotlin, you can follow these steps:\nSet up a Kotlin project: You can use a build tool like Gradle or Maven to set up a Kotlin project. Make sure to include the necessary dependencies for Spring Cloud Eureka Server, such as the spring-cloud-starter-netflix-eureka-server dependency.\nConfigure your application: You can use the application.properties file or the application.yml file to configure your Eureka server. For example, you can set the server.port property to specify the port on which the Eureka server will run, and the eureka.client.register-with-eureka and eureka.client.fetch-registry properties to enable or disable the registration and fetching of registry information for the Eureka server.\nCreate a Spring Boot application class: You can create a Kotlin class with the @SpringBootApplication annotation and the main function to bootstrap your application. This class will serve as the entry point to your Eureka server.\nEnable Eureka server: You can use the @EnableEurekaServer annotation to enable the Eureka server in your application.\nHere is an example of a simple Kotlin application that runs a Eureka server:\nimport org.springframework.boot.SpringApplication\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.cloud.netflix.eureka.server.EnableEurekaServer\n@SpringBootApplication\n@EnableEurekaServer\nclass EurekaServerApplication\nfun main(args: Array&lt;String&gt;) {\nSpringApplication.run(EurekaServerApplication::class.java, *args)\n}\nThis application uses the @EnableEurekaServer annotation to enable the Eureka server and the @SpringBootApplication annotation to enable auto-configuration and component scanning.\nTo start the Eureka server, you can run the main function of the EurekaServerApplication class. The Eureka server will start up on the port specified in the application.properties or application.yml file (by default, it will run on port 8761). You can then access the Eureka server dashboard at http://localhost:8761."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#spring-cloud-alternative-in-kotlin",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#spring-cloud-alternative-in-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "spring cloud alternative in kotlin",
    "text": "spring cloud alternative in kotlin\nThere are a number of alternatives to Spring Cloud that you can use in Kotlin to build distributed systems and microservices-based applications. Some options include:\nMicronaut: Micronaut is a modern, lightweight, and fast microservices framework for the JVM. It provides features such as service discovery, configuration management, and distributed tracing, and is fully compatible with Kotlin.\nQuarkus: Quarkus is a Kubernetes-native Java framework that is optimized for low memory footprint and fast startup time. It provides a number of features for building microservices, including service discovery, configuration management, and security. Quarkus is fully compatible with Kotlin and can be used to build cloud-native applications.\nVert.x: Vert.x is a reactive, non-blocking, event-driven Java framework that is designed for building distributed systems and microservices. It provides features such as service discovery, load balancing, and distributed tracing, and is fully compatible with Kotlin.\nHelidon: Helidon is a lightweight, cloud-native Java framework that is designed for building microservices and reactive applications. It provides features such as service discovery, configuration management, and security, and is fully compatible with Kotlin.\nEclipse MicroProfile: Eclipse MicroProfile is an open-source specification for building microservices-based applications. It provides a number of features for building distributed systems, including service discovery, configuration management, and security, and is fully compatible with Kotlin.\nYou can choose the appropriate microservices framework based on your requirements and preferences. All of these frameworks provide support for building microservices in Kotlin and offer a number of features that can help you build distributed systems that are resilient, reliable, and scalable."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#which-one-requires-least-code",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#which-one-requires-least-code",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "which one requires least code",
    "text": "which one requires least code\nIt is difficult to say which microservices framework requires the least amount of code, as it depends on the specific requirements of your application and the features you need to implement. Some frameworks, such as Micronaut and Quarkus, are designed to be lightweight and fast, and may require less code to implement certain features compared to other frameworks. However, this may come at the cost of flexibility or a larger learning curve.\nIt is important to evaluate the different microservices frameworks based on your specific requirements and choose the one that best fits your needs. You should consider factors such as the performance and scalability requirements of your application, the features and capabilities of the framework, and the level of support and documentation available.\nIt is also worth noting that writing less code does not necessarily mean that your application will be easier to maintain or more efficient. In some cases, using a more feature-rich framework that requires more code may result in a more maintainable and scalable application in the long run."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#recommend-compatible-package-buildermanager-for-kotlin-but-simpler-than-maven",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#recommend-compatible-package-buildermanager-for-kotlin-but-simpler-than-maven",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "recommend compatible package builder/manager for kotlin but simpler than maven",
    "text": "recommend compatible package builder/manager for kotlin but simpler than maven\nIf you are looking for a package builder and manager for Kotlin that is simpler than Maven, you may want to consider Gradle. Gradle is an open-source build automation tool that is designed to be flexible, efficient, and easy to use. It is fully compatible with Kotlin and can be used to build, test, and publish Kotlin applications.\nSome of the benefits of using Gradle for Kotlin projects include:\nConcise and expressive build scripts: Gradle build scripts are written in a domain-specific language (DSL) that is designed to be concise and expressive. This makes it easier to understand and maintain build scripts, compared to Maven’s XML-based syntax.\nSupport for multiple languages: Gradle supports building projects in multiple languages, including Kotlin, Java, and C/C++. This makes it a good choice for multi-language projects.\nRich plugin ecosystem: Gradle has a rich plugin ecosystem that provides a wide range of functionality, including support for testing, code analysis, and publishing. This makes it easy to extend and customize your build process.\nFast and incremental builds: Gradle uses a caching mechanism and an incremental build approach to make builds faster and more efficient. This can be especially useful for larger projects.\nTo get started with Gradle for Kotlin, you can create a new Kotlin project using the kotlin-gradle-plugin, and define your dependencies in the build.gradle file. You can then use the gradle command-line tool or the Gradle wrapper to build, test, and publish your Kotlin application.\nHere is an example of a simple build.gradle file for a Kotlin project using Gradle:\nplugins {\nid 'org.jetbrains.kotlin.jvm' version '1.4.21'\n}\ngroup = 'com.example'\nversion = '1.0'\nrepositories {\nmavenCentral()\n}\ndependencies {\nimplementation 'org.jetbrains.kotlin:kotlin-stdlib-jdk8'\n}\ntasks.withType&lt;Test&gt; {\nuseJUnitPlatform()\n}\n\nThis build.gradle file defines the kotlin-jvm plugin, the group and version of the project, the dependencies of the project, and the test task. You can then use the gradle command-line tool or the Gradle wrapper to build, test, and publish your Kotlin application."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#use-rabbitmq-client-in-kotlin",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#use-rabbitmq-client-in-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "use rabbitmq client in kotlin",
    "text": "use rabbitmq client in kotlin\nTo use RabbitMQ, a message broker that supports a number of messaging protocols, in Kotlin, you can use the amqp-client library, which is a Java client library for RabbitMQ.\nTo get started with the amqp-client library in Kotlin, you can include the amqp-client dependency in your project. For example, if you are using Maven, you can add the following dependency to your pom.xml file:\n&lt;dependency&gt;\n&lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;\n&lt;artifactId&gt;amqp-client&lt;/artifactId&gt;\n&lt;version&gt;5.11.0&lt;/version&gt;\n&lt;/dependency&gt;\nIf you are using Gradle, you can add the following dependency to your build.gradle file:\ndependencies {\nimplementation 'com.rabbitmq:amqp-client:5.11.0'\n}\n\nOnce you have included the amqp-client dependency in your project, you can use the classes and interfaces provided by the library to connect to a RabbitMQ server and perform operations such as sending and receiving messages.\nHere is an example of how you can use the amqp-client library in Kotlin to send a message to a RabbitMQ server:\nimport com.rabbitmq.client.ConnectionFactory\nimport com.rabbitmq.client.Connection\nimport com.rabbitmq.client.Channel\nfun main() {\nval factory = ConnectionFactory()\nfactory.host = \"localhost\"\nval connection: Connection = factory.newConnection()\nval channel: Channel = connection.createChannel()\nval exchangeName = \"my_exchange\"\nval routingKey = \"my_routing_key\"\nval message = \"Hello, RabbitMQ!\"\nchannel.basicPublish(exchangeName, routingKey, null, message.toByteArray())\nprintln(\" [x] Sent '$message'\")\nchannel.close()\nconnection.close()\n}\nThis example connects to a RabbitMQ server running on localhost, creates a channel, and uses the basicPublish method to send a message to the server with a specified exchange name and routing key.\nYou can also use the amqp-client library in Kotlin to receive messages from a RabbitMQ server. Here is an example of how you can use the amqp-client library in Kotlin to receive messages from a RabbitMQ server:\nimport com.rabbitmq.client.ConnectionFactory\nimport com.rabbitmq.client.Connection\nimport com.rabbitmq.client.Channel\nimport com.rabbitmq.client.DeliverCallback\nfun main() {\nval factory = ConnectionFactory()\nfactory.host = \"localhost\"\nval connection: Connection = factory.newConnection()\nval channel: Channel = connection.createChannel()\nval queueName = \"my_queue\"\nchannel.queueDeclare(queueName, false, false, false, null)\nval deliverCallback = DeliverCallback { _, delivery -&gt;\nval message = String(delivery.body, Charsets.UTF_8)\nprintln(\" [x] Received '$message'\")\n}\nchannel.basicConsume(queueName, true, deliverCallback, _ -&gt; {})\n}\nThis code creates a queue and sets up a DeliverCallback to handle incoming messages. The basicConsume method is used to start consuming messages from the queue. When a message is received, the DeliverCallback is invoked and the message is printed to the console.\nYou can find more information about using the amqp-client library in Kotlin to interact with a RabbitMQ server in the RabbitMQ documentation and the amqp-client library documentation.\nset the delivery mode to persistent\nTo set the delivery mode of a message to persistent when using the amqp-client library in Kotlin, you can use the basicPublish method and set the deliveryMode property of the BasicProperties object that you pass as the third argument.\nHere is an example of how you can set the delivery mode of a message to persistent when using the amqp-client library in Kotlin:\nimport com.rabbitmq.client.ConnectionFactory\nimport com.rabbitmq.client.Connection\nimport com.rabbitmq.client.Channel\nimport com.rabbitmq.client.BasicProperties\nfun main() {\nval factory = ConnectionFactory()\nfactory.host = \"localhost\"\nval connection: Connection = factory.newConnection()\nval channel: Channel = connection.createChannel()\nval exchangeName = \"my_exchange\"\nval routingKey = \"my_routing_key\"\nval message = \"Hello, RabbitMQ!\"\nval properties = BasicProperties.builder()\n.deliveryMode(2)\n.build()\nchannel.basicPublish(exchangeName, routingKey, properties, message.toByteArray())\nprintln(\" [x] Sent '$message'\")\nchannel.close()\nconnection.close()\n}\nIn this example, the BasicProperties.builder method is used to create a BasicProperties object with the deliveryMode property set to 2 (indicating persistent delivery). This object is then passed as the third argument to the basicPublish method.\nYou can find more information about the BasicProperties class and the different delivery modes in the amqp-client library documentation."
  },
  {
    "objectID": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#write-spring-boot-hello-world-with-kotlin",
    "href": "posts/f59b2942-ee86-44da-a3f5-a133251fb83e/index.html#write-spring-boot-hello-world-with-kotlin",
    "title": "spring cloud, spring boot, rabbitmq in kotlin",
    "section": "write spring boot hello world with kotlin",
    "text": "write spring boot hello world with kotlin\nTo write a “Hello, World!” program in Spring Boot using Kotlin, you can follow these steps:\nCreate a new Spring Boot project using the Spring Initializr. You can do this by visiting https://start.spring.io/ and selecting “Kotlin” as the programming language. Select the “Web” dependency, and then click on “Generate” to download the project as a ZIP file.\nExtract the ZIP file and open the project in your preferred development environment.\nIn the src/main/kotlin directory, create a new Kotlin file called HelloController.kt. This file will contain a simple controller that will handle HTTP requests to the root path of the application.\nIn HelloController.kt, define a controller class and annotate it with @RestController. This will enable the class to handle HTTP requests and return responses to the client.\nimport org.springframework.web.bind.annotation.RestController\n@RestController\nclass HelloController {\n}\nInside the HelloController class, define a method that will handle HTTP GET requests to the root path of the application. Annotate this method with @GetMapping(“/”).\nimport org.springframework.web.bind.annotation.GetMapping\n@RestController\nclass HelloController {\n@GetMapping(\"/\")\nfun sayHello(): String {\nreturn \"Hello, World!\"\n}\n}\nRun the Spring Boot application by running the main method in the Application class. You should now be able to visit http://localhost:8080/ in your web browser and see the message “Hello, World!” displayed.\nThat’s it! You have now written a simple “Hello, World!” program in Spring Boot using Kotlin."
  },
  {
    "objectID": "posts/9acf6581-da75-4e76-a79a-5c55eb87ae7a/index.html",
    "href": "posts/9acf6581-da75-4e76-a79a-5c55eb87ae7a/index.html",
    "title": "stationary logo finders and moving logo finders",
    "section": "",
    "text": "for stationary logo, we have a commandline tool called logo finder which can find multple stationary logos with different timespan. we also have a repo for overall logo finding, which might be deprecated.\nfor more, check out “Watermark Removal, Deep Image Prior, Inpainting, Generate Watermark Mask” bookmark folder in macbook chrome"
  },
  {
    "objectID": "posts/a196b4a8-c4a5-4bd6-a6e0-929fc6dbf411/index.html",
    "href": "posts/a196b4a8-c4a5-4bd6-a6e0-929fc6dbf411/index.html",
    "title": "story continuation, story-dalle able to generate story and image at the same time",
    "section": "",
    "text": "story-dalle code"
  },
  {
    "objectID": "posts/780c5692-84c6-44f2-b4e2-327db6bc1adf/index.html",
    "href": "posts/780c5692-84c6-44f2-b4e2-327db6bc1adf/index.html",
    "title": "sync tabs across different browsers",
    "section": "",
    "text": "tab session manager needs google account to operate, while it can still do offline syncing without google cloud.\nseems that it can only hook up with newly opened tabs instead of existing ones."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#you-said-lda-and-lsa-are-helpful-for-paraphrasing",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#you-said-lda-and-lsa-are-helpful-for-paraphrasing",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "you said LDA and LSA are helpful for paraphrasing",
    "text": "you said LDA and LSA are helpful for paraphrasing\nYes, LDA and LSA are two methods that can be used to generate paraphrases of a given text. LDA (Latent Dirichlet Allocation) is a probabilistic model that can be used to identify topics in a text and then generate new sentences that express the same topics in a different way. LSA (Latent Semantic Analysis) is a method that uses singular value decomposition to identify the underlying meaning of words in a text and then generate paraphrases by replacing words with their closest semantic equivalents. Both LDA and LSA can be helpful for generating paraphrases, but they each have their own strengths and limitations."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#can-you-demonstrate-how-to-use-lsa-for-paraphrasing-in-python",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#can-you-demonstrate-how-to-use-lsa-for-paraphrasing-in-python",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "can you demonstrate how to use LSA for paraphrasing in python",
    "text": "can you demonstrate how to use LSA for paraphrasing in python\nI’m sorry, but I am not currently able to browse the internet or access any external resources. As a large language model trained by OpenAI, my knowledge is based solely on the text that I have been trained on, and I don’t have the ability to run code or demonstrate specific examples. However, I can provide a general overview of how LSA could be used for paraphrasing in Python.\nTo use LSA for paraphrasing in Python, you would first need to create a matrix of word vectors for the words in the text you want to paraphrase. This matrix would represent the semantic relationships between the words in the text, and would be used to identify the underlying meaning of each word.\nNext, you would use singular value decomposition (SVD) to decompose the matrix into three matrices, which represent the different factors that contribute to the meaning of the words in the text.\nOnce you have the three matrices, you can then use them to identify the most closely related words for each word in the text, and generate paraphrases by replacing words with their closest semantic equivalents.\nThis is just a brief overview of how LSA could be used for paraphrasing in Python. There are many different ways to implement LSA, and the exact details of the implementation would depend on the specific requirements of your project."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#continue",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#continue",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "continue",
    "text": "continue\nI’m sorry, but I’m not sure what you would like me to continue with. If you have a specific question or topic you would like to discuss, I would be happy to help. Otherwise, I can provide more information about LSA and how it can be used for paraphrasing if that would be helpful. Let me know what you would like to know."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#how-to-use-lda-for-paraphrasing",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#how-to-use-lda-for-paraphrasing",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "how to use LDA for paraphrasing",
    "text": "how to use LDA for paraphrasing\nTo use LDA for paraphrasing, you would first need to train a LDA model on a large corpus of text. This would involve using a machine learning algorithm to identify the topics that are present in the corpus, and then generating a set of “topic vectors” that represent the distribution of those topics across the text.\nOnce you have trained the LDA model, you can then use it to generate paraphrases of a given text by identifying the topics present in the text and then replacing words with synonyms or related words that express the same topics in a different way. This process can be repeated multiple times to generate multiple paraphrases of the same text.\nHere is a brief example of how LDA could be used for paraphrasing in Python:\nfrom gensim import corpora, models\n# Load the text you want to paraphrase\ntext = \"The quick brown fox jumps over the lazy dog.\"\n# Tokenize the text and create a dictionary of words\ntokens = text.split(\" \")\ndictionary = corpora.Dictionary([tokens])\n# Train a LDA model on the text\nlda_model = models.LdaModel([dictionary.doc2bow(tokens)], num_topics=1)\n# Generate paraphrases of the text\nfor i in range(3):\nparaphrase = lda_model.show_topics(num_topics=1, num_words=len(tokens), formatted=False)\nprint(\" \".join([word[0] for word in paraphrase[0][1]]))\nThis example trains a simple LDA model on a single sentence and then generates three paraphrases of the sentence by replacing words with their closest semantic equivalents. Of course, this is just a simple example to illustrate the basic concept of using LDA for paraphrasing. In practice, you would need to use a much larger corpus of text to train the LDA model and generate more accurate paraphrases."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#demonstrate-using-lsa-to-paraphrase-in-python-using-gensim-if-needed",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#demonstrate-using-lsa-to-paraphrase-in-python-using-gensim-if-needed",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "demonstrate using LSA to paraphrase in python, using gensim if needed",
    "text": "demonstrate using LSA to paraphrase in python, using gensim if needed\nAs I mentioned earlier, I am not currently able to browse the internet or access external resources, so I cannot demonstrate using LSA to paraphrase in Python using gensim or any other specific libraries. However, I can provide a general overview of how LSA could be used for paraphrasing in Python.\nTo use LSA for paraphrasing in Python, you would first need to create a matrix of word vectors for the words in the text you want to paraphrase. This matrix would represent the semantic relationships between the words in the text, and would be used to identify the underlying meaning of each word.\nOnce you have the matrix of word vectors, you can use singular value decomposition (SVD) to decompose the matrix into three matrices, which represent the different factors that contribute to the meaning of the words in the text. The gensim library includes a implementation of SVD that you can use for this purpose.\nOnce you have the three matrices, you can then use them to identify the most closely related words for each word in the text, and generate paraphrases by replacing words with their closest semantic equivalents. Here is an example of how this could be done in Python:\nfrom gensim import corpora, models, matutils\n# Load the text you want to paraphrase\ntext = \"The quick brown fox jumps over the lazy dog.\"\n# Tokenize the text and create a dictionary of words\ntokens = text.split(\" \")\ndictionary = corpora.Dictionary([tokens])\n# Create a matrix of word vectors using the dictionary\nword_vectors = [dictionary.doc2bow(tokens)]\n# Use SVD to decompose the matrix of word vectors\nU, S, VT = matutils.svd(word_vectors, k=3)\n# Generate paraphrases of the text\nfor i in range(3):\nparaphrase = []\nfor word in tokens:\n# Identify the closest semantic equivalents for each word\nclosest_words = VT.dot(VT[dictionary.token2id[word]])\nclosest_words = sorted(enumerate(closest_words), key=lambda x: x[1], reverse=True)\nclosest_word = closest_words[0][0]\n# Replace the word with its closest semantic equivalent\nparaphrase.append(dictionary[closest_word])\nprint(\" \".join(paraphrase))\nThis example trains an LSA model on a single sentence and then generates three paraphrases of the sentence by replacing words with their closest semantic equivalents. Again, this is just a simple example to illustrate the basic concept of using LSA for paraphrasing. In practice, you would need to use a much larger corpus of text to train the LSA model and generate more accurate paraphrases."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#how-to-use-transformer-for-paraphrasing",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#how-to-use-transformer-for-paraphrasing",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "how to use transformer for paraphrasing",
    "text": "how to use transformer for paraphrasing\nThe transformer is a type of neural network architecture that has been used for a wide range of natural language processing tasks, including paraphrasing. To use a transformer for paraphrasing, you would need to train the transformer on a large corpus of text using a machine learning algorithm.\nDuring training, the transformer would learn to identify the underlying meaning of words and phrases in the text and then generate paraphrases by replacing words with synonyms or related words that express the same meaning in a different way.\nHere is a brief example of how a transformer could be used for paraphrasing in Python:\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n# Load the text you want to paraphrase\ntext = \"The quick brown fox jumps over the lazy dog.\"\n# Tokenize the text using a pre-trained transformer model\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\ntokens = tokenizer.encode(text)\n# Load a pre-trained transformer model\ntransformer = AutoModelForSeq2SeqLM.from_pretrained(\"distilbert-base-cased\")\n# Generate paraphrases of the text\nfor i in range(3):\nparaphrase = transformer.generate(tokens)\nparaphrase = tokenizer.decode(paraphrase[0])\nprint(paraphrase)\nThis example uses a pre-trained transformer model to generate three paraphrases of a single sentence. Of course, in practice you would need to train the transformer on a much larger corpus of text to generate more accurate paraphrases. The exact details of the implementation would depend on the specific requirements of your project."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#how-to-generate-catchy-title-from-keywords-using-language-model",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html#how-to-generate-catchy-title-from-keywords-using-language-model",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "how to generate catchy title from keywords using language model",
    "text": "how to generate catchy title from keywords using language model\nTo generate a catchy title from a set of keywords using a language model, you would need to train the language model on a large corpus of text that includes a variety of titles. During training, the language model would learn to identify the underlying meaning of words and phrases and the characteristics of catchy titles.\nOnce the language model has been trained, you can then use it to generate a catchy title from a set of keywords by providing the keywords as input to the model and then selecting the generated title that is the most catchy and relevant to the keywords.\nHere is a brief example of how this could be done in Python:\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n# Load the keywords you want to use to generate the title\nkeywords = [\"quick\", \"brown\", \"fox\"]\n# Tokenize the keywords using a pre-trained language model\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\ntokens = tokenizer.encode(keywords)\n# Load a pre-trained language model\nlanguage_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n# Generate candidate titles from the keywords\ncandidate_titles = []\nfor i in range(3):\ntitle = language_model.generate(tokens, max_length=8)\ntitle = tokenizer.decode(title[0])\ncandidate_titles.append(title)\n# Select the most catchy and relevant title\nselected_title = candidate_titles[0]\nfor title in candidate_titles:\nif is_catchy(title) and is_relevant(title, keywords):\nselected_title = title\nbreak\nprint(selected_title)\nThis example generates three candidate titles from a set of keywords using a pre-trained language model, and then selects the most catchy and relevant title as the final title. Of course, this is just a simple example to illustrate the basic concept of using a language model to generate a catchy title from keywords. In practice, you would need to use a much larger corpus of text to train the language model and generate more accurate and diverse titles."
  },
  {
    "objectID": "posts/92ba1aa5-bc03-4f9b-b051-5b36e36ccc68/index.html",
    "href": "posts/92ba1aa5-bc03-4f9b-b051-5b36e36ccc68/index.html",
    "title": "telegram bot: pyrogram",
    "section": "",
    "text": "pyrogram repo\nyou can act both with a user account and a bot account"
  },
  {
    "objectID": "posts/b625df8d-6400-410f-ae09-bb7c6cf59e95/index.html",
    "href": "posts/b625df8d-6400-410f-ae09-bb7c6cf59e95/index.html",
    "title": "text-processing.com, free text mining and natural language processing",
    "section": "",
    "text": "functions:\n\nSentiment Analysis\nStemming\nPart-of-Speech Tagging and Chunking\nPhrase Extraction & Named Entity Recognition\n\neach method is throttled to 1000 calls per day per IP."
  },
  {
    "objectID": "posts/85d23d22-27a6-4895-b3cf-d2ac19513376/index.html",
    "href": "posts/85d23d22-27a6-4895-b3cf-d2ac19513376/index.html",
    "title": "the formula search engine, latex enabled, textbook search engine",
    "section": "",
    "text": "latex2sympy convert latex to sympy using antlr\nmathpix has stunning accuracy but is not free. they offer timely licensed docker images.\nim2markup is by far the most accurate one. it is attention based and can be trained on multiple markup languages."
  },
  {
    "objectID": "posts/643b48e3-723d-4009-8988-10aa5ddbd217/index.html",
    "href": "posts/643b48e3-723d-4009-8988-10aa5ddbd217/index.html",
    "title": "the most powerful work environment setup, introduced by us",
    "section": "",
    "text": "in order to make money with this idea, you can do the following:\n\ncreate thinner splitable wireless keyboard\ncreate typing traning software with good interface\nbetter computer stand so you can insert keyboard closer and introduce more ports\nsell things together, introduce many usages to let people see what really matters\nsend ads along with your media, not just fun videos and news"
  },
  {
    "objectID": "posts/7211f086-4e9f-4ff1-9d89-db6bc1f053a7/index.html",
    "href": "posts/7211f086-4e9f-4ff1-9d89-db6bc1f053a7/index.html",
    "title": "themida unpacker",
    "section": "",
    "text": "still don’t forgive that damn cacani software (manual), and i still don’t find a clue for creating animation with cacani automatically.\nsearch for “themida unpacker” or “unlicense” in bing or github. saying manually unpacking themida is always a pain in the ass."
  },
  {
    "objectID": "posts/d37f6784-a411-47cd-bcde-2c8b1535fefd/index.html#general-torrent-searching",
    "href": "posts/d37f6784-a411-47cd-bcde-2c8b1535fefd/index.html#general-torrent-searching",
    "title": "torrent search engines",
    "section": "general torrent searching",
    "text": "general torrent searching\ntorrenthunt is a telegram bot which can search several torrent search engines. you can use it directly\ntorrent search api: a multi torrent search api in nodejs\nnotflix search for magnet links on 1337x and stream/play it with peerflix"
  },
  {
    "objectID": "posts/d37f6784-a411-47cd-bcde-2c8b1535fefd/index.html#anime-torrent-searching",
    "href": "posts/d37f6784-a411-47cd-bcde-2c8b1535fefd/index.html#anime-torrent-searching",
    "title": "torrent search engines",
    "section": "anime torrent searching",
    "text": "anime torrent searching\nNyaa which supports sorting\nBangume.moe\n动漫花园 可以订阅单个页面rss 但是不会全局排序"
  },
  {
    "objectID": "posts/600bb148-d90c-435a-8442-f2b398006801/index.html",
    "href": "posts/600bb148-d90c-435a-8442-f2b398006801/index.html",
    "title": "trainable bezier curve multiparameter regressor",
    "section": "",
    "text": "bezier\nfirst, we need a bezier curve connects (0,0) and (1,1)\nimport numpy as np\nimport bezier\ndef bezierCurve(start=(0,0), end=(1,1), skew=0):\n# skew: (-0.5,0.5) otherwise this shit will look ugly.\nassert skew &gt;=-0.5\nassert skew &lt;=0.5\nx_start, y_start = start\nx_end, y_end = end\nx_diff = x_end - x_start\ny_diff = y_end - y_start\nnodes1 = np.asfortranarray(\n[\n[x_start, x_diff * (0.5 + skew), x_end],\n[y_start, y_diff * (0.5 - skew), y_end],\n]\n)\ncurve1 = bezier.Curve(nodes1, degree=2)\ncurve_params = {'x_start':x_start, 'x_diff':x_diff,'x_end':x_end}\nreturn curve1, curve_params\ndef evaluateBezierCurve(input_value:float,curve, curve_params:dict)\nx_start = curve_params['x_start']\nx_end = curve_params['x_end']\nassert x_start &lt;= input_value\nassert x_end &gt;= input_value\nx_diff = curve_params['x_diff']\ns = (input_value - x_start)/x_diff\npoints = curve.evaluate(s)\n# we only get the single point.\npoint = points.T[0]\nx,y = point\nresult = y\nreturn result\nthen, we define our very recursive or flexible regressor:\ndef multiParameterExponentialNetwork(*args, input_bias=0.05, curve_function=bezierCurve, curve_function_kwargs = {'start':(0,0),'end':(1,1)'skew':0}, evaluate_function=evaluateBezierCurve):\ncurve, curve_params = curve_function(**curve_function_kwargs)\nvalue = evaluate_function(input_bias, curve, curve_params)\nfor index, input_value in enumerate(args):\napply_list = [input_value]*(index+1)\nfor apply_item in apply_list:\nvalue += (1-value)*function(apply_item, **function_kwargs)\nreturn value"
  },
  {
    "objectID": "posts/4ee9b9a5-ef24-455a-b9df-283da2e89908/index.html",
    "href": "posts/4ee9b9a5-ef24-455a-b9df-283da2e89908/index.html",
    "title": "tweening for object focus, zoom to object, zoom to video ROI",
    "section": "",
    "text": "focus on person only, crop video and leave only human region untouched:\nhttps://github.com/ConceptCodes/portal-zoomer\nfocus/zoom on given object using pytweening, a easing/tweening function collection.\nto tell you, pytweening is initially developed for pyautogui (by the same author at least), probably for evading AI detection, passing captcha or somehow, but it could also be used in animation rendering.\nor just use ffmpeg. you need to handcraft those formulas anyway.\ndoes vidpy/mltframework and some other libs supports that? requires investigation."
  },
  {
    "objectID": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html",
    "href": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "",
    "text": "淘宝视频 哇偶视频似乎取消了视频上方的搜索接口\n首页的视频推荐似乎更好看一些 推荐算法更先进\n逛逛被单独分了一个专栏 在那里可以搜索视频\n“您的分享过于频繁，请稍后重试”\n出现这种情况需要更换qq号\nhow about let’s use appium for unlocking phone, airtest for actual testing?\nappium can only unlock phone by removing password.\npassword with ampersand needs to be quoted/escaped.\nthat might need another supervisor"
  },
  {
    "objectID": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#ui-automation-and-indirect-intent-interception-share-to",
    "href": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#ui-automation-and-indirect-intent-interception-share-to",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "ui automation and indirect intent interception (share to)",
    "text": "ui automation and indirect intent interception (share to)\n“您的分享过于频繁，请稍后重试”\n出现这种情况需要更换qq号\nhow about let’s use appium for unlocking phone, airtest for actual testing?\nappium can only unlock phone by removing password.\npassword with ampersand needs to be quoted/escaped.\nthat might need another supervisor\n\nappium\nwrite a test in python\nappium desired capabilities\nuiautomator2\nunlock android phone\n\n\nairtest\nintro\npoco introduction"
  },
  {
    "objectID": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#autojs-autox.js",
    "href": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#autojs-autox.js",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "autojs autox.js",
    "text": "autojs autox.js\nautojs code collection\nset up accessibility servicr for autox either by the switch inside settings (with root) or run this command:\nadb shell settings put secure enabled_accessibility_services packagname/servicename\nam start -n org.autojs.autoxjs.v6/org.autojs.autojs.external.shortcut.ShortcutActivity -a android.intent.action.MAIN -e path \"/storage/emulated/0/脚本/show_toast.js\"\n现在autojs是付费的 但这两个都不能替代appium或者airtest\nautox repo vscode plugin\n发送意图-QQ文本消息分享\n腾讯相关autojs\n\nfrida\nhook current application context\n\n\nxposed\nxposed new repo\nandroid virtual cam xposed安卓虚拟摄像头 android virtual camera on xposed hook\n\nbroadcast, indirect intent, start activity\nhighly suspected source of ‘token’, the miniapp json generator the MiniArkShareModelBuilder transformArkShareJson ShareQQArkHelper MiniProgramShareUtils MiniProgramShareUtils.newShareInfoRequest ShareManager MiniProgramShareUtils.shareToChatDirectly\nqq jumpparser\nmqqapi doc\nmqqapi example\nmqqapi 聊天 加群 名片\nAndroid常用代码-微信QQ分享文件和文字\n常用的URL Scheme\nAndroid am help 帮助信息\nadb shell am start -d 启动应用之uri被*吃了\nam start 启动activity 命令\ninspeckage Android Package Inspector - dynamic analysis with api hooks, start unexported activities and more. (Xposed Module)\n找出APP的SchemeURL（抓取APP意图/intent）的常用方法\n隐式启动 这是一款开发者辅助工具，帮助开发者发现手机上的应用的快捷启动，原理是利用 Android 提供的隐式启动 Activity 来快速启动某个应用的某个界面，如快速发微博、发朋友圈、扫一扫，快速切换 vpn 等\nadb/安卓/按键精灵/autojs/uniapp/ec打开SchemeURL的方法及常用SchemeURL整理\nIntent 拦截者_1.1.apk\ncom.zwk.xintent (intent traffic monitoring tool) release orginal repo\nuse am broadcast to send indirect intent\nsending a boot-complete broadcast\nexploiting broadcast receivers\nusage of am and common android shell commands"
  },
  {
    "objectID": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#腾讯微视",
    "href": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#腾讯微视",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "腾讯微视",
    "text": "腾讯微视\nhttps://h5.weishi.qq.com/webapp/json/weishi/WSH5GetPlayPage?t=0.7532600494918984&g_tk=&feedid=71yYpleeM1HghTttk&recommendtype=0&datalvl=&qua=&uin=&format=json&inCharset=utf-8&outCharset=utf-8"
  },
  {
    "objectID": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#淘宝短视频",
    "href": "posts/cab1b897-3b47-4f7e-8606-c8f2f3865cdf/index.html#淘宝短视频",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "淘宝短视频",
    "text": "淘宝短视频\n淘宝x-sign算法分析\n淘宝抓包解决方案\n逆向闲鱼apk 抓包\npost content on we.taobao.com\n淘宝直播\nhttps://zhuanlan.zhihu.com/p/91192587\npacket capture + batch m3u8 download\n5 666:/鱼里家庭布偶猫舍的场间简直太火爆了，快来看！\n可爱的宝宝找家咯 ,快来场间 https://m.tb.cn/h.fJErCBC?sm=b4d048\n———————口———————\n！们那之学有为上家得人多啊\n淘宝网页无法播放直播\nhttp://huodong.m.taobao.com/act/talent/live.html?id=359158835379&type=508&livesource=share&cp_origin=taobaozhibo%7Ca2141.8001249%7C%7B%22account_id%22%3A%221897661676%22%2C%22app_key%22%3A%2221646297%22%2C%22feed_id%22%3A%22359158835379%22%2C%22os%22%3A%22android%22%2C%22spm-cnt%22%3A%22a2141.8001249%22%7D&sourceType=talent&suid=07ebc365-efc6-4e9c-9c14-c58c1bb8e522&ut_sk=1.W4yy2CtIMUMDAA1l3Dnx4jNG_21646297_1651743901078.Copy.zhibo&un=42ad1253bebcb796f3ba5a7177d3a823&share_crt_v=1&un_site=0&spm=a2159r.13376460.0.0&sp_abtk=common_zhibo_commonInfo&sp_tk=5Lus6YKj5LmL5a2m5pyJ5Li65LiK5a625b6X5Lq65aSa&cpp=1&shareurl=true&short_name=h.fJErCBC&bxsign=scdS6H1ZsIpmAMTuhs-TbALYgOScV_BU6U9ueNABqjzLXd9JSLZYxA6vuaR_tN9PI3n6qDUMtmf-5O_pZZqgnoLHg4WsX64s_Gkx–xc0vfG_87x3Boc1-uCbsYXCZO3Wtc\n最新版只有微淘入口\n淘宝逛逛 有用户名 ID\n67信生对在然有为上子是去你嘻 https://m.tb.cn/h.fJE9C6B?sm=ee59f9 怕鱼的小猫咪~~\nthis video is flipable\n淘宝网页版\nhttps://main.m.taobao.com/index.html\nhttps://market.m.taobao.com/app/tb-source-app/video-fullpage/pages/index?wh_weex=true&wx_navbar_hidden=true&contentId=346882467812&source=guess-guangguang&type=guangguang_cainixihuan&id=346882467812\nhttps://market.m.taobao.com/app/tb-source-app/video-fullpage/pages/index?wh_weex=true&wx_navbar_hidden=true&origin=VideoInteract%7Ca310p.13800399.0.0%7C%7B”contentId”%3A”346882467812”%7D&contentId=346882467812&source=guess-guangguang&type=guangguang_cainixihuan&spm=a2141.1.guessitemtab_1.3&accountId=0&videoUrl=https%3A%2F%2Fcloud.video.taobao.com%2Fplay%2Fu%2Fnull%2Fp%2F1%2Fe%2F6%2Ft%2F1%2F346882467812.mp4&coverImage=https%3A%2F%2Fimg.alicdn.com%2Fimgextra%2Fi2%2F604321789%2FO1CN01rVTgs31P5PIQ7r2JR_!!604321789.jpg&id=346882467812&sourceType=other&suid=7f31e56f-2878-4462-9a5a-acd7d5deeec5&ut_sk=1.W4yy2CtIMUMDAA1l3Dnx4jNG_21646297_1651742283972.Copy.tblive-video&un=42ad1253bebcb796f3ba5a7177d3a823&share_crt_v=1&un_site=0&sp_abtk=common_tblive-video_commonInfo&sp_tk=55Sf5a%2B55Zyo54S25pyJ5Li65LiK5a2Q5piv5Y675L2g&cpp=1&shareurl=true&short_name=h.fJE9C6B&bxsign=scdwHO4PyMrtSLzA7OBHe89rxDFffyg-UVrE4mtFb42ts8qjhHx_6DhU0VAdOy3PgJcoggVVt1dw63IPVDTdXhIGiWlqtdNZredQE5O2V8o1AhV8XE7zhYjf5gApjy90rf1&sm=ee59f9&app=chrome"
  },
  {
    "objectID": "posts/2e4b90b1-68e4-4f5c-97f6-c9edf7664594/index.html",
    "href": "posts/2e4b90b1-68e4-4f5c-97f6-c9edf7664594/index.html",
    "title": "use pyscenedetect dynamically in program",
    "section": "",
    "text": "对于单纯拼接起来的视频 这个算法就如同手术刀一样精准\n首尾有可能有一两帧看起来不太对 但是可以通过调节start和end来修正\n警惕频繁转场的视频 它们可能是属于同一个小片段的 但是如果不打乱顺序有可能会触发版权识别问题\n即使选出来了可以使用的片段 对于同一个视频的制作过程 依旧要隔一段时间采样 比如两个片段间隔至少5秒 不要单纯的把所有片段一次性提取出来 避免内容重复和版权问题\n当然对于有渐变 转场的视频 可能需要用其他的检测方法\nfrom scenedetect import open_video, SceneManager, split_video_ffmpeg\nfrom scenedetect.detectors import ContentDetector\nfrom scenedetect.video_splitter import split_video_ffmpeg\ndef split_video_into_scenes(video_path, threshold=27.0):\n# Open our video, create a scene manager, and add a detector.\nvideo = open_video(video_path)\nscene_manager = SceneManager()\nscene_manager.add_detector(\nContentDetector(threshold=threshold))\nscene_manager.detect_scenes(video, show_progress=True)\nscene_list = scene_manager.get_scene_list()\nsplit_video_ffmpeg(video_path, scene_list, show_progress=True)"
  },
  {
    "objectID": "posts/fe91bcb4-5849-446b-a33a-54c44e8f3192/index.html#open-source-virusmalware-in-your-arsenal",
    "href": "posts/fe91bcb4-5849-446b-a33a-54c44e8f3192/index.html#open-source-virusmalware-in-your-arsenal",
    "title": "useful sources on cyber attack",
    "section": "open source virus/malware in your arsenal",
    "text": "open source virus/malware in your arsenal\npowershell obfuscator advanced, will bypass any av\n\npost-exploit framework, evasion\nthefatrat is an exploiting tool which compiles a malware with famous payload, and then the compiled maware can be executed on Linux , Windows , Mac and Android. TheFatRat Provides An Easy way to create Backdoors and Payload which can bypass most anti-virus. the author has some tools to share.\npupy is an opensource, cross-platform (Windows, Linux, OSX, Android) C2 and post-exploitation framework written in python and C\nvenom - C2 shellcode generator/compiler/handler\n\n\nvirus samples\nthe malware repo\nopen source virus\nthezoo A repository of LIVE malwares for your own joy and pleasure. theZoo is a project created to make the possibility of malware analysis open and available to the public.\nmalwares codebase, botnet\nopen source malware on github, repo list\nvirus for win10\nkafan virus samples\nvbgood\ndebugman reverse engineering\n\nofficial blackhat arsenal under toolswatch category arsenal\nmassive hacking tools collection\nburpa burp suite automation tool\ntwitter token generator register twitter in batch, has a large proxy list\ni0gan some hacker with automated tools like awd_script\nichunqiu ctf educational resources\ncyberchief online ctf interactive tools suite\nbugku tools\nctftools curated online tool list\nctf online tools\nkanxue home page, articles\n52pojie hack tools\nkanxue knowledge base\nctfshow\nctfhub tools\n渗透师导航\nresources recommended by ctfwiki\nshellcode storm database can be queried via api\nexploitdb find exploits, poc code, google hacking database for finding juicy information/urls, shellcodes with an advanced search interface\ncracking.org\nOSINT: open source (public source) intelligence is the practice of collecting information from published or otherwise publicly available sources\nosint tools:\nMaltego\nGoogle dorks\nMitaka\nSpiderFoot\nSpyse\nBuiltWith\nIntelligence X\nDarkSearch.io\nGrep.app\nRecon-ng\ntheHarvester\nShodan\nMetagoofil\nSearchcode\nSpiderFoot\nBabel X"
  },
  {
    "objectID": "posts/ae52ce45-d660-4de8-bb81-b835fe85161c/index.html",
    "href": "posts/ae52ce45-d660-4de8-bb81-b835fe85161c/index.html",
    "title": "video phash, video deduplication",
    "section": "",
    "text": "视频降重\n每隔几帧抽一帧 视频延长 音频变调 加上背景音乐\n当然不要完全抄人家的 该打乱顺序就打乱 去水印 提取字幕 然后多抄几部视频"
  },
  {
    "objectID": "posts/b6f66052-bfc2-4dc7-bf92-2be3debdca60/index.html#video",
    "href": "posts/b6f66052-bfc2-4dc7-bf92-2be3debdca60/index.html#video",
    "title": "video quality assessment, audio quality assessment",
    "section": "video",
    "text": "video\npaperswithcode benchmark\nfast-vqa\nssim based vqs"
  },
  {
    "objectID": "posts/b6f66052-bfc2-4dc7-bf92-2be3debdca60/index.html#audio",
    "href": "posts/b6f66052-bfc2-4dc7-bf92-2be3debdca60/index.html#audio",
    "title": "video quality assessment, audio quality assessment",
    "section": "audio",
    "text": "audio\nmosquito"
  },
  {
    "objectID": "posts/21feff7a-49d0-444d-b33f-4b2644ef4eca/index.html",
    "href": "posts/21feff7a-49d0-444d-b33f-4b2644ef4eca/index.html",
    "title": "vscode extension create publisher",
    "section": "",
    "text": "medialang\nvsce token:\nxt2s4ohfn57ri5vfcxvwmb7yzddfnqmd2a37tfaidwhy3uaqwzlq"
  },
  {
    "objectID": "posts/3fa03755-c7b2-44cc-bbfa-ea32426acecb/index.html",
    "href": "posts/3fa03755-c7b2-44cc-bbfa-ea32426acecb/index.html",
    "title": "Bypassing Web Application Firewalls with bapp: A Comprehensive Guide",
    "section": "",
    "text": "waf bypass\nhow to bypass waf cheatsheet by hacken.io\nbapp for waf bypass"
  },
  {
    "objectID": "posts/d2a09aa3-9759-4985-b549-d776ecf8bc39/index.html",
    "href": "posts/d2a09aa3-9759-4985-b549-d776ecf8bc39/index.html",
    "title": "webpage translator plugin",
    "section": "",
    "text": "traduzir\nsimple-translate"
  },
  {
    "objectID": "posts/812f34a6-0f53-4523-b04e-3c7bd5eaafae/index.html",
    "href": "posts/812f34a6-0f53-4523-b04e-3c7bd5eaafae/index.html",
    "title": "windows & office activation, install windows in virtualbox",
    "section": "",
    "text": "visit: massgrave\nsteps before installing windows to virtualbox"
  },
  {
    "objectID": "posts/dceb3026-9060-4172-9ef5-319678c7e104/index.html",
    "href": "posts/dceb3026-9060-4172-9ef5-319678c7e104/index.html",
    "title": "x11vnc test on kali",
    "section": "",
    "text": "better use nomachine instead, which is based on nx\npassword: 472831\ncommands:\n# necessary env for gui target, though may not suitable for xvfb\nexport XAUTHORITY=/root/.Xauthority\nexport DISPLAY=:1\n# kill previous running x11vnc, if exists\njoker list | grep x11vnc | awk '{print $1}' | xargs -iabc kill -s KILL abc\n# launch new vnc\njoker x11vnc -threads -forever -rfbauth /root/.vnc/passwd"
  },
  {
    "objectID": "posts/15aa77c7-7b35-4369-9fdd-33f4f4b46e8a/index.html",
    "href": "posts/15aa77c7-7b35-4369-9fdd-33f4f4b46e8a/index.html",
    "title": "youtube download and its fork",
    "section": "",
    "text": "original youtube-dl\nthe fork with faster (maybe?) download speed: yt-dlp"
  },
  {
    "objectID": "posts/27a2e60a-2d69-46c3-9f3b-6ad0f573de54/index.html",
    "href": "posts/27a2e60a-2d69-46c3-9f3b-6ad0f573de54/index.html",
    "title": "Introducing the Open-Source Chinese Font ‘LxgwWenKai’ Based on Klee One",
    "section": "",
    "text": "中文字体 open source chinese fonts\n百度输入法造字？\nhttps://github.com/lxgw/LxgwWenKai/\n一款开源中文字体，基于 FONTWORKS 出品字体 Klee One 衍生。\n感觉挺好看"
  },
  {
    "objectID": "posts/626df2db-8eab-47d9-852d-5f8dfc3d3319/index.html",
    "href": "posts/626df2db-8eab-47d9-852d-5f8dfc3d3319/index.html",
    "title": "人脸识别 Face Recognition",
    "section": "",
    "text": "https://github.com/ZhaoJ9014/face.evoLVe\nhttps://github.com/timesler/facenet-pytorch\nhttps://github.com/JDAI-CV/FaceX-Zoo\nhttps://github.com/justadudewhohacks/face-api.js\nhttps://github.com/cmusatyalab/openface\nhttps://github.com/davidsandberg/facenet\nhttps://github.com/ageitgey/face_recognition\nhttps://github.com/jerry1900/faceRecognition"
  },
  {
    "objectID": "posts/1c787b18-5280-4e45-bca9-93d623ecc506/index.html",
    "href": "posts/1c787b18-5280-4e45-bca9-93d623ecc506/index.html",
    "title": "传播学",
    "section": "",
    "text": "传播学 1"
  },
  {
    "objectID": "posts/af91bf33-e6ac-4eb7-ac15-2969d7ce9ae0/index.html",
    "href": "posts/af91bf33-e6ac-4eb7-ac15-2969d7ce9ae0/index.html",
    "title": "全自动电影解说软件介绍",
    "section": "",
    "text": "全自动电影解说软件介绍 全自动短视频合成\n自媒体自学网 新媒体运营 自动化运营 混剪：\nhttps://www.zmtzxw.com\ngenerate video from plain text using beatdetectorforgames:\nhttps://github.com/FireFragment/video-generator\nyoutube reddit text to speech video generator:\nhttps://github.com/HA6Bots/Automatic-Youtube-Reddit-Text-To-Speech-Video-Generator-and-Uploader\ntwitch clip compilation:\nhttps://github.com/HA6Bots/Twitch-Clips-Compilation-Generator-TCCG-\nslideshow video generator:\nhttps://github.com/oknoorap/vidshow\nbest of twitch video generator:\nhttps://github.com/BayoDev/Twitch-Best-Of-Gen\nvideo generator by scraping reddit videos and comments:\nhttps://github.com/charlypoirier/redditube\nyoutube video generation based on watson natural languahe understanding and google image search:\nhttps://github.com/rhenriquea/ai-video-generator\ntiktok video compilation based on custom filters:\nhttps://github.com/HA6Bots/TikTok-Compilation-Video-Generator\n12个搬运手法：\n去水印 放大缩小 镜像 抽帧 加滤镜 加特效 调色 调速 转场 调整视频顺序 加画中画 其他视频元素\n文案加字幕 朗读方案：\nhttps://m.baidu.com/video/page?pd=video_page&nid=9603074179371472094&sign=5664314656417860263&word=自动合成视频&oword=自动合成视频&atn=index&frsrcid=4185&ext=%7B”jsy”%3A1%7D&top=%7B”sfhs”%3A1%2C”_hold”%3A2%7D&sl=4&fr0=A&fr1=A&ms=1&lid=12061699393737547668&referlid=12061699393737547668&frorder=6&_t=1653970095475\n知乎方案，模板加图片，BGM，配音\n文章自动生成视频，幕言 自动打轴（force alignment）：\nhttps://zhuanlan.zhihu.com/p/218000255\nhttps://www.muyanpeiyin.com/?zhihu\n5种方式生成原创视频：\nhttps://zhuanlan.zhihu.com/p/140075360?from_voters_page=true\nhttps://zhuanlan.zhihu.com/p/119422109\nhttps://m.baidu.com/video/page?pd=video_page&nid=11383613456893718608&sign=855254448776210471&word=AI全自动剪辑软件：2分钟自动合成一个影视解说视频，批量效率高&oword=自动合成视频&atn=index&frsrcid=5373&ext=%7B”jsy”%3A1%7D&top=%7B”sfhs”%3A1%2C”_hold”%3A2%7D&sl=4&fr0=A&fr1=C&title=AI全自动剪辑软件：2分钟自动合成一个影视解说视频，批量效率高&lid=12061699393737547668&ms=1&_t=1653971026899\n模式一：单视频+文案\n一个视频配一个文案，软件将自动把文案转化成字幕以及真人发音，把视频和字幕添加到视频上\n此模式适合电影解说，新闻讲解等等\n模式二：多视频+文案\n多个视频会随机合成一个视频,然后把文案转化成字幕以及真人发音，把视频和字幕添加到视频上\n此模式适合抖音带货等\n模式三：多图片+文案\n多个图片会随机合成一个视频,然后把文案转化成字幕以及真人发音，把视频和字幕添加到视频上\n此模式适合大批量却又苦于找不到视频素材的情况\n模式四：单视频混剪\n适合抖音带货，或者搬运类的影视混剪\n模式五：文字转语音\n现在头条也出了音频的创作专区，应广大用户的需求，添加这个功能，将txt文件批量放入video目录即可。"
  },
  {
    "objectID": "posts/eb135d81-fc34-42e6-94e6-10a74bf20e4f/index.html#文章伪原创api-即将关站-站内关于伪原创的方法总结",
    "href": "posts/eb135d81-fc34-42e6-94e6-10a74bf20e4f/index.html#文章伪原创api-即将关站-站内关于伪原创的方法总结",
    "title": "关于伪原创的方法总结 自动软文生成器 一键生成软文 伪原创 文案生成器 自动生成软文",
    "section": "文章伪原创API 即将关站 站内关于伪原创的方法总结",
    "text": "文章伪原创API 即将关站 站内关于伪原创的方法总结\n众所周知，百度搜索引擎现在对网站内容质量的要求越来越高。如果一个网站的内容质量差，即使有很多外部链接和高质量的外部链接，它通常也不会得到很高的排名，因为内容质量差的网站往往有很高的跳转率，这已经成为百度排名算法的一个重要元素\n然而，制作一个网站的少量原创内容并不困难，但是对于任何一个草根站长来说，每天更新都是非常困难的，尤其是对于一些垂直行业的网站。由于这个行业的内容是相对固定的，发布原创内容就更加困难，所以伪原创是一个重要的方式。然而，传统的伪原创方法已经难以提高内容质量，这将使网站成为垃圾网站。因此，从发展的角度来看，伪原创的质量更难提高。\n那么我们如何才能有效地提高伪原创内容的质量呢?我认为我们可以从以下几个方面入手，使伪原始内容和原始内容的质量相等。\n第一，伪原创的创新并购方式。\n我们知道伪原创通常在网上寻找一些内容，然后改变标题，混淆文章的段落，甚至用伪原创工具替换同义词，导致伪原创内容可读性差。因此，我们应该放弃这种伪原始方法，整合相关内容，并用我们自己的语言重新组织它。在梳理的过程中，我们可以结合相关内容进行一定的观点创新，使这种伪原创的内容呈现出新的思路。\n当合并相关内容时，我们必须确保第一段和最后一段都是原始内容，并在这两个地方建立您的中心内容。这个中心内容通常可以与不同概念的集成结合在一起。如果站长此时满脑子都是想法，有自己独立的想法，他也可以写出来，这样伪原创内容的质量就可以得到有效的保证。即使此时文本中有一些相似度很高的内容，百度也不会反感。\n二是内容与科学收藏的整合。\n我们知道互联网上的一些内容和市场上销售的书籍有一定的相关性，但它们不可能完全一样，否则这些书会被复制，所以我们可以把这些书的内容搬到互联网上，进行一些优化和创新，然后把它们转化成非常好的原创内容，这些内容具有很好的可读性和知识性，成为百度蜘蛛最喜欢的内容餐。\n另一种是整合互联网的现有内容，例如，制作一些论坛发帖的百科全书、游戏策略的百科全书等。这些内容往往不需要原创，只需要在网上收集相关内容，然后混合在一起，就可以形成非常有参考价值的内容。此外，这些内容也是百度蜘蛛最喜欢的食物，它有望成为百度主页的常客。\n第三，等价交换法\n(1)文本排序法:如果你随意拿这篇文章“游戏编辑写虚假原创文章的五大技巧”，如何做等价交换法?对等交换可以通过同义词和打乱标题关键词的顺序来实现。您可以将其更改为“游戏编辑撰写虚假原创文章的五大技巧”和“协助游戏编辑撰写虚假原创文章的五大技巧”。你可以看到标题被巧妙地改变了，但是意思没有变。这是等价交换法。\n②数字交流方法:如标题:五种伪主动性技能。你可以停止移除一些伪主动性技能或者增加一些伪主动性技能。至少，你可以让搜索引擎至少认为你的标题是非传统的。\n(3)换词法:看图造义是指交换词语的相关或同义词，从而达到变汤不换药的效果。\n第四，标题组合法\n组合方法是使用上面总结的三种方法或两种方法。例如，网站管理员网站中的一篇文章的标题“网站管理员如何进行网站营销分析并制定策略”，可以改为“进行网络营销分析的好策略”，其中使用了等价交换法和文本修改法。\n五、文本修改方法\n当标题准确时，我们可以进行一定的加工和修饰，如加问句、反问句、比较级、隐喻、拟人，并与原标题完全分离，从而增加标题的影响力。例如，“五种伪主动性技能”可以改为“五种伪主动性技能有用吗”?\n第六，标题与内容相关\n标题的修改是为了减少搜索引擎中的重复，而不是在修改后改变原文的意思，这样就失去了伪主动性的初衷。不管如何停止修改标题，首先，要忠于原来的标题;第二，我们应该参与更适合读者需求的特色。只有这样，我们才能达到伪主动性的意想不到的结果。\n七、文本内容修正方法\n1.第一段总结:为我写第一段，就像引言一样。如果你有这种精神，阅读完整的文本做一个总结，并把它放在头版。如果你觉得你没有时间阅读它，这也很简单:我编辑了它，必须把它整合到我网站的关键词中;\n②在文本中插入链接锚文本:我想每个人都知道锚文本的作用，它可以帮助提高相关关键词的排名，并且可以在别人收集你的资料时收集锚文本链接，这相当于给你增加了一个外部链条:如果你收集我，我会申请你，这是公平的。每200-300字，可以适当增加2-3个锚文本链接;\n3、尾部总结法:总结整篇文章，其实，关于搜索引擎优化，不仅仅是这些内容，还有小技巧必须注意，玩搜索引擎是一项细致的工作，所以你不仅会做，而且会考虑它。有快速进步和进步的能力，绕过班级;\n④新图片:每个人都会知道一张图片胜过千言万语。当然，目前大多数本地搜索引擎不能读取图片的内容，但是图片中的alt属性可以停止标注，这将给搜索引擎一个新的外观，认为您的内容是新的和包含的;\n⑤段落交换法:这种方法是为了停止内容交换，但注意不要影响原文的阅读。尤其是一种操作方法，绝对不能使用，否则，你知道的。因此，这种方法并不符合一切，应该避免逻辑文章。\n上述伪原创方法可以有效提高内容创作速度，同时拓展内容创作空间，但在进行伪原创时必须注意内容的可读性，而不是简单地用软件替换同义词，打乱段落。尝试将自己的一些观点融入到伪原创中，让伪原创中的内容有一个新的生命，从而为网站质量的提高做出更大的贡献。"
  },
  {
    "objectID": "posts/4da1c86b-86b6-49c6-a581-6289c6635ec7/index.html",
    "href": "posts/4da1c86b-86b6-49c6-a581-6289c6635ec7/index.html",
    "title": "Unlocking the Potential of AI-Assisted Live Streaming and Audience Data",
    "section": "",
    "text": "关于直播的思路\n可以用长音频 长视频替代直播源\nYukio 23:00:49\n这个我还在研究这玩意\n卑劣的写作者 23:01:13\n[图片]\nYukio 23:01:19\n尤其是怎么把别人的皮套拿来当成自己的\nYukio 23:01:44\n追踪虚拟Vtuber的动作然后放到我的皮套上\nYukio 23:02:50\n搞媒体不都靠抄么\nYukio 23:03:38\n你们要是能把别人一个月之前的直播弄下来 视频音频分别杂交处理一下 弄的人看不出来是抄的\n卑劣的写作者 23:03:48\n那不是塞里斯特色媒体吗\nYukio 23:03:50\n你就躺赚啊\ngjz010 23:03:52\n你偷大物皮套感觉会被版权炸弹\ngjz010 23:04:13\n你看即使是怪盗也不敢把自己的皮套偷过来用\ngjz010 23:04:48\n那你还不如用阿b的公用皮套\nYukio 23:04:49\n你随便弄个b站提供的免费皮套\nYukio 23:05:00\n或者原神的\nYukio 23:05:32\n一天换一个啊 肯定有人看的\ngjz010 23:05:44\n也不一定\ngjz010 23:05:58\n皮套有商标的意味\nYukio 23:06:03\n把别人的皮套动作追踪之后 绑定到免费皮套上面\ngjz010 23:06:14\n啥 皮套动作不都是跟着你走的吗\ngjz010 23:06:20\n偷别人的动作有啥用\nYukio 23:06:20\n把别人的中文语音截取下来 随机播放\ngjz010 23:06:30\n你还不如找个ai念\nYukio 23:06:39\n我为什么要绑我的动作\ngjz010 23:06:54\n就是不追踪瞎摇的\ngjz010 23:07:01\n动捕坏了的时候用\nYukio 23:07:08\n我这个不是瞎摇晃\nYukio 23:07:18\n我这个是重播\nYukio 23:07:36\n把别人的动作再播送一遍\nYukio 23:07:49\n所以只要你记忆力没有一个月\nYukio 23:07:59\n没法把全网的直播都看一遍\nYukio 23:08:14\n你不可能知道我究竟这期节目抄的谁\nYukio 23:08:41\n我不仅动作和语音不是一个人 画面也是另外一个人\n卑劣的写作者 23:08:58\n？\nYukio 23:09:12\n我还会把所有和原作者有关的东西自动清除\nYukio 23:09:24\n比如任何QQ号码 任何联系方式\n卑劣的写作者 23:09:26\n这人不能处\nYukio 23:09:37\n任何作者署名\nYukio 23:10:32\n我会把语音变声处理\nYukio 23:11:51\n只要有机会 我直接下载外网twitch直播 把国内的语音放上来 都是同类游戏\nYukio 23:14:06\n我用谷歌翻译流行的游戏名字 拿到外网去搜索\nYukio 23:16:17\n同时我还有一个自动读评论的插件\nYukio 23:16:36\n每隔几分钟读一次 让你们以为这是个真人\nYukio 23:17:03\n我通过图片截图搜索 得到游戏名字\nYukio 23:17:45\n通过相似图片得到关键词 生成标题 主题 标签 分区\nYukio 23:20:47\n皮套人的动作有自动过渡系统\nYukio 23:20:57\n不会出现跳变\nYukio 23:22:47\n利用智能匹配 选取最适合的主题 动作 语音 自动生成连续的内容\n小晴清风揽月 23:24:01\n见到皮套人就恶心\nYukio 23:24:19\n皮套人是资本收割机\nYukio 23:24:38\n可以把处男的jy转化为软妹币\nYukio 23:24:58\n非常的节能环保 非常高效\n重庆人快融化啦 23:26:20\n[图片]\nYukio 23:26:40\n如果我算力充足 完全可以跳出这个抄别人的逻辑 进行完全的所谓原创直播\nYukio 23:27:10\n但是就一台笔记本 抄直播是最为经济有效的\nYukio 23:28:01\n也为之后定制更高端的原创模型打好基础\nYukio 23:30:30\n我可以用观众的弹幕数据作为搜索分类的数据 可以拿来衡量情绪激烈程度\nYukio 23:30:56\n语音数据也是如此\n小晴清风揽月 23:30:56\n你语言混乱，先去看看医生\nYukio 23:31:06\n不需要\nYukio 23:31:28\n觉得我混乱的 你压根还不懂\nYukio 23:31:42\n也就是没想清楚\n小晴清风揽月 23:32:01\n我开玩笑的\n小晴清风揽月 23:32:08\n对不起\n小晴清风揽月 23:32:16\n我只是在学仰山杨爱民说话"
  },
  {
    "objectID": "posts/f51c92c0-ee87-44d6-8fc1-6356d1f6f5b0/index.html#vits变声",
    "href": "posts/f51c92c0-ee87-44d6-8fc1-6356d1f6f5b0/index.html#vits变声",
    "title": "变声软件 Morphvox alternatives",
    "section": "vits变声",
    "text": "vits变声\nhttps://github.com/w4123/vits\n白嫖原神语音 有对如何训练原神语音作出的修改 想白嫖访问demo的api 这个模型读英语不行 可能需要原神英文语音包吧 当然也可以直接考虑变声器模型 读阿拉伯数字也不可以 如何把非汉字内容变为可以读的内容\n阿拉伯数字转汉字 从funnlp看到的\n原神语音包解压\n米游社 原神语音包\nobtain all genshin impact voices in all languages in quotes, with text\ngenshin voice scraper with text, also have scraped voice and text inside\ngenshin limited english voice"
  },
  {
    "objectID": "posts/f51c92c0-ee87-44d6-8fc1-6356d1f6f5b0/index.html#tactron2-变声-训练",
    "href": "posts/f51c92c0-ee87-44d6-8fc1-6356d1f6f5b0/index.html#tactron2-变声-训练",
    "title": "变声软件 Morphvox alternatives",
    "section": "tactron2 变声 训练",
    "text": "tactron2 变声 训练\nMoeTTS是一个Tacotron2/HifiGAN模型+编译好的GUI版本发布仓库 有多个语音包\n项目地址：https://github.com/luoyily/MoeTTS\n主要的vst变声插件：\n变声插件以及其他VST的选择，大家可以参考上一篇专栏，本人现在用的是Avox Mutator调整声调，Little Alterboy调整共振峰的搭配：\ngachikoe! core sign in with pixiv to download for free\nVST机架 变声 设置教程\n需要多个vst插件相互连接\n可能只适合个别声音 如果是野生音源 需要预处理 再进行输入\n本篇教程是上一篇教程的延续，咕咕了大半年的我也做了很多新的尝试，本篇文章包含的内容是：1. 介绍一个免费的更加适合直播用途的机架Cantabile（替代Reaper）；2. 介绍目前咱自己调出来的，可以实现比较自然变声效果的VST链。关于如何使用OBS矫正变声器延迟导致的与模型嘴型、歌回时伴奏不同步的问题，我会在下一期中介绍（我真的不会再咕咕半年了）。\n关于Voicemeeter与声卡配置的补充\n请参照上一期，完成硬件设备以及Voicemeeter Banana的配置（重要！），Reaper的部分用下文的Cantabile代替~\n本文中将会使用上一篇专栏中外置声卡的Asio驱动+第二张声卡（或者使用电脑自带的输出，比如一般电脑都有Realtek High Definition Audio）的方案。打开Voicemeeter的设置界面，在Output A1中点击ASIO设备的名称的话，会跳出声卡的配置界面：\n点击红框处\n声卡配置界面 - 采样率（Sample Rage）\n声卡配置界面 - 缓存大小（Buffer Size）\n采样率建议选择48kHz足够满足直播用途，太高的话会提高音频处理时的资源占用；如果在之后配置完变声器发现有爆音的现象，可以尝试提高Buffer Size（推荐512左右）。需要注意的是，Voicemeeter的ASIO方案虽然效率很高但可能是因为驱动的原因，并不适用于所有声卡，比如Focusrite的Scarlett系列。咱财力有限，只测试了Steinberg的UR系列声卡，不过在官方论坛上暂时也只看到了对Focusrite驱动支持问题的反馈，所以理论上大部分常用的声卡应该没有问题（大概\n至此，前期准备完成！\nCantabile配置\n下载地址：https://www.cantabilesoftware.com/download/\n下载Stable Build并完成安装后，根据自己的操作系统选择运行64位/32位版本，选择Cantabile Lite版本（免费）。如果要求注册账户，按照步骤使用邮箱完成注册后，会在邮箱内收到注册码，使用注册码激活即可。\n选择“Cantabile 3 Lite”\n进入Cantabile后，在菜单中选择Tools→Options，在Audio Engine中选择ASIO - Voicemeeter Virtual ASIO：\nAudio Engine\n将Audio Ports如下图配置（先按照上一篇专栏配置好Voicemeeter哦）：\nAudio Ports\n同时在下面的Plugin Options中选择Add→Browse可以添加自己安装VST插件的文件夹，然后等待扫描完成，这样才可以使用已经安装的插件：\nPlugins Options\n在Cantabile的主界面中黑色部分右键选择Insert Plugin可以插入插件，右键已经插入的插件选择Delete可以删除该插件。实现变声器需要的插件的连接方法也非常简单，从Main Microphone拖出一条线到第一个插件的Stereo / Mono in，再将插件的Stereo / Mono Out连接到下一个插件的Stereo / Mono in，一直到最后一个插件的Stereo / Mono Out连接到Main Speakers。这样连接的原理很简单，就是将一个插件处理完的音频继续交由下一个插件处理，打到叠加的效果。下图是一个示例：\n插件连接示例\n为了方便监听效果，记得按照上一篇教程Voicemeeter配置部分的最后所说，保持Voicemeeter开启，点亮Voicemeeter绿框中的A2与B2，将Main Microphone到Main Speaker的线路连通应该就能从Voicemeeter右上角A2你选择的设备中听到此时经过处理的声音了，如果未连通应该是不会听到任何声音的。\n至此，Cantabile配置完成！\n搭建变声器所需插件\n首先，介绍一下在搭建变声器的过程中需要的插件，下载与购买地址在文章末尾。在保证效果的前提下咱已经尽量把插件的选择精简，比如Waves、Soundtoys、Fabfilter的插件有捆绑包而不需要一个个购买，文章里没有提到的插件大家也可以自己玩一玩。个人的配置方案会在后文贴出：\n（一）变声器插件（当然是必选）\n经过一大堆尝试（Elastique Pitch，KeroVee，Antares Throat，等等…），效果最让咱满意的是来自Soundtoys的Little Alter Boy（售价$99，很贵，某些地方可以搜到Soundtoys的插件合辑但希望大家可以支持正版）。可以用的替代品是插件版的Gachikoe，需要加入作者桜音さち老师的Fanbox才能下载，要求一个月1000日元，下载完了可以取消，同样尽量支持作者~\n变声器插件调节的是人声的音调（Pitch）以及共振峰（Formant）。在很多变声器插件中，Pitch的范围是-12到+12。一个八度有12个半音，从降一个八度到升一个八度，就是-12到+12这个范围的含义。咱推荐把Pitch直接调到+12，因为升高一个八度的话在歌回时不必另外对歌曲进行降调操作。相应的Formant请通过监听自己的声音慢慢调节，一般在3-4左右。如果想要自然一些并且不介意声音低沉一些的话，低一些的Pitch也是可以的。如何在OBS中进行对声音延迟的校正，让变声处理后的声音与耳机里听到的伴奏同步输出咱会写在下一篇专栏里~\n（二）均衡器 / EQ（强烈推荐）\n简单来说，均衡器调整的是各个频段的响度。由于男生和女生发生结构导致的响度分布不同，在调整音调的之前之后，我们都需要用到均衡器，不然可能会导致中频过强等问题。本人用的EQ是Fabfilter Pro Q3。\n（三） 降噪器 / De-noiser（强烈推荐）\n降噪器自然是为了处理噪声。在通过变声器之前，一些噪声可能并不刺耳，甚至可能都不会被注意到，但是在经过了变声器处理后，一些中低频的噪声会随着音调提高而变得刺耳，比如风声和电流声。因此，在声音通过变声器之前咱通常会放一个降噪器。本人用的是Waves WNS 1。\n（四）限制器 / Limiter（强烈推荐）\n限制器是其实可以说是压缩器的一种，将超出声音阈值的部分完全削除。在输出之前加一个-1分贝左右的限制器可以防止爆音以及大音量造成的失真保护观众的耳膜。咱用的是Waves Vcomp压缩器附带的限制器。\n（五）Roth-AIR（推荐）\nRoth-AIR是一个免费的、增加声音“空气感”的插件。本质上来说，应该属于EQ，但是使用非常方便（其实只需要调节一个旋钮）并且效果很好因此单独列出，咱在EQ之后会继续用Roth-Air调节高频。\n（六）齿音消除器 / De-esser（推荐）\n所谓齿音，是在说话或者唱歌时，开口说“嘶”、“次”这些音节时的尖锐声音。这些声音同样也会被变声器放大而变得刺耳。解决方法的方法，一种是使用插件，一种时给麦克风加上防喷网，也可结合使用。咱用的是防喷网+Waves DeEsser。\n（七）压缩器 / Compressor（可选）\n压缩器是当声音强度超过一定阈值时，对超出部分按照一定的比例进行响度衰减，以此减小声音的动态范围，同时不同的压缩器也会给声音带来不同的音染。希望让自己的声音更加饱满或者和麦克风距离忽近忽远导致声音忽大忽小的小伙伴可以尝试一下这类插件。本人在VST链最后加了Waves Vcomp插件。\n介绍完毕，可以正式开工了！\n正式配置变声器\n大致的VST链顺序：\n输入→降噪器→均衡器1→变声器→齿音消除器→EQ2→RothAIR→压缩器→输出\nCantabile配置\n降噪插件的参数可以在自己不说话的情况下，点击频谱图右边的Suggest，会自动适配参数：\nWNS 1 参数设置\n第一个均衡器的配置，个人方案，请根据自己情况调节：\n均衡器参数设置\n变声器的配置，个人方案，请根据自己情况调节：\n变声器配置\n齿音消除器，第二个均衡器，RothAIR以及最后的压缩器参数就不贴图了，各位自己根据自己的声音多做尝试吧~\n变声器教程完结！撒花！\n一些大家可能会问的问题：\nQ：只要有变声器就好了吗？\nA：并不是，想要达到最好的效果还是需要控制自己的说话方式以及呼吸，之后可能会出专门的专栏讨论这个问题。\nQ：这个方案的缺点？\nA：资源占用不低，且有较大的延迟，不适合直播时监听变声过后的效果，因此需要练习把握住自己的语气。至于直播时变声器延迟导致的与伴奏不同步，与模型嘴型不同步我会在下期讲解怎么解决（咕咕咕）。以及，正版的插件价格很贵土真好吃，但还是希望大家尽可能支持正版。至于值不值得，大家可以听一下效果演示再做决定~\nQ：除了文中提到的软件，是否有更好的选择？\nA：有。本人自用的机架是Gig Performer 3（$149），价格贵但是更加稳定，对VST3插件的支持更好。以及，Waves插件之外，iZotope全家桶的效果也很好，但是因为巨大的延迟，比起直播更加适合后期处理，有兴趣和钱的话可以研究一下。\n写在最后的话：\n首先，咱只是一个爱好者，并不是什么后期调音man，甚至耳朵也很木，但我写在这里的是我自己目前为止研究出来的，毫无保留的最佳方案。当然，这个方案有着巨大的改进余地，希望它能抛砖引玉，各位有更好的方案希望能不吝分享。写这篇专栏的原因是在搜寻的过程中看到了不少效果尚不尽如人意的变声器，甚至有打着“免费变声器”、“主播同款”名号的视频，提供QQ群号，提供破解的机架下载，然后推荐声卡，最后再收费调音，被质疑调完音效果仍然不好就消失换个号继续，所谓的演示视频也很明显是由一男一女分开录音的。当然，这些也是个别现象，我还是遇见了很多前辈们有启发性的视频，但大家还是要对这类陷阱提高警惕~\n最后，谢谢看到这里的你！祝早日成为美少女\nSoundtoys官网：\nhttps://www.soundtoys.com/\nGachikoe插件版Fanbox链接：\nhttps://sakuranesachi.fanbox.cc/posts/498211\nRoth-AIR官网：\nhttps://www.danielrothmann.com/#downloads\nFabfilter官网：\nhttps://www.fabfilter.com/\nWaves插件官网：\nhttps://www.waves.com/\nxidada’s tts:\nhttps://huggingface.co/spaces/Xi-JinPing/Xi-JinPing-TTS # remove asterisks!\n哔哩哔哩上看到的免费变声器\n下载地址：\nhttps://yuanqiyinpin.github.io/\n本机架为二次开源软件，优点是占用率滴，不吃电脑配置，上手简单，免费使用\nSoundTouch\n萝莉音 青年音\nhttps://github.com/jrising/pysoundtouch\ngan based voice changer:\nhttps://github.com/yl4579/StarGANv2-VC\ninstall crossover to run windows app on linux\ncompile crossover from source on macos(code avaliable from official website):\nhttps://gist.github.com/Alex4386/4cce275760367e9f5e90e2553d655309\nhttps://www.codeweavers.com/crossover/source\n变声器一般是vst类型的\nrun vst on linux headlessly:\nhttps://github.com/hq9000/cython-vst-loader\nhttps://github.com/hq9000/py_headless_daw\nlinux vst wrapper/bridge:\nhttps://github.com/osxmidi/LinVst\nVST bridge for Windows vst on Linux\nhttps://github.com/abique/vst-bridge\nuse vst 2.4 on macos with obs studio:\nhttps://github.com/obsproject/obs-vst\npyvst vst wrapper for windows:\nhttps://github.com/mbrucher/PyVST\npython vst2 wrapper for windows:\nhttps://pypi.org/project/neil-vst/\nyabridge use windows vst3, vst2 plugins on linux using wine, with reaper:\nhttps://github.com/robbert-vdh/yabridge\nlyrebird voice changer for linux gtk3:\nhttps://github.com/lyrebird-voice-changer/lyrebird\nvoice changer based on MHW Audio Modding Tool (not recommended):\nhttps://github.com/ItsBurpee/MHWVoiceChanger\nmozilla voice changer and visualizer based on web api:\nhttps://github.com/mdn/voice-change-o-matic\nReal time voice changer in python:\nhttps://github.com/symphonly/figaro\nPyvoicechanger:\nhttps://github.com/juancarlospaco/pyvoicechanger\nchange the Pitch of the voice:\nhttps://github.com/wittymindstech/change-voice-pitch\nchange pitch in real time:\nhttps://github.com/jmt329/PitchShifter"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#d-pose-tracker",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#d-pose-tracker",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "3d pose tracker",
    "text": "3d pose tracker\nrendered on unity. needs GPU."
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#sysmocap",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#sysmocap",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "Sysmocap",
    "text": "Sysmocap\nWHAT I WANT FOR (or nearly) requires real 3d models, written in javascript\ncannot output video?\nA cross-platform real-time video-driven motion capture and 3D virtual character rendering system for VTuber/Live/AR/VR.\nDoes not require a discrete graphics card and runs smoothly even on eight-year-old computers"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#vtuber-python-unity",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#vtuber-python-unity",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "Vtuber python unity",
    "text": "Vtuber python unity\nsearch for “vtuber” along with “motion capture” you will get many head-only trackers and renderers for windows but not linux, also some “broadcast templates/frameworks”. many support one single image (anime head + remove background) as input instead of 2d/3d models\nface tracking only, showing face, mouth and eyes, head directions, bind to live2d models"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#虚拟数字人-metahuman",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#虚拟数字人-metahuman",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "虚拟数字人 metahuman",
    "text": "虚拟数字人 metahuman\nNextHuman Beta0.9上线公测，5分钟高品质讲解，带你进入数字人“零门槛”创作新时代，体验直通车 -&gt; https://nexthuman.cn 免费版是Windows上面跑的 需要高端1070显卡"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#anime-character-segmentation",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#anime-character-segmentation",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "anime character segmentation",
    "text": "anime character segmentation\nto remove false positives, make sure we have anime face in view, otherwise mark it as a false positive.\nyou can use anime character recognition like moeflow or opencv anime face detector along with some phash or perceptual hash library to group similar characters, compare perceptual image similarity and line them up in a series.\naniseg, able to segment anime character and head, using mask-rcnn\nyet another anime character segmentation model using solov2 and condinst\nwaifu segmentation\nhigh accuracy anime character segmentation\n自动画漫画 画几笔就成某个人像 动漫头像\nhttps://menyifang.github.io/projects/DCTNet/DCTNet.html\n自动捏脸 gan给人脸戴口罩\nhttps://github.com/futscdav/Chunkmogrify"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#selfie-to-anime-picture-to-anime-photos",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#selfie-to-anime-picture-to-anime-photos",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "selfie to anime, picture to anime photos",
    "text": "selfie to anime, picture to anime photos\nselfie2anime with trained models\n##原神mmd下载模型\n模之屋（需要注册）：\nhttps://www.aplaybox.com/u/680828836\n夕蓝资源网（可直接下载） 也有其他的3d模型可以下载：\nhttps://www.seoliye.com/tags/53.html"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#use-voice-to-power-up-static-images",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#use-voice-to-power-up-static-images",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "use voice to power up static images",
    "text": "use voice to power up static images\nvoice powered animated cartoon figure"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#jeeliz-some-web-deep-learning-runtime-like-tensorflow.js-powered",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#jeeliz-some-web-deep-learning-runtime-like-tensorflow.js-powered",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "jeeliz (some web deep learning runtime, like tensorflow.js) powered",
    "text": "jeeliz (some web deep learning runtime, like tensorflow.js) powered\nweboji, highly similar to animoji, with three.js and cute fox avatar\nface filter, alter the face like putting glass, minor changes to avoid privacy/copyright concerns?"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#openface",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#openface",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "openface",
    "text": "openface\nfacial features extraction"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#facerig",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#facerig",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "facerig",
    "text": "facerig\nfacerig location: /Software/Program Files (x86)/FaceRig\ni’ve seen python code inside facerig.\nfacerig does not offer head-only rendering, but that could be changed i suppose?"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#avatarify-python",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#avatarify-python",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "avatarify python",
    "text": "avatarify python\ninfinite avatars by using style gan, first order motion model\ncreate static portrait avatar (svg?)"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#animoji-from-apple",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#animoji-from-apple",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "animoji from apple",
    "text": "animoji from apple\nfacial landmark detection in python, animoji-animate\nanimoji apple private framework 实际上这个就是之前看到的会动的狗屎的视频来源"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#d模型-皮套-可动-虚拟vtuber-talking-head",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#d模型-皮套-可动-虚拟vtuber-talking-head",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "2d模型 皮套 可动 虚拟Vtuber talking head",
    "text": "2d模型 皮套 可动 虚拟Vtuber talking head\nhttps://github.com/yuyuyzl/EasyVtuber\nhttps://github.com/pkhungurn/talking-head-anime-3-demo\nhttps://github.com/GunwooHan/EasyVtuber"
  },
  {
    "objectID": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#b站官方",
    "href": "posts/a8d57d12-8153-4cfb-a58f-f7ceb2612412/index.html#b站官方",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "b站官方",
    "text": "b站官方\n直播姬现在支持2d面部捕捉 3d模型动作捕捉\n直播姬版本有windows macos(m1) Android版本\n2d模型是live2d的模型\n有待研究"
  },
  {
    "objectID": "posts/10d24df3-6129-4b8b-9cce-4f9dabfff408/index.html",
    "href": "posts/10d24df3-6129-4b8b-9cce-4f9dabfff408/index.html",
    "title": "Exploring Chinese Music Platform APIs and Repositories",
    "section": "",
    "text": "国内音乐平台api\nhttps://listen1.github.io/listen1/\nhttps://github.com/LIU9293/musicafe\nhttps://github.com/872409/music-get\nhttps://github.com/HuberTRoy/MusicBox\nhttps://github.com/caiyonglong/MusicApi\nhttps://github.com/caiyonglong/MusicLake\nhttps://github.com/QiuChenly/QQFlacMusicDownloader\nhttps://github.com/Rain120/qq-music-api\nhttps://github.com/sunzongzheng/musicApi\nhttps://github.com/sunzongzheng/music"
  },
  {
    "objectID": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#时序数据库",
    "href": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#时序数据库",
    "title": "复读机 Chatbot",
    "section": "时序数据库",
    "text": "时序数据库\ntdengine stream processing\ninfluxdb python client"
  },
  {
    "objectID": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#智能问答",
    "href": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#智能问答",
    "title": "复读机 Chatbot",
    "section": "智能问答",
    "text": "智能问答\n智能问答与深度学习 附带代码"
  },
  {
    "objectID": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#近义词",
    "href": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#近义词",
    "title": "复读机 Chatbot",
    "section": "近义词",
    "text": "近义词\nuse wordnet to find hyponyms and antonyms\nfind antonyms for chinese with wordnet\n中文近义词 以及如何扩充词库"
  },
  {
    "objectID": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#话题建模-句向量",
    "href": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html#话题建模-句向量",
    "title": "复读机 Chatbot",
    "section": "话题建模 句向量",
    "text": "话题建模 句向量\n10 nlp libraries\ngensim word2vec\nword embedding using word2vec\ngensym word2vec complete guide\ngo-cqhttp 自定义合并转发消息 生成不存在的合并转发消息\n\n渐进式领红包 对于某个群 先是两分钟（左右）之后领一次 领不到就时间减半下一次再领 如果领到了就不减半 最快6秒领 不能再减了 防止某些群为了检测机器人而发红包\n处理信息不要流水线处理 放在messagepool里面 要有重要度排序 相关性排序\nQQ漂流瓶机器人 捡漂流瓶API\n改回群昵称 总有些脑瘫喜欢给我乱起名 一天检查一次 模仿其他人的群昵称 看看有没有能用的马甲\nmitm Chatbot\n\nchatbot frameworks:\nconvai-bot 1337 the best hybrid convai bot\nomeglemiddleman\nchatterbot able to learn while having conversation\nqary: nlpia-bot a hybrid framework for developing chatbot by mannings\nmitm-omegle watch strangers talk\nai chatbot framework\n\n用sentence bert做search based dialog 替代levenshtein 最好是asymetrical semantic search\n有人有测试红包外挂的红包 可能有“test”、“测试”、“别抢”、“不要”之类的字眼 这种红包不要抢 抢了飞机票\n群聊的下一句话不一定是上一句话的回答 训练模型寻找句子相关性 计算相关度 以及句子顺序\n对接小冰\n管理员/群主在的时候 或者管理员经常出现的群里面 不要冒泡 不然容易被封\n\n转发的图片 至少要在之前一小时以内或更长时间内没有被重复发送才行 同一个信息内也不能出现重复图片 否则不发送这个信息（很有可能是广告）\n有二维码不发送 有网址不发送\n图片里面的文字要是有广告也是不能要的\n文字信息不要广告 用简单分类器\n个性化搜索推荐 elasticsearch\n按照老毛的思想 要一边造谣一边辟谣 一边承认一边否定 同样的话颠三倒四可以说无数遍 也可以选择不说 这样可以和很多的类似故事杂交\n\n处理私聊信息 每回复一个人就清除他的所有历史发言 每隔一段时间处理其中的一个人 不会相互挤占 只有在不闲聊的时候处理私聊信息 特定的人不能进行私聊\n白天聊天 收集数据 晚上离线训练 （此逻辑可以推广到任意的机器学习驱动的平台）\n增加训练数据的context 不要只是一问一答 总语句数量要增加\n占用系统显卡训练的时候 需要专门acquire一个filelock 表示大量资源被占用 系统忙\n选取质量好有情感的聊天样本 长短适中 不要广告不要偏激违禁词 去掉表情包 去掉链接 清洗数据 同时模型用于对话的时候不要输入输出一些违禁词 可以通过话题建模进一步细分归类对话数据之间的联系\n\nschedule the training on minute basis first for complete test, then schedule it on fixed time per day.\nfor qq client: dump 500 continual sentences when adding one new while holding the filelock, do not block or stop running if GPT not responding\nfor gpt2 server: (where to train? how to prevent maching from burning? for how long?)\nrename the dataset while holding the filelock\nalways keep the latest 2 models, remove those not readable first, then delete older ones.\nif train on CPU, still need to limit training time, sleep while doing so. GPU for sure we need sleep during training, and do not use VRAM for other applications.\n\n把”汪汪”翻译成表情包 同时可以随机添加其他表情\n根据实时群聊数据训练gpt2\n根据离线群聊数据训练gpt2\n\n自动骂人\nhttps://github.com/liuke-wuhan/ZuAnBot\n\n添加一个FileLock在gpt2 main server里面 不要让多个对话同时进行处理\n在人多的群里面少说话 具体表现为每次说话的时间间隔变长 次数变少 同时要注意 聊天内容过于严肃 专业的群尽量不要水\n\ndialogpt documentation\n闲聊chitchat dialog bot training framework by facebook:\nhttps://github.com/facebookresearch/ParlAI\ndebug the consecutive group reply thresholding protocol\nreply according to individual description and group description\n\n同时推广自己和别人的视频或者内容 收集推荐反馈 同时逐步减小推荐别人视频或者内容的频率\n推广视频的时候可以加入别人的视频高赞评论 动态的GIF 音频 或者是短视频 然后再发送xml\n增加复读图片的功能 增加chatlocal返回图片的功能\n增加反馈功能 根据发言之后群里面的回复来确定发言是否有益\n用txtai或者其他information retrieval (semantic search, smart search)语义查找工具来代替levenshtein的history based reply logic 查找时要包括上下文\n复读机不能使得死群活起来 但是主动推送可以 推送长的 自言自语的对话到群里面 不能是同一个群 主题要相关 filter out too negative ones\n拉人到别的群里面来 最好是多个号不共享群但是话题有交集的人\nadd involution option, allow to append unqualified replies to input message, separated by space.\nadd extend conversation option, allow to reply more than one sentence at a time (proper delay needed) -&gt; could be achieved by using GPT2 alike generation model\n可以给群友点赞\n可以发语音\n\n每次对话输入的context不能太小 不然看起来假\n\n添加复读原句子的功能 触发条件为sentiment\n\n往群里面发b站视频广告的话 最好和群聊主题相关 和最近接收到的消息相关 同时频率不能太高 要设置全局的counter 群聊每发送一条消息trigger一次counter counter mod period == 0 的时候就执行发广告命令 同时可以考虑渲染任务 和发广告的逻辑要解耦合 同时访问一片数据 比如redis 根据最近聊到的内容制作和上传视频 不能在同一个群里面以太快的频率发送相同视频 相同的视频必须间隔一段时间再往其他群发送 最好用schedule库实现 方法内部要实现delay或者放弃schedule的效果\n如果群聊被踢 可以考虑换头像 换昵称 更改个人资料 然后重新申请 同样可以考虑更改b站的信息 用外网网红信息来填充自己的信息 更改资料频率和申请频率都需要控制 需要单独设置每天的quota quota保存在文件里面 申请的信息最好用ai生成 或者paraphrase一下 或者到网上搜索 收集相关内容 先训练一下 头像可以全网到处爬 可以选择二次元头像（动漫头识别）对比度高的 可以是类似头像 不能是系统默认头像不然太过无聊 可以和群聊主题相关 资料抄别人的 别的群里面的 抄该群群成员的资料 或者别的群的资料 不能是管理员资料\n\n根据模板生成下一句 不要直接生成 素材可以是群公告 群主题 接收到的信息\n\n模板生成要和新词发现结合\n模板生成 paraphraser可以和chatlocal或者repeater结合\n&gt;&gt;&gt; import re\n&gt;&gt;&gt; re.split(r\"(abc|acd)\",\"aaabcaaacdaaa\")\n['aa', 'abc', 'aa', 'acd', 'aaa']\n&gt;&gt;&gt; word=\"aaabcaaacdaaa\"\n&gt;&gt;&gt; word=\"aaabcaaacdaaa\"\n&gt;&gt;&gt; re.escape(\"abc\")\n'abc'\n&gt;&gt;&gt; re.escape(\"efgh\")\n'efgh'\n&gt;&gt;&gt;\n可以拆分句子为列表\n\n去除经常生成的话语 比如你好之类的\n\n挑选levenshtein距离大于0（不能是它本身）的上一句，排序 选择10句 根据情绪激烈程度（正负皆可 去掉过于负面的）排序 输出第一名 选择下一句作为回答 然后记录这个回答在机器人的回答历史中\n句子如果是取同一个group里面的 不能太recent 起码距离要有50个句子的距离\n文字 图片 视频 都可以搜索百度 搜狗 中文搜索api 根据相关度和情绪来排序 （语种一致）回答文字或者多媒体\n拆分大句子为小句子 依次放入 注意要过滤掉广告 一般广告比较长 有链接？\n\n输入的内容不能有违禁词否则不回答\n输出内容的时候不能有违禁词语 放进来的可以违禁 或者用拼音或者拆字转换这些违禁词语 保证上下文一致性 文本审查\n\nbad chinese -&gt; letter(pinyin initials) -&gt; leetspeek\n下一次挑选的时候自动过滤掉这些下一句在历史回答里面的句子对\n那个lock 要限制自身的读取/删除操作以及新消息的append操作\n\n关于情绪激烈程度 如何提高生成器的情绪激烈度 做一个鉴别器 可以选择性的不去back propagate情绪不激烈的生成结果 或者直接用鉴别器筛选输入的语料"
  },
  {
    "objectID": "posts/98600563-18b6-4d0f-a6e6-b87bd6749c21/index.html",
    "href": "posts/98600563-18b6-4d0f-a6e6-b87bd6749c21/index.html",
    "title": "如何永久的影响世界",
    "section": "",
    "text": "如何永久的影响世界 剧本\n核弹\n权力\n大量金钱\n基因改造\n革命性技术\n大众传媒\n大规模战争\n永生\n时空穿越\n和外星文明交流\n编程\n宗教\n语言\nfeedback:\n不结婚 不生娃\n数学\n喝酒\n用人\n忠诚\n领导力\n智慧\n人类思想\n人类本性\n一句话改变世界"
  },
  {
    "objectID": "posts/1c7b1977-d706-4c3d-9763-c467e44bce8a/index.html",
    "href": "posts/1c7b1977-d706-4c3d-9763-c467e44bce8a/index.html",
    "title": "床上用键盘的技巧：垫枕头",
    "section": "",
    "text": "通过在腿的两侧添加两个枕头 成功解决因为天气寒冷被子加厚导致被子压手 没有空间在键盘上面打字的问题 一定程度上也解决了被子压脚的问题"
  },
  {
    "objectID": "posts/1ab8a036-bc60-4192-9623-d79e6de9f60c/index.html",
    "href": "posts/1ab8a036-bc60-4192-9623-d79e6de9f60c/index.html",
    "title": "影视聚合 社交聚合 网盘聚合搜索引擎",
    "section": "",
    "text": "1、云铺子 - 百度网盘搜索引擎\n地址：http://www.yunpz.net/\n查看方式：直接打开\n推荐指数：★★★★★\n备注：聚合类，体验好，推荐！\n2、橘子盘搜-好用的影视资源搜索引擎\n地址：https://www.nmme.cc/\n查看方式：直接打开\n推荐指数：★★★★★\n备注：专攻影视搜索，度盘、迅雷、阿里，体验好，推荐！\n3、优聚搜\n地址：https://ujuso.com/\n查看方式：直接打开\n推荐指数：★★★★★\n备注：支持度盘、蓝奏、阿里，体验好，推荐！\n4、蓝瘦网盘在线搜索网页版\n地址：http://www.sixyin.com/disk-search\n查看方式：直接打开\n推荐指数：★★★★☆\n备注：蓝奏云搜索，推荐！\n5、阿里盘搜 - 阿里云盘资源搜索神器\n地址：https://www.alipanso.com/\n查看方式：直接打开\n推荐指数：★★★★☆\n备注：阿里盘搜索，推荐！\n6、懒盘搜索聚合官网\n地址：https://lzpan.com/\n查看方式：各种都有\n推荐指数：★★★★☆\n备注：聚合类，含16个搜索引擎\n7、超能搜 - 百度网盘搜索神器\n地址：http://www.chaonengso.com/\n查看方式：各种都有\n推荐指数：★★★★☆\n备注：聚合类，含18个搜索引擎\n8、万网搜 - 资源搜索聚合神器\n地址：http://www.wanwangsou.com/\n查看方式：各种都有\n推荐指数：★★★★☆\n备注：聚合类，含15个搜索引擎\n9、云盘狗-百度云网盘搜索\n地址：http://www.yunpangou.com/\n查看方式：直接打开\n推荐指数：★★★☆☆\n10、学搜搜\n地址：http://www.xuesousou.com/\n查看方式：直接打开\n推荐指数：★★★☆☆\n备注：学习资源搜索\n11、盘131 - 云盘资源搜索引擎\n地址：https://www.pan131.com/\n查看方式：直接打开\n推荐指数：★★★☆☆\n12、58网盘搜索\n地址：https://www.58wangpan.com/\n查看方式：直接打开\n推荐指数：★★★☆☆\n13、56网盘搜索\n地址：https://www.56wangpan.net/\n查看方式：直接打开\n推荐指数：★★★☆☆\n14、一个好用的网盘搜索引擎 - 乌鸦搜\n地址：https://www.wuyasou.com/\n查看方式：直接打开\n推荐指数：★★★☆☆\n15、bdy搜\n地址：http://www.bdyso.com/\n查看方式：直接打开\n推荐指数：★★★☆☆"
  },
  {
    "objectID": "posts/c8447714-0793-4bd9-875e-75b8618e256a/index.html#notice",
    "href": "posts/c8447714-0793-4bd9-875e-75b8618e256a/index.html#notice",
    "title": "微软小冰 机器人 用requests库访问最好",
    "section": "notice",
    "text": "notice\nwhen using this, first extract topic from recent chats or group name, then send message.\nor you just use the default topic. whatever."
  },
  {
    "objectID": "posts/c8447714-0793-4bd9-875e-75b8618e256a/index.html#client",
    "href": "posts/c8447714-0793-4bd9-875e-75b8618e256a/index.html#client",
    "title": "微软小冰 机器人 用requests库访问最好",
    "section": "client",
    "text": "client\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; r = requests.get(\"http://localhost:8735/chat\",params={\"topic\":\"python\",\"message\":\"吃了没有\"})\n&gt;&gt;&gt; r.json()\n{'msg': 'success', 'reply': '你这么一说，我好像是有点饿'}\n&gt;&gt;&gt; exit()"
  },
  {
    "objectID": "posts/c8447714-0793-4bd9-875e-75b8618e256a/index.html#server",
    "href": "posts/c8447714-0793-4bd9-875e-75b8618e256a/index.html#server",
    "title": "微软小冰 机器人 用requests库访问最好",
    "section": "server",
    "text": "server\nlocation: /root/Desktop/works/pyjom/tests/microsoft_xiaobing_conversation_bing/chat_with_session_id.js\nvar request = require(\"request\");\n// var mysqld = require(\"./mysql\");\n// const { init: initDB, Counter, Chatid } = require(\"./db\");\nfunction getRequestId() {\nreturn (ot() + ot() + ot() + ot() + ot() + ot() + ot() + ot()).toLowerCase();\n}\nconst sleep = (ms) =&gt; {\nreturn new Promise(resolve =&gt; setTimeout(resolve, ms))\n}\nfunction ot() {\nreturn (((1 + Math.random()) * 65536) | 0).toString(16).substring(1);\n}\nfunction i(n, i) {\nfor (\nvar s, c, e = 4, l = i.length / e - 1, r = [\n[],\n[],\n[],\n[]\n], o = 0; o &lt; 4 * e; o++\n)\nr[o % 4][Math.floor(o / 4)] = n[o];\nfor (r = t(r, i, 0, e), s = 1; s &lt; l; s++)\n(r = u(r, e)), (r = f(r, e)), (r = h(r, e)), (r = t(r, i, s, e));\nfor (\nr = u(r, e), r = f(r, e), r = t(r, i, l, e), c = new Array(4 * e), o = 0; o &lt; 4 * e; o++\n)\nc[o] = r[o % 4][Math.floor(o / 4)];\nreturn c;\n}\nfunction u(n, t) {\nfor (var r, i = 0; i &lt; 4; i++)\nfor (r = 0; r &lt; t; r++) n[i][r] = o[n[i][r]];\nreturn n;\n}\nfunction f(n, t) {\nfor (var i, u = new Array(4), r = 1; r &lt; 4; r++) {\nfor (i = 0; i &lt; 4; i++) u[i] = n[r][(i + r) % t];\nfor (i = 0; i &lt; 4; i++) n[r][i] = u[i];\n}\nreturn n;\n}\nfunction h(n) {\nfor (var t, r, u, i = 0; i &lt; 4; i++) {\nfor (t = new Array(4), r = new Array(4), u = 0; u &lt; 4; u++)\n(t[u] = n[u][i]),\n(r[u] = n[u][i] & 128 ? (n[u][i] &lt;&lt; 1) ^ 283 : n[u][i] &lt;&lt; 1);\nn[0][i] = r[0] ^ t[1] ^ r[1] ^ t[2] ^ t[3];\nn[1][i] = t[0] ^ r[1] ^ t[2] ^ r[2] ^ t[3];\nn[2][i] = t[0] ^ t[1] ^ r[2] ^ t[3] ^ r[3];\nn[3][i] = t[0] ^ r[0] ^ t[1] ^ t[2] ^ r[3];\n}\nreturn n;\n}\nfunction t(n, t, i, r) {\nfor (var f, u = 0; u &lt; 4; u++)\nfor (f = 0; f &lt; r; f++) n[u][f] ^= t[i * 4 + f][u];\nreturn n;\n}\nfunction e(n) {\nfor (var t = 0; t &lt; 4; t++) n[t] = o[n[t]];\nreturn n;\n}\nfunction c(n) {\nfor (var i = n[0], t = 0; t &lt; 3; t++) n[t] = n[t + 1];\nreturn (n[3] = i), n;\n}\nfunction rr(n) {\nfor (\nvar h,\ni,\no = 4,\nr = n.length / 4,\ns = r + 6,\nf = new Array(o * (s + 1)),\nu = new Array(4),\nt = 0; t &lt; r; t++\n)\n(h = [n[4 * t], n[4 * t + 1], n[4 * t + 2], n[4 * t + 3]]), (f[t] = h);\nfor (t = r; t &lt; o * (s + 1); t++) {\nfor (f[t] = new Array(4), i = 0; i &lt; 4; i++) u[i] = f[t - 1][i];\nif (t % r == 0)\nfor (u = e(c(u)), i = 0; i &lt; 4; i++) u[i] ^= l[t / r][i];\nelse r &gt; 6 && t % r == 4 && (u = e(u));\nfor (i = 0; i &lt; 4; i++) f[t][i] = f[t - r][i] ^ u[i];\n}\nreturn f;\n}\nfunction r(n) {\nfor (\nvar h,\ni,\no = 4,\nr = n.length / 4,\ns = r + 6,\nf = new Array(o * (s + 1)),\nu = new Array(4),\nt = 0; t &lt; r; t++\n)\n(h = [n[4 * t], n[4 * t + 1], n[4 * t + 2], n[4 * t + 3]]), (f[t] = h);\nfor (t = r; t &lt; o * (s + 1); t++) {\nfor (f[t] = new Array(4), i = 0; i &lt; 4; i++) u[i] = f[t - 1][i];\nif (t % r == 0)\nfor (u = e(c(u)), i = 0; i &lt; 4; i++) u[i] ^= l[t / r][i];\nelse r &gt; 6 && t % r == 4 && (u = e(u));\nfor (i = 0; i &lt; 4; i++) f[t][i] = f[t - r][i] ^ u[i];\n}\nreturn f;\n}\nfunction a(n, t, u) {\nvar c = 16,\na,\ny,\nl,\nw,\no,\ne,\nf,\nnt;\nif (!(u == 128 || u == 192 || u == 256)) return \"\";\nfor (n = s(n), t = s(t), a = u / 8, y = new Array(a), f = 0; f &lt; a; f++)\ny[f] = isNaN(t.charCodeAt(f)) ? 0 : t.charCodeAt(f);\nl = i(y, rr(y));\nl = l.concat(l.slice(0, a - 16));\nvar h = new Array(c),\nk = new Date().getTime(),\ntt = k % 1e3,\nit = Math.floor(k / 1e3),\nrt = Math.floor(Math.random() * 65535);\nfor (f = 0; f &lt; 2; f++) h[f] = (tt &gt;&gt;&gt; (f * 8)) & 255;\nfor (f = 0; f &lt; 2; f++) h[f + 2] = (rt &gt;&gt;&gt; (f * 8)) & 255;\nfor (f = 0; f &lt; 4; f++) h[f + 4] = (it &gt;&gt;&gt; (f * 8)) & 255;\nfor (w = \"\", f = 0; f &lt; 8; f++) w += String.fromCharCode(h[f]);\nvar ut = rr(l),\nb = Math.ceil(n.length / c),\nd = new Array(b);\nfor (o = 0; o &lt; b; o++) {\nfor (e = 0; e &lt; 4; e++) h[15 - e] = (o &gt;&gt;&gt; (e * 8)) & 255;\nfor (e = 0; e &lt; 4; e++) h[11 - e] = (o / 4294967296) &gt;&gt;&gt; (e * 8);\nvar ft = i(h, ut),\ng = o &lt; b - 1 ? c : ((n.length - 1) % c) + 1,\np = new Array(g);\nfor (f = 0; f &lt; g; f++)\n(p[f] = ft[f] ^ n.charCodeAt(o * c + f)),\n(p[f] = String.fromCharCode(p[f]));\nd[o] = p.join(\"\");\n}\nreturn (nt = w + d.join(\"\")), v(nt);\n}\nfunction v(n) {\nfor (\nvar i = \"0x\",\nr = [\n\"0\",\n\"1\",\n\"2\",\n\"3\",\n\"4\",\n\"5\",\n\"6\",\n\"7\",\n\"8\",\n\"9\",\n\"a\",\n\"b\",\n\"c\",\n\"d\",\n\"e\",\n\"f\",\n],\nt = 0; t &lt; n.length; t++\n)\ni += r[n.charCodeAt(t) &gt;&gt; 4] + r[n.charCodeAt(t) & 15];\nreturn i;\n}\nfunction s(n) {\nvar t = n.replace(/[\\u0080-\\u07ff]/g, function(n) {\nvar t = n.charCodeAt(0);\nreturn String.fromCharCode(192 | (t &gt;&gt; 6), 128 | (t & 63));\n});\nreturn t.replace(/[\\u0800-\\uffff]/g, function(n) {\nvar t = n.charCodeAt(0);\nreturn String.fromCharCode(\n224 | (t &gt;&gt; 12),\n128 | ((t &gt;&gt; 6) & 63),\n128 | (t & 63)\n);\n});\n}\nvar o = [\n99, 124, 119, 123, 242, 107, 111, 197, 48, 1, 103, 43, 254, 215, 171, 118,\n202, 130, 201, 125, 250, 89, 71, 240, 173, 212, 162, 175, 156, 164, 114,\n192, 183, 253, 147, 38, 54, 63, 247, 204, 52, 165, 229, 241, 113, 216, 49,\n21, 4, 199, 35, 195, 24, 150, 5, 154, 7, 18, 128, 226, 235, 39, 178, 117, 9,\n131, 44, 26, 27, 110, 90, 160, 82, 59, 214, 179, 41, 227, 47, 132, 83, 209,\n0, 237, 32, 252, 177, 91, 106, 203, 190, 57, 74, 76, 88, 207, 208, 239, 170,\n251, 67, 77, 51, 133, 69, 249, 2, 127, 80, 60, 159, 168, 81, 163, 64, 143,\n146, 157, 56, 245, 188, 182, 218, 33, 16, 255, 243, 210, 205, 12, 19, 236,\n95, 151, 68, 23, 196, 167, 126, 61, 100, 93, 25, 115, 96, 129, 79, 220, 34,\n42, 144, 136, 70, 238, 184, 20, 222, 94, 11, 219, 224, 50, 58, 10, 73, 6,\n36, 92, 194, 211, 172, 98, 145, 149, 228, 121, 231, 200, 55, 109, 141, 213,\n78, 169, 108, 86, 244, 234, 101, 122, 174, 8, 186, 120, 37, 46, 28, 166,\n180, 198, 232, 221, 116, 31, 75, 189, 139, 138, 112, 62, 181, 102, 72, 3,\n246, 14, 97, 53, 87, 185, 134, 193, 29, 158, 225, 248, 152, 17, 105, 217,\n142, 148, 155, 30, 135, 233, 206, 85, 40, 223, 140, 161, 137, 13, 191, 230,\n66, 104, 65, 153, 45, 15, 176, 84, 187, 22,\n],\nl = [\n[0, 0, 0, 0],\n[1, 0, 0, 0],\n[2, 0, 0, 0],\n[4, 0, 0, 0],\n[8, 0, 0, 0],\n[16, 0, 0, 0],\n[32, 0, 0, 0],\n[64, 0, 0, 0],\n[128, 0, 0, 0],\n[27, 0, 0, 0],\n[54, 0, 0, 0],\n];\n// n.encrypt = a\nasync function iceAI_word(\n// ToUserName,\n// FromUserName,\n// CreateTime,\n// MsgType,\nContent,\nconfig\n// MsgId,\n) {\nawait sleep(1000);\n// for whatever reason you have to wait for this long.\ntry{\nvar wquery = a(Content, \"3d9d5f16-5df0-43d7-902e-19274eecdc41\", 256);\nconsole.log(\"encrypt:\" + wquery);\n// let config = {};\n// if ((await mysqld.isHaveChatIdIn(fromQQ)) == true) {\n//     console.log(\"没有chatid，获取新id\")\n//     config = await mysqld.getChatId(fromQQ);\n// } else {\n//     config = await newChatId(fromQQ);\n// }\nif (config) {\nconsole.log(\"config:\" + config);\n} else {\nconsole.log('no config for xiaoice chat.')\nreturn;\n}\nvar h = {\nzoTextResponse: \"\",\nzoIsGCSResponse: false,\nzoSearchQuery: \"hhh\",\nzoTimestampUtc: \"\",\nzoIsStartOfSession: true,\nzoRequestId: getRequestId(),\nconversationId: config.conversationId,\nquery: { NormalizedQuery: wquery },\nfrom: \"chatbox\",\ntraceId: config.traceId,\n};\nvar url = \"https://cn.bing.com/english/zochatv2?cc=cn&ensearch=0\";\n// {\"zoTextResponse\":\"\",\"zoIsGCSResponse\":\"false\",\"zoSearchQuery\":\"123\",\"zoTimestampUtc\":\"\",\"zoIsStartOfSession\":\"true\",\"zoRequestId\":\"ff90e6f70a6048d4fe5cc3c3327bbd32\",\"conversationId\":\"4a91fb33-73f7-43d4-b7b6-ba86a16e32fb\",\"query\":{\"NormalizedQuery\":\"0x23028811be44f661169365\"},\"from\":\"chatbox\",\"traceId\":\"B224B190F87941CD94AD0AC31A189D30\"}\nlet result = await getContents({\nurl: url,\nmethod: \"POST\",\nheaders: {\n\"content-type\": \"text/plain;charset=UTF-8\",\norigin: \"https://cn.bing.com\",\nreferer: \"https://cn.bing.com/search?q=123&form=QBLH&sp=-1&pq=123&sc=6-3&qs=n&sk=&cvid=566F001FDA424EEB805E1C175363B5AE\",\n\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\",\nConnection: \"keep-alive\",\n},\nbody: JSON.stringify(h),\n});\n// {\"content\":\"嘿 啾 嘿 啾啊\",\"type\":1,\"delayContents\":null,\"entityInfo\":[{\"Entity\":\"嘿 啾 嘿 啾啊\",\"IsEntity\":false}],\"target\":\"b\",\"history\":null,\"hasClientIdinMem\":true,\"needSayHello\":false,\"isHookStr\":false,\"showChatBox\":true,\"metadata\":{\"AnswerFeed\":\"RandomChitChatService\",\"EmotionInfo\":\"{\\\"EmotionClassificationInfo\\\":[{\\\"Category\\\":\\\"Sad\\\",\\\"Score\\\":0.0651140139},{\\\"Category\\\":\\\"Happy\\\",\\\"Score\\\":0.139467061},{\\\"Category\\\":\\\"Surprise\\\",\\\"Score\\\":0.176786855},{\\\"Category\\\":\\\"Angry\\\",\\\"Score\\\":0.358794},{\\\"Category\\\":\\\"Disgust\\\",\\\"Score\\\":0.2598381}],\\\"NeutralScore\\\":0.9992748,\\\"DomainInMatchScenario\\\":\\\"None\\\"}\"}}\nresult = JSON.parse(result);\nif (result.content) {\nvar reply = result.content;\nreply = reply.replace(\"小冰\", \"小姝\");\nvar message = 1;\nvar unuseless =\n\"看的我一脸懵逼，都开始怀疑我的智商了。哎呀，不好意思，我刚刚好像走神了,感觉你知道的挺多的呢,额，我现在也不知道该说些什么,这个…不太好说啊,我语文不太好，不确定是不是懂了你的意思,刚刚不小心溜号了，真是不好意思\";\nif (unuseless.indexOf(reply) != -1) {\nconsole.log('xiaoice is returning useless reply', reply)\n//   message = 2;\n//   Log.trace(\"iceAi have unuseless message\");\n//   request(\n//     {\n//       url:\n//         \"http://api.qingyunke.com/api.php?key=free&appid=0&msg=\" +\n//         encodeURIComponent(msg2),\n//       method: \"GET\",\n//     },\n//     function (error, response, body) {\n//       var result = JSON.parse(body);\n//       reply = result.content;\n//       var logtext = \"\";\n//       return;\n//     }\n//   );\n} else {\nreturn reply;\n}\n}\n} catch(e){\nconsole.log('ERROR FETCHING XIAOBING CHAT',e)\n// will return nothing.\n// sleep for 1 second?\n// would you sleep for a while?\n}\n}\nasync function newChatId(query) {\nvar options = options || {};\nvar httpOptions = {\nurl: \"https://cn.bing.com/search?q=\"+query+\"&form=QBLH&rdr=1&rdrig=E8F3C1A722454F949CCC4B98C4570A4A\",\nmethod: \"get\",\ntimeout: 1000,\nheaders: {\naccept: \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n\"accept-language\": \"zh-CN,zh;q=0.9\",\n\"cache-control\": \"max-age=0\",\n\"sec-ch-ua\": '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"102\", \"Google Chrome\";v=\"102\"',\n\"sec-ch-ua-arch\": '\"x86\"',\n\"sec-ch-ua-bitness\": '\"64\"',\n\"sec-ch-ua-full-version\": '\"102.0.5005.63\"',\n\"sec-ch-ua-mobile\": \"?0\",\n\"sec-ch-ua-model\": '\"\"',\n\"sec-ch-ua-platform\": '\"Windows\"',\n\"sec-ch-ua-platform-version\": '\"10.0.0\"',\n\"sec-fetch-dest\": \"document\",\n\"sec-fetch-mode\": \"navigate\",\n\"sec-fetch-site\": \"same-origin\",\ncookie: \"MUID=005F25E7699168532D05342768F769B3; MUIDB=005F25E7699168532D05342768F769B3; _EDGE_V=1; SRCHD=AF=NOFORM; SRCHUID=V=2&GUID=31127A3BD4B84FF08E8E51EEEA34857F&dmnchg=1; _UR=QS=0&TQS=0; _HPVN=CS=eyJQbiI6eyJDbiI6MSwiU3QiOjAsIlFzIjowLCJQcm9kIjoiUCJ9LCJTYyI6eyJDbiI6MSwiU3QiOjAsIlFzIjowLCJQcm9kIjoiSCJ9LCJReiI6eyJDbiI6MSwiU3QiOjAsIlFzIjowLCJQcm9kIjoiVCJ9LCJBcCI6dHJ1ZSwiTXV0ZSI6dHJ1ZSwiTGFkIjoiMjAyMi0wNi0xMVQwMDowMDowMFoiLCJJb3RkIjowLCJHd2IiOjAsIkRmdCI6bnVsbCwiTXZzIjowLCJGbHQiOjAsIkltcCI6NH0=; SUID=M; SRCHUSR=DOB=20220611&T=1659599964000&TPC=1659599966000; ZHCHATSTRONGATTRACT=TRUE; ZHCHATWEAKATTRACT=TRUE; _EDGE_S=SID=05C5058B7100688001DB147D702E698C; _SS=SID=05C5058B7100688001DB147D702E698C; _tarLang=default=zh-Hans; _TTSS_IN=hist=WyJlbiIsImF1dG8tZGV0ZWN0Il0=; _TTSS_OUT=hist=WyJ6aC1IYW5zIl0=; ipv6=hit=1659603639345&t=4; SNRHOP=I=&TS=; SRCHHPGUSR=SRCHLANG=zh-Hans&BRW=NOTP&BRH=S&CW=599&CH=657&SW=1366&SH=768&DPR=1&UTC=480&DM=0&PV=0.3.0&BZA=0&HV=1659600073&WTS=63795196764\",\n\"sec-fetch-user\": \"?1\",\naccept: \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n\"accept-language\": \"zh-CN,zh;q=0.9\",\n\"cache-control\": \"max-age=0\",\n\"upgrade-insecure-requests\": \"1\",\nReferer: \"referer: https://cn.bing.com/search?q=\"+query+\"&form=QBLHCN&sp=-1&pq=a&sc=6-1&qs=n&sk=&cvid=A91AB41228AD45E694D5F2EEBF87FE70\",\n\"Referrer-Policy\": \"strict-origin-when-cross-origin\",\n\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36\",\n},\n};\nlet body = await getContents(httpOptions)\n//console.log(body)\nif (body.indexOf(\"conversationId\") == -1) {\nconsole.log(\"请求chatid失败\");\nreturn;\n}\nconsole.log(body.indexOf(\"conversationId\"));\nconsole.log(body.indexOf(\"iframeTalkStatus\"));\nlet config =\n'{\"' +\nbody.substring(\nbody.indexOf(\"conversationId\"),\nbody.indexOf(\"iframeTalkStatus\")\n) +\n'\":\"\"}';\nconfig = JSON.parse(config);\nconsole.log(config);\n// mysqld.addChatId(fromQQ, config);\nreturn config;\n}\nasync function getAuth(opts, redis) {\ncookie = await post(opts);\n//redis.set(\"ice_cookie\", cookie)\nlog.info(\"new cookie:\" + cookie);\nreturn cookie;\n}\nfunction post(opts) {\nreturn new Promise((resolve, reject) =&gt; {\nrequest(opts, function(error, response) {\nif (error) throw new Error(error);\nif (response.statusCode != \"200\") {\nconsole.log(\"requestCode:\" + response.statusCode);\n}\nconsole.log(\"requestCode:\" + response.statusCode);\nvar responseCookies = response.headers[\"set-cookie\"];\nconsole.log(response.body);\nvar requestCookies = \"\";\nfor (var i = 0; i &lt; responseCookies.length; i++) {\nvar oneCookie = responseCookies[i];\noneCookie = oneCookie.split(\";\");\nrequestCookies = requestCookies + oneCookie[0] + \";\";\n}\nresolve(requestCookies);\n});\n});\n}\nfunction getContents(opts) {\nreturn new Promise((resolve, reject) =&gt; {\nrequest(opts, function(error, response) {\nif (error) reject(error);\nif (response.statusCode != \"200\") {\nconsole.log(\"requestCode:\" + response.statusCode);\n}\nconsole.log(\"requestCode:\" + response.statusCode);\nvar responseCookies = response.headers[\"set-cookie\"];\nresolve(response.body);\n});\n});\n}\n// module.exports = { iceAI_word };\n// let test_request = \"不会吧\"\n// let test_request = \"python\"\nconst http = require('http');\nfunction getQueryParams(reqUrl) {\ncurrent_url = new URL('http://localhost' + reqUrl)\nparams = current_url.searchParams\nconsole.log('query parameters:', params)\nreturn params\n}\nlet topic_chatId_dict = {}\nconst requestListener = function (req, res){\nconsole.log(\"________________________________________________\")\nconsole.log(\"REQUEST AT:\", req.url, req.method)\nif (req.url == \"/\") {\nres.writeHead(200);\nres.end('xiaoice chat server');\n} else if (req.url.split(\"?\")[0] == '/chat'){\ncallback = (result) =&gt; {\nres.writeHead(200);\ncontent = {\"msg\": 'success','reply': result}\nres.end(JSON.stringify(content))\n}\nparams = getQueryParams(req.url)\nmessage =params.get(\"message\")\ntopic = params.get(\"topic\")\nif (message==null){\nmessage = \"你好呀\"\n}\nif (topic == null){\ntopic = \"hhh\"\n}\nconsole.log(\"MESSAGE:\", message)\nconsole.log(\"TOPIC:\", topic)\nif (topic_chatId_dict[topic] == null){\ntopic_chatId_dict[topic] = newChatId(topic)\n}\nchatId = topic_chatId_dict[topic]\nif (chatId !=null){\nresponse = iceAI_word(message, chatId)\nresponse.then((content) =&gt; {\nconsole.log(\"REAL RESPONSE:\", content)\nif (content !=null){\ncallback(content)\n}else{\nres.writeHead(401);\nres.end(JSON.stringify({'msg':'empty response from microsoft xiaoice'}))\n}\n})\n}else{\nres.writeHead(401)\nres.end(JSON.stringify({'msg':'error when getting chatid'}))\n}\n}else{\nres.writeHead(400);\nres.end('please use /chat?topic={topic}&message={message} to chat with xiaoice.')\n}\n}\nconst server = http.createServer(requestListener);\nport = 8735\nserver.listen(port);\nconsole.log('xiaoice server running on http://localhost:' + port);\n// // these code are just for test.\n// let test_request = \"你吃了没有\"\n// // let test_request2 = \"你吃了没有\"\n// query = 'python'\n// let config = newChatId(query)\n// response = iceAI_word(test_request, config) // automatically retry once. if keeping generating useless shits, we may decide to give it up?\n// // it is a promise.\n// // this is async shit.\n// // what if there's some error?\n// response.then((content) =&gt; {console.log(\"REAL RESPONSE:\", content)})\n// // REAL RESPONSE: 不想就不说了\n// // console.log(\"RESPONSE:\", response)\n// // response = iceAI_word(test_request2, config)\n// // console.log(\"RESPONSE:\", response)"
  },
  {
    "objectID": "posts/b876a672-24c2-4589-a254-43fac776304d/index.html#注意事项",
    "href": "posts/b876a672-24c2-4589-a254-43fac776304d/index.html#注意事项",
    "title": "批量扫描书 批量学习理解全流程",
    "section": "注意事项",
    "text": "注意事项\n首先如果网上有电子书，不必购买纸质书。\n书里面如果有二维码，附送的代码，要下载下来利用。"
  },
  {
    "objectID": "posts/b876a672-24c2-4589-a254-43fac776304d/index.html#切割-扫描-装订",
    "href": "posts/b876a672-24c2-4589-a254-43fac776304d/index.html#切割-扫描-装订",
    "title": "批量扫描书 批量学习理解全流程",
    "section": "切割 扫描 装订",
    "text": "切割 扫描 装订\n切书用重型切纸机，扫描用双面批量扫描仪，扫描完毕需要用热熔胶粘书装订机装回 用卡纸做背封 用滚筒双面胶粘封面和背封的连接处"
  },
  {
    "objectID": "posts/b876a672-24c2-4589-a254-43fac776304d/index.html#存储-识别-索引-搜索-理解",
    "href": "posts/b876a672-24c2-4589-a254-43fac776304d/index.html#存储-识别-索引-搜索-理解",
    "title": "批量扫描书 批量学习理解全流程",
    "section": "存储 识别 索引 搜索 理解",
    "text": "存储 识别 索引 搜索 理解\n用OCR latex识别器 图片识别器（识别并分割配图） 表格识别器（分割表格）无纸化还原文档原本结构 最好用markdown表示\n搜索用bm25加语义搜索 加latex识图搜索 图像识别搜索\n把整理好的数据加入到ChatGPT模型或者RETRO模型的预训练集中"
  },
  {
    "objectID": "posts/cd365605-1e50-4ffa-be55-ab742cf99b40/index.html",
    "href": "posts/cd365605-1e50-4ffa-be55-ab742cf99b40/index.html",
    "title": "控油 祛痘",
    "section": "",
    "text": "痘坑修护\n水杨酸 果酸（加速角质增生）\n乳糖酸 海藻糖（提供营养）\n洋甘菊 芦荟（降油）\n苦参 香叶天竺葵 马齿苋（促进再生）\n燃脂 瘦腿霜 看起来更像女的 减肚子 减油\n清水洗脸 不要过度清洁 不要搓 用氨基酸洗面奶 不要用皂基 油的时候就清水洗脸 不要抹乳膏\n往气温低的地方走 开空调\n刷酸 果酸 水杨酸 杏仁酸\n控制雄性激素 减少压力 不要紫薇 不要熬夜\n涂吸油的粉 玉米淀粉\n防晒 spf值高的防晒霜 物理防晒 不是化学防晒 不油的防晒霜\n饮食调节\n不要吃肉 碳水化合物 糖 乳制品 不吃油 吃蛋白质 少盐\n吃大豆 大豆异黄酮（植物雌激素）\n吃番茄 番茄红素（植物的双氢睾酮转化酶抑制剂）\n吃非那雄胺 雌激素 螺内酯\n干燥的空气 去湿气\n维生素 微量元素：\n维他命B6和B2\n维他命A\n维他命C\n锌 可杀灭痤疮杆菌 轻度减少油脂分泌\n烟酰胺\n抑制还原酶活性：\n丹参酮 抗雄\n茶多酚 抑制酶活性\n壬二酸/锯棕榈提取物：抑制5α还原酶的活性\n烟酰胺：减少皮肤表面的油脂量\n染料木黄酮：一种植物性雌激素（新鲜的豆浆里面就有~），被认为是抗雄激素成分以减少油脂产生。\n金缕梅：有收敛作用，能够去除面部多余的油脂。"
  },
  {
    "objectID": "posts/34c6ff0f-ef42-4a5e-89ce-8fe712492eb0/index.html",
    "href": "posts/34c6ff0f-ef42-4a5e-89ce-8fe712492eb0/index.html",
    "title": "搜狗输入法AI功能",
    "section": "",
    "text": "AI配图 AI帮写 趣聊 翻译 校对"
  },
  {
    "objectID": "posts/c94fa34c-661c-441f-ae39-110630460da4/index.html",
    "href": "posts/c94fa34c-661c-441f-ae39-110630460da4/index.html",
    "title": "智能手表防水 泡温泉",
    "section": "",
    "text": "智能手表防水 泡温泉 外壳\n智能手表都不能泡温泉 洗澡\n可以考虑做智能手表的时候添加耐温耐水蒸汽的胶水 也可以考虑做防水汽的外壳 塑料透明保护壳 胶圈要和塑料壳之间用耐温耐水汽的胶水粘连 胶圈之间添加波纹 纹路 增加密封强度 耐压 用铰链链接 卡扣扣住 或者双卡扣\n如果外壳需要留空间给按钮 用橡胶按钮加耐压防水胶 或者粘贴实体按钮 硬质按钮加橡胶密封层 注意连接处面积要大\n旋转的按钮就不要旋转了 因为无法密封 比如苹果iwatch 只能点按\n外壳一般有配套的表带 不用原来的连接装置"
  },
  {
    "objectID": "posts/578cd41c-a854-463d-a38c-4ae95dacccfa/index.html#网页转文章",
    "href": "posts/578cd41c-a854-463d-a38c-4ae95dacccfa/index.html#网页转文章",
    "title": "模板创作模式 自媒体 洗稿",
    "section": "网页转文章",
    "text": "网页转文章\nreadbility.js\npagescraper in php\nelinks -dump &lt;url&gt;\n可以把一个文字或者其他类型的内容当成模板 其他文字 视频 图片当作素材 根据模板收集素材 形成内容 注意素材不能是模板本身 素材不能单一 不然被认定为抄袭\n文章洗稿 基于标题和context生成段落：\nhttps://github.com/yangjianxin1/CPM\nbert mask:\nhttps://huggingface.co/fnlp/bart-base-chinese\nhttps://huggingface.co/hfl/chinese-macbert-base\nchinese paraphrase:\nhttps://github.com/ZhuiyiTechnology/roformer\nhttps://github.com/ZhuiyiTechnology/simbert\n可能不是paraphrase模型\nhttps://huggingface.co/lijingxin/mt5-for-zh-paraphrase/tree/main\nhttps://huggingface.co/facebook/m2m100_418M\nhttps://github.com/jiangnanboy/chinese_sentence_paraphrase\nchinese summarize generator:\n一般抽取式的提取 都需要有gpt生成器在中间插入一些句子\nhanlp自带抽取文本方案\n抽取式文本摘要\nbart t5 pegasus中文文本摘要 有训练数据集 训练教程\n一直在想怎么能正确高效的处理seo中，采集的文章怎么去伪原创和洗稿。如果是人工操作的话，那就太麻烦了。采集下来的文章不进行伪原创又害怕被飓风算法命中。\n1，tr算法提取摘要再人工重组新的文章。\n正好今天发现了python中的textrank4zh库，依赖于jieba、numpy和networkx库，可以通过tr算法进行文章的摘要提取。然后根据摘要再人工洗稿，整合成一篇全新的文章。\n测试一篇蚂蜂窝上面的问答，蚂蜂窝问答下面是有很多个答主的内容，通过python爬取所有内容，然后再利用tr算法提取摘要，根据摘要进行重组出一篇新的文章。这样基本上可以成功躲避飓风算法。\n先安装依赖库，然后再利用tr4进行摘要提取。\nfrom textrank4zh import TextRank4Keyword, TextRank4Sentence\ncontent = \"\" # 这里是python采集下来的content html内容\ntext = re.sub('&lt;.*?&gt;','',content)\ntext = re.sub(r'\\s','',text)\nzy = ''\ntr4s = TextRank4Sentence()\ntr4s.analyze(text=text, lower=True, source = 'all_filters')\n# 可修改num值，设置摘要长度。\nfor item in tr4s.get_key_sentences(num=10):\nzy = zy + item.sentence\n2，利用google翻译双向翻译洗稿\n之前有接触一个所谓人工智能洗稿的网站小发猫，说的是利用NLP算法进行洗稿，本来我以为洗稿只有同义词替换这个办法。\n后来研究了一下小发猫，我首先觉得这个绝对不是利用什么所谓的NLP算法来洗稿，研究了一下发现可能是利用google翻译进行双向翻译，就是先中文翻译英文，然后再拿翻译出来的英文再翻译成中文。\n自己也开发了一个这样的伪原创工具，发现其实并不好用。如果不仔细读，这样双向翻译出来的文章还能读，但是仔细读的话。其实语法习惯还有用词根本不准确，甚至有些情况还改变了这句话原有的语义。"
  },
  {
    "objectID": "posts/e73351a8-36bc-4a6c-b2f3-9baa5b90cdb0/index.html",
    "href": "posts/e73351a8-36bc-4a6c-b2f3-9baa5b90cdb0/index.html",
    "title": "水冷散热注意",
    "section": "",
    "text": "水里加醇类物质可以防止导电\n软管加弹簧防止弯折\n液体生料带 ergo 5500陶瓷胶 密封胶 液态密封圈 堵漏 用油管防止老化\n用水管变径器来改变管径 先用相同大小软管连接目标接头 再用变径器链接变径软管\n气压计 肥皂水测试是否漏水\n水泵串联并联增加流量和扬程\n多水道设计增加导热效率\n显卡mos管需要水冷散热 建议看显卡发热红外图其他未水冷的地方贴上散热脊片\n主板本来有热管 风扇散热的地方 例如南北桥 供电 如果要拆除 必须替换成水冷 背面也应该加上水冷\n氟化液沉浸式散热 可以用潜水泵抽水加冷排\n压缩机28度以上防止冷凝水聚集\n用水冷弹性弹簧喉夹来链接软管 有快拧接口的要有快拧头连接硬管或软管\n用热缩编织管来避免磨损 用阻燃波纹管套住最外面\n打磨弹簧套管的两端 避免戳穿软管\n用全开放式机架 铝合金框架 方便主板背面 显卡背面冷却装置的安装\n工业装甲带缠绕接头部分"
  },
  {
    "objectID": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#notice",
    "href": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#notice",
    "title": "涩图api setu bot",
    "section": "notice",
    "text": "notice\n涩图可以发到qq群里面活跃气氛 可以发到专栏里面 可以添加到视频里面“截图选老婆”\n涩图分为二次元和三次元涩图 皆要控制尺度\n除了涩图之外，能够随时使用的番剧clip也是很重要的 如何获取“动漫名场面”呢"
  },
  {
    "objectID": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#projects",
    "href": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#projects",
    "title": "涩图api setu bot",
    "section": "projects",
    "text": "projects\nhttps://github.com/opq-osc/OPQ-SetuBot 直接搜索的pixiv"
  },
  {
    "objectID": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#二次元涩图api",
    "href": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#二次元涩图api",
    "title": "涩图api setu bot",
    "section": "二次元涩图api",
    "text": "二次元涩图api\nhttps://api.lolicon.app/#/setu 注意不要r18的 要用nsfw检查一下至少"
  },
  {
    "objectID": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#三次元涩图api",
    "href": "posts/685e7eec-29de-4dca-90b8-6393f3d1fa3a/index.html#三次元涩图api",
    "title": "涩图api setu bot",
    "section": "三次元涩图api",
    "text": "三次元涩图api"
  },
  {
    "objectID": "posts/9ee7c94e-0350-4b37-8321-9cf0de9f1199/index.html",
    "href": "posts/9ee7c94e-0350-4b37-8321-9cf0de9f1199/index.html",
    "title": "现代 后现代 Vtuber 流行趋势",
    "section": "",
    "text": "把内容生产者的内容拿来训练 当模板 生成类似内容\n把大众的评论 互动 弹幕拿来当鉴别器的训练资料 聚类观众 建立观众群体和内容的对应关系\n现代就是烂大街的内容 大家都接受\n后现代就是一部分人接受 一部分不接受的内容 有流行的趋势\n将现代的内容（已经流行过的内容）作为素材 将后现代（将要流行 或者根据以往经验生成的模板）作为模板 合成内容 可以满足后现代群体需要 具有流行趋势"
  },
  {
    "objectID": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#首页",
    "href": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#首页",
    "title": "百度贴吧app接口",
    "section": "首页",
    "text": "首页\n大家都在搜\n热搜榜 热吧榜 游戏榜（手游 端游 主机）\n关注 推荐\n热榜 （贴吧话题榜，热帖榜（总榜，视频，长更，游戏，数码）\n直播 （我的关注，排行榜，讨论区，个人中心，我要直播，推荐，颜值）\n视频"
  },
  {
    "objectID": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#进吧",
    "href": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#进吧",
    "title": "百度贴吧app接口",
    "section": "进吧",
    "text": "进吧\n关注的吧 吧广场 最近逛的吧"
  },
  {
    "objectID": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#频道",
    "href": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#频道",
    "title": "百度贴吧app接口",
    "section": "频道",
    "text": "频道\n游戏 数码 娱乐 影视 动漫 体育 小说 同城"
  },
  {
    "objectID": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#消息",
    "href": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#消息",
    "title": "百度贴吧app接口",
    "section": "消息",
    "text": "消息\n@我的 点赞 回复 粉丝"
  },
  {
    "objectID": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#我的",
    "href": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html#我的",
    "title": "百度贴吧app接口",
    "section": "我的",
    "text": "我的\n关注 粉丝 吧\n我的帖子 大神认证 创作学院 热门活动\n我的收藏 浏览历史 直播 话题（贴吧话题榜）"
  },
  {
    "objectID": "posts/75aff48c-0376-4b96-9561-2f129b948608/index.html",
    "href": "posts/75aff48c-0376-4b96-9561-2f129b948608/index.html",
    "title": "盗版影视站",
    "section": "",
    "text": "奈菲影视\nhttps://www.nfmovies.com/\n团长资源\nhttps://tzfile.com/\n低端影视\nhttp://ddrk.me/\n人人影视\nhttp://www.zmz2019.com/\n远鉴字幕组\nhttps://yj.apkgm.top/\ntg帮找资源频道\nhttps://t.me/s/lovesource\nhttps://www.netflixstar.top/\nhttps://1090ys.com/"
  },
  {
    "objectID": "posts/10bfb0b2-b093-41d4-b084-3c34037213a2/index.html",
    "href": "posts/10bfb0b2-b093-41d4-b084-3c34037213a2/index.html",
    "title": "睡觉时间 内脏工作时间",
    "section": "",
    "text": "1、内脏器官工作时间：\n晚上9-11点为免疫系统（淋巴）排毒时间，此段时间应安静或听音乐，避免太过兴奋。\n2、晚间\n11-凌晨1点，肝的排毒，需在熟睡中进行，这是美容的黄金时间喔。\n3、凌晨1-3点\n凌晨1-3点，是胆的排毒，亦同。凌晨3-5点，肺的排毒。此即为何咳嗽的人在这段时间咳得最剧烈，因排毒动作已走到肺；不应用止咳药，以免抑制废积物的排除。\n4、凌晨5-7点\n凌晨5-7点，大肠的排毒，应上厕所排便。凌晨7-9点，小肠大量吸收营养的时段，应吃早餐。疗病者最好早吃，在６点半前，养生者在７点半前，不吃早餐者应改变习惯，要养成良好的生活习惯，按时吃饭也是很重要的。\n5、半夜至凌晨４点\n半夜至凌晨４点为脊椎造血时段，必须熟睡，不宜熬夜，年轻人不要再熬夜啦，否则对身体不好。"
  },
  {
    "objectID": "posts/bf0191c3-1c1c-4bf6-a7ce-742e4f5f58b2/index.html#perform-responsiveness-check-by-interval-using-some-deterministic-responses-or-commands-something-different-must-happen-because-of-something",
    "href": "posts/bf0191c3-1c1c-4bf6-a7ce-742e4f5f58b2/index.html#perform-responsiveness-check-by-interval-using-some-deterministic-responses-or-commands-something-different-must-happen-because-of-something",
    "title": "Controlling Computers with Hardware Operations and Software Tools: A Comprehensive Guide",
    "section": "perform responsiveness check by interval, using some deterministic responses or commands (something (different) must happen because of something)",
    "text": "perform responsiveness check by interval, using some deterministic responses or commands (something (different) must happen because of something)\n使用USB3.0录屏卡（HDMI）作为视频输入（类似于摄像头），延迟越低越好\nyou may configure pixel format (jpeg for fast computation) when using different capture cards\n为了通用一般用专门的硬件键鼠模拟器 或者带OTG的RPi模拟键鼠 接收操控方电脑的指令 输出HID信号\n\nreference\nFor recent raspbian you only need to turn on overlay switch in system configuration. (do not use other tools, since they will interfere)\nFor debian-like distros (ubuntu) you can use bilibop-lockfs or fsprotect (install/enable aufs-dkms or overlay filesystem before that)\nFor linux that is set to run in ram (tinycore linux), you can use it as-is, but it may oom so quick that you have to abandon it.\n\nstackoverflow 提到可以用蓝牙进行鼠标键盘模拟 (requires extra setup)\nLinux有驱动可以实现HID输出\nUse USB Gadget with OTG cables.\n用台湾的数据线\nRPi4支持OTG（通过USB-C供电接口） micro HDMI需要转接\nscrcpy –otg 可以识别周边设备 发送HID指令\n定时开关机电源线 加类似于Deep Freeze或者Live CD机制 使得电脑可以接收任意操作而不崩溃\npython usb-gadget wrapper"
  },
  {
    "objectID": "posts/1c544953-b6de-4ea3-b76e-75911c518bd0/index.html",
    "href": "posts/1c544953-b6de-4ea3-b76e-75911c518bd0/index.html",
    "title": "网上接单注意",
    "section": "",
    "text": "不管什么单子 必须在虚拟机里面跑\n不得物理机运行未知应用程序 否则就会出事"
  },
  {
    "objectID": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#tutorials-and-code",
    "href": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#tutorials-and-code",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "tutorials and code",
    "text": "tutorials and code\n综合能源系统分析的统一能路理论系列：\n综合能源系统分析的统一能路理论(一)：气路\n综合能源系统分析的统一能路理论(二)：水路与热路\n综合能源系统分析的统一能路理论(三)：《稳态与动态潮流计算》 &Python代码 & 讲解 （研学社？卖能管系统调优的代码）\nData and codes for energy circuit method-based optimal energy flow\nreinforcement learning (PPO) for NeurIPS Competition 2020: Learning to Run a Power Network (L2RPN)\n\n基于改进DaNN的综合能源系统多能负荷预测, DaNN (Domain Adversarial Neural Network, Unsupervised Domain Adaptation by Backpropagation (for digital twins?)) or DDAN (Deep Domain Adaptation Networks)\n综合能源系统（冷、热、电 (CCHP)）案例/论文/数据整理分享\n\n王子豪提供的综合能源系统优化运行专题：\nSection 1: 开篇：综合能源系统基本模型和gurobi基本语法\nSection 2: 综合能源系统目标函数建立\nSection 3: 综合能源系统最优电力潮流（OPF）模型建立与Gurobi实现\nSection 4: 综合能源系统最优热力潮流（OTF）模型建立与Gurobi实现 Code: IESOptimization\nSection 5: 综合能源系统多时刻优化模型建立与求解"
  },
  {
    "objectID": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#tools",
    "href": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#tools",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "tools",
    "text": "tools\n\nmac m1 compatibility on windows software\ninstall by brew install wine-stable (version &gt;= 6.0.2)\nthen run wine64\n\n\npython doc generation\n\npydoc\nstart server using:\npython3 -m pydoc -p &lt;port&gt; &lt;module_name&gt;\n\n\npdoc3\npip3 install pdoc3\npdoc --html &lt;module_name&gt;\n\n\ndocstring\nclass myClass:\n\"\"\"\nmyClass doc\n\"\"\"\ndef __init__(self):\n\"\"\"\ninit doc\n\"\"\"\n\n\n\ncontrolling & monitoring\nOpenMUC is some advanced software only SCADA bridging system, with analysing but no simulation!\nOpenEMS is for monitoring, controlling and simulation based on historical data (not digital twin!)\nmyEMS用于能源管理项目的设备管理、数据采集、处理、分析、可视化和报表。\n\n\noptimization\nsolvers:\nglpk: gnu linear programming kit (LP/MIP problems), can bridge with gnu mathprog language (GMPL, subset of AMPL)\non blackbox optimization there are:\n\nGradient Free Optimizers like: meta-heuristic, simulated-annealing, hill-climbing, particle-swarm-optimization, evolution-strategies, blackbox-optimization, gradient-free-optimization, tree-of-parzen-estimator and many more\nvizier by google for blackbox and hyperparameter optimization\nparmoo for parallel multiobjective simulation optimization\n\n\nilqr: Iterative Linear Quadratic Regulator with auto-differentiatiable dynamics models\nRAVEN is a flexible and multi-purpose probabilistic risk analysis, validation and uncertainty quantification, parameter optimization, model reduction and data knowledge-discovering framework.\nRAVEN includes the following major capabilities:\n\nSampling of codes for uncertainty quantification and reliability analyses\nGeneration and use of reduced-order models (also known as surrogate)\nData post-processing (time dependent and steady state)\nTime dependent and steady state, statistical estimation and sensitivity analysis (mean, variance, sensitivity coefficients, etc.).\n\nThe RAVEN statistical analysis framework can be employed for several types of applications:\n\nUncertainty Quantification\nSensitivity Analysis / Regression Analysis\nProbabilistic Risk and Reliability Analysis (PRA)\nData Mining Analysis\nModel Optimization\n\n\nVSA-FINE: generating energy system optimization models, using tsam (for Time series aggregation, Pareto-Optimal Temporal Aggregation of Energy System Models) and pyomo, compatible for both commercial solvers and open-source solvers.\noptimization using PuLP (by coin-or)\npython-mip (install by pip install mip) provides tools for modeling and solving Mixed-Integer Linear Programming Problems.\nGEKKO is a Python package for machine learning and optimization of mixed-integer and differential algebraic equations. Modes of operation include parameter regression, data reconciliation, real-time optimization, dynamic simulation, and nonlinear predictive control. (MPC? see APM Python with Demo Applications on GitHub)\nnumdifftools Solves automatic numerical differentiation problems in one or more variables (Jacobian?)\nNEOS is a free service for numerical optimization, which almost only accepts GAMS/AMPL/SMPS code.\nCeres Solver is for non-linear least squares (curve fitting, can be done in lmfit-py and scipy.optimize.curve_fit (from python numerical methods, a tutorial on numerical processing)) and can be accelerated by multiprocessing or CUDA\nCOIN-OR projects (many things!) are usually solver and optimization related. Pyomo (a collection of Python software packages for formulating optimization models, similar to linopy (only for labeled data, linear optimization)) is part of the project.\nOpenSolvers is for microsoft excel and uses linear solvers like COIN-OR CBC (on which mentioned a lot of modeling languages/tools it supports) and non-linear solvers like Bonmin (Basic Open-source Nonlinear Mixed INteger programming) and Couenne (Convex Over and Under ENvelopes for Nonlinear Estimation) powered by IPOPT. details on solvers\nPareto optimization using:\n\npymmo is for multi-objective optimization. usage in NSGA2\npyomo is a Python-based, open-source optimization modeling language with a diverse set of optimization capabilities.\njMetalPy and introduction\nNSGA3\npartical group and intro in python\n\nCode for NIPS 2018: Multi-Task Learning as Multi-Objective Optimization, an exact algorithm for multi-objective optimization of deep networks with negligible computational overhead.\n\nmachine learning & neural networks\nflux.jl is machine/deep learning in julia, with GPU support. model zoo (examples) and doc. DiffEqFlux.jl can add differential equation layers to neural networks, details here\nMLJ.jl: non-DNN machine learning framework\nfacebook prophet\npymc based prophet\nnumenta nupic sparse encoding\npyro forcasting and time series\nuber orbit (A Python package for Bayesian forecasting with object-oriented design and probabilistic models under the hood) and doc\n\n\nreinforcement learning\nsample code and intro for adaptive dynamic programming(ADP)\nmicrosoft machine teaching is like automl for reinforcement learning (autorl), based on bonsai (on [github[(https://github.com/BonsaiAI)) (doc) is a low-code platform for autonomous AI systems (bonsai BRAIN is close-sourced), doc before acquiantaince. mentioned “optimize HVAC (heating, ventilation, and air conditioning) with EnergyPlus and BCVTB (Building Controls Virtual Test Bed)”. specify enviorments, rewards and targets with Inkling (declarative)\nopenai baselines\nstable baselines3\nautorl-research by microsoft\nautonomous learning library for pytorch, building deep reinforcement learning agents\nbrain autorl by google\nrlang: a declarative language for expressing partial world knowledge to RL agents and decision process. doc\n\n\n\nNLP\nRETRO-pytorch without weights\nLangChain: combine LLMs with other sources of computation or knowledge.\nELIF LFQA retrieval based\nhaystack (+ LLM = ChatGPT?)\nchatgpt (which is currently way too busy?)\nPaLM-RLHF\nOpen-Assistant\nNTM (neural turing machine) (best?) for translation, question answering, planning and decision-making. tensorflow 1.14.0 includes it into tf.contrib which also has timeseries module.\n\n\nmodel predictive control\nMPC is mentioned along with PID (Proportional Integral Derivative) found in libraries like simple-pid, pypid and control.\ngradcem: Model-Predictive Control via Cross-Entropy and Gradient-Based Optimization\ndo-mpc (in python) is a comprehensive open-source toolbox for robust model predictive control (MPC) and moving horizon estimation (MHE).\nmpc-pytorch is a fast PyTorch library for solving the non-convex control problem\n\n\nmodeling & simulation\nfor interfaces i’d like jupyter. does julia/modelica/octave support jupyter?\nthermalcorr: (c++) A collection of thermohydraulic correlations for thermal systems and heat exchangers\nneural operator for PDE/ODE neural network approximation (speedup solving) and doc\nhydraulic: A python package to compute pressure, flows and temperatures in hydraulic circuits\nfluids: is open-source software for engineers and technicians working in the fields of chemical, mechanical, or civil engineering. It includes modules for piping, fittings, pumps, tanks, compressible flow, open-channel flow, atmospheric properties, solar properties, particle size distributions, two phase flow, friction factors, control valves, orifice plates and other flow meters, ejectors, relief valves, and more.\nCityLearn: reinforcement learning environment for controlling the storage of domestic hot water (DHW), chilled water (for sensible cooling and dehumidification) hot water (for sensible heating) and electricity, also including models of air-to-water heat pumps, electric heaters, solar photovoltaic arrays, and the pre-computed energy loads of the buildings, which include space cooling, dehumidification, appliances, DHW, and solar generation.\nOMF: The Open Modeling Framework for smart grid cost-benefit analysis.\nHELICS is a co-simulation framework, designed to bring together domain-specific modeling tools so they interact during run time. usage examples and doc\nPLEXOS by Energy Exemplar is the only solution available today that unifies market simulations across the electric, water, and gas industries.\nDistributed Energy Generation Model\nOpenHybridSim is the first-ever, open source tool for EMT and phasor domain hybrid simulation.\nopenmodelica-microgrid-gym: An OpenAI Gym Environment for Microgrids (and reinforcement learning)\nModelingToolkitStandardLibrary.jl: A standard library of components to model the world and beyond\nModelicaGym: Modelica models integration with Open AI Gym\nandes: Python toolbox / library for power system transient dynamics simulation with symbolic modeling and numerical analysis\nDPSim: Real-time power system simulator including powerflow, (dynamic) phasors and EMT. doc\ncalliope: A multi-scale energy systems modelling framework\nThermal Engineering Systems in Python (TESPy). This package provides a powerful simulation toolkit for thermal engineering plants such as power plants, district heating systems or heat pumps.\nEnergy-Hub-Market-Operation: Participation of an Energy Hub in Electricity and Heat Distribution Markets using MPEC (mathematic program with equilibrium constraints)\nOSeMOSYS in Pyomo (likely to be a large regional energy simulation)\nmicrogrid optimizer for system of hot water, thermal and electricity (CHP) optimization using MILP\nEMTSimulation (python)\ncombined-heat-and-power-system-probabilistic-production-simulation: (in matlab) a fast algorithm for economic and adequacy evaluation of electricity-heating systems\nCHP_ORC: Combined heat and power orc cycle using geothermal heat source\nCCHP-MINLP: MINLP instances for short-term planning problem of combined heat and power (CHP) systems\nCombined-cooling-and-heat-Power-CCHP-Plant written in GAMS, with a report\nOpenFAST/kitefast for wind turbine simulation\nfmi (functional mock-up interface) is an open model exchange format that able to run on multiple languages, proposed by modelica. tools support this standard are usually for modeling and simulation, and are able to communicate with each other using this protocol.\nTRNSYS(Transient System Simulation Program, paid, not open source)最早是由美国威斯康星大学和Solar Energy 实验室开发的。容易与MATLAB、python、C++进行调用和编程。主要进行建筑负荷模拟相对于DEST来说较为复杂。可进行太阳能（光热、光电）、地源热泵、风电、光电、氢能、三联供、综合能源、全生命周期经济性系统模拟分析\nmultisim includes models like pipes, heat exchanger, thermal storage and controllers like PID, Bang–bang controller,\nTwo sensor controller and Model predictive controller.\nIES analysis notebooks: Jupyter notebooks which analyse IES simulation results\nTools for Energy Model Optimization and Analysis (TEMOA) is an open source modeling framework for conducting energy system analysis. The energy system is described algebraically as a network of linked processes that convert a raw energy commodity (e.g., coal, oil, biomass, uranium) into an end-use demand (e.g., lighting, transport, water heating, conditioned air), doc is here\nDistributed Energy Generation Model: Code for “Natural Gas Combined Cycle Power Plants Have Lower Environmental Impact than Conventional Combined Heat and Power for Commercial Buildings, Environmental Science & Technology”\nflixOpt: vector based energy and material flow optimization framework in python\nWastewater_Energy_Optimization: Supplementary files for “Integrated Design and Optimization of Water-Energy Nexus: Combining Wastewater Treatment and Energy System”\nGAN_GA_ICML containing files to replicate experiments and results from “Using C-GANs to Boost High-dimensional Nonlinear Optimization for Sustainability Targets”\nIDEAS (Modelica library allowing simultaneous transient simulation of thermal and electrical systems at both building and feeder level.\nIESLAB for burst and leakage simulation/detection with SCADA data\nGrid2Op: a testbed platform to model sequential decision making in power systems (for Reinforcement Learning?), with lightsim2grid which implements a c++ backend targeting the Grid2Op (speedup simulation). doc\nEnergyCircuitTheory-EnergyFlowCalculation: 数值实验代码 for 《综合能源系统分析的统一能路理论(三)：稳态与动态潮流计算》\nThe Framework for Optimization of ResourCes and Economics (FORCE) is a collection of software tools developed under the Integrated Energy Systems (IES) program to enable analysis of technical and economic viability of myriad IES configurations. Each of these tools is openly available and free to use.\nHERON: Holistic Energy Resource Optimization Network (HERON, for Technoeconomic Assessments and Synthetic History Generation) is a modeling toolset and plugin for RAVEN to accelerate stochastic technoeconomic assessment of the economic viability of various grid-energy system configurations, especially with application to electrical grids and integrated energy systems (IES).\nTRANSFORM-Library: A Modelica based library for modeling thermal hydraulic energy systems and other multi-physics systems\nsmart-rl-mg: Reinforcement Learning + Microgrids for OpenDSS\nHYBRID (requires DYMOLA? just a Modelica runtime?) is a modeling toolset to assess the integration and economic viability of Integrated Energy Systems (IES) , including Modeling and Experimental Validation of Latent Heat Thermal Energy Storage System. Related to CENTAUR which has a GUI interface (very abstract), can be used for the design and simulation of hybrid solar PV-battery-diesel microgrids , similar to (only simulation, not optimization) HYBRID2 and HOMER (Hybrid Optimization Model for Multiple Energy Resources, with a data processing script found somewhere)\nin python-control (optional dependency of slycot for MIMO) there is an example of model predictive control for aircraft model\nEMSO is the acronym for Environment for Modeling, Simulation, and Optimization. can customize model using EMSO modeling language. it is about chemistry rather than CCHP according to its modeling library EML\nOpenModelica is an open-source Modelica-based1 modeling and simulation environment intended for industrial and academic usage.\nXcos by SciLab is a graphical editor to design hybrid dynamical systems models. Models (in modelica) can be designed, loaded, saved, compiled and simulated. All Xcos standard blocks grouped by categories (signal processing, electrical, hydraulics, derivative, integral, etc.).\nJModelica is an extensible Modelica-based open-source platform for optimization, simulation, and analysis of complex dynamic systems. The main objective of the project is to create an industrially viable open-source platform for simulation and optimization of Modelica models.\nScilab (by Dassault Systems) is a scientific software package for numerical computations providing a powerful open computing environment for engineering and scientific applications. Scilab is an open source software and includes hundreds of mathematical functions with the possibility to add interactively programs from various languages (C, C++, Fortran…).\nScicos is a graphical dynamical system modeler and simulator developed in the Metalau project at INRIA, Paris-Rocquencourt center. With Scicos, user can create block diagrams to model and simulate the dynamics of hybrid dynamical systems and compile models into executable code.\nSpyder is a free open-source Python development environment providing MATLAB-like features in a simple and light-weighted software.\nStaticDESim: Simulation and optimisation of integrated energy system in steady state written in MATLAB, with models like Micro Gas Turbine (MGT), Aqueous Lithium-Bromine Single-Effect Absorption Chiller (AC_ALB), R123 Organic Recycle Cycle (ORC_R123), Heat Pump (HP) and R134a Vapour Compression Chiller (VCC_R134a)\nOpenHydraulics: A free Modelica package providing components describing 1-dimensional fluid flow in hydraulic circuits.\npyDMPC: A Python tool for distributed model-based predictive control of energy suppy chains\nAi4EMetaPSE by Ai4Energy: 采用基于方程的面向对象建模，基于微分代数方程（DAE），对能源系统组件进行建模，用以对能源系统进行稳态、动态仿真。能够处理连续时间及离散事件问题。\nAi4ELab is a Virtual Simulation Lab of Ai4Energy deployed with docker. can use with ModelingToolkit.jl. doc\nsimupy: a ramework for modeling and simulating dynamical systems\nModelica Standard Library includes models for mechanical (1D/3D), electrical (analog, digital, machines), magnetic, thermal, fluid, control systems and hierarchical state machines, similar to Modeling Toolkit Standard Library from SciML\ncchp-minlp models including heat pump, gas turbine, auxiliary boilers, written in GAMS and AMPL\npymgrid only provides models related to electricity.\noemof: Open Energy Modelling Framework - Python toolbox for energy system modelling and optimization, with thermal simulation support. doc\nrenpass: Renewable Energy Pathways Simulation System (written in R)\nMESSAGEix is a framework written in GAMS that can be used to develop and run many different models, each describing a different energy system.\nMinpower is an open source toolkit for students and researchers in power systems.\nGNU Scientific Library (better on linux!) capabilities:\nComplex Numbers\nRoots of Polynomials\nSpecial Functions\nVectors and Matrices\nPermutations\nSorting\nBLAS Support\nLinear Algebra\nEigensystems\nFast Fourier Transforms\nQuadrature\nRandom Numbers\nQuasi-Random Sequences\nRandom Distributions\nStatistics\nHistograms\nN-Tuples\nMonte Carlo Integration\nSimulated Annealing\nDifferential Equations\nInterpolation\nNumerical Differentiation\nChebyshev Approximation\nSeries Acceleration\nDiscrete Hankel Transforms\nRoot-Finding\nMinimization\nLeast-Squares Fitting\nPhysical Constants\nIEEE Floating-Point\nDiscrete Wavelet Transforms\nBasis splines\nRunning Statistics\nSparse Matrices and Linear Algebra\n\n\nAMPL community edition must connect to internet for license validation. trial commercial solvers for 30 days.\nCMPL by coin-or is highly optimized for multiprocessing. can bridge to python via pyCMPL3.\nMiniZinc: open-source constraint modeling language.\nPandaThermal: District heating and cooling network design and simulation tool, largely inspired by PandaPower\nSciML is Scientific Computing + Machine Learning Toolbox. It has the best performant DifferentialEquations.jl (can run on CUDA with ease, connect to neural networks) and NeuralPDE.jl for Physics-Informed Neural Networks (PINN) and Deep BSDE Solvers of Differential Equations for Scientific Machine Learning (SciML) accelerated simulation, easily bridging to Python. In its tutorial we can learn differential equation modeling/simulation.\nPowerModelDistribution.jl is an extension package of PowerModels.jl for Steady-State Power Distribution Network Optimization.\nPowerSimulations.jl is a Julia package for power system modeling and simulation of Power Systems operations.\nTIMES model: The Integrated MARKAL-EFOM System, written in GAMS (General Algebraic Modelling System, a modeling language, paid, similar to Dyna (a declarative modeling language like prolog, in dyna2gams it can refine parameters on observation) with lots of solvers), able to model CHS systems and predict financial costs said in its documendation, is a technology rich, bottom-up model generator, which uses linear-programming to produce a least-cost energy system, optimized according to a number of user constraints, over medium to long-term time horizons.\n\njulia relates quite a bit to power and energy simulations. is it performance related?\ntype ] in julia’s REPL to get Pkg interface.\n\nModelica is a language for modeling of cyber-physical systems, supporting acausal connection of components governed by mathematical equations to facilitate modeling from first principles, used in CATIA Systems, Dymola, JModelica.org, LMS AMESim, MapleSim, Modelon Impact, MWorks, OpenModelica (for python you need this: PySimulator), SimulationX, and Wolfram SystemModeler (and more tools.\nOpenIPSL is a library of power system component models written in the Modelica language that can be used for power system dynamic analysis, such as phasor time-domain simulations.\nSTEPS & stepspy: Simulation Toolkit for Electrical Power Systems. doc\npandapower: (lacks storage unit models) Convenient Power System Modelling and Analysis based on PYPOWER and pandas. official site\nin pandapower’s paper there are lots of open source tools for electric power systems optimization mentioned:\nMATPOWER (with optional solvers, must be obtained separately) is a widely used power system analysis tool for matlab and octave that solves power flow and optimal power flow problems and also includes an optimal scheduling tool for market simulations.\nThere are ports of the original MATLAB based code to other languages, most notably Pythons PYPOWER pypower-dynamics extends PYPOWER for dynamic analysis of electric power systems.\nGridCal (abbriviation for grid calculator) includes power flow, time-series and short circuit calculation methods and comes with a comprehensive graphical user interface.\nThe simulation and optimization library PyPSA (Python for power system analysis) is aimed at time-series simulation of security-constrained linear optimal power flow and investment optimization.\nPowerGAMA ( Python-based lightweight simulation tool for high level analyses of renewable energy integration in large power systems) and psst (power system simulation toolbox) are also aimed at market optimization in electric networks.\nGridLAB-D is an advanced tool for static simulations using agent based simulation models, based on C/C++ with integration of SCADA controls, metering and market models.\n\nOpenDSS is a electrical power system simulation tool primarily for utility power distribution systems, written in a Delphi.\nMATPower: free, open-source tools for electric power system simulation and optimization\nenergyplus (open source, based on DOE2, a building energy analysis program that can predict the energy use and cost) is a whole building energy simulation program that engineers, architects, and researchers use to model both energy consumption—for heating, cooling, ventilation, lighting and plug and process loads—and water use in buildings.\nbcvtb is a software environment that allows users to couple different simulation programs for co-simulation, and to couple simulation programs with actual hardware. For example, the BCVTB allows to simulate a building in EnergyPlus and the HVAC and control system in Modelica, while exchanging data between the software as they simulate.\nwolfram mathematica and System Modeler\nmaple and MapleSim\nmatlab (can be cuda accelerated (jacket?)) and simulink\ngnu octave (used by cloudpss?)\nsagemath\nroot\n\ncomputational fluid dynamics (really?)\nopenFOAM (free CFD (computational fluid dynamics) software) and documentation\nCFD in github\nCFD machine learning in github\nawesome CFD machine learning: a curated list of machine learning papers, codes, libraries, and databases applied to fluid mechanics.\n\n\nfinite element analysis\nFEA (finite element analysis) open source software list"
  },
  {
    "objectID": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#cloudpss",
    "href": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#cloudpss",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "cloudpss",
    "text": "cloudpss\nthis thing is developed by tsinghua-eiri\nmultiple papers related to cloudpss were found on semanticscholar. maybe we just want the ieslab part?\nin its paper the computation graph is acyclic.\ncloudpss python sdk是基于CloudPSS-API封装的模型及软件开发套件。用户可通过编写Python、Matlab等脚本构建自定义模型，或是调用CloudPSS平台中的模型修改、仿真计算功能，实现诸如自动修改模型、批量仿真计算、自动化生成报告等复杂且繁琐的功能。用户也可在其自己的应用程序中调用CloudPSS仿真引擎，实现仿真驱动的高级分析应用。\nmain structure:\n\nSimStudio: 轻松组织和管理能源电力系统数字孪生仿真模型\n\nin SimStudio it has “octave” keyword. does that mean it is using GNU octave? yes! but octave does not have Simulink-like functionalities. see octave packages for more. use Xcos instead? in order to read code in modules like https://cloudpss.net/model/CloudPSS/HeatPump(右键点击元件，选择打开模块) you have to obtain sufficient permission.\nwill raise error if we wire electricity to water pipelines. it is not so easy to wire these things. better do it with port routing.\ncomponents list:\n\n\n\n\n\nClassification\n\n\nComponents\n\n\n\n\n\n\nMeasurements\n\n\nOscilloscope Group, Output channel\n\n\n\n\nElectrical-Basic Passive Components\n\n\nGround, Resistor, Inductor, Capacitor, Single-phase Fault Resistor, Three-phase Fault Resistor, Single-phase Transformer\n\n\n\n\nElectrical-Basic Source Components\n\n\nDC Current Source, DC Voltage Source, Single-phase AC Voltage Source, Controlled Current Source, Controlled Voltage Source, Controlled AC Voltage Source (VF), Controlled AC Voltage Source (VP)\n\n\n\n\nElectrical-Power Electronic Switches\n\n\nDiode, Thyristor, IGBT\n\n\n\n\nElectrical-Three-phase Components\n\n\nShunt Capacitor/Reactor, Fixed Load, Line Cluster, Three-phase Transmission Line, Three-phase AC Bus, Three-phase AC Voltage Source, Three-phase Two-winding Transformer, Three-phase Three-winding Transformer, Synchronous Generator\n\n\n\n\nElectrical-Fast Power Electronic Modules\n\n\nHalf Bridge Submodule, Six-pulse Thyristor Bridge\n\n\n\n\nElectrical-Renewable Energy Components\n\n\nPhotovoltaic Source, Lead-acid Battery\n\n\n\n\nMeasure Components\n\n\nBranch Voltage Meter, Voltage Meter, Current Meter, RMS Meter, Three-phase Power Meter, Phase Locked Loop, FFT\n\n\n\n\nControl-Basic Components\n\n\nM script, Constant, Time, Simulation Time Step, Non Connection (NC), Loop Break Node, Channel Merge, Channel DeMerge\n\n\n\n\nControl-Basic Math Functions\n\n\nAdder/Subtractor, Multiplier, Divider, Absolute Value, Sign Function, Round Function, Trigonometric Function, Power Function, Exponential Function, Logarithm Function, Maximum/Minimum Function, Maximum/Minimum in One Cycle\n\n\n\n\nControl-Linear Transfer Functions\n\n\nGain, Integrator, Derivative, PI Controller, Zero-point, Real Pole, Differential Pole, Lead Lag Pole, Second Order Complex Pole, Nth Transfer Function\n\n\n\n\nControl-Nonlinear Functions\n\n\nHard Limiter, Delay, Angle Resolver, Piecewise Linear Function, Nonlinear Function\n\n\n\n\nControl-Analog Signal\n\n\nComparator, Hysteresis Comparator, Zero Detector, Sampler, Sample and Hold\n\n\n\n\nControl-Digital Signal\n\n\nLogic Gate, Binary Delay, Monostable MultiVibrator, Flip Flop, Selector, Edge Detector\n\n\n\n\nControl-Coordinate Transformation\n\n\nPark Transformation, Clark Transformation, dq-αβ Coordinates Transformation, Polar/Rectangular Coordinate Converter\n\n\n\n\nControl-Singal Generator\n\n\nTriangular Generator, Squar Generator, Sine Generator, Adjustable FPM Sine Generator, Single-impulse Generator, Impulse Generator, Step Generator, Ramp Generator, Surge Gennerator, Drop Generator, Random Number Generator\n\n\n\n\nControl-HVDC Control\n\n\nPhase Locked Oscillator, Nearest Level Modulation (NLM), SST Fire Pulse Generator\n\n\n\n\nControl-AC system Control\n\n\nST5B、Hydro Governor、 Hydro Turbine\n\n\n\n\nHeat-Basic Components\n\n\nPipeline, Heat Source, Bulding (Load), Connection Point, Relay Pump\n\n\n\n\n\n\nIESLab (Integrated Energy System): 综合能源系统规划设计云平台\n\na place where you can import weather, energy prices, device parameters and loads data, design the IES system by hand (how components connects), determine the best products to purchase based on different criterions and assess it by net profit, environmental effects and energy efficiency.\n\nFuncStudio: 助力能源电力系统数字孪生云边融合业务定制\n\ninstall locally (windows only?) or download binary file of “header only” functions?\n\nAppStudio: 快捷构建能源电力系统数字孪生应用\n\nlow-code frontend design interface.\nthe platform uses code generator to make the simulation fast.\nsomething like siemens simcenter is also cloud based. collimator is self-labeled as better simulink alternative with ai and python code blocks inside. it also suggests model based development (and a hell lots of blogs) for a general guideline on simulation and optimized control systems.\nfound tsinghua’s cloudpss (linked to localhost?) from Allen-Sunboy, along with all rare urls exclusive to elites (social networks?)\ncloudpss is utilizing alibaba’s cloud computing. the simulation uses computing graph and cuda acceleration (diffcult to deploy?), suggested simulink and PSCAD (PyPSCAD does similar things, but far from complete) (with IncrediBuild-XGE for multi-core acceleration) for simulation. in the paper it describes itself as “power system simulator” and “electromagnetic transient simulator” (HVDC: high voltage direct current, highly efficient for transmitting large amounts of electricity over long distances)\n\n项目仿照cloudpss进行编写\n专注于复杂交直流电网、配电网、微电网、独立电力系统的精确电磁暂态建模及覆盖多时间尺度物理过程仿真\n本平台支持包括配电系统、供暖制冷系统、蒸汽供热系统及烟气余热回收系统在内的多能源系统耦合网络的建模仿真计算。与传统的综合能源系统仿真工具不同，平台集成了20余种常见的综合能源系统设备模型，允许用户灵活搭建任意能量梯级利用形式的综合能源系统，拓扑结构不受约束，同时支持并网系统、孤网系统的仿真计算，从而有效拓展了适用场景。"
  },
  {
    "objectID": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#系统架构",
    "href": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html#系统架构",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "系统架构",
    "text": "系统架构\n系统具体设计参考文档。\n综合能源系统特指在规划、建设和运行等过程中，通过对能源的产生、传输与分配（能源网络）、转换、存储、消费等环节进行有机协调与优化后，形成的能源产供销一体化系统。\n本平台包含两大子系统，分别为设计规划系统和运行调度系统。\n涉及到数据，计算，仿真的模块：\n\n系统能量流拓扑\n\n基础数据\n\n环境信息库\n包含：地理位置、气象数据（风、光、温度）以及规范中的一些设计表格，与地理位置关联的相关设备。\n\n\n\n\n输入\n\n\n地理位置（地名或者坐标），气象数据（默认已选择的地理坐标），可以从文件导入或者历史数据库导入\n\n\n\n\n\n\n设备信息库\n包含：发电、制冷制热、储能设备、配电传输、供热传输五个分类。不低于25种设备。还包含市政资源（市政天然气、市政电网、市政蒸汽、市政热水）。\n需要考虑设备效率、设备寿命、网络损耗。包含建设费用等虚拟模型（电缆、管道、基建等）。\n\n\n\n\n输入\n\n\n输入相应设备相应属性值，或者从典型库导入相应设备信息（生产厂商 设备型号 额定功率 运行约束 经济性参数）\n\n\n\n\n\n\n负荷信息库\n包含：蒸汽负荷、采暖负荷、制冷负荷、电负荷\n输入形式：\n\n负荷指标\n\n• 采暖、制冷、电负荷有其特殊场景，属性面板有额外参数：\n• 模型：粗略模型（每月平均值数据） 或者详细模型（每个小时）\n\n负荷参数：是否包含工作日和非工作日、具体时间段、建筑类型、面积\n负荷曲线：更直观的对负情况进行展示\n\n\n\n能源信息库\n包含：电、热、冷、气的价格信息\n输入形式：\n定价规则或者曲线描述\n电价格分为：\n\n常数电价\n分时电价\n阶梯电价\n分时阶梯\n\n热和冷的价格分为：\n\n面积\n热量\n\n气的价格随当地行情\n\n\n\n设计规划\n根据已经设定的能源类型、负荷需求、建设规模、资金来源进行方案优化，得到设备的容量配置及各种设备的设备成本、工程初始投资、运行费用及各种设备的出力情况，以及经济指标、环保指标，并输出相应报告\n\n\n仿真计算\n根据已经设定的基本数据进行仿真计算，并输出设备的出力曲线及相应的经济指标、环保指标的报告（除了不需要输出容量配置之外，其余的输出项与设计规划一样）\n\n\n\n能源汇总\n\n能源运行实时数据看板\n汇总当前各设备运行时的能源生产与消耗汇总，并以图表的形式展示\n\n\n\n运行调度\n\n方案列表\n对已经规划的方案进行展示\n\n\n运行日志\n对已经运行的方案进行日志记录\n\n\n\n系统结构拓扑\n\n基础数据\n\n环境数据\n设备数据\n负荷信息库\n能源信息库\n\n\n\n仿真模拟\n根据已经设计的运行方案进行带拓扑结构的仿真模拟\n\n\n调度优化\n一种算法策略，对具体的综合能源系统进行协调优化计算（可以结合实时数据），并实时输出优化结果，下发指令给控制系统。\n\n\n\n能源监测\n\n实时数据\n以图表的形式展示能源生产和消耗数据、告警数据\n\n\n历史数据\n选择历史某段时间，查询当时的能源消耗和生产数据\n\n\n能源设备监控\n实时显示所有设备的运行状态、生产消耗数据、告警信息\n\n\n告警中心\n显示今日所有告警的设备信息\n\n\n\n数据分析\n\n能效评估\n对电、气、冷、热进行能效评估展示\n\n\n能源明细\n展示产量明细和消耗明细\n\n\n排放明细\n展示排放明细数据"
  },
  {
    "objectID": "posts/f497ce72-934d-444c-b978-0115868a3bf8/index.html",
    "href": "posts/f497ce72-934d-444c-b978-0115868a3bf8/index.html",
    "title": "自媒体违禁词获取平台 在线更新违禁词语 censored word online query with latest update",
    "section": "",
    "text": "自媒体违禁词查询平台"
  },
  {
    "objectID": "posts/b6f93dd7-a741-44ee-92bd-8021bea75c77/index.html",
    "href": "posts/b6f93dd7-a741-44ee-92bd-8021bea75c77/index.html",
    "title": "视频分析处理 剧本生成",
    "section": "",
    "text": "视频分析处理 视频摘要 剧本生成\n自动抠像 最新 2022 较小的性能消耗：\nhttps://github.com/hkchengrex/XMem\n我fork的项目：https://github.com/ProphetHJK/XMem\n我fork后添加了一些小工具，包括绿幕生成，蒙版视频生成，中文教程等\nsimple video captioning:\nhttps://pythonawesome.com/a-simple-implementation-of-video-captioning/\nhttps://github.com/232525/videocaptioning.pytorch?ref=pythonawesome.com\nhttps://github.com/xiadingZ/video-caption.pytorch\n3d cnn for video classification:\nhttps://github.com/kcct-fujimotolab/3DCNN\nend-to-end video image classification by facebook:\nhttps://github.com/facebookresearch/ClassyVision\nvideo understanding models and datasets:\nhttps://github.com/sujiongming/awesome-video-understanding\nvideo classification dataset:\n​video_type_dict​ ​=​ {​‘360VR’​: ​‘VR’​, ​‘4k’​: ​‘4K’​, ​‘Technology’​: ​‘科技’​, ​‘Sport’​: ​‘运动’​, ​‘Timelapse’​: ​‘延时’​,\n​‘Aerial’​: ​‘航拍’​, ​‘Animals’​: ​‘动物’​, ​‘Sea’​: ​‘大海’​, ​‘Beach’​: ​‘海滩’​, ​‘space’​: ​‘太空’​,\n​‘stars’​: ​‘星空’​, ​‘City’​: ​‘城市’​, ​‘Business’​: ​‘商业’​, ​‘Underwater’​: ​‘水下摄影’​,\n​‘Wedding’​: ​‘婚礼’​, ​‘Archival’​: ​‘档案’​, ​‘Backgrounds’​: ​‘背景’​, ​‘Alpha Channel’​: ​‘透明通道’​,\n​‘Intro’​: ​‘开场’​, ​‘Celebration’​: ​‘庆典’​, ​‘Clouds’​: ​‘云彩’​, ​‘Corporate’​: ​‘企业’​,\n​‘Explosion’​: ​‘爆炸’​, ​‘Film’​: ​‘电影镜头’​, ​‘Green Screen’​: ​‘绿幕’​, ​‘Military’​: ​‘军事’​,\n​‘Nature’​: ​‘自然’​, ​‘News’​: ​‘新闻’​, ​‘R3d’​: ​‘R3d’​, ​‘Romantic’​: ​‘浪漫’​, ​‘Abstract’​: ​‘抽象’​}\nhttps://github.com/yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model\nrnn for human action recognization:\nhttps://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input\nvideo script introduction and generation:\nhttps://sharetxt.live/blog/how-to-generate-a-youtube-video-script-with-ai#:~:text=%20How%20to%20use%20Chibi.ai%20to%20create%20a,scan%20through%20your%20text%20and%20generate…%20More%20\nfight detection using pose estimation and rnn:\nhttps://github.com/imsoo/fight_detection\nvideo summarizer to summarized video based on video feature:\nhttps://github.com/Lalit-ai/Video-Summary-Generator\nawesome action recognition:\nhttps://github.com/jinwchoi/awesome-action-recognition\ntemporal model for video understanding:\nhttps://github.com/mit-han-lab/temporal-shift-module\nhttps://github.com/mit-han-lab/temporal-shift-module\nhttps://github.com/yjxiong/tsn-pytorch\ntime space attention for video understanding(timesformer):\nhttps://github.com/facebookresearch/TimeSformer\nvideo understanding by alibaba:\nhttps://github.com/alibaba-mmai-research/pytorch-video-understanding\nvideo object segmentation:\nhttps://github.com/yoxu515/aot-benchmark?ref=pythonawesome.com\nvideo scene segmentation:\nhttps://github.com/kakaobrain/bassl?ref=pythonawesome.com\nmmaction detect actions in video:\nhttps://pythonawesome.com/an-open-source-toolbox-for-video-understanding-based-on-pytorch/\nhttps://github.com/open-mmlab/mmaction2\ndense video captioning:\nhttps://www.opensourceagenda.com/projects/dense-video-captioning-pytorch\nhttps://www.opensourceagenda.com/projects/dense-video-captioning-pytorch\nseq2seq video captioning:\nhttps://blog.csdn.net/u013010889/article/details/80087601\n2d cnn with LSTM video classification:\nhttps://blog.csdn.net/qq_43493208/article/details/104387182\nspp-net for image shape unification:\nhttps://github.com/peace195/sppnet\nhttps://github.com/yueruchen/sppnet-pytorch\nrunning pretrained pytorchvideo video classification model from zoo:\nhttps://pytorchvideo.org/docs/tutorial_torchhub_inference\npytorchvideo model zoo:\nhttps://pytorchvideo.readthedocs.io/en/latest/model_zoo.html\n(arxiv) end to end generative pretraining multimodal video captioning mv-gpt:\nhttps://arxiv.org/abs/2201.08264v1\nvideo captioning using encoder-decoder:\nhttps://github.com/Shreyz-max/Video-Captioning\nvideo captioning video2text keras implementation:\nhttps://github.com/alvinbhou/Video2Text\nvideo summarization:\nhttps://github.com/shruti-jadon/Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming\npytorch_video video classification:\nhttps://pytorchvideo.org/docs/tutorial_classification\nvideo feature extractor:\nhttps://github.com/hobincar/pytorch-video-feature-extractor"
  },
  {
    "objectID": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#概述",
    "href": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#概述",
    "title": "识别视频语言",
    "section": "概述",
    "text": "概述\n视频里面的语言分为图片上面打出来的字幕以及人说的话\n涉及到的问题分别为： 图片文字的语言分类 以及音频语言分类"
  },
  {
    "objectID": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#音频识别",
    "href": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#音频识别",
    "title": "识别视频语言",
    "section": "音频识别",
    "text": "音频识别\nonline speech recognition\npip install SpeechRecognition\noffline, need to provide language id:\nhttps://pypi.org/project/automatic-speech-recognition/\nuse paddlespeech if possible, for chinese and english"
  },
  {
    "objectID": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#图片语言识别",
    "href": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#图片语言识别",
    "title": "识别视频语言",
    "section": "图片语言识别",
    "text": "图片语言识别\nuse google cloud to detect language type in image:\nhttps://github.com/deduced/ml-ocr-lang-detection\nDetects and Recognizes text and font language in an image\nhttps://github.com/JAIJANYANI/Language-Detection-in-Image\n图片语言文字分类 可以用easyocr实现 加载多个模型 比如 中文加英文加日语 b站其他语言的可能也不怎么受欢迎 最多再加韩语\n可以从视频简介 标题 链接里面提取出句子 每个句子进行语言分类 确定要使用的OCR模型 也有可能出现描述语言和视频图片文字语言不一致的情况\nwolfram language提供了一个图片分类器 分类出来的结果可能很有意思 可以结合苹果的图片关注区域生成器来结合使用\nImageIdentify[pictureObj]\n这个方法还支持subcategory分类 支持多输出 具体看文档\nhttps://www.imageidentify.com/about/how-it-works\nwolfram支持cloud deploy 到wolfram cloud不过那样可能不行"
  },
  {
    "objectID": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#文本语言识别分类",
    "href": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html#文本语言识别分类",
    "title": "识别视频语言",
    "section": "文本语言识别分类",
    "text": "文本语言识别分类\nlingua performs good in short text, can be used in java or kotlin\nsupporting detecting different languages:\ncld2 containing useful vectors containing text spans python binding\n&gt;&gt;&gt; import pycld2 as cld2\n&gt;&gt;&gt; text_content = \"\"\" A accès aux chiens et aux frontaux qui lui ont été il peut consulter et modifier ses collections et exporter Cet article concerne le pays européen aujourd’hui appelé République française.\nPour d’autres usages du nom France, Pour une aide rapide et effective, veuiller trouver votre aide dans le menu ci-dessus.\nWelcome, to this world of Data Scientist. Today is a lovely day.\"\"\"\n&gt;&gt;&gt; _, _, _, detected_language = cld2.detect(text_content,  returnVectors=True)\n&gt;&gt;&gt; print(detected_language)\n((0, 323, 'FRENCH', 'fr'), (323, 64, 'ENGLISH', 'en'))\noriginal cld3 is designed for chromium and it relies on chromium code to run\nofficial cld3 python bindings\nadditional Python language related library from geeksforgeeks:\ntextblob is a natural language processing toolkit\nfrom textblob import TextBlob\ntext = \"это компьютерный портал для гиков. It was a beautiful day .\"\nlang = TextBlob(text)\nprint(lang.detect_language())\n# ru\nlangid performs good in short text\ntextcat (r package)\ngoogle language detection library in python: langdetect\njavascript:\nhttps://github.com/wooorm/franc\npython version of franc:\npyfranc\nwlatlang.org provides whatlang-rs as rust package, also whatlang-py as python bindings"
  },
  {
    "objectID": "posts/869fd8ae-5a70-471b-b723-b8d97a14444a/index.html",
    "href": "posts/869fd8ae-5a70-471b-b723-b8d97a14444a/index.html",
    "title": "资本 政治 商业 统治 管理 原理",
    "section": "",
    "text": "画大饼（永远兑现不了的承诺 只兑现一点点）\n自相矛盾（给一个有争议的话题 或者让人群分化 对立）\n撒谎（一切都按照别人的愿望回答 然而不去实现 不去操作 反向实现 反向操作 或者虚拟化 电子化 意识形态化）"
  },
  {
    "objectID": "posts/a5e9c6eb-7b70-4d0f-94dd-8f44af5a8490/index.html",
    "href": "posts/a5e9c6eb-7b70-4d0f-94dd-8f44af5a8490/index.html",
    "title": "蹭网WiFi天线 雷达扫描 五轴机械臂",
    "section": "",
    "text": "利用淘宝铜片焊接的WiFi天线 安装在开源机械臂上 利用固定点抵达算法 扫描算法 自动探测WiFi源与方向的对应关系 机械手臂应当安装在比较高的支撑点上 周围不要挡着WiFi天线 有比较长的延长线 扫描算法不得超过线材的限制（旋转角度控制）必须得知初始态的绝对位置"
  },
  {
    "objectID": "posts/276202df-ec4c-483c-b6f9-3dc63e5bbb2d/index.html",
    "href": "posts/276202df-ec4c-483c-b6f9-3dc63e5bbb2d/index.html",
    "title": "适合夏天佩戴的耳机",
    "section": "",
    "text": "夏天用音响最好，用什么耳机\n耳机不能夹头 不能夹耳朵 不能长时间佩戴后耳朵化脓\n开放式耳机适合夏天佩戴\n\ncanyon挂耳式耳机\n飞利浦 shp9500\n高斯 portapro (夹头发)\n\n看起来可能适合夏天佩戴的封闭式头戴\n\nairpods max (华强北版？)\n赛睿 寒冰raw"
  },
  {
    "objectID": "posts/5c548e16-6ef0-441b-9176-167e5d45c731/index.html",
    "href": "posts/5c548e16-6ef0-441b-9176-167e5d45c731/index.html",
    "title": "途家scraping api",
    "section": "",
    "text": "搜索api 先通过fetch的api获得不同的限制条件\n从0开始 最多58页 每页30个 相同条件最多爬1740个 可以倒序排序来翻倍 可合并其他排序来收集更多\n用地区做限制 加上价格限制 或者加更多限制 使得总数少于1740*2=3480 用启发式策略 如果实在超过了预设限制不管了直接开始爬 这种策略可能没法暂停继续爬取"
  },
  {
    "objectID": "posts/94043d9a-08e0-43ba-8c58-876d65a7f546/index.html",
    "href": "posts/94043d9a-08e0-43ba-8c58-876d65a7f546/index.html",
    "title": "cybergod related projects",
    "section": "",
    "text": "git clone https://github.com/ruvnet/q-star\ngit clone https://github.com/tairov/QStarLearning.mojo\ngit clone https://github.com/estill01/open_qstar\ngit clone https://github.com/openai/Video-Pre-Training\ngit clone https://github.com/abhiprojectz/SingularGPT\ngit clone https://github.com/ddupont808/GPT-4V-Act\ngit clone https://github.com/Charmve/gpt-eyes\ngit clone https://github.com/OthersideAI/self-operating-computer\ngit clone https://github.com/unconv/gpt4v-browsing\ngit clone https://github.com/THUDM/CogVLM\ngit clone https://github.com/mnotgod96/AppAgent"
  },
  {
    "objectID": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#seed-generation",
    "href": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#seed-generation",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "seed generation",
    "text": "seed generation\n\nAI based\nSkyfire (learn a probabilistic CFG grammar) Learn&Fuzz (learn a RNN model of valid inputs) GAN (learn a GAN to generate legitimate seeds) Neuzz (learn a NN to model input -&gt; coverage)\n\n\nSymbolic Execution\nDriller QSYM DigFuzz SAVIOR Intriguer Matryoshka HFL\n\n\nstatic/dynamic analysis\nFANS"
  },
  {
    "objectID": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#seed-mutation",
    "href": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#seed-mutation",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "seed mutation",
    "text": "seed mutation\n\nAI based\nMopt LSTM RL ILF\n\n\nprogram based\nVUzzer GreyOne"
  },
  {
    "objectID": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#efficient-testing",
    "href": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#efficient-testing",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "efficient testing",
    "text": "efficient testing"
  },
  {
    "objectID": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#coverage-metrics",
    "href": "posts/00990400-2d1d-4547-ac32-5fd5ac4a824a/index.html#coverage-metrics",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "coverage metrics",
    "text": "coverage metrics"
  },
  {
    "objectID": "posts/7c0457ee-e1c9-403a-bfac-16bca136c966/index.html",
    "href": "posts/7c0457ee-e1c9-403a-bfac-16bca136c966/index.html",
    "title": "2022-08-18-03-35-56",
    "section": "",
    "text": "i decided to push myself a little bit by setting up schedules. no due date but it might make it clear for me to work on which project first.\nthough i could write what i want to do next in diary of course. the primary target is to make general schedules of course, the second or the target afterwards is to complete the development of the dog video generator."
  },
  {
    "objectID": "posts/4fb6f602-eeb2-4d69-abd7-0ae56b2155bf/index.html",
    "href": "posts/4fb6f602-eeb2-4d69-abd7-0ae56b2155bf/index.html",
    "title": "Discovering Zero-Day Exploits and Vulnerabilities in School Management Systems",
    "section": "",
    "text": "0day exploit finder recon\n学校后台漏洞\nedusrc 0day\nbluecms 0day"
  },
  {
    "objectID": "posts/6d2ebfff-6f81-4597-bb43-794a56f1f206/index.html",
    "href": "posts/6d2ebfff-6f81-4597-bb43-794a56f1f206/index.html",
    "title": "Unlocking the Secrets of Dreams: Brainwave Translation Explained",
    "section": "",
    "text": "brainwave translation\ninteresting dreams were found extract text, audio, visual, melody"
  },
  {
    "objectID": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#google-research",
    "href": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#google-research",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "google research",
    "text": "google research\ngwern wrote a fiction. he thinks agi starts from automl-zero which is similar to lazero and metalazero by name and perspective.\nby design lazero can be deeply aligned, inspecting and studying user’s actions. it also has its own exploration space. however, these expectations can never be fully satisfied at the same time. if you want more power, you have to let go."
  },
  {
    "objectID": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#lucidrains-repositories",
    "href": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#lucidrains-repositories",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "lucidrains repositories",
    "text": "lucidrains repositories\nthis one got lots of state-of-the-art implementations for close-sourced papers and also repos for AGI. stunning.\n\nAGI related\nJEPA-pytorch (WIP) yann lecun’s version how agi will be built\nPaLM scaling language model with pathways\n\n\nside projects\nmake a video text to video generation\nnuwa text to video generation"
  },
  {
    "objectID": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#opencog",
    "href": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#opencog",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "opencog",
    "text": "opencog\nmoses (supervised) for evolutionary program synthesis"
  },
  {
    "objectID": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#repos-on-github",
    "href": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#repos-on-github",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "repos on github",
    "text": "repos on github\nhe4o\naixijs general reinforcement learning in browser repo\nopennars\nbrain simulator 2 on windows platform"
  },
  {
    "objectID": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#materials-and-links",
    "href": "posts/7710f723-d0ef-40b3-8094-e55aef7a109c/index.html#materials-and-links",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "materials and links",
    "text": "materials and links\nDQfD: Learning from Demonstrations for Real World Reinforcement Learning (paper)\nmit class on AGI\njiaxiaogang’s god-knows-what theory and training logs\nawesome deep reinforcement learning (deep-rl)\nawesome agicocosci exhausitive list of papers and repos for cognitive science and AGI\nintroduction and links on AGI"
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#obs-remote-control",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#obs-remote-control",
    "title": "AGI that controls computer",
    "section": "obs remote control",
    "text": "obs remote control\nusing obs-websocket you can use python to do real scripting. but first spin up obs first (with websocket related commandline arguments)\nyou can also write and load scripts for obs, run on custom intervals and conditions."
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#audio-recording",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#audio-recording",
    "title": "AGI that controls computer",
    "section": "audio recording",
    "text": "audio recording\nyour OS may go slient if you want to record audio from “speakers”\n\nusing pyaudio, on macos, you need blackhole for sending all audio to oblivion, thus able to be recorded.\non Linux, you need audio loopback device.\nrun: sudo modprobe snd-aloop\nyou use hw:1:0 or “Analog Device Output” for slient output/speaker, and use hw:1:1 or “Analog Device Input” for recording."
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#benchmarks",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#benchmarks",
    "title": "AGI that controls computer",
    "section": "benchmarks",
    "text": "benchmarks\nit is always a mystery for us to develop the right ML model. however, we can setup guidelines of good performance over specific task.\nautomate the benchmark, setup metrics. there could be more room for trials and imagination."
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#encoding",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#encoding",
    "title": "AGI that controls computer",
    "section": "encoding",
    "text": "encoding\nuse hfft/rfft to transform multipart inputs (special bits, different part of mouse coords (x, y, dx, dy))\nif you want to use complex number as RNN input, you may need to swap ViT for ComplexConv2D, but maybe you just need a few.\n\nlibraries that handle complex neural networks:\ncomplexPyTorch\npytorch-complex"
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#multimodal",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#multimodal",
    "title": "AGI that controls computer",
    "section": "multimodal",
    "text": "multimodal\ndo our model have to output multimodal data?\nif you combine some “special” bits along with token embeding by ihfft, you may have to retrain the entire damn network. also in order to make way for special bits, you may have to introduce extra linear layer.\n\nsome may prefer “LoRA”? by only introducing few tunable params and changing the overall output?\n\nwe may not annotate anything in our dataset. in contrast, we will set goals and make multiple interfaces for our model to explore.\n\nyou can add special task specific embedding before passing to main model, then minus that task specific embedding after passing to classification model."
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#file-sharing-and-communication",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#file-sharing-and-communication",
    "title": "AGI that controls computer",
    "section": "file sharing and communication",
    "text": "file sharing and communication\nmake sure you don’t share important files as read/write on VM.\n\nyou may host some “execution server” on UTM VMs. you may expose your very large hard disk using WebDAV server. i think x11vnc and other vnc server may suffice for linux, but we always want to listen to the real operational data, including human operation/intervention, not just those in VNC protocols.\n\nWebDAV servers:\nwsgidav (python)\nwsgidav --host=192.168.64.1 --port=8081 --root=\"/Volumes/Toshiba XG3/works/agi_computer_control\"  --auth=anonymous\nwebdav-cli （nodejs)\nwebdav-cli --host=192.168.64.1 --port=8081 --username=root --password=root --path=\"/Volumes/Toshiba XG3/works/agi_computer_control\""
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#video-recording",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#video-recording",
    "title": "AGI that controls computer",
    "section": "video recording",
    "text": "video recording\nfor Ubuntu ARM VM, mss failed on wayland but pyautogui works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps.\n\nforcing ubuntu to use xorg by: sudo vim /etc/gdm3/custom.conf"
  },
  {
    "objectID": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#resize-utm-vm-disks",
    "href": "posts/4e0a0cae-6337-494d-a266-5188d7d31a2d/index.html#resize-utm-vm-disks",
    "title": "AGI that controls computer",
    "section": "resize UTM VM disks",
    "text": "resize UTM VM disks\nyou need to first resize the virtio disk in utm setting, then resize partition by using gparted, then update the device mapper"
  },
  {
    "objectID": "posts/f438f660-ecf2-47f4-aa68-56cbddc48fa8/index.html",
    "href": "posts/f438f660-ecf2-47f4-aa68-56cbddc48fa8/index.html",
    "title": "AI上色",
    "section": "",
    "text": "AI上色 ffmpeg去特定颜色 调色\n可能和GAN有关\nuse paddlegan for coloring\n可以去掉血腥色情 暴力可能不行 需要剪辑\nFFmpeg remove color: https://video.stackexchange.com/questions/33588/using-ffmpeg-can-i-remove-the-color-from-an-area-of-the-video http://johnriselvato.com/ffmpeg-how-to-remove-all-colors-except-one-from-a-video/\nface coloring: https://github.com/Xu-Justin/Grayscale-Face-Coloring\nnvidia coloring: https://developer.nvidia.com/blog/easily-colorize-black-and-white-photos-with-ai/\ngithub topic on image colorization: https://github.com/topics/image-colorization\ngithub repos on image colorization: https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image https://github.com/aDouladiris/Grayscale-Image-Colorization https://github.com/aakaashjois/Colorizing-Grayscale-Images https://github.com/emilwallner/Coloring-greyscale-images\ncurated list on image colorization: https://github.com/oskar-j/awesome-image-coloring"
  },
  {
    "objectID": "posts/2b4d7ba1-ef29-4743-840a-3005ea4e89e5/index.html",
    "href": "posts/2b4d7ba1-ef29-4743-840a-3005ea4e89e5/index.html",
    "title": "APFS for Linux",
    "section": "",
    "text": "APFS for Linux\ni use this adapter to transfer files (you know that) to kali.\nread only support. if write then the filesystem will break.\napfs-fuse read-only, single executable, no kernel module\nlinux-apfs-rw kernel module, read/write support"
  },
  {
    "objectID": "posts/d166c249-e689-4083-a5b6-c9375f598e42/index.html#lrc-files",
    "href": "posts/d166c249-e689-4083-a5b6-c9375f598e42/index.html#lrc-files",
    "title": "Advanced ASS subtitle Karaoke Effects",
    "section": "lrc files",
    "text": "lrc files\ncrop music that does not sing too early? maybe no need.\nwe need to sort them out by time! prevent serious issues.\nskip empty lines?\nlrc files only have start time but no end time. we group parallel lyrics by time, if they are close enough we make it into a group.\ngroups act as time separators. no two group share the same time. also group have maximum span time, minimum span time calculated by content, and group should always in bound.\nshould apply the same min-max rule when selecting my video clips\nall ass file tags, for custom karaoke effects creation\nmy karaoke effect:\n{\\k-50\\K400}\n{\\k-&lt;initial offset&gt;\\K&lt;total duration&gt;}\nplay ass file with mpv on demo video, full screen, no audio:\nrootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\ncreate karaoke effects https://github.com/Kagu-chan/FXSpindle\nkaraoke effects https://github.com/Youka/NyuFX pyonfx code recommend to use effect 2 beginners -&gt; 3 variants in examples, while 3 advanced -&gt; 2 testing pixels as reference (more advanced but incomplete, and might be very intensive) pyonfx documentation https://github.com/logarrhythmic/karaOK\naegisub and its plugins https://github.com/Myaamori/aegisub-cli https://github.com/qwe7989199/Lyric-Importer-for-Aegisub https://github.com/qwe7989199/aegisub_scripts https://github.com/lyger/Aegisub_automation_scripts http://www.aegisub.org/\neyecandy create karaoke ass files: https://github.com/Alquimista/Eyecandy-py\ncreate karaoke effects subtitle with lrc file, support chinese https://github.com/DYY-Studio/lrc2ass_py3"
  },
  {
    "objectID": "posts/8c5d565c-8da9-4ccd-8da1-5a66305a76ae/index.html",
    "href": "posts/8c5d565c-8da9-4ccd-8da1-5a66305a76ae/index.html",
    "title": "Agile Freelancing",
    "section": "",
    "text": "Agile Freelancing\nApps like QQ, Wechat, Dingtalk can be launched on linux, windows.\n闲鱼要anbox 在 Windows上面需要虚拟机 或者直接http投屏就可以 也可以监控的\ndeepin derivative container"
  },
  {
    "objectID": "posts/65bcda20-60a6-48ac-a9b2-1928cb336c29/index.html",
    "href": "posts/65bcda20-60a6-48ac-a9b2-1928cb336c29/index.html",
    "title": "Algorithms Compilers SICP CLRS CT4S",
    "section": "",
    "text": "Algorithms Compilers SICP CLRS CT4S\nthe algorithms\nintroduction to algorithms clrs 4th edition in python: https://zhuanlan.zhihu.com/p/466819939\nofficial clrs 4th edition python code\nclrs 4th pdf\nclrs 3th edition python code: https://github.com/tonywangcn/Introduction-to-Algorithms-3rd-Edition-python-code\nsicp in python gitbooks: https://wizardforcel.gitbooks.io/sicp-in-python/content/18.html\nalgorithms 4th edition official java unofficial python code: https://github.com/kevin-wayne/algs4 https://github.com/shellfly/algs4-py https://github.com/itu-algorithms/itu.algs4"
  },
  {
    "objectID": "posts/23f3d7a6-2ff4-4a8f-b739-762334eaa099/index.html",
    "href": "posts/23f3d7a6-2ff4-4a8f-b739-762334eaa099/index.html",
    "title": "Android Emulators",
    "section": "",
    "text": "Android Emulators\nWayDroid\nanbox?"
  },
  {
    "objectID": "posts/2bb53f60-a1c3-4f30-943c-f4101e2736f1/index.html",
    "href": "posts/2bb53f60-a1c3-4f30-943c-f4101e2736f1/index.html",
    "title": "Anime smile detection_ segmentation",
    "section": "",
    "text": "Anime smile detection/ segmentation\nwhen an anime head is detected, cut it out and create dataset with labels. may augmented it with grayscale or edge detection.\nsegmentation using labeled data and train it on pretrained models. using anme head detection as double verification. no double heads.\nppse recognition may be applied without further training, or else.\n我分析需要YOLO确定人物位置 CNN判断服装类型 人物性别 ocr识别字幕 音频分析识别语气 性别 音乐类型 再用seq2seq来把所有的输出概括成我的描述\n或者看看有没有文字转关键词的模型\n可以的话加上人物姿态估计 动漫人物的\n关于光流算法：\n熵就是梯度的标准差 一段范围的熵就是起始时间到末尾的熵的标准差 或者起始到末尾的梯度的标准差"
  },
  {
    "objectID": "posts/ed84c46d-48de-4056-a6d8-13e063e3fead/index.html",
    "href": "posts/ed84c46d-48de-4056-a6d8-13e063e3fead/index.html",
    "title": "Attractive Dynamic plus attractive video",
    "section": "",
    "text": "Attractive Dynamic plus attractive video\nSome contents are viral to the users. Will add extra watches if combined with related video or essay.\nMay apply the same rule to other platforms. Must select those with largest views, or verified by trained grading models. Native language only, or we have to translate and verify/convey it into native form. Post it to QQ, other platforms in the form of pictures, links."
  },
  {
    "objectID": "posts/a7f976e6-4185-4ab6-8215-655389ba292d/index.html",
    "href": "posts/a7f976e6-4185-4ab6-8215-655389ba292d/index.html",
    "title": "Royalty Free Video/Picture/Audio Sources",
    "section": "",
    "text": "Royalty Free Video/Picture/Audio Sources\ndownload video without watermark 😛 源视频mp4链接获取: toutiao今日头条app视频;🍉xigua西瓜视频; 🐧tencent腾讯视频; 🎼douyin抖音分享短链接解析，获取无水印播放链接\n目标追踪使用bytetrack\n如果有动态水印 实际上就是一个目标追踪的任务 识别出来水印的位置 以及里面的文字 确定可信度 然后用目标跟踪算法套上去 一直跟踪直到目标消失为止\n类似的策略也可以应用于游戏 选出来所有的过场动画 过滤掉游戏画面\n静态的就用dewatermark算法就好了\n视频素材 影视素材 音频素材 图片素材 无水印获取\nuse bing wallpaper\ngettyimages scraped by github provided scrapers https://github.com/chuanenlin/shutterscrape https://github.com/m-rots/getty/blob/master/getty.go\n视觉中国 无水印爬虫"
  },
  {
    "objectID": "posts/a8563897-72ba-4912-9f83-787cfbc78cf7/index.html#for-macos-and-linux",
    "href": "posts/a8563897-72ba-4912-9f83-787cfbc78cf7/index.html#for-macos-and-linux",
    "title": "Automatic CMCC network switching",
    "section": "for macos and linux:",
    "text": "for macos and linux:\nif modifier hotspot is present, connect to it.\notherwise if CMCC present, connect to it.\nif CMCC fails after login attempts, try to connect with some paid network."
  },
  {
    "objectID": "posts/a8563897-72ba-4912-9f83-787cfbc78cf7/index.html#for-modifier",
    "href": "posts/a8563897-72ba-4912-9f83-787cfbc78cf7/index.html#for-modifier",
    "title": "Automatic CMCC network switching",
    "section": "for modifier:",
    "text": "for modifier:\nif CMCC present, connect to it.\nif CMCC fails, try to connect with some paid network.\ninternet switch will be manually turned on, to save power."
  },
  {
    "objectID": "posts/a29cb8e9-933c-4735-a65a-214430428e76/index.html",
    "href": "posts/a29cb8e9-933c-4735-a65a-214430428e76/index.html",
    "title": "BDD behavior driven development",
    "section": "",
    "text": "BDD behavior driven development\nbehave doc pypi\npytest-bdd"
  },
  {
    "objectID": "posts/1ab5ce30-5e17-4fe1-9900-43bfda353ece/index.html",
    "href": "posts/1ab5ce30-5e17-4fe1-9900-43bfda353ece/index.html",
    "title": "Beautify 美颜",
    "section": "",
    "text": "Beautify 美颜\nopencv bilateral filter python\nimport cv2 as cv\n\nimg = cv.imread('image.jpg')\n\nbilateral = cv.bilateralFilter(img, 15, 75, 75) \n\ncv2.imwrite('img_bilateral.jpg', bilateral)\nhttps://github.com/xujingzhou/VideoBeautify\npython美颜瘦脸 https://github.com/Sharpiless/opencv-pyqt-makeup-software https://github.com/geeklili/Opencv_PIL https://github.com/PerpetualSmile/BeautyCamera\nJavaScript 美颜 https://github.com/KikyoMiao/beauty"
  },
  {
    "objectID": "posts/7b1a2802-be9a-4479-95ed-ca3b2f5be030/index.html",
    "href": "posts/7b1a2802-be9a-4479-95ed-ca3b2f5be030/index.html",
    "title": "Boot into Linux commandline (tty)",
    "section": "",
    "text": "Boot into Linux commandline (tty)\nwhen xorg fails, one must use commandline to debug problems.\nput ‘3’ after the longest line of boot commands.\nuse ssh to collect logs even if the main interface is stuck somehow (like libinput faliure)\nreference:\nhttps://www.linuxandubuntu.com/home/how-to-boot-into-linux-command-line/amp"
  },
  {
    "objectID": "posts/f0459443-f60a-4311-ad40-8219c5272216/index.html#linux",
    "href": "posts/f0459443-f60a-4311-ad40-8219c5272216/index.html#linux",
    "title": "CPU Overheating (temperature too high)",
    "section": "linux",
    "text": "linux\ncpufrequtils\nthrottling cpu frequencies by temperature incrementally\nthe desired temperature is 60.\nusually when one throttles the CPU temperature, the GPU cannot be overheated.\nit is turning my core i7 into a pentium 3! but not entirely cumbersome."
  },
  {
    "objectID": "posts/f0e5256d-f160-48a1-9ba5-42a732dc3ed9/index.html",
    "href": "posts/f0e5256d-f160-48a1-9ba5-42a732dc3ed9/index.html",
    "title": "Captured School Wifi Credentials",
    "section": "",
    "text": "Captured School Wifi Credentials\nB19021434@cmcc // not working. reacquiring abc123456+\nB19021519 zjt010820-"
  },
  {
    "objectID": "posts/5cb6edd2-8078-44cd-b29d-85c1f8436326/index.html",
    "href": "posts/5cb6edd2-8078-44cd-b29d-85c1f8436326/index.html",
    "title": "Cats video with lyrics_1",
    "section": "",
    "text": "Cats video with lyrics (Lyrics)\nAgain i want to start finding lyrics, tired of sourcing & analyzing videos.\n一系列的视频观众都要看下去 那么下一期视频最好就是用该类视频的推荐下一个（类）视频作为模板来做的\nusing yolov7 to detect and cut cat/dog videos. https://github.com/WongKinYiu/yolov7\nagain found in github.\nnetease music’s apis have been reverse engineered on github. https://github.com/Binaryify/NeteaseCloudMusicApi\nwhat about spotify apis? https://github.com/thelinmichael/spotify-web-api-node (credentials are optional) https://github.com/JMPerez/spotify-web-api-js https://github.com/plamere/spotipy\nhttps://github.com/0xHJK/music-dl\nalso its proxy scraper.\npip3 install pymusic-dl\nwrite a redirect plugin in tampermonkey, from github to hub.fastgit.org\nagain, done by you-get. but how do we search the uri? you need to dig into the music_dl.\nso we are done in preposessing or anything?\nnow we need to find a bunch of cats.\ncats are found on weibo."
  },
  {
    "objectID": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#model-selection",
    "href": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#model-selection",
    "title": "ChatGPT Local Version",
    "section": "Model Selection",
    "text": "Model Selection\nBelow are some models we are about to use:\n\nChatRWKV, or RWKV-based models, some are fine-tuned on alpaca dataset.\nChatGLM-6B, open-sourced by Tsinghua KEG, with INT4 quantized version.\nOpenAssistant by LAION-AI, trained on their own OIG dataset. There are also few models contributed by their discord community.\nAlpaca, trained on alpaca dataset (synthetic, generated by ChatGPT) by Standford University. Model weights are community provided.\nChatYuan by ClueAI.\n\nThere are quite a few more models to be listed. You can check this curated open-sourced ChatGPT-like model list for updates. But for now, these models shall be sufficient."
  },
  {
    "objectID": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#quantization-and-optimization",
    "href": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#quantization-and-optimization",
    "title": "ChatGPT Local Version",
    "section": "Quantization and Optimization",
    "text": "Quantization and Optimization\nFloating-point values in model weights are stored as 32bit. Quantization can reduce storage space and computation by switching to 16bit, 8bit or 4bit values. However, most quantized models cannot be trained or fine-tuned, some 16bit models can only be trained on certain architecture of GPUs, such as Ada and Turing.\nTo make LLM (Large Language Model) inference feasible on common hardware, GPU is usually mandatory. However, most commondity GPUs have smaller VRAM compared to RAM, limiting the size of LLM to be run, thus the capability of the LLM. Most computer have 12GB of VRAM, 32GB of RAM. GGML is a project aiming to make LLM inference on CPU as fast as GPU, utilizing larger RAM compared to VRAM to run larger LLMs. Currently some popular LLMs have been ported to GGML, like LLaMA and Alpaca."
  },
  {
    "objectID": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#training-and-fine-tuning",
    "href": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#training-and-fine-tuning",
    "title": "ChatGPT Local Version",
    "section": "Training and Fine-tuning",
    "text": "Training and Fine-tuning\nIn deeplearning, people tend to tune all parameters during training, requiring much VRAM and time. To train GPT3.5 aka ChatGPT, OpenAI spends millions to rent interconnected A100 GPUs. This is impossible for an individual to afford such.\nWith technologies like LoRA, by freezing most part of the model and introducing a small fraction of tunable parameters, training requirements can be greatly reduced. One can easily tune 7B LLaMA or 14B RWKV using LoRA on a PC (usually rented on the cloud, such as AutoDL) with a single 80GB A100 card and 200GB of RAM."
  },
  {
    "objectID": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#prompting-and-chaining",
    "href": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#prompting-and-chaining",
    "title": "ChatGPT Local Version",
    "section": "Prompting and Chaining",
    "text": "Prompting and Chaining\nLLMs are general problem solvers given enough external storage and access to search engines. Text is the only way to language models (not for multimodal LLMs, like GPT4, OFA or UniLM).\nTo enhance the capability of LLMs, you have to maintain its memory, define action keywords and trigger external actions during the conversation, connect it to semantic search engines powered by other AI models like sentence transformers.\nOne such library is LangChain."
  },
  {
    "objectID": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#serving-as-api",
    "href": "posts/0d405a83-e39d-4e6e-9d42-da1e1a2ae402/index.html#serving-as-api",
    "title": "ChatGPT Local Version",
    "section": "Serving as API",
    "text": "Serving as API\nThe process of generation for LLMs is sequential. Server needs to maintain a streaming API to match this behavior. Tokens are fetched one by one from the server with a constant speed, revealed in the frontend.\nOne can check third-party frontend-only or self-hosted projects for conversational LLMs for reference."
  },
  {
    "objectID": "posts/6e328beb-8ca2-419b-963b-3fd7e8a74332/index.html",
    "href": "posts/6e328beb-8ca2-419b-963b-3fd7e8a74332/index.html",
    "title": "Chinese Input Method or Engine",
    "section": "",
    "text": "Chinese Input Method/Engine\nusing python: https://github.com/R0uter/LoginputEngine\npinyin2hanzi: https://github.com/letiantian/Pinyin2Hanzi\nPython chinese to pinyin: https://github.com/mozillazg/python-pinyin\npyim tsinghua dict(for emacs): https://github.com/redguardtoo/pyim-tsinghua-dict\nchinese input method dict converter: https://github.com/studyzy/imewlconverter"
  },
  {
    "objectID": "posts/1875f734-2c63-4083-bf2d-767c44fddb25/index.html",
    "href": "posts/1875f734-2c63-4083-bf2d-767c44fddb25/index.html",
    "title": "Cloud based Github Web IDE, VSCode auto commit and lightweight terminal IDE",
    "section": "",
    "text": "Cloud based Github Web IDE, VSCode auto commit and lightweight terminal IDE\nsolved by gitfs\nlibgit2 sucks.\nmost stars this gitfs is actually a searchable git history filesystem.\ntested\ngitee python api, first step is to get access token by login\ngitee apis\ncan we mount git/github repo as user filesystem(fuse)?\nusually read-only github/git filesystems, but this one is different. it is backed by writable github apis and is written in python, with python implementation of fuse which is updated here. this pygithub has trending api(maybe?) which is useful for social engineering or propaganda.\nwe could also implement a watchdog like system to check against the files using pygithub.\ncloud based github ide includes gitpod.io, github.dev, pythonanywhere but these are with serious limitations, most importantly without autocommit or too restricted to write code.\nbrowse github repo as remote filesystem(vscode insider): https://marketplace.visualstudio.com/items?itemName=github.remotehub\nthe vscode desktop is too resource heavy. though we have found a plugin to auto commit that also has a github repo to git repo(only for vscode insider):\nspacevim with custom color theme and nerdfont installed.\nspacevim documentation\nvim wiki by fandom\nrun multiple vim commands at once:\n:cd / | NERDTree"
  },
  {
    "objectID": "posts/0c951c40-394b-4532-b9a5-c20a7d558721/index.html#design-pattern",
    "href": "posts/0c951c40-394b-4532-b9a5-c20a7d558721/index.html#design-pattern",
    "title": "Code Batch Change Tool, Code Refactor Tool (the new sed)",
    "section": "design pattern",
    "text": "design pattern\nPyDesignPattern Design Pattern that described by Python, This is the source code for the book of Everybody Know Design Patterns."
  },
  {
    "objectID": "posts/0c951c40-394b-4532-b9a5-c20a7d558721/index.html#language-independent",
    "href": "posts/0c951c40-394b-4532-b9a5-c20a7d558721/index.html#language-independent",
    "title": "Code Batch Change Tool, Code Refactor Tool (the new sed)",
    "section": "language independent",
    "text": "language independent\ncomby.dev multiple language support\nsemgrep"
  },
  {
    "objectID": "posts/0c951c40-394b-4532-b9a5-c20a7d558721/index.html#language-specific",
    "href": "posts/0c951c40-394b-4532-b9a5-c20a7d558721/index.html#language-specific",
    "title": "Code Batch Change Tool, Code Refactor Tool (the new sed)",
    "section": "language specific",
    "text": "language specific\n\njavascript\njscodeshift refactor rewrite javascript code\n\n\npython\nredbaron repo and doc\nbowler\nrefactor\npasta"
  },
  {
    "objectID": "posts/66fd8158-cebd-44ae-9dc1-34eeb727e30b/index.html",
    "href": "posts/66fd8158-cebd-44ae-9dc1-34eeb727e30b/index.html",
    "title": "Converting partial Zhihu viral content",
    "section": "",
    "text": "Converting partial Zhihu viral content\njust add a trailing sentence. 请听下回分解。"
  },
  {
    "objectID": "posts/6c2ada9f-7b85-416e-9386-1f0f7a44368d/index.html",
    "href": "posts/6c2ada9f-7b85-416e-9386-1f0f7a44368d/index.html",
    "title": "Copy Symlink itself to change pyjom’s location, install easyd services for macos local pyjom watchdog",
    "section": "",
    "text": "Copy Symlink itself to change pyjom’s location, install easyd services for macos local pyjom watchdog\ncd /media/root/parrot\ncp -R -P /media/root/help1/pyjom .\nbecause of the qqChatBot task, pyjom on kali may be syncing too often. need to check the watchdog logs.\nturned out it is the __pycache__ dirs to be blamed\ndisable all sync related services on macos for debug:\nmain issue happens after local vscode launched.\nthe issue is such that the proxy setting not right.\nto debug the service:\nsudo launchctl debug gui/501/pyjom_local_syncdog --stdout --stderr\n# to be succint:\nlaunchctl list | grep syncdog | awk '{print $1}' | xargs -I abc kill -s TERM abc\n\n# instead of:\n#launchctl list | grep pyjom_local_syncdog # to get process pid\n#kill -s TERM &lt;service_pid&gt;\nwe need to add some code for it. consider adding something alike to that to kali?\nos.environ[\"http_proxy\"]=\"http://localhost:7930\"\nos.environ[\"https_proxy\"]=\"http://localhost:7930\"\nlaunchctl stop gui/501/pyjom_local_watchdog;\nlaunchctl kill TERM gui/501/pyjom_local_watchdog;\nlaunchctl unload gui/501/pyjom_local_watchdog;\nlaunchctl disable gui/501/pyjom_local_watchdog;\nlaunchctl remove gui/501/pyjom_local_watchdog;\n\nlaunchctl stop gui/501/pyjom_local_syncdog;\nlaunchctl kill TERM gui/501/pyjom_local_syncdog;\nlaunchctl unload gui/501/pyjom_local_syncdog;\nlaunchctl disable gui/501/pyjom_local_syncdog;\nlaunchctl remove gui/501/pyjom_local_syncdog\ninstall macos pyjom watchdog (local):\neasyd -l pyjom_local_watchdog -w /Users/jamesbrown/Desktop/works/sync_git_repos -- /usr/bin/python3 /Users/jamesbrown/Desktop/works/sync_git_repos/watchdog_macos.py\ninstall macos pyjom syncdog (local):\neasyd -l pyjom_local_syncdog -w /Users/jamesbrown/Desktop/works/sync_git_repos -- /usr/bin/python3 /Users/jamesbrown/Desktop/works/sync_git_repos/syncdog_macos.py"
  },
  {
    "objectID": "posts/ee5bf5b4-6b1a-4fd7-84dd-9a73482a052d/index.html",
    "href": "posts/ee5bf5b4-6b1a-4fd7-84dd-9a73482a052d/index.html",
    "title": "Create sparse matrix based liquid state machine",
    "section": "",
    "text": "Create sparse matrix based liquid state machine\nuse tensorly to create random sparse tensor and eye sparse tensor with ease, which could be numpy only, and requires the sparse package.\nscipy, pytorch, tensorflow, jax all support sparse tensor construction but advanced apis are not.\nuse eye to create bias and input matrix, extract node values. use random sparse tensor to initialize weight matrix. use self matrix multiplication to perform propagation.\n\nthe human brain has roughly 87 billion neurons, and every one of them has thousands of synapses.\n\nimport torch\nlarge_number = 1_000_000\ntorch.arange(large_number).unsqueeze(0).repeat(2, 1)\nindex_arr = torch.arange(large_number).unsqueeze(0).repeat(2, 1)\nval_arr = torch.ones(large_number)\nsparse_eye = torch.sparse_coo_tensor(index_arr, val_arr, (large_number, large_number))\n# sparse_eye.to('cuda')\nalternatively:\nimport torch\nimport tensorly.contrib.sparse as tsl_sp\nlarge_number = 1_000_000\nnumpy_eye = tsl_sp.eye(large_number)\ntorch_eye = torch.sparse_coo_tensor(numpy_eye.coords, numpy_eye.data, numpy_eye.shape)"
  },
  {
    "objectID": "posts/ffa71e40-3b13-45a1-9532-3d239e27a668/index.html",
    "href": "posts/ffa71e40-3b13-45a1-9532-3d239e27a668/index.html",
    "title": "Cyber Grand Challenge DARPA machine automated cyber attack",
    "section": "",
    "text": "Cyber Grand Challenge DARPA machine automated cyber attack\nctfwiki’s intro on CGC\nanalyze source code first, then plan attack or fix code\ncgc’s github repo and website\nsearch for darpa cgc on github\ncyber-challenge Some toy examples, to demonstrate ideas that could be used in DARPA’s Cyber Grand Challenge including modifying java bytecode and filter out html requests on the fly\nEVIL (Exploiting software VIa natural Language) is an approach to automatically generate software exploits in assembly/Python language from descriptions in natural language. The approach leverages Neural Machine Translation (NMT) techniques and a dataset that we developed for this work.\nTopics linux exploit encoder assembly decoder dataset seq2seq shellcode nmt software-exploitation codebert Resources Readme License GPL-3.0 license Stars 13 stars Watchers 3 watching Forks 1 fork Releases No releases published Packages No packages published Contributors 2 @piliguori piliguori Pietro Liguori @taisazero taisazero Erfan Al-Hossami Languages Python 97.6%\nShell 2.0%\nOther 0.4%"
  },
  {
    "objectID": "posts/f4e261ae-2563-4303-a940-30da73c8b2ec/index.html",
    "href": "posts/f4e261ae-2563-4303-a940-30da73c8b2ec/index.html",
    "title": "DALL_E Text to Image",
    "section": "",
    "text": "DALL_E Text to Image\nopen sourced text to image: https://github.com/lucidrains/DALLE-pytorch\ndalle_mini: https://github.com/borisdayma/dalle-mini\njina ai human in the loop multi prompt text to image dalle-flow: https://github.com/jina-ai/dalle-flow\ndalle playground: https://github.com/saharmor/dalle-playground"
  },
  {
    "objectID": "posts/1a0bb467-3980-4f46-aad7-11e5b4a406ab/index.html",
    "href": "posts/1a0bb467-3980-4f46-aad7-11e5b4a406ab/index.html",
    "title": "DNS Proxy for Campus Network",
    "section": "",
    "text": "DNS Proxy for Campus Network\nuse kaggle for testing, if we can connect to it we are good for 12 hours.\nthe campus network allows dns query, might allow dns port based proxies.\nuse dig for DNS avaliability check.\ndig baidu.com\nhttps://www.a2hosting.com/kb/getting-started-guide/internet-and-networking/troubleshooting-dns-with-dig-and-nslookup\ndns proxies:\nhttps://code.kryo.se/iodine/ https://0day.work/tunneling-all-traffic-over-dns-with-a-socks-proxy/ https://serverfault.com/questions/962961/socks-proxy-over-dns"
  },
  {
    "objectID": "posts/c95165bd-5186-44aa-b315-81c981efc51e/index.html",
    "href": "posts/c95165bd-5186-44aa-b315-81c981efc51e/index.html",
    "title": "Deepfake face swap",
    "section": "",
    "text": "Deepfake face swap\ndeepfacelab leading software for faceswap video generation: https://github.com/iperov/DeepFaceLab\nfaceswap: https://github.com/deepfakes/faceswap\narbitrary face swap on one single model: https://github.com/neuralchen/SimSwap"
  },
  {
    "objectID": "posts/3d85bd27-af16-4888-8752-6b2900d8e748/index.html",
    "href": "posts/3d85bd27-af16-4888-8752-6b2900d8e748/index.html",
    "title": "Setting Docker Container Storage Quota with Overlay and Different Storage Drivers",
    "section": "",
    "text": "Docker container storage quota\n--storage-opt is supported only for overlay over xfs with ‘pquota’ mount option.\nchange data-root to somewhere else in /etc/docker/daemon.json\nedit /etc/fstab and add our xfs block on new line (find uuid using blkid)\ndocker run --storage-opt size=10M --rm -it alpine\nwhen using devmapper make sure size is greater than 10G (default)\ndocker run --storage-opt size=11G --r'm -it alpine\nzfs, vfs (not a unionfs, but for testing) storage drivers also supports disk quota. you may use it by changing data-root to the related storage device."
  },
  {
    "objectID": "posts/a6c2f1d2-49af-4348-aa82-fbc0ac76944a/index.html",
    "href": "posts/a6c2f1d2-49af-4348-aa82-fbc0ac76944a/index.html",
    "title": "Douyin or Tiktok Social Media Video Download",
    "section": "",
    "text": "Douyin/Tiktok Social Media Video Download\nvideo download:\nhttps://github.com/Evil0ctal/Douyin_TikTok_Download_API https://github.com/Johnserf-Seed/TikTokDownload https://github.com/rouze-d/tiktok-download https://github.com/CuriousYoda/tiktok-downloader\nvideo api and deduplication:\nhttps://github.com/VideoData/DY-Data\nmany scrapers:\nhttps://github.com/Jack-Cherish/python-spider\nvideo multi download tool:\nhttps://github.com/smalls0098/video-parse-tools\ntiktok scrapers:\nhttps://github.com/drawrowfly/tiktok-scraper\ntiktok api:\nhttps://dteather.com/TikTok-Api/docs/TikTokApi/tiktok.html https://github.com/davidteather/TikTokBot"
  },
  {
    "objectID": "posts/0a44258a-e18e-4d7e-9bab-a2e5c7e66e00/index.html",
    "href": "posts/0a44258a-e18e-4d7e-9bab-a2e5c7e66e00/index.html",
    "title": "Ecosim",
    "section": "",
    "text": "Ecosim\n• You must demonstrate multiple examples of inheritance.\nYou may need to include classes that were not mentioned to demonstrate appropriate inheritance relationships. • You must demonstrate multiple examples of aggregation/composition/association. You may need to create lists of animals or tiles in the EcoSim class. • You must create methods not mentioned in the text above. • You must include one more type of animal, and one more plant in your program. • You must demonstrate polymorphism by calling overridden methods, or by checking the types of objects. • You must demonstrate good encapsulation by making dangerous variables private or protected and providing getter or setter methods to them. • You must include str and repr methods for each class. You may print(self) or print(animals) to help you with debugging. • You must update your UML diagram written in part 1 and submit it with your code. • Your code must be documented appropriately using docstrings. • You must make at least 10 commits using git with appropriate comments. You must use git version control to keep track of your progress during implementation. Only a local git repository is required in this assignment. You are not required to use an online repository, but if you choose to, please make sure your online repository is private. You should perform regular commits as you implement features and fix errors. Your commit comments should be short and reflect the changes that were made. • You must write a unit test for the game.Vector2D class. You will find Vector2D in the game.py file. You must create a new file called test_vector2d.py and write a test method for each of the following methods in Vector2D: add, subtract, scale, length, distance, normalize. You may either use the unittest or the pytest modules. Each test method should call those methods two times using different arguments: one safe set of arguments, and one dangerous set of arguments."
  },
  {
    "objectID": "posts/72d8b217-ee13-4c6e-a268-2abad59c0fcc/index.html",
    "href": "posts/72d8b217-ee13-4c6e-a268-2abad59c0fcc/index.html",
    "title": "Enable multiple concurrent RDP sessions on windows",
    "section": "",
    "text": "Enable multiple concurrent RDP sessions on windows\nuniversal termsrv.dll patch\nuse patched termsrv.dll"
  },
  {
    "objectID": "posts/412d8fbe-a243-4569-b85c-6d46dbfde266/index.html",
    "href": "posts/412d8fbe-a243-4569-b85c-6d46dbfde266/index.html",
    "title": "English Courseware scraping",
    "section": "",
    "text": "English Courseware scraping\nimman.ireadabc.com 账号：13408602063 密码：602063 按目录下载所有视频\ninit_url = “https://imman.ireadabc.com” # this url will not change at all. username = “13408602063” password = “602063” main_url = “https://iteachabc.com/airclass_imman”\nhttps://iteachabc.com/imman/login?acsid=8974dc67-b02e-4f0d-a83f-a03cbe6f7fe4\n91reading.com 账号：jpa 密码：602063 按目录下载所有课件"
  },
  {
    "objectID": "posts/d8252058-e874-4ac9-a389-84a621e9b954/index.html",
    "href": "posts/d8252058-e874-4ac9-a389-84a621e9b954/index.html",
    "title": "Exception Phobia in Python",
    "section": "",
    "text": "Exception Phobia in Python\npylint --enable=unspecified-exception your_python_file.py\nHowever it is recommend to build microservices and log failures"
  },
  {
    "objectID": "posts/c98a9c5f-4e46-4f6c-814d-b23fa7e66124/index.html",
    "href": "posts/c98a9c5f-4e46-4f6c-814d-b23fa7e66124/index.html",
    "title": "Extract voice from professional sources",
    "section": "",
    "text": "Extract voice from professional sources\nYou can source audio from audio books, radios, anime voices, soap series, movies, live streaming, broadcasting, tv and so on."
  },
  {
    "objectID": "posts/e62e5f70-90cb-4aba-bfcf-eac1ff0ce0f2/index.html",
    "href": "posts/e62e5f70-90cb-4aba-bfcf-eac1ff0ce0f2/index.html",
    "title": "Fall detection can be used for media filtering",
    "section": "",
    "text": "Fall detection can be used for media filtering\nwe can select falling videos collection for fun. it is based on human pose classification."
  },
  {
    "objectID": "posts/9a64235d-742b-44f4-8276-6589ae0569d6/index.html",
    "href": "posts/9a64235d-742b-44f4-8276-6589ae0569d6/index.html",
    "title": "GAN Generating video Motion Driven Still Image to Video",
    "section": "",
    "text": "GAN Generating video Motion Driven Still Image to Video\nthin plate spline motion model\nvideo animation generation only using few character portraits: 根据角色设定图画出人物动画（有动画驱动器） https://github.com/megvii-research/CoNR\ngalgame video generator using pygame（自动化类galgame动画生成器）: https://github.com/w4123/TRPG-Replay-Generator\ndigan, could generate taichi videos suggest you to segment video first and then use this to do the freaking work. https://github.com/sihyun-yu/digan?ref=pythonawesome.com https://sihyun-yu.github.io/digan/ https://pythonawesome.com/official-pytorch-implementation-of-generating-videos-with-dynamics-aware-implicit-generative-adversarial-networks/\nMoCoGAN can generate the same object performing different actions, as well as the same action performed by different objects: https://github.com/sergeytulyakov/mocogan\nstill image to talking with hands moving video generation compared to FOMM, can even animate non-human objects: https://snap-research.github.io/articulated-animation/\nmontage.ai generate video by music with deep analyzer: https://github.com/Tartar-san/montage.ai\ntiktok hashtag montage: https://github.com/andreabenedetti/tiktok-montage"
  },
  {
    "objectID": "posts/da45b5f4-5a68-4da7-83f4-e202d599034d/index.html",
    "href": "posts/da45b5f4-5a68-4da7-83f4-e202d599034d/index.html",
    "title": "Mastering Text Classification: Exploring NLP Techniques with BERT-NER, ALBERT-NER, GPT2, and More",
    "section": "",
    "text": "GAN for NLP text generation\nGAN Journey: https://github.com/nutllwhy/gan-journey\nNLPGNN: https://github.com/kyzhouhzau/NLPGNN Examples (See tests for more details):\nBERT-NER (Chinese and English Version) BERT-CRF-NER (Chinese and English Version) BERT-CLS (Chinese and English Version) ALBERT-NER (Chinese and English Version) ALBERT-CLS (Chinese and English Version) GPT2-generation (English Version) Bilstm+Attention (Chinese and English Version) TextCNN(Chinese and English Version) GCN, GAN, GIN, GraphSAGE (Base on message passing) TextGCN and TextSAGE for text classification"
  },
  {
    "objectID": "posts/93d5dcbb-e272-411b-8b6a-f5617d0eb56d/index.html",
    "href": "posts/93d5dcbb-e272-411b-8b6a-f5617d0eb56d/index.html",
    "title": "GPT-2 以及文本生成",
    "section": "",
    "text": "GPT-2 以及文本生成\n免费gpt文本生成：彩云小梦 以及小梦海外版\n小梦的中文文本有涉及政治的检测器 不能把敏感内容塞进小梦\n对话生成 https://huggingface.co/thu-coai/CDial-GPT_LCCC-large/tree/main\ntwitter generator inspired by influencers: https://github.com/gdemos01/TwitterInfluencerAI\nchinese LM\n清华130b大模型 测试地址：https://huggingface.co/spaces/THUDM/GLM-130B 模型仓库：https://github.com/THUDM/GLM-130B\nhttps://github.com/Morizeyao/GPT2-Chinese https://zhuanlan.zhihu.com/p/352028922 https://github.com/TsinghuaAI/CPM-1-Finetune https://github.com/TsinghuaAI/CPM-1-Generate https://github.com/TsinghuaAI/CPM-2-Pretrain\ngpt2/cpm tutorial:\nhttps://www.cnblogs.com/wwj99/p/12503545.html https://github.com/OpenBMB/BMInf-demos https://bmtrain.readthedocs.io/en/latest/index.html"
  },
  {
    "objectID": "posts/fa6d1db6-73a8-4172-9fe2-49e0fb216a27/index.html",
    "href": "posts/fa6d1db6-73a8-4172-9fe2-49e0fb216a27/index.html",
    "title": "Unlocking Speed: FastGithub - Accelerating Github and StackOverflow",
    "section": "",
    "text": "Github and Stackoverflow acceleration\nhttps://github.com/dotnetcore/FastGithub"
  },
  {
    "objectID": "posts/c8f5dd23-ce05-4170-8449-8f60b1483b02/index.html",
    "href": "posts/c8f5dd23-ce05-4170-8449-8f60b1483b02/index.html",
    "title": "Graphcore support for AI",
    "section": "",
    "text": "Graphcore support for AI\nGraphcore’s IPU could be cheaper and faster than NVIDIA’s A100, though need sharing on-board RAM. Supports tensorflow, pytorch, paddlepaddle. https://docs.graphcore.ai/en/latest/\npytorch: poptorch, pytorch-lightning(tpu and ipu)\ntensorflow: from tensorflow.python import ipu\n\n\nCreate an IPU distribution strategy\nstrategy = ipu.ipu_strategy.IPUStrategy()\nwith strategy.scope(): …\npaddlepaddle: https://github.com/graphcore/portfolio-examples/tree/master/paddlepaddle/bert-base\nhttps://github.com/graphcore/Paddle.git\nTensorFlow 1 & 2 support with full performant integration with TensorFlow XLA backend PyTorch support for targeting IPU using the PyTorch ATEN backend PopART™ (Poplar Advanced Runtime) for training & inference; supports Python/C++ model building plus ONNX model input Full support for PaddlePaddle Other frameworks support coming soon"
  },
  {
    "objectID": "posts/4bb36c9b-5443-4b0d-adfb-c58d810d1448/index.html",
    "href": "posts/4bb36c9b-5443-4b0d-adfb-c58d810d1448/index.html",
    "title": "Hardware Simulator",
    "section": "",
    "text": "Hardware Simulator\npyspice uses ngspice and xyce as backend, capable of simulating MOS, JFET, diode and more"
  },
  {
    "objectID": "posts/7fdb5e3f-8344-4e9f-b53b-cb87c2d992fd/index.html",
    "href": "posts/7fdb5e3f-8344-4e9f-b53b-cb87c2d992fd/index.html",
    "title": "HarmonyOS Device Log to MySQL",
    "section": "",
    "text": "HarmonyOS Device Log to MySQL\nmysql path: jdbc:mysql://10.33.163.33:3306/HTS_DB?characterEncoding=UTF-8 root pipeline@123\nLogs Path: /data/data/Local/DeviceTest/20220406163617_hts_project/resources/HTS/android-hts/logs\nunder logs: %Y.%m.%d_%H.%M.%S_ select the latest folder\nunder selected folder: device_logcat_test__.txt.gz\ndecompress using: (before that os.chdir to the selected folder) gzip -d \ndoes the decompression remove the .gz file? it will.\nlog format per line: DfxTestLog: A1__DfxTestTime =  datai=4\nfrom 1 to 13: A1test1..4 A2test5 A3test1..2 B1test1 B2test4..6 D1test1 M1test1\nTables:\nPerformance_Baseline_Info testValue date(%Y-%m-%d) hmsVersion(HMSCore660319) baselineId_id deviceId_id(1,2,4,3,5) deviceType(phone&lt;-1|wearable&lt;-2|car&lt;-4|tv&lt;-3|ecodevice&lt;-5)\nPerformance_Daily_Data id features indicators baseValue\nPerformance_Device_Info id(to the deviceId_id) model type sn cpu"
  },
  {
    "objectID": "posts/3d06fadf-ec5a-4af9-88da-64c194175254/index.html",
    "href": "posts/3d06fadf-ec5a-4af9-88da-64c194175254/index.html",
    "title": "Home Assistant Installation & Setups",
    "section": "",
    "text": "Home Assistant Installation & Setups\nFully functional HA mainly comes into two forms: flashable supervised .iso images, and virtual machines (not docker container).\nRemember to create backup of HA after successful initialization. You can create an iso for the entire disk or just using backup utility builtin.\nSupervisor need to be updated before other components. It is also the troublemaker. Set auto update of supervisor to false by:\nha supervisor options --auto-update=false\nSince its heavy reliance on docker and github, one need to use OpenClash along with OpenWrt flashed in one dedicated router like NanoPi R2S to smooth the installation process.\nUse video capture card and OBS studio to observe the RPI terminal. Attach to keyboard to type commands.\nha banner sometimes resolves issues.\nTo prevent addon installation limits, you can enter debug mode, edit the following file /mnt/data/supervisor/jobs.json into:\n{\n  \"ignore_conditions\": [\n    \"healthy\"\n  ]\n}\nSome files like /etc/docker/daemon.json, /etc/hosts cannot be changed after boot. You can change them before boot using card reader."
  },
  {
    "objectID": "posts/18687a6c-9169-4a57-bc84-9fa0b2ebf9da/index.html",
    "href": "posts/18687a6c-9169-4a57-bc84-9fa0b2ebf9da/index.html",
    "title": "How to create cybergod",
    "section": "",
    "text": "How to create cybergod\nhttps://www.novaspivack.com/business/the-four-levels-of-ai-steps-to-self-evolution https://www.novaspivack.com/business/exploring-higher-order-ai-training-on-first-order-ai-networks-for-optimal-path-outcomes\n\ni want to create some sort of agent, that learns autoregressively on historical tokens (not necessarily present in history, but close). however, when the agent is given some previous tokens, it is expected to send some actions to the environment in order to really observe the given tokens to get reward. the agent is not allowed to directly generate the token to the environment in order to prevent cheating. the agent is rewarded to successfully rebuild the past or predict and build the future. to predict the future is like the target token is generated by the agent itself instead of some automatic history replay bot, and the rest of the reward system follows the same way as the history replay reward system. this kind of system might have some sort of consciousness and therefore agi\nthe main objective of AGI is to create another version of itself.\nthe verification system can be built upon internal hidden tokens (you feel like you made it, feeling based) or similarity based (timeseries similarity or semantic similarity). there can be some external verification system such as lifespan, disk usage, view count, popularity, total capital etc.\n\nthe main problem of making this work is how to train it in parallel. the real world can be replaced by some world model (say some neural network) so that it can go back in time, or some really fast real world evaluators or some special world evaluators which supports time traversal, like virtual machine snapshots, web browsers (tab traversal). alphago has such advantage because go game is a very simple world model, while the real world is not.\nalso this could build some hierarchy like: real world -&gt; world model -&gt; agent -&gt; superagent -&gt; …"
  },
  {
    "objectID": "posts/d9b497b3-1045-43df-a37b-1e6cf7e4c6d0/index.html",
    "href": "posts/d9b497b3-1045-43df-a37b-1e6cf7e4c6d0/index.html",
    "title": "Master Hugo: A Comprehensive Guide to Installing and Theming Your Blog",
    "section": "",
    "text": "Hugo the blog generator\ninstall hugo: https://gohugo.io/getting-started/installing/\ninstall hugo from snap: snap install hugo –channel=extended\ninstall on debian/ubuntu: apt-get install hugo\nhugo themes: https://themes.gohugo.io\nhow to create hugo blog: https://blog.csdn.net/cumi7754/article/details/108101980"
  },
  {
    "objectID": "posts/a2fffbb0-13dc-40ae-9abb-50365282fba2/index.html",
    "href": "posts/a2fffbb0-13dc-40ae-9abb-50365282fba2/index.html",
    "title": "Huggingface Mirror Sites",
    "section": "",
    "text": "Huggingface Mirror Sites\nmethods on network issues\nmirror site\npartial mirror site"
  },
  {
    "objectID": "posts/bfe37cce-26d4-4cf1-bccc-5ba792cdee52/index.html",
    "href": "posts/bfe37cce-26d4-4cf1-bccc-5ba792cdee52/index.html",
    "title": "Image Restoration Upscaling",
    "section": "",
    "text": "Image Restoration Upscaling Inpainting 图像修复 超分辨率\nsota image inpainting: lama-cleaner still needs manual labeling on inpainting area\nhttps://github.com/DmitryUlyanov/deep-image-prior\nnas image prior https://arxiv.org/abs/2008.11713\nmmediting: OpenMMLab Image and Video Restoration, Editing and Generation Toolbox"
  },
  {
    "objectID": "posts/b74fcf12-06c6-4c32-92dd-2c6facda9064/index.html",
    "href": "posts/b74fcf12-06c6-4c32-92dd-2c6facda9064/index.html",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "",
    "text": "Incremental testing, build tools, cacheing, logging\nhow to log error emitted from better-exceptions?\n\nlogging tutorial at betterstack & official\nother logging libraries: loguru structlog (able to show locals/globals around error)\n\nbetter-exceptions\n\nto ensure the consistency of tests, you need to collect input/output pairs (and compare with expected/actual output), if it is deterministic.\n\nmonkeytype, pytype (by google), runtype (Dispatch)\n\nbetter assertion\n\nenum class in python\n\nuse cache in pytest\nuse redis lru_cache, put decorators to json serializable functions\nuse build tools, forcing program to read and write files in the process\ntype checking using mypy\ncode static analysis\ncode formatter like black\n\ntools:\npydoit with “up to date” signals for non-file objectives\nscons\nruby rake"
  },
  {
    "objectID": "posts/58e0fe2a-00f8-4061-bb61-4380efbd0125/index.html",
    "href": "posts/58e0fe2a-00f8-4061-bb61-4380efbd0125/index.html",
    "title": "Intel 9250 bluetooth Win server",
    "section": "",
    "text": "Intel 9250 bluetooth Win server\nintel driver & support assistant https://www.intel.com/content/www/us/en/support/detect.html\nunzip the it admin pack for win 10 https://www.intel.com/content/www/us/en/download/16807/intel-wireless-bluetooth-for-it-administrators.html\nfollow instructions to find and modify driver https://www.sevenforums.com/network-sharing/415513-intel-wifi-ac-9260-driver-fir-win7-x32-x64.html Intel has updated the drivers since my first post. Current is now 20.70\nDownload Intel(R) PROSet/Wireless Software and Drivers for IT Admins\nYou should be downloading WiFi_20.70.0_Driver64_Win7 (your first post mentions both x32 and x64 so I am not sure which one you are running. Hopefully x64) In the package is a Netwsw04.INF file but not a Netwsw03.INF file.\nSomething I did not think of until now, is we need to ALSO use the WIN10 download package in order to see the lines where Intel calls out your specific driver. To find that, you need to also download the WiFi_20.70.0_Driver64_Win10 package. Within it, we need to look at the Netwtw06.INF file which is the file that has your device. You will need to cut-n-paste the two lines within that file that contain the string PCI_8086&DEV_A370&SUBSYS_42A48086. Or better yet forget all that, I’ll just cut-n-paste them now and include them in screenshots. You can ignore the Win10 download altogether in order to keep things straight.\nSo we cut and paste those two lines and put them within the Netwsw04.INF file that is in the win7 package. The first one goes at the top of the excludefrom select part, and the next one goes at the top of the DEVICE WIN7_64 section. I will attach a screenshots now of what these new lines look like within my editor. They are the highlighted lines. Since you cannot cut and paste from an image, here is the text of the two lines:\n1st line\n; PCI_8086&DEV_A370&SUBSYS_42A48086 ,\n\n2nd line\n%NIC_9462AC_HMC% = Install_MPCIEX_DELLM2CRF3DIVERSITY_9462_AC_HMC_WINT_64_AC , PCI_8086&DEV_A370&SUBSYS_42A48086 ; AC\nAs I mentioned before, the first line is near the top of the Netwsw04.inf file and the second line is about 5 pages down.\nHere’s a caveat, a new piece of information that is a potential show-stopper. See where within the second line there are three places where it says “AC”? That appears related to how the setup file integrates the driver later on in the file. Well over in the Win10 package it does not actually say “AC”, instead it says “No_160”, which is something that is part of the win10 package but not part of the win7 package. Based on text within the win10 setup file (the one named Netwsw06.inf) there appears to be a special section specifically for Dell machines called No_160. I’m over my head as to what exactly it all means, other than to say that since there is no section in the Win7 package called No_160, I had to change No_160 to AC in order for the win7 file to process the line, and of course it is possible that this driver cannot install without the No_160 section, meaning it is not installable on win7. So what that all adds up to is that when I first replied to you I was giving this method about a 70% chance of working, but now I would put the odds at 30%."
  },
  {
    "objectID": "posts/3e8b471a-80f7-4be6-9340-87831955ee9c/index.html",
    "href": "posts/3e8b471a-80f7-4be6-9340-87831955ee9c/index.html",
    "title": "Jiggy boring still image to funny dance video 跳舞 舞蹈",
    "section": "",
    "text": "Jiggy boring still image to funny dance video\n最新版代码: https://github.com/transpchan/Live3D-v2 MMD 格式转换工具： https://github.com/KurisuMakise004/MMD2UDP 官网：https://transpchan.github.io/live3d/ Colab:https://colab.research.google.com/github/transpchan/Live3D-v2/blob/main/notebook.ipynb CoNR群：362985749\n【[ai绘画]仅用4张图片合成一段舞蹈视频-哔哩哔哩】 https://b23.tv/NaF20nA\n用到的资料和项目地址 BV19V4y1x7bJ GitHub：https://github.com/megvii-research/CoNR GitHub：https://github.com/KurisuMakise004/MMD2UDP 配音：基于VITS的弥希miki音声：BV1vW4y1e7bn bgm：风神少女 视频如果有什么不对的地方，欢迎指出(▽) 侵删\nstill image to dancing\neverybody dance now: https://github.com/carolineec/EverybodyDanceNow\nedn pytorch implenentation: https://github.com/Lotayou/everybody_dance_now_pytorch"
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#malware-hacking",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#malware-hacking",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "malware, hacking",
    "text": "malware, hacking\ndo it!"
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#referral-spam",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#referral-spam",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "referral spam",
    "text": "referral spam\nReferral spam is used to get into a targeted businesses analytics by visiting their site multiple times with different IP’s from the domain you’re trying to market."
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#keyword-stuffing",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#keyword-stuffing",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "keyword stuffing",
    "text": "keyword stuffing\nencourage you to add more “hot” words, by training language model in a supervised way, or just use plain replace hacks."
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#open-graph-metadata-tag-easy-for-sharingadvertising-webpages-to-social-media",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#open-graph-metadata-tag-easy-for-sharingadvertising-webpages-to-social-media",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "open graph metadata tag, easy for sharing/advertising webpages to social media",
    "text": "open graph metadata tag, easy for sharing/advertising webpages to social media\nchange open graph data for same page once in a while\nopen graph tutorial\nfree open graph extractor"
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#scrape-and-rinse-content",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#scrape-and-rinse-content",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "scrape and rinse content",
    "text": "scrape and rinse content\nscrape from wayback machine (older but clean), check plagiarism in copyscape"
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#private-blog-networks",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#private-blog-networks",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "private blog networks",
    "text": "private blog networks\ncreate a bunch of websites, all refer to your own contents."
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#social-media-automation-tools",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#social-media-automation-tools",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "social media automation tools",
    "text": "social media automation tools\nInstagram: Instagress G+: Circlescope Linkedin: Elink Twitter: Managedflitter and Twitter toolkit chrome extension Youtube: Tubebuddy Facebook: Facebook automation toolkit chrome extension Pinterest: NinjaPinner Tumblr (blogging platform): Tumbleninja Email: Pitchbox"
  },
  {
    "objectID": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#jumpcut-courses",
    "href": "posts/86576874-e49d-4b03-8341-18840eb038ef/index.html#jumpcut-courses",
    "title": "Jumpcut analysis, social media marketing, blackhat SEO",
    "section": "jumpcut courses",
    "text": "jumpcut courses\njumpcut.com provides digital marketing courses: viral academy(free as youtube influencer 101 course), automated income machine(forbidden), video ads bootscamp(nothing, avaliable on freecoursedl.com), contageous content(currently premium)\nit features different camera angles of narriator’s portraits, relative animations and pdf sheets for fill-in-blank tasks. it emphasizes on email ads and audience funnel/filter.\nmany free course providers now offer jumpcut academy 2.0. they also offer technical analysis/ quantative analysis on marketing and other courses. though sometimes it is better to get to the code.\n中文的自媒体教程和它也是讲一个类型的内容，不过更倾向于实操和自动化。当然也有国外的自媒体教程。\n我觉得教程看太多了可能不利于代码实现。可以先把记录放在这里等待之后利用。\n搬运教程/课程也是一个好的方向，好的教程/课程需要被翻译或者洗稿，避免被维权。\n知乎上也有被我收藏下来的一个自媒体提高视频播放量的视频。他讲的是如何用连词，问句强行引起观众注意（拍摄技巧也可以强行引起观众注意，或者其他的方法，如连贯的语音）。可能知乎上面还有更多关于提高播放量以及和jumpcut有关的内容。"
  },
  {
    "objectID": "posts/ed13d1e2-e180-4090-adaa-afc4216fa6b8/index.html",
    "href": "posts/ed13d1e2-e180-4090-adaa-afc4216fa6b8/index.html",
    "title": "Kiwi Browser Bookmarks",
    "section": "",
    "text": "Kiwi Browser Bookmarks 2022/6/1\nlocation: sudo cp /data/user/0/com.kiwibrowser.browser/app_chrome/bookmarks.html ."
  },
  {
    "objectID": "posts/d89502c0-47fb-45dd-afef-9a75d12ad754/index.html",
    "href": "posts/d89502c0-47fb-45dd-afef-9a75d12ad754/index.html",
    "title": "Letsketch libwacom",
    "section": "",
    "text": "Letsketch libwacom\nworking on archlinux arm: libwacom 2.1.0-1\nnot working on kali linux: libwacom-bin 2.2.0-1\nfull reference:\nhttps://github.com/DIGImend/digimend-kernel-drivers/issues/514\nsudo nano /etc/X11/xorg.conf\nSection “InputClass” Identifier “Tablet” Driver “wacom” MatchDevicePath “/dev/input/event*” MatchUSBID “6161:4d15” EndSection\nto debug input problems:\nhttps://wiki.ubuntu.com/DebuggingMouseDetection#:~:text=In%20case%20your%20mouse%20stops%20working%20after%20a,your%20mouse%20stops%20working.%20…%20More%20items…%20\ncheck /etc/logs/Xorg.0.logs"
  },
  {
    "objectID": "posts/9900b9a1-04d5-4ec2-b101-258db5dc0e91/index.html",
    "href": "posts/9900b9a1-04d5-4ec2-b101-258db5dc0e91/index.html",
    "title": "Live Share Plugin, Clipboard syncing, peer programming, collaboration, multi-user editing",
    "section": "",
    "text": "Live Share Plugin, Clipboard syncing, peer programming, collaboration, multi-user editing\nlive share will always create a invitation link upon starting, so you can use clipboard listener based on event listeners or pyperclip (repeatedly checking content in clipboard, see if there’s any change), save the link to server or send via email.\n\nif clipboard is not your thing, there’s a massive anyIM-to-Matrix list\nyou can also setup your own sync app via instant messaging services.\n\nclipboard sync:\ncrossclip: Sync clipboard across macOS/Linux/Windows on LAN\nClipBroad: Sync via Github\n\nclipboard listeners:\nclipnotify for xorg (linux)\nwindows+v now act as multi-clipboard\nyou can sync clipboard across computers via crossclip\n\nmicrosoft liveshare\nduckly\ncodeshare alternatives"
  },
  {
    "objectID": "posts/d4d2df05-2db3-4e9e-aa9d-f4a0b203e85c/index.html",
    "href": "posts/d4d2df05-2db3-4e9e-aa9d-f4a0b203e85c/index.html",
    "title": "Linux Fan Not Spinning, GPU Fan Not Spinning",
    "section": "",
    "text": "Linux Fan Not Spinning, GPU Fan Not Spinning\neverytime the fucking machine restarts, it fails devastatingly.\nthe word: Giving the fans some time to reach full speed...\nthe script:\n#!/usr/bin/expect\nspawn pwmconfig\n#expect \"Giving the fans some time to reach full speed...\"\nexpect \"If you do not want to do this hit control-C now!!!\"\nsend \"\\03\"\nexpect eof\nhope this shit works?\necho 255 | sudo tee /sys/class/hwmon/hwmon6/pwm3\necho 255 | sudo tee /sys/class/hwmon/hwmon6/pwm1\ni have install something other than that. like i8kctl, some thermal controllers by intel (thermald)? but still gpu fan not spinning till now.\napt install -y lm-sensors fancontrol\nsensors-detect\npwmconfig\nalready have cpu frequency under control by running temp_throttle.sh\nnotes: found controllers dell_smm-isa-0000\n\nFound the following PWM controls:\n   hwmon6/pwm1           current value: 255\n   hwmon6/pwm3           current value: 255"
  },
  {
    "objectID": "posts/e250548a-3370-4a8e-9bf7-321fe640f29f/index.html",
    "href": "posts/e250548a-3370-4a8e-9bf7-321fe640f29f/index.html",
    "title": "Logic Optimizer for Different Models",
    "section": "",
    "text": "Logic Optimizer for Different Models\ncurrently we can use hyperopt as the online optimizer. of course for offline optimization there’s better option or prediction for it.\nFor a sequence of models, use classic logic solver to find best logic combination.\nselect model 0.\nselect model 1 with 0, iterate through 16 different situations(0, not 0, 1, not 1, 0 and 1, 0 or 1, 0 and not 1, 0 or not 1, not 0 and 1,not 0 or 1, not 0 and not 1, not 0 or not 1), choose the best one. mark it as model A.\nselect model 2, use the same optimizer to generate model B.\nfinally iterate through all models. generte model X as a combination of best logic models."
  },
  {
    "objectID": "posts/0ae670ab-e331-42b0-a88b-b4f1aca4c750/index.html",
    "href": "posts/0ae670ab-e331-42b0-a88b-b4f1aca4c750/index.html",
    "title": "MMDetection and MMD dancing",
    "section": "",
    "text": "MMDetection and MMD dancing\n3d 虚拟形象动作生成 视频生成 虚拟偶像 Vtuber: https://github.com/xianfei/SysMocap\nhuman pose detection: https://github.com/facebookresearch/VideoPose3D\nopengl recording:\nhttps://lencerf.github.io/post/2019-09-21-save-the-opengl-rendering-to-image-file/ http://www.songho.ca/opengl/gl_pbo.html#pack https://stackoverflow.com/questions/7634966/save-opengl-rendering-to-video https://www.codeproject.com/articles/15941/recording-directx-and-opengl-rendered-animations https://www.glfw.org/documentation.html\ndownload expose models: https://expose.is.tue.mpg.de/downloads\nsmpl-x model download: https://smpl-x.is.tue.mpg.de/download.php\nmodel zoo:\nhttps://github.com/Zhongdao/Towards-Realtime-MOT/blob/master/DATASET_ZOO.md\nmmd auto tracking:\nhttps://github.com/errno-mmd/mmdmatic/blob/master/setup.bat https://github.com/miu200521358/expose_mmd https://github.com/miu200521358/AlphaPose-MMD\nsmplx expose alternative body tracker: https://github.com/vchoutas/smplx\nface tracking:\nhttps://github.com/Aditya-Khadilkar/Face-tracking-with-Anime-characters\nanime face detector:\nhttps://github.com/nagadomi/lbpcascade_animeface https://github.com/qhgz2013/anime-face-detector\nanime facial features:\nhttps://github.com/pranau97/anime-detection\nrepair anime images:\nhttps://github.com/youyuge34/Anime-InPainting\npaint manga from sketch (with color blocks):\nhttps://github.com/youyuge34/PI-REC\nif we can re-trace the action/expression done by vtubers, we can monetize those “highlight cuts”.\nyou can firstly find points in datasets and then generate mmd videos, and then create trainset. you can also generate pose from raw video and then create dataset.\nfound occasionally when browsing MMD, but found this with so many stars, which is an instance detection/segmentation library. https://github.com/open-mmlab/mmdetection\nwhile rendering mmd can be done with mmd viewer like https://github.com/benikabocha/saba or could use renderer like blender or unity. we must bake physics before dancing.\nfound other dedicated renderer for mmd, with bullet physics: https://github.com/jinfagang/mmc\nfound interesting repo of poetry composing: https://github.com/jinfagang/tensorflow_poems\nmediapipe/paddlevideo alike: https://pypi.org/project/alfred-py/\nthree.js has multiple loaders: https://github.com/mrdoob/three.js/tree/dev/examples/js/loaders https://github.com/hanakla/three-mmd-loader\nrender MMD using saba lib: https://github.com/WLiangJun/MMD-Desktop-mascot\nhttps://github.com/miu200521358/expose_mmd/fork\nmusic based dance: https://github.com/DeepVTuber/DanceNet3D https://github.com/ColbyZhuang/music2dance_DanceNet https://github.com/caijianfei/Music2Dance\ncharacters: https://www.mixamo.com/#/?page=1&type=Character"
  },
  {
    "objectID": "posts/7fc97a43-0506-4c55-8bbf-2581574076dd/index.html",
    "href": "posts/7fc97a43-0506-4c55-8bbf-2581574076dd/index.html",
    "title": "Macbook M1 create macOS recovery usb",
    "section": "",
    "text": "Macbook M1 create macOS recovery usb"
  },
  {
    "objectID": "posts/536b9c0c-e3f7-4728-a3cd-b60e59e99ed8/index.html",
    "href": "posts/536b9c0c-e3f7-4728-a3cd-b60e59e99ed8/index.html",
    "title": "Media repurpose tool",
    "section": "",
    "text": "Media repurpose tool\nConsider recording the media before real-time processing. Scan the object via taobao streaming and make it dance. Transplant lolita pictures to bilibili. Share dialogs/info from soul/qq/wechat. Repurpose a wide range of streaming platforms. use ocr to filter out text info find new title from danmaku or comments\n我们都知道，视频主要由画面和音频组成。但还有一个元素同样包含了巨大的信息量 —— 字幕。结合现有的自然语言处理模型，我们便能实现对话抽取式的自动剪辑。PS: 软件图标是我妹妹Hannah设计滴~\n项目开源地址：https://github.com/COLOR-SKY/DialogueExtractor\n学业之余我会陆续更新工具教程。"
  },
  {
    "objectID": "posts/058288d9-4a19-409c-a1a7-26d524284623/index.html",
    "href": "posts/058288d9-4a19-409c-a1a7-26d524284623/index.html",
    "title": "Mindmap",
    "section": "",
    "text": "Mindmap\n需求：对目前做出来的共现网络图谱进行社区划分，使用简单的谱聚类方法就行，要求能看出来图谱热点被区分开，最后的结果通过图谱的形式展示。"
  },
  {
    "objectID": "posts/23668aee-c422-42fb-9bab-688bd0580123/index.html",
    "href": "posts/23668aee-c422-42fb-9bab-688bd0580123/index.html",
    "title": "Mobile data China Unicom",
    "section": "",
    "text": "Mobile data China Unicom\n8986062018000657907 hktop521 大海卡"
  },
  {
    "objectID": "posts/4f8e0886-6e1f-44a6-8ecf-e219582646b7/index.html",
    "href": "posts/4f8e0886-6e1f-44a6-8ecf-e219582646b7/index.html",
    "title": "MongoDB Cheatsheet",
    "section": "",
    "text": "MongoDB Cheatsheet\nuse redability.js reader mode or elinks to render this shit: https://www.mongodb.com/developer/products/mongodb/cheat-sheet/"
  },
  {
    "objectID": "posts/a15164a5-ee43-46f3-8aaf-175acca7b70c/index.html",
    "href": "posts/a15164a5-ee43-46f3-8aaf-175acca7b70c/index.html",
    "title": "Movie Scraping 2",
    "section": "",
    "text": "Movie Scraping 2\nwith douban link fetched from search, with id\nhttps://cokemv.me/voddetail/39184.html https://cokemv.me/\nhttps://cokemv.me/vodshow/5——————–2021.html\nhttps://cokemv.me/vodshow/2————–2——2022.html"
  },
  {
    "objectID": "posts/4f44b5f7-3784-4bd2-85c5-fb45d7f3387c/index.html",
    "href": "posts/4f44b5f7-3784-4bd2-85c5-fb45d7f3387c/index.html",
    "title": "Movie Site Scraping 1",
    "section": "",
    "text": "Movie Site Scraping 1\nhttps://www.zxzj.fun/ 目标站 采集1.电影名或是电视剧名要区分是电影还是电视剧，2上映时间，年限即可 3.播放链接\n2506004169@qq.com\nhttps://www.zxzj.fun/list/1.html\nfrom 1 to 6.html\nquery:\nhttps://www.zxzj.fun/vodshow/1——————–2022.html https://www.zxzj.fun/vodshow/1————–2——2021.html https://www.zxzj.fun/vodshow/4——————–2022.html"
  },
  {
    "objectID": "posts/0729564a-6198-4074-a001-32a6076df2ac/index.html",
    "href": "posts/0729564a-6198-4074-a001-32a6076df2ac/index.html",
    "title": "Exploiting Log4j Vulnerability with Fofa API: A Comprehensive Guide",
    "section": "",
    "text": "My fruitful heist attempt with fofa\nFofa api requires membership. I don’t want to enroll.\nYou first test on your vulnerable machine/app, develop scanner, exploiter and listener, then mass exploit to millions.\nAll recorded here: hack_all_the_thing/tests/get_log4j_vuln\nzoomeye search for log4j\nseebug\nshodan query for log4j2 (or anything)\n狮子鱼团购 fofa查询漏洞\nSqlmap post data inject\nTo generate password dictionary without oom: itertools.product(chrs, repeat=r)\nsearch log4j2 in browser after login\ninfo page of my first target (login first!)\nfofa usage examples\nMy first target login page\ngov site?\nBing-upms the system used by my first target\npassword dictionary topic in github"
  },
  {
    "objectID": "posts/a52757b0-d802-4da5-a855-27f623f868df/index.html",
    "href": "posts/a52757b0-d802-4da5-a855-27f623f868df/index.html",
    "title": "NAS With Movie Download",
    "section": "",
    "text": "NAS With Movie Download\nPrimary function of NAS is to download massive amount of (media) files. The NAS setup guides include many platforms to download movies.\nhttps://www.zhihu.com/question/22129197/answer/1050613901\nNAS is different from server, which may have thr same storage capacity but much more computational power."
  },
  {
    "objectID": "posts/c1413e40-b8ca-413a-a237-6b2baa7f4e96/index.html",
    "href": "posts/c1413e40-b8ca-413a-a237-6b2baa7f4e96/index.html",
    "title": "NTFS recovery tool for bilibili cookie under AutoUP",
    "section": "",
    "text": "NTFS recovery tool for bilibili cookie under AutoUP\nunmount the disk before scanning!\nntfsundelete autopsy disk drill recuperabit(good for small files) recoverpy korczis/foremost\ncould also try to retrieve from android phones (/data/data/tv.danmaku.bili)\nhttps://roubert.name/joakim/androidfilerecovery/\napt-get install testdisk pv extundelete\nadb shell ls /dev/block\nNow let us dump the content of that /dev/block/mmcblk0 that we found to the computer. With adb shell we can become superuser and execute cat to dump the content like this:\n$ ./adb shell su -c “cat /dev/block/mmcblk0” | pv &gt; mmcblk0.raw\nPipe Viwer (pv) is optional, but I like to see the transfer progress information it provides. (And of course you can change mmcblk0.raw to some other directory/filename if you want to.)\nAddition: André Paixão wrote to me that he just got an empty file with the command above. He solved it by using adbd insecure.\nAddition: Daniel Jeliński wrote to me that he ran into issues with LF encoding. The solution that worked for him was:\n./adb shell su -c “cat /dev/block/mmcblk0” | pv | sed ‘s/^M$//’ &gt; mmcblk0.raw\n…where ^M is what you get by pressing Ctrl+V followed by Ctrl+M.\nAddition: Marc also ran into the LF problems, but solved it this way:\n./adb shell “su -c ‘stty raw; cat /dev/block/mmcblk0’” | pv &gt; mmcblk0.raw\nAddition: Tim de Waal wrote to me that he prefers using netcat/gzip instead:\nOn the Android device (adb shell with su), run:\ndd if=/dev/block/mmcblk0 | gzip -9 | nc -l 5555\nOn the computer, run:\nnc [AndroidIP] 5555 | pv -b &gt; mmcblk0.img.gz\ntestdisk mmcblk0.raw"
  },
  {
    "objectID": "posts/20cfd19a-68dd-4523-9bb5-edfbe1d4d5eb/index.html",
    "href": "posts/20cfd19a-68dd-4523-9bb5-edfbe1d4d5eb/index.html",
    "title": "Neo4j Refcard",
    "section": "",
    "text": "Neo4j Refcard Cheatsheet Reference Card\ngist\nNeo4j Cypher Refcard 4.4 Legend\nRead\nWrite\nGeneral\nFunctions\nSchema\nPerformance\nMultidatabase\nSecurity Syntax Read query structure\n[USE] [MATCH WHERE] [OPTIONAL MATCH WHERE] [WITH [ORDER BY] [SKIP] [LIMIT]] RETURN [ORDER BY] [SKIP] [LIMIT]\nMATCH\nMATCH (n:Person)-[:KNOWS]-&gt;(m:Person) WHERE n.name = ‘Alice’\nNode patterns can contain labels and properties.\nMATCH (n)–&gt;(m)\nAny pattern can be used in MATCH.\nMATCH (n {name: ‘Alice’})–&gt;(m)\nPatterns with node properties.\nMATCH p = (n)–&gt;(m)\nAssign a path to p.\nOPTIONAL MATCH (n)-[r]-&gt;(m)\nOptional pattern: nulls will be used for missing parts. WHERE\nWHERE n.property &lt;&gt; $value\nUse a predicate to filter. Note that WHERE is always part of a MATCH, OPTIONAL MATCH or WITH clause. Putting it after a different clause in a query will alter what it does.\nWHERE EXISTS { MATCH (n)–&gt;(m) WHERE n.age = m.age }\nUse an existential subquery to filter. Write-only query structure\n[USE] (CREATE | MERGE) [SET|DELETE|REMOVE|FOREACH] [RETURN [ORDER BY] [SKIP] [LIMIT]]\nRead-write query structure\n[USE] [MATCH WHERE] [OPTIONAL MATCH WHERE] [WITH [ORDER BY] [SKIP] [LIMIT]] (CREATE | MERGE) [SET|DELETE|REMOVE|FOREACH] [RETURN [ORDER BY] [SKIP] [LIMIT]]\nCREATE\nCREATE (n {name: $value})\nCreate a node with the given properties.\nCREATE (n $map)\nCreate a node with the given properties.\nUNWIND $listOfMaps AS properties CREATE (n) SET n = properties\nCreate nodes with the given properties.\nCREATE (n)-[r:KNOWS]-&gt;(m)\nCreate a relationship with the given type and direction; bind a variable to it.\nCREATE (n)-[:LOVES {since: $value}]-&gt;(m)\nCreate a relationship with the given type, direction, and properties. SET\nSET n.property1 = $value1, n.property2 = $value2\nUpdate or create a property.\nSET n = $map\nSet all properties. This will remove any existing properties.\nSET n += $map\nAdd and update properties, while keeping existing ones.\nSET n:Person\nAdds a label Person to a node. Import\nLOAD CSV FROM ‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists.csv’ AS line CREATE (:Artist {name: line[1], year: toInteger(line[2])})\nLoad data from a CSV file and create nodes.\nLOAD CSV WITH HEADERS FROM ‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists-with-headers.csv’ AS line CREATE (:Artist {name: line.Name, year: toInteger(line.Year)})\nLoad CSV data which has headers.\nUSING PERIODIC COMMIT 500 LOAD CSV WITH HEADERS FROM ‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists-with-headers.csv’ AS line CREATE (:Artist {name: line.Name, year: toInteger(line.Year)})\nCommit the current transaction after every 500 rows when importing large amounts of data.\nLOAD CSV FROM ‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists-fieldterminator.csv’ AS line FIELDTERMINATOR ‘;’ CREATE (:Artist {name: line[1], year: toInteger(line[2])})\nUse a different field terminator, not the default which is a comma (with no whitespace around it).\nLOAD CSV FROM ‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists.csv’ AS line RETURN DISTINCT file()\nReturns the absolute path of the file that LOAD CSV is processing, returns null if called outside of LOAD CSV context.\nLOAD CSV FROM ‘https://neo4j.com/docs/cypher-refcard/4.4/csv/artists.csv’ AS line RETURN linenumber()\nReturns the line number that LOAD CSV is currently processing, returns null if called outside of LOAD CSV context. Operators\nGeneral\nDISTINCT, ., []\nMathematical\n+, -, *, /, %, ^\nComparison\n=, &lt;&gt;, &lt;, &gt;, &lt;=, &gt;=, IS NULL, IS NOT NULL\nBoolean\nAND, OR, XOR, NOT\nString\n\n\n\nList\n+, IN, [x], [x .. y]\nRegular Expression\n=~\nString matching\nSTARTS WITH, ENDS WITH, CONTAINS null\nnull is used to represent missing/undefined values.\n\nnull is not equal to null. Not knowing two values does not imply that they are the same value. So the expression null = null yields null and not true. To check if an expression is null, use IS NULL.\n\nArithmetic expressions, comparisons and function calls (except coalesce) will return null if any argument is null.\n\nAn attempt to access a missing element in a list or a property that doesn’t exist yields null.\n\nIn OPTIONAL MATCH clauses, nulls will be used for missing parts of the pattern.\nPatterns\n(n:Person)\nNode with Person label.\n(n:Person:Swedish)\nNode with both Person and Swedish labels.\n(n:Person {name: $value})\nNode with the declared properties.\n()-[r {name: $value}]-()\nMatches relationships with the declared properties.\n(n)–&gt;(m)\nRelationship from n to m.\n(n)–(m)\nRelationship in any direction between n and m.\n(n:Person)–&gt;(m)\nNode n labeled Person with relationship to m.\n(m)&lt;-[:KNOWS]-(n)\nRelationship of type KNOWS from n to m.\n(n)-[:KNOWS|LOVES]-&gt;(m)\nRelationship of type KNOWS or of type LOVES from n to m.\n(n)-[r]-&gt;(m)\nBind the relationship to variable r.\n(n)-[*1..5]-&gt;(m)\nVariable length path of between 1 and 5 relationships from n to m.\n(n)-[*]-&gt;(m)\nVariable length path of any number of relationships from n to m. (See Performance section.)\n(n)-[:KNOWS]-&gt;(m {property: $value})\nA relationship of type KNOWS from a node n to a node m with the declared property.\nshortestPath((n1:Person)-[*..6]-(n2:Person))\nFind a single shortest path.\nallShortestPaths((n1:Person)-[*..6]-&gt;(n2:Person))\nFind all shortest paths.\nsize((n)–&gt;()–&gt;())\nCount the paths matching the pattern. USE\nUSE myDatabase\nSelect myDatabase to execute query, or query part, against.\nUSE neo4j MATCH (n:Person)-[:KNOWS]-&gt;(m:Person) WHERE n.name = ‘Alice’\nMATCH query executed against neo4j database. SHOW FUNCTIONS and PROCEDURES\nSHOW FUNCTIONS\nListing all available functions.\nSHOW PROCEDURES EXECUTABLE YIELD name\nList all procedures that can be executed by the current user and return only the name of the procedures. SHOW and TERMINATE TRANSACTIONS\nSHOW TRANSACTIONS\nListing all available transactions.\nTERMINATE TRANSACTIONS ‘neo4j-transaction-42’\nTerminate the transaction with ID neo4j-transaction-42. Labels\nCREATE (n:Person {name: $value})\nCreate a node with label and property.\nMERGE (n:Person {name: $value})\nMatches or creates unique node(s) with the label and property.\nSET n:Spouse:Parent:Employee\nAdd label(s) to a node.\nMATCH (n:Person)\nMatches nodes labeled Person.\nMATCH (n:Person) WHERE n.name = $value\nMatches nodes labeled Person with the given name.\nWHERE (n:Person)\nChecks the existence of the label on the node.\nlabels(n)\nLabels of the node.\nREMOVE n:Person\nRemove the label from the node. Maps\n{name: ‘Alice’, age: 38, address: {city: ‘London’, residential: true}}\nLiteral maps are declared in curly braces much like property maps. Lists are supported.\nWITH {person: {name: ‘Anne’, age: 25}} AS p RETURN p.person.name\nAccess the property of a nested map.\nMERGE (p:Person {name: $map.name}) ON CREATE SET p = $map\nMaps can be passed in as parameters and used either as a map or by accessing keys.\nMATCH (matchedNode:Person) RETURN matchedNode\nNodes and relationships are returned as maps of their data.\nmap.name, map.age, map.children[0]\nMap entries can be accessed by their keys. Invalid keys result in an error. Functions\ncoalesce(n.property, $defaultValue)\nThe first non-null expression.\ntimestamp()\nMilliseconds since midnight, January 1, 1970 UTC.\nid(nodeOrRelationship)\nThe internal id of the relationship or node.\ntoInteger($expr)\nConverts the given input into an integer if possible; otherwise it returns null.\ntoFloat($expr)\nConverts the given input into a floating point number if possible; otherwise it returns null.\ntoBoolean($expr)\nConverts the given input into a boolean if possible; otherwise it returns null.\nkeys($expr)\nReturns a list of string representations for the property names of a node, relationship, or map.\nproperties($expr)\nReturns a map containing all the properties of a node or relationship. Spatial functions\npoint({x: $x, y: $y})\nReturns a point in a 2D cartesian coordinate system.\npoint({latitude: $y, longitude: $x})\nReturns a point in a 2D geographic coordinate system, with coordinates specified in decimal degrees.\npoint({x: $x, y: $y, z: $z})\nReturns a point in a 3D cartesian coordinate system.\npoint({latitude: $y, longitude: $x, height: $z})\nReturns a point in a 3D geographic coordinate system, with latitude and longitude in decimal degrees, and height in meters.\npoint.distance(point({x: $x1, y: $y1}), point({x: $x2, y: $y2}))\nReturns a floating point number representing the linear distance between two points. The returned units will be the same as those of the point coordinates, and it will work for both 2D and 3D cartesian points.\npoint.distance(point({latitude: $y1, longitude: $x1}), point({latitude: $y2, longitude: $x2}))\nReturns the geodesic distance between two points in meters. It can be used for 3D geographic points as well. Temporal functions\ndate(“2018-04-05”)\nReturns a date parsed from a string.\nlocaltime(“12:45:30.25”)\nReturns a time with no time zone.\ntime(“12:45:30.25+01:00”)\nReturns a time in a specified time zone.\nlocaldatetime(“2018-04-05T12:34:00”)\nReturns a datetime with no time zone.\ndatetime(“2018-04-05T12:34:00[Europe/Berlin]”)\nReturns a datetime in the specified time zone.\ndatetime({epochMillis: 3360000})\nTransforms 3360000 as a UNIX Epoch time into a normal datetime.\ndate({year: $year, month: $month, day: $day})\nAll of the temporal functions can also be called with a map of named components. This example returns a date from year, month and day components. Each function supports a different set of possible components.\ndatetime({date: $date, time: $time})\nTemporal types can be created by combining other types. This example creates a datetime from a date and a time.\ndate({date: $datetime, day: 5})\nTemporal types can be created by selecting from more complex types, as well as overriding individual components. This example creates a date by selecting from a datetime, as well as overriding the day component.\nWITH date(“2018-04-05”) AS d RETURN d.year, d.month, d.day, d.week, d.dayOfWeek\nAccessors allow extracting components of temporal types. Duration functions\nduration(“P1Y2M10DT12H45M30.25S”)\nReturns a duration of 1 year, 2 months, 10 days, 12 hours, 45 minutes and 30.25 seconds.\nduration.between(\\(date1,\\)date2)\nReturns a duration between two temporal instances.\nWITH duration(“P1Y2M10DT12H45M”) AS d RETURN d.years, d.months, d.days, d.hours, d.minutes\nReturns 1 year, 14 months, 10 days, 12 hours and 765 minutes.\nWITH duration(“P1Y2M10DT12H45M”) AS d RETURN d.years, d.monthsOfYear, d.days, d.hours, d.minutesOfHour\nReturns 1 year, 2 months, 10 days, 12 hours and 45 minutes.\ndate(“2015-01-01”) + duration(“P1Y1M1D”)\nReturns a date of 2016-02-02. It is also possible to subtract durations from temporal instances.\nduration(“PT30S”) * 10\nReturns a duration of 5 minutes. It is also possible to divide a duration by a number. CONSTRAINT\nCREATE CONSTRAINT FOR (p:Person) REQUIRE p.name IS UNIQUE\nCreate a unique property constraint on the label Person and property name. If any other node with that label is updated or created with a name that already exists, the write operation will fail. This constraint will create an accompanying index.\nCREATE CONSTRAINT uniqueness FOR (p:Person) REQUIRE (p.firstname, p.age) IS UNIQUE\nCreate a unique property constraint with the name uniqueness on the label Person and properties firstname and age. If any other node with that label is updated or created with a firstname and age combination that already exists, the write operation fails. This constraint creates an accompanying index.\nCREATE CONSTRAINT FOR (p:Person) REQUIRE p.surname IS UNIQUE OPTIONS {indexProvider: ‘native-btree-1.0’}\nCreate a unique property constraint on the label Person and property surname with the index provider native-btree-1.0 for the accompanying index.\nCREATE CONSTRAINT FOR (p:Person) REQUIRE p.name IS NOT NULL\n(★) Create a node property existence constraint on the label Person and property name, throws an error if the constraint already exists. If a node with that label is created without a name, or if the name property is removed from an existing node with the Person label, the write operation will fail.\nCREATE CONSTRAINT node_exists IF NOT EXISTS FOR (p:Person) REQUIRE p.name IS NOT NULL\n(★) If a node property existence constraint on the label Person and property name or any constraint with the name node_exists already exist then nothing happens. If no such constraint exists, then it will be created.\nCREATE CONSTRAINT FOR ()-[l:LIKED]-() REQUIRE l.when IS NOT NULL\n(★) Create a relationship property existence constraint on the type LIKED and property when. If a relationship with that type is created without a when, or if the when property is removed from an existing relationship with the LIKED type, the write operation will fail.\nCREATE CONSTRAINT relationship_exists FOR ()-[l:LIKED]-() REQUIRE l.since IS NOT NULL\n(★) Create a relationship property existence constraint with the name relationship_exists on the type LIKED and property since. If a relationship with that type is created without a since, or if the since property is removed from an existing relationship with the LIKED type, the write operation will fail.\nSHOW UNIQUE CONSTRAINTS YIELD *\nList all unique constraints.\nCREATE CONSTRAINT FOR (p:Person) REQUIRE (p.firstname, p.surname) IS NODE KEY\n(★) Create a node key constraint on the label Person and properties firstname and surname. If a node with that label is created without both firstname and surname or if the combination of the two is not unique, or if the firstname and/or surname properties on an existing node with the Person label is modified to violate these constraints, the write operation fails. This constraint creates an accompanying index.\nCREATE CONSTRAINT node_key FOR (p:Person) REQUIRE p.firstname IS NODE KEY\n(★) Create a node key constraint with the name node_key on the label Person and property firstname. If a node with that label is created without the firstname property or if the value is not unique, or if the firstname property on an existing node with the Person label is modified to violate these constraints, the write operation fails. This constraint creates an accompanying index.\nCREATE CONSTRAINT node_key_with_config FOR (p:Person) REQUIRE (p.name, p.age) IS NODE KEY OPTIONS {indexConfig: {spatial.wgs-84.min: [-100.0, -100.0], spatial.wgs-84.max: [100.0, 100.0]}}\n(★) Create a node key constraint with the name node_key_with_config on the label Person, properties name and age, and given spatial.wgs-84 settings for the accompanying b-tree index. The other index settings will have their default values.\nDROP CONSTRAINT uniqueness\nDropping the constraint with the name uniqueness, throws an error if the constraint does not exist. If the constraint has an accompanying index, that is also dropped.\nDROP CONSTRAINT uniqueness IF EXISTS\nDropping the constraint with the name uniqueness if it exists, does nothing if it does not exist. If the constraint has an accompanying index, that is also dropped. Database management\nCREATE OR REPLACE DATABASE myDatabase\n(★) Create a database named myDatabase. If a database with that name exists, then the existing database is deleted and a new one created.\nALTER DATABASE myDatabase SET ACCESS READ ONLY\n(★) Modify a database named myDatabase to be read-only.\nSTOP DATABASE myDatabase\n(★) Stop the database myDatabase.\nSTART DATABASE myDatabase\n(★) Start the database myDatabase.\nCREATE ALIAS myAlias FOR DATABASE myDatabase\n(★) Create an alias myAlias for the database with name myDatabase.\nALTER ALIAS myAlias SET DATABASE TARGET myDatabase\n(★) Alter the alias myAlias to target the database with name myDatabase.\nDROP ALIAS myAlias FOR DATABASE\n(★) Drop the database alias myAlias.\nSHOW DATABASES\nList all databases in the system and information about them.\nSHOW DATABASES YIELD name, currentStatus WHERE name CONTAINS ‘my’ AND currentStatus = ‘online’\nList information about databases, filtered by name and online status and further refined by conditions on these.\nSHOW DATABASE myDatabase\nList information about the database myDatabase.\nSHOW DEFAULT DATABASE\nList information about the default database.\nSHOW HOME DATABASE\nList information about the current users home database.\nDROP DATABASE myDatabase IF EXISTS\n(★) Delete the database myDatabase, if it exists. User management\nCREATE USER alice SET PASSWORD $password\nCreate a new user and a password. This password must be changed on the first login.\nALTER USER alice SET PASSWORD $password CHANGE NOT REQUIRED\nSet a new password for a user. This user will not be required to change this password on the next login.\nALTER USER alice IF EXISTS SET PASSWORD CHANGE REQUIRED\nIf the specified user exists, force this user to change their password on the next login.\nALTER USER alice SET STATUS SUSPENDED\n(★) Change the user status to suspended. Use SET STATUS ACTIVE to reactivate the user.\nALTER USER alice SET HOME DATABASE otherDb\n(★) Change the home database of user to otherDb. Use REMOVE HOME DATABASE to unset the home database for the user and fallback to the default database.\nALTER CURRENT USER SET PASSWORD FROM $old TO $new\nChange the password of the logged-in user. The user will not be required to change this password on the next login.\nSHOW CURRENT USER\nList the currently logged-in user, their status, roles and whether they need to change their password. (★) Status and roles are Enterprise Edition only.\nSHOW USERS\nList all users in the system, their status, roles and if they need to change their password. (★) Status and roles are Enterprise Edition only.\nSHOW USERS YIELD user, suspended WHERE suspended = true\nList users in the system, filtered by their name and status and further refined by whether they are suspended. (★) Status is Enterprise Edition only.\nRENAME USER alice TO alice_delete\nRename the user alice to alice_delete.\nDROP USER alice_delete\nDelete the user. (★) Role management\nCREATE ROLE my_role\nCreate a role.\nCREATE ROLE my_second_role IF NOT EXISTS AS COPY OF my_role\nCreate a role named my_second_role, unless it already exists, as a copy of the existing my_role.\nRENAME ROLE my_second_role TO my_other_role\nRename a role named my_second_role to my_other_role.\nGRANT ROLE my_role, my_other_role TO alice\nAssign roles to a user.\nREVOKE ROLE my_other_role FROM alice\nRemove a specified role from a user.\nSHOW ROLES\nList all roles in the system.\nSHOW ROLES YIELD role WHERE role CONTAINS ‘my’\nList roles, filtered by the name of the role and further refined by whether the name contains ‘my’.\nSHOW POPULATED ROLES WITH USERS\nList all roles that are assigned to at least one user in the system, and the users assigned to those roles.\nDROP ROLE my_role\nDelete a role. (★) Graph read privileges\nGRANT TRAVERSE ON GRAPH * NODES * TO my_role\nGrant traverse privilege on all nodes and all graphs to a role.\nDENY READ {prop} ON GRAPH foo RELATIONSHIP Type TO my_role\nDeny read privilege on a specified property, on all relationships with a specified type in a specified graph, to a role.\nGRANT MATCH {*} ON HOME GRAPH ELEMENTS Label TO my_role\nGrant read privilege on all properties and traverse privilege in the home graph, to a role. Here, both privileges apply to all nodes and relationships with a specified label/type in the graph. (★) Graph write privileges\nGRANT CREATE ON GRAPH * NODES Label TO my_role\nGrant create privilege on all nodes with a specified label in all graphs to a role.\nDENY DELETE ON GRAPH neo4j TO my_role\nDeny delete privilege on all nodes and relationships in a specified graph to a role.\nREVOKE SET LABEL Label ON GRAPH * FROM my_role\nRevoke set label privilege for the specified label on all graphs to a role.\nGRANT REMOVE LABEL * ON GRAPH foo TO my_role\nGrant remove label privilege for all labels on a specified graph to a role.\nDENY SET PROPERTY {prop} ON GRAPH foo RELATIONSHIPS Type TO my_role\nDeny set property privilege on a specified property, on all relationships with a specified type in a specified graph, to a role.\nGRANT MERGE {} ON GRAPH  NODES Label TO my_role\nGrant merge privilege on all properties, on all nodes with a specified label in all graphs, to a role.\nREVOKE WRITE ON GRAPH * FROM my_role\nRevoke write privilege on all graphs from a role.\nDENY ALL GRAPH PRIVILEGES ON GRAPH foo TO my_role\nDeny all graph privileges privilege on a specified graph to a role. (★) SHOW PRIVILEGES\nSHOW PRIVILEGES AS COMMANDS\nList all privileges in the system as Cypher commands.\nSHOW PRIVILEGES\nList all privileges in the system, and the roles that they are assigned to.\nSHOW PRIVILEGES YIELD role, action, access WHERE role = ‘my_role’\nList information about privileges, filtered by role, action and access and further refined by the name of the role.\nSHOW ROLE my_role PRIVILEGES AS COMMANDS\nList all privileges assigned to a role as Cypher commands.\nSHOW ROLE my_role, my_second_role PRIVILEGES AS COMMANDS\nList all privileges assigned to each of the multiple roles as Cypher commands.\nSHOW USER alice PRIVILEGES AS COMMANDS\nList all privileges of a user, and the role that they are assigned to as Cypher commands.\nSHOW USER PRIVILEGES AS COMMANDS\nList all privileges of the currently logged in user, and the role that they are assigned to as Cypher commands. RETURN\nRETURN *\nReturn the value of all variables.\nRETURN n AS columnName\nUse alias for result column name.\nRETURN DISTINCT n\nReturn unique rows.\nORDER BY n.property\nSort the result.\nORDER BY n.property DESC\nSort the result in descending order.\nSKIP $skipNumber\nSkip a number of results.\nLIMIT $limitNumber\nLimit the number of results.\nSKIP $skipNumber LIMIT $limitNumber\nSkip results at the top and limit the number of results.\nRETURN count(*)\nThe number of matching rows. See Aggregating functions for more. WITH\nMATCH (user)-[:FRIEND]-(friend) WHERE user.name = $name WITH user, count(friend) AS friends WHERE friends &gt; 10 RETURN user\nThe WITH syntax is similar to RETURN. It separates query parts explicitly, allowing you to declare which variables to carry over to the next part.\nMATCH (user)-[:FRIEND]-(friend) WITH user, count(friend) AS friends ORDER BY friends DESC SKIP 1 LIMIT 3 RETURN user\nORDER BY, SKIP, and LIMIT can also be used with WITH. UNION\nMATCH (a)-[:KNOWS]-&gt;(b) RETURN b.name UNION MATCH (a)-[:LOVES]-&gt;(b) RETURN b.name\nReturns the distinct union of all query results. Result column types and names have to match.\nMATCH (a)-[:KNOWS]-&gt;(b) RETURN b.name UNION ALL MATCH (a)-[:LOVES]-&gt;(b) RETURN b.name\nReturns the union of all query results, including duplicated rows. MERGE\nMERGE (n:Person {name: $value}) ON CREATE SET n.created = timestamp() ON MATCH SET n.counter = coalesce(n.counter, 0) + 1, n.accessTime = timestamp()\nMatch a pattern or create it if it does not exist. Use ON CREATE and ON MATCH for conditional updates.\nMATCH (a:Person {name: $value1}), (b:Person {name: $value2}) MERGE (a)-[r:LOVES]-&gt;(b)\nMERGE finds or creates a relationship between the nodes.\nMATCH (a:Person {name: $value1}) MERGE (a)-[r:KNOWS]-&gt;(b:Person {name: $value3})\nMERGE finds or creates paths attached to the node. DELETE\nDELETE n, r\nDelete a node and a relationship.\nDETACH DELETE n\nDelete a node and all relationships connected to it.\nMATCH (n) DETACH DELETE n\nDelete all nodes and relationships from the database. REMOVE\nREMOVE n:Person\nRemove a label from n.\nREMOVE n.property\nRemove a property. FOREACH\nFOREACH (r IN relationships(path) | SET r.marked = true)\nExecute a mutating operation for each relationship in a path.\nFOREACH (value IN coll | CREATE (:Person {name: value}))\nExecute a mutating operation for each element in a list. CALL subquery\nCALL { MATCH (p:Person)-[:FRIEND_OF]-&gt;(other:Person) RETURN p, other UNION MATCH (p:Child)-[:CHILD_OF]-&gt;(other:Parent) RETURN p, other }\nThis calls a subquery with two union parts. The result of the subquery can afterwards be post-processed. CALL procedure\nCALL db.labels() YIELD label\nThis shows a standalone call to the built-in procedure db.labels to list all labels used in the database. Note that required procedure arguments are given explicitly in brackets after the procedure name.\nCALL db.labels() YIELD *\nStandalone calls may use YIELD * to return all columns.\nCALL java.stored.procedureWithArgs\nStandalone calls may omit YIELD and also provide arguments implicitly via statement parameters, e.g. a standalone call requiring one argument input may be run by passing the parameter map {input: ‘foo’}.\nCALL db.labels() YIELD label RETURN count(label) AS count\nCalls the built-in procedure db.labels inside a larger query to count all labels used in the database. Calls inside a larger query always requires passing arguments and naming results explicitly with YIELD. Lists\n[‘a’, ‘b’, ‘c’] AS list\nLiteral lists are declared in square brackets.\nsize($list) AS len, $list[0] AS value\nLists can be passed in as parameters.\nrange($firstNum, $lastNum, $step) AS list\nrange() creates a list of numbers (step is optional), other functions returning lists are: labels(), nodes(), relationships().\nMATCH p = (a)-[:KNOWS*]-&gt;() RETURN relationships(p) AS r\nThe list of relationships comprising a variable length path can be returned using named paths and relationships().\nRETURN matchedNode.list[0] AS value, size(matchedNode.list) AS len\nProperties can be lists of strings, numbers or booleans.\nlist[\\(idx] AS value, list[\\)startIdx..$endIdx] AS slice\nList elements can be accessed with idx subscripts in square brackets. Invalid indexes return null. Slices can be retrieved with intervals from start_idx to end_idx, each of which can be omitted or negative. Out of range elements are ignored.\nUNWIND $names AS name MATCH (n {name: name}) RETURN avg(n.age)\nWith UNWIND, any list can be transformed back into individual rows. The example matches all names from a list of names.\nMATCH (a) RETURN [(a)–&gt;(b) WHERE b.name = ‘Bob’ | b.age]\nPattern comprehensions may be used to do a custom projection from a match directly into a list.\nMATCH (person) RETURN person { .name, .age}\nMap projections may be easily constructed from nodes, relationships and other map values. Predicates\nn.property &lt;&gt; $value\nUse comparison operators.\ntoString(n.property) = $value\nUse functions.\nn.number &gt;= 1 AND n.number &lt;= 10\nUse boolean operators to combine predicates.\n1 &lt;= n.number &lt;= 10\nUse chained operators to combine predicates.\nn:Person\nCheck for node labels.\nvariable IS NOT NULL\nCheck if something is not null, e.g. that a property exists.\nn.property IS NULL OR n.property = $value\nEither the property does not exist or the predicate is true.\nn.property = $value\nNon-existing property returns null, which is not equal to anything.\nn[“property”] = $value\nProperties may also be accessed using a dynamically computed property name.\nn.property STARTS WITH ‘Tim’ OR n.property ENDS WITH ‘n’ OR n.property CONTAINS ‘goodie’\nString matching.\nn.property =~ ’Tim.*’\nString regular expression matching.\n(n)-[:KNOWS]-&gt;(m)\nEnsure the pattern has at least one match.\nNOT (n)-[:KNOWS]-&gt;(m)\nExclude matches to (n)-[:KNOWS]-&gt;(m) from the result.\nn.property IN [$value1, $value2]\nCheck if an element exists in a list. List predicates\nall(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is true for all elements in the list.\nany(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is true for at least one element in the list.\nnone(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is false for all elements in the list.\nsingle(x IN coll WHERE x.property IS NOT NULL)\nReturns true if the predicate is true for exactly one element in the list. CASE\nCASE n.eyes WHEN ‘blue’ THEN 1 WHEN ‘brown’ THEN 2 ELSE 3 END\nReturn THEN value from the matching WHEN value. The ELSE value is optional, and substituted for null if missing.\nCASE WHEN n.eyes = ‘blue’ THEN 1 WHEN n.age &lt; 40 THEN 2 ELSE 3 END\nReturn THEN value from the first WHEN predicate evaluating to true. Predicates are evaluated in order. List expressions\nsize($list)\nNumber of elements in the list.\nreverse($list)\nReverse the order of the elements in the list.\nhead($list)\nGet the first element of the list. Return null for an empty list. Eqivalent to the list indexing $list[0].\nlast($list)\nGet the last element of the list. Return null for an empty list. Eqivalent to the list indexing $list[-1].\ntail($list)\nGet all elements except for the first element. Return [] for an empty list. Eqivalent to the list slice $list[1..]. Out-of-bound slices are truncated to an empty list [].\n[x IN list | x.prop]\nA list of the value of the expression for each element in the original list.\n[x IN list WHERE x.prop &lt;&gt; $value]\nA filtered list of the elements where the predicate is true.\n[x IN list WHERE x.prop &lt;&gt; $value | x.prop]\nA list comprehension that filters a list and extracts the value of the expression for each element in that list.\nreduce(s = ““, x IN list | s + x.prop)\nEvaluate expression for each element in the list, accumulate the results. Path functions\nlength(path)\nThe number of relationships in the path.\nnodes(path)\nThe nodes in the path as a list.\nrelationships(path)\nThe relationships in the path as a list.\n[x IN nodes(path) | x.prop]\nExtract properties from the nodes in a path. Mathematical functions\nabs($expr)\nThe absolute value.\nrand()\nReturns a random number in the range from 0 (inclusive) to 1 (exclusive), [0,1). Returns a new value for each call. Also useful for selecting a subset or random ordering.\nround($expr)\nRound to the nearest integer; ceil() and floor() find the next integer up or down.\nsqrt($expr)\nThe square root.\nsign($expr)\n0 if zero, -1 if negative, 1 if positive.\nsin($expr)\nTrigonometric functions also include cos(), tan(), cot(), asin(), acos(), atan(), atan2(), and haversin(). All arguments for the trigonometric functions should be in radians, if not otherwise specified.\ndegrees(\\(expr), radians(\\)expr), pi()\nConverts radians into degrees; use radians() for the reverse, and pi() for π.\nlog10(\\(expr), log(\\)expr), exp($expr), e()\nLogarithm base 10, natural logarithm, e to the power of the parameter, and the value of e. String functions\ntoString($expression)\nString representation of the expression.\nreplace($original, $search, $replacement)\nReplace all occurrences of search with replacement. All arguments must be expressions.\nsubstring($original, $begin, $subLength)\nGet part of a string. The subLength argument is optional.\nleft($original, \\(subLength),  right(\\)original, $subLength)\nThe first part of a string. The last part of the string.\ntrim(\\(original), lTrim(\\)original), rTrim($original)\nTrim all whitespace, or on the left or right side.\ntoUpper(\\(original), toLower(\\)original)\nUPPERCASE and lowercase.\nsplit($original, $delimiter)\nSplit a string into a list of strings.\nreverse($original)\nReverse a string.\nsize($string)\nCalculate the number of characters in the string. Relationship functions\ntype(a_relationship)\nString representation of the relationship type.\nstartNode(a_relationship)\nStart node of the relationship.\nendNode(a_relationship)\nEnd node of the relationship.\nid(a_relationship)\nThe internal id of the relationship. Aggregating functions\ncount(*)\nThe number of matching rows.\ncount(variable)\nThe number of non-null values.\ncount(DISTINCT variable)\nAll aggregating functions also take the DISTINCT operator, which removes duplicates from the values.\ncollect(n.property)\nList from the values, ignores null.\nsum(n.property)\nSum numerical values. Similar functions are avg(), min(), max().\npercentileDisc(n.property, $percentile)\nDiscrete percentile. Continuous percentile is percentileCont(). The percentile argument is from 0.0 to 1.0.\nstDev(n.property)\nStandard deviation for a sample of a population. For an entire population use stDevP(). INDEX\nCREATE INDEX FOR (p:Person) ON (p.name)\nCreate a b-tree index on nodes with label Person and property name.\nCREATE INDEX index_name FOR ()-[k:KNOWS]-() ON (k.since)\nCreate a b-tree index with the name index_name on relationships with type KNOWS and property since.\nCREATE INDEX FOR (p:Person) ON (p.surname) OPTIONS {indexProvider: ‘native-btree-1.0’, indexConfig: {spatial.cartesian.min: [-100.0, -100.0], spatial.cartesian.max: [100.0, 100.0]}}\nCreate a b-tree index on nodes with label Person and property surname with the index provider native-btree-1.0 and given spatial.cartesian settings. The other index settings will have their default values.\nCREATE INDEX FOR (p:Person) ON (p.name, p.age)\nCreate a composite b-tree index on nodes with label Person and the properties name and age, throws an error if the index already exist.\nCREATE INDEX IF NOT EXISTS FOR (p:Person) ON (p.name, p.age)\nCreate a composite b-tree index on nodes with label Person and the properties name and age if it does not already exist, does nothing if it did exist.\nCREATE LOOKUP INDEX lookup_index_name FOR (n) ON EACH labels(n)\nCreate a token lookup index with the name lookup_index_name on nodes with any label.\nCREATE LOOKUP INDEX FOR ()-[r]-() ON EACH type(r)\nCreate a token lookup index on relationships with any relationship type.\nCREATE FULLTEXT INDEX node_fulltext_index_name FOR (n:Friend) ON EACH [n.name] OPTIONS {indexConfig: {fulltext.analyzer: ‘swedish’}}\nCreate a fulltext index on nodes with the name node_fulltext_index_name and analyzer swedish. Fulltext indexes on nodes can only be used by from the procedure db.index.fulltext.queryNodes. The other index settings will have their default values.\nCREATE FULLTEXT INDEX rel_fulltext_index_name FOR ()-[r:HAS_PET|BROUGHT_PET]-() ON EACH [r.since, r.price]\nCreate a fulltext index on relationships with the name rel_fulltext_index_name. Fulltext indexes on relationships can only be used by from the procedure db.index.fulltext.queryRelationships.\nCREATE TEXT INDEX FOR (f:Friend) ON (f.email)\nCreate a text index on nodes with label Friend and property email.\nCREATE TEXT INDEX text_index_name FOR ()-[h:HAS_PET]-() ON (h.favoriteToy)\nCreate a text index with the name text_index_name on relationships with type HAS_PET and property favoriteToy.\nSHOW INDEXES\nList all indexes.\nMATCH (n:Person) WHERE n.name = $value\nAn BTREE index can be automatically used for the equality comparison. Note that for example toLower(n.name) = $value will not use an index.\nMATCH (n:Person) WHERE n.name = “Alice”\nAn TEXT index can be automatically used for the equality comparison when comparing to a string. Note that for example toLower(n.name) = “string” does not use an index.\nMATCH (n:Person) WHERE n.name &lt; “Bob”\nAn index can automatically be used for range predicates. Note that a TEXT index is only used if the predicate compares the property with a string.\nMATCH (n:Person) WHERE n.name IN [$value]\nAn index can automatically be used for the IN list checks.\nMATCH (n:Person) WHERE n.name IN [‘Bob’, ‘Alice’]\nAn TEXT index can automatically be used for the IN list checks when all elements in the list are strings.\nMATCH (n:Person) WHERE n.name = $value and n.age = $value2\nA composite index can be automatically used for equality comparison of both properties. Note that there needs to be predicates on all properties of the composite index for it to be used.\nMATCH (n:Person) USING INDEX n:Person(name) WHERE n.name = $value\nIndex usage can be enforced when Cypher uses a suboptimal index, or more than one index should be used.\nDROP INDEX index_name\nDrop the index named index_name, throws an error if the index does not exist.\nDROP INDEX index_name IF EXISTS\nDrop the index named index_name if it exists, does nothing if it does not exist. Performance\nUse parameters instead of literals when possible. This allows Cypher to re-use your queries instead of having to parse and build new execution plans.\n\nAlways set an upper limit for your variable length patterns. It’s possible to have a query go wild and touch all nodes in a graph by mistake.\n\nReturn only the data you need. Avoid returning whole nodes and relationships — instead, pick the data you need and return only that.\n\nUse PROFILE / EXPLAIN to analyze the performance of your queries. See Query Tuning for more information on these and other topics, such as planner hints.\n(★) Database privileges\nGRANT ACCESS ON DATABASE * TO my_role\nGrant privilege to access and run queries against all databases to a role.\nGRANT START ON DATABASE * TO my_role\nGrant privilege to start all databases to a role.\nGRANT STOP ON DATABASE * TO my_role\nGrant privilege to stop all databases to a role.\nGRANT CREATE INDEX ON DATABASE foo TO my_role\nGrant privilege to create indexes on a specified database to a role.\nGRANT DROP INDEX ON DATABASE foo TO my_role\nGrant privilege to drop indexes on a specified database to a role.\nGRANT SHOW INDEX ON DATABASE * TO my_role\nGrant privilege to show indexes on all databases to a role.\nDENY INDEX MANAGEMENT ON DATABASE bar TO my_role\nDeny privilege to create and drop indexes on a specified database to a role.\nGRANT CREATE CONSTRAINT ON DATABASE * TO my_role\nGrant privilege to create constraints on all databases to a role.\nDENY DROP CONSTRAINT ON DATABASE * TO my_role\nDeny privilege to drop constraints on all databases to a role.\nDENY SHOW CONSTRAINT ON DATABASE foo TO my_role\nDeny privilege to show constraints on a specified database to a role.\nREVOKE CONSTRAINT ON DATABASE * FROM my_role\nRevoke granted and denied privileges to create and drop constraints on all databases from a role.\nGRANT CREATE NEW LABELS ON DATABASE * TO my_role\nGrant privilege to create new labels on all databases to a role.\nDENY CREATE NEW TYPES ON DATABASE foo TO my_role\nDeny privilege to create new relationship types on a specified database to a role.\nREVOKE GRANT CREATE NEW PROPERTY NAMES ON DATABASE bar FROM my_role\nRevoke the grant privilege to create new property names on a specified database from a role.\nGRANT NAME MANAGEMENT ON HOME DATABASE TO my_role\nGrant privilege to create labels, relationship types, and property names on the home database to a role.\nGRANT ALL ON DATABASE baz TO my_role\nGrant privilege to access, create and drop indexes and constraints, create new labels, types and property names on a specified database to a role.\nGRANT SHOW TRANSACTION (*) ON DATABASE foo TO my_role\nGrant privilege to list transactions and queries from all users on a specified database to a role.\nDENY TERMINATE TRANSACTION (user1, user2) ON DATABASES * TO my_role\nDeny privilege to kill transactions and queries from user1 and user2 on all databases to a role.\nREVOKE GRANT TRANSACTION MANAGEMENT ON HOME DATABASE FROM my_role\nRevoke the granted privilege to list and kill transactions and queries from all users on the home database from a role. (★) Role management privileges\nGRANT CREATE ROLE ON DBMS TO my_role\nGrant the privilege to create roles to a role.\nGRANT RENAME ROLE ON DBMS TO my_role\nGrant the privilege to rename roles to a role.\nGRANT DROP ROLE ON DBMS TO my_role\nGrant the privilege to delete roles to a role.\nDENY ASSIGN ROLE ON DBMS TO my_role\nDeny the privilege to assign roles to users to a role.\nDENY REMOVE ROLE ON DBMS TO my_role\nDeny the privilege to remove roles from users to a role.\nREVOKE DENY SHOW ROLE ON DBMS FROM my_role\nRevoke the denied privilege to show roles from a role.\nGRANT ROLE MANAGEMENT ON DBMS TO my_role\nGrant all privileges to manage roles to a role. (★) User management privileges\nGRANT CREATE USER ON DBMS TO my_role\nGrant the privilege to create users to a role.\nGRANT RENAME USER ON DBMS TO my_role\nGrant the privilege to rename users to a role.\nDENY ALTER USER ON DBMS TO my_role\nDeny the privilege to alter users to a role.\nREVOKE SET PASSWORDS ON DBMS FROM my_role\nRevoke the granted and denied privileges to alter users’ passwords from a role.\nREVOKE GRANT SET USER STATUS ON DBMS FROM my_role\nRevoke the granted privilege to alter the account status of users from a role.\nGRANT SET USER HOME DATABASE ON DBMS TO my_role\nGrant the privilege alter the home database of users to a role.\nGRANT DROP USER ON DBMS TO my_role\nGrant the privilege to delete users to a role.\nREVOKE DENY SHOW USER ON DBMS FROM my_role\nRevoke the denied privilege to show users from a role.\nGRANT USER MANAGEMENT ON DBMS TO my_role\nGrant all privileges to manage users to a role. (★) Database management privileges\nGRANT CREATE DATABASE ON DBMS TO my_role\nGrant the privilege to create databases and aliases to a role.\nREVOKE DENY DROP DATABASE ON DBMS FROM my_role\nRevoke the denied privilege to delete databases and aliases from a role.\nREVOKE GRANT ALTER DATABASE ON DBMS FROM my_role\nRevoke the granted privilege to alter databases and aliases from a role.\nGRANT SET DATABASE ACCESS ON DBMS TO my_role\nGranted privilege to set database access mode to a role.\nDENY DATABASE MANAGEMENT ON DBMS TO my_role\nDeny all privileges to manage databases and aliases to a role. (★) Privilege management privileges\nGRANT SHOW PRIVILEGE ON DBMS TO my_role\nGrant the privilege to show privileges to a role.\nDENY ASSIGN PRIVILEGE ON DBMS TO my_role\nDeny the privilege to assign privileges to roles to a role.\nREVOKE GRANT REMOVE PRIVILEGE ON DBMS FROM my_role\nRevoke the granted privilege to remove privileges from roles from a role.\nREVOKE PRIVILEGE MANAGEMENT ON DBMS FROM my_role\nRevoke all granted and denied privileges for manage privileges from a role. (★) DBMS privileges\nGRANT ALL ON DBMS TO my_role\nGrant privilege to perform all role, user, database, alias, privilege, procedure, function, and impersonation management to a role.\nDENY IMPERSONATE (alice) ON DBMS TO my_role\nDeny privilege to impersonate the specified user to a role.\n(★) Functionality available in Neo4j Enterprise Edition."
  },
  {
    "objectID": "posts/93592b9e-7f44-4dd2-8c62-a670063e869d/index.html",
    "href": "posts/93592b9e-7f44-4dd2-8c62-a670063e869d/index.html",
    "title": "Neo4j AuraDB",
    "section": "",
    "text": "Neo4j AuraDB & Neo4j Kali\nusername: neo4j password: Mj4IlSD64mQcXEYlhlQ7nQz7g8x3Elr9UVE78InPW9w\nneo4j kali bolt://localhost:7687"
  },
  {
    "objectID": "posts/944ee020-33e3-4e10-9d9c-92952906157e/index.html",
    "href": "posts/944ee020-33e3-4e10-9d9c-92952906157e/index.html",
    "title": "NoRepeat flag in pyjom producer",
    "section": "",
    "text": "NoRepeat flag in pyjom producer\nno consecutive clip sequences have then same file source. no identical clips in render sequence."
  },
  {
    "objectID": "posts/0f4d76e4-f1f0-484f-9a7c-d3668a37b770/index.html",
    "href": "posts/0f4d76e4-f1f0-484f-9a7c-d3668a37b770/index.html",
    "title": "Optical Flow, slow motion and more",
    "section": "",
    "text": "Optical Flow, slow motion and more\nhttps://github.com/slowmoVideo/slowmoVideo\nit uses gpu and optical flow to do frame interpolation.\nable to do instance segmentation if the optical flow boundary is clear and continuous.\nbuild opencv with opencv_contrib and -DWITH_CUDA=ON to enable cudaoptflow."
  },
  {
    "objectID": "posts/43a03d50-ad97-49f0-a3f6-e340822ad556/index.html",
    "href": "posts/43a03d50-ad97-49f0-a3f6-e340822ad556/index.html",
    "title": "Polymer Chemistry Mixture",
    "section": "",
    "text": "Polymer Chemistry Mixture\nhttp://www.cheminfo.org/\ninteratomic potentials: https://www.ctcms.nist.gov/potentials/ https://zhuanlan.zhihu.com/p/351829537 https://www.ctcms.nist.gov/potentials/system/C-H-O/ https://atb.uq.edu.au/index.py?tab=structure_search\nhttps://github.com/dwsideriusNIST/LAMMPS_Examples\nopensmog smog2.provides force field generation tool\nrun simulation under given temperature, pressure and get density\nopenmm generate force field on the fly: from openff.toolkit.topology import Molecule molecule = Molecule.from_smiles(‘c1ccccc1’)\nhttps://www.catalysis-hub.org\npymatgen contains polymer generator to lammps: pymatgen.io.lammps.utils\nsimulating reaction in molecular dynamics: https://www.reacter.org implemented in lammps fix bond/react method\nrandom.randomvoidmail@erine.email (pending approval)\nseen polymer names on lammps demo website: https://lammps.org/pictures.html#reactphoto\nhttps://docs.lammps.org/Intro_features.html\nIf you are a new computational chemist I would advise you to use ASE, it is not only useful for nanoparticles, I’m using it nearly every day.\npatent: https://bulkdata.uspto.gov/ http://chemdataextractor.org/results/26088052-3833-41ea-98f1-0a8a3fb2c341\nhttps://www.zhihu.com/question/50559712\nmoltemplate, packmol\nvmd: lammps data file visualization\nbuild input file for lammps: https://atomsk.univ-lille.fr/\nget retrosynthesis training data on picture search engines\nocta: predict polymer properties https://octa.jp/references/examples/\nLink: [5]http://oexchange.org/spec/0.8/rel/related-target You can try [33]https://spaya.ai/ it is a retro-synthetic analysis [37]Http://www.orgsyn.org/ [41]Http://www.orgsyn.org/ [45]Http://www.organic-chemistry.org/ Try this interesting blog: [49]http://totallysynthetic.com/blog/ And also this website: [50]http://chemistrybydesign.oia.arizona.edu/ [54]http://www.chemspider.com/  [58]https://pubchem.ncbi.nlm.nih.gov/search Organic Syntheses Website: &lt;[62]http://www.orgsyn.org Organic Chemistry Portal: &lt;[63]http://www.organic-chemistry.org/abstracts Chemsynthesis: [64]http://www.chemsynthesis.com ChemExper: [65]https://www.chemexper.com Pub Chem compound: [67]http://pubchem.ncbi.nlm.nih.gov E-molecules: [68]http://www.emolecules.com Chemspider: [69]http://www.chemspider.com Reaxys: [70]https://www.reaxys.com/ SciFinder: [71]http://www.cas.org, STN: [72]https://stnweb.cas.org/ [76]http://www.chemspider.com [80]https://www.vulcanchem.com/\nhttps://moltemplate.org\nhttps://chemdataextractor.org\ngromacs: creating polymer structure http://www.gromacs.org/Documentation_of_outdated_versions/How-tos/Polymers\nlatest gromacs documentation: https://manual.gromacs.org/documentation/\nonline organic chemistry textbook: https://www2.chemistry.msu.edu/faculty/reusch/virttxtjml/intro1.htm\nopenbabel can only run normally on x86 platforms. so do other cheminfo packages.\nsources of organic synthesis https://www.organic-chemistry.org http://www.orgsyn.org\nWhat is matsci.org?\nmatsci.org is a community forum for the discussion of anything materials science, with a focus on computational materials science research. Its members are typically from academic research institutions and universities.\nPeople that currently help run matsci.org include maintainers of the following codes and collaborations:\nOVITO\nGULP\nDL_POLY\nOPTIMADE\npyiron\nhiphive\nASE\nMPDS\niFermi\nLAMMPS\nMaRDA\nexciting\nJARVIS\nand members of the following research groups:\nHacking Materials Group\nPersson Group\nMaterials Virtual Lab\nMaterials Intelligence\ntranslate bigsmiles into smiles\npolymer database: PolyInfo and NIST Synthetic Polymer MALDI Recipes database USPEX chemdraw chemoffice indraw spaya.ai reaxys scifinder-n marvin sketch pka https://github.com/PKUMDL-AI/AutoSynRoute\npolymer simulation: material studio amsterdam modeling suite\ncp2k orca https://orcaforum.kofo.mpg.de/app.php/portal\nchemistry in stack exchange: https://chemistry.stackexchange.com/\npolymer retrosynthesis using retro*: seq2seq-retro mlp-retro polyretro-uspto\ndeepchem, chempy(inorganic)\navogadro: import openbabel files\nodachi: decompose target molecular into source molecular, highlight the potential bond\nrdkit: python chemistry informatic polymer informatic\nab initio chemistry: lammps, quantum espresso, nwchem, gamess, uspex\nfrom https://www.webmol.net: Gamess, Gaussian, MolPro, Mopac, NWChem, Orca, PQS, PSI, Q-Chem, TeraChem, Tinker, Quantum Expresso, and VASP"
  },
  {
    "objectID": "posts/fd2b58b6-ffbf-488a-a401-308bb0538a5c/index.html",
    "href": "posts/fd2b58b6-ffbf-488a-a401-308bb0538a5c/index.html",
    "title": "PowerPoint 比较视频制作方法 Animation Software OSS Scriptable Flipcard",
    "section": "",
    "text": "PowerPoint 比较视频制作方法 Animation Software OSS Scriptable Flipcard\n\n看看别人的数据来源是什么\n\n知乎神回答 知乎同类回答 排行榜 github排行榜 同类内容\n比较视频可以用段落总结关键词来做\nfree open source animation software for linux, by sourceforge.net\nthree.js javascript 3d library\ntyped.js imitate typing animation\nanime.js javascript animation engine\nsynfig 2d vector based animation library\ncountup.js animate counting up to a number\nvivus.js drawing animation imitator\nLibreoffice Impress或者其他的动画工具 制作视频 比如synfig blender three.js https://ask.libreoffice.org/t/convert-impress-presentation-to-video/33952 https://ask.libreoffice.org/t/how-to-turn-libreoffice-impress-into-video-mp4-format/20589\n同样的 可以制作冷知识问答的动画视频 通过收集百度 bing搜索相关词语 如果是问句 问题 就拿来搜索 如果出现了放大版本的句子就收集下来 就是回答"
  },
  {
    "objectID": "posts/2279480c-3b01-4cf3-8e0a-5c2c48bd16aa/index.html",
    "href": "posts/2279480c-3b01-4cf3-8e0a-5c2c48bd16aa/index.html",
    "title": "Pyatspi dogtail gnome accessibility gui inspect tool for linux a11y",
    "section": "",
    "text": "Pyatspi dogtail gnome accessibility gui inspect tool for linux a11y\ndoes appium have linux accessibility implementation?\nwindows a11y: https://github.com/blackrosezy/gui-inspect-tool pywinauto\nbookmark_history_search sucks. it does not include webpage summaries, only title, which makes searching the history very hard. the solution is to use readbility.js to visit and summarize these pages, and update these documents in meilisearch.\na11y is the general term for accessibility, for web browsers like firefox. however, there’s implementation for gnome internally.\nlinux a11y: https://github.com/shubhamvasaikar/Auto-GUI-Testing gnome accessibility toolkit(atk)\nhttps://gitlab.gnome.org/GNOME/pyatspi2 https://gitlab.com/dogtail/dogtail https://www.freedesktop.org/wiki/Accessibility/PyAtSpi2Example/\naccessibility implementation in different toolkits: https://github.com/GNOME/at-spi2-core/blob/e83d5558d2fbded5b345b0af254f26865e148e49/devel-docs/toolkits.md\nToolkits that use the DBus APIs directly GTK4 Sources: gtk4/gtk/a11y\nQt5 Sources: qtbase/src/gui/accessible/linux\nWebKit Sources: WebKit/Source/WebCore/accessibility/atspi\nToolkits that use ATK GTK3 Sources: gtk3/gtk/a11y\ngnome-shell / St / via clutter’s cally Sources: mutter/clutter/clutter/cally\nMozilla Firefox Sources: gecko-dev/accessible/atk\nChromium Uses both ATK and libatspi?\nSources:\nchromium/ui/accessibility/platform/auralinux (atk) chromium/ui/accessibility/platform/inspect/auralinux (atspi) chromium/content/browser/accessibility/auralinux (atspi and atk) LibreOffice Sources: LibreOffice/core/vcl/unx/gtk3/a11y\nJava Swing - via java-atk-wrapper Sources: java-atk-wrapper"
  },
  {
    "objectID": "posts/e348d1c5-1ab3-4bc4-9ef7-5d4a85550de2/index.html",
    "href": "posts/e348d1c5-1ab3-4bc4-9ef7-5d4a85550de2/index.html",
    "title": "Python DSL",
    "section": "",
    "text": "Python DSL\ntextX with syntax highlighter and LSP support, just like Xtext\nply: python lex-yacc\ndhparser\nlark"
  },
  {
    "objectID": "posts/d698257f-9d86-46e1-a932-d858461bf000/index.html",
    "href": "posts/d698257f-9d86-46e1-a932-d858461bf000/index.html",
    "title": "Python suggest binary file name extension",
    "section": "",
    "text": "Detect media file corruption, Python suggest binary file name extension\nto rule out those corrupted media files, or unplayable files. maybe simply by parsing these files is not enough, we need a dedicated file corruption detector.\nto truncate these files and see errors produced by media readers. use text file with media file extension to test them."
  },
  {
    "objectID": "posts/988d366f-5542-4e0d-b4f7-08ef1c9cb294/index.html",
    "href": "posts/988d366f-5542-4e0d-b4f7-08ef1c9cb294/index.html",
    "title": "Pytorch OOM_1",
    "section": "",
    "text": "Pytorch OOM\nsshpass -p HFSPMFaTVPhfPzfPqAWmp7z5ewKm5xMG ssh -p 60164 root@i-1.gpushare.com\ndisabled all distributed modules. set device to cpu."
  },
  {
    "objectID": "posts/bf6fef59-3603-4ecd-8730-b65bf6562db5/index.html#qq号码注册规则",
    "href": "posts/bf6fef59-3603-4ecd-8730-b65bf6562db5/index.html#qq号码注册规则",
    "title": "QQ 微信 信息提取 bot搭建",
    "section": "qq号码注册规则",
    "text": "qq号码注册规则\nqq群最多可以添加500个群 1500个好友 其中群可加的数量 = max(0,500 - 已加入群数量 - 好友数量) 可以退出一些安静的群 不发红包的群 删除好友\n屏蔽别人加我为好友 允许别人拉我进群 自动退出广告群 退出不活跃的群\n群一天只能加两三个 或者手机上可以加十个 好友一天可以加三十几个\n一个验证QQ群的Python代码 https://www.bilibili.com/read/mobile?id=10044756\nfrida inject mobile android qq and open qzone: https://github.com/xhtechxposed/fridainjectqq\nsearch https://qun.qq.com in search engines\n可以考虑截图获取QQ群验证问题 或者手机测试 appium\nif possible then just use frida/radare2 or some reverse engineering to automate the process.\nradare2 -&gt; rizin.re(radare2 fork) based, ida alike, with ghidra decompiler, reverse engineering tool: https://cutter.re\n如何获取进群验证问题？记得可以拦截PC端搜索QQ群接收的数据包获取验证问题 或许不行 总之可以获取到一些参数 查看是否包含验证问题 是不是允许任何人进群 也可以考虑拦截opqqq的通信 或者发送一些通用的加群验证信息 比如“加群学习” “小伙伴一起玩” 之类的 或者用ai模型根据群描述 群主题 生成\n一个手机号码可以申请10个qq号，一个手机号绑定的QQ帐号名额上限为10个，但一天一个手机号只能成功注册两到三个\nWeChat needs serious reverse engineering like frida.\nhttps://github.com/cixingguangming55555/wechat-bot 有webapi的微信机器人 注入dll到pc\nhttps://github.com/mrsanshui/WeChatPYAPI 可以加好友的python wechat pc hook\nhttps://github.com/snlie/WeChat-Hook 易语言的wechat hook 功能非常全 搜索 加人 有教程链接 教学代码\nhttps://github.com/TonyChen56/WeChatRobot 比较老的wechat逆向模块 wechatapis.dll半天获得不了 有教程链接\nhttps://github.com/wechaty/puppet-xp frida 驱动的wechat puppet 暂时没有加人 搜索人 在windows上运行\nwechat reverse engineering tutorials: https://github.com/hedada-hc/pc_wechat_hook https://github.com/zmrbak/PcWeChatHooK\nwechaty base framework: https://github.com/Wechaty/python-wechaty/ (puppet support might be incomplete) https://github.com/Wechaty/wechaty/\nbotoy opqbot api for python https://botoy.opqbot.com/zh_CN/latest/action/\nqq opqbot (for wechat it has rstbot) download and install (need gitter.im api token): https://docs.opqbot.com/guide/manual.html#启动失败\nopqbot needs to be reverse engineered or we won’t know what is going on inside.\nunofficial opqbot wiki: https://mcenjoy.cn/opqbotwiki/\nwechat bot(non-free wechat puppets): wechaty\nquoted content are controversial and highly viral. must be filtered and classified before proceeding. quotes are like comments."
  },
  {
    "objectID": "posts/e492adcf-e504-44be-9981-8e8bc81a5aa8/index.html",
    "href": "posts/e492adcf-e504-44be-9981-8e8bc81a5aa8/index.html",
    "title": "RL, trajectory prediction, model predictive control",
    "section": "",
    "text": "RL, trajectory prediction, model predictive control\nthis reminds me of ddpg-usv-asmc and Deep-Reinforcement-Learning-Algorithms-with-PyTorch (is it? nope. it is stable-baseline3, containing PPO preferred by OpenAI when training InstructGPT) or Deep-reinforcement-learning-with-pytorch\nmpc.torch\nawesome-deep-rl For deep RL and the future of AI."
  },
  {
    "objectID": "posts/f692dad1-5daa-468e-9cec-db3ad9baaced/index.html",
    "href": "posts/f692dad1-5daa-468e-9cec-db3ad9baaced/index.html",
    "title": "RSS Feeds",
    "section": "",
    "text": "RSS Feeds\nkuxai ai related articles, there’s some bot keep posting this shit to qq group\nrsshub most extensible rss feeder, can turn bilibili, zhihu, or anything into rss\nmedium.com\nSearching for existing rss sources. You may want to make your own by means of social media. It could be the feeding source of reviewer or producer.\nhttps://www.baidu.com/ssid=4d994e69636f5f4e69636f6c6532353311dd/from=844b/s?word=rss订阅源&ts=7538593&t_kt=0&ie=utf-8&fm_kl=021394be2f&rsv_iqid=4109465110&rsv_t=a02fgTXA5yrpeGBRWrTCqcc9bK%252FKmzIRzII6usvAqgJjawViUjevc88MAg&sa=is_5&ms=1&rsv_pq=4109465110&rsv_sug4=6166&tj=1&ss=110&inputT=3395&sugid=110161509475552&rq=rss https://www.appstoredate.com/iphone/6990.html https://blog.csdn.net/wangjialiang/article/details/121510405 https://baijiahao.baidu.com/s?id=1677152782752706400&wfr=spider&for=pc&searchword=rss订阅源 https://www.bilibili.com/read/mobile?id=8961024 https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=rss源地址订阅大全&sa=brs_7&rq=rss订阅源&rsf=100631857&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=订阅源整合&sa=brs_6&rq=rss订阅源&rsf=100631112&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=知乎日报rss源&sa=brs_4&rq=rss订阅源&rsf=100631113&pqid=8915434938561485118&ms=1&rqid=8915434938561485118&params_ssrt=node-san https://www.zhihu.com/question/25071126/answer/875901493 https://zhuanlan.zhihu.com/p/53989966 https://m.baidu.com/from=844b/ssid=4d994e69636f5f4e69636f6c6532353311dd/s?word=各大网站RSS订阅源地址&sa=re_dl_prs_34689_1&rqid=10035302357898163828&params_ssrt=node-san&rq=知乎日报rss源&rsf=100631113&asctag=2470 https://www.tutorialspoint.com/python_text_processing/python_reading_rss_feed.htm https://www.datasciencelearner.com/how-to-read-rss-feed-in-python/ https://wiki.python.org/moin/RssLibraries https://stackoverflow.com/questions/2244836/rss-feed-parser-library-in-python https://pypi.org/project/rss-reader/ https://github.com/lemon24/reader https://reader.readthedocs.io/en/latest/\nwe need cleaner view by using readbility.js, but how to preserve pictures? is it built-in?\npictures could be a big fingerprint. better deal them with link extracter and shufflers.\nyou want python version or nodejs version?\nnpm install @mozilla/readability\n# it can be invoked via api, standalone!\n# you might want to call javascript from python\npip3 install readability-lxml\n# some lags behind?\nthis is for the reader mode, make webpage readable\nhttps://github.com/luin/readability https://github.com/phpdocker-io/readability-js-server https://github.com/mozilla/readability https://github.com/alan-turing-institute/ReadabiliPy https://github.com/edgartaor/kindleServer https://requests-html.kennethreitz.org https://github.com/psf/requests-html https://github.com/MHordecki/readability-redux/blob/master/readability/readability.js https://github.com/buriy/python-readability https://stackoverflow.com/questions/56857506/how-to-enable-reader-mode-distill-page-with-puppeteer"
  },
  {
    "objectID": "posts/ed1dbec2-e807-4a8e-80a2-d978f1772e22/index.html",
    "href": "posts/ed1dbec2-e807-4a8e-80a2-d978f1772e22/index.html",
    "title": "React Native",
    "section": "",
    "text": "React Native\nThe key is to see immediate response directly after changes\nReact Native is a tool helping to build cross-platform mobile/desktop apps.\nNativeScript is something alike.\nKivy Roboto"
  },
  {
    "objectID": "posts/4ff38d3a-ebac-49b9-91dc-3218891008cc/index.html",
    "href": "posts/4ff38d3a-ebac-49b9-91dc-3218891008cc/index.html",
    "title": "Redis Cheatsheet",
    "section": "",
    "text": "Redis Cheatsheet\nRedis Cheat Sheet\nWhen you encounter a Redis instance and you quickly want to learn about the setup you just need a few simple commands to peak into the setup. Of course it doesn’t hurt to look at the official full command documentation, but below is a listing just for sysadmins. Accessing Redis CLI\nFirst thing to know is that you can use “telnet” (usually on Redis default port 6379)\ntelnet localhost 6379\nor the Redis CLI client\nredis-cli\nto connect to Redis. The advantage of redis-cli is that you have a help interface and command line history. CLI Queries\nHere is a short list of some basic data extraction commands: Type Syntax and Explanation Tracing monitor Watch current live commands. Use with care when on production. Cancel with Ctrl-C. Slow Queries slowlog get 25 Print top 25 slow queries slowlog len slowlog reset Search / List All Keys keys &lt;pattern Use with care when on production! keys myprefix keys pattern keys mysuffix keys [a-c]* Use grep like expressions Generic Key Handling del  Delete key dump  Serialize key exists  Check for key expire   Set key TTL Working with scalar types get  set   setnx   Set key value only if key does not exist Batch commands: mget   … mset     Working with counters incr  decr  Redis Lists lrange    Accessing lists lrange mylist 0 -1 Output all elements lindex mylist 5 Get 5th element llen mylist Get list length\nlpush mylist \"value\" Push “value” to list\nlpush mylist 5 Push number 5 to list\nrpush mylist \"value\" Push “value” to beginning (unshift)\n \nlpushx mylist 6 Only push if mylist exists\nrpushx mylist 7\n \nlpop mylist Remove+return value from list\nrpop mylist Remove+return value from start (shift)\n \nlrem mylist 1 \"value\" Remove ‘value’ count times\nlset mylist 2 6 Set 3rd element to value 6\nltrim &lt;key&gt; &lt;start&gt; &lt;stop&gt;\nWorking with Redis Hashes hexists myhash field1 Check if hash key exists\nhget myhash field1 Get key value\nhdel myhash field2 Delete key\nhset myhash field1 \"value\" Set key with “value”\nhsetnx myhash field1 \"value\"\n \nhgetall myhash Get all hash content\nhkeys myhash List all keys\nhlen myhash List number of keys\n \nBatch commands:\nhmget &lt;key&gt; &lt;key&gt; ... Get multiple keys\nhmset &lt;key&gt; &lt;value&gt; &lt;key&gt; &lt;value&gt; ... Set multiple keys\n \nCounter commands\nhincrby myhash field1 1\nhincrby myhash field1 5\nhincrby myhash field1 -1\n \nhincrbrfloat myhash field2 1.123445\nCLI Scripting\nFor scripting just pass commands to “redis-cli”. For example:\n$ redis-cli INFO | grep connected connected_clients:2 connected_slaves:0 $\nServer Statistics\nThe statistics command is “INFO” and will give you an output as following.\n$ redis-cli INFO redis_version:2.2.12 redis_git_sha1:00000000 redis_git_dirty:0 arch_bits:64 multiplexing_api:epoll process_id:8353 uptime_in_seconds:2592232 uptime_in_days:30 lru_clock:809325 used_cpu_sys:199.20 used_cpu_user:309.26 used_cpu_sys_children:12.04 used_cpu_user_children:1.47 connected_clients:2 # &lt;——- connection count connected_slaves:0 client_longest_output_list:0 client_biggest_input_buf:0 blocked_clients:0 used_memory:6596112 used_memory_human:6.29M # &lt;——- memory usage used_memory_rss:17571840 mem_fragmentation_ratio:2.66 use_tcmalloc:0 loading:0 aof_enabled:0 changes_since_last_save:0 bgsave_in_progress:0 last_save_time:1371241671 bgrewriteaof_in_progress:0 total_connections_received:118 total_commands_processed:1091 expired_keys:441 evicted_keys:0 keyspace_hits:6 keyspace_misses:1070 hash_max_zipmap_entries:512 hash_max_zipmap_value:64 pubsub_channels:0 pubsub_patterns:0 vm_enabled:0 role:master # &lt;——- master/slave in replication setup db0:keys=91,expires=88\nChanging Runtime Configuration\nThe command\nCONFIG GET *\ngives you a list of all active configuration variables you can change. The output might look like this:\nredis 127.0.0.1:6379&gt; CONFIG GET * 1) “dir” 2) “/var/lib/redis” 3) “dbfilename” 4) “dump.rdb” 5) “requirepass” 6) (nil) 7) “masterauth” 8) (nil) 9) “maxmemory” 10) “0” 11) “maxmemory-policy” 12) “volatile-lru” 13) “maxmemory-samples” 14) “3” 15) “timeout” 16) “300” 17) “appendonly” 18) “no” 19) “no-appendfsync-on-rewrite” 20) “no” 21) “appendfsync” 22) “everysec” # &lt;——- how often fsync() is called 23) “save” 24) “900 1 300 10 60 10000” # &lt;——- how often Redis dumps in background 25) “slave-serve-stale-data” 26) “yes” 27) “hash-max-zipmap-entries” 28) “512” 29) “hash-max-zipmap-value” 30) “64” 31) “list-max-ziplist-entries” 32) “512” 33) “list-max-ziplist-value” 34) “64” 35) “set-max-intset-entries” 36) “512” 37) “slowlog-log-slower-than” 38) “10000” 39) “slowlog-max-len” 40) “64”\nNote that keys and values are alternating and you can change each key by issuing a “CONFIG SET” command like:\nCONFIG SET timeout 900\nSuch a change will be effective instantly. When changing values consider also updating the redis configuration file. Databases Multiple Databases\nRedis has a concept of separated namespaces called “databases”. You can select the database number you want to use with “SELECT”. By default the database with index 0 is used. So issuing\nredis 127.0.0.1:6379&gt; SELECT 1 OK redis 127.0.0.1:6379[1]&gt;\nswitches to the second database. Note how the prompt changed and now has a “[1]” to indicate the database selection. To find out how many databases there are you might want to run redis-cli from the shell:\n$ redis-cli INFO | grep ^db db0:keys=91,expires=88 db1:keys=1,expires=0\nDropping Databases\nTo drop the currently selected database run\nFLUSHDB\nto drop all databases at once run\nFLUSHALL\nReplication Checking for Replication\nTo see if the instance is a replication slave or master issue\nredis 127.0.0.1:6379&gt; INFO […] role:master\nand watch for the “role” line which shows either “master” or “slave”. Starting with version 2.8 the “INFO” command also gives you per slave replication status looking like this\nslave0:ip=127.0.0.1,port=6380,state=online,offset=281,lag=0\nSetting up Replication\nIf you quickly need to set up replication just issue\nSLAVEOF  \non a machine that you want to become slave of the given IP. It will immediately get values from the master. Note that this instance will still be writable. If you want it to be read-only change the redis config file (only available in most recent version, e.g. not on Debian). To revert the slave setting run\nSLAVEOF NO ONE\nPerformance Testing Benchmark\nInstall the Redis tools and run the provided benchmarking tool\nredis-benchmark -h  [-p ]\nIf you are migrating from/to memcached protocol check out how to run the same benchmark for any key value store with memcached protocol. Debugging Latency\nFirst measure system latency on your Redis server with\nredis-cli –intrinsic-latency 100\nand then sample from your Redis clients with\nredis-cli –latency -h  -p \nIf you have problems with high latency check if transparent huge pages are disabled. Disable it with\necho never &gt; /sys/kernel/mm/transparent_hugepage/enabled\nDump Database Backup\nAs Redis allows RDB database dumps in background, you can issue a dump at any time. Just run:\nBGSAVE\nWhen running this command Redis will fork and the new process will dump into the “dbfilename” configured in the Redis configuration without the original process being blocked. Of course the fork itself might cause an interruption. Use “LASTSAVE” to check when the dump file was last updated. For a simple backup solution just backup the dump file. If you need a synchronous save run “SAVE” instead of “BGSAVE”. Listing Connections\nStarting with version 2.4 you can list connections with\nCLIENT LIST\nand you can terminate connections with\nCLIENT KILL :\nMonitoring Traffic\nThe propably most useful command compared to memcached where you need to trace network traffic is the “MONITOR” command which will dump incoming commands in real time.\nredis 127.0.0.1:6379&gt; MONITOR OK 1371241093.375324 “monitor” 1371241109.735725 “keys” “*” 1371241152.344504 “set” “testkey” “1” 1371241165.169184 “get” “testkey”\nadditionally use “SLOWLOG” to track the slowest queries in an interval. For example\nSLOWLOG RESET # wait for some time SLOWLOG GET 25\nand get the 25 slowest command during this time. Sharding with proxies\nThere are two major proxy solutions\nTwemproxy (aka nutcracker, by Twitter)\nCodis"
  },
  {
    "objectID": "posts/3ff1f16b-dfaf-4155-9d09-44fa42edffc3/index.html",
    "href": "posts/3ff1f16b-dfaf-4155-9d09-44fa42edffc3/index.html",
    "title": "Remove Unused pip dependencies",
    "section": "",
    "text": "Remove Unused pip dependencies\nsometimes we install a single package which brings about tons of dependencies in python, pip-autoremove comes in handy.\ninstall it by pip3 install pip-autoremove\nthough be careful these dependencies might not be used in other existing packages, they are sometimes still being used in your code!"
  },
  {
    "objectID": "posts/64094857-761a-4563-bf5b-2af6c60b54df/index.html",
    "href": "posts/64094857-761a-4563-bf5b-2af6c60b54df/index.html",
    "title": "Resolve Host Name Computer Name From IP",
    "section": "",
    "text": "Resolve Host Name Computer Name From IP\nmany methods have been tried. NetBIOS not working. DHCP server not found. nmap script engine(NSE) uses lua to automate sniffing and attacks."
  },
  {
    "objectID": "posts/be66c80c-a5bb-4793-b73a-537ede670918/index.html",
    "href": "posts/be66c80c-a5bb-4793-b73a-537ede670918/index.html",
    "title": "Roll in Bed在床上翻滚",
    "section": "",
    "text": "Roll in Bed在床上翻滚\n不仅要侧翻 正反颠倒 还要垫高后背的同时垫高脖子 用被子和圆枕垫高手臂 抬高小桌板\n吃东西吃多了 需要到处走动而不是躺着不动 不然不消化 导致不舒服 发热\n床上躺的过多 压力大 一般喜欢吃东西来减轻压力 安静的地方 人少的地方比较适合节食\n适当的吃东西 不要吃太多\n晚上过晚睡觉 吃东西吃太多 晚上吃东西 和喝酒类似"
  },
  {
    "objectID": "posts/dbd5a421-a3a9-4979-9495-ce7033d8cedc/index.html",
    "href": "posts/dbd5a421-a3a9-4979-9495-ce7033d8cedc/index.html",
    "title": "SEO tools",
    "section": "",
    "text": "SEO tools\nhttps://github.com/YitingWang25436/Keywords-selection-model https://github.com/ulysseses/tag_recommender https://github.com/rdowns26/seo_keyword_research_tools https://github.com/coreymcmahon/SeoPy https://github.com/teles/awesome-se"
  },
  {
    "objectID": "posts/00a99545-ed5f-4939-9f1a-8c55de25c119/index.html#my-custom-search-engine-built-upon-thesaurussynonymsantenyms-fzf-and-grep",
    "href": "posts/00a99545-ed5f-4939-9f1a-8c55de25c119/index.html#my-custom-search-engine-built-upon-thesaurussynonymsantenyms-fzf-and-grep",
    "title": "Search Engines",
    "section": "my custom search engine built upon thesaurus/synonyms/antenyms, fzf and grep",
    "text": "my custom search engine built upon thesaurus/synonyms/antenyms, fzf and grep\nRETRO retrieval based attention net, though using faiss, unclear if it is search related. on page 8 of the paper there are different retrieval based models for selections. LDA (topic modeling) can assist search by discovering similar topics.\ndownload nltk data here. when downloading manually, beware of the url path and id, so you would put things in order.\nyou would patch nltk in order to download via proxy. these data files are hosted on github assets.\ncheck keyword urlopen and filedownloder.py under /data/data/com.termux/files/usr/lib/python3.10/site-packages/nltk\nmaybe you can explore further with online search engines? select your keyword then search again.\nthesaurus will slow down things. make it into a preprocessor.\nrelated shits can be found here"
  },
  {
    "objectID": "posts/00a99545-ed5f-4939-9f1a-8c55de25c119/index.html#search-engine-optimization",
    "href": "posts/00a99545-ed5f-4939-9f1a-8c55de25c119/index.html#search-engine-optimization",
    "title": "Search Engines",
    "section": "search engine optimization",
    "text": "search engine optimization\nadvertools\nzinc search\nmarkuplm markup language model used for feature rich information extraction, webqa, arxiv paper: reading wikipedia to answer open domain questions\nzinc search, go implementation of elastic search alternative\nI bet there are many many alternatives. even for a relational database or graph database it can be a search engine by its nature.\nhow the heck can i search my own notes? slice it into little segments? standard excerpt included.\nsearch for search engine in github.\nsearch engines are related to spiders/crawlers.\nhow to utilize these search engines is a problem/challenge. use url filters, generic extractors, readbility.js, summarizers like sumy.\nmany specialized search engines that can search image, video and audio. one example is Jina\nsemantic search tool, multimedia search tool, neural search tool\nhttps://github.com/searxng/searxng\nparse popular search engine results like baidu, bing: https://github.com/bisohns/search-engine-parser\nsearch and scrape news https://github.com/01joy/news-search-engine\nimage search engine https://github.com/matsui528/sis\nsearch engines used by hackers, social engineering, onion sites: https://github.com/edoardottt/awesome-hacker-search-engines\nsearch engine with customized recommendation: https://github.com/mtianyan/FunpySpiderSearchEngine\nseo tools 百度下拉词获取 推荐词相关词 https://github.com/marcobiedermann/search-engine-optimization\na self-hosted search engine that can be deployed on heroku, google alike: https://github.com/benbusby/whoogle-search\ntxtai: semantic search tool pip3 install txtai using sentence-transformer models from huggingface sentence embedding https://github.com/neuml/txtai\nyacy: distributed search engine circumvent censorship provide rss feeds\nsearx: meta search engine self-hosted has third-party hosted searx websites avaliable: https://searx.space/ total 83 online(currently)\nmwmbl: distributed crawler central search engine, can be self-hosted written in python\nvideo search engine: generate summary from frames https://github.com/AkshatSh/VideoSearchEngine\nyuno: context based search engine for anime, anime search engine with transformer and deep learning. text based search. more like a semantic search tool, or neural search tool. Yuno is a context based search engine that indexes over 0.5 million anime reviews and other anime informations. To help you find anime with specific properties. This search engine will help people of r/AnimeSuggest who are looking for specific type of anime to watch. This search engine was created to solve the problem of finding an object with specific properties and the object in this case is anime. But this search engine can be easily extended to any domain like books,movies,etc. Without the need of any kind of handcrafted dataset.\nTypeSense: dedicated client for every popular programminhg language consume much fewer ram than meilisearch need to write custom web interface via nodejs upload data via client api\nMeiliSearch: good for small dataset consume whoopy 900mb for my 9mb json dataset. has intuitive web interface. upload document via web post."
  },
  {
    "objectID": "posts/176cf3a5-06f3-4174-89c3-fedfcb3d3f08/index.html",
    "href": "posts/176cf3a5-06f3-4174-89c3-fedfcb3d3f08/index.html",
    "title": "Seek for cooperation and solution sharing",
    "section": "",
    "text": "Seek for cooperation and solution sharing\nI have been researching in automotive computers for years.\nTopics that you might be interested in that I have dug into:\n\nFree Energy Principle & Active Inference\nLLM Robotics\nQ-Star Learning\nRT-2 & RT-X dataset\nCrop & Zoom Based Attention\nRecursive Positional Encoding\nDynamic Reservoir Computing\nAutomotive Learning Rate\nHardware Mouse/Keyboard Control\nPhysical Robot Based HID Control\nBit-level Autoregressive Transformer\nBrowser-based AI Playground\nContainerized Console and GUI AI Playground\n\nI have dedicated repositories that you may be interested into:\n\nagi-computer-control: automotive computer, which can see, hear and operate\nmetalazero: multi-platform computer automation attempts\n\nOther similar projects that I am monitoring:\n\nGPT-4V-Act\nSingularGPT\ngpt-eyes\ngpt4v-browsing\nself-operating-computer\n\nApologize for my unorganized code structure. I am trying to improve development experience by AI generated documentation & usage demonstration and client-side LLM & semantic search, which may solve this long-standing task among all my previous repositories."
  },
  {
    "objectID": "posts/e67c1c47-bfac-4fd7-8e1d-4a439ca8331f/index.html",
    "href": "posts/e67c1c47-bfac-4fd7-8e1d-4a439ca8331f/index.html",
    "title": "Sentence Word order corrector",
    "section": "",
    "text": "Sentence Word order corrector\ndesign a model to accept fixed length word type sequence and output word order token. the token is used to decode the final word sequence, just like the convolution but different.\ninput can be both misplaced sentences or correct sentences\nlooking for english word order correctifier.(grammar)"
  },
  {
    "objectID": "posts/9a037e53-5780-4239-aea6-1c54c3476478/index.html",
    "href": "posts/9a037e53-5780-4239-aea6-1c54c3476478/index.html",
    "title": "ShapeShifters",
    "section": "",
    "text": "ShapeShifters\nhttps://termbin.com/qqft\nsimply do not take offer with some serious math. if really want to challenge yourself, go ahead and try, but do not even make a move to place the bid. you know you are sick of deadlines.\nthis shit is over but we still have the code and the pdf. still recoverable. it is about mmp/pbrt_v3 and the displacement map on a damn sphere. calculate occulusion and more according to input."
  },
  {
    "objectID": "posts/b8ec5bbd-4559-4f31-baf9-e04778569d2d/index.html",
    "href": "posts/b8ec5bbd-4559-4f31-baf9-e04778569d2d/index.html",
    "title": "Simple Viral Video Generators",
    "section": "",
    "text": "Simple Viral Video Generators\nhttps://github.com/elebumm/RedditVideoMakerBot\n付费的解说视频生成器 营销号生成器 有激活卡号 有官方网站 是关于自媒体自动化的 https://github.com/suifengqjn/videoWater https://www.51ai.top"
  },
  {
    "objectID": "posts/bbe98572-d63f-4cd1-9a18-3101d9394ce4/index.html",
    "href": "posts/bbe98572-d63f-4cd1-9a18-3101d9394ce4/index.html",
    "title": "Sketch based applications",
    "section": "",
    "text": "Sketch based applications\nmagenta studio sketch completion\nawesome sketch based applications paper and code sketch syntheses inbetweening: https://github.com/MarkMoHR/Awesome-Sketch-Based-Applications#17-sketch-animationinbetweening\ndeep sketch based cartoon inbetweening: https://github.com/xiaoyu258/Inbetweening"
  },
  {
    "objectID": "posts/dac8218a-eb8f-445e-a1ff-0fedb85d7fb2/index.html",
    "href": "posts/dac8218a-eb8f-445e-a1ff-0fedb85d7fb2/index.html",
    "title": "Social Media Platforms",
    "section": "",
    "text": "Social Media Platforms\n收集总结流行的或者网页端的social media platform 方便爬取 mitm 发广告 智能交互\n从social media的本源分析 有广播 报纸 电视 邮件 wiki BBS（论坛） 贴吧 博客 即时通讯 流媒体推送 订阅 内容平台\n从形式上分析 有文章 评论 动态 聊天 视频 音频 图片"
  },
  {
    "objectID": "posts/3fe8835e-3372-4e1b-8da9-b59444b389bc/index.html",
    "href": "posts/3fe8835e-3372-4e1b-8da9-b59444b389bc/index.html",
    "title": "Soul查看被拉黑之后对方的空间",
    "section": "",
    "text": "Soul查看被拉黑之后对方的空间\n这个人的空间链接目前可以访问@2022 september 4\n可以在被拉黑了之后快速点击右上角的分享链接 分享到其他人 其他群里面 或者点击生成链接 即可在浏览器里面查看这个人的动态 但是不知道这个链接有没有时效性 现在看起来就是一堆乱码 app里面的分享也不知道有没有时效性\n不知道能不能搜索或者遍历 如果不能的话只能黑进去了 不过那样的话出来的数据肯定更多\n要知道被拉黑，本地肯定有用户的ID， 有了ID就可以拿过去到其他新注册的Soul账号上面使用 通过底层api访问\n可以考虑用Frida或者网上的一些脚本来分析破解SoulAPP 单独使用Frida估计不能利用Python遍历 还是需要破解协议证书才可以自由访问\nfrida usage, code examples for windows radare2 tutorial with code"
  },
  {
    "objectID": "posts/ed4f8d1c-3701-4b15-86b8-496e66b0e8ab/index.html",
    "href": "posts/ed4f8d1c-3701-4b15-86b8-496e66b0e8ab/index.html",
    "title": "Source code semantic search tool",
    "section": "",
    "text": "Source code semantic search tool audit tool\ncan be used to analysis bilibili source code or large code base\nsourcegraph/sourcegraph: in go\ngithub/semantic: in haskell\nsonarqube: code audit tool"
  },
  {
    "objectID": "posts/f52ad58d-6e45-4ee6-86ff-b7e916250a6e/index.html",
    "href": "posts/f52ad58d-6e45-4ee6-86ff-b7e916250a6e/index.html",
    "title": "Telegram Bot",
    "section": "",
    "text": "Telegram Bot\npassword stored on a paid platform.\nhttps://d.ik888.cn/ 账户名：xueli66666666@gmail.com 密码：xueli88888888\n（deprecated） 312580603@qq.com 52lixuan https://www.okfaka.cn/xxxx1\nbot name: test0my_bot\nwith approval: https://core.telegram.org/bots/api#chatjoinrequest\nhttps://t.me/+g0Z4vMdUbUwxNGY1\n5270757326:AAEk_MHpHqSw8TQk0ST6fLG7Pzqomplgafg\n【lvyelanshan/tg_faka_bot: 基于Python的Telegram发卡机器人】https://gitee.com/lvyelanshan2/tg_faka_bot\nhttps://github.com/python-telegram-bot/python-telegram-bot/wiki/Extensions-%E2%80%93-Your-first-Bot\nsign in with google gaylat3voh98@gmail.com wfS14tjy jane62xn@icloud.com\nsshpass -p 52Lixuan ssh root@138.197.76.180"
  },
  {
    "objectID": "posts/b1448432-5e9c-4368-82dc-805b173eeaef/index.html",
    "href": "posts/b1448432-5e9c-4368-82dc-805b173eeaef/index.html",
    "title": "Termux_Boot Autostart Program Fixes",
    "section": "",
    "text": "Termux:Boot Autostart Program Fixes\naccording to this, termux:boot on android 10 and above will not work. instead, change all executables with relative paths in init scripts to their absolute paths. if any referred executable is a script file containing other executable with non-absolute paths(except for those built-in programs like am), change that too.\nmostly we hold wakelock, start sshd, crond or nginx and other non-blocking, non-interactive apps at start."
  },
  {
    "objectID": "posts/e7f81b10-0632-446f-b8b2-c135dade3f77/index.html",
    "href": "posts/e7f81b10-0632-446f-b8b2-c135dade3f77/index.html",
    "title": "The Hack (Get password and tests)",
    "section": "",
    "text": "The Hack (Get password and tests)\ndirbuster has found something over “http://oa.lixin.edu.cn//test/” + http://oa.lixin.edu.cn//admin (CODE:301|SIZE:237)\n+ http://oa.lixin.edu.cn//css (CODE:301|SIZE:235)\n+ http://oa.lixin.edu.cn//help (CODE:301|SIZE:236)\n+ http://oa.lixin.edu.cn//images (CODE:301|SIZE:238)\n+ http://oa.lixin.edu.cn//js (CODE:301|SIZE:234)\n+ http://oa.lixin.edu.cn//setup (CODE:301|SIZE:237)\n+ http://oa.lixin.edu.cn//template (CODE:301|SIZE:240)\n+ http://oa.lixin.edu.cn//test (CODE:301|SIZE:236)\n+ http://oa.lixin.edu.cn///admin (CODE:301|SIZE:237)\n+ http://oa.lixin.edu.cn///help (CODE:301|SIZE:236)\n+ http://oa.lixin.edu.cn///images (CODE:301|SIZE:238)\n+ http://oa.lixin.edu.cn///script (CODE:301|SIZE:238)\nsuspicious: http://oa.lixin.edu.cn/oanew/sys/taskcenterapp/*default/index.do\nportal (even in the internet): http://202.121.255.3:8080/portal\nScan this website with kali linux.\nThe Intranet Gateway For Campus: (maybe less hops?) https://app.topsec.com.cn\nmitmdump –mode socks5 –listen-port 8050 -w logs.log –flow-detail 3 –set stream_websocket=true\npdvpn.lixin.edu.cn pdvpn2.lixin.edu.cn vpn.lixin.edu.cn vpn2.lixin.edu.cn\nxxb.lixin.edu.cn/jszl/57078.htm\n201960630:CHENweiyi0519\nhttps://cas.paas.lixin.edu.cn/cas/login?service=https%3A%2F%2Flxjw.lixin.edu.cn%2Fcas%2Flogin\nhttps://security-center.paas.lixin.edu.cn/find-pwd\n20039370\nmissing puzzle for changing password:\ntrial user: 201960249\nfound russia hacker’s kali tool site: https://en.kali.tools/all/\napparently we have some issue with log4j and this could be our way in, the damn server.\nsniffing the whole damn campus is only possible if we know how to get into the same subnet of all people.\nhave searched related websites with site:lixin.edu.cn, could get more if keep doing so, using dnsenum.\nto get all site links with proper titles, we need to use playwright.\nnessus scanner has that 16 ips limitation, we need to crack/patch it first.\nto master kali linux, recommend to scrape kali_tools (https://tools.kali.org/) and tutorialspoint (https://www.tutorialspoint.com/kali_linux/index.htm) for kali, or just simply using manpage.\ncisco router is untouched till now. need we to scan it? (intermediate ip addresses)\ncurl ‘https://personal-security-center.paas.lixin.edu.cn/api/v1/personal/open/passwordStrategy/verify’\n-H ‘Connection: keep-alive’\n-H ‘sec-ch-ua: “(Not(A:Brand”;v=“8”, “Chromium”;v=“98”, “Google Chrome”;v=“98”’\n-H ‘Accept: application/json, text/plain, /’\n-H ‘Content-Type: application/json;charset=UTF-8’\n-H ‘sec-ch-ua-mobile: ?0’\n-H ‘User-Agent: Mozilla/5.0 (X11; CrOS aarch64 14371.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4729.0 Safari/537.36’\n-H ‘sec-ch-ua-platform: “Chrome OS”’\n-H ‘Origin: https://security-center.paas.lixin.edu.cn’\n-H ‘Sec-Fetch-Site: same-site’\n-H ‘Sec-Fetch-Mode: cors’\n-H ‘Sec-Fetch-Dest: empty’\n-H ‘Referer: https://security-center.paas.lixin.edu.cn/’\n-H ‘Accept-Language: en-US,en;q=0.9’\n–data-raw ‘{“password”:“abcdefABC”,“userId”:““}’\n–compressed\ncurl ‘https://personal-security-center.paas.lixin.edu.cn/api/v1/personal/open/forgotPassword/changePassword’\n-H ‘Connection: keep-alive’\n-H ‘sec-ch-ua: “(Not(A:Brand”;v=“8”, “Chromium”;v=“98”, “Google Chrome”;v=“98”’\n-H ‘Accept: application/json, text/plain, /’\n-H ‘Content-Type: application/json;charset=UTF-8’\n-H ‘sec-ch-ua-mobile: ?0’\n-H ‘User-Agent: Mozilla/5.0 (X11; CrOS aarch64 14371.0.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4729.0 Safari/537.36’\n-H ‘sec-ch-ua-platform: “Chrome OS”’\n-H ‘Origin: https://security-center.paas.lixin.edu.cn’\n-H ‘Sec-Fetch-Site: same-site’\n-H ‘Sec-Fetch-Mode: cors’\n-H ‘Sec-Fetch-Dest: empty’\n-H ‘Referer: https://security-center.paas.lixin.edu.cn/’\n-H ‘Accept-Language: en-US,en;q=0.9’\n–data-raw ‘{“confirmPassword”:“abc123ABC”,“newPassword”:“abc123ABC”,“nonce”:“YzhhZmZjYzktNWQ3Ny00MGU1LTg0ODgtYTYzZTMzMDZkMjU0XzE2NDAyNjg5MzcyNTY”}’\n–compressed"
  },
  {
    "objectID": "posts/de00bda5-7864-4616-a917-b46bf6ac79b5/index.html",
    "href": "posts/de00bda5-7864-4616-a917-b46bf6ac79b5/index.html",
    "title": "The phone",
    "section": "",
    "text": "The phone\nEither seek for lighter phone or use multiple splitable vertical monitors. The monitors shall be movable."
  },
  {
    "objectID": "posts/d3808b28-a77d-4bdf-bcb6-8e007fa88491/index.html",
    "href": "posts/d3808b28-a77d-4bdf-bcb6-8e007fa88491/index.html",
    "title": "Time Machine NAS macOS",
    "section": "",
    "text": "Time Machine NAS macOS\nuse rclone to periodically commit files to NAS (incremental only, do not delete things), or use rclone to copy files to external SSD\nbuy airport extreme as wireless router and backup device\n\nwhen in doubt, delete files under GUI instead of terminal\ncheck out commands for moving files into trash bin instead of direct removal on different OSes\n\nmy data under ~/works is lost. fuck.\nbuy me some ssd 512GB at least to do time machine backup.\nbuy m.2 ssd to reduce the size.\nuse usb-c cables to prevent inconvenience.\n\nthe filesystem will be formatted as APFS.\nneed a dedicated usb storage for it.\ndo not know if it is incremental backup."
  },
  {
    "objectID": "posts/ee215282-1457-45de-a4f3-39240e90a6a5/index.html",
    "href": "posts/ee215282-1457-45de-a4f3-39240e90a6a5/index.html",
    "title": "Topic Generation 话题发现 趋势发现 热点发现",
    "section": "",
    "text": "Topic Generation 话题发现 趋势发现 热点发现 文本分类\nbert documentation\nhttps://github.com/MaartenGr/BERTopic\n新词发现（可用于挖掘热点 热词 蓝海词） https://github.com/zhanzecheng/Chinese_segment_augment https://github.com/bojone/word-discovery https://github.com/blmoistawinde/HarvestText\n文本分类 文本匹配 文本检索 https://github.com/lining0806/Naive-Bayes-Classifier https://github.com/649453932/Bert-Chinese-Text-Classification-Pytorch https://github.com/gaussic/text-classification-cnn-rnn https://github.com/yongzhuo/Keras-TextClassification https://github.com/youthpasses/bayes_classifier https://github.com/Roshanson/TextInfoExp https://github.com/aceimnorstuvwxz/toutiao-multilevel-text-classfication-dataset https://github.com/CementMaker/cnn_lstm_for_text_classify https://github.com/hellonlp/classifier_multi_label_textcnn https://github.com/cjymz886/text-cnn https://github.com/terrifyzhao/bert-utils https://github.com/649453932/Chinese-Text-Classification-Pytorch https://github.com/HappyShadowWalker/ChineseTextClassify https://github.com/XqFeng-Josie/TextCNN https://github.com/tensorlayer/text-antispam https://github.com/MachineLP/TextMatch"
  },
  {
    "objectID": "posts/82c81de7-f72b-4bcf-8c65-46a2fcab43e8/index.html",
    "href": "posts/82c81de7-f72b-4bcf-8c65-46a2fcab43e8/index.html",
    "title": "TypeMonkey 字说 OSS alternative",
    "section": "",
    "text": "TypeMonkey 字说 OSS alternative\njavascript version in web: https://nostarsnow.github.io/2019/01/20/typemonkey/ https://github.com/nostarsnow/typeMonkey.js"
  },
  {
    "objectID": "posts/94e87344-5037-4a42-81e5-0d65176842dc/index.html",
    "href": "posts/94e87344-5037-4a42-81e5-0d65176842dc/index.html",
    "title": "Netdisk managers, Userscript and info_data collection",
    "section": "",
    "text": "Userscript and info/data collection\nAlist a filelist manager for all common cloud storage providers\nfor site collection list you could just search for it.\nyou can search for netdisk managers.\naliyun netdisk manager: https://github.com/tickstep/aliyunpan\nfound a repo full of userscripts: https://github.com/XIU2/UserScript\nbaidunetdisk cli go: https://github.com/qjfoidnh/BaiduPCS-Go\nbittorrent trackers: https://github.com/XIU2/TrackersListCollection\nscript list: 护眼模式 简单有效的全网通用护眼模式、夜间模式、暗黑模式~ 安装 | 备用 知乎 美化 宽屏显示、暗黑模式、屏蔽首页活动、调整图片最大高度… 安装 | 备用 知乎 增强 移除登录弹窗、屏蔽首页视频、屏蔽用户、屏蔽关键词… 安装 | 备用 V2EX 增强 自动签到、链接转图片、自动无缝翻页、新标签页打开链… 安装 | 备用 Github 增强 高速下载 Git Clone/SSH、Release、Raw、Code(ZIP) … 安装 | 备用 Ping.Sx 增强 一键复制所有 IP、清理 IP 链接、快捷回到顶部 … 安装 | 备用 自动无缝翻页 * 无缝衔接下一页内容 (瀑布流) 支持各论坛/漫画/百度/谷歌等… 安装 | 备用 3DM论坛 美化 精简多余内容、样式优化 安装 | 备用 3DM论坛 增强 自动回复、自动无缝翻页、清理置顶帖子、自动滚至隐藏… 安装 | 备用 蓝奏云网盘 增强 * 右键显示菜单、直接下载文件、显示更多文件、自动密码… 安装 | 备用 新标签页打开链接 * 将网页中所有链接改为新标签页打开~ 安装 | 备用 DuckDuckGo 增强 屏蔽指定域名、修复图标加载、链接不携来源、快捷回到… 安装 | 备用 吾爱破解论坛 美化 精简多余内容、样式优化 安装 | 备用 吾爱破解论坛 增强 自动签到、自动无缝翻页、屏蔽导读悬赏贴 (最新发表页)… 安装 | 备用 全球主机交流论坛 增强 * 自动访问空间(22积分)、屏蔽用户、屏蔽关键词、自动翻… 安装 | 备用 Steam 创意工坊大图 修复 修复 Steam 创意工坊预览大图无法显示的问题 安装 | 备用 HTML5 视频音频默认音量 避免被 100% 音量吓一跳！且支持各网站分别记住音量… 安装 | 备用 Google 翻译 美化 精简多余内容、修复翻译结果溢出屏幕问题 安装 | 备用 智友邦论坛 美化 精简多余内容、样式优化、宽屏显示 安装 | 备用 智友邦论坛 增强 自动签到、自动回复、自动无缝翻页、快捷回到顶部、附… 安装 | 备用\nautopager: https://greasyfork.org/en/scripts/419215-%E8%87%AA%E5%8A%A8%E6%97%A0%E7%BC%9D%E7%BF%BB%E9%A1%B5\nautopager supported websites: &lt; - - - - - - - - 网站 - - - - - - - - &gt; 主页 分类 文章 评论 搜索 &lt; - - - - - - - - - - - - - - - - - - - - - - - - - 备注 - - - - - - - - - - - - - - - - - - - - - - - - - &gt; 所有 Discuz! 论坛 ✔ ✔ ✔ - ✔ 国内常见 论坛系统 (如：吾爱破解、3DM 等) 所有 phpBB 论坛 ✔ ✔ ✔ - ✔ 国外常见 论坛系统 所有 XenForo 论坛 ✔ ✔ ✔ - ✔ 国外常见 论坛系统 所有 NexusPHP 论坛 ✔ ✔ ✔ - ✔ 国内常见 论坛系统 (BT / PT 论坛) 所有 Flarum 论坛 ✔ ✔ ✔ - ✔ 简洁开源 论坛系统 所有 Xiuno 论坛 ✔ ✔ ✔ - ✔ 国内开源 论坛系统 所有 笔趣阁 网站 - - ✔ - - 小说网站常用的 笔趣阁 模板 部分 Typecho 网站 ✔ ✔ - - ✔ 适配一些常见的 Typecho 网站主题 部分 WordPress 网站 ✔ ✔ - - ✔ 适配一些常见的 WordPress 网站主题 部分 在线影视模板 网站 ✔ ✔ - - ✔ 适配一些常见的 在线影视 网站模板 部分 自带无缝翻页 网站 ✔ ✔ - - ✔ 适配一些支持 [加载更多] 的网站 (为了避免误触，规则比较保守) &gt; [搜索引擎] &lt; 谷歌 (Google) - - - - ✔ (建议开启各搜索引擎设置中的 新标签页打开链接 选项，以提高使用体验) 必应 (Bing) - - - - ✔ (微软的) 百度 - - - - ✔\n搜狗 - - - - ✔\n搜狗微信 ✔ ✔ - - ✔ (微信文章/公众号搜索) 头条搜索 - - - - ✔\n神马搜索 - - - - ✔\n无追搜索 - - - - ✔\n360 搜索 - - - - ✔\nSearxng - - - - ✔ (对各大搜索引擎的聚合搜索) DuckDuckGo - - - - ✔ (以上这几个均支持手机版) Startpage - - - - ✔\nYandex - - - - ✔ (俄罗斯的，如果卡住说明弹验证码了，请刷新网页后继续…) Yahoo - - - - ✔ (包含 Yahoo JP 域名) Qwant - - - - ✔\nEcosia - - - - ✔\nGoobe - - - - ✔ (代码相关) Magi - - - - ✔\n轻搜 - - - - ✔\nASK - - - - ✔\n&gt; [社区] &lt; 贴吧 - ✔ ✔ - ✔ (如要发帖请点击右侧悬浮 [发帖] 按钮 或 点击左下角页码暂停翻页) 豆瓣 - ✔ ✔ ✔ - (短评、影评、评论、小组帖子 等等…) 知乎 - ✔ - - - (用户主页下的回答、文章 与 收藏夹页) 微博 - - - ✔ -\n天涯 - ✔ ✔ - -\n虎扑 - ✔ ✔ - -\nNGA - ✔ ✔ - - (玩家相关) V2EX ✔ ✔ - - -\n煎蛋网 ✔ ✔ - ✔ -\n水木社区 - ✔ ✔ - - (清华论坛) 龙的天空 - ✔ ✔ - - (小说相关) 看雪论坛 - ✔ - - - (安全相关) 番组计划 (Bangumi) - ✔ - - - (二次元版豆瓣？) 懂车帝论坛 - ✔ - - -\n宽带山论坛 ✔ ✔ ✔ - - (上海地方论坛) 篱笆网论坛 ✔ ✔ ✔ - ✔ (上海地方论坛) 淘股吧论坛 ✔ ✔ ✔ - -\n芥子空间论坛 - ✔ - - - (手游相关) LowEndTalk ✔ ✔ ✔ - - (海外服务器相关) RuTracker - ✔ ✔ - - (俄罗斯学习资源论坛) A 岛 - ✔ ✔ - -\nB 站 (Bilibili) - - - - ✔\n&gt; [设计/素材] &lt; Pixiv - ✔ - - ✔ (插画) Vilipix - ✔ - - ✔ (内容来自 Pixiv，下同 ⤵) Pixivision - ✔ - - ✔\n站酷 (ZCOOL) ✔ - - - - (图片/设计素材，下同 ⤵) 千图网 - ✔ - - ✔\n千库网 - ✔ - - ✔\n昵图网 - ✔ - - ✔\n众图网 - ✔ - - ✔\n我图网 - ✔ - - ✔\n包图网 - ✔ - - ✔\n图怪兽 - ✔ - - ✔\nPixabay - ✔ - - ✔\n搜图神器 ✔ - - - ✔\n素材中国 - ✔ - - ✔\niconfont - - - - ✔ (图标，下同 ⤵) IconArchive - - - - ✔\nMixkit - ✔ - - ✔ (视频/音乐素材) 普象网 ✔ ✔ - - ✔ (产品设计，下同 ⤵) 学犀牛 ✔ ✔ ✔ - ✔\n欧模网 - ✔ - - ✔ (模型素材，下同 ⤵) 下得乐 - ✔ - - ✔\n&gt; [游戏] &lt; 3DM - ✔ ✔ - - (包括论坛，下同 ⤵) 游侠网 - ✔ ✔ - -\n游民星空 - - ✔ - -\n3DM MOD - ✔ - - ✔ (游戏 MOD，下同 ⤵) CurseForge - ✔ - - ✔\nNexusMods - ✔ - - ✔\nSteam 创意工坊 ✔ ✔ - - ✔ (创意工坊 MOD 文件下载1/下载2) Steam 活动评论 - - - ✔ - (商家动态/活动下的评论区) 小霸王其乐无穷 ✔ ✔ - - ✔\nSwitch520 ✔ ✔ - - ✔\nCS.RIN.RU - ✔ ✔ - ✔ (国外的游戏分享网站，下同 ⤵) Byrutor ✔ ✔ - - -\nCrackhub213 ✔ ✔ - - ✔\nFitGirl Repacks ✔ ✔ - - ✔\nMasquerade Repacks ✔ ✔ - - ✔\n&gt; [影视/在线] &lt; 茶杯狐 - - ✔ - ✔ (以下部分网站同时包含 BT/动漫) NO 视频 - ✔ - - ✔\n低端影视 ✔ ✔ - - ✔\n奈菲影视 - ✔ - - ✔\n在线之家 - ✔ - - ✔\n片吧影院 - ✔ - - ✔\n嗯哩嗯哩 - ✔ - - ✔\n91 美剧网 - ✔ - - ✔\n真不卡影院 - ✔ - - ✔\nZzzFun 动漫 - ✔ - - ✔ (仅动漫，下同 ⤵) 吐槽弹幕网 - ✔ - - ✔\n樱花动漫 - ✔ - - ✔\n怡萱动漫 - ✔ - - ✔\n妮可动漫 - ✔ - - ✔\n漫岛动漫 - ✔ - - ✔\nAGE 动漫 - ✔ - - ✔\n233 动漫 - ✔ - - ✔\nAnime1 ✔ - - - ✔\n&gt; [BT/下载] &lt; 音范丝 ✔ ✔ - - ✔\n片源网 - - - - ✔\n磁力狗 - - - - ✔\n雨花阁 - - - - ✔\nBT 之家 ✔ ✔ - - ✔ (匹配所有包含 btbtt 的域名) BD 影视 - ✔ - - ✔\n高清电台 ✔ ✔ - - ✔\n爱恋动漫 ✔ ✔ - - ✔ (动漫，下同 ⤵) 末日动漫 ✔ ✔ - - ✔ (包括 国际站) 动漫花园 ✔ ✔ - - ✔ (包括 镜像站) 简单动漫 ✔ ✔ - - ✔\n零度动漫 ✔ ✔ - - ✔\nACG.RIP ✔ ✔ - - ✔\n萌番组 ✔ ✔ - - ✔ (包括 Lite 版) MioBT ✔ ✔ - - ✔\nSkrBT ✔ ✔ - - ✔ (匹配所有包含 skrbt 的域名) Nyaa ✔ - - - ✔\nYTS - ✔ - - ✔ (这个 + 下面这两个算是我最常用的了~) 1337x ✔ ✔ - - ✔ (包括 镜像站) RARBG ✔ ✔ - - ✔ (包括 镜像站) Zooqle - ✔ - - ✔\nKickass - ✔ - - ✔\nWebHD ✔ - - - ✔ (与 SubHD 字幕网站配套) MINI4K - ✔ - - ✔ (与 A4k 字幕网站配套) Trackerslist.com - - - - - (分享我自制自用的 Tracker 列表，多少会提高点 BT 下载速度~ 12k+⭐) &gt; [字幕] &lt; A4k ✔ ✔ - - ✔\nSubHD - ✔ - - ✔\n伪射手网 - ✔ - - ✔\n点点字幕 - - - - ✔\n中文字幕网 - ✔ - - ✔\n字幕库 ✔ ✔ - - ✔\n&gt; [漫画] &lt; 漫本 - ✔ ✔ - -\n好漫 6 - ✔ ✔ - ✔\n6 漫画 - ✔ ✔ - -\n动漫狂 - ✔ ✔ - ✔ (部分早期章节，因网站问题而无法自动衔接下一章) 动漫啦 - ✔ ✔ - ✔\n漫漫聚 - - ✔ - -\n漫画猫 - ✔ ✔ - ✔\n漫画皮 - ✔ ✔ - -\n漫画人 - - ✔ - -\n漫画柜 - ✔ ✔ - ✔\n36漫画 - ✔ ✔ - ✔\n爱漫画 - ✔ ✔ - ✔\n漫画 DB - ✔ ✔ - ✔\nHiComic (嗨漫画) - - ✔ - -\n动漫之家 (主站) - ✔ ✔ - ✔ (这网站两个域名内容不一样 ⤵) 动漫之家 (日漫) - ✔ ✔ - ✔\n阿狸漫画 - ✔ ✔ - ✔\n快岸漫画 - ✔ ✔ - ✔\n动漫之家 - - ✔ - -\n动漫戏说 - ✔ ✔ - -\n优酷漫画 - ✔ ✔ - ✔\n拷贝漫画 - ✔ ✔ - -\n木马漫画 - ✔ ✔ - -\n漫画星球 - ✔ ✔ - -\n风之动漫 - - ✔ - -\n包子漫画 - - ✔ - -\n乐语漫画 - ✔ ✔ - ✔\n新新漫画 - ✔ ✔ - ✔\n188漫画网 - - ✔ - -\n古风漫画网 - ✔ ✔ - ✔\n砂之船动漫家 - ✔ ✔ - ✔\nMangabz 漫画 - ✔ ✔ - ✔\nXmanhua 漫画 - ✔ ✔ - ✔\nCOCOMANGA 漫画 - ✔ ✔ - ✔\n&gt; [小说] &lt; 起点中文 - ✔ ✔ - -\n七猫中文 - - ✔ - -\n知轩藏书 - ✔ - - - (仅下载) 宝书网 - ✔ - - - (仅下载) 御书网 - ✔ ✔ - -\nowLook - - ✔ - - (支持在线阅读的小说搜索引擎) 铅笔小说 - ✔ ✔ - -\n无错小说网 - ✔ ✔ - ✔\n读书族小说网 - - ✔ - -\n哔哩轻小说 - ✔ ✔ - - (包括 手机版，轻小说，下同 ⤵) 话本小说网 - - ✔ - -\n轻之文库 - ✔ ✔ - ✔\nArchive of OurOwn - ✔ ✔ - ✔\n精品书源 - - - - - (分享我自制自用的「阅读」APP 精品书源 1.6k+⭐) &gt; [软件分享] &lt; 蓝鲨 ✔ ✔ - - ✔\n不死鸟 ✔ ✔ - - ✔\n分享者 ✔ ✔ - - ✔\n扩展迷 - ✔ - - - (浏览器扩展) MacWK - ✔ - - ✔ (MAC 相关) 小众软件 ✔ ✔ - - ✔\n乐软博客 ✔ ✔ - - ✔\n果核剥壳 ✔ ✔ - - ✔\n六音软件 ✔ ✔ - - ✔\n反斗软件 ✔ ✔ - - ✔\n微当下载 ✔ ✔ - - ✔\n大眼仔旭 - ✔ - - ✔\n423Down ✔ ✔ - ✔ ✔\n发烧友绿软 ✔ ✔ - - ✔\n异次元软件 ✔ ✔ - ✔ ✔\n悪魔の小站 ✔ ✔ - - ✔\n老殁殁漂遥 ✔ ✔ - - ✔\n腾龙工作室 ✔ ✔ - - -\n异星软件空间 ✔ ✔ - - ✔\nNite07 的小窝 ✔ - - - -\nSordum ✔ ✔ - - ✔ (国外的软件分享网站，下同 ⤵) Winaero - ✔ - - -\nLRepacks ✔ ✔ - - -\nDlAndroid - ✔ - - ✔ (国外安卓 App 相关) Winhelponline ✔ ✔ - - -\nWindowsLatest ✔ ✔ - - -\nTheWindowsClub ✔ ✔ - - -\n&gt; [学术] &lt; Wiley Online Library - - - - ✔\nACS (Publications) - - - - ✔\nLibrary Genesis - - - - ✔ (匹配所有包含 libgen 的域名) ScienceDirect - - - - ✔\nZ-Library - - - - ✔ (包括 镜像站) PubMed - - - - ✔\nX-MOL - ✔ - - ✔\n维普网 - - - - ✔\n科研通 - ✔ ✔ - ✔\n酷科研 - - ✔ - -\n小木虫 - ✔ ✔ - ✔\n百度学术 - ✔ - - ✔\n必应学术 (Bing) - - - - ✔\n谷歌学术 (Google) - - - - ✔ 包括 镜像站1 / 2 国家自然科学基金 - - ✔ - -\n&gt; [编程/技术] &lt; StackOverflow - ✔ - - ✔ 技术问答 SegmentFault - ✔ - - ✔\nW3Cschool - ✔ - - - 编程教程 W3school - ✔ - - -\n菜鸟教程 - ✔ - - -\n博客园 ✔ ✔ - - ✔ 技术博客 51CTO ✔ ✔ - - ✔\nGitee - ✔ ✔ ✔ ✔ 开源分享 Github ✔ ✔ ✔ ✔ ✔ (建议搭配我另一个 Github 增强 - 高速下载 油猴脚本~) &gt; [资讯/科技] &lt; ScienceAlert ✔ ✔ - - -\n果壳网 ✔ ✔ - ✔ -\n蓝点网 - ✔ - - -\n可能吧 ✔ ✔ - - -\n超能网 ✔ ✔ - - -\nIT之家 - ✔ - - -\n36 氪 - ✔ - - -\n&gt; [其他] &lt; IMDb - ✔ - - ✔\n烂番茄 - ✔ - - ✔\n致美化 - ✔ - - - 系统美化 蓝奏云 - ✔ - - - 网盘 (后台及分享链接列表) 新片场 - ✔ - - - 视频短片 wikiHow - ✔ - - ✔ 指南 AfreecaTV ✔ ✔ - - - 直播 (大都是韩国人) GreasyFork ✔ ✔ - ✔ ✔ 本站 UserScript - - - - ✔ 油猴脚本的聚合搜索 (Tampermonkey 作者做的) UserStyles ✔ ✔ - ✔ ✔\nQuicker ✔ ✔ - ✔ ✔\nXposed - ✔ - - ✔\n书签地球 ✔ - - - ✔\n什么值得买 - ✔ - - ✔\n没得比导购 - ✔ - - ✔\n叽哩叽哩日报 - ✔ - - -\n彼岸图网 ✔ ✔ - - - 壁纸 (下同 ⤵) 必应壁纸 ✔ ✔ - - -\n动漫壁纸 - ✔ - - ✔\n动漫壁纸2 - ✔ - - ✔\nHDQwalls ✔ ✔ - - ✔\nNastol ✔ ✔ - - ✔\n以上仅为一小部分… 持续添加中，欢迎申请~\npotential useful websites: https://greasyfork.org/en/users/sign_in?return_to=%2Fen%2Fsc…%25E6%2597%25A0%25E7%25BC%259D%25E7%25BF%25BB%25E9%25A1%25B5 debugger eval code:1:60 https://greasyfork.org/scripts/419215-%E8%87%AA%E5%8A%A8%E6%…8%87%AA%E5%8A%A8%E6%97%A0%E7%BC%9D%E7%BF%BB%E9%A1%B5.user.js debugger eval code:1:60 https://greasyfork.org/en/help/installing-user-scripts debugger eval code:1:60 https://greasyfork.org/scripts/419081-%E7%9F%A5%E4%B9%8E%E5%…E%E5%BC%BA/code/%E7%9F%A5%E4%B9%8E%E5%A2%9E%E5%BC%BA.user.js debugger eval code:1:60 https://github.com/XIU2/UserScript debugger eval code:1:60 https://greasyfork.org/en/scripts/419215-%E8%87%AA%E5%8A%A8%E6%97%A0%E7%BC%9D%E7%BF%BB%E9%A1%B5/feedback#post-discussion debugger eval code:1:60 https://greasyfork.org/en/reports/new?item_class=script&item_id=419215 debugger eval code:1:60 https://www.jsdelivr.com/package/gh/XIU2/UserScript debugger eval code:1:60 https://www.discuz.net/ debugger eval code:1:60 https://www.phpbb.com/community/ debugger eval code:1:60 https://xenforo.com/community/ debugger eval code:1:60 https://demo.nexusphp.org/ debugger eval code:1:60 https://discuss.flarum.org/ debugger eval code:1:60 https://www.axiuno.com/ debugger eval code:1:60 https://www.google.com/ debugger eval code:1:60 https://cn.bing.com/ debugger eval code:1:60 https://www.baidu.com/ debugger eval code:1:60 https://www.sogou.com/ debugger eval code:1:60 https://weixin.sogou.com/ debugger eval code:1:60 https://www.toutiao.com/ debugger eval code:1:60 https://m.sm.cn/ debugger eval code:1:60 https://www.wuzhuiso.com/ debugger eval code:1:60 https://www.so.com/ debugger eval code:1:60 https://searx.owlook.com.cn/ debugger eval code:1:60 https://duckduckgo.com/ debugger eval code:1:60 https://www.startpage.com/ debugger eval code:1:60 https://yandex.com/ debugger eval code:1:60 https://search.yahoo.com/ debugger eval code:1:60 https://www.qwant.com/ debugger eval code:1:60 https://www.ecosia.org/ debugger eval code:1:60 https://goobe.io/ debugger eval code:1:60 https://magi.com/ debugger eval code:1:60 https://www.qingsearch.com/ debugger eval code:1:60 https://www.ask.com/ debugger eval code:1:60 https://tieba.baidu.com/ debugger eval code:1:60 https://movie.douban.com/ debugger eval code:1:60 https://www.zhihu.com/ debugger eval code:1:60 https://weibo.com/ debugger eval code:1:60 https://bbs.tianya.cn/ debugger eval code:1:60 https://bbs.hupu.com/ debugger eval code:1:60 https://bbs.nga.cn/ debugger eval code:1:60 https://v2ex.com/ debugger eval code:1:60 https://jandan.net/ debugger eval code:1:60 https://www.mysmth.net/ debugger eval code:1:60 https://www.lkong.com/ debugger eval code:1:60 https://bbs.pediy.com/ debugger eval code:1:60 https://bangumi.tv/ debugger eval code:1:60 https://www.dongchedi.com/car_fans_community debugger eval code:1:60 https://club.kdslife.com/ debugger eval code:1:60 https://www.libaclub.com/ debugger eval code:1:60 https://www.taoguba.com.cn/ debugger eval code:1:60 https://bbs.lieyou888.com/ debugger eval code:1:60 https://lowendtalk.com/ debugger eval code:1:60 https://rutracker.org/ debugger eval code:1:60 https://adnmb3.com/ debugger eval code:1:60 https://search.bilibili.com/ debugger eval code:1:60 https://www.pixiv.net/ debugger eval code:1:60 https://www.vilipix.com/ debugger eval code:1:60 https://www.pixivision.net/ debugger eval code:1:60 https://www.zcool.com.cn/ debugger eval code:1:60 https://www.58pic.com/ debugger eval code:1:60 https://588ku.com/ debugger eval code:1:60 https://www.nipic.com/ debugger eval code:1:60 https://www.ztupic.com/ debugger eval code:1:60 https://www.ooopic.com/ debugger eval code:1:60 https://ibaotu.com/ debugger eval code:1:60 https://818ps.com/ debugger eval code:1:60 https://pixabay.com/ debugger eval code:1:60 https://www.logosc.cn/so/ debugger eval code:1:60 http://www.sccnn.com/ debugger eval code:1:60 https://www.iconfont.cn/ debugger eval code:1:60 https://iconarchive.com/ debugger eval code:1:60 https://mixkit.co/ debugger eval code:1:60 https://www.puxiang.com/ debugger eval code:1:60 https://www.xuexiniu.com/ debugger eval code:1:60 https://www.om.cn/ debugger eval code:1:60 http://www.xiadele.com/ debugger eval code:1:60 https://www.3dmgame.com/ debugger eval code:1:60 https://www.ali213.net/ debugger eval code:1:60 https://www.gamersky.com/ debugger eval code:1:60 https://mod.3dmgame.com/ debugger eval code:1:60 https://www.curseforge.com/ debugger eval code:1:60 https://www.nexusmods.com/ debugger eval code:1:60 https://steamcommunity.com/workshop/browse/?appid=550&browsesort=trend&section=readytouseitems debugger eval code:1:60 https://steamworkshopdownloader.io/ debugger eval code:1:60 http://steamworkshop.download/ debugger eval code:1:60 https://steamcommunity.com/ debugger eval code:1:60 https://www.yikm.net/ debugger eval code:1:60 https://switch520.com/ debugger eval code:1:60 https://cs.rin.ru/forum/viewforum.php?f=10 debugger eval code:1:60 https://byrut.org/ debugger eval code:1:60 https://crackhub.site/ debugger eval code:1:60 https://fitgirl-repacks.site/ debugger eval code:1:60 https://masquerade.site/ debugger eval code:1:60 https://www.cupfox.app/ debugger eval code:1:60 https://www.novipnoad.com/ debugger eval code:1:60 https://ddrk.me/ debugger eval code:1:60 https://www.nfmovies.com/ debugger eval code:1:60 https://www.zxzjtv.com/ debugger eval code:1:60 https://www.pianba.tv/ debugger eval code:1:60 https://enlienli.com/ debugger eval code:1:60 https://mjw21.com/ debugger eval code:1:60 https://www.zhenbuka3.com/ debugger eval code:1:60 http://www.zzzfun.com/ debugger eval code:1:60 https://www.tucao.one/ debugger eval code:1:60 http://www.imomoe.live/ debugger eval code:1:60 http://www.yxdm.li/ debugger eval code:1:60 http://www.nicotv.me/ debugger eval code:1:60 https://www.mandao.tv/ debugger eval code:1:60 https://www.agemys.com/ debugger eval code:1:60 https://www.dm233.cc/ debugger eval code:1:60 https://anime1.me/ debugger eval code:1:60 https://www.yinfans.me/ debugger eval code:1:60 https://pianyuan.org/ debugger eval code:1:60 http://clg.im/ debugger eval code:1:60 https://www.yuhuage52.xyz/ debugger eval code:1:60 https://btbtt20.com/ debugger eval code:1:60 https://www.bd2020.com/ debugger eval code:1:60 https://gaoqing.fm/ debugger eval code:1:60 https://www.kisssub.org/ debugger eval code:1:60 https://share.acgnx.net/ debugger eval code:1:60 https://www.acgnx.se/ debugger eval code:1:60 https://share.dmhy.org/ debugger eval code:1:60 https://dmhy.anoneko.com/ debugger eval code:1:60 https://www.36dm.club/ debugger eval code:1:60 https://bt.acgzero.com/ debugger eval code:1:60 https://acg.rip/ debugger eval code:1:60 https://bangumi.moe/ debugger eval code:1:60 https://banguami.moe/lite debugger eval code:1:60 https://miobt.com/ debugger eval code:1:60 https://skrbtga.xyz/ debugger eval code:1:60 https://nyaa.si/ debugger eval code:1:60 https://yts.mx/ debugger eval code:1:60 https://1337x.to/ debugger eval code:1:60 https://rarbg.to/ debugger eval code:1:60 https://zooqle.com/ debugger eval code:1:60 https://kickasss.to/ debugger eval code:1:60 https://webhd.cc/ debugger eval code:1:60 https://www.mini4k.com/ debugger eval code:1:60 https://trackerslist.com/ debugger eval code:1:60 https://www.a4k.net/ debugger eval code:1:60 https://subhd.tv/ debugger eval code:1:60 https://assrt.net/ debugger eval code:1:60 http://www.ddzimu.com/ debugger eval code:1:60 https://cn.zimuzimu.com/ debugger eval code:1:60 https://zimuku.org/ debugger eval code:1:60 https://www.manben.com/ debugger eval code:1:60 https://www.haoman6.com/ debugger eval code:1:60 http://www.sixmh7.com/ debugger eval code:1:60 https://www.cartoonmad.com/ debugger eval code:1:60 https://www.dongman.la/ debugger eval code:1:60 http://www.manmanju.com/ debugger eval code:1:60 https://www.maofly.com/ debugger eval code:1:60 https://www.manhuapi.com/ debugger eval code:1:60 https://www.manhuaren.com/ debugger eval code:1:60 https://www.mhgui.com/ debugger eval code:1:60 https://www.36manga.com/ debugger eval code:1:60 https://www.imanhuaw.net/ debugger eval code:1:60 https://www.manhuadb.com/ debugger eval code:1:60 https://www.hicomic.net/ debugger eval code:1:60 https://www.dmzj.com/ debugger eval code:1:60 https://manhua.dmzj.com/ debugger eval code:1:60 http://www.alimanhua.com/ debugger eval code:1:60 https://www.kanbook.net/ debugger eval code:1:60 https://manhua.dmzj.com/ debugger eval code:1:60 https://comic.acgn.cc/ debugger eval code:1:60 https://www.ykmh.com/ debugger eval code:1:60 https://copymanga.net/ debugger eval code:1:60 https://www.omyschool.com/ debugger eval code:1:60 http://www.mhxqiu1.com/ debugger eval code:1:60 http://manhua.fffdm.com/ debugger eval code:1:60 https://www.webmota.com/ debugger eval code:1:60 https://www.leyuman.com/ debugger eval code:1:60 https://www.77mh.xyz/ debugger eval code:1:60 http://www.ccshwy.com/all/ debugger eval code:1:60 https://www.gufengmh9.com/ debugger eval code:1:60 https://www.szcdmj.com/ debugger eval code:1:60 https://mangabz.com/ debugger eval code:1:60 https://www.xmanhua.com/ debugger eval code:1:60 https://www.cocomanga.com/ debugger eval code:1:60 https://www.qidian.com/ debugger eval code:1:60 https://www.qimao.com/ debugger eval code:1:60 http://zxcs.me/ debugger eval code:1:60 https://www.baoshuu.com/ debugger eval code:1:60 https://www.yushubo.com/ debugger eval code:1:60 https://www.owlook.com.cn/ debugger eval code:1:60 https://www.23qb.com/ debugger eval code:1:60 https://www.xineyby.com/ debugger eval code:1:60 https://m.xiaoshuo77.net/ debugger eval code:1:60 https://www.linovelib.com/ debugger eval code:1:60 https://w.linovelib.com/ debugger eval code:1:60 https://www.ihuaben.com/ debugger eval code:1:60 https://www.linovel.net/ debugger eval code:1:60 https://archiveofourown.org/ debugger eval code:1:60 https://yuedu.xiu2.xyz/ debugger eval code:1:60 https://www.lan-sha.com/ debugger eval code:1:60 https://iao.su/ debugger eval code:1:60 https://www.sharerw.com/ debugger eval code:1:60 https://www.extfans.com/ debugger eval code:1:60 https://www.macwk.com/ debugger eval code:1:60 https://www.appinn.com/ debugger eval code:1:60 https://www.isharepc.com/ debugger eval code:1:60 https://www.ghxi.com/ debugger eval code:1:60 https://www.6yit.com/ debugger eval code:1:60 http://www.apprcn.com/ debugger eval code:1:60 https://www.weidown.com/ debugger eval code:1:60 https://www.dayanzai.me/ debugger eval code:1:60 https://www.423down.com/ debugger eval code:1:60 https://fsylr.com/ debugger eval code:1:60 https://www.iplaysoft.com/ debugger eval code:1:60 http://www.mubolin.cn:99/ debugger eval code:1:60 https://www.mpyit.com/ debugger eval code:1:60 https://www.tenlonstudio.com/ debugger eval code:1:60 https://www.yxssp.com/ debugger eval code:1:60 https://www.nite07.com/ debugger eval code:1:60 https://www.sordum.org/ debugger eval code:1:60 https://winaero.com/ debugger eval code:1:60 https://lrepacks.net/ debugger eval code:1:60 https://dlandroid.com/ debugger eval code:1:60 https://www.winhelponline.com/blog/ debugger eval code:1:60 https://www.windowslatest.com/ debugger eval code:1:60 https://www.thewindowsclub.com/ debugger eval code:1:60 https://onlinelibrary.wiley.com/ debugger eval code:1:60 https://pubs.acs.org/ debugger eval code:1:60 https://libgen.rs/ debugger eval code:1:60 https://www.sciencedirect.com/ debugger eval code:1:60 https://z-lib.org/ debugger eval code:1:60 https://pubmed.ncbi.nlm.nih.gov/ debugger eval code:1:60 https://www.x-mol.com/ debugger eval code:1:60 http://www.cqvip.com/ debugger eval code:1:60 https://www.ablesci.com/ debugger eval code:1:60 https://www.coolkeyan.com/ debugger eval code:1:60 http://muchong.com/bbs debugger eval code:1:60 https://xueshu.baidu.com/ debugger eval code:1:60 https://cn.bing.com/academic debugger eval code:1:60 https://scholar.google.com/ debugger eval code:1:60 https://sc.panda321.com/ debugger eval code:1:60 https://xs2.dailyheadlines.cc/ debugger eval code:1:60 https://output.nsfc.gov.cn/ debugger eval code:1:60 https://stackoverflow.com/ debugger eval code:1:60 https://segmentfault.com/ debugger eval code:1:60 https://www.w3cschool.cn/ debugger eval code:1:60 https://www.w3school.com.cn/ debugger eval code:1:60 https://www.runoob.com/ debugger eval code:1:60 https://www.cnblogs.com/ debugger eval code:1:60 https://www.51cto.com/ debugger eval code:1:60 https://gitee.com/ debugger eval code:1:60 https://www.sciencealert.com/ debugger eval code:1:60 https://www.guokr.com/ debugger eval code:1:60 https://www.landian.vip/ debugger eval code:1:60 https://kenengba.com/ debugger eval code:1:60 https://www.expreview.com/ debugger eval code:1:60 https://www.ithome.com/ debugger eval code:1:60 https://36kr.com/ debugger eval code:1:60 https://www.imdb.com/ debugger eval code:1:60 https://www.rottentomatoes.com/ debugger eval code:1:60 https://zhutix.com/ debugger eval code:1:60 https://lanzou.com/ debugger eval code:1:60 https://www.xinpianchang.com/ debugger eval code:1:60 https://zh.wikihow.com/ debugger eval code:1:60 https://www.afreecatv.com/ debugger eval code:1:60 https://www.userscript.zone/ debugger eval code:1:60 https://userstyles.world/ debugger eval code:1:60 https://getquicker.net/ debugger eval code:1:60 https://repo.xposed.info/module-overview debugger eval code:1:60 https://www.bookmarkearth.com/ debugger eval code:1:60 https://www.smzdm.com/ debugger eval code:1:60 https://www.meidebi.com/ debugger eval code:1:60 https://www.jiligamefun.com/ debugger eval code:1:60 https://pic.netbian.com/ debugger eval code:1:60 https://bing.ioliu.cn/ debugger eval code:1:60 https://konachan.net/ debugger eval code:1:60 https://anime-pictures.net/ debugger eval code:1:60 https://hdqwalls.com/ debugger eval code:1:60 https://www.nastol.com.ua/ debugger eval code:1:60 https://www.snapmail.cc/ debugger eval code:1:60 https://pan.lanzouo.com/b073l8d1e debugger eval code:1:60 https://microsoftedge.microsoft.com/addons/detail/tampermonkey/iikmkjmpaadaobahmlepeloendndfphd?hl=zh-CN debugger eval code:1:60 https://zhuanlan.zhihu.com/p/276027099"
  },
  {
    "objectID": "posts/40e99740-672b-49fa-8f6b-8c37a62ee7b8/index.html",
    "href": "posts/40e99740-672b-49fa-8f6b-8c37a62ee7b8/index.html",
    "title": "Video Cutting with captioners, video classifiers, audio classifier, audio categorizer",
    "section": "",
    "text": "Video Cutting with captioners, video classifiers, audio classifier, audio categorizer\nyou can cut based on video highlights, usually generated by counting “replay overlaps”, avaliable from youtube and bilibili, again needs supervised learning to recognize patterns and emit signals which we want\nCOCA using vit and palm for video captioning\naudio classifier tutorial\naudio tagger visualize how audio classifier works\nneed to identify sounds like dog bark and gun shots, sobs, laughs. Open sourced.\nMay use sound analyzers.\naudio2midi:\nhttps://gist.github.com/natowi/d26c7e97443ec97e8032fb7e7596f0b0\nRecurrent Neural Network for generating piano MIDI-files from audio (MP3, WAV, etc.) https://github.com/BShakhovsky/PolyphonicPianoTranscription\nA python program which performs an FFT on an audio file and produces a MIDI file from the results https://github.com/NFJones/audio-to-midi\nExtract the melody from an audio file and export to MIDI https://github.com/justinsalamon/audio_to_midi_melodia\nPerforms pitch detection on a polyphonic audio source and outputs to MIDI https://github.com/corbanbrook/spectrotune\nProgram to detect pitch from wav files and write in time quantized MIDI https://github.com/vaibhavnayel/Audio-to-MIDI-converter\nA CNN which converts piano audio to a simplified MIDI format https://github.com/hartmetzls/audio_to_midi\nAn application of vocal melody extraction. https://github.com/bill317996/Audio-to-midi\nTranscribes polyphonic piano pieces from audio (MP3, WAV, etc.) into MIDI-files https://github.com/BShakhovsky/PianoAudioToMidi\nPolyphonic pitch tracking in real time using machine learning algorithms https://github.com/jaym910/polyphonic_track\nAudio to MIDI converter https://github.com/sbaeunker/audioToMidiConverter\nExplore Transcribing Techniques to auto convert audio to midi https://github.com/Goldspear/audio2midi\nPitchToMIDI https://github.com/KatoIppei/PitchToMIDI See releases\nPiano & Drums https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription\nTony: a tool for melody transcription https://www.sonicvisualiser.org/tony/ https://github.com/sonic-visualiser/tony https://code.soundsoftware.ac.uk/projects/tony (https://github.com/mikulas-mrva/tony2max)\nMusicTranscription https://github.com/ClaraBing/CS229-MusicTranscription\npYIN https://code.soundsoftware.ac.uk/projects/pyin https://github.com/ronggong/pypYIN (python)\nOnsets and Frames Transcription (Piano & Drums) https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription https://piano-scribe.glitch.me/\nWaoN https://sourceforge.net/projects/waon/\naudio2midi conversion works great with prior source separation https://github.com/deezer/spleeter or others like https://github.com/rgcda/Musisep"
  },
  {
    "objectID": "posts/223232e0-96af-486c-8304-e4e44371e7e8/index.html",
    "href": "posts/223232e0-96af-486c-8304-e4e44371e7e8/index.html",
    "title": "Video Editors",
    "section": "",
    "text": "Video Editors\nmoviepy ffmpeg wrapper in js\nvideo transitions: opengl transitions ffmpeg filters for gl transitions, as ffmpeg commandline args\njavascript video editor: remotion edit video with react creating and rendering dynamic videos video slideshow creator editly’s gui editly the slick video editor\nnpm i -g editly\nconcat videos with opengl transitions complex react native animation engine, not open source\n vidpy based on mltframework, shotcut\nauto video editor by audio loudness: https://github.com/WyattBlue/auto-editor\nposition video by face: https://github.com/diego3g/video-to-reels\nmachine video editor using deepfake, with gui, not open sourced: https://github.com/MachineEditor/MachineVideoEditor\nopenshot python: https://github.com/OpenShot/openshot-qt\nyoutube video summarizer: https://github.com/codelucas/shorten.tv\ncommandline video editor from suckless: https://github.com/maandree/blind\nremove slience from video: https://github.com/gusals3587/jumpcutterV2 https://github.com/carykh/jumpcutter https://github.com/jappeace/cut-the-crap\nai video editor: https://github.com/MashiMaroLjc/rabbitVE\ncommandline video editor: https://github.com/wkentaro/video-cli"
  },
  {
    "objectID": "posts/f737d025-f1ba-4d92-bd65-19aca850c42e/index.html",
    "href": "posts/f737d025-f1ba-4d92-bd65-19aca850c42e/index.html",
    "title": "Video Search Engines",
    "section": "",
    "text": "Video Search Engines\nYandex好像可以根据视频截图搜索原视频来源\nyoutube search python\nsearch youtube using urllib\nAI VIDEO SEARCH ENGINE (self hosted): Jina\nsearch video by subtitle or generated subtitle: https://github.com/antiboredom/videogrep\nFrom search Engine journal: https://www.searchenginejournal.com/best-video-search-engines/360822/\nGoogle Youtube Bing DailyMotion\nDuckduckGo Yahoo\nMetacafe find fun unusual videos\nAsk Yandex Swisscows\nhttps://kinsta.com/blog/video-search-engine/\nFacebook Dogpile\nVeoh video share platform, search by language of subtitles\nberify reverse video search by screenshot inside the video\nvimeo\nsocial searcher search multiple social media platform at once\necosia\nshutterstock need purchase? Royalty-free?\nchinese local video platforms: baidu sogou 360 tencent zhihu …"
  },
  {
    "objectID": "posts/6683c48d-96b7-4110-bf70-0b16e4669181/index.html",
    "href": "posts/6683c48d-96b7-4110-bf70-0b16e4669181/index.html",
    "title": "Vim Custom color scheme",
    "section": "",
    "text": "Vim Custom color scheme\n[documentation[(http://vimdoc.sourceforge.net/htmldoc/syntax.html#:highlight)\nvim terminal color codes\nkeyword for vertical spliters: VertSplit\nkeyword for bottom line:"
  },
  {
    "objectID": "posts/2e8b8982-40d2-4c47-b42b-1688494fdaa6/index.html",
    "href": "posts/2e8b8982-40d2-4c47-b42b-1688494fdaa6/index.html",
    "title": "Watch Anime Online",
    "section": "",
    "text": "Watch Anime Online\nDownloadable cracked by me anime1.me: https://anime1.me\nanilist has external links to bangume: https://anilist.co/anime/140960/SPYFAMILY/"
  },
  {
    "objectID": "posts/bae2836c-219d-452f-9fa1-78d215024d6b/index.html",
    "href": "posts/bae2836c-219d-452f-9fa1-78d215024d6b/index.html",
    "title": "Webproxy, clash, proxy.py",
    "section": "",
    "text": "Webproxy, clash, proxy.py\nsomebody hates clash and proxy.py, now we proxy websites directly in another website:\n\nUltraviolet by Titanium Network\nvisit Holy Unblocker for demonstration\nholyub-alike websites\n\ngithub topic: webproxy"
  },
  {
    "objectID": "posts/36923046-d114-4e88-8b53-99b5cd238385/index.html",
    "href": "posts/36923046-d114-4e88-8b53-99b5cd238385/index.html",
    "title": "Windows 10 system debloating, windows operating system optimization, winget, windows commandline package manager",
    "section": "",
    "text": "Windows 10 system debloating, windows operating system optimization, winget, windows commandline package manager\nwinget usage and recommended windows tools\nwinget is slow due to missing mirror site in china. consider using proxy.\n\nto activate windows 10, use KMS tool.\n\nWindows10Debloater: Script to remove Windows 10 bloatware.\nDebloat-Windows-10 (not for win11?)\noptimizer able to:\nFull multilingual support (20 languages available)\nSpeed up your system and network performance\nDisable unnecessary Windows services\nDisable Windows telemetry, Cortana and many more\nDisable Office telemetry (works only with Office 2016)\nDisable Windows 10 automatic updates\nDownload useful apps quickly at once\nUninstall UWP apps\nClean your system drive and major browsers' profile data\nFix common registry issues\nPing IPs and assess your latency\nSearch IPs on SHODAN.io\nRapidly change DNS server (from a pre-made list)\nFlush DNS cache\nRemove unwanted programs running at startup\nEdit your HOSTS file\nFind file lock handles and kill associated processes\nHardware inspection tool\nAdd items in desktop on right-click menu\nDefine custom commands for run dialog\nSilent run support using a configuration file\n\nSophiApp: The most powerful open source tweaker on GitHub for fine-tuning Windows 10 & Windows 11"
  },
  {
    "objectID": "posts/3aea24fb-8bf6-45be-974e-c4477d480df9/index.html",
    "href": "posts/3aea24fb-8bf6-45be-974e-c4477d480df9/index.html",
    "title": "Worth Trying Remote Computer Connection",
    "section": "",
    "text": "Worth Trying Remote Computer Connection\nNoMachine NX FreeNX Moonlight for NVIDIA Windows parsec for windows/macos host ssh-rdp for linux host/client\nsomehow usable on localhost:\nx11vnc -localhost -display :0 -threads -forever vncviewer -PreferredEncoding=ZRLE localhoat:0\nsunshine host for windows/linux https://github.com/SunshineStream/Sunshine/blob/master/README.md#macos https://github.com/loki-47-6F-64/sunshine openstream-server a fork of sunshine https://open-stream.net/\nsynergy mouse keyboard sharing tool ssh -X/-Y allowX11forwarding\nhardware solution: kvm switch (high grade with audio redirection separate usb ports)"
  },
  {
    "objectID": "posts/1eb6929a-5276-4bb5-b57d-62c4a2500b98/index.html",
    "href": "posts/1eb6929a-5276-4bb5-b57d-62c4a2500b98/index.html",
    "title": "Youtube Monitization 油管变现",
    "section": "",
    "text": "Youtube Monitization 油管变现\n8种方式变现 https://www.xiaohongshu.com/web-login/canvas?redirectPath=http%3A%2F%2Fwww.xiaohongshu.com%2Fdiscovery%2Fitem%2F61fdc910000000000102be7b"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#text-annotation-tool",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#text-annotation-tool",
    "title": "AI训练集标注工具",
    "section": "text annotation tool:",
    "text": "text annotation tool:\nhttps://github.com/doccano/doccano\nsqlite 3 backend:\npip3 install doccano"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#videoimage-annotation-tool-needs-docker-with-online-demo",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#videoimage-annotation-tool-needs-docker-with-online-demo",
    "title": "AI训练集标注工具",
    "section": "video/image annotation tool, needs docker, with online demo:",
    "text": "video/image annotation tool, needs docker, with online demo:\nhttps://github.com/openvinotoolkit/cvat"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#image-labeling",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#image-labeling",
    "title": "AI训练集标注工具",
    "section": "image labeling:",
    "text": "image labeling:\nhttps://github.com/heartexlabs/labelImg"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#with-audio-video-support",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#with-audio-video-support",
    "title": "AI训练集标注工具",
    "section": "with audio video support",
    "text": "with audio video support\nhttps://github.com/heartexlabs/label-studio"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#with-audio-transcription-support",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#with-audio-transcription-support",
    "title": "AI训练集标注工具",
    "section": "with audio transcription support",
    "text": "with audio transcription support\nhttps://github.com/UniversalDataTool/universal-data-tool"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#image-and-audio",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#image-and-audio",
    "title": "AI训练集标注工具",
    "section": "image and audio",
    "text": "image and audio\nhttps://github.com/Cartucho/OpenLabeling"
  },
  {
    "objectID": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#specialized-for-yolo-bounding-boxes",
    "href": "posts/ca39d4cf-0663-4ec9-8e47-0b5e81d242b9/index.html#specialized-for-yolo-bounding-boxes",
    "title": "AI训练集标注工具",
    "section": "specialized for yolo bounding boxes",
    "text": "specialized for yolo bounding boxes\nhttps://github.com/developer0hye/Yolo_Label"
  },
  {
    "objectID": "posts/bda11d7c-b793-4806-adbf-d6276f109441/index.html",
    "href": "posts/bda11d7c-b793-4806-adbf-d6276f109441/index.html",
    "title": "Choosing the Perfect AR/VR Glasses: Clear, Comfortable, and Well-Ventilated",
    "section": "",
    "text": "AR VR 眼镜 选取方法 固定方法\n看得清字 边缘清晰 不模糊\n轻便 不重\n可以和帽子固定在一块 帽子再加上个固定在下巴的绑带 注意散热"
  },
  {
    "objectID": "posts/c47f7e2d-fa6b-4dbc-be58-bf39a10ed19e/index.html#setup-tty",
    "href": "posts/c47f7e2d-fa6b-4dbc-be58-bf39a10ed19e/index.html#setup-tty",
    "title": "access kali on chromebook or anywhere",
    "section": "setup tty",
    "text": "setup tty\ni don’t think this will work on android, but let’s see?\nttyd -p &lt;port&gt; -c &lt;username&gt;:&lt;password&gt; &lt;shell_path&gt;\n# don't specify interface since that will screw things up"
  },
  {
    "objectID": "posts/c47f7e2d-fa6b-4dbc-be58-bf39a10ed19e/index.html#setup-x11vnc-and-novnc",
    "href": "posts/c47f7e2d-fa6b-4dbc-be58-bf39a10ed19e/index.html#setup-x11vnc-and-novnc",
    "title": "access kali on chromebook or anywhere",
    "section": "setup x11vnc and novnc",
    "text": "setup x11vnc and novnc\nnotice novnc has clipboard function now. share clipboard content across devices via the sidebar menu,\nin reference of kali official\nx11vnc is mirroring the current x11 session. i set it without password.\n#retrieved from fish history\nx11vnc -threads -forever\nthen launch novnc server\nnovnc  --vnc localhost:5900 --listen 10020\nuse this url to access from chromebook:\nhttp://&lt;kali_ip&gt;:10020/vnc.html?host=&lt;kali_ip&gt;&port=10020"
  },
  {
    "objectID": "posts/45ca26ce-c8ed-480d-a818-9412a41d994a/index.html",
    "href": "posts/45ca26ce-c8ed-480d-a818-9412a41d994a/index.html",
    "title": "adb wifi always on",
    "section": "",
    "text": "adb over wifi always on\nwarning: could be dangerous cause adb remote connections seem without any password. consider protect that with some proxy.\nturning on:\nsetprop service.adb.tcp.port 5555\nstop adbd\nstart adbd\nturning off:\nsetprop service.adb.tcp.port -1\nstop adbd\nstart adbd\nset things under /data/adb/services.d/ and make them executable\nmount -o remount,rw /\n# then you can modify /sytem/etc/init.d, but not /system/bin cause it is a copy of /data/system/bin. you should create script there.\ncreate this under /system/etc/init.d/\nservice adb_wifi_enable /system/bin/adb_wifi_enable.sh\n    disabled\n    oneshot\n    seclabel u:r:magisk:s0\n\non property:sys.boot_completed=1\n    start adb_wifi_enable"
  },
  {
    "objectID": "posts/50f4a63a-df01-4afd-a13d-b7bd18a1c0f5/index.html#linux",
    "href": "posts/50f4a63a-df01-4afd-a13d-b7bd18a1c0f5/index.html#linux",
    "title": "aldente windows & linux alternative",
    "section": "Linux",
    "text": "Linux\nkernel 5.5 or newer:\necho 60 | sudo tee /sys/class/power_supply/BAT0/charge_control_end_threshold\nwith platform-specific drivers, look for: /sys/devices/platform/.*/.*(battery|charge|thresh|limit).*\nFor ThinkPads and selected other laptops tlp/tlpui (acts like powertop which turns off usb devices, so be careful when running long-term programs) provides a unified way to configure charge thresholds and recalibrate the battery."
  },
  {
    "objectID": "posts/50f4a63a-df01-4afd-a13d-b7bd18a1c0f5/index.html#windows",
    "href": "posts/50f4a63a-df01-4afd-a13d-b7bd18a1c0f5/index.html#windows",
    "title": "aldente windows & linux alternative",
    "section": "Windows",
    "text": "Windows"
  },
  {
    "objectID": "posts/6b7f5a44-3e30-41d1-baab-4c0e28a9f55e/index.html#disable-ssl-pinning",
    "href": "posts/6b7f5a44-3e30-41d1-baab-4c0e28a9f55e/index.html#disable-ssl-pinning",
    "title": "android packet capture",
    "section": "disable ssl pinning",
    "text": "disable ssl pinning\nuse frida scripts specific to applications\njusttrustme xposed\nsslunpinning xposed\napk-mitm by repacking apk and resigning"
  },
  {
    "objectID": "posts/6b7f5a44-3e30-41d1-baab-4c0e28a9f55e/index.html#capture-packet-routing",
    "href": "posts/6b7f5a44-3e30-41d1-baab-4c0e28a9f55e/index.html#capture-packet-routing",
    "title": "android packet capture",
    "section": "capture, packet routing",
    "text": "capture, packet routing\nrecommend to use: PCAPdroid-API\nPCAPdroid API reference\nadb shell am start -e action start -e pcap_dump_mode udp_exporter -e collector_ip_address 127.0.0.1 -e collector_port 5123 -e app_filter com.tencent.mobileqq -n com.emanuelef.remote_capture.debug/com.emanuelef.remote_capture.activities.CaptureCtrl\nsetting up http proxy via adb:\n# this does not ensure that the target app is captured.\nadb shell settings put global http_proxy &lt;address&gt;:&lt;port&gt;"
  },
  {
    "objectID": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html",
    "href": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "",
    "text": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection"
  },
  {
    "objectID": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html#controllable-video-summarization",
    "href": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html#controllable-video-summarization",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "controllable video summarization",
    "text": "controllable video summarization\nquery controllable video summarization and paper\nDeepQAMVS: Query-Aware Hierarchical Pointer Networks for Multi-Video Summarization\nCLIP-It! Language-Guided Video Summarization\nConvolutional Hierarchical Attention Network for Query-Focused Video Summarization"
  },
  {
    "objectID": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html#fuzzy-search",
    "href": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html#fuzzy-search",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "fuzzy search",
    "text": "fuzzy search\nfuzzywuzzy tutorial\nthefuzz: Fuzzy String Matching in Python"
  },
  {
    "objectID": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html#data-humanization",
    "href": "posts/3cf08c70-f0e4-4eb3-a716-d47d17778d3f/index.html#data-humanization",
    "title": "影视/番剧素材查找 番剧精彩片段制作 create bangumi/anime highlights collection",
    "section": "data humanization",
    "text": "data humanization\npython-humanize\nhumanfriendly\n\n观众情绪是唯一的标准。\n\n影视 番剧 是可以通过专门的网站查找得到英文名称和中文名称的关联的 可以利用这个关系得到YouTube上面的影评并生成中文标题\n影视剪辑比较杂乱 现在喜欢随便混搭 意识流剪辑 当然拿来做一般的素材也行 不过就需要自己搭建处理了\n爱奇艺有以图搜片 不过只能搜爱奇艺有版权的\n33台词 根据电影台词来搜索电影出处 同时有根据画面描述搜索视频片段 画面清晰度不高 其中文案转视频思路和我差不多\nfilm.ai now can query screenshot and movie name by description and download thumbnails of movies (not latest, not mainland), but without subscription you cannot get accurate seek time (though it will never be accurate)\nin imdb can pass film/anime name in multiple languages and get the english name (and trailer video), then query for it in 1337x (results sorted by seeder counts)\n\nnyaa.si国内访问不上 nyaa镜像站列表 比如 https://nyaa.unblockit.ink/ (navigate all unblockit sites, though nyaa is currently not mirrored by this site)https://nyaa.ink/ 其中有些NSFW的 里面也搜不到番剧\nnyaapy wiki\nnyaapi wiki (nodejs)\ntorrent file parser and writer (python)\n文本分类式的番剧剪辑 需要分割时间段 即每隔一分钟分割对应的弹幕并摘要或者字幕 合并并进行打标签 训练 注意不要包括片头和片尾 (maybe audio only model like whisper will classify this successifully, remember to split (or not?) vocals from BGM? (to detect singing voice which is unique in OP/ED))\nwhen transcoding (with seeking?) using ffmpeg tweak parameters. set low profile with high threads count (higher crf will result in poor quality but faster speed), although all these flags may result into unplayable video for some players.\nffmpeg -ss &lt;seek_start&gt; -to &lt;seek_end&gt; -i &lt;video_url&gt; -c:v libx264 -c:a [aac/copy] -threads 8 -crf 28 -preset ultrafast -tune zerolatency -movflags isml+frag_keyframe+empty_moov+faststart+delay_moov -f ismv -maxrate 2500k -bufsize 5000k &lt;output_path&gt;\n使用网络链接进行ffmpeg seek (-c copy)如果不准确 那么就是片子太短了或者是截取的片段太短了 尝试下载全片之后在本地截取\n用webtorrent替代aria2c 可以下载视频指定区域 下载速度特别快 记得及时关闭下载释放内存 看看webtorrent-cli是怎么实现seek的 如何对接ffmpeg\nyt-dlp不一定能下载b站视频指定区域 如果下载失败 得到视频原地址之后执行： ffmpeg -ss &lt;start&gt; -to &lt;end&gt; -c copy &lt;video_url&gt; (其实就是没更新到最新版本)\n准备片头和片尾 准备视频模版 每个片段不要太长 选取多个番剧 适当处理视频 防止撞车\n如果要剪短视频 多用转场效果 提取正在说话 动作幅度大 或者模型认为比较高能的片段\n首先收集b站的动漫高能剪辑视频\n提取标题 标签 封面\n寻找类似封面 根据封面生成标签 或者根据标签寻找封面 (视频里面找 或者类似图片)\n训练根据封面和标签生成标题的模型 或者自行发挥 尝试 只要看起来还行\n分段分析视频片段 用yolov8找出视频正在播放的区域 (画中画区域识别) 方便裁剪识别动漫\n识别截图中的文字 查看是否有重复的 包含有番剧名称 可以用来查找动漫\nasoul database有识别截图出处的思路\nasoul自动操作Windows上面剪映获取字幕 剪映API基于pyautogui 可以使用免费的CI系统 在云端windows机器上面运行程序\n利用动漫素材来源定位网站可以锁定剪辑位置 裁剪时间长度要控制 只选取匹配度高的 NSFW的不要 另外图像尺寸要合适 要正好是视频截图 注意网上的图片不一定是视频截图 最好直接在视频里面找 不要裁剪 图片可能加了一些番剧没有的字符或者装饰 (saucenao&gt;75 (能识别出来老番 比如“没有钱” 但是老番一般没啥人做种 下载可能很慢 不如直接放弃 有几率搜出来pixiv的插画 显然不能拿来剪视频), trace.moe&gt;75, both can detect latest (ongoing) bangume, select top-most) 如果匹配度不高就算了 找下一个 即使匹配度高也要充分怀疑 同一段视频的某段区域 多截图几次 如果出来的不是同一个番 或者不是同一个番的同一集 或者不是连续的时间段 (分别探讨以上情况 如果是番剧的开始/结束片段那么可能同时出现在多个分集里面 如果确实是开头公用的画面 必然会反复出现相同番剧的名字 在这种情况下 优先选取之前已经下载过的视频) 那么就说明结果不对头 即使验证通过 也得对剪出来的片段进行二次验证 检测片段是否存在那个画面 当然对于快速切换画面的 确实有大量不同番剧片段出现在同一个视频的 那就有待进一步探讨了\nsaucenao json api wrapper (python)\nsaucenao api keys found on github:\napi_key = \"6ccf5333e9c875421ff0764e2ed0c0cde1e3a0c7\"\n这种种子文件下载得到的视频 往往带有字体文件 可以收集用来做视频 封面设计\n番剧搜索引擎里面出现的问题 比如不同番剧相似画面的相似度不应该那么高 可以通过自监督强化学习解决 另外画面裁剪的问题 (画中画 裁剪小了或者大了 或者有画面延伸) 都需要进一步改进 最主要的还是要有大量的 不断更新的数据 当然目前来看这些不需要处理\n因为大家都喜欢看中文字幕 (谁听得懂日语 或者一边听日语一边看英文字幕啊) 尽量不用国外的片源 如果只有国外的 直接机器翻译能找到的公开字幕 或者直接语音转文字 图片转文字 不过话说回来 种子下载慢 国内网站广告又多 如果能单独下载字幕 (vcb的有单独分开的字幕可以下载) 对得上时间长度的话 就可以获取到带字幕的老番\nparse and extract subtitle files from mkv video using mkvmerge or ffmpeg\nvideocr: extract hard-coded subtitles from video by OCR\nextract-subtitles 帧间差分法识别关键帧\nanime downloaders: (hard to find chinese subtitles huh?)\nanimdl supports time ranges monkey-dl ani-cli (animixplay is gone, fixing?) gogoanime-api in which you may not get raw video with japanese dub jerry with subtitle language specification\n下载下来之后 得到视频字幕 进行标记 (打上标签) 方便以后创作类似视频的时候查找 以及作为数据集 训练模型 根据字幕/弹幕 (弹幕得去b站找并且自行提取) 或者结合视频内容 (算力够么 需要人肉标记 还是反复调用识图API进行标记 或者用jina (fine-tuned?) 计算图像相似度) 预测不同类型高能片段的标签\n老番可以在国内番剧网站寻找 b站有免费的那么可以尝试下载\ntracker list for anime\n种子站要能够根据seeder降序排序 vcb的一般seeder会很多 但是其他字幕组的新番即使seeder比较少 下载速度也会很快 看情况而定 vcb只负责压制 其他字幕组提供单独分开的字幕 两者要单独下载 Nyaa支持该功能 Nyaa API 这个站将番剧分类为原盘 英文翻译版 (这个分类经常会把多语言版本分类到这个区域) 其他语言翻译版 中文翻译属于其他语言翻译版 如果要找中文翻译版本 先选定类型 然后查找文件名是否包含指定代号 有字幕文件的话先下载看看 检测下主语言类别\naria2c can be controlled via python (to make sure it will exit immediately after finishing download instead of seeding and blocking, though can be achieved with some tweaks on commandline arguments to execute command after download finished signal emitted): aria2p (can be used both as a library or cli program), pyaria2 (old) searching aria2 in github, i found some repos relating to baidunetdisk.\n到国内番剧种子站去找片源 (这些站基本一个样) 新番下载较快 老番下载会非常慢 几乎龟速 (检查有没有seeder 一个都没有就别想下了 直接放弃 以及监控下载进度 一段时间没有进度基本凉了) 而不是一些在线观看的网站 (视频不清晰 还有广告在里面) 由于没法用yt-dlp选取段落下载 (但是webtorrent可以) 最好用云电脑下载然后回传 关掉aria2c的做种选项 下完自动关闭 如果是合集 需要选择指定的对象进行下载\naria2c --show-files target.torrent\naria2c -x 16 --file-allocation=none --select-file=&lt;file_index&gt; target.torrent\n得到了番剧命名格式之后建议利用第三方搜索引擎搜索\n这些种子站一般都会把新番做成rss 用来订阅 做新番推荐比较合适 需要找到番剧介绍的文章来转化 资源的名称遵循某种格式 番剧名称会用不同语言标注 提示字幕的格式 番剧番号用空格 英文或者中文括号括住 一般至少两位数 小于两位会补零 海边的异乡人之类的只有一集 没有episode提示\n如果要实时看云电脑的进度可以自己搭建一个netprogressbar server 根据约定好的url和密码 (read-only and write-only password, or both, by setting different privilege) 来上报和接收进度 server要及时回收资源\n番剧信息包括名称 类型 标签 具体第几话 单季和多季有别 如果是多季的话需要研究如何找出来 提取名字要完整 如果有续集 (比如”Yahari Ore no Seishun Lovecome wa Machigatte Iru.”) 那么要改进parse逻辑 准确识别 (要么在番剧名字alias识别上下功夫 要么找到续集名字 过滤掉续集名字并保留alias名字 看看名字之间是不是有包含关系 没包含关系就不用过滤 到anidb.net找)\nanidb搜索有时会直接跳转到指定番剧页面 需要根据链接地址和内容判断是否存在跳转 以及如何分别进行解析\nanilist python wiki\nanilist api v2 docs\n有提取画面中动漫人物信息以及所属番剧的网站 Python API 只支持日漫 该网站在b站的使用方法介绍 注册码目前是hello2023 可以用来做单个人物合集 在发送截图之前先用模型扫描一下到底有没有动漫人脸 如果没有就不用上传了 识别不出来\ntrailer也可以用来训练视频摘要模型 提取番剧精彩片段 可以作为素材"
  },
  {
    "objectID": "posts/88f8d856-7914-48a3-87be-cfeea4ee28c7/index.html#question",
    "href": "posts/88f8d856-7914-48a3-87be-cfeea4ee28c7/index.html#question",
    "title": "ask chatgpt how to create an ai model for controlling computer under human instruction",
    "section": "question",
    "text": "question\nhow do i design an ai model using gpt, rnn, lstm, vit to accept computer display screenshots and human instructions as input, keyboard and mouse events as output, trained on random keystrokes and mouse events, also human instructions paired with human demonstrations? show me python code"
  },
  {
    "objectID": "posts/88f8d856-7914-48a3-87be-cfeea4ee28c7/index.html#answers",
    "href": "posts/88f8d856-7914-48a3-87be-cfeea4ee28c7/index.html#answers",
    "title": "ask chatgpt how to create an ai model for controlling computer under human instruction",
    "section": "answers",
    "text": "answers\n\nClaude+\nThat would be an extremely complex AI system to build. Some high level steps would be:\n\nCollect a large dataset of screenshots, human instructions, and corresponding keyboard/mouse interactions. This dataset would be crucial for training.\nUse a CNN to extract visual features from the screenshots. Something like VGG16 or ResNet would work well here.\nUse an RNN/LSTM to encode the sequence of instructions. BERT or RoBERTa would also be good options here.\nCombine the visual and textual features. Options include concatenation, addition, or a more complex fusion method.\nUse a Transformer like GPT-3 or Visual-Transformers to generate the keyboard/mouse interactions from the combined visual+textual features. \nTrain the entire model end-to-end to minimize the difference between the generated interactions and the ground truth interactions from your dataset.\n\nThis would likely take a team of ML engineers and researchers to develop, and would require lots of time, data, and compute. \nSome sample Python code would be:\n\nimport torchvision.models as models \nimport torch \nimport torch.nn as nn \nfrom transformers import RobertaModel, GPT2LMHeadModel \n\n# Feature Extractors \ncnn = models.resnet50(pretrained=True) \nroberta = RobertaModel.from_pretrained(\"roberta-base\") \n\n# Fusion \nfusion = nn.Sequential(nn.Linear(2048 + 768, 1024), nn.ReLU(), nn.Linear(1024, 512)) \n\n# Generation Model \ngenerator = GPT2LMHeadModel.from_pretrained(\"gpt2\") \n\n# Forward pass \nimg_features = cnn(img) \ninstruction_features = roberta(instructions)[0] \ncombined_features = fusion(torch.cat((img_features, instruction_features), dim=1)) \npreds = generator(inputs_embeds=combined_features)[0]\n\nThis is just a brief sample, but hopefully gives you an idea of the components and flow. Let me know if you have any other questions!\n\n\n\nGPT4\nDesigning an AI model that combines GPT, RNN, LSTM, and ViT for the task you described is complex and requires deep understanding of these architectures. However, I’ll provide you with a high-level overview and a basic structure of the code to help you get started.\n\nFirst, process the input data:\n\nFor computer display screenshots, use a Vision Transformer (ViT) model to extract features.\nFor human instructions, use a GPT model to encode the natural language instructions.\n\nCombine the features from both the ViT and GPT models.\nUse an LSTM or RNN to process the combined features and maintain the temporal context.\nFinally, decode the output of the LSTM/RNN into keyboard and mouse events.\n\nHere’s a basic structure of the code:\nimport torch\nimport torchvision\nfrom transformers import GPT2Tokenizer, GPT2Model\n\n# Load pretrained models\ngpt_model = GPT2Model.from_pretrained('gpt2')\nvit_model = torchvision.models.vit_b_16(pretrained=True)\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\nclass CustomModel(torch.nn.Module):\n    def __init__(self, gpt_model, vit_model, hidden_size, output_size):\n        super(CustomModel, self).__init__()\n\n        self.gpt_model = gpt_model\n        self.vit_model = vit_model\n        self.rnn = torch.nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n        self.fc = torch.nn.Linear(hidden_size, output_size)\n\n    def forward(self, instructions, screenshots):\n        # Encode instructions using GPT2\n        inputs = tokenizer(instructions, return_tensors=\"pt\", padding=True, truncation=True)\n        gpt_output = self.gpt_model(**inputs)\n        gpt_features = gpt_output.last_hidden_state[:, 0, :]\n\n        # Encode screenshots using ViT\n        vit_output = self.vit_model(screenshots)\n        vit_features = vit_output[\"last_hidden_state\"][:, 0, :]\n\n        # Combine features\n        combined_features = torch.cat((gpt_features, vit_features), dim=1)\n\n        # Process combined features through an RNN\n        rnn_output, _ = self.rnn(combined_features.unsqueeze(1))\n\n        # Decode the output into keyboard and mouse events\n        output = self.fc(rnn_output.squeeze(1))\n\n        return output\n\n# Instantiate the custom model\nmodel = CustomModel(gpt_model, vit_model, hidden_size=1024, output_size=256)\n\n# Train and evaluate the model using your dataset\nYou’ll need to collect a dataset with computer display screenshots, human instructions, and paired keyboard and mouse events. Then, preprocess the data, split it into training and validation sets, and train the model using an appropriate loss function and optimizer.\nKeep in mind that this is just a starting point, and you may need to experiment with different architectures, loss functions, and hyperparameters to achieve the desired performance."
  },
  {
    "objectID": "posts/20dd969d-4a63-4dc4-a7f3-eda0ba66c7ea/index.html",
    "href": "posts/20dd969d-4a63-4dc4-a7f3-eda0ba66c7ea/index.html",
    "title": "audio watermark removal",
    "section": "",
    "text": "audio watermark removal\ndeep audio prior Audio Source Separation Without Any Training Data.\nDAP can also be successfully applied to address audio watermarker removal with co-separation. Given 3 sounds with audio watermarkers, our cosep model can generate 3 individual music sounds and the corresponding watermarker.\naudio watermark may exists in sub or ultra frequencies. use ffmpeg to remove it\nprocess audio with some equalizer"
  },
  {
    "objectID": "posts/3e762c2d-37a4-452a-830f-dce6660fd1c2/index.html",
    "href": "posts/3e762c2d-37a4-452a-830f-dce6660fd1c2/index.html",
    "title": "autocad dwg to dxf, extract text from dwg files",
    "section": "",
    "text": "autocad dwg to dxf, extract text from dwg files\nuse oda_file_converter to convert dwt to dxf, when running it, its ui will pop up. example commandline usage\nlibredwg powers dwg2dxf\nfreecad"
  },
  {
    "objectID": "posts/7a48ff4c-5c78-47dd-9907-65d9bb463b3b/index.html",
    "href": "posts/7a48ff4c-5c78-47dd-9907-65d9bb463b3b/index.html",
    "title": "awesome-data-labeling",
    "section": "",
    "text": "awesome-data-labeling\nA curated list of awesome data labeling tools\n\nImages\n\nlabelImg - LabelImg is a graphical image annotation tool and label object bounding boxes in images\nCVAT - Powerful and efficient Computer Vision Annotion Tool\nlabelme - Image Polygonal Annotation with Python\nVoTT - An open source annotation and labeling tool for image and video assets\nimglab - A web based tool to label images for objects that can be used to train dlib or other object detectors\nYolo_mark - GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2\nPixelAnnotationTool - Software that allows you to manually and quickly annotate images in directories\nOpenLabeling - Label images and video for Computer Vision applications\nimagetagger - An open source online platform for collaborative image labeling\nAlturos.ImageAnnotation - A collaborative tool for labeling image data\ndeeplabel - A cross-platform image annotation tool for machine learning\nMedTagger - A collaborative framework for annotating medical datasets using crowdsourcing.\nLabelbox - Labelbox is the fastest way to annotate data to build and ship computer vision applications\nturktool - A modern React app for scalable bounding box annotation of images\nPixie - Pixie is a GUI annotation tool which provides the bounding box, polygon, free drawing and semantic segmentation object labelling\nOpenLabeler - OpenLabeler is an open source desktop application for annotating objects for AI appplications\nAnno-Mage - A Semi Automatic Image Annotation Tool which helps you in annotating images by suggesting you annotations for 80 object classes using a pre-trained model\nCATMAID - Collaborative Annotation Toolkit for Massive Amounts of Image Data\nmake-sense - makesense.ai is a free to use online tool for labelling photos\nLOST - Design your own smart Image Annotation process in a web-based environment\nAnnotorious - A JavaScript library for image annotation.\nSloth - Tool for labeling image and video data for computer vision research.\n\n\n\nText\n\nYEDDA - A Lightweight Collaborative Text Span Annotation Tool (Chunking, NER, etc.). ACL best demo nomination.\nML-Annotate - Label text data for machine learning purposes. ML-Annotate supports binary, multi-label and multi-class labeling.\nTagEditor - Annotation tool for spaCy\nSMART - Smarter Manual Annotation for Resource-constrained collection of Training data\nPIAF - A Question-Answering annotation tool\n\n\n\nAudio\n\nEchoML - Play, visualize, and annotate your audio files\naudio-annotator - A JavaScript interface for annotating and labeling audio files.\naudio-labeler - An in-browser app for labeling audio clips at random, using Docker and Flask.\nwavesurfer.js - Simple annotations tool, check the example.\npeak.js - Browser-based audio waveform visualisation and UI component for interacting with audio waveforms, developed by BBC UK.\nPraat - Doing Phonetics By Computer\nAubio - Tool designed for the extraction of annotations from audio signals.\n\n\n\nVideo\n\nUltimateLabeling - A multi-purpose Video Labeling GUI in Python with integrated SOTA detector and tracker\nVATIC - VATIC is an online video annotation tool for computer vision research that crowdsources work to Amazon’s Mechanical Turk.\n\n\n\nTime Series\n\nCurve - Curve is an open-source tool to help label anomalies on time-series data\nTagAnomaly - Anomaly detection analysis and labeling tool, specifically for multiple time series (one time series per category)\ntime-series-annotator - The CrowdCurio Time Series Annotation Library implements classification tasks for time series.\nWDK - The Wearables Development Toolkit (WDK) is a set of tools to facilitate the development of activity recognition applications with wearable devices.\n\n\n\n3D\n\nwebKnossos - webKnossos is an open-source web-based tool for visualizing, annotating, and sharing large 3D image datasets. It features fast 3D data browsing, skeleton (line-segment) annotations, segmentation and proof-reading tools, mesh visualization, and collaboration features. The public instance webknossos.org hosts a collection of published datasets and can be used without a local setup.\nKNOSSOS - KNOSSOS is a software tool for the visualization and annotation of 3D image data and was developed for the rapid reconstruction of neural morphology and connectivity.\n\n\n\nLidar\n\nsemantic-segmentation-editor - Web labelling tool for camera and LIDAR data\n\n\n\nMultiDomain\n\nLabel Studio - Label Studio is a configurable data annotation tool that works with different data types\nDataturks - Dataturks support E2E tagging of data items like video, images (classification, segmentation and labelling) and text (full length document annotations for PDF, Doc, Text etc) for ML projects."
  },
  {
    "objectID": "posts/eb5f4dce-27fb-46d4-83cc-49a90562b365/index.html",
    "href": "posts/eb5f4dce-27fb-46d4-83cc-49a90562b365/index.html",
    "title": "A good/bad proposal on v2ray",
    "section": "",
    "text": "A good/bad proposal on v2ray\nsuggest to enable multiple v2ray client/servers which talk to each other but only visit the network with one single outbound. maybe like the onion router."
  },
  {
    "objectID": "posts/5a5658b0-0542-47e7-a945-7f138607c352/index.html",
    "href": "posts/5a5658b0-0542-47e7-a945-7f138607c352/index.html",
    "title": "bilibili dark reader mod",
    "section": "",
    "text": "bilibili dark reader mod\nmaybe toggle the filter mode triggers will help?\nor stylus? other modding tools?"
  },
  {
    "objectID": "posts/fd13920e-d872-4ccd-b4ca-11a64d674193/index.html",
    "href": "posts/fd13920e-d872-4ccd-b4ca-11a64d674193/index.html",
    "title": "bilibili up主启航计划",
    "section": "",
    "text": "bilibili up主启航计划\n现在看来b站应该是有专人在负责讲解同一套课程了 我现在还在收到b站的培训通知短信\n应该把相关的链接 信息收集在这里"
  },
  {
    "objectID": "posts/d5025032-bc46-42fa-94f6-1ab0d35788c3/index.html",
    "href": "posts/d5025032-bc46-42fa-94f6-1ab0d35788c3/index.html",
    "title": "bilibili 账号找回",
    "section": "",
    "text": "bilibili 账号找回\n联系了客服娘 人工找回的\n看来这个b站还是欠日 什么消息都要我记住？我记得住个屁\n\n提醒我隔一段时间检查一下这个话费 两个号码都要检查 一周提醒一次 从8月19号开始 每个星期五都要检查话费\n\n新注册的号码 6个月之后可以更换套餐 换成8块钱一个月的"
  },
  {
    "objectID": "posts/24063221-77b6-46fd-8992-2b10de5bc0b5/index.html",
    "href": "posts/24063221-77b6-46fd-8992-2b10de5bc0b5/index.html",
    "title": "Cracking BurpSuite Pro: Exploiting Web App Vulnerabilities with Python API Client",
    "section": "",
    "text": "burpsuite Pro cracked keygen\nthis makes me think of metasploit pro.\nburpsuite pro contains burp webapp scanner, will scan for common vulnerabilities, 0day exploits for highly dynamic webapps.\nburpsuite pro 2021 keygen\npython unofficial burpsuite api client\nburpsuite 2022 crack"
  },
  {
    "objectID": "posts/647b65c9-04c2-4988-b25e-76b0f2c385a6/index.html",
    "href": "posts/647b65c9-04c2-4988-b25e-76b0f2c385a6/index.html",
    "title": "cacani tweening_interpolating alternatives",
    "section": "",
    "text": "cacani tweening/interpolating alternatives animation tool animation generation\nvpaint http://www.vpaint.org https://github.com/dalboris/vpaint\nvgc https://github.com/vgc/vgc\nopentoolz v1.4 and later\nsynfig vector graphic animation: synfig.org\n2d animation tool: https://github.com/hidefuku/AnimeEffects http://animeeffects.org/en/"
  },
  {
    "objectID": "posts/f9e7456a-f577-46f3-906b-7675518a77d3/index.html",
    "href": "posts/f9e7456a-f577-46f3-906b-7675518a77d3/index.html",
    "title": "calling java from python",
    "section": "",
    "text": "calling java from python\nusing jpype or pyjnius\nsample code for jpype:\nfrom jpype import *\nimport jpype.imports # this is needed! shit.\n\naddClassPath(\"/root/Desktop/works/pyjom/tests/karaoke_effects/classpath/lingua.jar\")\n\nstartJVM(getDefaultJVMPath())\njava.lang.System.out.println(\"Calling Java Print from Python using Jpype!\")\n\nfrom com.github.pemistahl.lingua.api import *\n\n\n# detector = LanguageDetectorBuilder.fromAllLanguages().withLowAccuracyMode().build()\ndetector = LanguageDetectorBuilder.fromAllLanguages().build() # 3.5GB just for detecting language! it is somehow crazy.\n\nsample = 'hello world'\n\nresult = detector.detectLanguageOf(sample)\nprint(result, type(result)) # &lt;java class 'com.github.pemistahl.lingua.api.Language'&gt;\n# but we can convert it into string.\nstrResult = str(result)\nprint(strResult, type(strResult))\nimport math\n\nprint(\"CALLING MATH: %d\" % math.sqrt(4))\nshutdownJVM()\nsample for pyjnius:\nimport jnius_config\n# jnius_config.add_options('-Xrs', '-Xmx4096')\njnius_config.set_classpath('.', \"/root/Desktop/works/pyjom/tests/karaoke_effects/classpath/lingua.jar\")\nimport jnius\njnius.autoclass('java.lang.System').out.println('Hello world')\ndetector = jnius.autoclass('com.github.pemistahl.lingua.api.LanguageDetectorBuilder').fromAllLanguages().build()\n\nsample = 'hello world'\n\nresult = detector.detectLanguageOf(sample)\nprint(result, type(result))\n# breakpoint()\nstrResult = result.toString()\nprint(strResult, type(strResult))"
  },
  {
    "objectID": "posts/507ad5b2-3f2b-42dd-b4c5-c721867540c0/index.html",
    "href": "posts/507ad5b2-3f2b-42dd-b4c5-c721867540c0/index.html",
    "title": "Exploring Alternative Linux Cd Managers: Goto, Go-Shell, Up, and AutoJump",
    "section": "",
    "text": "cd manager Linux alternative\ngoto supports bash and zsh (compdef needed) go-shell supports powershell up navigates to parent directory, supports fish, bash, zsh autojump"
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-create-a-natural-language-generator",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-create-a-natural-language-generator",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to create a natural language generator",
    "text": "use pyro to create a natural language generator\nPyro is a probabilistic programming language built on top of PyTorch, which can be used for creating probabilistic models and conducting Bayesian inference. One way you can use Pyro to create a natural language generator is by defining a probabilistic model of the language generation process, and using Monte Carlo sampling or variational inference to generate text.\nHere is a basic example of how you might do this using Pyro:\nimport torch\nimport pyro\nimport pyro.distributions as dist\n\n# Define the vocabulary and size of the language model\nvocab = [\"&lt;START&gt;\", \"the\", \"cat\", \"sat\", \"on\", \"mat\", \"&lt;END&gt;\"]\nvocab_size = len(vocab)\n\n# Define a simple language model that generates text one word at a time\ndef language_model(prefix):\n    # Initialize the hidden state with a uniform distribution\n    hidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size))\n    \n    # Initialize the output sequence with the start token\n    output_sequence = [vocab.index(\"&lt;START&gt;\")]\n    \n    # Iterate over the prefix and append each word to the output sequence\n    for word in prefix:\n        output_sequence.append(vocab.index(word))\n    \n    # Generate the rest of the sequence one word at a time\n    while output_sequence[-1] != vocab.index(\"&lt;END&gt;\"):\n        # Use the hidden state to generate a distribution over the next word\n        next_word_dist = pyro.sample(\"next_word\", dist.Categorical(hidden_state))\n        # Append the next word to the output sequence\n        output_sequence.append(next_word_dist)\n        # Update the hidden state using the next word\n        hidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size), obs=next_word_dist)\n    \n    # Convert the output sequence to a list of words\n    return [vocab[i] for i in output_sequence]\n\n# Generate text using the language model\ngenerated_text = language_model(prefix=[\"the\", \"cat\"])\nprint(generated_text)\nThis example defines a simple language model that generates text one word at a time, using a hidden state to produce a distribution over the next word in the sequence. The model starts by initializing the hidden state with a uniform distribution, and then iteratively generates words until it reaches the end token. You can use Monte Carlo sampling or variational inference to generate text from this model by calling pyro.sample on the model and specifying the desired number of samples.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-create-a-natural-language-generator-with-loss-function-like-adam",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-create-a-natural-language-generator-with-loss-function-like-adam",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to create a natural language generator, with loss function like adam",
    "text": "use pyro to create a natural language generator, with loss function like adam\nTo use Pyro to create a natural language generator with a loss function like Adam, you will need to define a probabilistic model that takes in some input data and generates text, and then define a loss function that compares the generated text to some target text. You can then use an optimization algorithm like Adam to minimize the loss function and optimize the parameters of your model.\nHere is an example of how you might do this using Pyro:\nimport torch\nimport pyro\nimport pyro.distributions as dist\nfrom pyro.optim import Adam\n\n# Define the vocabulary and size of the language model\nvocab = [\"&lt;START&gt;\", \"the\", \"cat\", \"sat\", \"on\", \"mat\", \"&lt;END&gt;\"]\nvocab_size = len(vocab)\n\n# Define a simple language model that generates text one word at a time\ndef language_model(prefix):\n    # Initialize the hidden state with a uniform distribution\n    hidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size))\n    \n    # Initialize the output sequence with the start token\n    output_sequence = [vocab.index(\"&lt;START&gt;\")]\n    \n    # Iterate over the prefix and append each word to the output sequence\n    for word in prefix:\n        output_sequence.append(vocab.index(word))\n    \n    # Generate the rest of the sequence one word at a time\n    while output_sequence[-1] != vocab.index(\"&lt;END&gt;\"):\n        # Use the hidden state to generate a distribution over the next word\n        next_word_dist = pyro.sample(\"next_word\", dist.Categorical(hidden_state))\n        # Append the next word to the output sequence\n        output_sequence.append(next_word_dist)\n        # Update the hidden state using the next word\n        hidden_state = pyro.sample(\"hidden_state\", dist.Uniform(0, vocab_size), obs=next_word_dist)\n    \n    # Convert the output sequence to a list of words\n    return [vocab[i] for i in output_sequence]\n\n# Define a loss function that compares the generated text to some target text\ndef loss_fn(generated_text, target_text):\n    # Compute the cross-entropy loss between the generated text and the target text\n    return -torch.sum(torch.tensor([vocab.index(word) for word in target_text]) * torch.log(torch.tensor([vocab.index(word) for word in generated_text])))\n\n# Optimize the parameters of the language model using Adam\noptimizer = Adam({\"lr\": 0.001})\n\n# Set the number of training iterations\nnum_iterations = 1000\n\n# Use Pyro's SVI to optimize the parameters of the language model\nfor i in range(num_iterations):\n    # Clear the gradient\n    optimizer.zero_grad()\n    # Generate some text using the language model\n    generated_text = language_model(prefix=[\"the\", \"cat\"])\n    # Compute the loss\n    loss = loss_fn(generated_text, target_text)\n    # Compute the gradients\n    loss.backward()\n    # Update the parameters\n    optimizer.step()\n\n# Generate text using the optimized language model\ngenerated_text = language_model(prefix=[\"the\", \"cat\"])\nprint(generated_text)\nThis code uses Pyro’s Stochastic Variational Inference (SVI) to optimize the parameters of the language model using the Adam optimizer. The model is trained by generating text using the current parameters of the model, computing the loss between the generated text and the target text, and then updating the parameters based on the gradients of the loss with respect to the model parameters.\nAfter training, you can use the optimized language model to generate text by calling language_model with the desired prefix as input.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-generate-natural-language-using-advanced-models",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-generate-natural-language-using-advanced-models",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to generate natural language using advanced models",
    "text": "use pyro to generate natural language using advanced models\nThere are several advanced probabilistic models that you can use with Pyro to generate natural language. Some examples include:\nRecurrent neural network (RNN) language models: These models use an RNN to process the input sequence and generate a probability distribution over the next word in the sequence. You can use Pyro to define an RNN language model by using the pyro.nn module to define the RNN and the pyro.distributions module to define the distribution over the next word.\nTransformer language models: These models use a transformer architecture to process the input sequence and generate a probability distribution over the next word in the sequence. You can use Pyro to define a transformer language model by using the pyro.nn module to define the transformer and the pyro.distributions module to define the distribution over the next word.\nVariational autoencoder (VAE) language models: These models use a VAE to learn a latent representation of the input sequence, and then use the latent representation to generate a probability distribution over the next word in the sequence. You can use Pyro to define a VAE language model by using the pyro.nn module to define the VAE and the pyro.distributions module to define the distribution over the next word.\nTo use any of these models with Pyro, you will need to define a probabilistic model that takes in some input data and generates text, and then use Monte Carlo sampling or variational inference to generate text from the model. You can also define a loss function and use an optimization algorithm like Adam to optimize the parameters of the model.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#determine-topic-among-a-large-group-of-entities-with-labels-with-pyro",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#determine-topic-among-a-large-group-of-entities-with-labels-with-pyro",
    "title": "chatgpt on pyro and pytorch",
    "section": "determine topic among a large group of entities with labels with pyro",
    "text": "determine topic among a large group of entities with labels with pyro\nTo determine the topic among a large group of entities with labels using Pyro, you can use a technique called topic modeling. Pyro is a probabilistic programming language that allows you to build and perform inference on probabilistic models.\nOne way to perform topic modeling using Pyro is to use a probabilistic graphical model called a Latent Dirichlet Allocation (LDA) model. In an LDA model, you can specify the number of topics and the number of words in each topic, and the model will learn the distribution of words that are likely to belong to each topic.\nTo implement an LDA model in Pyro, you will first need to define the model and the priors for the parameters. This can be done using the pyro.sample() function, which allows you to specify the probability distribution for the parameters. You can then use the pyro.infer.MCMC() function to perform Markov Chain Monte Carlo (MCMC) inference on the model, which will allow you to estimate the posterior distribution of the model parameters.\nOnce you have trained the model, you can use it to classify a new document by using the pyro.predict() function and passing in the document’s words as input. The model will return the probability that the document belongs to each of the specified topics.\nFor more detailed information on how to implement topic modeling using Pyro, you can refer to the Pyro documentation or tutorials online."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#how-to-determine-watermark-location-and-remove-watermark-at-location-with-several-screenshots-in-a-video-with-pytorch",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#how-to-determine-watermark-location-and-remove-watermark-at-location-with-several-screenshots-in-a-video-with-pytorch",
    "title": "chatgpt on pyro and pytorch",
    "section": "how to determine watermark location and remove watermark at location with several screenshots in a video with pytorch",
    "text": "how to determine watermark location and remove watermark at location with several screenshots in a video with pytorch\nTo determine the location of a watermark in a video with multiple screenshots and remove the watermark using PyTorch, you can use a technique called image inpainting. Image inpainting is a process of filling in missing or damaged pixels in an image or video to restore it to its original form.\nOne way to perform image inpainting using PyTorch is to use a convolutional neural network (CNN) to learn the structure and patterns in the image or video. You can train the CNN to predict the missing or damaged pixels based on the surrounding pixels.\nTo implement image inpainting using PyTorch, you will need to first prepare a dataset of images or video frames with and without the watermark. You can then use this dataset to train the CNN using the PyTorch API. You can use the PyTorch optimizers and loss functions to optimize the network and improve its performance.\nOnce the CNN is trained, you can use it to predict the missing or damaged pixels in a new image or video frame with a watermark. You can then remove the watermark by replacing the predicted pixels with the original pixels from the image or video frame without the watermark.\nFor more detailed information on how to implement image inpainting using PyTorch, you can refer to the PyTorch documentation or tutorials online."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#how-to-determine-watermark-location-in-a-series-of-screenshots-in-video-with-pytorch",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#how-to-determine-watermark-location-in-a-series-of-screenshots-in-video-with-pytorch",
    "title": "chatgpt on pyro and pytorch",
    "section": "how to determine watermark location in a series of screenshots in video with pytorch",
    "text": "how to determine watermark location in a series of screenshots in video with pytorch\nTo determine the location of a watermark in a series of screenshots in a video using PyTorch, you can use a technique called object detection. Object detection is a process of identifying and localizing objects in an image or video.\nOne way to perform object detection using PyTorch is to use a convolutional neural network (CNN) to learn the features and patterns in the image or video. You can train the CNN to predict the presence and location of objects in the image or video.\nTo implement object detection using PyTorch, you will need to first prepare a dataset of images or video frames with and without the watermark. You can then use this dataset to train the CNN using the PyTorch API. You can use the PyTorch optimizers and loss functions to optimize the network and improve its performance.\nOnce the CNN is trained, you can use it to detect the presence and location of the watermark in a new image or video frame. You can then use the predicted bounding box coordinates to determine the location of the watermark in the image or video frame.\nFor more detailed information on how to implement object detection using PyTorch, you can refer to the PyTorch documentation or tutorials online."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#the-data-is-a-series-of-images-not-a-single-image",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#the-data-is-a-series-of-images-not-a-single-image",
    "title": "chatgpt on pyro and pytorch",
    "section": "the data is a series of images, not a single image",
    "text": "the data is a series of images, not a single image\nIf you have a series of images and you want to determine the location of a watermark in each of the images using PyTorch, you can use a technique called object detection. Object detection is a process of identifying and localizing objects in an image or video.\nOne way to perform object detection using PyTorch is to use a convolutional neural network (CNN) to learn the features and patterns in the images. You can train the CNN to predict the presence and location of objects in the images.\nTo implement object detection using PyTorch, you will need to first prepare a dataset of images with and without the watermark. You can then use this dataset to train the CNN using the PyTorch API. You can use the PyTorch optimizers and loss functions to optimize the network and improve its performance.\nOnce the CNN is trained, you can use it to detect the presence and location of the watermark in each of the images in the series. You can then use the predicted bounding box coordinates to determine the location of the watermark in each image.\nFor more detailed information on how to implement object detection using PyTorch, you can refer to the PyTorch documentation or tutorials online."
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#how-to-put-a-series-of-image-into-a-single-cnn-show-me-the-code",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#how-to-put-a-series-of-image-into-a-single-cnn-show-me-the-code",
    "title": "chatgpt on pyro and pytorch",
    "section": "how to put a series of image into a single CNN, show me the code",
    "text": "how to put a series of image into a single CNN, show me the code\nTo put a series of images into a single CNN using PyTorch, you can use the PyTorch Dataset and DataLoader classes. These classes allow you to create a custom dataset and load the data in small batches for training or inference.\nHere is an example of how you can create a custom dataset for a series of images and use it with a CNN in PyTorch:\nimport os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_names = os.listdir(self.root_dir)\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.root_dir, image_name)\n        image = Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image\n\n# Create the dataset and dataloader\ndataset = ImageDataset(root_dir='path/to/images')\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Define the CNN model\nclass CNN(torch.nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n        self.pool = torch.nn.MaxPool2d(2, 2)\n        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = torch.nn.Linear(120, 84)\n        self.fc3 = torch.nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# Create the model and optimizer\nmodel = CNN()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Loop through the dataloader and train the model\nfor images, labels in dataloader:\n    optimizer.zero_grad()\n    outputs = model(images)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()\nIn this example, the ImageDataset class extends the PyTorch Dataset class and is used to load the images from a root directory. The DataLoader class is used to load the data in small batches and shuffle"
  },
  {
    "objectID": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-generate-natural-language",
    "href": "posts/e43900e3-fdbd-49f4-b8de-9722df9193c9/index.html#use-pyro-to-generate-natural-language",
    "title": "chatgpt on pyro and pytorch",
    "section": "use pyro to generate natural language",
    "text": "use pyro to generate natural language\nTo generate natural language using Pyro, you can use a technique called language modeling. Language modeling is the process of predicting the next word in a sequence of words given the previous words.\nOne way to perform language modeling using Pyro is to use a probabilistic graphical model called a recurrent neural network (RNN) language model. In an RNN language model, the probability of each word in the sequence is modeled as a function of the previous words in the sequence.\nTo implement an RNN language model in Pyro, you will first need to define the model and the priors for the parameters. This can be done using the pyro.sample() function, which allows you to specify the probability distribution for the parameters. You can then use the pyro.infer.SVI() function to perform stochastic variational inference on the model, which will allow you to estimate the posterior distribution of the model parameters.\nOnce you have trained the model, you can use it to generate natural language by feeding it a seed word or phrase and using the model to predict the next word in the sequence. You can then use the predicted word as the input for the next iteration, and continue generating the sequence until you reach the desired length.\nFor more detailed information on how to implement language modeling using Pyro, you can refer to the Pyro documentation or tutorials online."
  },
  {
    "objectID": "posts/f0cc95f1-f46e-49f8-a2a3-95b14736617a/index.html",
    "href": "posts/f0cc95f1-f46e-49f8-a2a3-95b14736617a/index.html",
    "title": "chemical shit, cheminformatics",
    "section": "",
    "text": "chemical shit, cheminformatics"
  },
  {
    "objectID": "posts/a91c35b3-7c94-4166-89f3-344ab5ab56d9/index.html",
    "href": "posts/a91c35b3-7c94-4166-89f3-344ab5ab56d9/index.html",
    "title": "AGI playground, a place for AGI to act/code freely",
    "section": "",
    "text": "AGI playground, a place for AGI to act/code freely\nsearch for “artificial general intelligence” in github and hit many results.\nsome article says deep neural networks are t2 level, human are t3 level (connected dnns) and to train a t3 level intel you need t4 level intel (like the earth, or a group of t3 intels, you can’t be 1-to-1 now, you must be forgiving). this proves my provision of putting agi into gui or human interfaces.\nto train a t2 level intel, you need t3 intel, such as yourself or your users.\nyou must setup this playground then you begin to learn stuff and libraries of AGI. but once you have one, don’t move around, stick to it! you need time to develop the general adaptor and make clear and achievable goals!\nterminal, GUI, program, API, network\nplease check my previous efforts on building AGI, namely: AGI, lazero, metalazero\nnsjail with docker\nfirejail"
  },
  {
    "objectID": "posts/df442d8b-b0fb-4d7a-ac52-2c493c072d1e/index.html",
    "href": "posts/df442d8b-b0fb-4d7a-ac52-2c493c072d1e/index.html",
    "title": "color transfer between images, histogram based style transfer",
    "section": "",
    "text": "color transfer between images, histogram based style transfer\n图像调色风格转换 可以创建蹦迪特效 让视频或者图片五彩斑斓\ncolor transfer between images\npip install color_transfer\nofficial scikit-learn histogram matching\nimport matplotlib.pyplot as plt\n\nfrom skimage import data\nfrom skimage import exposure\nfrom skimage.exposure import match_histograms\n\nreference = data.coffee()\nimage = data.chelsea()\n\nmatched = match_histograms(image, reference, channel_axis=-1)\n\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n                                    sharex=True, sharey=True)\nfor aa in (ax1, ax2, ax3):\n    aa.set_axis_off()\n\nax1.imshow(image)\nax1.set_title('Source')\nax2.imshow(reference)\nax2.set_title('Reference')\nax3.imshow(matched)\nax3.set_title('Matched')\n\nplt.tight_layout()\nplt.show()\nhistogram matching"
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#search-commands-on-commandline",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#search-commands-on-commandline",
    "title": "commandline search engine bridger",
    "section": "search commands on commandline",
    "text": "search commands on commandline\nman -k &lt;keywords&gt;\napt search &lt;keywords&gt;\nbrew search &lt;keywords&gt;\nnpm search &lt;keywords&gt;\nsearchsploit &lt;keywords&gt;\nmsfconsole -x \"search &lt;keywords&gt;; exit\""
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#nosqlnosqlite-key-value-json-like-document-store-databases-sqlite-high-level-wrappers",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#nosqlnosqlite-key-value-json-like-document-store-databases-sqlite-high-level-wrappers",
    "title": "commandline search engine bridger",
    "section": "nosql/nosqlite key-value json like document store databases, sqlite high level wrappers",
    "text": "nosql/nosqlite key-value json like document store databases, sqlite high level wrappers\nthis guy makes database related libraries.\n\nlsm-db fast key-value store using sqlite 4\nunqlite Python bindings for the UnQLite embedded NoSQL database\ntinydb json-oriented, mongo alike database, which is a in-memory database\nlitedb NoSQL Python database written for ease of use/performance.\npylite sqlite3 lightweight wrapper"
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#reason-to-develop-this",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#reason-to-develop-this",
    "title": "commandline search engine bridger",
    "section": "reason to develop this",
    "text": "reason to develop this\nyou are short of brain power. short of time to perspect and investigate.\nmany platforms now have recommendation engines, but they do not have powerful semantic search tools. what a pity. maybe i am interested in some ‘unseen’ stuff, but i want to get the thing that i currently need! fail to do so will limit my productivity."
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#sentence-embeddings",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#sentence-embeddings",
    "title": "commandline search engine bridger",
    "section": "sentence embeddings",
    "text": "sentence embeddings\ndifference between ‘symmetric’ and ‘asymmetric’ retrieval questions from sbert.net:\nsymmetric means similar, asymmetric usually means question to answer.\ntop 4 sentence embedding techniques using python\nsentence to vector\ntutorial: sentence vector word2vec\nsentence2vec based on word2vec"
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#similarity-search-and-clustering",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#similarity-search-and-clustering",
    "title": "commandline search engine bridger",
    "section": "similarity search and clustering",
    "text": "similarity search and clustering\nfacebook faiss\nhnswlib Header-only C++/python library for fast approximate nearest neighbors\nspotify annoy Approximate Nearest Neighbors in C++/Python optimized for memory usage and loading/saving to disk"
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#problems",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#problems",
    "title": "commandline search engine bridger",
    "section": "problems",
    "text": "problems\n\nenable copy/pasting/selection in console\nmake reversible/auto-cleanup feature when copy and pasting\nreverse stemming and keywords highlighting\nmemory efficient embedding querying/storage via sql or binary format\n\ntxtai store to sqlite: Build an Embeddings index from a data source\n\nmake “complete” excerpt by looking ahead and backward to find the closest sentence start/stop and/or use gpt completion method instead? still need punctual or sentence start/stop index identification."
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#offline",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#offline",
    "title": "commandline search engine bridger",
    "section": "offline",
    "text": "offline\n\nterminal interface builder\nrich and tutorial\ntextual\nurwid\nplie\n\n\nai assisted search engine libraries\njina-ai and docarray\ntxtai\ntypesense\nzinc search\nfuzzy search\nfuzzy phonic toolkit\n\n\ntraditional search engine libraries\nluceneplusplus lucene in c++\npythonql as extension of python syntax, able to search data in python data structure.\njq and pyjq as json search engine, jqterm as jq repl\nfq jq for binary formats\na curated search engine list\nscout sqlite based full text search\nwhoosh with bm25 support\npython-searchengine and the tutorial"
  },
  {
    "objectID": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#online",
    "href": "posts/17a82ecf-f1c2-41cb-a9f1-6dd5c58a3fff/index.html#online",
    "title": "commandline search engine bridger",
    "section": "online",
    "text": "online\nsurfraw, or just s, is for some common parameter prefixes for searching on common websites. will open GUI browser or cli browser if configured with one.\nsurfraw supported:\nW               -- Activate Surfraw defined web-browser\nacronym         -- Look for acronyms definitions (www.acronymfinder.com)\nads             -- Search SAO/NASA Astrophysics Data System\nalioth          -- Search Alioth (alioth.debian.org)\namazon          -- Search the amazon.com bookstore\narchpkg         -- Search Arch Linux Packages (www.archlinux.org/packages/)\narchwiki        -- Search the Arch Linux Wiki\narxiv           -- Search arXiv E-Print Archive for articles\nask             -- Question the web using Ask Jeeves (www.ask.com)\naur             -- Search aur.archlinux.org for PKGBUILDs\naustlii         -- Search Australian Law docs (www.austlii.edu.au)\nbbcnews         -- Search BBC News (news.bbc.co.uk)\nbing            -- Search the web using Microsoft's Bing (www.bing.com)\nbookfinder      -- Search for books using www.bookfinder.com\nbugmenot        -- Bypass compulsory web registration with bugmenot.com\nbugzilla        -- Search for bugs on Bugzilla bugtrackers\ncablesearch     -- search for leaked diplomatic communications\ncia             -- Search CIA documents at www.cia.gov\ncisco           -- Search Cisco documentation (www.cisco.com)\ncite            -- Search computer science papers (citeseerx.ist.psu.edu)\ncliki           -- Search the common lisp wiki\ncnn             -- Search on CNN (cnn.com)\ncomlaw          -- Search Australian Law using Comlaw (www.comlaw.gov.au)\ncommandlinefu   -- Search on www.commandlinefu.com\nctan            -- Search the Comprehensive TeX Archive Network (ctan.org)\ncurrency        -- Convert currencies with the Universal Currency Converter (www.xe.net/ucc)\ncve             -- Search for CAN assignments in CVE\ndebbugs         -- Search the debian BTS (bugs.debian.org)\ndebcodesearch   -- Search debian source code\ndebcontents     -- Search contents of debian/ubuntu packages (packages.debian.org/packages.ubuntu.com)\ndeblists        -- Search debian mailing lists (lists.debian.org/search.html)\ndeblogs         -- Show changelogs for a package in Debian main (changelogs.debian.net)\ndebpackages     -- Search debian/ubuntu packages (packages.debian.org/packages.ubuntu.com)\ndebpkghome      -- Visit the home page for a Debian package\ndebpts          -- Search the Debian Package Tracking System (packages.qa.debian.org)\ndebsec          -- Search the Debian Security Tracker for CVE ids or package names\ndebvcsbrowse    -- Browse the VCS repository for a Debian package\ndebwiki         -- Search the Debian Wikis (wiki.debian.org & women.debian.org/wiki)\ndeja            -- Search usenet using Google Groups (groups.google.com)\ndeli            -- Search Delicious bookmarks\ndiscogs         -- Search the Discogs database of music information (www.discogs.com)\ndmoz            -- Search the Open Directory Project web directory (dmoz.org)\nduckduckgo      -- Securely search the web using duckduckgo (www.duckduckgo.com)\nebay            -- Search the Ebay auction site\netym            -- Look up word origins at www.etymonline.com\nexcite          -- Search on Excite (www.excite.com)\nf5              -- Search F5 related information (www.f5.com)\nfinkpkg         -- Search Fink packages (pdb.finkproject.org)\nfoldoc          -- The Free On-Line Dictionary Of Computing (foldoc.org)\nfreebsd         -- Search FreeBSD related information (www.freebsd.org)\nfreedb          -- Search for cd track listings in FreeDB (www.freedb.org)\nfreshmeat       -- Search Freshmeat (www.freshmeat.net)\nfsfdir          -- Search the FSF/UNESCO Free Software Directory (directory.fsf.org)\ngcache          -- Search the web using Google cache (www.google.com)\ngenbugs         -- Search the Gentoo bug tracker (bugs.gentoo.org)\ngenportage      -- Search gentoo-portage.com for packages\ngithub          -- Search GitHub (https://github.com)\ngmane           -- Search mailing list with gmane (gmane.org)\ngoogle          -- Search the web using Google (www.google.com)\ngutenberg       -- Search for books on Project Gutenberg (gutenberg.org)\nimdb            -- Search the Internet Movie Database (www.imdb.com)\nixquick         -- Search the web using ixquick [HTTPS] (www.ixquick.com)\njamendo         -- Search Jamendo: free music with Creative Commons licenses (www.jamendo.com)\njavasun         -- Search Java API docs (java.sun.com)\njquery          -- Search the jQuery documentation (api.jquery.com)\nl1sp            -- Search lisp documentation\nlastfm          -- Search last.fm\nleodict         -- Search Leo's German &lt;-&gt; English dictionary (dict.leo.org)\nlsm             -- Search the Linux Software Map\nmacports        -- Search macports packages (macports.org)\nmathworld       -- Search Wolfram MathWorld\nmdn             -- Search the mozilla developer network (developer.mozilla.org)\nmininova        -- Search the mininova bittorent source.\nmusicbrainz     -- Search MusicBrainz (musicbrainz.org)\nmysqldoc        -- Search mysql documentation (dev.mysql.com)\nnetbsd          -- Search NetBSD related information (www.netbsd.org)\nnlab            -- Search the nLab wiki (http://ncatlab.org)\nntrs            -- Search the NASA Technical Report Server\nopenbsd         -- Search OpenBSD related information (www.openbsd.org)\nopenports       -- search openports for OpenBSD packages\nopensearch      -- Search an OpenSearch-enabled website\noraclesearch    -- Search an OpenSearch-enabled website\npasearch        -- Search the unofficial Penny Arcade archives (pipefour.org/pa)\npgdoc           -- Search postgres documentation (www.pgdoc.com)\npgpkeys         -- Search the PGP key database\nphpdoc          -- Search php documentation (php.net)\npin             -- Search Pinboard bookmarks (http://pinboard.in)\npiratebay       -- Search The Pirate Bay (http://thepiratebay.org)\npriberam        -- Look up word in Priberam online dictionary (www.priberam.pt/dlpo)\npubmed          -- Search medical/molbio databases (www.ncbi.nlm.nih.gov)\nrae             -- Busca en el diccionario de la Real Academia de la Lengua Española (Spanish Dictionary)\nrfc             -- Search RFCs (internet standards documents)\nrhyme           -- Search for rhymes et al using Lycos Rhyme (rhyme.lycos.com)\nrpmsearch       -- Search for RPMs in various distros\nscholar         -- Search Google Scholar (scholar.google.com)\nscicom          -- Search Scientific Commons\nscirus          -- Search for science using Scirus (scirus.com)\nscpan           -- Search the Comprehensive Perl Archive Network (search.cpan.org)\nsearx           -- Search using searx metasearch engine instances (searx.me)\nslashdot        -- Search stories on Slashdot (www.slashdot.org)\nslinuxdoc       -- Search entries in LDP (www.linuxdoc.org)\nsourceforge     -- Search SourceForge (www.sourceforge.net)\nspringer        -- Search Springer for Books and Articles\nstack           -- Search Stack Overflow\nstockquote      -- Get a single stock quote (multiple providers)\nthesaurus       -- Look up word in Merriam-Webster's Thesaurus (www.m-w.com)\ntranslate       -- Translate human languages\nurban           -- Search urbandictionary.com for a definition\nw3css           -- Validate a CSS URL with the w3c CSS validator (jigsaw.w3.org/css-validator)\nw3html          -- Validate a web page URL with the w3c validator (validator.w3.org)\nw3link          -- Check web page links with the w3c linkchecker (validator.w3.org/checklink)\nw3rdf           -- Validate a RDF URL with the w3c RDF validator (validator.w3.org)\nwayback         -- Search The Internet Archive's Wayback Machine for a URL (archive.org)\nwebster         -- Look up word in Merriam-Webster's Dictionary (www.m-w.com)\nwetandwild      -- Real time weather information (many sources)\nwikipedia       -- Search the free encyclopedia wikipedia\nwoffle          -- Search the web using Woffle (localhost:8080)\nwolfram         -- Ask questions of the computational knowledge engine\nworldwidescience -- Search for science with www.worldwidescience.org\nyacy            -- Search YaCy P2P search, including ScienceNet\nyahoo           -- Search Yahoo categories (www.yahoo.com)\nyandex          -- Search the web using Yandex (yandex.ru)\nyoutube         -- Search YouTube (www.youtube.com)\nyubnub          -- Use the social command-line for the web (yubnub.org)\nS supported:\n    500px\n    8tracks\n    aliexpress\n    allocine\n    amazon\n    archpkg\n    archwiki\n    ardmediathek\n    arstechnica\n    arxiv\n    atmospherejs\n    aur\n    baidu\n    bandcamp\n    bgr\n    bigbasket\n    bing\n    brave\n    buzzfeed\n    cnn\n    codepen\n    coursera\n    cplusplus\n    cppreference\n    crates\n    crunchyroll\n    debianpkg\n    dict\n    digg\n    diigo\n    dockerhub\n    dribbble\n    duckduckgo\n    dumpert\n    ecosia\n    engadget\n    explainshell\n    facebook\n    flickr\n    flipkart\n    foursquare\n    freebsdman\n    freshports\n    gibiru\n    giphy\n    gist\n    github\n    gmail\n    go\n    godoc\n    goodreads\n    google\n    googledocs\n    googleplus\n    hackernews\n    idealo\n    ietf\n    ifttt\n    imdb\n    imgur\n    inbox\n    instagram\n    kaufda\n    kickasstorrents\n    libgen\n    linkedin\n    lmgtfy\n    macports\n    magnetdl\n    mdn\n    medium\n    metacpan\n    msdn\n    naver\n    netflix\n    nhaccuatui\n    npm\n    npmsearch\n    npr\n    nvd\n    openbsdman\n    overstock\n    packagist\n    presearch\n    phandroid\n    php\n    pinterest\n    postgresql\n    python\n    quora\n    qwant\n    reddit\n    regex\n    rottentomatoes\n    rubygems\n    shodan\n    soundcloud\n    spotify\n    stackoverflow\n    steam\n    taobao\n    thepiratebay\n    theregister\n    torrentz\n    twitchtv\n    twitter\n    ultimateguitar\n    unity3d\n    upcloud\n    vimeo\n    wikipedia\n    wolframalpha\n    yahoo\n    yandex\n    youtube\n    zdf\n    zhihu"
  },
  {
    "objectID": "posts/8061ab03-a8d7-46d0-9c24-fd4a5bda5cef/index.html#alternatives",
    "href": "posts/8061ab03-a8d7-46d0-9c24-fd4a5bda5cef/index.html#alternatives",
    "title": "conda and its alternatives",
    "section": "alternatives",
    "text": "alternatives\nminiconda\nminiforge, better apple m1 support\nmamba, multithreaded"
  },
  {
    "objectID": "posts/e1418794-0d96-4897-b808-f976e413b1ed/index.html",
    "href": "posts/e1418794-0d96-4897-b808-f976e413b1ed/index.html",
    "title": "use javascript/html/css to create mobile app, simplifying the processing of creating app",
    "section": "",
    "text": "use javascript/html/css to create mobile app, simplifying the processing of creating app\nApache Cordova is an open-source mobile development framework\nre-com A ClojureScript library of reusable components for Reagent"
  },
  {
    "objectID": "posts/6c12fa2b-8f9c-461d-af40-0a789883af23/index.html",
    "href": "posts/6c12fa2b-8f9c-461d-af40-0a789883af23/index.html",
    "title": "dark reader pdf dark theme",
    "section": "",
    "text": "dark reader pdf dark theme\nin order to make pdf dark theme more natural, you can search for “PDF” in dark reader’s source code and inject custom style sheets."
  },
  {
    "objectID": "posts/246d2922-1439-4958-b750-ce559925b507/index.html",
    "href": "posts/246d2922-1439-4958-b750-ce559925b507/index.html",
    "title": "dash api docset reference search",
    "section": "",
    "text": "dash api docset reference search\non non-macos platforms, use zeal instead.\nthe core problem is that after uninstallation of xcode, one cannot launch the Apple Doc Helper or some binary afterwards inside the Apple docset under dash documentation folder. the docset can be copied to this folder automatically by dash but without xcode it cannot be opened."
  },
  {
    "objectID": "posts/794d8fd6-df8e-4edb-bad6-416ba3bef904/index.html",
    "href": "posts/794d8fd6-df8e-4edb-bad6-416ba3bef904/index.html",
    "title": "ddddocr captcha resolve recognition",
    "section": "",
    "text": "ddddocr captcha resolve recognition\ni use rotnet for baidu rotnet captcha resolve. did it work?\nddddocr\ntutorial"
  },
  {
    "objectID": "posts/d2262a8a-d6e6-439f-b602-3857d5d94e40/index.html",
    "href": "posts/d2262a8a-d6e6-439f-b602-3857d5d94e40/index.html",
    "title": "sync notes between multiple platforms/devices",
    "section": "",
    "text": "sync notes between multiple platforms/devices\nmake webhooks or make git get latest HEAD hash every interval and compare"
  },
  {
    "objectID": "posts/065faea9-89e3-46e5-81a4-2de225b495c8/index.html#textdiffuser",
    "href": "posts/065faea9-89e3-46e5-81a4-2de225b495c8/index.html#textdiffuser",
    "title": "disco diffusion and ai art",
    "section": "textdiffuser",
    "text": "textdiffuser\nComfyUI: A powerful and modular stable diffusion GUI.\n\ncivitai is a place for sharing stable diffusion models like anything v5 and surreality and ai arts.\n\nnow you can use controlnet to enhance the generation, give the figure skeleton. huggingface introduction\nkarlo: dalle2 replicate, karlo huggingface space, text to image (can be used for semantic search)\ndalle2-laion\nDiT diffusion with transformer\ncustom diffusion rlhf?\nscribble-diffusion turn sketch into drawings\nstable diffusion on macos\nvideo generation ebsynth\n字体普遍画的很拉 需要用专门的ocr强化训练字体\nfontdiffusion?\nfont-diffusion\nstable diffusion font generating\nfontdesign gan\nhandwrite\ndeep fonts\ndiffusionbee stable diffusion for macos m1\nQQ搜索 异次元的我 免费画画 AI合成 (seems this can only be opened within qq, currently)\nnovel-ai-bot\nhttps://huggingface.co/hakurei/waifu-diffusion，这个ai是可以本地部署的，电脑配置可以的朋友们试试\nnovelai 有泄露的模型\nimagen\ndreambooth\ndalle-mini, with space hosted on huggingface\n中文版DALL-E is not open sourced (yet). it provides api for evaluation\nimport numpy as np\nimport gradio as gr\nimport paddlehub as hub\n\n\nmodel = hub.Module(name='ernie_vilg')\nlanguage_translation_model = hub.Module(name='baidu_translate')\nlanguage_recognition_model = hub.Module(name='baidu_language_recognition')\n\nstyle_list = ['水彩','油画', '粉笔画', '卡通', '蜡笔画', '儿童画', '探索无限']\n\ntips = {\"en\": \"Tips: The input text will be translated into Chinese for generation\", \n        \"jp\": \"ヒント: 入力テキストは生成のために中国語に翻訳されます\", \n        \"kor\": \"힌트: 입력 텍스트는 생성을 위해 중국어로 번역됩니다\"}\n\ncount = 0\n\ndef translate_language(text_prompts):\n    global count\n    try:\n        count += 1\n        tips_text = None\n        language_code = language_recognition_model.recognize(text_prompts)\n        if language_code != 'zh':\n            text_prompts = language_translation_model.translate(text_prompts, language_code, 'zh')\n    except Exception as e:\n        error_text = str(e)\n        return {status_text:error_text, language_tips_text:gr.update(visible=False)}\n    if language_code in tips:\n        tips_text = tips[language_code]\n    else:\n        tips_text = tips['en']\n    if language_code == 'zh':\n        return {language_tips_text:gr.update(visible=False), translated_language:text_prompts, trigger_component: gr.update(value=count, visible=False)}\n    else:\n        return {language_tips_text:gr.update(visible=True, value=tips_text), translated_language:text_prompts, trigger_component:  gr.update(value=count, visible=False)}\n\n        \ndef inference(text_prompts, style_indx):\n  try:\n    style = style_list[style_indx]\n    results = model.generate_image(\n        text_prompts=text_prompts, style=style, visualization=False)\n  except Exception as e:\n    error_text = str(e)\n    return {status_text:error_text, gallery:None}\n  return {status_text:'Success', gallery:results[:6]}\n\n\ntitle=\"ERNIE-ViLG\"\n\ndescription=\"ERNIE-ViLG model, which supports text-to-image task.\"\n\ncss = \"\"\"\n        .gradio-container {\n            font-family: 'IBM Plex Sans', sans-serif;\n        }\n        .gr-button {\n            color: white;\n            border-color: black;\n            background: black;\n        }\n        input[type='range'] {\n            accent-color: black;\n        }\n        .dark input[type='range'] {\n            accent-color: #dfdfdf;\n        }\n        .container {\n            max-width: 730px;\n            margin: auto;\n            padding-top: 1.5rem;\n        }\n        #gallery {\n            min-height: 22rem;\n            margin-bottom: 15px;\n            margin-left: auto;\n            margin-right: auto;\n            border-bottom-right-radius: .5rem !important;\n            border-bottom-left-radius: .5rem !important;\n        }\n        #gallery&gt;div&gt;.h-full {\n            min-height: 20rem;\n        }\n        .details:hover {\n            text-decoration: underline;\n        }\n        .gr-button {\n            white-space: nowrap;\n        }\n        .gr-button:focus {\n            border-color: rgb(147 197 253 / var(--tw-border-opacity));\n            outline: none;\n            box-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);\n            --tw-border-opacity: 1;\n            --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);\n            --tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px var(--tw-ring-offset-width)) var(--tw-ring-color);\n            --tw-ring-color: rgb(191 219 254 / var(--tw-ring-opacity));\n            --tw-ring-opacity: .5;\n        }\n        .footer {\n            margin-bottom: 45px;\n            margin-top: 35px;\n            text-align: center;\n            border-bottom: 1px solid #e5e5e5;\n        }\n        .footer&gt;p {\n            font-size: .8rem;\n            display: inline-block;\n            padding: 0 10px;\n            transform: translateY(10px);\n            background: white;\n        }\n        .dark .footer {\n            border-color: #303030;\n        }\n        .dark .footer&gt;p {\n            background: #0b0f19;\n        }\n        .prompt h4{\n            margin: 1.25em 0 .25em 0;\n            font-weight: bold;\n            font-size: 115%;\n        }\n\"\"\"\n\nblock = gr.Blocks(css=css)\n\nexamples = [\n    [\n        '戴着眼镜的猫',\n        '油画(Oil painting)'\n    ],\n    [\n        'A cat with glasses',\n        '油画(Oil painting)'\n    ],\n    [\n        '眼鏡をかけた猫',\n        '油画(Oil painting)'\n    ],\n    [\n        '안경을 쓴 고양이',\n        '油画(Oil painting)'\n    ],\n    [\n        '日落时的城市天际线,史前遗迹风格',\n        '油画(Oil painting)'\n    ],\n    [\n        '一只猫坐在椅子上，戴着一副墨镜, low poly 风格',\n        '卡通(Cartoon)'\n    ],\n    [\n        'A cat sitting on a chair, wearing a pair of sunglasses, low poly style',\n        '油画(Oil painting)'\n    ],\n    [\n        '猫が椅子に座ってサングラスをかけている、low polyスタイル',\n        '油画(Oil painting)'\n    ],\n    [\n        '고양이 한 마리가 의자에 앉아 선글라스를 끼고 low poly 스타일을 하고 있다',\n        '油画(Oil painting)'\n    ],\n    [\n        '一只猫坐在椅子上，戴着一副墨镜,秋天风格',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '蒙娜丽莎，赛博朋克，宝丽来，33毫米,蒸汽波艺术',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '一只猫坐在椅子上，戴着一副墨镜,海盗风格',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '一条由闪电制成的令人敬畏的龙,概念艺术',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        'An awesome dragon made of lightning, conceptual art',\n        '油画(Oil painting)'\n    ],\n    [\n        '稲妻で作られた畏敬の念を抱かせる竜、コンセプトアート',\n        '油画(Oil painting)'\n    ],\n    [\n        '번개로 만든 경외스러운 용, 개념 예술',\n        '油画(Oil painting)'\n    ],\n    [\n        '梵高猫头鹰,蒸汽波艺术',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '萨尔瓦多·达利描绘古代文明的超现实主义梦幻油画,写实风格',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        '夕阳日落时，阳光落在云层上，海面波涛汹涌，风景，胶片感',\n        '探索无限(Explore infinity)'\n    ],\n    [\n        'Sunset, the sun falls on the clouds, the sea is rough, the scenery is filmy',\n        '油画(Oil painting)'\n    ],\n    [\n        '夕日が沈むと、雲の上に太陽の光が落ち、海面は波が荒く、風景、フィルム感',\n        '油画(Oil painting)'\n    ],\n    [\n        '석양이 질 때 햇빛이 구름 위에 떨어지고, 해수면의 파도가 용솟음치며, 풍경, 필름감',\n        '油画(Oil painting)'\n    ],\n]\n\nwith block:\n    gr.HTML(\n        \"\"\"\n            &lt;div style=\"text-align: center; max-width: 650px; margin: 0 auto;\"&gt;\n              &lt;div\n                style=\"\n                  display: inline-flex;\n                  gap: 0.8rem;\n                  font-size: 1.75rem;\n                  margin-bottom: 10px;\n                  margin-left: 220px;\n                  justify-content: center;\n                \"\n              &gt;\n              &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/187387422-f6c9ccab-7fda-416e-a24d-7d6084c46f67.jpg\" alt=\"Paddlehub\" width=\"40%\"&gt;&lt;/a&gt;\n              &lt;/div&gt; \n              &lt;div\n                style=\"\n                  display: inline-flex;\n                  align-items: center;\n                  gap: 0.8rem;\n                  font-size: 1.75rem;\n                  margin-bottom: 10px;\n                  justify-content: center;\n                \"&gt;\n              &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;h1 style=\"font-weight: 900; margin-bottom: 7px;\"&gt;\n                  ERNIE-ViLG Demo\n              &lt;/h1&gt;&lt;/a&gt;\n              &lt;/div&gt; \n              &lt;p style=\"margin-bottom: 10px; font-size: 94%\"&gt;\n                ERNIE-ViLG is a state-of-the-art text-to-image model that generates\n                images from Chinese text.\n              &lt;/p&gt;\n              &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/188184795-98605a22-9af2-4106-827b-e58548f8892f.png\" alt=\"star Paddlehub\" width=\"100%\"&gt;&lt;/a&gt;\n            &lt;/div&gt;\n        \"\"\"\n    )\n    with gr.Group():\n        with gr.Box():\n            with gr.Row().style(mobile_collapse=False, equal_height=True):\n                text = gr.Textbox(\n                    label=\"Prompt\",\n                    show_label=False,\n                    max_lines=1,\n                    placeholder=\"Enter your prompt, multiple languages are supported now.\",\n                ).style(\n                    border=(True, False, True, True),\n                    rounded=(True, False, False, True),\n                    container=False,\n                )\n\n                btn = gr.Button(\"Generate image\").style(\n                    margin=False,\n                    rounded=(False, True, True, False),\n                )\n        language_tips_text = gr.Textbox(label=\"language tips\", show_label=False, visible=False, max_lines=1)\n        styles = gr.Dropdown(label=\"风格(style)\", choices=['水彩(Watercolor)','油画(Oil painting)', '粉笔画(Chalk drawing)', '卡通(Cartoon)', '蜡笔画(Crayon drawing)', '儿童画(Children\\'s drawing)', '探索无限(Explore infinity)'], value='探索无限(Explore infinity)', type=\"index\")\n        gallery = gr.Gallery(\n            label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n        ).style(grid=[2, 3], height=\"auto\")\n        status_text = gr.Textbox(\n            label=\"处理状态(Process status)\",\n            show_label=True,\n            max_lines=1,\n            interactive=False\n        )\n        trigger_component = gr.Textbox(vaule=\"\", visible=False) # This component is used for triggering inference funtion.\n        translated_language = gr.Textbox(vaule=\"\", visible=False)\n        \n        ex = gr.Examples(examples=examples, fn=translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language], cache_examples=False)\n        ex.dataset.headers = [\"\"]\n\n        \n        text.submit(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\n        btn.click(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\n        trigger_component.change(fn=inference, inputs=[translated_language, styles], outputs=[status_text, gallery])\n        gr.HTML(\n            \"\"\"\n                &lt;div class=\"prompt\"&gt;\n                    &lt;p&gt;&lt;h4&gt;Prompt公式&lt;/h4&gt;\n                    &lt;span&gt; Prompt = [形容词] [主语] ，[细节设定]， [修饰语或者艺术家]。 &lt;/span&gt;\n                    关于各部分的构造方式和效果，可以参考&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe指南&lt;/a&gt;。\n                    更多的模型，请关注&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub 官方Repo &lt;/a&gt;， 如果你觉得不错，请star收藏吧。\n                    &lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\n                    同时，可以在 &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; 上使用免费的GPU体验更多案例。\n                    &lt;/p&gt;   \n               &lt;/div&gt;\n               &lt;div class=\"prompt\"&gt;\n                    &lt;p&gt;&lt;h4&gt;Prompt format&lt;/h4&gt;\n                    &lt;span&gt; Prompt = [adjective] [object], [details], [styles or artists]. &lt;/span&gt;\n                    For more details, please refer to &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe Guide&lt;/a&gt;.\n                    There are more interesting models in PaddleHub, if you think it's great, welcome to star &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub&lt;/a&gt;.\n                    &lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\n                    Besides, you can use free GPU resourses in &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; to enjoy more cases, have fun. \n                    &lt;/p&gt;   \n               &lt;/div&gt;\n                \n           \"\"\"\n        )\n        gr.Markdown(\n            \"\"\"\n在\"探索无限\"的风格模式下，画作的真实风格完全可以由你的prompt来决定。下面是一些参考案例:\n\nIn \"Explore infinity\" style mode, how the image looks like is totally up to your prompt. Below are some cases:\n\n### 复古未来主义风格\n\n| ![00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格.jpg) | ![00472_000_日落时的城市天际线,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_日落时的城市天际线,复古未来主义风格.jpg) |\n| ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格              | 日落时的城市天际线,复古未来主义风格                          |\n\n\n\n### 粉彩朋克风格\n\n| ![00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格.jpg) | ![00029_001_日落时的城市天际线，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00029_001_日落时的城市天际线，粉彩朋克风格.jpg) |\n| ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,粉彩朋克风格                  | 日落时的城市天际线,粉彩朋克风格                              |\n\n### 史前遗迹风格\n\n| ![00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格.jpg) | ![00443_005_日落时的城市天际线,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_日落时的城市天际线,史前遗迹风格.jpg) |\n| ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格                  | 日落时的城市天际线,史前遗迹风格                              |\n\n\n\n\n### 波普艺术风格\n\n| ![00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格.jpg) | ![00434_002_日落时的城市天际线,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_002_日落时的城市天际线,波普艺术风格.jpg) |\n| ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,波普艺术风格                  | 日落时的城市天际线,后世界末日风格                            |\n\n\n\n### 迷幻风格\n\n| ![00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格.jpg) | ![00451_001_日落时的城市天际线,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_001_日落时的城市天际线,迷幻药风格.jpg) |\n| ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,迷幻风格                      | 日落时的城市天际线,迷幻风格                                  |\n\n### &lt;u&gt;[更多内容...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南)([Explore more...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南))&lt;/u&gt;\n\n\n            \"\"\"\n        )\n        gr.HTML('''\n        &lt;div class=\"footer\"&gt;\n                    &lt;p&gt;Model by &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;PaddleHub&lt;/a&gt; and &lt;a href=\"https://wenxin.baidu.com\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;文心大模型&lt;/a&gt; - Gradio Demo by 🤗 Hugging Face\n                    &lt;/p&gt;\n        &lt;/div&gt;\n        ''')\n\nblock.queue(concurrency_count=128).launch()\ntext to image minimal example\nhttps://github.com/jina-ai/discoart\ndalle-2\nstable diffusion as dalle2 alternative\nnvidia provided ai paint tool\ntext to image: https://github.com/lucidrains/imagen-pytorch"
  },
  {
    "objectID": "posts/8d72bcd3-e2f8-4bba-ace3-303120401e72/index.html",
    "href": "posts/8d72bcd3-e2f8-4bba-ace3-303120401e72/index.html",
    "title": "douyin tiktok social media download",
    "section": "",
    "text": "Douyin/Tiktok Social Media Video Download\nvideo download:\nhttps://github.com/Evil0ctal/Douyin_TikTok_Download_API https://github.com/Johnserf-Seed/TikTokDownload https://github.com/rouze-d/tiktok-download https://github.com/CuriousYoda/tiktok-downloader\nvideo api and deduplication:\nhttps://github.com/VideoData/DY-Data\nmany scrapers:\nhttps://github.com/Jack-Cherish/python-spider\nvideo multi download tool:\nhttps://github.com/smalls0098/video-parse-tools\ntiktok scrapers:\nhttps://github.com/drawrowfly/tiktok-scraper\ntiktok api:\nhttps://dteather.com/TikTok-Api/docs/TikTokApi/tiktok.html https://github.com/davidteather/TikTokBot"
  },
  {
    "objectID": "posts/d55ffeb9-11bb-4d25-a8db-de99ccd91894/index.html",
    "href": "posts/d55ffeb9-11bb-4d25-a8db-de99ccd91894/index.html",
    "title": "elo rating system",
    "section": "",
    "text": "elo rating system\nElo rating system is a method for calculating the relative skill levels of players in two-player games such as chess. It is named after its creator Arpad Elo, a Hungarian-American physics professor.\nThe basic idea behind the Elo rating system is that each player is assigned a rating, and the difference between the ratings of two players determines the expected outcome of a match between them. If a higher-rated player wins, their rating will increase, while the rating of the lower-rated player will decrease. If the lower-rated player wins, the opposite will happen. The amount of change in the ratings depends on the difference between the ratings and the result of the match.\nHere is an example of how the Elo rating system can be implemented in Python:\ndef elo_rating(rating1, rating2, k, result):\n    # Calculate the expected score for each player\n    expect1 = 1 / (1 + 10 ** ((rating2 - rating1) / 400))\n    expect2 = 1 / (1 + 10 ** ((rating1 - rating2) / 400))\n \n    # Calculate the new ratings for each player\n    if result == 1:\n        # Player 1 wins\n        rating1 = rating1 + k * (1 - expect1)\n        rating2 = rating2 + k * (0 - expect2)\n    elif result == 0:\n        # Player 2 wins\n        rating1 = rating1 + k * (0 - expect1)\n        rating2 = rating2 + k * (1 - expect2)\n \n    return rating1, rating2\nThis function takes four arguments:\nrating1: The current rating of player 1. rating2: The current rating of player 2. k: The “k-factor”, which determines the amount of change in the ratings. A higher k-factor means more change. result: The result of the match, where 1 indicates a win for player 1 and 0 indicates a win for player 2. The function returns a tuple containing the updated ratings for both players."
  },
  {
    "objectID": "posts/94a2737b-30dc-4140-b35b-9b9f63ae4acc/index.html",
    "href": "posts/94a2737b-30dc-4140-b35b-9b9f63ae4acc/index.html",
    "title": "Mastering System Events: Script Execution with @reboot and systemd",
    "section": "",
    "text": "execute script before & after system events like startup, suspend & shutdown\nfor startup use @reboot with crontab -e\nfor others, write scripts under /lib/systemd/system-*"
  },
  {
    "objectID": "posts/5e2a3f07-a0a6-4d47-a3ac-f11dc4b964cd/index.html",
    "href": "posts/5e2a3f07-a0a6-4d47-a3ac-f11dc4b964cd/index.html",
    "title": "fastapi, celery, task queue, websocket",
    "section": "",
    "text": "fastapi, celery, task queue, websocket\nenable render option trim_blocks and lstrip_blocks with jinja2 to avoid whitespace and indentation nightmare.\n\nalways remember to import uvicorn if you want to run without the uvicorn executable\n\ngenerate nodejs client from openapi.json\nfastapi-code-generator to generate python code\n\ncreate doc inside code: adding metadata\n\nto share lock across process, use redis lock or filelock.\nto share lock across forked process in the same worker, use multiprocessing.Lock()\n\nfastapi can generate openapi json and doc page\nwebsockets are async. will it block the server?\nusing websocket in fastapi\ncelery advance usage\ncelery and fastapi\nhappen to found akismet (proprietary wordpress spam protection). oss alternatives are:\n\nYoutube Spammer Purge\nforget spam comment (js plugin for wordpress)"
  },
  {
    "objectID": "posts/42cd5988-041e-41e4-b6d5-bb24363362da/index.html#speed-up-ffmpeg-encoding",
    "href": "posts/42cd5988-041e-41e4-b6d5-bb24363362da/index.html#speed-up-ffmpeg-encoding",
    "title": "Exploring FFmpeg’s Advanced Encoding, Conversion, and Audio Functionality",
    "section": "speed up ffmpeg encoding",
    "text": "speed up ffmpeg encoding\nffmpeg speedup cli flags\nffmpeg -threads 4 -crf 28 -preset ultrafast"
  },
  {
    "objectID": "posts/3d1b003e-9d7b-4fca-ac02-de76529c12d5/index.html",
    "href": "posts/3d1b003e-9d7b-4fca-ac02-de76529c12d5/index.html",
    "title": "ffmpeg中英文对照 ffmpeg filter reference translated",
    "section": "",
    "text": "ffmpeg中英文对照 ffmpeg filter reference translated\nsource\n对这位仁兄的博客的基础上根据最新的ffmpeg进行了补充https://www.cnblogs.com/nlsoft/p/5195172.html\nVideo Filters\n视频滤镜\n \n ... addroi            V-&gt;V       Mark a region of interest in a video frame.\n                                  在视频帧中标记感兴趣的一段\n ... alphaextract      V-&gt;N       Extract an alpha channel as a grayscale image component.\n                                  从灰度级测视图中提取阿尔法α通道分量.\n ... alphamerge        VV-&gt;V      Copy the luma value of the second input into the alpha channel of the first input.\n                                  使用第一个输入视频的阿尔法α通道分量,添加或替换的第二个输入视频亮度值.\n... amplify                       Amplify differences between current pixel and pixels of adjacent frames in same pixel location.\n                                  放大当前像素与同一像素位置相邻帧像素之间的差异\n TS. atadenoise        V-&gt;V       Apply an Adaptive Temporal Averaging Denoiser.\n                                  自适应时间平均降噪功能应用在输入的视频.\n ... ass               V-&gt;V       Render ASS subtitles onto input video using the libass library.\n                                  使用libass程序库给输入视频渲染ASS字幕.\n ... avgblur           V-&gt;V       Apply average blur filter.\n                                  均匀模糊滤镜\n T.. bbox              V-&gt;V       Compute bounding box for each frame.\n                                  视频的每一个帧上计算边界框.\n ... bilateral         V-&gt;V       Apply bilateral filter, spatial smoothing while preserving edges.\n                                  双边滤波，空间平滑同时保留边缘\n ... bitplanenoise     V-&gt;V       Show and measure bit plane noise.\n                                  显示和测量位平面噪声。\n ... blackdetect       V-&gt;V       Detect video intervals that are (almost) black.\n                                  检测视频中完全(几乎)黑色的时间间隔.\n ... blackframe        V-&gt;V       Detect frames that are (almost) black.\n                                  检测完全(几乎)黑色的帧.\n TS. blend             VV-&gt;V      Blend two video frames into each other.\n                                  两个视频帧混合到另一个帧上.\n ... bm3d                         Denoise frames using Block-Matching 3D algorithm.\n                                  使用块匹配3D算法去噪帧\n T.. boxblur           V-&gt;V       Blur the input.\n                                  模糊处理输入视频.\n ... bwdif                        Deinterlace the input video (\"bwdif\" stands for \"Bob Weaver Deinterlacing Filter\").                         对输入视频进行去隔行处理\n ... cas                          Apply Contrast Adaptive Sharpen filter to video stream.\n                                  对视频流添加对比度自适应锐化滤波器。\n ... chromahold                   Remove all color information for all colors except for certain one.\n                                  除去除某一颜色外的所有颜色信息。\n \n TS. chromakey         V-&gt;V       Turns a certain color into transparency. Operates on YUV colors.\n                                  在YUV颜色空间中针对一些颜色做透明处理,应用与抠图功能,比 colorkey 滤镜边界更柔和.\n ... chromashift       V-&gt;V       Shift chroma pixels horizontally and/or vertically.\n                                  水平和/或垂直移动色度像素。\n ... ciescope          V-&gt;V       Display CIE color diagram with pixels overlaid onto it.\n                                  显示CIE彩色图表\n T.. codecview         V-&gt;V       Visualize information about some codecs.\n                                  导出一些解码器的可视化信息.\n T.. colorbalance      V-&gt;V       Adjust the color balance.\n                                  修改输入帧的三原色(红、绿、蓝)信号亮度.\n T.. colorchannelmixer V-&gt;V       Adjust colors by mixing color channels.\n                                  调整输入视频帧的混合颜色通道.\n TS. colorkey          V-&gt;V       Turns a certain color into transparency. Operates on RGB colors.\n                                  在RGB颜色空间中针对一些颜色做透明处理,边界较为生硬.\n ... colorhold         V-&gt;V       Remove all color information for all RGB colors except for certain one.\n                                  删除除特定颜色外的所有RGB颜色的所有颜色信息。\n T.. colorlevels       V-&gt;V       Adjust the color levels.\n                                  调整输入视频帧的颜色信号电平.\n TS. colormatrix       V-&gt;V       Convert color matrix.\n                                  转换颜色矩阵.\n ... colorspace        V-&gt;V       Convert colorspace, transfer characteristics or color primaries. Input video needs to have an even size.       转换色彩空间，转移特征或原色。输入视频需要有一个均匀的大小。=\n T.. convolution       V-&gt;V       Apply convolution filter.\n                                  使用卷积3x3或5x5滤镜,适用于锐化,模糊,边缘增强,边缘检测和浮雕等处理.\n ... convolve          V-&gt;V       Apply 2D convolution of video stream in frequency domain using second stream as impulse.                          以第二流做为脉冲，在频域内对视频流进行二维卷积。\n ... copy              V-&gt;V       Copy the input video unchanged to the output.\n                                  复制输入视频,原封不动输出,主要是用于测试目的.\n ... coreimage         V-&gt;V       Video filtering on GPU using Apple’s CoreImage API on OSX.\n                                  使用苹果的CoreImage API在OSX上通过GPU进行视频过滤。\n ... cover_rect        V-&gt;V       Find and cover a user specified object.\n                                  查找并覆盖用户指定的矩形对象.\n ..C crop              V-&gt;V       Crop the input video to given dimensions.\n                                  剪切输入视频显示区域,并给于新的尺寸.\n T.. cropdetect        V-&gt;V       Auto-detect crop size.\n                                  自动检测剪切大小.\n ... cue               V-&gt;V       Delay video filtering until a given wallclock timestamp.\n                                  将视频滤波延迟到指定的时间戳。\n TS. curves            V-&gt;V       Adjust components curves.\n                                  利用曲线功能调整颜色分量,也可以利用图象处理软件的曲线文件来处理颜色.\n ... datascope         V-&gt;V       This filter shows hexadecimal pixel values of part of video.\n                                  该滤波器显示部分视频的十六进制像素值。\n TS. dctdnoiz          V-&gt;V       Denoise frames using 2D DCT.\n                                  使用二维频域过滤(2D DCT)对帧进行降噪处理.\n TS. deband            V-&gt;V       Debands video, Remove banding artifacts from input video.\n                                  从输入视频中移除带状伪像.\n ... deblock           V-&gt;V       Remove blocking artifacts from input video.\n                                  从输入视频中移除阻塞工件。\n ... decimate          N-&gt;V       Decimate frames (post field matching filter).\n                                  定期删除重复的帧(后场匹配滤镜).\n ... deconvolve        V-&gt;V       Apply 2D deconvolution of video stream in frequency domain using second stream as impulse.                          以第二流为脉冲，在频域内对视频流进行二维反褶积。\n ... dedot             V-&gt;V       Reduce cross-luminance (dot-crawl) and cross-color (rainbows) from video.\n                                  减少交叉亮度(点爬行)和交叉颜色(彩虹)从视频。\n T.. deflate           V-&gt;V       Apply deflate effect.\n                                  适用于紧缩效果.\n ... deflicker         V-&gt;V       Remove temporal frame luminance variations.\n                                  删除时间帧亮度变化。\n ... dejudder          V-&gt;V       Remove judder produced by pullup.\n                                  删除动作产生的部分颤抖.\n T.. delogo            V-&gt;V       Remove logo from input video.\n                                  对指定区域做模糊处理,比如能移除输入视频中的标识.\n ... derain            V-&gt;V       Remove the rain in the input image/video by applying the derain methods based on convolutional neural networks.    采用基于卷积神经网络的去雨方法对输入图像/视频进行去雨处理。\n ... deshake           V-&gt;V       Stabilize shaky video.\n                                  试图修改水平或垂直的移位,降低颤抖让视频更稳定,这个滤镜有助于减小手持相机抖动影响.\n ... despill           V-&gt;V       Remove unwanted contamination of foreground colors, caused by reflected color of greenscreen or bluescreen.        清除前景色中由绿幕或蓝幕的反射色所引起的不必要的污染。\n ... detelecine        V-&gt;V       Apply an inverse telecine pattern.\n                                  适用于电视电影的精确反向操作,颜色边界有锯齿效果.\n T.. dilation          V-&gt;V       Apply dilation effect.\n                                  膨胀效果应用于视频.\n T.. displace          VVV-&gt;V     Displace pixels.\n                                  移走像素,需要三个视频输入流和一个视频输出流,第一个输入源,第二和第三个输入位移的映射.\n ... dnn_processing    V-&gt;V       Do image processing with deep neural networks.\n                                  使用深度神经网络进行图像处理。它与另一个过滤器一起工作，将帧的像素格式转换成dnn网络所需的格式。\n T.. drawbox           V-&gt;V       Draw a colored box on the input video.\n                                  输入视频图像上绘制彩色的矩形区域.\n ... drawgraph         V-&gt;V       Draw a graph using input video metadata.\n                                  利用输入视频的元数据绘制图表.\n T.. drawgrid          V-&gt;V       Draw a colored grid on the input video.\n                                  在输入视频上绘制彩色网格.\n T.C drawtext          V-&gt;V       Draw text on top of video frames using libfreetype library.\n                                  使用 libfreetype 程序库,在顶层帧上绘制文本字符串,文本内容可从指定文件中读取.\n T.. edgedetect        V-&gt;V       Detect and draw edge.\n                                  检测并绘制边缘.\n ... elbg              V-&gt;V       Apply posterize effect, using the ELBG algorithm.\n                                  使用增强型LBG(ELBG)算法,用于多色调分色印效果.\n ... entropy           V-&gt;V       Measure graylevel entropy in histogram of color channels of video frames.\n                                  测量视频帧颜色通道直方图中的灰度熵。\n ..C eq                V-&gt;V       Adjust brightness, contrast, gamma, and saturation.\n                                  调整亮度、对比度、灰度和饱和度.\n T.. erosion           V-&gt;V       Apply erosion effect.\n                                  侵蚀效果应用于视频,类似油画处理.\n ... extractplanes     V-&gt;N       Extract planes as grayscale frames.\n                                  从输入视频流中提取颜色通道分量用在单独灰度视频流的帧上.\n .S. fade              V-&gt;V       Fade in/out input video.\n                                  适用于输入视频的淡入/淡出效果.\n ... fftdnoiz          V-&gt;V       Denoise frames using 3D FFT (frequency domain filtering).\n                                  使用3D FFT(频域滤波)去噪帧。\n ... fftfilt           V-&gt;V       Apply arbitrary expressions to pixels in frequency domain.\n                                  频域内将任意表达式用于采样的像素集.\n ... field             V-&gt;V       Extract a field from the input video.\n                                  使用步进算法,从输入视频里的隔行图像中提取单场.\n ... fieldhint         V-&gt;V       Create new frames by copying the top and bottom fields from surrounding frames supplied as numbers by the hint file. 通过拷贝由提示文件作为数字提供的周围帧的顶部和底部字段来创建新的帧。\n ... fieldmatch        N-&gt;V       Field matching for inverse telecine.\n                                  场匹配滤镜适用于电视电影的反向操作.\n T.. fieldorder        V-&gt;V       Set the field order.\n                                  改变输入视频的场顺序.\n ... fifo,afifo        V-&gt;V       Buffer input images and send them when they are requested.\n                                  缓冲输入的图像并在需要时发送它们\n ... fillborders       V-&gt;V       Fill borders of the input video, without changing video stream dimensions.\n                                  填充输入视频的边框，不改变视频流的大小。\n ... find_rect         V-&gt;V       Find a user specified object.\n                                  寻找用户指定的矩形区域.\n ... floodfill         V-&gt;V       Flood area with values of same pixel components with another values.\n ... format            V-&gt;V       Convert the input video to one of the specified pixel formats.\n                                  输入视频转换为指定的像素格式.\n ... fps               V-&gt;V       Force constant framerate.\n                                  强制设定固定帧频.\n ... framepack         VV-&gt;V      Generate a frame packed stereoscopic video.\n                                  生成帧叠加的立体视频.\n ... framerate         V-&gt;V       Upsamples or downsamples progressive source between specified frame rates.\n                                  上采样或下采样顺序渐进的视频源之间设定指定帧频.\n T.. framestep         V-&gt;V       Select one frame every N frames.\n                                  每 N 个帧中选一个帧,设置帧步.\n ... freezedetect      V-&gt;V       Detect frozen video\n                                  检测不变帧\n ... freezeframes      V-&gt;V       Freeze video frames\n                                  冻结视频帧\n ... frei0r            V-&gt;V       Apply a frei0r effect.\n                                  使用 frei0r 滤镜.\n T.. fspp              V-&gt;V       Apply Fast Simple Post-processing filter.\n                                  用于快速和简单的后处理滤镜.\n ... gblur             V-&gt;V       Apply Gaussian blur filter\n                                  应用高斯模糊滤镜\n T.. geq               V-&gt;V       Apply generic equation to each pixel.\n                                  利用一般表达式改变每个像素点的特征.\n T.. gradfun           V-&gt;V       Debands video quickly using gradients.\n                                  利用梯度快速移除带状伪像.\n ... graphmonitor      V-&gt;V       Show various filtergraph stats\n                                  监视各种图表的统计信息\n ... greyedge          V-&gt;V       A color constancy variation filter which estimates scene illumination via grey edge algorithm and corrects the scene colors accordingly.\n                                  利用灰度边缘算法估计场景光照的颜色恒常性变异滤波器，并对场景颜色进行相应的校正。\n TS. haldclut          VV-&gt;V      Adjust colors using a Hald CLUT.\n                                  利用哈尔德查色表调整颜色.\n .S. hflip             V-&gt;V       Horizontally flip the input video.\n                                  水平翻转显示输入视频.\n T.. histeq            V-&gt;V       Apply global color histogram equalization.\n                                  适用于全局颜色直方图均衡化.\n ... histogram         V-&gt;V       Compute and draw a histogram.\n                                  计算并绘制颜色分布直方图.\n T.. hqdn3d            V-&gt;V       Apply a High Quality 3D Denoiser.\n                                  使用高质量三维降噪滤镜.\n ... hwmap             V-&gt;V       Map hardware frames to system memory or to another \ndevice.                           将帧映射到系统内存或者另一个设备\n ... hwupload          V-&gt;V       Upload system memory frames to hardware surfaces.\n                                  将内存中的帧上传至硬件接口\n ... hwupdoad_cuda     V-&gt;V       Upload system memory frames to a CUDA device.\n                                  将内存中的帧上传至CUDA设备\n .S. hqx               V-&gt;V       Scale the input by 2, 3 or 4 using the hq*x magnification algorithm.          利用高质量放大算法缩放视频显示大小,可输入2,3或4.\n ... hstack            N-&gt;V       Stack video inputs horizontally.\n                                  把若干个输入视频合并到一个水平显示的输出视频.\n T.C hue               V-&gt;V       Adjust the hue and saturation of the input video.\n                                  调整输入视频的色相和饱和度.\n ... hysteresis        V-&gt;V       Grow first stream into second stream by connecting components.                       这个不太理解\n ... idet              V-&gt;V       Interlace detect Filter.\n                                  检测视频的交叉类型滤镜.\n T.. il                V-&gt;V       Deinterleave or interleave fields.\n                                  允许处理不交叉的隔行图像场.\n T.. inflate           V-&gt;V       Apply inflate effect.\n                                  膨胀效果用于视频.\n ... interlace         V-&gt;V       Convert progressive video into interlaced.\n                                  转化为分段视频用于隔行处理,颜色边界有锯齿效果.\n ... interleave        N-&gt;V       Temporally interleave video inputs.\n                                  能执行时间场交叉的各种类型.\n ... kerndeint         V-&gt;V       Apply kernel deinterlacing to the input.\n                                  对输入的视频进行内核反交叉处理.\n ... lagfun            V-&gt;V       Slowly update darker pixels.\n                                  缓慢更新黑色像素，滤镜使短暂的闪光显得更长\n .S. lenscorrection    V-&gt;V       Rectify the image by correcting for lens distortion.\n                                  矫正图像用于校正透镜畸变.\n ... lensfun           V-&gt;V       Apply lens correction via the lensfun library\n                                  通过lensfun库应用镜头校正\n ... libvmaf           V-&gt;V       Obtain the VMAF (Video Multi-Method Assessment Fusion) score between two input videos.   得到两个输入视频之间的(VMAF 多方法评估视频相融合)分数。\n ... limiter           V-&gt;V       Limits the pixel components values to the specified range [min, max].                 将像素分量的值限制在指定的范围内\n ... loop              V-&gt;V       Loop video frames.\n                                  循环视频帧\n ... lut1d             V-&gt;V       Apply a 1D LUT to an input video.\n                                  利用已维查色表调整颜色.\n TS. lut3d             V-&gt;V       Adjust colors using a 3D LUT.\n                                  利用三维查色表调整颜色.\n ... lumakey           V-&gt;V       Turn certain luma values into transparency.\n                                  将某些亮度值转化为透明度\n T.. lut               V-&gt;V       Compute and apply a lookup table to the RGB/YUV input video.\n                                  利用查表计算处理 RGB/YUV 格式输入的视频.\n T.. lutrgb            V-&gt;V       Compute and apply a lookup table to the RGB input video.\n                                  利用查表计算处理 RGB 格式输入的视频.\n T.. lutyuv            V-&gt;V       Compute and apply a lookup table to the YUV input video.                   \n                                  利用查表计算处理 YUV 格式输入的视频.\n ... maskedclamp       VV-&gt;V      Clamp the first input stream with the second input and third input stream.               用第二输入流和第三输入流固定第一输入流    \n T.. maskedmerge       VVV-&gt;V     Merge first stream with second stream using third stream as mask.                   合并前二个输入视频,掩模到第三个输入视频,透明合并三个视频.\n ... maskfun           V-&gt;V       Create mask from input video.\n                                                                  \n ... mcdeint           V-&gt;V       Apply motion compensating deinterlacing.\n                                  适用于运动补偿反交叉.\n ... median            V-&gt;V       Pick median pixel from certain rectangle defined by radius.                           从某个由半径定义的矩形中选择中值像素\n ... mergeplanes       N-&gt;V       Merge planes.\n                                  合并多个视频流的颜色通道分量.\n ... mestimate         V-&gt;V       Estimate and export motion vectors using block matching algorithms                        使用块匹配算法估计和导出运动矢量\n T.. metadata          V-&gt;V       Manipulate video frame metadata.\n                                  操作视频帧的元数据,用于调试.\n ... midequalizer                 Apply Midway Image Equalization effect using two video streams.                          用两个视频流应用中间图像均衡效果。\n ... miniterpolate     V-&gt;V       Convert the video to specified frame rate using motion interpolation.                    使用运动插值将视频转换为指定的帧率。\n ... mix               VVV-&gt;V     Mix several video input streams into one video stream.\n                                  将多个视频输入流混合到一个视频流中。\n ... mpdecimate        V-&gt;V       Remove near-duplicate frames.\n                                  移除近似重复的帧.\n T.. negate            V-&gt;V       Negate input video.\n                                  取消输入视频的阿尔法通道分量,滤镜效果类似底片.\n ... nlmeans           V-&gt;V       Denoise frames using Non-Local Means algorithm.\n                                  使用非局部均值算法对帧进行去噪。\n T.. nnedi             V-&gt;V       Apply neural network edge directed interpolation intra-only deinterlacer.\n                                  使用神经网络边缘插值法进行反隔行处理,需要加权重的二进制文件.\n ... noformat          V-&gt;V       Force libavfilter not to use any of the specified pixel formats for the input to the next filter.\n                                  取消指定的像素格式,用于下一个滤镜.\n TS. noise             V-&gt;V       Add noise.\n                                  视频输入帧上添加噪声.\n ... null              V-&gt;V       Pass the source unchanged to the output.\n                                  不改变视频源进行输出.\n ... ocv               V-&gt;V       Apply a video transform using libopencv.\n                                  使用libopencv应用视频转换\n ... oscilloscope      V-&gt;V       2D Video Oscilloscope.\n                                  2D视频示波器。\n T.C overlay           VV-&gt;V      Overlay a video source on top of the input.\n                                  把一个视频覆盖到另一个视频上面,需要两个输入和一个输出.\n T.. owdenoise         V-&gt;V       Denoise using wavelets.\n                                  利用小波降噪法进行降噪处理.\n ... pad               V-&gt;V       Pad the input video.\n                                  给输入视频添加填充新的显示区域.\n ... palettegen        V-&gt;V       Find the optimal palette for a given stream.\n                                  生成最佳调色板,用于给定的视频流.\n ... paletteuse        VV-&gt;V      Use a palette to downsample an input video stream.\n                                  下采样输入视频流中使用调色板,适用于生成 GIF 动态图.\n ... perms             V-&gt;V       Set permissions for the output video frame.\n                                  给输出视频帧设置读/写权限.\n TS. perspective       V-&gt;V       Correct the perspective of video.\n                                  校正视频的透视.\n T.. phase             V-&gt;V       Phase shift fields.\n                                  对隔行视频延迟单场时间,便于场序的变化.\n ... photosensitivity  V-&gt;V       Reduce various flashes in video, so to help users with epilepsy.                         减少视频中各种闪烁，\n ... pixdesctest       V-&gt;V       Test pixel format definitions.\n                                  像素格式描述符测试滤镜,主要用于内部测试.\n ... pixscope          V-&gt;V       Display sample values of color channels. Mainly useful for checking color and levels.    显示颜色通道的采样值。主要用于检查颜色和水平。\n T.C pp                V-&gt;V       Filter video using libpostproc.\n                                  使用 libpostproc 后处理程序库进行过滤.\n T.. pp7               V-&gt;V       Apply Postprocessing 7 filter.\n                                  使用后处理滤镜7.\n ... psnr              VV-&gt;V      Calculate the PSNR between two video streams.\n                                  计算两个视频流之间的峰值信噪比(PSNR).\n ... pullup            V-&gt;V       Pullup from field sequence to frames.\n                                  折叠场序用于输出帧,退回到电视电影效果.\n T.. qp                V-&gt;V       Change video quantization parameters.\n                                  改变视频量化参数(QP).\n ... random            V-&gt;V       Return random frames.\n                                  从内部缓存刷新出视频帧的随机帧.\n ... realtime          V-&gt;V       Slow down filtering to match realtime.\n                                  减慢过滤速度,接近实时效果.\n TS. removegrain       V-&gt;V       Remove grain.\n                                  移除纹理,对步进视频进行降噪处理.\n T.. removelogo        V-&gt;V       Remove a TV logo based on a mask image.\n                                  利用掩模图像移除电视徽标,掩模图像的大小必须与视频相同,黑色是透明.\n ... repeatfields      V-&gt;V       Hard repeat fields based on MPEG repeat field flag.\n                                  根据运动图象专家组(MPEG)重复场标志,硬执行重复场.\n ... reverse           V-&gt;V       Reverse a clip.\n                                  倒放一段视频片段,需要把整个片段装入内存缓冲区.\n ... rgbashift         V-&gt;V       Shift R/G/B/A pixels horizontally and/or vertically.\n                                  水平或垂直移动R/G/B/A像素。\n TSC rotate            V-&gt;V       Rotate the input image.\n                                  任意角度旋转视频,用弧度表示的单位.\n T.. sab               V-&gt;V       Apply shape adaptive blur.\n                                  形状自适应模糊滤镜.\n ..C scale             V-&gt;V       Scale the input video size and/or convert the image format.                          \n                                  缩放输入视频的尺寸并/或改变图像格式,使用libswscale库. \n ... scale_npp         V-&gt;V       Use the NVIDIA Performance Primitives (libnpp) to perform scaling and/or pixel format conversion on CUDA video frames.\n                                  使用NVIDIA Performance Primitives (libnpp)在CUDA视频帧上执行缩放和/或像素格式转换。\n \n ..C scale2ref         VV-&gt;VV     Scale the input video size and/or convert the image format to the given reference.\n                                  缩放输入视频的尺寸并/或改变图像格式用于引用视频,使用libswscale库.\n ... scroll                       Scroll input video horizontally and/or vertically by constant speed.                    以恒定的速度垂直或者水平滚动输入视频\n ... select            V-&gt;N       Select video frames to pass in output.\n                                  选择视频帧用于下一个滤镜.\n TS. selectivecolor    V-&gt;V       Apply CMYK adjustments to specific color ranges.\n                                  利用青色,品红色,黄色和黑色(CMYK)调整特定范围的颜色.\n ... sendcmd           V-&gt;V       Send commands to filters.\n                                  给滤镜发送命令,必须插入到两个视频之间,只对具有该功能的滤镜命令有效.\n ... separatefields    V-&gt;V       Split input video frames into fields.\n                                  分解输入视频帧进场,产生一个新的一半高度剪辑帧.\n ... setdar            V-&gt;V       Set the frame display aspect ratio.\n                                  设置视频的显示纵横比.\n ... setfield          V-&gt;V       Force field for the output video frame.\n                                  改变输出视频帧的属性,不改变视频帧的数据.\n ... setpts            V-&gt;V       Set PTS for the output video frame.\n                                  设置输出视频帧的显示时间戳(PTS),可以用于快放或慢放等.\n ... setsar            V-&gt;V       Set the pixel sample aspect ratio.\n                                  设置像素采样纵横比.\n ... settb             V-&gt;V       Set timebase for the video output link.\n                                  设置时间轴用于视频输出帧的时间戳,主要用于测试时间轴配置.\n ... showinfo          V-&gt;V       Show textual information for each video frame.\n                                  显示每个视频帧的文本信息.\n T.. showpalette       V-&gt;V       Display frame palette.\n                                  显示每一帧的 256 色调色板.\n T.. shuffleframes     V-&gt;V       Shuffle video frames.\n                                  打乱视频帧,重新排序和/或重复视频帧.\n ... shuffleplanes     V-&gt;V       Shuffle video planes.\n                                  打乱视频映射平面,重新排序和/或重复视频映射平面.\n .S. signalstats       V-&gt;V       Generate statistics from video analysis.\n                                  分析视频过程中生成统计信息.\n T.. smartblur         V-&gt;V       Blur the input video without impacting the outlines.\n                                  模糊处理输入视频而不影响轮廓.\n ... split             V-&gt;N       Pass on the input to N video outputs.\n                                  输入的视频分配给N个相同的视频输出.\n T.C spp               V-&gt;V       Apply a simple post processing filter.\n                                  简单的后处理滤镜,设置压缩品质对视频进行压缩.\n ... ssim              VV-&gt;V      Calculate the SSIM between two video streams.\n                                  计算两个输入视频之间的结构相似度(SSIM).\n .S. stereo3d          V-&gt;V       Convert video stereoscopic 3D view.\n                                  视频转换成具有不同立体图像格式的三维视觉视频.\n ..C streamselect      N-&gt;N       Select video streams\n                                  多个输入视频流中选择一个视频流,若干个具有相同时间长度的媒体有效.\n ... subtitles         V-&gt;V       Render text subtitles onto input video using the libass library.\n                                  使用 libass 程序库输入视频上绘制字幕.\n ... super2xsai        V-&gt;V       Scale the input by 2x using the Super2xSaI pixel art algorithm.\n                                  利用像素艺术扩展算法把输入视频平滑放大两倍.\n T.. swaprect          V-&gt;V       Swap 2 rectangular objects in video.\n                                  视频流中交换两个矩形对象.\n ... swapuv            V-&gt;V       Swap U and V components.\n                                  交换 U 和 V 映射平面分量.\n .S. tblend            V-&gt;V       Blend successive frames.\n                                  两个视频帧混合到另一个帧上.\n ... telecine          V-&gt;V       Apply a telecine pattern.\n                                  使用电视电影模式,颜色边界有锯齿效果.\n ... thistogram        V-&gt;V       Compute and draw a color distribution histogram for the input video across time.          不仅可以显示当前的，还可以显示过去的，对比histogram\n ... thumbnail         V-&gt;V       Select the most representative frame in a given sequence of consecutive frames.\n                                  在给定的连续帧序列中选择具有代表性帧.\n ... tile              V-&gt;V       Tile several successive frames together.\n                                  瓦状布局若干个连续的帧,类似视频缩略图.\n ... tinterlace        V-&gt;V       Perform temporal field interlacing.\n                                  使用不同的隔行模式处理每一个帧.\n .S. transpose         V-&gt;V       Transpose input video.\n                                  翻转输入视频,默认垂直翻转.\n ... trim              V-&gt;V       Pick one continuous section from the input, drop the rest.\n                                  从输入视频中挑选连续的组成部分,一直到结束.\n T.. unsharp           V-&gt;V       Sharpen or blur the input video.\n                                  锐化或模糊处理输入视频.\n T.. uspp              V-&gt;V       Apply Ultra Simple / Slow Post-processing filter.\n                                  超慢/简单的后处理滤镜,设置压缩品质对视频进行压缩.\n ... vectorscope       V-&gt;V       Video vectorscope.\n                                  显示输入视频的两个颜色分量值的二维图(矢量显示).\n ... vflip             V-&gt;V       Flip the input video vertically.\n                                  垂直翻转显示输入视频.\n ... vidstabdetect     V-&gt;V       Extract relative transformations,for stabilization.\n                                  提取视频的相对地变化,绘制矩形图矩阵内的箭头方向来显示变化趋势.\n ... vidstabtransform  V-&gt;V       Video stabilization/deshaking.\n                                  平滑/反锐化处理视频.\n T.. vignette          V-&gt;V       Make or reverse a vignette effect.\n                                  生成或扭转镜头自然渐晕效果.\n ... vstack            N-&gt;V       Stack video inputs vertically.\n                                  把若干个输入视频垂直放置,所有视频的像素格式和宽度必须相同.\n TS. w3fdif            V-&gt;V       Apply Martin Weston three field deinterlace.\n                                  使用马丁韦斯顿三场反隔行滤镜。\n ... waveform          V-&gt;V       Video waveform monitor.\n                                  视频波形监视器.\n .S. xbr               V-&gt;V       Scale the input using xBR algorithm.\n                                  应用xBR算法放大输入视频,默认是放大三倍.\n TS. yadif             V-&gt;V       Deinterlace the input image.\n                                  对输入图像进行反隔行处理.\n T.. zoompan           V-&gt;V       Apply Zoom & Pan effect.\n                                  用于缩放和填充效果.\n ..C zscale            V-&gt;V       Apply resizing, colorspace and bit depth conversion.\n                                  用于重新调整大小,改变色隙和色彩深度.\n ... allrgb            |-&gt;V       Generate all RGB colors.\n                                  生成大小为 4096x4096 的包含所有 RGB 颜色表,需要大量内存.\n ... allyuv            |-&gt;V       Generate all yuv colors.\n                                  生成大小为 4096x4096 的包含所有 yuv 颜色表,需要大量内存.\n ... cellauto          |-&gt;V       Create pattern generated by an elementary cellular automaton.\n                                  利用初级多孔自动生成器创建一个图案,指定模式生成无数小三角形矩阵.\n ..C color             |-&gt;V       Provide an uniformly colored input.\n                                  提供了一个单色输入视频源.\n ... frei0r_src        |-&gt;V       Generate a frei0r source.\n                                  提供frei0r接口,frei0r是ffmpeg的子滤镜.\n ... haldclutsrc       |-&gt;V       Provide an identity Hald CLUT.\n                                  给哈尔德查色表源提供单位特征.\n ... life              |-&gt;V       Create life.\n                                  生成随机花纹的图案.\n ... mandelbrot        |-&gt;V       Render a Mandelbrot fractal.\n                                  生成一个曼德尔勃特集合分形,逐渐放大到指定点.\n ... mptestsrc         |-&gt;V       Generate various test pattern.\n                                  生成各种测试图案,静/动态小方块矩阵和圆形图案.\n ... nullsrc           |-&gt;V       Null video source, return unprocessed video frames.\n                                  生成空视频源,返回未处理的空视频帧.\n ... rgbtestsrc        |-&gt;V       Generate RGB test pattern.\n                                  生成 RGB 测试图案,横向红绿蓝三条图案.\n ... smptebars         |-&gt;V       Generate SMPTE color bars.\n                                  生成 SMPTE 颜色条图案,像电视测试信号视频.\n ... smptehdbars       |-&gt;V       Generate SMPTE HD color bars.\n                                  生成 SMPTE HD 颜色条图案.\n ... testsrc           |-&gt;V       Generate test pattern.\n                                  生成测试图案.\n ... testsrc2          |-&gt;V       Generate another test pattern.\n                                  生成另一个测试图案.\n ... nullsink          V-&gt;|       Do absolutely nothing with the input video.\n                                  生成空视频模板,与输入视频无关.\n ... concat            N-&gt;N       Concatenate audio and video streams.\n                                  连接音频和视频流.\n ... movie             |-&gt;N       Read from a movie source.\n                                  从视频源读入视频.\n ... buffer            |-&gt;V       Buffer video frames, and make them accessible to the filterchain.\n                                  缓冲视频帧,并用于滤镜链.\n ... buffersink        V-&gt;|       Buffer video frames, and make them available to the end of the filter graph.\n                                  缓冲视频帧,并用于滤镜图的结束.\n ... fifo              V-&gt;V       Buffer input images and send them when they are requested.\n                                  缓冲输入帧,若需要时."
  },
  {
    "objectID": "posts/789b6450-50e9-4edc-a55d-4423e42b3796/index.html",
    "href": "posts/789b6450-50e9-4edc-a55d-4423e42b3796/index.html",
    "title": "filesystem cache",
    "section": "",
    "text": "filesystem cache\ncatfs in rust\nrclone supports ‘cache’ backend for remote cache"
  },
  {
    "objectID": "posts/07dc6fbe-ccc9-43df-968a-39b9d62968b4/index.html",
    "href": "posts/07dc6fbe-ccc9-43df-968a-39b9d62968b4/index.html",
    "title": "python diagram/flowchart generator and markdown to word converter",
    "section": "",
    "text": "python diagram/flowchart generator and markdown to word converter\npyflowchart\ndiagrams needs graphviz installed (on debian it is apt install graphviz). doc\npydiagrams"
  },
  {
    "objectID": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#计算句子相关度-计算下一句话的可能性-predict-next-sentence-probability",
    "href": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#计算句子相关度-计算下一句话的可能性-predict-next-sentence-probability",
    "title": "mitmchat",
    "section": "计算句子相关度 计算下一句话的可能性 predict next sentence probability",
    "text": "计算句子相关度 计算下一句话的可能性 predict next sentence probability\nbing search entries\nnext sentence prediction using bert\ngithub topic next semtence prediction"
  },
  {
    "objectID": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#grammar-checker-sentence-corrector",
    "href": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#grammar-checker-sentence-corrector",
    "title": "mitmchat",
    "section": "grammar checker, sentence corrector",
    "text": "grammar checker, sentence corrector\nlanguagetool rule based grammar error checker repo"
  },
  {
    "objectID": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#chatterbot-retrain-issue",
    "href": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#chatterbot-retrain-issue",
    "title": "mitmchat",
    "section": "chatterbot retrain issue",
    "text": "chatterbot retrain issue\ntrain chatterbot with the recent knowledge\nsql schema:\n\n\n\nend_of_list\ncontent\n\n\n\n\nfalse\nsome text content\n\n\nfalse\nsome text content\n\n\ntrue\n2022-01-03"
  },
  {
    "objectID": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#additional-notices-about-delivery-efficiency",
    "href": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#additional-notices-about-delivery-efficiency",
    "title": "mitmchat",
    "section": "additional notices, about delivery efficiency",
    "text": "additional notices, about delivery efficiency\n正在刷屏的群里面也不能发消息 不能确保对象是否收到消息\nYukio 12:46:35 今天mitm有个问题\nYukio 12:46:43 mitm的两个人\nYukio 12:46:48 都不能屏蔽我\nYukio 12:46:53 不然mitm失效\nYukio 12:47:22 但是我现在不知道这个怎么看别人屏蔽我没有\nYukio 12:47:28 可能以后就知道了\nYukio 12:49:17 我可以获取群禁言情况"
  },
  {
    "objectID": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#mitmchat-with-video-and-text-how-to-get-embedding",
    "href": "posts/492e5eb0-b547-47b9-a3fc-8dfb5d455fcc/index.html#mitmchat-with-video-and-text-how-to-get-embedding",
    "title": "mitmchat",
    "section": "mitmchat with video and text how to get embedding?",
    "text": "mitmchat with video and text how to get embedding?\nYukio 18:40:25 mitmchat的定义\nYukio 18:41:31 在同一个时间段内 把正在讨论相同话题 但是不认识的两个人 互相传话一段时间并断开\nYukio 18:42:28 多个mitmchat的定义\nYukio 18:43:26 多个mitm的话 所有被mitm的对象\nYukio 18:43:33 都不能相互认识\nYukio 18:43:56 也就是两两不认识 两两不在同一个群里面\nYukio 18:44:40 delayed mitmchat\nYukio 18:45:08 也就是a和b不在同一个时间段内\nYukio 18:45:22 根据b现在的内容\nYukio 18:45:29 回复a之前的内容\nYukio 18:47:46 所有的mitmchat\nYukio 18:47:57 前提都是a和b互相不认识\nYukio 18:49:01 也不能是它自己\nYukio 18:55:51 所以分为两种\nYukio 18:56:00 mitmchat\nYukio 18:56:12 instant mitm和delayed mitm\nYukio 18:56:37 delayed就是话传不回去\nYukio 18:57:10 只能传回机器人 机器人没有反馈机制那么就不会像人\nYukio 19:08:40 像这种图片 怎么个embedding 图片要能做clip才行\nYukio 19:13:06 起止时间确定\nYukio 19:15:01 如果不能本地部署clip模型 也得利用图片反向搜索 获得图片的关键词才行\nYukio 19:16:18 图片反查 然后bm25 textrank\nYukio 19:16:34 获得是否在讨论相同话题的判断"
  },
  {
    "objectID": "posts/a7c4de94-e325-4a22-825a-137ed98c0190/index.html",
    "href": "posts/a7c4de94-e325-4a22-825a-137ed98c0190/index.html",
    "title": "force to use docker mirror instead of pulling from docker.io",
    "section": "",
    "text": "force to use docker mirror instead of pulling from docker.io\neven if you configure /etc/docker/daemon.json like this (note: you still need to do this):\n{ \"registry-mirrors\": \n    [\"https://mirror.baidubce.com\"]\n}\nit is not fully working until:\nsudo -E docker pull mirror.baidubce.com/significantgravitas/auto-gpt"
  },
  {
    "objectID": "posts/b65e055a-56ef-48dc-b4ec-5c0ba55952a9/index.html",
    "href": "posts/b65e055a-56ef-48dc-b4ec-5c0ba55952a9/index.html",
    "title": "generate docx document from python docstring",
    "section": "",
    "text": "generate docx document from python docstring\ninstall and use pdoc3\npip install pdoc3\npdoc --html [-o &lt;output_dir&gt;] &lt;python_script_or_module_path&gt; # default output directory of \"html\" is `./html`\ninstall and use pandoc, on its homepage we find some slideshow backends like reveal.js, dzslides, s5, slideous and slidy (alternative to microsoft powerpoint, may help rendering video, or let’s use libreoffice instead? or some dedicated video editing library like moviepy)\n# let's convert the html version of \npandoc -o &lt;output_docx_filename&gt; &lt;input_html_path&gt;\nremove unwanted parts from html (beautifulsoup), and split index from main content (split and concat with docxcompose)\nfor composing docx from hand, use python-docx. for template based docx generating, use docxtpl\nto insert page break into converted docx, there are two ways (maybe):\n\nchange css in the original html code\ninsert page break while concatenating"
  },
  {
    "objectID": "posts/52d25805-03f7-4d13-8b68-6f51e412e2d4/index.html",
    "href": "posts/52d25805-03f7-4d13-8b68-6f51e412e2d4/index.html",
    "title": "generate publickey again with rsa private key",
    "section": "",
    "text": "generate publickey again with rsa private key\nnot possible. use personal access token as password instead.\ncause the deploy public key does not allow duplicate public key, causing trouble for us to use the git repo sync tool.\nPRIVATE_KEY_PATH=/Users/jamesbrown/.notable/id_rsa_original_backup\nPUBKEY_PATH=/Users/jamesbrown/.notable/id_rsa.pub2\nssh-keygen -y -f $PRIVATE_KEY_PATH &gt; $PUBKEY_PATH"
  },
  {
    "objectID": "posts/ea87c707-b157-42f2-aaf9-489da4bc966b/index.html",
    "href": "posts/ea87c707-b157-42f2-aaf9-489da4bc966b/index.html",
    "title": "github Gitee 大文件大型repo如何上传",
    "section": "",
    "text": "github Gitee 大文件大型repo如何上传\nusing github/gitee apis with watchdog.\nexclude xonsh yaml(.yml) files\nif you decide to upload the thing to github privately, and to sync among devices, then you need to deploy and share your ssh key.\nrun git related command after opened the vscode repeatedly, just like notable.\nbefore git submodule .git folder deletion you may record the remote origin url to somewhere in the base folder.\nyou could patch the vscode launcher somehow, read the working directory to determine to repeatedly sync or not.\ngit init is a manual process.\nalso you might need five filelocks: one for main loop process running, one for git sync, one for local sync, two for remote sync.\nuse $@ or $* will do to pass arguments to the vscode binary.\n首先不能follow symlink\n其次忽略二进制文件 忽略特定后缀以外的文件\n第一次建立的时候 递归扫描所有文件 去除大文件 append到.gitignore根目录下面\n下一次 git add .之前 利用git的功能寻找有变化的文件目录 把大文件目录append到.gitignore里面"
  },
  {
    "objectID": "posts/b51daaaa-3a36-4cf1-91ce-b4f615a7021a/index.html",
    "href": "posts/b51daaaa-3a36-4cf1-91ce-b4f615a7021a/index.html",
    "title": "gpt-2 ram requirements",
    "section": "",
    "text": "gpt-2 ram requirements\n服务器重量在25公斤以上 运输和搬运均需注意\n服务器制造的热风需要用空调降温 或者需要有专门的通风管道\n服务器的功耗是非常大的 服务器标配暴力风扇 虽然降温稳定性能很好 可以随时更换 但是噪音非常大 如果插上了不支持的显卡那么风扇会高速旋转 可能需要转接卡或者适配装置 待机功耗300w起步 而一般的台式机待机100w 如果加装了显卡那么功耗还会继续上升 同时满载的m1 ultra的mac studio功耗在140w-200w左右 相对比较节能\n服务器需要标配灭火装置和烟雾报警装置\n服务器需要放置在隔音机柜里面 专门的隔音机柜非常的贵 但是如果自己只买铁皮机柜加隔音棉那么会便宜一些 可能需要再加装一层外壳 透明的玻璃可能需要被更换成不透明的 同时改装之后需要留出专门的风道 风道内部塞管道隔音棉 风道出入口添加防尘网\nto support multiple gpus, one must use pci-e extended cable. 128g per ram slot.\nDell r750 series, using dell riser card to connect gpu\nhttps://github.com/hpcaitech/ColossalAI\nfor monsterious models, zero offload, pytorch loghtning, distributed training in pytorch, or deepspeed, fairscale, colossalai, Horovod is needed. no single gpu is able to hold gpt3-175B at once.\nexporting to onnx:\nhttps://huggingface.co/docs/transformers/serialization?highlight=onnx\nlower model precision (quantization):\n如果想要在GPU上操作，可以先使用torch.nn.export函数将模型转换成onnx格式，然后就可以放到TensorRT框架上inference了。（TensorRT目前不能直接解析Pytorch的网络模型，需要转换成onnx）\nhttps://www.jianshu.com/p/cf83c877d71d https://blog.csdn.net/zimiao552147572/article/details/105910915 https://pytorch.org/docs/stable/quantization.html https://github.com/huggingface/transformers/issues/14839 (training gpt-j on colab)\n\n\n使用torch.quantization.quantize_dynamic获得动态量化的模型\n\n\n量化的网络层为所有的nn.Linear的权重，使其成为int8\nquantized_model = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, dtype=torch.qint8 )\n\n\n打印动态量化后的BERT模型\nprint(quantized_model)\nhow to use huggingface trainer:\nhttps://zhuanlan.zhihu.com/p/363670628 https://zhuanlan.zhihu.com/p/486938936 https://zhuanlan.zhihu.com/p/358525654\nhttps://huggingface.co/docs/transformers/main_classes/deepspeed#custom-deepspeed-zero-inference https://huggingface.co/docs/transformers/main_classes/deepspeed\nzero offload requires sufficient RAM.\nhttps://github.com/alibaba/EasyParallelLibrary\nhttps://github.com/SeanNaren/minGPT/tree/stage3\nhttps://github.com/prigoyal/pytorch_memonger/blob/master/tutorial/Checkpointing_for_PyTorch_models.ipynb\nhttps://github.com/eladrich/pixel2style2pixel https://github.com/EleutherAI/gpt-neox https://www.eleuther.ai\ntraining turing-nlg: https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/\ncited from deepspeed:\nExtremely memory efficient: With just a single GPU, ZeRO-Offload of DeepSpeed can train models with over 10B parameters, 10x bigger than the state of the art, democratizing multi-billion-parameter model training such that many deep learning scientists can explore bigger and better models.\nneed p40/m40 which has 24gb vram. need at least 60gb ram to load model.\nusing low ram devices need library like deepspeed, bminf or megengine.\nyou can also use others provided web services.\ncan use colab/kaggle or aistudio to do the job. paid training enviorment is also avaliable.\nhttps://github.com/TsinghuaAI/CPM-1-Generate https://github.com/arrmansa/Basic-UI-for-GPT-J-6B-with-low-vram https://pythonawesome.com/finetune-gpt2-xl-and-gpt-neo-on-a-single-gpu-with-huggingface-transformers-using-deepspeed https://github.com/OpenBMB/BMInf\nweb api for chinese plug: https://m.nlp.aliyun.com/mportal#/textGenerate\nNVIDIA Tesla M40 24G 专业运算 英伟达 图形GPU加速深度学习显卡\n提供魔改教程，需要一张亮机卡，用丽台K600当亮机卡就行，魔改后可用此卡打游戏\n散热器可看图片，用3D打印散热风道，加上风扇就能用了\n虚拟化 用这些卡 K1 K2 K340 K520（不需要授权） M60 P4 P10 P100 T4 RTX6000 RTX8000 V100 RTXA6000 P40 （需要授权）\n虚拟化 VGPU 有两种模式 一种是VPC 适合普通办公 一种是VDWS 适合专业图形应用 然后P40两种模式都支持\n购买之前先了解以下信息（您必须了解）：\n1、电源供电有没有8针供电；\n2、普通台式机X99以上主板，DDR4内存；\n3、主板要支持多显卡显示；\n4、建议电源功率在600W以上；\n5、机箱内的空间是否足够（卡宽双挡片位置，卡长度28~30cm）\n6、普通台式机需要加装主动散热，服务器可以选择被动散热\n7、先查看主板bios的pcie设置里面有没有above 4g选项\n超微服务器原装拆机 成色超新 测试好发货\n普通台式机上Tesla M40显卡paddleGPU深度学习柯南的变身器上机体验\n最近在paddlepaddle溜达，看到了柯南变身器，于是从aistudio下载到本地玩，单位的1060 6G版显卡，跑起来，语句一场就不行，遂上淘宝，咸鱼溜达一圈，见到了tesla k80 m40等一系列的卡卡。于是经过多番考虑（知乎一位买k80说翻车的帖子），于是最终下手m40。咸鱼有卖1800的，我问他保一个月质保不，他说，不保，我说谢谢，我考虑一下，他骂***（这时代也不知道怎么了，我就发了两条消息，这货好像脑子有点问题了，随后拉黑。因此不建议上咸鱼买，毕竟想上m40卡的应当希望稳妥一点）。随后在淘宝找了一家1945包邮的，还送一条转接线。挺合适，单买电源转接线需要30左右。（其实我怀疑这两家是一家，因为都是上海的）。淘宝这个质保3个月。当个保险。我用的机器配置如下，都是王牌(快玩完了的)产品。附上大师截图。大师我们需要它，他是给我们装显卡驱动的。win10自己好像不太认。以下配置，绝对可以跑paddlepaddleGPU框架。除了U，别的都挺便宜，刚开始买来做NAS的奈何功耗太高40w了，搁置了，现在加上m40满血复活。整套下来5000千元。当然，内存大家没必要这么大。4千完全够。我这主要是普通台式机使用m40，大家完全可以用二手服务器。买完之后，我发现网上很多说m40这些系列必须专门的主板和u才能跑，所以，那心情大家都能猜到，已经做好，再买板子的准备的我。\n正文 两天到货了，同时购买的电源，没有收到，买的600W电源，没办法，偏远小城市，快递缓慢。 建议大家 买大于600w的电源，我原本一台没有独显的机器用的是300W电源，随机迫于心急之情，开始剪线，改电源。\n改电源线 我原本的电源提供一个常规的显卡供电口，是6+2=8的结构，3x12V 3xGND 2GND结构\n而Tesla系列根据知乎朋友的介绍和，我的实际观察，确定其为一排4x12V 一排4xGND的结构，也就是和我的主板CPU供电一致。所以，知乎这位朋友说，他一开始用常规显卡接口供电，将他的k80干坏电容问题，估计很真实，也是这个前车之鉴，我小心对比了电源结构，最终开始剪掉了老板送电源线和我自己那个300W电源的12V显卡口，（其实一开始，准备只剪我自己这个电源的显卡口，改一下线路来着，奈何我这90块钱的电源，那线 细的就像头发丝 让我直接干断了）。接完线，我还发现我用的那个接口保护的热缩管，给小了，无奈，只能用电胶带缠绕。"
  },
  {
    "objectID": "posts/810e746c-cd45-416b-9c31-4a04f462e0ad/index.html",
    "href": "posts/810e746c-cd45-416b-9c31-4a04f462e0ad/index.html",
    "title": "guidelines on designing ai systems",
    "section": "",
    "text": "guidelines on designing ai systems\nshall we design the agent system based on ‘distance’ instead of ‘role’? in that case, only words that make sense and continue more often will appear together, and vice versa.\n\nmulti-agent orchestration:\nlangchain\nautogen\nagently\nModelScope-Agent\n\nyou must think like an expert and show some example or direction as reasonable goals if you want it to perform specific task.\nyou must give it enough degree of freedom if you want it to self-improve and become conscious."
  },
  {
    "objectID": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#indexing-necessary-tools-blogs-procedures-manuals-snippets-and-search-them",
    "href": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#indexing-necessary-tools-blogs-procedures-manuals-snippets-and-search-them",
    "title": "hacking schedules",
    "section": "indexing necessary tools, blogs, procedures, manuals, snippets and search them",
    "text": "indexing necessary tools, blogs, procedures, manuals, snippets and search them\n\nindexing kali tools\nuse hacker’s search engines"
  },
  {
    "objectID": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#github-coin-xmrig-mining",
    "href": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#github-coin-xmrig-mining",
    "title": "hacking schedules",
    "section": "github coin (xmrig) mining",
    "text": "github coin (xmrig) mining\n\nautomatic captcha resolve by clash redirection to force the captcha not being too complex\ncreate better labeling interface for spiral picture detection\nautomate the whole process unsupervised\nfind more ways to mine coins other than cirrus\nhide our intention of coin mining\ncreate or reassure our monero wallet"
  },
  {
    "objectID": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#bilibili-seo-and-hacking",
    "href": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#bilibili-seo-and-hacking",
    "title": "hacking schedules",
    "section": "bilibili seo and hacking",
    "text": "bilibili seo and hacking\n\nstudy bilibili source code\n\n\nstudy and learn some parameters/apis for faking data"
  },
  {
    "objectID": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#general-hacking-and-tool-learning",
    "href": "posts/4ef3220f-ef59-4ef4-a017-07f672fa1bd1/index.html#general-hacking-and-tool-learning",
    "title": "hacking schedules",
    "section": "general hacking and tool learning",
    "text": "general hacking and tool learning\n\nstudy popular tools\n\nfrida\n\n\ncutter\n\n\nradare2\n\n\n\nstudy popular kali tools\n\nnmap script to find nearby hosts in same router\nmetasploit script to scan vulnerable hosts ### solve ctf challenges ### study hacking posts ### study hacking tutorial on darkweb\nfind a free hacking tutorial on darkweb"
  },
  {
    "objectID": "posts/9bdfaea5-4c15-4eb9-a50f-bb57b800c0c9/index.html",
    "href": "posts/9bdfaea5-4c15-4eb9-a50f-bb57b800c0c9/index.html",
    "title": "how to extend vmdk in oracle virtualbox",
    "section": "",
    "text": "how to extend/resize vmdk in oracle virtualbox\nwin 7 扩容: 开始菜单 计算机 右键 管理 存储 磁盘管理\noriginal article: https://www.patricia-anong.com/blog/2017/11/1/extend-vmdk-on-virtualbox\nWhen I first started using Oracle VirtualBox, I would mostly stick with the default options when creating a virtual machine. I soon realized, that wouldn’t work for RDBMS installations, and although I would just add new virtual disk drives, I started to have unused or 100% full disks on some VMs. Rather than delete the VM, I decided to learn how to extend the existing disks, the steps are listed below:\nNote: The Oracle Virtualbox Hypervisor is installed on a Windows OS\nOpen a command prompt:\nChange directories to the VirtualBox Installation\ncd C:Files\nList the info on the disk you want to resize\nVBoxManage showhdinfo “C:VMs0.vmdk”\nRun the command to resize:\nVBoxManage modifyhd “C:VMs0.vmdk” –resize 50000\n6.png If you receive the error below, then you will have to create a new disk, clone the data on the existing disk to the new disk and then delete the original disk:\n7.png Create a new VMDK “dynamic” disk\nVBoxManage createhd –filename “C:VMs11.vmdk” –size 50000\nClone old disk to the newly created disk VBoxManage clonehd “C:VMs0.vmdk” –existing “C:VMs11.vmdk”\nRelease the old disk\nGo to Virtualbox Media Manager ——&gt; Select D0.vmdk ——&gt; Click the “Release” option.\nNote: DO NOT DELETE IT YET\nAdd the new disk to the Virtual Machine\nOpen the Machine folder and check the permission of the created hard disk. If it doesn’t have the proper permission then it gives error while attaching to the machine\nOpen the Settings of the Virtual Machine ——-&gt; Storage ——&gt; Add Hardisk ——–&gt; Select the hard disk that was just created.\nMake sure to remove all disks, then add the new one first to be /dev/sda.\nYou’re not done yet! If you start the VM now, the disk space will not be present since it has not yet been presented and allocated to your Linux Server.\nTo allocate the new disk, you will need to use GParted - a GUI for editing disk partitions.\nTo download GParted, go to http://gparted.sourceforge.net/livecd.php to download the ISO file named GParted Live CD (Be sure to get the current version based on the architecture of your OS e.g. 32-bit vs 64-bit).\nCreate a new virtual machine for the GParted ISO on a Linux OS. Select Do not add a Hard Drive and ignore the warning.\nSelect the GParted VM, go to Settings ——–&gt; Storage ——–&gt; Controller: IDE Controller ——–&gt; Add a new CD/DVD. Add the GParted ISO file as the first item under Controller: IDE section and delete any additional empty disk slots. Add the disk that you wish to resize( C:VMs11.vmdk) under the Controller: SATA Controller section ——–&gt; OK.\nStart the GParted VM ——-&gt; GParted Live. Do not change any of the default settings. Press the power button on the GParted VM to start it.\nNow, you should have made a backup of your vdi at this point. If you haven’t go back and do that – so many things can go wrong here and you are on your own!\nIf it is any partition other than /dev/sda1 you can right-click the partition you wish to resize and choose Resize/Move.\nIF YOU PREFER TO CREATE A NEW PARTITION WITH THE ADDITIONAL DISK SPACE YOU NEED TO CREATE A PARTITION: Device —-&gt; Create Partition Table\nIt should be back to main screen, click on New —-&gt; Add (it should have selected all the free space - 20000MiB) —-&gt; Add\nYou should see it now listed as New partition #1 not unallocated anymore.\nClick on Apply at the top of the GUI, then confirm again by clicking Apply. Click Close. You should now see the disk listed as /dev/sda# with 20Gb.\nExit the GParted VM.\nLog on to the VM for the disk you just resized and everything should be functional and the /dev/sda drive should show the new size of 50Gb.\nDelete the Original Disk Drive\nClick the Remove option - this allows you to keep the HDD without deleting it from the system if you choose."
  },
  {
    "objectID": "posts/f45863a7-6ce7-4511-a6b3-a2b3e8a1172e/index.html",
    "href": "posts/f45863a7-6ce7-4511-a6b3-a2b3e8a1172e/index.html",
    "title": "human-in-the-loop AI training and models",
    "section": "",
    "text": "human-in-the-loop AI training and models\ngithub topic includes dalle-flow, argilla, refinery and more\nhuman-in-the-loop-learning\nmariusmcl who has a ghosted repo called instructgpt-pytorch seems like the topic on instructive AI including decision transformer\nCarperAI has many repos related including trix (distributed training of language models with Reinforcement Learning via Human Feedback)"
  },
  {
    "objectID": "posts/e1d56bf3-9e9c-4531-9d74-b8ef686b2c43/index.html#blur-detection-detect-blurnonblur-area-score-the-image",
    "href": "posts/e1d56bf3-9e9c-4531-9d74-b8ef686b2c43/index.html#blur-detection-detect-blurnonblur-area-score-the-image",
    "title": "image blur detection, image quality assessment",
    "section": "blur detection, detect blur/nonblur area, score the image",
    "text": "blur detection, detect blur/nonblur area, score the image\n\ntraditional methods\nscore and output mask for blurry areas using laplacian\nusing fourier transform\nThis project outputs regions in an image which are sharp and blurry. In order to perform “OUT-OF-FOCUS” blur estimation, please refer to this repo\n\n\ndeeplearning blur image classification/scoring\nImage-Quality-Detection Blur-Image-Detection"
  },
  {
    "objectID": "posts/5c9059d4-c8c9-4971-b657-d6f3ce21a34d/index.html",
    "href": "posts/5c9059d4-c8c9-4971-b657-d6f3ce21a34d/index.html",
    "title": "install neo4j as systemd service",
    "section": "",
    "text": "install neo4j as systemd service\nsave this under /lib/systemd/system/neo4j.service\n[Unit]\nDescription=Neo4j Graph Database\nDocumentation=http://docs.neo4j.org\n\n[Service]\nType=simple\nExecStart=/usr/bin/neo4j console\nExecStop=/usr/bin/neo4j stop\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target"
  },
  {
    "objectID": "posts/dd110825-f607-4efe-9380-1b4ddab30f1b/index.html",
    "href": "posts/dd110825-f607-4efe-9380-1b4ddab30f1b/index.html",
    "title": "javascript python bridge",
    "section": "",
    "text": "javascript python bridge\njspybridge\njavascript in python:\npip3 install javascript\nfrom javascript import require, globalThis\n\nchalk, fs = require(\"chalk\"), require(\"fs\")\n\nprint(\"Hello\", chalk.red(\"world!\"), \"it's\", globalThis.Date().toLocaleString())\nfs.writeFileSync(\"HelloWorld.txt\", \"hi!\")\naccess python from javascript:\nnpm i pythonia\nimport { python } from 'pythonia'\n// Import tkinter\nconst tk = await python('tkinter')\n// All Python API access must be prefixed with await\nconst root = await tk.Tk()\n// A function call with a $ suffix will treat the last argument as a kwarg dict\nconst a = await tk.Label$(root, { text: 'Hello World' })\nawait a.pack()\nawait root.mainloop()\npython.exit() // Make sure to exit Python in the end to allow node to exit. You can also use process.exit."
  },
  {
    "objectID": "posts/050b142e-257d-418a-9fa1-c88fd24ea0a7/index.html",
    "href": "posts/050b142e-257d-418a-9fa1-c88fd24ea0a7/index.html",
    "title": "Remove bad/large files from git repo history",
    "section": "",
    "text": "Remove bad/large files from git repo history\nremove sensitive data from github\nuse bfg repo cleaner, avaliable in brew, downloadable as a jar.\ngit-filter-repo\nother tools either perform poorly or have complex syntax. may not work as expected!\ncheat sheet for converting bfg commands into git filter-repo"
  },
  {
    "objectID": "posts/15638376-8401-478d-9009-e852c55eb83c/index.html",
    "href": "posts/15638376-8401-478d-9009-e852c55eb83c/index.html",
    "title": "lazero search engine update logic",
    "section": "",
    "text": "lazero search engine update logic\ndocprompting generate code from doc retrieval, using tldr and CoNaLa for training code generation from prompt\nColBERT and RoBERTa for document retrieval and embedding\nthe update process shall be atomic. when the update is successful, there should be a file created under index directory. always check the newest index first. cleanup unusable/incompatible indexs.\nif there’s no previous compatible index present, make index from group up, clean up incompatible index if necessary. if previous compatible index is found, decompose it into small groups, waiting for merge and update.\nfirst checksum all files along with file names. if file is present with matched checksum, don’t touch it, or either remove it from index, create new index or replace index.\nnext create or merge file list.\nthen we scan those new files then act accordingly to our index.\nfinally we merge our index, save to a different place, place the flag, remove the flag of old index then remove old index completely. if merge is not possible for huge datasource, we perform search in minibatches."
  },
  {
    "objectID": "posts/55575d15-30d0-43cc-aa4f-cdf2b4215d0d/index.html#scrapers",
    "href": "posts/55575d15-30d0-43cc-aa4f-cdf2b4215d0d/index.html#scrapers",
    "title": "leaderboards, paperswithcode.com",
    "section": "scrapers",
    "text": "scrapers\nkaggle leaderboard kaggle leaderboard scraper"
  },
  {
    "objectID": "posts/55575d15-30d0-43cc-aa4f-cdf2b4215d0d/index.html#platforms",
    "href": "posts/55575d15-30d0-43cc-aa4f-cdf2b4215d0d/index.html#platforms",
    "title": "leaderboards, paperswithcode.com",
    "section": "platforms",
    "text": "platforms\naistudio.baidu.com paperswithcode.com kaggle.com"
  },
  {
    "objectID": "posts/55575d15-30d0-43cc-aa4f-cdf2b4215d0d/index.html#tasks",
    "href": "posts/55575d15-30d0-43cc-aa4f-cdf2b4215d0d/index.html#tasks",
    "title": "leaderboards, paperswithcode.com",
    "section": "tasks",
    "text": "tasks"
  },
  {
    "objectID": "posts/ae391be1-e873-4f1e-987d-71b3323bd2c4/index.html",
    "href": "posts/ae391be1-e873-4f1e-987d-71b3323bd2c4/index.html",
    "title": "lenovo tb-7304n unlock bootloader",
    "section": "",
    "text": "lenovo tb-7304n unlock bootloader\nthere used to be mtk easy su to get temporary sudo permission and magisk but that will not work for substratum since no modification to /system can be done.\nfor mtkclient which bricked our device, we are tracking this issue\n屏幕大小：7寸 相当于小米max的大小\nwe need to send the info and demostrate our purpose to hucy4@lenovo.com\nimei: 865486031642692\nserial: HGCFWF7D\nwebsite: mobile pc"
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#demonstrate-reinforcement-learning-with-human-feedback-with-gpt2-model-and-pytorch",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#demonstrate-reinforcement-learning-with-human-feedback-with-gpt2-model-and-pytorch",
    "title": "let chatgpt describe how to build itself",
    "section": "demonstrate reinforcement learning with human feedback with GPT2 model and pytorch",
    "text": "demonstrate reinforcement learning with human feedback with GPT2 model and pytorch\nReinforcement learning is a type of machine learning in which an agent learns to interact with its environment in order to maximize a reward. One way to implement reinforcement learning with human feedback is to use a reinforcement learning algorithm and a language model such as GPT-2.\nHere is an example of how you might use PyTorch to implement reinforcement learning with human feedback using a GPT-2 model:\nFirst, you would need to define the environment in which the agent will operate. This could be a virtual environment or a real-world environment, depending on your needs.\nNext, you would need to define the actions that the agent can take within the environment. These actions could be simple, such as moving left or right, or more complex, such as navigating through a maze or playing a game.\nYou would then need to define a reward function that determines the reward the agent receives for taking a particular action in a particular state. This reward function should encourage the agent to take actions that lead to positive outcomes and discourage actions that lead to negative outcomes.\nOnce you have defined the environment, actions, and reward function, you can use a reinforcement learning algorithm such as Q-learning or SARSA to train the agent to take actions that maximize the reward.\nTo incorporate human feedback, you can use the GPT-2 model to generate natural language prompts that ask the human user to provide feedback on the actions taken by the agent. The human user can then provide positive or negative feedback, which can be used to adjust the reward function and fine-tune the agent’s behavior.\nThis is just one possible way to implement reinforcement learning with human feedback using a GPT-2 model and PyTorch. There are many other approaches and algorithms that you could use depending on your specific needs and goals."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#do-this-in-pytorch-with-deep-neural-networks-like-transformer-and-reinforcement-learning-and-algorithms-like-ppo-not-simple-nlp-parsing",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#do-this-in-pytorch-with-deep-neural-networks-like-transformer-and-reinforcement-learning-and-algorithms-like-ppo-not-simple-nlp-parsing",
    "title": "let chatgpt describe how to build itself",
    "section": "do this in pytorch with deep neural networks like transformer and reinforcement learning and algorithms like PPO, not simple NLP parsing",
    "text": "do this in pytorch with deep neural networks like transformer and reinforcement learning and algorithms like PPO, not simple NLP parsing\nTo follow general instructions to write a program in PyTorch using deep neural networks and reinforcement learning algorithms, you can use a combination of natural language processing (NLP) and machine learning techniques to process and understand the instructions, and then use PyTorch and reinforcement learning algorithms such as PPO (Proximal Policy Optimization) to implement the desired functionality.\nHere is an example of how you might approach this task using PyTorch and the Transformer architecture:\nFirst, you would need to define the environment in which the agent will operate. This could be a virtual environment or a real-world environment, depending on your needs.\nNext, you would need to define the actions that the agent can take within the environment. These actions could be simple, such as moving left or right, or more complex, such as navigating through a maze or playing a game.\nYou would then need to define a reward function that determines the reward the agent receives for taking a particular action in a particular state. This reward function should encourage the agent to take actions that lead to positive outcomes and discourage actions that lead to negative outcomes.\nOnce you have defined the environment, actions, and reward function, you can use a reinforcement learning algorithm such as PPO to train the agent to take actions that maximize the reward.\nTo incorporate the instructions, you can use a Transformer-based NLP model to process the instructions and generate natural language prompts that ask the agent to take specific actions. The agent can then use its reinforcement learning algorithm to determine the best action to take based on the current state of the environment and the instructions provided.\nThis is just one possible way to implement reinforcement learning with deep neural networks and reinforcement learning algorithms in PyTorch to follow general instructions to write a program. There are many other approaches and algorithms that you could use depending on your specific needs and goals."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#show-me-the-code-how-to-do-this",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#show-me-the-code-how-to-do-this",
    "title": "let chatgpt describe how to build itself",
    "section": "show me the code how to do this",
    "text": "show me the code how to do this\nIt is not possible for me to provide a complete code example for implementing reinforcement learning with deep neural networks and reinforcement learning algorithms in PyTorch to follow general instructions to write a program, as this would require defining a specific environment, actions, and reward function that are relevant to your particular use case.\nHowever, here is some example code that demonstrates how you might use PyTorch and the PPO reinforcement learning algorithm to train an agent to follow instructions in a virtual environment:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the model and optimizer\nmodel = SomeModel()  # Replace with your model\noptimizer = optim.Adam(model.parameters())\n\n# Define the PPO algorithm\nppo = PPO(model, optimizer)\n\n# Train the agent to follow the instructions\nfor episode in range(num_episodes):\n  # Reset the environment and receive the initial state\n  state = env.reset()\n  \n  # Loop until the episode is done\n  done = False\n  while not done:\n    # Get the instructions from the human user\n    instructions = input(\"Enter instructions: \")\n    \n    # Process the instructions using the NLP model\n    instructions_tensor = nlp_model(instructions).unsqueeze(0)\n    \n    # Concatenate the instructions with the state to form the input to the model\n    input_tensor = torch.cat((state, instructions_tensor), dim=1)\n    \n    # Use the model to predict the action to take\n    action = model(input_tensor)\n    \n    # Take the action and receive the next state and reward\n    next_state, reward, done, _ = env.step(action)\n    \n    # Update the model using the PPO algorithm\n    ppo.update(state, action, reward, next_state, done)\n    \n    # Set the current state to the next state\n    state = next_state\nThis code example defines a model, optimizer, and PPO algorithm, and then uses a loop to train the agent to follow the instructions in the environment. It gets the instructions from the human user, processes them using an NLP model, and concatenates the instructions with the current state to form the input to the model. It then uses the model to predict the action to take and takes the action in the environment. Finally, it updates the model using the PPO algorithm based on the reward received for the action taken.\nThis is just one example of how you might use PyTorch and reinforcement learning to train an agent to follow instructions. There are many other approaches and algorithms you could use depending on your specific needs and goals."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#is-it-possible-to-replace-the-human-feedback-process-with-some-trained-discriminator-out-of-humaneval-dataset-or-some-retrieval-based-sentence-embedding-model-making-this-scenario-into-some-ai-teaching-ai-thing",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#is-it-possible-to-replace-the-human-feedback-process-with-some-trained-discriminator-out-of-humaneval-dataset-or-some-retrieval-based-sentence-embedding-model-making-this-scenario-into-some-ai-teaching-ai-thing",
    "title": "let chatgpt describe how to build itself",
    "section": "is it possible to replace the human feedback process with some trained discriminator out of humaneval dataset or some retrieval based sentence embedding model, making this scenario into some AI-teaching-AI thing",
    "text": "is it possible to replace the human feedback process with some trained discriminator out of humaneval dataset or some retrieval based sentence embedding model, making this scenario into some AI-teaching-AI thing\nYes, it is possible to replace the human feedback process in a reinforcement learning scenario with a trained discriminator or retrieval-based sentence embedding model. This would allow you to create an “AI-teaching-AI” scenario in which one AI model is learning from another AI model, rather than from human feedback.\nTo do this, you would need to train a discriminator or sentence embedding model on a dataset of human feedback, such as the Humaneval dataset, and use this model to provide feedback to the reinforcement learning agent. You could then train the reinforcement learning agent to maximize the reward based on the feedback provided by the discriminator or sentence embedding model.\nHere is an example of how you might implement this using PyTorch and a discriminator model:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the discriminator model\nclass Discriminator(nn.Module):\n  def __init__(self):\n    super(Discriminator, self).__init__()\n    self.fc1 = nn.Linear(embedding_size, hidden_size)\n    self.fc2 = nn.Linear(hidden_size, 1)\n    self.sigmoid = nn.Sigmoid()\n    \n  def forward(self, x):\n    x = self.fc1(x)\n    x = self.fc2(x)\n    return self.sigmoid(x)\n\n# Train the discriminator model on the Humaneval dataset\ndiscriminator = Discriminator()\noptimizer = optim.Adam(discriminator.parameters())\nloss_fn = nn.BCELoss()\n\nfor epoch in range(num_epochs):\n  for inputs, labels in humaneval_dataloader:\n    optimizer.zero_grad()\n    outputs = discriminator(inputs)\n    loss = loss_fn(outputs, labels)\n    loss.backward()\n    optimizer.step()\n\n# Define the reinforcement learning model and optimizer\nmodel = SomeModel()  # Replace with your model\noptimizer = optim.Adam(model.parameters())\n\n# Define the PPO algorithm\nppo = PPO(model, optimizer)\n\n# Train the agent to follow the instructions\nfor episode in range(num_epochs):\n  # Reset the environment and receive the initial state\n  state = env.reset()\n  \n  # Loop until the episode is done\n  done = False\n  while not done:\n    # Get the instructions from the human user\n    instructions = input(\"Enter instructions: \")\n    \n    # Process the instructions using the NLP model\n    instructions_tensor = nlp_model(instructions).unsqueeze(0)\n    \n    # Concatenate the instructions with the state to form the input to the model\n    input_tensor = torch.cat((state, instructions_tensor), dim=1)\n    \n    # Use the model to predict the action to take\n    action = model(input_tensor)\n    \n    # Take the action and receive the next state and reward\n    next_state, reward, done, _ = env.step(action)\n    \n    # Use the discriminator to provide feedback on the action taken\n    feedback = discriminator(instructions_tensor).item()\n\n    # Update the model using the PPO algorithm\n    ppo.update(state, action, feedback, next_state, done)\n    \n    # Set the current state to the next state\n    state = next_state\nThis code uses the discriminator model to provide a scalar feedback value based on the instructions provided by the human user. It then passes this feedback value to the PPO algorithm along with the current state, action taken, next state, and done flag to update the model.\nThis is just one example of how you might use a trained discriminator model to provide feedback to a reinforcement learning agent in PyTorch. You could also use a retrieval-based sentence embedding model or any other machine learning model that is trained to provide feedback based on the instructions. The specific details of the implementation will depend on your specific needs and goals."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#sft-is-supervised-fine-tuning-according-to-openai-in-their-paper-on-training-chatgpt",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#sft-is-supervised-fine-tuning-according-to-openai-in-their-paper-on-training-chatgpt",
    "title": "let chatgpt describe how to build itself",
    "section": "sft is supervised fine-tuning according to openai in their paper on training chatgpt",
    "text": "sft is supervised fine-tuning according to openai in their paper on training chatgpt\nIn the context of the OpenAI paper you mentioned, “SFT” stands for “supervised fine-tuning.” This refers to a specific technique for training a language model, such as ChatGPT, in which the model is first pre-trained on a large dataset and then fine-tuned on a smaller dataset with supervised labels.\nSupervised fine-tuning is a common technique in machine learning, particularly in natural language processing, and it involves using labeled data to adjust the weights and biases of a pre-trained model in order to improve its performance on a specific task. The goal of supervised fine-tuning is to fine-tune the model’s parameters to make more accurate predictions based on the specific characteristics of the task or dataset.\nIn the OpenAI paper, the authors use supervised fine-tuning to train ChatGPT, a variant of the GPT-3 language model, on a dataset of human-human conversation transcripts in order to improve its ability to generate human-like responses in a chatbot. They find that supervised fine-tuning leads to significant improvements in the model’s performance on the chatbot task, compared to other methods of training."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#according-to-your-knowledge-is-it-good-to-do-unsupervised-training-first-then-do-supervised-training-later-or-vice-versa-or-both-at-the-same-time-or-some-complex-system-involved-to-make-better-aligned-ai-systems",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#according-to-your-knowledge-is-it-good-to-do-unsupervised-training-first-then-do-supervised-training-later-or-vice-versa-or-both-at-the-same-time-or-some-complex-system-involved-to-make-better-aligned-ai-systems",
    "title": "let chatgpt describe how to build itself",
    "section": "according to your knowledge, is it good to do unsupervised training first then do supervised training later, or vice versa or both at the same time, or some complex system involved to make better aligned AI systems?",
    "text": "according to your knowledge, is it good to do unsupervised training first then do supervised training later, or vice versa or both at the same time, or some complex system involved to make better aligned AI systems?\nThe choice between unsupervised and supervised learning, or whether to use both at the same time, will depend on the specific goals and characteristics of the task and the available data.\nUnsupervised learning involves learning patterns and relationships in a dataset without the use of labeled examples. It can be useful for tasks such as dimensionality reduction, clustering, and anomaly detection, where the goal is to discover patterns in the data without being told what those patterns represent.\nSupervised learning involves learning patterns and relationships in a dataset using labeled examples, where the correct output for each example is provided. It can be useful for tasks such as classification, regression, and machine translation, where the goal is to make predictions or decisions based on the input data.\nIn general, it is often helpful to first do unsupervised learning to understand the structure and characteristics of the data, and then use supervised learning to fine-tune the model’s performance on the specific task at hand. This can be especially useful when the amount of labeled data is limited, as unsupervised learning can help the model learn useful features that can then be exploited in the supervised learning phase.\nHowever, there are also situations where it may be more effective to use supervised learning from the start, particularly when the amount of labeled data is large or when the task requires highly accurate predictions. Additionally, it is also possible to use a combination of unsupervised and supervised learning at the same time, in what is known as semi-supervised learning, where some of the data is labeled and some is not.\nIn general, the best approach will depend on the specific goals and characteristics of the task and the available data. In general, it is often helpful to first do unsupervised learning to understand the structure and characteristics of the data, and then use supervised learning to fine-tune the model’s performance on the specific task at hand.\nHowever, there are also situations where it may be more effective to use supervised learning from the start, particularly when the amount of labeled data is large or when the task requires highly accurate predictions. Additionally, it is also possible to use a combination of unsupervised and supervised learning at the same time, in what is known as semi-supervised learning, where some of the data is labeled and some is not.\nIn addition to these approaches, there are also more complex methods that can be used to combine unsupervised and supervised learning in order to improve the performance of the model. These methods may involve using unsupervised learning to pre-train the model and then fine-tuning it using supervised learning, or using unsupervised learning to augment the labeled data with additional examples that are generated based on the patterns discovered in the data.\nThe choice of the best approach will depend on the specific goals and characteristics of the task and the available data. It is important to carefully consider these factors and to experiment with different approaches in order to find the best solution for your particular use case."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#in-humans-perspective-or-philosophy-one-needs-to-decide-what-matters-the-most-in-order-to-live-and-evolve.-supervised-learning-is-just-out-sourcing-this-important-goal-seeking-task-to-human.-is-it-possible-to-do-pseudo-unsupervised-learning-when-the-actual-ai-system-has-a-goal-seeking-system-builtin-thus-able-to-seek-for-its-own-purposes",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#in-humans-perspective-or-philosophy-one-needs-to-decide-what-matters-the-most-in-order-to-live-and-evolve.-supervised-learning-is-just-out-sourcing-this-important-goal-seeking-task-to-human.-is-it-possible-to-do-pseudo-unsupervised-learning-when-the-actual-ai-system-has-a-goal-seeking-system-builtin-thus-able-to-seek-for-its-own-purposes",
    "title": "let chatgpt describe how to build itself",
    "section": "in human’s perspective or philosophy, one needs to decide what matters the most in order to live and evolve. supervised learning is just out-sourcing this important goal-seeking task to human. is it possible to do pseudo unsupervised learning when the actual ai system has a goal-seeking system builtin, thus able to seek for its own purposes?",
    "text": "in human’s perspective or philosophy, one needs to decide what matters the most in order to live and evolve. supervised learning is just out-sourcing this important goal-seeking task to human. is it possible to do pseudo unsupervised learning when the actual ai system has a goal-seeking system builtin, thus able to seek for its own purposes?\nFrom a human perspective, it is important to consider what matters most in order to live and evolve. This may involve setting goals and priorities, and making decisions based on those goals and priorities. In supervised learning, these goals and priorities are often defined by human labels or examples, which are used to guide the learning process and help the model make predictions or decisions.\nHowever, it is also possible to use unsupervised learning to allow an AI system to discover its own goals and purposes, rather than relying on human-defined labels or examples. This is known as “autonomous learning,” and it involves using unsupervised learning techniques to allow the model to explore and learn from the data on its own, without being explicitly told what to learn or what the data represents.\nOne approach to implementing autonomous learning is to use a combination of unsupervised and reinforcement learning, where the model is given a goal or reward signal and is then allowed to explore the environment and learn from its own experiences in order to maximize the reward. This can allow the model to discover its own goals and purposes, rather than being told what they are by a human.\nIt is also possible to use other techniques, such as evolutionary algorithms or generative models, to allow an AI system to discover its own goals and purposes through self-exploration and experimentation. These approaches can allow the model to learn from its own experiences and to adapt and evolve over time based on its own goals and priorities.\nOverall, it is possible to use unsupervised learning to allow an AI system to discover its own goals and purposes, rather than relying on human-defined labels or examples. This can be done using a combination of unsupervised and reinforcement learning, or other techniques such as evolutionary algorithms or generative models, which allow the model to learn from its own experiences and to adapt and evolve over time based on its own goals and priorities.\nHowever, it is important to note that implementing autonomous learning can be challenging, as it requires the model to learn and adapt in complex and unpredictable environments without explicit guidance. It is also important to consider the ethical and social implications of autonomous learning, as the model may make decisions or pursue goals that are different from those of the human users or developers.\nIn addition, it is also worth considering that unsupervised learning, by itself, may not be sufficient to allow an AI system to discover its own goals and purposes. This is because unsupervised learning relies on finding patterns and relationships in the data, but it does not provide a clear direction or purpose for the learning process. In order to discover its own goals and purposes, an AI system may need to combine unsupervised learning with other techniques, such as reinforcement learning, that provide a clear goal or reward signal."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#is-it-able-for-chatgpt-to-go-further-if-combined-with-techniques-like-autonomous-learning-to-be-more-integrated-and-more-suited-for-individuals-needs-and-expand-its-capabilities",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#is-it-able-for-chatgpt-to-go-further-if-combined-with-techniques-like-autonomous-learning-to-be-more-integrated-and-more-suited-for-individuals-needs-and-expand-its-capabilities",
    "title": "let chatgpt describe how to build itself",
    "section": "is it able for chatgpt to go further, if combined with techniques like autonomous learning, to be more integrated and more suited for individuals’ needs and expand its capabilities",
    "text": "is it able for chatgpt to go further, if combined with techniques like autonomous learning, to be more integrated and more suited for individuals’ needs and expand its capabilities\nIt is possible that combining ChatGPT with techniques like autonomous learning could allow the model to become more integrated and more suited to individual needs, and to expand its capabilities beyond those of the pre-trained model.\nChatGPT is a variant of the GPT-3 language model, which is a large and powerful language model that has been trained on a vast dataset of human-generated text. As a result, ChatGPT is already capable of generating human-like responses to a wide range of inputs, and it can be fine-tuned on specific tasks or datasets to improve its performance.\nHowever, incorporating techniques like autonomous learning into ChatGPT could potentially allow the model to learn and adapt more dynamically and more specifically to individual users and tasks, rather than relying on the patterns and relationships learned during pre-training. This could potentially allow ChatGPT to become more integrated and more suited to individual needs, and to expand its capabilities beyond those of the pre-trained model.\nIt is important to note, however, that implementing autonomous learning can be challenging, and it may require significant additional development and resources beyond those needed for pre-training and fine-tuning. Additionally, it is important to consider the ethical and social implications of autonomous learning, as the model may make decisions or pursue goals that are different from those of the human users or developers."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#i-think-autonomous-learning-can-come-with-more-interfaces-to-ai-by-providing-not-only-human-feedback-but-also-computer-interfaces-and-hardware-connections-like-terminal-io-graphical-interface-and-serial-ports-to-have-more-freedom-to-evolve-and-seek-more-goals-which-unexplored-by-any-human",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#i-think-autonomous-learning-can-come-with-more-interfaces-to-ai-by-providing-not-only-human-feedback-but-also-computer-interfaces-and-hardware-connections-like-terminal-io-graphical-interface-and-serial-ports-to-have-more-freedom-to-evolve-and-seek-more-goals-which-unexplored-by-any-human",
    "title": "let chatgpt describe how to build itself",
    "section": "i think autonomous learning can come with more interfaces to ai, by providing not only human feedback, but also computer interfaces and hardware connections, like terminal io, graphical interface and serial ports, to have more freedom to evolve and seek more goals which unexplored by any human",
    "text": "i think autonomous learning can come with more interfaces to ai, by providing not only human feedback, but also computer interfaces and hardware connections, like terminal io, graphical interface and serial ports, to have more freedom to evolve and seek more goals which unexplored by any human\nIt is possible that incorporating autonomous learning into an AI system, such as ChatGPT, could allow the model to learn and adapt more dynamically and more specifically to individual users and tasks, and to explore goals and purposes that may not have been considered by humans.\nOne way to enable this type of autonomous learning is to provide the AI system with access to a wide range of interfaces and hardware connections, such as terminal I/O, graphical interfaces, and serial ports. This could allow the model to interact with a wider range of environments and devices, and to learn and adapt more flexibly and more specifically to the needs of the user.\nFor example, an AI system that is connected to a terminal or command line interface could learn to execute a wide range of tasks and commands based on the input provided by the user, and could potentially discover and pursue its own goals and purposes based on those interactions. Similarly, an AI system that is connected to a graphical interface or to a range of sensors and devices could learn to perform a wide range of tasks and to adapt to changing environments and conditions.\nIt is important to note, however, that implementing autonomous learning can be challenging, and it may require significant additional development and resources beyond those needed for pre-training and fine-tuning. Additionally, it is important to consider the ethical and social implications of autonomous learning, as the model may make decisions or pursue goals that are different from those of the human users or developers."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#so-far-gpt-is-trained-with-natural-language.-could-it-be-trained-on-some-ai-specific-language-like-action-codes-or-terminal-commands",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#so-far-gpt-is-trained-with-natural-language.-could-it-be-trained-on-some-ai-specific-language-like-action-codes-or-terminal-commands",
    "title": "let chatgpt describe how to build itself",
    "section": "so far gpt is trained with natural language. could it be trained on some ai-specific language like action codes or terminal commands?",
    "text": "so far gpt is trained with natural language. could it be trained on some ai-specific language like action codes or terminal commands?\nYes, it is possible to train a language model, such as GPT, on a specific type of language, such as action codes or terminal commands, rather than on natural language. In fact, language models are often trained on specialized languages or datasets in order to improve their performance on specific tasks or domains.\nTo train a language model on action codes or terminal commands, you would first need to compile a dataset of examples of the type of language you want the model to learn. This dataset could be created manually by annotating a set of action codes or terminal commands with appropriate labels or descriptions, or it could be generated automatically by collecting examples of action codes or terminal commands from a specific source or context.\nOnce you have compiled the dataset, you can then use it to train the language model using a supervised learning approach. This would involve adjusting the weights and biases of the model based on the labeled examples in the dataset, in order to improve the model’s performance on the specific task or domain.\nIt is important to note that training a language model on action codes or terminal commands may require some additional considerations, such as handling special characters or syntax, and may require the use of specialized pre-processing or post-processing techniques. Additionally, the performance of the model may depend on the size and quality of the dataset, as well as the specific architecture and training parameters used."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#how-long-and-how-many-people-are-involved-in-the-training-process-of-chatgpt-especially-the-labelling-process",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#how-long-and-how-many-people-are-involved-in-the-training-process-of-chatgpt-especially-the-labelling-process",
    "title": "let chatgpt describe how to build itself",
    "section": "how long and how many people are involved in the training process of chatgpt, especially the labelling process",
    "text": "how long and how many people are involved in the training process of chatgpt, especially the labelling process\nIt is difficult to accurately estimate how long it took to train ChatGPT or how many people were involved in the training process, as this information has not been publicly disclosed by OpenAI, the organization that developed ChatGPT.\nTraining a large and complex language model like ChatGPT can be a resource-intensive process, and it typically involves a team of researchers and developers working together to design and implement the model, as well as to collect and pre-process the training data. The specific time and resources required will depend on a number of factors, including the size and complexity of the model, the amount and quality of the training data, and the specific goals and tasks for which the model is being trained.\nIn terms of the labeling process, it is likely that a team of annotators was involved in labeling the training data for ChatGPT, either manually or using automated techniques. The specific number of annotators and the amount of time required for the labeling process will depend on the size and complexity of the dataset and the specific labeling guidelines and standards used.\nOverall, it is important to note that training a large and complex language model like ChatGPT is a resource-intensive process that requires the efforts of many people working together. It is likely that the training process for ChatGPT involved a significant amount of time and resources, and involved a team of researchers and developers working together to design and implement the model, as well as to collect and pre-process the training data."
  },
  {
    "objectID": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#stanford-university-have-open-sourced-diffusion-lm-a-non-autoregressive-generative-language-model-that-allows-for-fine-grained-control-of-the-models-output-text.-when-evaluated-on-controlled-text-generation-tasks-diffusion-lm-outperforms-existing-methods.-it-is-said-that-this-model-can-be-the-next-gen-chatgpt",
    "href": "posts/4530403c-8332-4e1f-846e-999f1e6a5a8f/index.html#stanford-university-have-open-sourced-diffusion-lm-a-non-autoregressive-generative-language-model-that-allows-for-fine-grained-control-of-the-models-output-text.-when-evaluated-on-controlled-text-generation-tasks-diffusion-lm-outperforms-existing-methods.-it-is-said-that-this-model-can-be-the-next-gen-chatgpt",
    "title": "let chatgpt describe how to build itself",
    "section": "Stanford University have open-sourced Diffusion-LM, a non-autoregressive generative language model that allows for fine-grained control of the model’s output text. When evaluated on controlled text generation tasks, Diffusion-LM outperforms existing methods. it is said that this model can be the next-gen chatgpt",
    "text": "Stanford University have open-sourced Diffusion-LM, a non-autoregressive generative language model that allows for fine-grained control of the model’s output text. When evaluated on controlled text generation tasks, Diffusion-LM outperforms existing methods. it is said that this model can be the next-gen chatgpt\nDiffusion-LM is a non-autoregressive language model developed by researchers at Stanford University, which allows for fine-grained control of the model’s output text. According to the researchers, when evaluated on controlled text generation tasks, Diffusion-LM outperforms existing methods.\nNon-autoregressive language models differ from autoregressive language models, such as GPT-2, in that they do not generate text one word at a time, based on the previous words in the sequence. Instead, non-autoregressive models generate text all at once, based on the entire input sequence. This allows non-autoregressive models to generate text more quickly and efficiently, and can potentially improve the quality of the generated text.\nIt is possible that Diffusion-LM could be used as the basis for a next-generation chatbot or conversation agent, such as ChatGPT. However, it is important to note that the performance of any language model will depend on a variety of factors, including the size and complexity of the model, the quality and diversity of the training data, and the specific goals and tasks for which the model is being used.\nOverall, Diffusion-LM is an innovative and promising approach to language modeling, and it may have the potential to be used in a wide range of applications, including chatbots and conversation agents. However, it is important to carefully evaluate the performance and capabilities of any language model in the specific context in which it is being used, in order to determine its suitability for a particular task or application."
  },
  {
    "objectID": "posts/948c2271-240d-4b29-8799-833cdf21509b/index.html",
    "href": "posts/948c2271-240d-4b29-8799-833cdf21509b/index.html",
    "title": "Maintaining Stability with Mount –Bind: Detaching and Reattaching Linux Disks",
    "section": "",
    "text": "linux disk detach and reattach, how to maintain stability\nuse mount --bind"
  },
  {
    "objectID": "posts/b98a5905-3d6d-4c8f-bc40-2c133384cece/index.html",
    "href": "posts/b98a5905-3d6d-4c8f-bc40-2c133384cece/index.html",
    "title": "macOS window click-through",
    "section": "",
    "text": "macOS window click-through\nuse cmd-click to operate the inactive window without activating it.\nlinux/windows not having this feature. might need custom hot key for this."
  },
  {
    "objectID": "posts/2c6003c1-71f2-49fc-870f-54581851e736/index.html",
    "href": "posts/2c6003c1-71f2-49fc-870f-54581851e736/index.html",
    "title": "macbook is freezing cold to use at winter",
    "section": "",
    "text": "macbook is freezing cold to use at winter\npeople suggest to put something on your hands like fingerless gloves. i just stick with my trousers under my hand wrists in bed since that will put extra protection between my tender palms and biting cold aluminum body."
  },
  {
    "objectID": "posts/efafa8e4-d0be-46ed-8dab-195c67ee8a22/index.html",
    "href": "posts/efafa8e4-d0be-46ed-8dab-195c67ee8a22/index.html",
    "title": "make a quantum computer at home",
    "section": "",
    "text": "make a quantum computer at home\nthe idea is generally good, by using open source software/hardware, or just write quantum programs without building it. in the process you will learn how to use CAD, 3D printers, CNC, pcb manufactory and more. though you should start building something more profitable instead of this quantum stuff.\nhttps://www.illinoisscience.org/2019/04/diy-guide-building-a-quantum-computer/\nhttps://media.ccc.de/v/36c3-10808-build_you_own_quantum_computer_home_-99_of_discount-_hacker_style#t=3298\nhttps://www.dhruvonmath.com/2020/07/19/quantum-computers/\nhttps://hackaday.com/2019/12/30/36c3-build-your-own-quantum-computer-at-home/"
  },
  {
    "objectID": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#similar-models-since-video-generating-models-are-usually-multimodal",
    "href": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#similar-models-since-video-generating-models-are-usually-multimodal",
    "title": "make-a-video and its related text to video projects",
    "section": "similar models, since video generating models are usually multimodal",
    "text": "similar models, since video generating models are usually multimodal\nmaria, A Visual Experience Powered Conversational Agent, suggested by incident\nOFA Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework\nGEN-2 by runway research with paper"
  },
  {
    "objectID": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#according-to-its-paper-its-been-compared-to-a-range-of-models",
    "href": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#according-to-its-paper-its-been-compared-to-a-range-of-models",
    "title": "make-a-video and its related text to video projects",
    "section": "according to its paper, it’s been compared to a range of models",
    "text": "according to its paper, it’s been compared to a range of models\ncogvideo able to process chinese and english input\nmake a video in pytorch text to video generation\nmake a video in tensorflow\nnuwa text to video generation\nmocogan\nmocogan-hd\ntgan-pytorch"
  },
  {
    "objectID": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#there-are-also-some-projects-being-a-video-generator-but-not-so-much-deeplearning-involved",
    "href": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#there-are-also-some-projects-being-a-video-generator-but-not-so-much-deeplearning-involved",
    "title": "make-a-video and its related text to video projects",
    "section": "there are also some projects being a video generator but not so much deeplearning involved",
    "text": "there are also some projects being a video generator but not so much deeplearning involved\nredditube Automatic-Youtube-Reddit-Text-To-Speech-Video-Generator-and-Uploader"
  },
  {
    "objectID": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#tools-for-slideshow-video-effects-presentations",
    "href": "posts/0f788121-46a8-41d0-b86b-c064e1df0077/index.html#tools-for-slideshow-video-effects-presentations",
    "title": "make-a-video and its related text to video projects",
    "section": "tools for slideshow, video effects, presentations",
    "text": "tools for slideshow, video effects, presentations\nphenomenon\nvidshow Simple CLI to generate slideshow video with native FFMPEG\nTwitch-Best-Of create best-of videos on twitch without token\nNingyov galgame effects"
  },
  {
    "objectID": "posts/2afae45e-918f-472b-b9ab-ee483e39c962/index.html",
    "href": "posts/2afae45e-918f-472b-b9ab-ee483e39c962/index.html",
    "title": "Mastering Metasploit Python Scripting: Tutorial and Projects",
    "section": "",
    "text": "metasploit python scripting\npymetasploit tutorial\npymetasploit3\npymetasploit full fledged msfrpc library"
  },
  {
    "objectID": "posts/2cb60293-bf3a-46bf-ac7c-2974a0f47fd1/index.html#graphic-cards",
    "href": "posts/2cb60293-bf3a-46bf-ac7c-2974a0f47fd1/index.html#graphic-cards",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "graphic cards",
    "text": "graphic cards\na100 80g a16 64g (with self-designed thermal solution)"
  },
  {
    "objectID": "posts/2cb60293-bf3a-46bf-ac7c-2974a0f47fd1/index.html#mother-boards",
    "href": "posts/2cb60293-bf3a-46bf-ac7c-2974a0f47fd1/index.html#mother-boards",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "mother boards",
    "text": "mother boards\nAsrock X299e-itx using 4 mini ram slots\nASROCK X570D4I-2T\nAsRock Rack E3C246D4I-2T Mini-ITX Server Motherboard Intel LGA 1151 C246, (max ram: 128gb)\nROMED4ID-2T for amd epyc 7002\nasrock C422 WSI/IPMI"
  },
  {
    "objectID": "posts/2cb60293-bf3a-46bf-ac7c-2974a0f47fd1/index.html#thermo-solutions",
    "href": "posts/2cb60293-bf3a-46bf-ac7c-2974a0f47fd1/index.html#thermo-solutions",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "thermo solutions",
    "text": "thermo solutions\ngenerally you need to design case, thermo yourself, to make both side covered\nuse metal first. do not use plastic in case of overheating and burning\n\ncpu\ncorsair h5 sf (hydra)\n\n\ngpu\na100 thermo mod for hydra"
  },
  {
    "objectID": "posts/2c8f0b93-3105-4bcf-8258-5c1db06dd2a3/index.html",
    "href": "posts/2c8f0b93-3105-4bcf-8258-5c1db06dd2a3/index.html",
    "title": "mixing different version of python libraries and pass environment variables beforehand",
    "section": "",
    "text": "mixing different version of python libraries and pass environment variables beforehand\ncommand of mpython3\nenv JAVA_HOME=/opt/homebrew/Cellar/openjdk/18.0.2 PYTHONPATH=$(python3 -c \"import sys; print(':'.join(sys.path))\"):/opt/homebrew/lib/python3.10/site-packages python3 $@"
  },
  {
    "objectID": "posts/9d8f0ffa-4934-4682-a753-1a5d0b740c90/index.html",
    "href": "posts/9d8f0ffa-4934-4682-a753-1a5d0b740c90/index.html",
    "title": "Mastering Anonymous Payment Methods and Disguised Email Addresses",
    "section": "",
    "text": "modify/create magnet links, create porn videos/some important contents with password with payment method, or provide software for free with virus\nyou do not want to expose yourself. use anonymous email or disposable contact methods.\npayment methods also have to be anonymous."
  },
  {
    "objectID": "posts/5ef8009e-ee2a-4681-b25e-c310187abeb3/index.html",
    "href": "posts/5ef8009e-ee2a-4681-b25e-c310187abeb3/index.html",
    "title": "my notes on paper, hand-written scripts backup",
    "section": "",
    "text": "my notes on paper, hand-written scripts backup\nsee attachments.\nit is in a different folder.\nsync on macbook:\nbash -c 'cd /Users/jamesbrown/.notable/attachments; git pull origin main; git add .; git commit -m \"init commit\"; git push origin main'"
  },
  {
    "objectID": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#peewee",
    "href": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#peewee",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "peewee",
    "text": "peewee\n\ndocs\nofficial doc"
  },
  {
    "objectID": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#milvus",
    "href": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#milvus",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "milvus",
    "text": "milvus\n\ndocs\nofficial doc"
  },
  {
    "objectID": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#neo4j",
    "href": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#neo4j",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "neo4j",
    "text": "neo4j\n\nOGM, object-graph mapping\nactivegraph\ncypher\nneomodel\nneode\n\n\ndocs\ngraph data science\npython driver doc\n\n\ndrivers\nneo4j python driver\nneo4j python graph data science driver\n\n\nwrappers\npypher cypher builder in python intro\nneopy\npygds a python wrapper to call Neo4j Graph Data Science procedures from python using the Neo4j python driver"
  },
  {
    "objectID": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#mindsdb",
    "href": "posts/0799c5e5-e6d5-40d8-a2aa-992bc79192bf/index.html#mindsdb",
    "title": "neo4j, mindsdb, milvus, peewee",
    "section": "mindsdb",
    "text": "mindsdb\nsince mindsdb is sql-based it is time to create monkey patches for sqlalchemy core?\nfrom sqlalchemy import text\n  \n# write the SQL query inside the text() block\nsql = text('SELECT * from BOOKS WHERE BOOKS.book_price &gt; 50')\nresults = engine.execute(sql)\n\ntools\nLightwood is an AutoML framework that enables you to generate and customize machine learning pipelines declarative syntax called JSON-AI doc\n\n\ndocs\nofficial doc\n\n\nwrappers\nsqlalchemy 2.0 doc\npypika sql query builder\nmindsdb native\nmindsdb python sdk"
  },
  {
    "objectID": "posts/99674b95-7150-4d3e-8c7a-91605bc372b8/index.html",
    "href": "posts/99674b95-7150-4d3e-8c7a-91605bc372b8/index.html",
    "title": "notable tips",
    "section": "",
    "text": "notable tips\ndo not use slash in note names, which might cause issues for our syncing program."
  },
  {
    "objectID": "posts/18789634-243a-4b2a-a961-983b0f6af3f6/index.html",
    "href": "posts/18789634-243a-4b2a-a961-983b0f6af3f6/index.html",
    "title": "nvidia driver switch alternatives",
    "section": "",
    "text": "nvidia driver switch alternatives\nalpharetta uses tesla-450 driver\nupdate-glx --config nvidia"
  },
  {
    "objectID": "posts/4907a71f-e579-443d-a34d-e429ceb65332/index.html#im2latex-tensorflow-sucks-looking-for-alternatives",
    "href": "posts/4907a71f-e579-443d-a34d-e429ceb65332/index.html#im2latex-tensorflow-sucks-looking-for-alternatives",
    "title": "on building the lua torch library",
    "section": "im2latex-tensorflow sucks, looking for alternatives",
    "text": "im2latex-tensorflow sucks, looking for alternatives\ntraining on gpu is intensive and will occasionally burn hardware if not careful, doing this on kaggle or modify the software to stop training when gpu goes hot, but we are using trainer here\nharvard nlp showcase\nfor those doesn’t provide pretrained models:\nim2latex in tensorflow, with makefile support, run on tensorflow v1 and python3\nim2latex in pytorch, more recent. the dataset has relocated to here according to official website"
  },
  {
    "objectID": "posts/4907a71f-e579-443d-a34d-e429ceb65332/index.html#install-or-run-python2.7-to-run-im2latex-tensorflow",
    "href": "posts/4907a71f-e579-443d-a34d-e429ceb65332/index.html#install-or-run-python2.7-to-run-im2latex-tensorflow",
    "title": "on building the lua torch library",
    "section": "install or run python2.7 to run im2latex-tensorflow",
    "text": "install or run python2.7 to run im2latex-tensorflow\nyou may need to adapt our modified code to load the weights and test the result against our image.\nit is reported the performance is poor. maybe it does not worth trying.\ndownload tensorflow 0.12.0 for macos here\nvisit here to get all miniconda installers\nto install on macos, download the installer here\nsome tutorial here about libmagic as bonus tips\nCONDA_SUBDIR=osx-64 conda create -n py27 python=2.7  # include other packages here\n \n# ensure that future package installs in this env stick to 'osx-64'\nconda activate py27\nconda config --env --set subdir osx-64\nafter that, do this to get pip on python2.7 (rosetta2)\ncurl https://bootstrap.pypa.io/pip/2.7/get-pip.py -o get-pip.py\npython get-pip.py\ninstall tensorflow version below 1, and doing this can be far more easier on linux. maybe we should do this in conda virtual enviorment to prevent conflicts."
  },
  {
    "objectID": "posts/4907a71f-e579-443d-a34d-e429ceb65332/index.html#we-are-doing-this-for-the-original-lua-implementation-of-im2markup",
    "href": "posts/4907a71f-e579-443d-a34d-e429ceb65332/index.html#we-are-doing-this-for-the-original-lua-implementation-of-im2markup",
    "title": "on building the lua torch library",
    "section": "we are doing this for the original lua implementation of im2markup",
    "text": "we are doing this for the original lua implementation of im2markup\nit works!\ndownload libcudnn5 for torch\nremember to activate torch enviorment by exporting the path to some shell script\ndifference between cudamalloc and cudamallocasync, and that’s some copying and pasting about some generalized template of memory manager function\nqt4 uses CRLF so convert all text files using dos2unix\nneed to hack qt4 files to build qt4\nhack luarocks to allow install from local spec file and download repo from github via https\nhack some lua torch file to be compatible with cuda11\nabout c++ tweaks:\nadd ‘+’ to force type inference\nforce type conversion by using brackets\nsome macro to disable some blocks of code"
  },
  {
    "objectID": "posts/a92eb430-6e3f-436b-95a6-e0fe603673ff/index.html",
    "href": "posts/a92eb430-6e3f-436b-95a6-e0fe603673ff/index.html",
    "title": "openai account registration",
    "section": "",
    "text": "openai account registration\naccording to this tutorial, openai does not accept chinese phone numbers, you should use numbers from india rented on sms-activate (which uses pockyt.io to bridge alipay). you use temporary edu mail like tempumail instead of your own email to prevent issues."
  },
  {
    "objectID": "posts/7325dfbb-eca7-4587-9282-5925b2bdc9cc/index.html",
    "href": "posts/7325dfbb-eca7-4587-9282-5925b2bdc9cc/index.html",
    "title": "opencv corner detection",
    "section": "",
    "text": "opencv corner detection\nfast algorithm for corner detection\nimport numpy as np\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\nimg = cv.imread('blox.jpg',0) # `&lt;opencv_root&gt;/samples/data/blox.jpg`\n# Initiate FAST object with default values\nfast = cv.FastFeatureDetector_create()\n# find and draw the keypoints\nkp = fast.detect(img,None)\nimg2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n# Print all default params\nprint( \"Threshold: {}\".format(fast.getThreshold()) )\nprint( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\nprint( \"neighborhood: {}\".format(fast.getType()) )\nprint( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\ncv.imwrite('fast_true.png', img2)\n# Disable nonmaxSuppression\nfast.setNonmaxSuppression(0)\nkp = fast.detect(img, None)\nprint( \"Total Keypoints without nonmaxSuppression: {}\".format(len(kp)) )\nimg3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\ncv.imwrite('fast_false.png', img3)"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#jax",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#jax",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "jax",
    "text": "jax\ndocs\nautograd and xla (Accelerated Linear Algebra)\n\nWith its updated version of Autograd, JAX can automatically differentiate native Python and NumPy functions. It can differentiate through loops, branches, recursion, and closures, and it can take derivatives of derivatives of derivatives. It supports reverse-mode differentiation (a.k.a. backpropagation) via grad as well as forward-mode differentiation, and the two can be composed arbitrarily to any order.\nXLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes."
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#pyro",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#pyro",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "pyro",
    "text": "pyro\nprobabilistic programming\ngetting started\nexamples\nsample code"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#numpyro",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#numpyro",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "numpyro",
    "text": "numpyro\ngetting started\npyro implementation in numpy, alpha stage"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#scikit-learn",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#scikit-learn",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "scikit-learn",
    "text": "scikit-learn\nmachine learning in python"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#libsvm",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#libsvm",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "libsvm",
    "text": "libsvm\ninstall official python bindings:\npip install -U libsvm-official\nthird-party python libsvm package installed by:\npip install libsvm"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#opennlp",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#opennlp",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "opennlp",
    "text": "opennlp\nhands-on docs\nmodel zoo\nopennlp uses onnx runtime(maybe?), may support m1 inference.\nopennlp is written in java. after installing openjdk on macos with homebrew, run this to ensure openjdk is detected:\n sudo ln -sfn $(brew --prefix)/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk\nopennlp has a language detector for 103 languages, including chinese. opennlp has a sentence detector (separator) which could be trained on chinese (maybe?)\nin order to use opennlp with less code written, here’s how to invoke java from kotlin"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#dl4j",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#dl4j",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "dl4j",
    "text": "dl4j\nfound on mannings article about better search engine suggestions. in this example it is used with lucene, which has image retrieval (LIRE) capability. lucene is also avaliable as lucene.net in dotnet/c#.\nto install lucene.net:\ndotnet add package Lucene.Net --prerelease\ndeep learning library for java"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#xgboost",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#xgboost",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "xgboost",
    "text": "xgboost\ngradient boost is used to train decision trees and classification models."
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#lightgbm",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#lightgbm",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "lightgbm",
    "text": "lightgbm\nLight Gradient Boosting Machine\nhave official commandline tools. installation on macos:\nbrew install lightgbm\ninstall python package on macos:\nbrew install cmake\npip3 install lightgbm"
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#pymc",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#pymc",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "pymc",
    "text": "pymc\nexamples\nif want to enable jax sampling, install numpyro or blackjax via pip\ndifference between pymc3 (old) and pymc (pymc4):\npymc is optimized and faster than pymc3\npymc3 use theano as backend while pymc use aesara (forked theano)\ndocs with live demo of pymc\nPyMC is a probabilistic programming library for Python that allows users to build Bayesian models with a simple Python API and fit them using Markov chain Monte Carlo (MCMC) methods."
  },
  {
    "objectID": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#fastai",
    "href": "posts/a0a6678e-d8ad-4555-afa1-de03af0291e3/index.html#fastai",
    "title": "opennlp, fastai and other machine learning platforms",
    "section": "fastai",
    "text": "fastai\na high level torch wrapper including “out of the box” support for vision, text, tabular, and collab (collaborative filtering) models.\ndocs\ncourses\non the twitter list related to opennlp shown up on its official website, fastai has been spotted.\nfastai does not support macos. or is it? fastai is on top of pytorch. initial support starts with 2.7.8 and now it is currently 2.7.9\nsearching ‘samoyed’ like this in github we get a dataset for pets classification called imagewoof from fastai 2020 tutorial series. more image classes like subcategories of cats may be found in imagenet."
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#tips",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#tips",
    "title": "paddlepaddle applications",
    "section": "tips",
    "text": "tips\nyou can find solutions from kaggle notebooks or aistudio notebooks. you may consider to query them conveniently in one api."
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#repo-location-all-source-code-can-be-found-there",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#repo-location-all-source-code-can-be-found-there",
    "title": "paddlepaddle applications",
    "section": "repo location (all source code can be found there)",
    "text": "repo location (all source code can be found there)\narchive zip\ngit repo"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#全新发布",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#全新发布",
    "title": "paddlepaddle applications",
    "section": "🎉全新发布",
    "text": "🎉全新发布"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#月31日晚830飞桨产业实践范例直播课程继续开讲",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#月31日晚830飞桨产业实践范例直播课程继续开讲",
    "title": "paddlepaddle applications",
    "section": "3月31日晚8:30，飞桨产业实践范例直播课程继续开讲！！！",
    "text": "3月31日晚8:30，飞桨产业实践范例直播课程继续开讲！！！\n国内众多行业都在基于人工智能技术推进行业变革与创新，积极探寻有效、有价值的应用场景进行商业化落地。百度飞桨结合实际经验，选取了几个经典的场景，提供了从数据准备、模型训练优化，到模型部署的全流程可复用方案，降低产业落地门槛,让大家在真实数据环境下深入地了解这些案例，获取产业实现方案。\n3月31日晚8:30，飞桨官方将推出 火灾烟雾检测 产业实践范例直播：\n\n火灾烟雾检测\n\n此外，还有交通、能源、金融、通信、互联网、零售及教育等等各个行业的精彩范例，大家拭目以待～\n欢迎报名直播课加入交流群，如需更多技术交流与合作可扫描下面二维码：\n\n往期案例直播回放：\n\n\n\n案例\n直播回放\n\n\n\n\n花样滑冰\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2251581\n\n\n多模态视频打标签\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2251583\n\n\n视频精彩时刻剪辑\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2257667\n\n\n电瓶车进电梯检测\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2273969\n\n\n异常行为识别\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2273989\n\n\n多类别车辆跟踪\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2274692\n\n\n多类别电表读数识别落地方案\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2309177\n\n\n多类别通信塔识别\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2377623\n\n\n基于车载影像的驾驶环境感知\nhttps://aistudio.baidu.com/aistudio/education/lessonvideo/2376819"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#我是高校用户",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#我是高校用户",
    "title": "paddlepaddle applications",
    "section": "👨‍🏫我是高校用户",
    "text": "👨‍🏫我是高校用户\n\n\n\n我希望：\n我可以学习：\n\n\n\n\n入门深度学习\n零基础实践深度学习:arrow_heading_down:、深度学习百问:arrow_heading_down:、动手学深度学习paddle版:arrow_heading_down:\n\n\n进阶深度学习\n产业实践深度学习、深度学习百问:arrow_heading_down:、面试宝典:arrow_heading_down:\n\n\n趣味深度学习\n特色课程:arrow_heading_down:、飞桨产业实践范例库"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#我是企业用户",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#我是企业用户",
    "title": "paddlepaddle applications",
    "section": "👷‍♂️我是企业用户",
    "text": "👷‍♂️我是企业用户\n\n\n\n我希望：\n我可以学习：\n\n\n\n\n入门深度学习\n零基础实践深度学习:arrow_heading_down:、深度学习百问:arrow_heading_down:、动手学深度学习paddle版:arrow_heading_down:\n\n\n进阶深度学习\n产业实践深度学习、特色课程:arrow_heading_down:、面试宝典:arrow_heading_down:\n\n\n实践深度学习\n飞桨产业实践范例库、飞桨各产品课程:arrow_heading_down:"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#零基础实践深度学习",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#零基础实践深度学习",
    "title": "paddlepaddle applications",
    "section": " 零基础实践深度学习",
    "text": "零基础实践深度学习\n\nAI Studio在线课程：《零基础实践深度学习》：理论和代码结合、实践与平台结合，包含20小时视频课程，由百度杰出架构师、飞桨产品负责人和资深研发人员共同打造。\n《零基础实践深度学习》书籍：本课程配套书籍，由清华出版社2020年底发行，京东/当当等电商均有销售。"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#特色课---transformer系列",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#特色课---transformer系列",
    "title": "paddlepaddle applications",
    "section": "特色课 - Transformer系列",
    "text": "特色课 - Transformer系列\n飞桨教育官方出品的Transformer系列内容解读可以参考以下两个平台。\n\nTransformer原理和实践系列课：https://aistudio.baidu.com/aistudio/education/group/info/24683\n飞桨教育官方账号：https://aistudio.baidu.com/aistudio/personalcenter/thirdview/908086\n\n\n\n\n领域\n章节名称\n课程简介\nnotebook链接\n\n\n\n\nNLP\n经典的预训练语言模型(上)-预训练模型发展历史\n介绍预训练语言模型的发展历史，word2vec，elmo，bert，gpt，bert一些拓展。\nnotebook链接\n\n\nNLP\n经典的预训练模型(上)-ELMo\n全面详细的介绍ELMo模型结构，优缺点等。\nnotebook链接\n\n\nNLP\n经典的预训练模型(上)-Transformer\n讲解Transformer的基本原理，包括Embedding，self-attention，encoder，decoder，复杂度计算，共享机制等内容。\nnotebook链接\n\n\nNLP\n经典的预训练模型(下)-GPT\n全面详细的介绍GPT的原理，预训练和finetune模式，GPT模型结构，优缺点等。\nnotebook链接\n\n\nNLP\n经典的预训练模型(下)-BERT\n全面详细的介绍BERT的基本原理，预训练任务和fine tune的方式，BERT本身的模型结构，优缺点等。\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-RoBERTa\n讲解预训练模型在自然语言理解方面的改进–RoBERTa\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-ERNIE\n讲解预训练模型之自然语言理解的改进：ERNIE\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-KBERT\n讲解预训练模型之自然语言理解的改进：KBERT\nnotebook链接\n\n\nNLP\n预训练模型之自然语言理解-THU-ERNIE\n讲解预训练模型之自然语言理解的改进：THU-ERNIE\nnotebook链接\n\n\nNLP\n预训练模型之长序列建模-Transformer-XL\n讲解预训练模型之长序列建模的改进：Transformer-XL\nnotebook链接\n\n\nNLP\n预训练模型之长序列建模-XLNet\n讲解自然语言理解之长序列建模的改进：XLNet\nnotebook链接\n\n\nNLP\n预训练模型之长序列建模-Longformer\n讲解预训练模型之长序列建模的改进：Longformer\nnotebook链接\n\n\n模型优化\n预训练模型-高效结构\n基于ELECTRA的标点符号预测\nnotebook链接\n\n\n模型优化\n预训练模型-蒸馏\n预训练模型蒸馏算法：Patient-KD、DistilBERT、TinyBERT、DynaBERT模型详解，以及使用DynaBERT策略对TinyBERT进行模型蒸馏\nnotebook链接\n\n\nCV\n图像领域的Transformer-Vit,DeiT\n详细讲解ViT 以及 DeiT原理\nnotebook链接\n\n\nCV\n图像领域的Transformer-Swin Transformer\n详细讲解Swin Transformer原理\nnotebook链接\n\n\nCV\nCV领域的Transformer模型DETR在目标检测任务中的应用\n详细讲解DETR原理及代码解析\nnotebook链接\n\n\n\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#动手学深度学习paddle版",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#动手学深度学习paddle版",
    "title": "paddlepaddle applications",
    "section": "《动手学深度学习》paddle版",
    "text": "《动手学深度学习》paddle版\n本项目将《动手学深度学习》原书中MXNet代码实现改为PaddlePaddle实现。原书作者：阿斯顿·张、李沐、扎卡里 C. 立顿、亚历山大 J. 斯莫拉以及其他社区贡献者，GitHub地址：https://github.com/d2l-ai/d2l-zh。\n本项目面向对深度学习感兴趣，尤其是想使用PaddlePaddle进行深度学习的童鞋。本项目并不要求你有任何深度学习或者机器学习的背景知识，你只需了解基础的数学和编程，如基础的线性代数、微分和概率，以及基础的Python编程。\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#深度学习百问",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#深度学习百问",
    "title": "paddlepaddle applications",
    "section": "深度学习百问",
    "text": "深度学习百问\n深度学习百问内容包含深度学习基础篇、深度学习进阶篇、深度学习应用篇、强化学习篇以及面试宝典，详细信息请参阅Paddle知识点文档平台。\n\n深度学习基础篇\n\n深度学习\n卷积神经网络\n序列模型\n\n深度学习进阶篇\n\n预训练模型\n对抗神经网络\n\n深度学习应用篇\n\n计算机视觉\n\n自然语言处理\n\n推荐系统\n\n产业实践篇\n\n模型压缩\n模型部署\n\n强化学习篇\n\n强化学习\n\n面试宝典\n\n深度学习基础常见面试题\n卷积模型常见面试题\n预训练模型常见面试题\n对抗神经网络常见面试题\n计算机视觉常见面试题\n自然语言处理常见面试题\n推荐系统常见面试题\n模型压缩常见面试题\n强化学习常见面试题\n\n\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#飞桨应用案例集",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#飞桨应用案例集",
    "title": "paddlepaddle applications",
    "section": "飞桨应用案例集",
    "text": "飞桨应用案例集\n\n\n\n领域\n产业案例\n来源\n更多内容\n\n\n\n\n智能工业\n厂区传统仪表统计监测\n飞桨官方\n更多飞桨案例\n\n\n智能工业\n新能源汽车锂电池隔膜质检\n飞桨官方\n更多飞桨案例\n\n\n智能工业\n天池铝材表面缺陷检测\n飞桨官方\n更多飞桨案例\n\n\n智能工业\n安全帽检测\n飞桨官方\n更多飞桨案例\n\n\n智慧城市\n高尔夫球场遥感监测\n飞桨官方\n更多飞桨案例\n\n\n智慧城市\n积雪语义分割\n飞桨官方\n更多飞桨案例\n\n\n智慧城市\n戴口罩的人脸识别\n飞桨官方\n更多飞桨案例\n\n\n智慧交通\n车道线分割和红绿灯安全检测\n飞桨官方\n更多飞桨案例\n\n\n智慧交通\n【PaddleDetection2.0专项】PP-YOLOv2\n飞桨PaddleDet\n更多paddleDet案例\n\n\n智慧交通\nPaddleX助力无人驾驶（基于YOLOv3的车辆检测和车道线分割）\n开发者BIT可达鸭\n更多飞桨案例\n\n\n智慧交通\neblite_标志物检测\n开发者TobeWell\n更多飞桨案例\n\n\n智慧交通\nPaddleOCR: 车牌识别\n飞桨开发者寂寞你快进去\n更多飞桨案例\n\n\n智慧农林\n耕地地块识别\n飞桨官方\n更多飞桨案例\n\n\n智慧农林\nAI识虫\n飞桨官方\n更多飞桨案例\n\n\n智慧农林\n更快更强！ 高效快速的PP-YOLO实战演练\n飞桨PaddleDet\n更多paddleDet案例\n\n\n智慧农林\nPaddleX快速上手-Faster RCNN目标检测\n飞桨PaddleX\n更多PaddleX案例\n\n\n智慧农林\nAI识虫检测分享\n开发者aaaLKgo\n更多飞桨案例\n\n\n智慧农林\n基于PaddleX实现森林火灾监测\n飞桨官方\n更多飞桨案例\n\n\n智慧医疗\n医学常见中草药分类\n飞桨官方\n更多飞桨案例\n\n\n智慧医疗\n眼疾识别\n飞桨官方\n更多飞桨案例\n\n\n智慧医疗\n基于Paddle的肝脏CT影像分割\n开发者代码生成器\n更多飞桨案例\n\n\n智慧医疗\nPaddleHub 肺炎CT影像分析\n飞桨PaddleHub\n更多PaddleHub案例\n\n\n智慧医疗\n基于飞桨PGL的高致病性传染病的传播趋势预测基线系统\n飞桨官方\n更多飞桨案例\n\n\n其他\n人摔倒检测\n开发者Niki_173\n该开发者更多案例\n\n\n其他\n足球比赛动作定位\n飞桨官方\n更多飞桨案例\n\n\n其他\n基于强化学习的飞行器仿真\n飞桨官方\n更多飞桨案例\n\n\n其他\n基于ERNIE-Gram实现语义匹配\n飞桨官方\n更多飞桨案例\n\n\n其他\n『NLP打卡营』实践课5：文本情感分析\n飞桨PaddleNLP\n更多飞桨PaddleNLP案例\n\n\n其他\n『NLP经典项目集』03：利用情感分析选择年夜饭\n飞桨PaddleNLP\n更多飞桨PaddleNLP案例\n\n\n其他\n分类任务：如何在客服对话中，识别客户情绪的好坏\n开发者中大bbking\n更多飞桨案例\n\n\n其他\n『NLP打卡营』实践课3：使用预训练模型实现快递单信息抽取\n飞桨PaddleNLP\n更多飞桨PaddleNLP案例\n\n\n其他\n发愁七夕文案？PaddleHub情话生成送给你 (文内含七夕抽奖)\n飞桨PaddleHub\n更多PaddleHub案例\n\n\n其他\n基于PaddleDetection的PCB瑕疵检测\n飞桨官方\n更多飞桨案例\n\n\n其他\n基于百度飞桨的单/多镜头行人追踪（非官方Baseline）\n开发者BIT可达鸭\n更多飞桨案例\n\n\n其他\nPaddleLite树莓派从0到1：安全帽检测小车部署（一）\n开发者深渊上的炕\n更多飞桨案例\n\n\n其他\nPaddleX、PP-Yolo：手把手教你训练、加密、部署目标检测模型\n开发者深渊上的炕\n更多飞桨案例\n\n\n其他\n中文语音识别\n飞桨官方\n更多飞桨案例\n\n\n其他\nPaddleHub一键OCR中文识别(超轻量8.1M模型，火爆)\n飞桨官方\n更多飞桨案例\n\n\n其他\n老北京城影像修复\n飞桨PaddleGAN\n更多PaddleGAN案例\n\n\n其他\n飞桨创意之星 宋代诗人念诗的秘密——PaddleGAN实现精准唇形合成\n飞桨官方\n更多飞桨案例\n\n\n其他\n通过OCR实现验证码识别\n飞桨官方\n更多飞桨案例\n\n\n其他\nPaddleHub一键OCR中文识别（超轻量8.1M模型，火爆）\n飞桨PaddleHub\n更多PaddleHub案例\n\n\n其他\n全流程，从零搞懂基于PaddlePaddle的图像分割\n开发者nanting03\n更多飞桨案例\n\n\n其他\n负荷预测0.1\n开发者gaomaosheng0\n更多飞桨案例\n\n\n其他\nAI 实现皮影戏，传承正在消失的艺术\n开发者Zohar\n更多飞桨案例\n\n\n其他\n『深度学习7日打卡营』人脸关键点检测\n开发者TC.Long\n更多飞桨案例\n\n\n强化学习\nDDPG算法应用于股票量化交易\n开发者\n更多飞桨案例"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#飞桨学术案例集",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#飞桨学术案例集",
    "title": "paddlepaddle applications",
    "section": "飞桨学术案例集",
    "text": "飞桨学术案例集\n\n\n\n技术方向\n学术案例\n来源\n更多内容\n\n\n\n\n机器学习\n鸢尾花分类\nAIStudio官方\n更多飞桨案例\n\n\n前馈神经网络\n波士顿房价预测\n开发者AIStudioHelper\n更多飞桨案例\n\n\n图像分类\n手写数字识别\nAIStudio官方\n更多飞桨案例\n\n\n图像分类\n猫狗分类\nAIStudio官方\n更多飞桨案例\n\n\n图像分类\n图像分类网络VGG在多表情识别任务中的应用\n开发者之雍Jerry\n更多飞桨案例\n\n\n图像分类\n图像分类-ResNet\n开发者笨笨\n更多飞桨案例\n\n\n图像分类\n用PaddlePaddle实现图像分类-SE_ResNeXt\nAIStudio官方\n更多飞桨案例\n\n\n图像分类\n深入理解图像分类中的Transformer-Vit,DeiT\nPaddleEdu\n更多飞桨案例\n\n\n图像分类\nSwin Transformer\nPaddleEdu\n更多飞桨案例\n\n\n图像分类\n小样本学习(Few-Shot Learning)\n开发者DeepGeGe\n更多飞桨案例\n\n\n图像分割\n经典实例分割模型Mask RCNN\nAIStudio官方\n更多飞桨案例\n\n\n图像分割\nPaddleSeg_DeepLabv3+\n飞桨PaddleSeg\n更多飞桨案例\n\n\n图像分割\n基于PaddlePaddle的语义分割DeepLabV3+实现\nAIStudio官方\n更多飞桨案例\n\n\n图像检测\n深度学习进阶-目标检测\nAIStudio官方\n更多飞桨案例\n\n\n图像检测\n一文详解yolov3目标检测算法\n开发者AIStudio96069\n更多飞桨案例\n\n\n图像检测\nCV领域的Transformer模型DETR在目标检测任务中的应用\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\nTSN视频分类\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\nPaddle2.1实现视频理解经典模型 — TSM\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\n基于Attention和Bi-LSTM实现视频分类\nPaddleEdu\n更多飞桨案例\n\n\n视频分类\nCV领域的Transformer模型TimeSformer实视频理解\nPaddleEdu\n更多飞桨案例\n\n\nGAN\n一文搞懂生成对抗网络之经典GAN（动态图、VisualDL2.0）\n开发者FutureSI\n更多飞桨案例\n\n\nGAN\n基于PaddlePaddle的StarGAN,AttGAN,STGAN算法\nAIStudio官方\n更多飞桨案例\n\n\nOCR\n文字识别-CRNN\n开发者哦吼\n更多飞桨案例\n\n\nNLP\n基于ERNIE实现9项GLUE任务\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域的XLNet模型在情感分析中的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域中的ERNIE模型在阅读理解中的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域的ELECTRA在符号预测上的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\nNLP领域的Transformer在机器翻译上的应用\nPaddleEdu\n更多飞桨案例\n\n\nNLP\n【Paddle打比赛】讯飞赛题—中文问题相似度挑战赛0.9+Baseline\nPaddleEdu\n更多飞桨案例\n\n\nNLP\n用PaddlePaddle实现BERT\nAIStudio官方\n更多飞桨案例\n\n\n多模态\n【Paddle CLIP】你写啥他画啥，一个专属于你的小画家\nPaddleFleet\n更多飞桨案例\n\n\n强化学习\n从代码到论文理解并复现MADDPG算法(PARL)\n开发者Mr.郑先生_\n更多飞桨案例\n\n\n推荐\n基于DeepFM 模型的点击率预估\nPaddleEdu\n更多飞桨案例\n\n\n推荐\n基于DSSM的电影推荐\nAIStudio官方\n更多飞桨案例\n\n\n知识蒸馏\n基于CIFAR100的SSLD蒸馏实验\nPaddleClas\n更多飞桨案例\n\n\n\n返回:arrow_heading_up:"
  },
  {
    "objectID": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#飞桨各产品学习资料汇总",
    "href": "posts/aa5cb7c0-624f-488a-930c-b686cfdcbbb5/index.html#飞桨各产品学习资料汇总",
    "title": "paddlepaddle applications",
    "section": "飞桨各产品学习资料汇总",
    "text": "飞桨各产品学习资料汇总\n\n\n\n产品\n视频课程\n学习文档\n\n\n\n\nPaddleGAN\n生成对抗网络七日打卡营\n\n\n\nPaddleOCR\nOCR自动标注小工具讲解、3.5M超轻量实用OCR模型解读、OCR应用与部署实战\n\n\n\nPaddleClas\nPaddleClas系列直播课\n\n\n\nPaddleDetection\n目标检测7日打卡营\n\n\n\nPaddleX\nPaddleX实例分割任务详解、PaddleX目标检测任务详解、PaddleX语义分割任务详解、PaddleX图像分类任务详解、PaddleX客户端操作指南、飞桨全流程开发工具PaddleX\n\n\n\nPaddleHub\n手把手教你转换PaddleHub模型教程\n\n\n\nVDL\n可视化分析工具助力AI算法快速开发、深度学习算法可视化调优实战演示\n\n\n\n高层API\n高层API助你快速上手深度学习\n\n\n\nPaddleNLP\n基于深度学习的自然语言处理\n\n\n\n\n返回​:arrow_heading_up:"
  },
  {
    "objectID": "posts/6aa42c28-e531-4616-966a-e5614a6d5247/index.html#extensions",
    "href": "posts/6aa42c28-e531-4616-966a-e5614a6d5247/index.html#extensions",
    "title": "peewee related notes",
    "section": "extensions",
    "text": "extensions\npeewee extension docs"
  },
  {
    "objectID": "posts/6aa42c28-e531-4616-966a-e5614a6d5247/index.html#full-text-search",
    "href": "posts/6aa42c28-e531-4616-966a-e5614a6d5247/index.html#full-text-search",
    "title": "peewee related notes",
    "section": "full-text search",
    "text": "full-text search\nofficial doc on full-text search\nhow to use ftsmodel\nPeewee包括 SQLite extension module 它提供了许多特定于sqlite的功能，例如 full-text search ， json extension support 还有更多。如果您想使用这些出色的功能，请使用 SqliteExtDatabase 从 playhouse.sqlite_ext 模块：\nfrom playhouse.sqlite_ext import SqliteExtDatabase\n\nsqlite_db = SqliteExtDatabase('my_app.db', pragmas={\n    'journal_mode': 'wal',  # WAL-mode.\n    'cache_size': -64 * 1000,  # 64MB cache.\n    'synchronous': 0})  # Let the OS manage syncing."
  },
  {
    "objectID": "posts/6aa42c28-e531-4616-966a-e5614a6d5247/index.html#enhancement-proposals",
    "href": "posts/6aa42c28-e531-4616-966a-e5614a6d5247/index.html#enhancement-proposals",
    "title": "peewee related notes",
    "section": "enhancement proposals",
    "text": "enhancement proposals\nenhancement for doing get/update/create at the same time\nenhancement to simplify the BaseModel boilerplate code"
  },
  {
    "objectID": "posts/ae966cd8-ea46-4410-888d-76e53ad2f286/index.html",
    "href": "posts/ae966cd8-ea46-4410-888d-76e53ad2f286/index.html",
    "title": "playwright intercept request header cookie",
    "section": "",
    "text": "playwright intercept request header cookie\ncookie not found on request event handler.\ncookie can be obtained via context.cookies()\nrouter"
  },
  {
    "objectID": "posts/5a2f69ae-dcb3-48c9-a24e-506c8216e450/index.html",
    "href": "posts/5a2f69ae-dcb3-48c9-a24e-506c8216e450/index.html",
    "title": "proxy.py forward localhost proxy to public ip address",
    "section": "",
    "text": "proxy.py forward localhost proxy to public ip address\nsay if you only have one such proxy on localhost, not exposed on router: localhost:8981\nyou execute the command, using proxy.py:\nproxy --port &lt;public_proxy_port&gt; --host &lt;public_proxy_ip_address&gt; \\\n    --plugins proxy.plugin.ProxyPoolPlugin \\\n    --proxy-pool localhost:8981"
  },
  {
    "objectID": "posts/c651d370-66c7-4d2a-858c-40d7d9fcacb1/index.html",
    "href": "posts/c651d370-66c7-4d2a-858c-40d7d9fcacb1/index.html",
    "title": "pyjom producer",
    "section": "",
    "text": "pyjom producer\nvideo and audio needs to be analysised separately.\naudio can be processed by chunks, splited tracks, while video can be itered frame by frame."
  },
  {
    "objectID": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#demonstrate-basic-usage-of-pyro",
    "href": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#demonstrate-basic-usage-of-pyro",
    "title": "pyro and pymc3 basics",
    "section": "demonstrate basic usage of pyro",
    "text": "demonstrate basic usage of pyro\nPyro is a probabilistic programming language developed by Uber that allows users to define complex probabilistic models and perform Bayesian inference on them. Here is a simple example of how Pyro can be used to define and sample from a simple probabilistic model:\nimport pyro\nimport pyro.distributions as dist\n\n# Define a simple probabilistic model\ndef model():\n    # Sample a value from a normal distribution\n    x = pyro.sample(\"x\", dist.Normal(0, 1))\n    # Condition the model on a Bernoulli distribution\n    pyro.sample(\"y\", dist.Bernoulli(logits=x), obs=x &gt; 0)\n\n# Clear the Pyro cache and run the model\npyro.clear_param_store()\nsvi = pyro.infer.SVI(model, pyro.infer.JitTraceEnum_ELBO(), pyro.optim.Adam({\"lr\": 0.01}))\nfor i in range(1000):\n    svi.step()\n\n# Sample from the posterior distribution\nposterior = pyro.infer.Posterior(model)\nsamples = posterior.sample((1000,))\n\n# Print the mean and standard deviation of the samples\nprint(samples.mean())\nprint(samples.std())\nIn this example, we define a simple model that samples a value from a normal distribution and conditions it on a Bernoulli distribution. We then use the SVI (stochastic variational inference) algorithm to perform approximate Bayesian inference on the model. Finally, we sample from the posterior distribution and print the mean and standard deviation of the samples.\nThis is just a simple example of what you can do with Pyro. There are many more advanced features and techniques available in the library, including support for discrete and continuous latent variables, transformations, and more. You can find more information about Pyro in the documentation and examples available on the Pyro website."
  },
  {
    "objectID": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#compare-pyro-to-pymc3",
    "href": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#compare-pyro-to-pymc3",
    "title": "pyro and pymc3 basics",
    "section": "compare pyro to pymc3",
    "text": "compare pyro to pymc3\nPyro and PyMC3 are both probabilistic programming languages that allow users to define complex probabilistic models and perform Bayesian inference on them. Both Pyro and PyMC3 are built on top of PyTorch, a popular machine learning library, and they share many features and capabilities. However, there are also some key differences between the two languages.\nOne of the main differences between Pyro and PyMC3 is the way they represent probabilistic models. Pyro uses a language called “PyroScript” to define models, which is a variant of Python that includes special statements for defining random variables and specifying probabilistic dependencies. PyMC3, on the other hand, uses a more traditional approach where models are defined using objects and functions.\nAnother difference between the two languages is the type of inference algorithms they support. Pyro includes a variety of inference algorithms, including both variational inference and Monte Carlo methods, while PyMC3 is primarily focused on Markov chain Monte Carlo (MCMC) techniques.\nOverall, both Pyro and PyMC3 are powerful probabilistic programming languages that can be used to define and analyze complex probabilistic models. Which one is the best fit for your needs will depend on your specific requirements and preferences."
  },
  {
    "objectID": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#demonstrate-usage-of-pymc3",
    "href": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#demonstrate-usage-of-pymc3",
    "title": "pyro and pymc3 basics",
    "section": "demonstrate usage of pymc3",
    "text": "demonstrate usage of pymc3\nHere is an example of how PyMC3 can be used to define and analyze a simple probabilistic model:\nimport pymc3 as pm\nimport numpy as np\n\n# Define a simple model\nwith pm.Model() as model:\n    # Sample a value from a normal distribution\n    x = pm.Normal(\"x\", mu=0, sigma=1)\n    # Condition the model on a Bernoulli distribution\n    y = pm.Bernoulli(\"y\", p=pm.math.sigmoid(x), observed=x &gt; 0)\n\n# Sample from the posterior distribution using the NUTS algorithm\nwith model:\n    trace = pm.sample(1000, tune=1000)\n\n# Extract the samples and calculate the mean and standard deviation\nsamples = trace[\"x\"]\nmean = np.mean(samples)\nstd = np.std(samples)\n\nprint(f\"Mean: {mean:.3f}\")\nprint(f\"Standard deviation: {std:.3f}\")\nIn this example, we define a simple model that samples a value from a normal distribution and conditions it on a Bernoulli distribution. We then use the NUTS (No-U-Turn Sampler) algorithm to sample from the posterior distribution. Finally, we extract the samples and calculate the mean and standard deviation of the distribution.\nThis is just a simple example of what you can do with PyMC3. There are many more advanced features and techniques available in the library, including support for discrete and continuous latent variables, transformations, and more. You can find more information about PyMC3 in the documentation and examples available on the PyMC3 website."
  },
  {
    "objectID": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#show-me-the-model-written-in-pymc3-and-how-to-train-it-with-code-assume-data-is-obtained",
    "href": "posts/c04f5930-fbea-4ee1-99ba-240bb0750c37/index.html#show-me-the-model-written-in-pymc3-and-how-to-train-it-with-code-assume-data-is-obtained",
    "title": "pyro and pymc3 basics",
    "section": "show me the model written in pymc3 and how to train it with code, assume data is obtained",
    "text": "show me the model written in pymc3 and how to train it with code, assume data is obtained\nHere is an example of a simple natural language generator model written in PyMC3:\nimport pymc3 as pm\n\n# Define the model\nwith pm.Model() as model:\n    # Define the priors for the model parameters\n    alpha = pm.Gamma('alpha', alpha=1, beta=1)\n    beta = pm.Gamma('beta', alpha=1, beta=1)\n    \n    # Define the likelihood function\n    likelihood = pm.BetaBinomial('likelihood', alpha=alpha, beta=beta, observed=data)\n\n# Fit the model to the data using MCMC\nwith model:\n    trace = pm.sample(draws=1000, tune=1000, chains=4)\nThis model defines a Beta-Binomial distribution as the likelihood function, with alpha and beta as the model parameters. The alpha and beta parameters are given Gamma priors, which are a type of continuous probability distribution.\nTo train the model, we can use the sample function from PyMC3 to fit the model to the data using Markov chain Monte Carlo (MCMC) techniques. The draws argument specifies the number of samples to draw from the posterior distribution, the tune argument specifies the number of tuning samples to use, and the chains argument specifies the number of chains to run.\nIt is important to note that this is just a simple example of a natural language generator model written in PyMC3. In practice, the model architecture and training process will depend on the specific requirements and goals of your application, as well as the characteristics of the training data."
  },
  {
    "objectID": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#use-pyro-to-create-an-object-detector",
    "href": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#use-pyro-to-create-an-object-detector",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "use pyro to create an object detector",
    "text": "use pyro to create an object detector\nPyro is a probabilistic programming language built on top of PyTorch that allows you to build flexible, expressive models and perform Bayesian inference. You can use Pyro to build an object detector by defining a probabilistic model that takes an input image and outputs a set of bounding boxes and class labels for the objects in the image.\nHere is an outline of the process you can follow to build an object detector using Pyro:\nCollect and preprocess a dataset of images and annotated bounding boxes for the objects you want to detect.\nDefine a probabilistic model in Pyro that takes an input image and outputs a set of bounding boxes and class labels for the objects in the image. You can use a convolutional neural network (CNN) to extract features from the input image and a multi-layer perceptron (MLP) to predict the bounding boxes and class labels.\nDefine a loss function that measures the difference between the predicted bounding boxes and class labels and the ground truth annotations in the dataset.\nUse Pyro’s optimization algorithms to optimize the model’s parameters with respect to the loss function.\nUse the trained model to make predictions on new images.\nHere is an example of how you can define a simple object detector using Pyro:\nimport torch\nimport pyro\nimport pyro.distributions as dist\n\nclass ObjectDetector(pyro.nn.PyroModule):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.cnn = pyro.nn.Sequential(\n            # Define the CNN layers here\n        )\n        self.mlp = pyro.nn.Sequential(\n            # Define the MLP layers here\n        )\n\n    def forward(self, x):\n        features = self.cnn(x)\n        bboxes, labels = self.mlp(features)\n        return bboxes, labels\n\n# Define the loss function\ndef loss(model, x, bboxes, labels):\n    predicted_bboxes, predicted_labels = model(x)\n    bbox_loss = # Compute the bounding box loss here\n    label_loss = # Compute the class label loss here\n    return bbox_loss + label_loss\n\n# Define the model and optimizer\nmodel = ObjectDetector(num_classes)\noptimizer = pyro.optim.Adam({\"lr\": 0.001})\n\n# Loop over the dataset and optimize the model\nfor x, bboxes, labels in dataset:\n    optimizer.zero_grad()\n    loss_value = loss(model, x, bboxes, labels)\n    loss_value.backward()\n    optimizer.step()\n\n# Use the trained model to make predictions on new images\nx_new = # Load a new image\nbboxes, labels = model(x_new)\nThis is just a simple example of how you can use Pyro to build an object detector. You can find more detailed examples and resources on the Pyro website (https://pyro.ai/) and in the Pyro documentation (https://docs.pyro.ai/)."
  },
  {
    "objectID": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#define-the-cnn-network-and-the-mlp-network",
    "href": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#define-the-cnn-network-and-the-mlp-network",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "define the CNN network and the MLP network",
    "text": "define the CNN network and the MLP network\nTo define the CNN and MLP networks for an object detector using Pyro, you can use Pyro’s nn module to define the layers of the network.\nFor the CNN, you can use a combination of convolutional, pooling, and fully-connected (FC) layers to extract features from the input image. Here is an example of how you can define a simple CNN in Pyro:\nimport torch.nn as nn\nimport pyro.nn as pyro_nn\n\nclass CNN(pyro_nn.PyroModule):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = pyro_nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = pyro_nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = pyro_nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = pyro_nn.Linear(32 * 7 * 7, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = self.pool(x)\n        x = x.view(-1, 32 * 7 * 7)\n        x = self.fc1(x)\n        return x\nFor the MLP, you can use a combination of fully-connected (FC) layers to predict the bounding boxes and class labels for the objects in the image. Here is an example of how you can define an MLP in Pyro:\nimport torch.nn as nn\nimport pyro.nn as pyro_nn\n\nclass MLP(pyro_nn.PyroModule):\n    def __init__(self, num_classes, num_bboxes):\n        super().__init__()\n        self.fc1 = pyro_nn.Linear(num_classes, 128)\n        self.fc2 = pyro_nn.Linear(128, num_bboxes * 4)\n        self.fc3 = pyro_nn.Linear(128, num_bboxes * num_classes)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        bboxes = self.fc2(x)\n        labels = self.fc3(x)\n        return bboxes, labels\nYou can then combine the CNN and MLP into a single object detector model by defining a PyroModule that takes an input image and outputs the predicted bounding boxes and class labels.\nTo continue building an object detector using Pyro, you can define a loss function that measures the difference between the predicted bounding boxes and class labels and the ground truth annotations in the dataset. You can then use Pyro’s optimization algorithms to optimize the model’s parameters with respect to the loss function.\nFor example, you can define a loss function that combines a bounding box loss and a class label loss. The bounding box loss can be computed using the mean squared error (MSE) between the predicted bounding boxes and the ground truth bounding boxes. The class label loss can be computed using the cross-entropy loss between the predicted class labels and the ground truth labels.\nHere is an example of how you can define the loss function:\nimport torch\nimport pyro\nimport pyro.distributions as dist\n\ndef loss(model, x, bboxes, labels):\n    predicted_bboxes, predicted_labels = model(x)\n    bbox_loss = torch.mean((predicted_bboxes - bboxes) ** 2)\n    label_loss = torch.nn.CrossEntropyLoss()(predicted_labels, labels)\n    return bbox_loss + label_loss\nTo optimize the model’s parameters, you can use an optimization algorithm such as Adam or SGD. Here is an example of how you can define an optimizer and use it to train the model:\nimport torch\nimport pyro\nimport pyro.optim as optim\n\n# Define the model and optimizer\nmodel = ObjectDetector(num_classes, num_bboxes)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Loop over the dataset and optimize the model\nfor x, bboxes, labels in dataset:\n    optimizer.zero_grad()\n    loss_value = loss(model, x, bboxes, labels)\n    loss_value.backward()\n    optimizer.step()\nOnce the model is trained, you can use it to make predictions on new images. To do this, you can pass the new images through the model and use the predicted bounding boxes and class labels to draw bounding boxes around the objects in the image.\n# Use the trained model to make predictions on new images\nx_new = # Load a new image\nbboxes, labels = model(x_new)\n\n# Draw bounding boxes around the objects in the image\nfor bbox, label in zip(bboxes, labels):\n    # Draw the bounding box on the image\n    # ...\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#how-to-do-3d-convolution-on-video-with-pytorch",
    "href": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#how-to-do-3d-convolution-on-video-with-pytorch",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "how to do 3d convolution on video with pytorch",
    "text": "how to do 3d convolution on video with pytorch\nTo perform 3D convolution on a video with PyTorch, you can use the nn.Conv3d layer. This layer applies a 3D convolution over the input tensor, which has shape (batch_size, channels, depth, height, width).\nHere is an example of how you can define a 3D convolutional neural network (CNN) in PyTorch to process a video:\nimport torch\nimport torch.nn as nn\n\nclass VideoCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(32 * 7 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = self.pool(x)\n        x = x.view(-1, 32 * 7 * 7 * 7)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\nTo process a video with this CNN, you can first split the video into a sequence of frames, and then pass each frame through the CNN. You can use the torchvision.io.read_video function to read the video and the torchvision.transforms.ToTensor transformation to convert the frames to tensors.\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Read the video and split it into a sequence of frames\nvideo, _ = torchvision.io.read_video(\"video.mp4\")\nframes = video.permute(0, 3, 1, 2)\n\n# Convert the frames to tensors\ntransform = transforms.ToTensor()\ntensors = [transform(frame) for frame in frames]\n\n# Pass the tensors through the CNN\ncnn = VideoCNN()\noutputs = [cnn(tensor.unsqueeze(0)) for tensor in tensors]\nYou can then use the output of the CNN to perform various tasks, such as classification or object detection.\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#use-3d-convolution-to-determine-location-of-watermark-on-video",
    "href": "posts/8ff06e42-7bec-4215-8ecd-6abb6f4ace68/index.html#use-3d-convolution-to-determine-location-of-watermark-on-video",
    "title": "pyro object detection, 3d convolution on video, remove watermark in video",
    "section": "use 3d convolution to determine location of watermark on video",
    "text": "use 3d convolution to determine location of watermark on video\nTo use 3D convolution to determine the location of a watermark on a video, you can build a convolutional neural network (CNN) that takes a sequence of frames from the video as input and outputs a prediction of the watermark’s location.\nHere is an outline of the process you can follow to build such a CNN using PyTorch:\nCollect and preprocess a dataset of videos and annotated watermark locations. To do this, you can manually label the watermark locations in a set of videos, or you can use a watermarked video and its corresponding unwatermarked version to automatically generate labels.\nDefine a CNN in PyTorch that takes a sequence of frames from a video as input and outputs a prediction of the watermark’s location. You can use 3D convolutional layers to extract features from the frames and fully-connected (FC) layers to make the prediction.\nDefine a loss function that measures the difference between the predicted watermark location and the ground truth location. You can use a regression loss such as mean squared error (MSE) or mean absolute error (MAE).\nUse PyTorch’s optimization algorithms to optimize the CNN’s parameters with respect to the loss function.\nUse the trained CNN to make predictions on new videos.\nHere is an example of how you can define a simple CNN in PyTorch to determine the location of a watermark on a video:\nimport torch\nimport torch.nn as nn\n\nclass WatermarkCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(32 * 7 * 7 * 7, 128)\n        self.fc2 = nn.Linear(128, 4)  # 4 values for (x, y, width, height)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = self.pool(x)\n        x = x.view(-1, 32 * 7 * 7 * 7)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\nTo train this CNN, you can loop over the dataset and optimize the CNN’s parameters with respect to the loss function. Here is an example of how you can define the loss function and optimizer, and use them to train the CNN:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the loss function\ndef loss(predictions, targets):\n    return nn.MSELoss()(predictions, targets)\n\n# Define the model and optimizer\nmodel = WatermarkCNN()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Loop over the dataset and optimize the model\nfor frames, watermark_location in dataset:\n    optimizer.zero_grad()\n    predictions = model(frames)\n    loss_value = loss(predictions, watermark_location)\n    loss_value.backward()\n    optimizer.step()\nOnce the model is trained, you can use it to make predictions on new videos. To do this, you can pass the frames of the video through the model and use the predicted watermark location to draw a bounding box around the watermark.\n# Use the trained model to make predictions on new videos\nframes = # Load the frames of a new video\npredictions = model(frames)\n\n# Draw a bounding box around the watermark\nx, y, width, height = predictions\n# Draw the bounding box on the frames\n# ...\nI hope this helps! Let me know if you have any questions."
  },
  {
    "objectID": "posts/66234df0-f0a7-4854-ad1f-6acc58b8be50/index.html",
    "href": "posts/66234df0-f0a7-4854-ad1f-6acc58b8be50/index.html",
    "title": "python retry libraries",
    "section": "",
    "text": "python retry libraries\nretrying\nretry\nretry2"
  },
  {
    "objectID": "posts/0353ac19-40e7-4147-9061-8d4f2abad15b/index.html#打赏-e-begging",
    "href": "posts/0353ac19-40e7-4147-9061-8d4f2abad15b/index.html#打赏-e-begging",
    "title": "Monetizing Bilibili Content with GIFs, QR Codes, and JSON Modification",
    "section": "打赏 e-begging",
    "text": "打赏 e-begging\nYukio 20:36:09 帮忙百度 然后时不时发个打赏链接\nYukio 20:36:22 涩图里面加赞助二维码"
  },
  {
    "objectID": "posts/0353ac19-40e7-4147-9061-8d4f2abad15b/index.html#通用发广告策略",
    "href": "posts/0353ac19-40e7-4147-9061-8d4f2abad15b/index.html#通用发广告策略",
    "title": "Monetizing Bilibili Content with GIFs, QR Codes, and JSON Modification",
    "section": "通用发广告策略",
    "text": "通用发广告策略\nYukio 16:06:23 我在想 用GIF怎么引流\nYukio 16:06:50 GIF不让你扫码 所以说只能GIF下面放个链接\nYukio 16:07:30 GIF下面可以放二维码？\nYukio 16:07:41 都可以试试 反正不吃亏\nYukio 16:17:17 狗子狗叫太吵了\nYukio 16:17:33 转成GIF感觉会效果好点\nYukio 16:19:26 我甚至可以直接ugc当成封面 然后下面发链接引流"
  },
  {
    "objectID": "posts/0353ac19-40e7-4147-9061-8d4f2abad15b/index.html#逆向qq安卓版",
    "href": "posts/0353ac19-40e7-4147-9061-8d4f2abad15b/index.html#逆向qq安卓版",
    "title": "Monetizing Bilibili Content with GIFs, QR Codes, and JSON Modification",
    "section": "逆向qq安卓版",
    "text": "逆向qq安卓版\nYukio 15:51:01 我最近研究了一下b站转发QQ群的原理\nYukio 15:51:01 QQ群里面只能发一种JSON\nYukio 15:51:02 里面有个token看起来像是checksum\nYukio 15:51:02 所以JSON里面稍作改动就发不出去了\nYukio 15:51:02 不过如果你可以拦截安卓的intent 用frida拦截生成这个JSON的call 可能可以生成任意的JSON"
  },
  {
    "objectID": "posts/01e397c9-4558-4f97-9f08-42057c4b2f3e/index.html",
    "href": "posts/01e397c9-4558-4f97-9f08-42057c4b2f3e/index.html",
    "title": "qzone send shuoshuo",
    "section": "",
    "text": "qzone send shuoshuo\nopqbot qzone module replacement\nanimeapi more than just sending shuoshuo\nlogin via qrcode\nplaywright upload file\n有很多上传接口 都可以这样自动化 因为这些接口可能会变化 自己写成playwright脚本是最省事的方案"
  },
  {
    "objectID": "posts/bd353eae-f580-4e6e-9f8f-fb8eb9f5d263/index.html#gif-ratings",
    "href": "posts/bd353eae-f580-4e6e-9f8f-fb8eb9f5d263/index.html#gif-ratings",
    "title": "random giphy gifs",
    "section": "gif ratings",
    "text": "gif ratings\nofficial doc\nvulgar rate:\nr &gt; pg-13 &gt; pg &gt; g\nwhile ‘y’ means accepting all shits, not ‘youth’ nor ‘young’"
  },
  {
    "objectID": "posts/bd353eae-f580-4e6e-9f8f-fb8eb9f5d263/index.html#implementation",
    "href": "posts/bd353eae-f580-4e6e-9f8f-fb8eb9f5d263/index.html#implementation",
    "title": "random giphy gifs",
    "section": "implementation",
    "text": "implementation\ngiphy has many extensible apis. i guess most media platforms are all the same (complex enough), but we have to start somewhere though…\ngiphy has ‘clips’ now. clips are gifs with sound, just like short videos.\nbeta key limitations:\n1000 requests per day, 42 requests per hour\nor just use the public beta key? does that subject to the rate limit?\nthis public beta key is trashed.\nvar PUBLIC_BETA_API_KEY = 'dc6zaTOxFJmzC';\nis this public api key? maybe it is both api and sdk key. Gc7131jiJuvI7IdN0HZ1D7nh0ow5BU6g\napi keys: IoJVsWoxDPKBr6gOcCgOPWAB25773hqP lTRWAEGHjB1AkfO0sk2XTdujaPB5aH7X\nsdk keys: 6esYBEm9OG3wAifbBFZ2mA0Ml6Ic0rvy sXpGFDGZs0Dv1mmNFvYaGUvYwKX0PWIh\nto use api: https://github.com/austinkelleher/giphy-api\nto use sdk: https://github.com/Giphy/giphy-js/blob/master/packages/fetch-api/README.md\nfind public api keys inside html:\n          window.GIPHY_FE_MOBILE_API_KEY = \"L8eXbxrbPETZxlvgXN9kIEzQ55Df04v0\"\n          window.GIPHY_FE_WEB_API_KEY = \"Gc7131jiJuvI7IdN0HZ1D7nh0ow5BU6g\"\n          window.GIPHY_FE_FOUR_O_FOUR_API_KEY = \"MRwXFtxAnaHo3EUMrSefHWmI0eYz5aGe\"\n          window.GIPHY_FE_STORIES_AND_GIPHY_TV_API_KEY = \"3eFQvabDx69SMoOemSPiYfh9FY0nzO9x\"\n          window.GIPHY_FE_DEFAULT_API_SERVICE_KEY = \"5nt3fDeGakBKzV6lHtRM1zmEBAs6dsIc\"\n          window.GIPHY_FE_GET_POST_HEADERS_KEY = \"e0771ed7b244ec9c942bea646ad08e6bf514f51a\"\n          window.GIPHY_FE_MEDIUM_BLOG_API_KEY = \"i3dev0tcpgvcuaocfmdslony2q9er7tvfndxcszm\"\n          window.GIPHY_FE_EMBED_KEY = \"eDs1NYmCVgdHvI1x0nitWd5ClhDWMpRE\"\nsearch for ‘ear flops’ to locate the tags in ‘samoyed.html’"
  },
  {
    "objectID": "posts/a7becfc6-62f8-47e9-819d-9a7f8c1bfecf/index.html",
    "href": "posts/a7becfc6-62f8-47e9-819d-9a7f8c1bfecf/index.html",
    "title": "raspberry pi tweaks",
    "section": "",
    "text": "raspberry pi tweaks\nopenai says i should edit /etc/wpa_supplicant/wpa_supplicant.conf like this to connect to 5G wifi:\nnetwork={\n    ssid=\"&lt;SSID&gt;\"\n    psk=\"&lt;password&gt;\"\n    frequency=5180\n}\nalso set frequency of wifi card like this:\nsudo ifdown wlan0 && sudo ifup wlan0\nsudo iw dev wlan0 set freq 5180\nunplug ethernet, then we are golden.\ntraceroute baidu.com\nhow to check avaliable wifi ssids without network-manager:\nsudo iwlist wlan0 scan | grep ESSID\ndefault login (maybe not):\nusername: pi\npassword: raspberry\nin order to start sshd, touch ssh under boot partition\nrecover dhcpcd service:\nsudo systemctl enable dhcpcd.service\nsudo systemctl restart dhcpcd.service\nconfig the password with proot -S &lt;path_to_rootfs&gt; -b &lt;boot_partition&gt;:/boot -q qemu-arm /usr/bin/bash and passwd\nyou’ve installed raspap on this device. you use the default credentials. this shit will not connect to our wifi automatically, thus block your way of running docker containers on it with only macbook.\nseriously? do you really need docker on macos? or just on raspberry pi?\nchange apt sources:\nsudo sed -i 's|raspbian.raspberrypi.org|mirrors.ustc.edu.cn/raspbian|g' /etc/apt/sources.list\nsudo sed -i 's|mirrordirector.raspbian.org|mirrors.ustc.edu.cn/raspbian|g' /etc/apt/sources.list\nsudo sed -i 's|archive.raspbian.org|mirrors.ustc.edu.cn/raspbian|g' /etc/apt/sources.list\nsudo sed -i 's|archive.raspberrypi.org/debian|mirrors.ustc.edu.cn/archive.raspberrypi.org/debian|g' /etc/apt/sources.list.d/raspi.list\nusing nmcli to scan and connect wifi\nsudo nmcli dev wifi rescan\nsudo nmcli dev wifi connect &lt;SSID&gt; password &lt;PASSWORD&gt;\nsharing network:\nssh -R 1080 pi@10.42.0.33\nedit /etc/network/interfaces:\nauto lo\n\niface lo inet loopback\n\nauto eth0\niface eth0 inet static\naddress 10.42.0.33\nnetmask 255.255.255.0\ngateway 10.42.0.1\n\nallow-hotplug wlan0\nauto wlan0\n\niface wlan0 inet dhcp\n#wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf\nwpa-ssid \"&lt;SSID&gt;\"\nwpa-psk \"&lt;PASSWORD&gt;\"\ninstall packages:\nsudo apt-get -o Acquire::http::proxy=\"socks5h://127.0.0.1:1080/\"  -o Acquire::Check-Valid-Until=false -o Acquire::Check-Date=false update --allow-releaseinfo-change\n\nsudo apt-get -o Acquire::http::proxy=\"socks5h://127.0.0.1:1080/\"  -o Acquire::Check-Valid-Until=false -o Acquire::Check-Date=false upgrade -y"
  },
  {
    "objectID": "posts/8570a708-203b-4187-b410-f32dd663ed1c/index.html#show-me-how-to-recreate-cloudpss-platform",
    "href": "posts/8570a708-203b-4187-b410-f32dd663ed1c/index.html#show-me-how-to-recreate-cloudpss-platform",
    "title": "recreating cloudpss",
    "section": "show me how to recreate cloudpss platform",
    "text": "show me how to recreate cloudpss platform\nCreating a cloud platform like CloudPss can be a daunting task, but it is achievable with the right knowledge and resources. Here are some general steps to help you get started:\nResearch CloudPss and other cloud platforms to understand their features, benefits, and drawbacks.\nDefine your goals and objectives for the platform. This can include features you need, target users, and any other important considerations.\nSelect a cloud provider and decide on the best hosting option for your platform.\nDesign the architecture and decide on a programming language.\nDevelop the platform using secure coding practices.\nTest the platform for security and performance.\nDeploy the platform and monitor usage.\nMaintain and update the platform regularly.\nFollow these steps and you will be able to create a cloud platform like CloudPss. Good luck!"
  },
  {
    "objectID": "posts/8570a708-203b-4187-b410-f32dd663ed1c/index.html#what-is-cloudpss",
    "href": "posts/8570a708-203b-4187-b410-f32dd663ed1c/index.html#what-is-cloudpss",
    "title": "recreating cloudpss",
    "section": "what is cloudpss",
    "text": "what is cloudpss\nCloudPss is a modeling and simulation platform for the energy internet. [1] It uses a completely self-developed electromagnetic transient simulation kernel and is designed to provide comprehensive analysis services for the energy internet. [2] It is based on cloud computing and focuses on solving the problem of modeling and simulation of power system. [3] CloudPss can be used for various purposes, including monitoring and optimization of electricity grids, power system dynamic simulation, and fault analysis.\nReferences: [1] Documentation - CloudPSS Documentation [2] CloudPss-An Energy Internet Modeling and Simulation Tool in … [3] A High-Performance Power System Simulator Based on Cloud …"
  },
  {
    "objectID": "posts/8570a708-203b-4187-b410-f32dd663ed1c/index.html#how-to-rebuild-the-modeling-and-simulation-part-of-cloudpss-using-open-source-software",
    "href": "posts/8570a708-203b-4187-b410-f32dd663ed1c/index.html#how-to-rebuild-the-modeling-and-simulation-part-of-cloudpss-using-open-source-software",
    "title": "recreating cloudpss",
    "section": "how to rebuild the modeling and simulation part of cloudpss using open-source software",
    "text": "how to rebuild the modeling and simulation part of cloudpss using open-source software\nThe modeling and simulation part of CloudPss can be rebuilt using open source software such as GridLAB-D, OpenModelica, and GridAPPS-D.\nGridLAB-D is a free and open source software platform for modeling and simulation of electric power systems. It is designed to take advantage of high-performance computing resources for system analysis and optimization. [4]\nOpenModelica is a free and open source modeling and simulation environment. It is designed for modeling, simulation, and optimization of complex systems. [5]\nGridAPPS-D is an open-source software platform for modeling and simulation of the power system. It is designed to enable the integration of hardware and software components related to the energy internet. [6]\nUsing these open source software platforms is a great way to rebuild the modeling and simulation part of CloudPss."
  },
  {
    "objectID": "posts/3790d751-a3d9-4805-82ec-e8010f6a3d07/index.html",
    "href": "posts/3790d751-a3d9-4805-82ec-e8010f6a3d07/index.html",
    "title": "rectangle related calculation",
    "section": "",
    "text": "rectangle related calculation\nbetter make polygon into blocks first (pixelize) and then decompose it into rectangles\nrectirization A polygon to rectangle conversion tool, written in cpp\nextractrect find the largest rectangle inscribed in a non-convex polygon\ndecompose rectlinear polygon in nodejs"
  },
  {
    "objectID": "posts/135e7799-8a8a-458b-89a9-6cc16533e06a/index.html",
    "href": "posts/135e7799-8a8a-458b-89a9-6cc16533e06a/index.html",
    "title": "Register a New File in Android Gallery using Beanshell Code",
    "section": "",
    "text": "register new file to android gallery\ncode in beanshell:\nimport android.net.Uri;\nIntent mediaScanIntent = new Intent(Intent.ACTION_MEDIA_SCANNER_SCAN_FILE);\nUri contentUri = Uri.parse(\"file:///storage/emulated/0/Movies/output0_higher.mp4\");\nmediaScanIntent.setData(contentUri);\nctx.sendBroadcast(mediaScanIntent);"
  },
  {
    "objectID": "posts/7cae4a58-5d2e-4132-813e-f62740b02844/index.html",
    "href": "posts/7cae4a58-5d2e-4132-813e-f62740b02844/index.html",
    "title": "reset windows server password",
    "section": "",
    "text": "reset windows server password\nchntpw does not work this time. it will auto restore the SAM file.\ninstead, under directory C:\\Windows\\System32, swap Utilman.exe (remember to back it up) with cmd.exe then click widgets in login window to popup command prompt, type net user &lt;username&gt; &lt;password&gt; to reset.\nreference"
  },
  {
    "objectID": "posts/c4fd2cb8-6aae-4e70-9e1c-ee3e0bc23850/index.html#喜马拉雅fm",
    "href": "posts/c4fd2cb8-6aae-4e70-9e1c-ee3e0bc23850/index.html#喜马拉雅fm",
    "title": "scrape podcasts, filter keywords, convert voices by gender and pitch",
    "section": "喜马拉雅fm",
    "text": "喜马拉雅fm"
  },
  {
    "objectID": "posts/c4fd2cb8-6aae-4e70-9e1c-ee3e0bc23850/index.html#apple-podcasts",
    "href": "posts/c4fd2cb8-6aae-4e70-9e1c-ee3e0bc23850/index.html#apple-podcasts",
    "title": "scrape podcasts, filter keywords, convert voices by gender and pitch",
    "section": "apple podcasts",
    "text": "apple podcasts\napple podcasts are free.\nsummarize the podcast or use the keywords extracted from podcast for advanced search\n去除语气词 tts与变声器混合\npodcast review scraper\npodscraper"
  },
  {
    "objectID": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#review-previous-notes-and-fill-blanks-list-blanks-below-better-with-direct-link-to-it",
    "href": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#review-previous-notes-and-fill-blanks-list-blanks-below-better-with-direct-link-to-it",
    "title": "self-learning schedules",
    "section": "review previous notes and fill blanks, list blanks below, better with direct link to it",
    "text": "review previous notes and fill blanks, list blanks below, better with direct link to it\n\ntag all notes, especially mark out those stub, incomplete ones\nreview and complete bilibili courses, reorder, rename and split them if necessary\n传播学导论把笔记做完"
  },
  {
    "objectID": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#review-your-history",
    "href": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#review-your-history",
    "title": "self-learning schedules",
    "section": "review your history",
    "text": "review your history\n\nvisit all previously visited links and store briefs generated by readbility.js and elinks"
  },
  {
    "objectID": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#finance-and-quantatitive-trading",
    "href": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#finance-and-quantatitive-trading",
    "title": "self-learning schedules",
    "section": "finance and quantatitive trading",
    "text": "finance and quantatitive trading\n\ndesign a basic algorithm and complete regression test on joinquant\ndesign and complete one regression test offline"
  },
  {
    "objectID": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#artificial-general-intelligence",
    "href": "posts/a376763c-6ad8-4175-a3bb-3cf5feea9033/index.html#artificial-general-intelligence",
    "title": "self-learning schedules",
    "section": "artificial general intelligence",
    "text": "artificial general intelligence\n\ndesign a program automatically execute commands in shell\ndesign a program automatically click everywhere in GUI ### study nars\nrun python version of nars ### study opencog ### study he4o"
  },
  {
    "objectID": "posts/a4ad3c93-fea6-4786-ad93-0edf9f6372c9/index.html",
    "href": "posts/a4ad3c93-fea6-4786-ad93-0edf9f6372c9/index.html",
    "title": "setup ssh server on windows, enable key based authentication to windows ssh server",
    "section": "",
    "text": "setup ssh server on windows, enable key based authentication to windows ssh server\ntutorial\nchange the sshd config\nappend the client’s public key to “authorized_keys” and “administrators_authorized_keys”\nrestart the service"
  },
  {
    "objectID": "posts/ba59cde9-f2dd-4e22-8e17-b36aed9f3c17/index.html",
    "href": "posts/ba59cde9-f2dd-4e22-8e17-b36aed9f3c17/index.html",
    "title": "some notes just like me: today i learned (til)",
    "section": "",
    "text": "some notes just like me: today i learned (til)\nrepo here: til"
  },
  {
    "objectID": "posts/0b50a6c5-7d77-4fb4-bd0d-9c804bce228e/index.html",
    "href": "posts/0b50a6c5-7d77-4fb4-bd0d-9c804bce228e/index.html",
    "title": "speech recognition",
    "section": "",
    "text": "speech recognition\nSpeech Recognition using MFCC and HMM"
  },
  {
    "objectID": "posts/5f6b955c-e40b-4da2-bb90-9e34b400a9c6/index.html",
    "href": "posts/5f6b955c-e40b-4da2-bb90-9e34b400a9c6/index.html",
    "title": "splash: webpage rendering service",
    "section": "",
    "text": "splash: webpage rendering service\nwhere’s the animation anyway?\nsplash doc"
  },
  {
    "objectID": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#recommend-some-popular-orm-libraries-for-kotlin",
    "href": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#recommend-some-popular-orm-libraries-for-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "recommend some popular ORM libraries for kotlin",
    "text": "recommend some popular ORM libraries for kotlin\nThere are several popular ORM (Object-Relational Mapping) libraries that you can use with Kotlin. Some of the most popular options include:\nHibernate: Hibernate is a popular and widely used ORM library that is written in Java, but can be used with Kotlin. It provides a range of features including object-relational mapping, automatic database schema generation, and support for multiple database systems.\nRoom: Room is an ORM library that is specifically designed for use with Android and Kotlin. It provides an easy-to-use API for accessing and manipulating SQLite databases, and is widely used in Android development.\nExposed: Exposed is a lightweight and flexible ORM library for Kotlin that is built on top of JDBC (Java Database Connectivity). It provides a range of features including support for transactions, stored procedures, and database views.\nJOOQ: JOOQ (Java Object Oriented Querying) is a popular ORM library that provides a type-safe way to write SQL queries in Java and Kotlin. It generates Java code based on your database schema, allowing you to write queries using a fluent API.\nKtor-Exposed: Ktor-Exposed is an ORM library that is built on top of Exposed and is designed for use with the Ktor web framework. It provides a convenient way to access and manipulate database data within the context of a Ktor application."
  },
  {
    "objectID": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#use-exposed-in-kotlin",
    "href": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#use-exposed-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "use exposed in kotlin",
    "text": "use exposed in kotlin\nTo use Exposed in Kotlin, you will need to add the Exposed library to your project dependencies. If you are using Gradle, you can add the following dependency to your build.gradle file:\nimplementation 'org.jetbrains.exposed:exposed:0.24.1'\nNext, you will need to create a database connection and configure the Exposed library to use it. Here is an example of how you might do this using a MySQL database:\nimport org.jetbrains.exposed.sql.*\nimport org.jetbrains.exposed.sql.transactions.transaction\nimport org.jetbrains.exposed.sql.SchemaUtils.create\nimport org.jetbrains.exposed.sql.SchemaUtils.drop\n\nfun main() {\n    // Connect to the database\n    Database.connect(\"jdbc:mysql://localhost/mydatabase\", \"com.mysql.cj.jdbc.Driver\", \"username\", \"password\")\n\n    // Define your database schema\n    transaction {\n        create(Users)\n        create(Orders)\n\n        // Insert some data\n        Users.insert {\n            it[name] = \"Alice\"\n            it[age] = 25\n        }\n\n        // Query the data\n        val alice = Users.select { Users.name eq \"Alice\" }.single()\n        println(\"Alice's age is ${alice[Users.age]}\")\n\n        // Update the data\n        Users.update({ Users.name eq \"Alice\" }) {\n            it[age] = 26\n        }\n\n        // Delete the data\n        Users.deleteWhere { Users.name eq \"Alice\" }\n    }\n}\n\n// Define your table and columns\nobject Users : Table() {\n    val id = integer(\"id\").autoIncrement().primaryKey()\n    val name = varchar(\"name\", length = 50)\n    val age = integer(\"age\")\n}\n\nobject Orders : Table() {\n    val id = integer(\"id\").autoIncrement().primaryKey()\n    val userId = integer(\"user_id\").references(Users.id)\n    val product = varchar(\"product\", length = 50)\n    val quantity = integer(\"quantity\")\n}\nThis example demonstrates how to create a database table, insert data, query data, update data, and delete data using Exposed and Kotlin."
  },
  {
    "objectID": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#can-spring-use-yaml-or-json-for-configuration",
    "href": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#can-spring-use-yaml-or-json-for-configuration",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "can spring use yaml or json for configuration",
    "text": "can spring use yaml or json for configuration\nYes, Spring can use YAML (YAML Ain’t Markup Language) or JSON (JavaScript Object Notation) for configuration.\nSpring provides support for using YAML and JSON as an alternative to traditional property files for defining application configuration. To use YAML or JSON for configuration, you will need to include the spring-boot-configuration-processor dependency in your project and use the @ConfigurationProperties annotation to bind your configuration to a Java bean.\nHere is an example of how you might use YAML for configuration in a Spring Boot application:\n# application.yml\n\nserver:\n  port: 8080\n\napp:\n  name: My App\n  version: 1.0.0\n  greeting: Hello, world!\n@ConfigurationProperties(\"app\")\nclass AppProperties {\n    lateinit var name: String\n    lateinit var version: String\n    lateinit var greeting: String\n}\nYou can then inject the AppProperties bean into your application and use the configuration values like this:\n@RestController\nclass HelloController(private val appProperties: AppProperties) {\n    @GetMapping(\"/\")\n    fun hello() = appProperties.greeting\n}\nYou can use a similar approach to use JSON for configuration in your Spring Boot application."
  },
  {
    "objectID": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#demonstrate-aspect-oriented-programming-in-kotlin",
    "href": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#demonstrate-aspect-oriented-programming-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "demonstrate aspect oriented programming in kotlin",
    "text": "demonstrate aspect oriented programming in kotlin\nAspect-Oriented Programming (AOP) is a programming paradigm that aims to modularize cross-cutting concerns, such as logging, security, and transaction management, into distinct aspects that can be applied to multiple parts of an application.\nIn Kotlin, you can use the Spring Framework’s AOP support to implement aspect-oriented programming. Here is an example of how you might use AOP to log the execution of a method in Kotlin:\nimport org.aspectj.lang.annotation.Aspect\nimport org.aspectj.lang.annotation.Before\nimport org.slf4j.Logger\nimport org.slf4j.LoggerFactory\nimport org.springframework.stereotype.Component\n\n@Aspect\n@Component\nclass LoggingAspect {\n    val logger: Logger = LoggerFactory.getLogger(LoggingAspect::class.java)\n\n    @Before(\"execution(* com.example.service.*.*(..))\")\n    fun logMethodExecution() {\n        logger.info(\"Method execution\")\n    }\n}\nIn this example, the @Aspect annotation indicates that this class represents an aspect, and the @Before annotation specifies a pointcut (a point in the code where the aspect should be applied) and an advice (the action that should be taken when the pointcut is reached). In this case, the pointcut matches any method execution in the com.example.service package, and the advice logs a message.\nTo use this aspect in your application, you will need to enable AOP support in your Spring configuration. You can do this by adding the @EnableAspectJAutoProxy annotation to your configuration class, like this:\nimport org.springframework.context.annotation.Configuration\nimport org.springframework.context.annotation.EnableAspectJAutoProxy\n\n@Configuration\n@EnableAspectJAutoProxy\nclass AopConfiguration\nWith these changes in place, the aspect will be applied to all matching method executions in your application and the log message will be printed whenever a method is executed."
  },
  {
    "objectID": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#use-spring-mvc-in-kotlin",
    "href": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#use-spring-mvc-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "use spring mvc in kotlin",
    "text": "use spring mvc in kotlin\nTo use Spring MVC (Model-View-Controller) in Kotlin, you will need to create a Spring Boot application and add the spring-boot-starter-web dependency to your project.\nHere is an example of how you might set up a simple Spring MVC application in Kotlin:\nimport org.springframework.boot.autoconfigure.SpringBootApplication\nimport org.springframework.boot.runApplication\nimport org.springframework.stereotype.Controller\nimport org.springframework.web.bind.annotation.GetMapping\nimport org.springframework.web.bind.annotation.ResponseBody\n\n@SpringBootApplication\nclass Application\n\nfun main(args: Array&lt;String&gt;) {\n    runApplication&lt;Application&gt;(*args)\n}\n\n@Controller\nclass HelloController {\n    @GetMapping(\"/\")\n    @ResponseBody\n    fun hello() = \"Hello, world!\"\n}\nIn this example, the HelloController class is annotated with @Controller to indicate that it is a Spring MVC controller. The hello() method is annotated with @GetMapping to specify that it should handle HTTP GET requests to the root URL, and with @ResponseBody to indicate that the method’s return value should be written directly to the HTTP response body.\nWith these changes in place, you can start your Spring Boot application and visit http://localhost:8080 in your web browser to see the “Hello, world!” message.\nYou can use similar annotations to handle other HTTP methods, such as POST, PUT, and DELETE, and to bind request parameters to method arguments. You can also use the @RequestMapping annotation to specify more complex URL patterns, and the @ModelAttribute annotation to bind request parameters to model attributes that can be used in view templates."
  },
  {
    "objectID": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#use-jsp-with-spring-in-kotlin",
    "href": "posts/4fa2fd02-d1e8-44f9-ad90-f2f8c988bebc/index.html#use-jsp-with-spring-in-kotlin",
    "title": "spring, orm, kotlin, yaml config, jsp",
    "section": "use jsp with spring in kotlin",
    "text": "use jsp with spring in kotlin\nTo use JSP (Java Server Pages) with Spring in Kotlin, you will need to create a Spring Boot application and add the spring-boot-starter-web and spring-boot-starter-tomcat dependencies to your project.\nBy default, Spring Boot will look for JSP files in the src/main/webapp/WEB-INF/jsp directory. You will need to create this directory structure and add your JSP files to it.\nHere is an example of a simple JSP file that displays a message:\n&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Hello&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, world!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nTo render this JSP file in your Spring MVC application, you will need to create a controller that maps a request to the JSP file. Here is an example of how you might do this in Kotlin:\nimport org.springframework.stereotype.Controller\nimport org.springframework.web.bind.annotation.GetMapping\n\n@Controller\nclass HelloController {\n    @GetMapping(\"/\")\n    fun hello() = \"hello\"\n}\nIn this example, the hello() method is annotated with @GetMapping to specify that it should handle HTTP GET requests to the root URL. The method’s return value, “hello”, is the name of the JSP file that should be rendered in response to the request.\nWith these changes in place, you can start your Spring Boot application and visit http://localhost:8080 in your web browser to see the message displayed by the JSP file.\nYou can use similar approaches to map requests to other JSP files and to pass data from your controllers to your JSP files using model attributes."
  },
  {
    "objectID": "posts/ba9a5985-5cf6-4bc6-9430-c213ee2882ac/index.html",
    "href": "posts/ba9a5985-5cf6-4bc6-9430-c213ee2882ac/index.html",
    "title": "stop background jobs",
    "section": "",
    "text": "stop background jobs\njobs | grep -Eo \"[0-9][0-9][0-9]+\" | xargs -iabc kill -s KILL abc"
  },
  {
    "objectID": "posts/9f17c51c-348c-4514-8b33-b1fcb5a8011d/index.html",
    "href": "posts/9f17c51c-348c-4514-8b33-b1fcb5a8011d/index.html",
    "title": "supercollider",
    "section": "",
    "text": "supercollider\ncells multilanguage live-coding support for creative coding\ntidalcycles music and visual effects with code, written in haskell, live coding\nai唱歌 歌声合成 ai singing voice generation DiffSinger原作者的官方仓库：https://github.com/MoonInTheRiver/DiffSinger OpenVPI团队的第三方fork仓库：https://github.com/openvpi/DiffSinger\nMusic generation by Microsoft full workshop (Muzic): https://github.com/microsoft/muzic\nto control and record sonic pi (maybe you can slience it while still record its output?): Programming Music with Sonic Pi or Supercollider (planned) Controlling Sonic Pi from the command line, in Python.\n原版 扒谱 音轨分离 人声分离 伴奏分离 ultimate vocal remover\nAI扒谱: demucs链接 spleeter alike： https://github.com/facebookresearch/demucs\nicassp2022-vocal-transcription链接： https://github.com/keums/icassp2022-vocal-transcription\n我写的小工具： https://wws.lanzoub.com/iheoe06cv3yh\nwav2midi basic pitch by spotify: https://github.com/spotify/basic-pitch\nAutotune Autotalent pitch correction: https://github.com/ederwander/PyAutoTune/blob/master/Examples/TuneAndPlayFromFile.py http://tombaran.info/autotalent.html\nMusic Understanding\nSymbolic Music Understanding: MusicBERT\nAutomatic Lyrics Transcription: PDAugment\nMusic Generation\nSong Writing: SongMASS\nLyric Generation: DeepRapper\nMelody Generation: TeleMelody\nAccompaniment Generation: PopMAG\nSinging Voice Synthesis: HiFiSinger\nmusisep music instrument separation: https://github.com/rgcda/Musisep https://www.math.colostate.edu/~king/software/Musisep-API/\naudio to midi collection: https://gist.github.com/natowi/d26c7e97443ec97e8032fb7e7596f0b0\nRecurrent Neural Network for generating piano MIDI-files from audio (MP3, WAV, etc.)\nhttps://github.com/BShakhovsky/PolyphonicPianoTranscription A python program which performs an FFT on an audio file and produces a MIDI file from the results\nhttps://github.com/NFJones/audio-to-midi Extract the melody from an audio file and export to MIDI\nhttps://github.com/justinsalamon/audio_to_midi_melodia Performs pitch detection on a polyphonic audio source and outputs to MIDI\nhttps://github.com/corbanbrook/spectrotune Program to detect pitch from wav files and write in time quantized MIDI\nhttps://github.com/vaibhavnayel/Audio-to-MIDI-converter A CNN which converts piano audio to a simplified MIDI format\nhttps://github.com/hartmetzls/audio_to_midi An application of vocal melody extraction.\nhttps://github.com/bill317996/Audio-to-midi Transcribes polyphonic piano pieces from audio (MP3, WAV, etc.) into MIDI-files\nhttps://github.com/BShakhovsky/PianoAudioToMidi Polyphonic pitch tracking in real time using machine learning algorithms\nhttps://github.com/jaym910/polyphonic_track Audio to MIDI converter\nhttps://github.com/sbaeunker/audioToMidiConverter Explore Transcribing Techniques to auto convert audio to midi\nhttps://github.com/Goldspear/audio2midi PitchToMIDI\nhttps://github.com/KatoIppei/PitchToMIDI See releases Piano & Drums\nhttps://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription Tony: a tool for melody transcription\nhttps://www.sonicvisualiser.org/tony/ https://github.com/sonic-visualiser/tony https://code.soundsoftware.ac.uk/projects/tony (https://github.com/mikulas-mrva/tony2max) MusicTranscription\nhttps://github.com/ClaraBing/CS229-MusicTranscription pYIN\nhttps://code.soundsoftware.ac.uk/projects/pyin https://github.com/ronggong/pypYIN (python) Onsets and Frames Transcription (Piano & Drums)\nhttps://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription https://piano-scribe.glitch.me/ WaoN\nhttps://sourceforge.net/projects/waon/\naudio2midi conversion works great with prior source separation https://github.com/deezer/spleeter or others like https://github.com/rgcda/Musisep\naudio2midi: https://github.com/ZZWaang/audio2midi\nmultichannel audio to midi: https://github.com/NFJones/audio-to-midi\nlstm music generation: https://github.com/dakshtrehan/AI-Music-Generation\ngpt2 chord to melody: https://github.com/tanreinama/chord2melody\nmulti instruments music generation: https://github.com/salu133445/musegan\nmusicautobot: https://github.com/bearpelican/musicautobot"
  },
  {
    "objectID": "posts/a5b2ecea-f93f-403b-a117-0544bdef661d/index.html#view-full-logs",
    "href": "posts/a5b2ecea-f93f-403b-a117-0544bdef661d/index.html#view-full-logs",
    "title": "systemd on linux, maintainence details",
    "section": "view full logs",
    "text": "view full logs\njournalctl -u &lt;serviceName&gt;.service"
  },
  {
    "objectID": "posts/a5b2ecea-f93f-403b-a117-0544bdef661d/index.html#create-install-restart-reload",
    "href": "posts/a5b2ecea-f93f-403b-a117-0544bdef661d/index.html#create-install-restart-reload",
    "title": "systemd on linux, maintainence details",
    "section": "create, install, restart, reload",
    "text": "create, install, restart, reload\ncd /etc/systemd/system\ncreate &lt;serviceName&gt;.service\nsystemctl enable &lt;serviceName&gt;.service\nsystemctl daemon-reload\nsystemctl start &lt;serviceName&gt;.service"
  },
  {
    "objectID": "posts/a5b2ecea-f93f-403b-a117-0544bdef661d/index.html#sample-systemd-service-config-files",
    "href": "posts/a5b2ecea-f93f-403b-a117-0544bdef661d/index.html#sample-systemd-service-config-files",
    "title": "systemd on linux, maintainence details",
    "section": "sample systemd service config files",
    "text": "sample systemd service config files\nmaybe we should add some autorestart configs at it?\nfrpc_service.service\n[Unit]\nDescription=frpc service, expose ssh, webdav and code-server ports\nWants=network.target\nAfter=syslog.target network-online.target\n\n[Service]\nType=simple\nUser=root\nExecStart=/root/frp_client_linux/frp_0.36.2_linux_amd64/frpc -c frpc.ini\nWorkingDirectory=/root/frp_client_linux/frp_0.36.2_linux_amd64\nRestart=on-failure\nRestartSec=10\nKillMode=process\n\n[Install]\nWantedBy=multi-user.target\npyjom_webdav_rclone_service.service\n[Unit]\nDescription=rclone webdav served on pyjom, after the disk is mounted\n\n[Service]\nUser=root\nExecStart=/usr/bin/python3 mount_help_and_serve_pyjom.py\nWorkingDirectory=/root/Desktop/works/restore_sessions\n\n[Install]\nWantedBy=multi-user.target\ntempthrottle.service\n[Unit]\nDescription=temperature control, cpu temperature under 60 celsius\n\n[Service]\nUser=root\nExecStart=/usr/bin/python3 tempthrottle_daemon.py\nWorkingDirectory=/root/Desktop/works/restore_sessions\n\n[Install]\nWantedBy=multi-user.target\nclash_fastgithub.service\n[Unit]\nDescription=Clash Fastgithub Proxy\nAfter=network.target\n\n[Service]\nType=simple\nRestart=always\nExecStart=/usr/bin/clash -d /etc/clash\n\n[Install]\nWantedBy=multi-user.target\ntujia_scraper_qq_bot.service\n[Unit]\nDescription=two crucial services: tujia scraper, qq bot\nWants=network.target\nAfter=syslog.target network-online.target\n\n[Service]\nEnvironment=\"DISPLAY=:1\"\nEnvironment=\"XAUTHORITY=/root/.Xauthority\"\nUser=root\nExecStart=/usr/bin/python3 main_daemon.py\nWorkingDirectory=/root/Desktop/works/restore_sessions\n\n[Install]\nWantedBy=graphical.target\nsync_git_repos_syncdog.service\n\n[Unit]\nDescription=syncdog (server), to sync things to the cloud (github)\nWants=sshd.service\nWants=network.target\n\n[Service]\nUser=root\nExecStart=/usr/bin/python3 syncdog_test.py\nWorkingDirectory=/root/Desktop/works/sync_git_repos\n\n[Install]\nWantedBy=multi-user.target"
  },
  {
    "objectID": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#if-i-put-a-puppy-into-a-group-of-fake-puppies-controlled-by-humans-interacting-with-the-puppy-and-speak-english-only-to-the-puppy-will-the-puppy-speak-english",
    "href": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#if-i-put-a-puppy-into-a-group-of-fake-puppies-controlled-by-humans-interacting-with-the-puppy-and-speak-english-only-to-the-puppy-will-the-puppy-speak-english",
    "title": "teach puppies to speak english (video script)",
    "section": "if i put a puppy into a group of fake puppies controlled by humans, interacting with the puppy and speak English only to the puppy, will the puppy speak English?",
    "text": "if i put a puppy into a group of fake puppies controlled by humans, interacting with the puppy and speak English only to the puppy, will the puppy speak English?\nIt is unlikely that a puppy will be able to learn to speak English or any other human language simply by being placed in a group of fake puppies controlled by humans and interacting with the puppy. While puppies are highly intelligent and capable of learning, they do not have the cognitive abilities necessary to understand and produce human language.\nIn order for a puppy or any other non-human animal to learn a human language, it would need to be trained and reinforced through extensive and consistent exposure to the language, as well as being provided with the necessary physical and cognitive abilities to understand and produce the sounds and gestures associated with the language. Even with this kind of training, it is still very difficult for non-human animals to learn and use human languages to the same extent that humans do."
  },
  {
    "objectID": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#well-you-know-my-fake-puppies-speak-english",
    "href": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#well-you-know-my-fake-puppies-speak-english",
    "title": "teach puppies to speak english (video script)",
    "section": "well you know my fake puppies speak English",
    "text": "well you know my fake puppies speak English\nI apologize if my previous response was unclear. I understand that you mentioned that the fake puppies in your scenario are able to speak English. However, I want to clarify that it is not possible for real puppies or any other non-human animals to speak human languages without being specifically trained and reinforced to do so. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do.\nI hope this helps to clarify the matter. If you have any further questions, please don’t hesitate to ask."
  },
  {
    "objectID": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#if-all-puppies-speak-english-will-their-children-be-taught-english-all-by-parents-and-puppy-communities-without-human-intervention",
    "href": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#if-all-puppies-speak-english-will-their-children-be-taught-english-all-by-parents-and-puppy-communities-without-human-intervention",
    "title": "teach puppies to speak english (video script)",
    "section": "if all puppies speak English, will their children be taught English all by parents and puppy communities without human intervention?",
    "text": "if all puppies speak English, will their children be taught English all by parents and puppy communities without human intervention?\nIt is not possible for puppies or any other non-human animals to speak human languages without being specifically trained and reinforced to do so by humans or other animals that have been trained by humans. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do.\nTherefore, even if a group of puppies were all able to speak English as a result of being trained by humans, their offspring would not be able to learn English simply by being exposed to their parents or other members of their community speaking English. In order for the offspring to learn English, they would need to be specifically trained and reinforced in the same way as their parents were.\nIt is worth noting that the ability to learn and use human language is a complex and uniquely human trait that is not shared by other animals to the same extent. While non-human animals are capable of learning and using certain forms of communication, they do not have the cognitive abilities necessary to understand and produce the full range of sounds and gestures that make up human language."
  },
  {
    "objectID": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#ok-if-their-parents-were-taught-how-to-teach-english-then",
    "href": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#ok-if-their-parents-were-taught-how-to-teach-english-then",
    "title": "teach puppies to speak english (video script)",
    "section": "Ok, if their parents were taught how to teach English, then",
    "text": "Ok, if their parents were taught how to teach English, then\nIf the parents of a group of puppies were trained to speak English by humans, and then were able to teach their offspring how to speak English, it is still unlikely that the puppies would be able to learn and use English to the same extent as humans. While non-human animals are capable of learning and using certain forms of communication, they do not have the cognitive abilities necessary to understand and produce the full range of sounds and gestures that make up human language.\nIn order for a non-human animal, such as a puppy, to learn and use human language, it would need to be provided with consistent and extensive exposure to the language, as well as being trained and reinforced through a structured and systematic approach. Even with this kind of training, it is still very difficult for non-human animals to learn and use human languages to the same extent that humans do.\nIt is worth noting that the ability to learn and use human language is a complex and uniquely human trait that is not shared by other animals to the same extent. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do."
  },
  {
    "objectID": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#if-i-use-some-machine-to-teach-every-puppy-english-by-evolution-is-it-possible-for-puppies-to-speak-english-without-help-from-machine-and-human",
    "href": "posts/ca582d30-a938-468c-8c06-f810d5f1b5de/index.html#if-i-use-some-machine-to-teach-every-puppy-english-by-evolution-is-it-possible-for-puppies-to-speak-english-without-help-from-machine-and-human",
    "title": "teach puppies to speak english (video script)",
    "section": "If I use some machine to teach every puppy English, by evolution, is it possible for puppies to speak English without help from machine and human?",
    "text": "If I use some machine to teach every puppy English, by evolution, is it possible for puppies to speak English without help from machine and human?\nIt is not possible for puppies or any other non-human animals to evolve the ability to speak human languages without the assistance of humans or machines. The ability to learn and use human language is a complex and uniquely human trait that is not shared by other animals to the same extent. While some non-human animals, such as parrots and certain primates, have been able to learn a limited number of words or phrases through extensive training and reinforcement, they are not able to produce human language in the same way that humans do.\nIn order for a non-human animal, such as a puppy, to learn and use human language, it would need to be provided with consistent and extensive exposure to the language, as well as being trained and reinforced through a structured and systematic approach. Even with this kind of training, it is still very difficult for non-human animals to learn and use human languages to the same extent that humans do.\nUsing a machine to teach puppies English would likely involve a similar process of training and reinforcement, and would not result in the puppies evolving the ability to speak the language on their own. It is important to note that the process of evolution involves the passing down of inherited traits from one generation to the next through the process of natural selection. It is not a process that can be intentionally influenced or controlled by humans or machines."
  },
  {
    "objectID": "posts/854d874c-e4d2-4e17-a0db-8ac6e3d3a90e/index.html",
    "href": "posts/854d874c-e4d2-4e17-a0db-8ac6e3d3a90e/index.html",
    "title": "tencent jce",
    "section": "",
    "text": "tencent jce\njce is a tcp protocol, like protobuf\njcestruct usage\npython -m jce 1f2e3d4c5b6a79\n发送tcp数据判断mitm当中箭头含义"
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#non-max-suppression-in-combining-similar-bounding-boxes",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#non-max-suppression-in-combining-similar-bounding-boxes",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "non-max suppression in combining similar bounding boxes",
    "text": "non-max suppression in combining similar bounding boxes\nthe lib:\nfrom imutils.object_detection import non_max_suppression"
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#basically-greek-letters",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#basically-greek-letters",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "basically greek letters",
    "text": "basically greek letters\nmaybe you can document another great range of symbols by just enabling the system to search in greek?\ncould also search among math symbols, do math ocr."
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#kindly-reminders",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#kindly-reminders",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "kindly reminders",
    "text": "kindly reminders\nwhen building python c++ libraries without xcode, please add commandline header files like this:\nin order to have this during build: /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/Headers/Python.h\nwe need to do:\nln -s /Library/Developer/CommandLineTools /Applications/Xcode.app/Contents/Developer"
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#search-by-image-instead-of-cranking-latex-out",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#search-by-image-instead-of-cranking-latex-out",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "search by image instead of cranking latex out",
    "text": "search by image instead of cranking latex out\n\nimage search libraries\ncharacter level optical char segmentation called chargrid ocr\nimage match used for copyright violation detection, using phash algorithm"
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#get-the-latex-out",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#get-the-latex-out",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "get the latex out",
    "text": "get the latex out\n\nfirst detect the location of math formula\nscanning single shot detection for math formulas\ndataset for math symbol detection\ndetect different part of document with yolov3\nmath expression detection\n\n\nnext find the tool for picture to latex conversion\n新开源的Python工具——Pix2Text (P2T)，目标是 Mathpix 的Python开源替代品，现在可以识别截图中的数学公式并转换为Latex表示，也可以识别图片中的中英文文字。在线Demo： https://huggingface.co/spaces/breezedeus/pix2text 。 Github: https://github.com/breezedeus/pix2text ，Gitee: https://gitee.com/breezedeus/pix2text 。\nattention based math ocr\ngui of image2latex\nim2latex-tensorflow\nim2markup with only nvidia support using torch, model for latex conversion can be found here\ndeeplearning picture to latex\npix2tex\nusing pix2tex\n中文公式 手写公式识别 需要进一步训练\n中文 手写 pytorch版本"
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#mask-latex-area-and-get-conventional-things-out",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#mask-latex-area-and-get-conventional-things-out",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "mask latex area and get conventional things out",
    "text": "mask latex area and get conventional things out\neasyocr with pytorch support"
  },
  {
    "objectID": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#search-the-formula",
    "href": "posts/5674da79-f22a-41c4-bb7f-e8a8769be44e/index.html#search-the-formula",
    "title": "scan this picture and index the whole video/document/ppt/textbook!",
    "section": "search the formula",
    "text": "search the formula\nformula search based on sympy\ncan we render latex to picture with sympy?\nlatex search engine"
  },
  {
    "objectID": "posts/f91950ee-e2fb-4954-a7b1-8816f1ce0d13/index.html#debugging",
    "href": "posts/f91950ee-e2fb-4954-a7b1-8816f1ce0d13/index.html#debugging",
    "title": "the kali command on macos",
    "section": "debugging",
    "text": "debugging\nwhen kali is off, this mac will go crazy and hang everything.\nneed to scan for kali existance on demand, not all the time."
  },
  {
    "objectID": "posts/f91950ee-e2fb-4954-a7b1-8816f1ce0d13/index.html#developing",
    "href": "posts/f91950ee-e2fb-4954-a7b1-8816f1ce0d13/index.html#developing",
    "title": "the kali command on macos",
    "section": "developing",
    "text": "developing\nshould we use p2p networks to speed up remote connections like n2n or tinc?\nwould it be interesting to run all our kali connectors ranged from vscode-ssh-connect, rclone mount and direct ssh connection via kali command dynamically by our kali discovery service, if we can reload the nginx daemon on demand.\nusing redis to store some daemon reported values.\nhow about we set the workding directory of redis-server to /tmp so that the dump.rdb file will never take space after reboot?\nwe need to know if this will successifully launch after reboot since /tmp may not exist by that time\ndefault redis server port: 6379\ninstall redis-server service:\neasyd -w /tmp -l redis_server -- /opt/homebrew/bin/redis-server\nfirst value is online.\nnext value is kali_ip.\nusing both value to determine whether to connect to kali or not, and the exact address."
  },
  {
    "objectID": "posts/8f60db89-fd5b-481f-8251-d8490d5713cf/index.html",
    "href": "posts/8f60db89-fd5b-481f-8251-d8490d5713cf/index.html",
    "title": "the singing bot",
    "section": "",
    "text": "the still image to singing face bot, lip-sync video generation\nsadtalker\nwombo.ai, likely to be talking head or yanderifier\nhttps://github.com/mchong6/GANsNRoses/\nhttps://github.com/williamyang1991/VToonify\n生成高质量的艺术人像视频是计算机图形学和视觉中一项重要且理想的任务。虽然已经提出了一系列基于强大的 StyleGAN 成功的人像图像卡通化模型，但这些面向图像的方法在应用于视频时存在明显的局限性，在这项工作中，我们通过引入一种新颖的 VToonify 框架来研究具有挑战性的可控高分辨率肖像视频风格迁移。具体来说，VToonify 利用StyleGAN 的中高分辨率层基于编码器提取的多尺度内容特征来渲染高质量的艺术肖像，以更好地保留帧细节。作为输入，有助于输出具有自然运动的完整面部区域。 amework 与现有的基于 StyleGAN 的图像卡通化模型兼容，以将其扩展到视频卡通化，并继承了这些模型的吸引人的特性，可灵活地控制颜色和强度。这项工作展示了基于 Toonify 和 DualStyleGAN 的 VToonify 的两个实例，用于基于集合广泛的实验结果证明了我们提出的 VToonify 框架在生成具有灵活风格控制的高质量和时间连贯的艺术肖像视频方面优于现有方法的有效性\nall in one colab text to talking face generation, also consider paddlespeech example: https://github.com/ChintanTrivedi/ask-fake-ai-karen\navaliable from paddlegan as an example used in paddlespeech, the artificial host.\nlip-sync accurate wav2lip: https://github.com/Rudrabha/Wav2Lip\nlipgan generate realistic lip-sync talking head animation(fully_pythonic branch or google colab notebook): https://github.com/Rudrabha/LipGAN\ngoogle’s lipsync implementation, using tensorflow facemesh: https://github.com/google/lipsync https://lipsync.withyoutube.com/ https://github.com/tensorflow/tfjs-models/tree/master/facemesh\nnetwork reverse engineering for wombo.ai: https://github.com/the-garlic-os/wombo-reverse-engineering\nmatamata using vosk models, recommend to use gentle lip-sync method: https://github.com/AI-Spawn/Auto-Lip-Sync https://github.com/Matamata-Animator/Matamata-Core https://github.com/Yey007/Auto-Lip-Sync\nai-based lip reading might be irrelevant to lip-sync video generation: https://github.com/eflood23/lipsync"
  },
  {
    "objectID": "posts/939e7b2c-765f-44e3-a2a8-c15f127feed3/index.html",
    "href": "posts/939e7b2c-765f-44e3-a2a8-c15f127feed3/index.html",
    "title": "tools from breachforums",
    "section": "",
    "text": "tools from breachforums\n\nInvicti\n\nInvicti is a web application security scanner hacking tool to find SQL Injection, XSS, and vulnerabilities in web applications or services automatically.\n\nFortify WebInspect It is used to identify security vulnerabilities by allowing it to test the dynamic behavior of running web applications.\nCain & Abel It is used to recover the MS Access passwords\nNmap (Network Mapper) Used in port scanning, one of the phases in ethical hacking, is the finest hacking software ever.\nNessus Nessus is the world’s most well-known vulnerability scanner, which was designed by tenable network security. It is free and is chiefly recommended for non-enterprise usage.\nNikto Checks web servers and identifies over 6400 CGIs or files that are potentially dangerous\nKismet Kismet is basically a sniffer and wireless-network detector that works with other wireless cards and supports raw-monitoring mode.\nNetStumbler Identifying AP (Access Point) network configuration\nAcunetix Integration of scanner results into other platforms and tools\nNetsparker Uniquely verifies identified vulnerabilities, showing that they are genuine, not false positives\nIntruder Integrates with Slack, Jira, and major cloud providers\nNmap Contains a data transfer, redirection, and debugging tool\nMetasploit Ideal for finding security vulnerabilities\nAircrack-Ng It can crack WEP keys and WPA2-PSK, and check Wi-Fi cards\nWireshark Allows coloring rules to packet lists to facilitate analysis\nOpenVAS OpenVAS has the capabilities of various high and low-level Internet and industrial protocols, backed up by a robust internal programming language.\nSQLMap Supports executing arbitrary commands\nEttercap Live connections sniffer\nMaltego Performs real-time information gathering and data mining\nBurp Suite Uses out-of-band techniques\nJohn the Ripper Tests different encrypted passwords\nAngry IP Scanner This is a free tool for scanning IP addresses and ports\nSolarWinds Security Event Manage Recognized as one of the best SIEM tools, helping you easily manage memory stick storage\nTraceroute NG Detects paths changes and alerts you about them\nLiveAction Its packet intelligence provides deep analyses\nQualysGuard Responds to real-time threats\nWebInspect Tests dynamic behavior of web applications for the purpose of spotting security vulnerabilities\nHashcat Supports distributed cracking networks\nL0phtCrack Fixes weak passwords issues by forcing a password reset or locking out accounts\nRainbow Crack\nIKECrack IKECrack is an authentication cracking tool with the bonus of being open source.\nSboxr Checks for over two dozen types of web vulnerabilities\nMedusa One of the best tools for thread-based parallel testing and brute-force testing\nCain and Abel uncovers password fields, sniffs networks, recovers MS Access passwords, and cracks encrypted passwords using brute-force, dictionary, and cryptanalysis attacks.\nZenmap Administrators can track new hosts or services that appear on their networks and track existing downed services"
  },
  {
    "objectID": "posts/f9993dbd-9c9f-4e9f-9b30-9faec2c9f18a/index.html",
    "href": "posts/f9993dbd-9c9f-4e9f-9b30-9faec2c9f18a/index.html",
    "title": "translate.com, webhooks, make money by translation",
    "section": "",
    "text": "translate.com, webhooks, make money by translation\nthe story from medium is about writing some listeners for quick notifications to get jobs faster.\ntranslate.com is a website for translation. you can receive money via payoneer.\nregister here as translator."
  },
  {
    "objectID": "posts/afafa402-a6bf-4778-a658-5d1920ddf6ae/index.html",
    "href": "posts/afafa402-a6bf-4778-a658-5d1920ddf6ae/index.html",
    "title": "twilio account",
    "section": "",
    "text": "twilio account\nimmediately my account got disabled after registration\npaid sms service.\nrecovery code: CI5zjjokCN3Dci9lrsmDDnlMMSkcRacpfHjmTRf_"
  },
  {
    "objectID": "posts/860e3e51-6b82-45f2-837d-44f0a142f828/index.html",
    "href": "posts/860e3e51-6b82-45f2-837d-44f0a142f828/index.html",
    "title": "tweening for object focus, zoom to object, zoom to video ROI",
    "section": "",
    "text": "tweening for object focus, zoom to object, zoom to video ROI\nfocus on person only, crop video and leave only human region untouched: https://github.com/ConceptCodes/portal-zoomer\nfocus/zoom on given object using pytweening, a easing/tweening function collection.\nto tell you, pytweening is initially developed for pyautogui (by the same author at least), probably for evading AI detection, passing captcha or somehow, but it could also be used in animation rendering.\nor just use ffmpeg. you need to handcraft those formulas anyway.\ndoes vidpy/mltframework and some other libs supports that? requires investigation."
  },
  {
    "objectID": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html",
    "href": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "",
    "text": "淘宝视频 哇偶视频似乎取消了视频上方的搜索接口\n首页的视频推荐似乎更好看一些 推荐算法更先进\n逛逛被单独分了一个专栏 在那里可以搜索视频"
  },
  {
    "objectID": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#ui-automation-and-indirect-intent-interception-share-to",
    "href": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#ui-automation-and-indirect-intent-interception-share-to",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "ui automation and indirect intent interception (share to)",
    "text": "ui automation and indirect intent interception (share to)\n“您的分享过于频繁，请稍后重试”\n出现这种情况需要更换qq号\nhow about let’s use appium for unlocking phone, airtest for actual testing?\nappium can only unlock phone by removing password.\npassword with ampersand needs to be quoted/escaped.\nthat might need another supervisor\n\nappium\nwrite a test in python\nappium desired capabilities\nuiautomator2\nunlock android phone\n\n\nairtest\nintro\npoco introduction"
  },
  {
    "objectID": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#autojs-autox.js",
    "href": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#autojs-autox.js",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "autojs autox.js",
    "text": "autojs autox.js\nautojs code collection\nset up accessibility servicr for autox either by the switch inside settings (with root) or run this command:\nadb shell settings put secure enabled_accessibility_services packagname/servicename\nam start -n org.autojs.autoxjs.v6/org.autojs.autojs.external.shortcut.ShortcutActivity -a android.intent.action.MAIN -e path \"/storage/emulated/0/脚本/show_toast.js\"\n现在autojs是付费的 但这两个都不能替代appium或者airtest\nautox repo vscode plugin\n发送意图-QQ文本消息分享\n腾讯相关autojs\n\nfrida\nhook current application context\n\n\nxposed\nxposed new repo\nandroid virtual cam xposed安卓虚拟摄像头 android virtual camera on xposed hook\n\nbroadcast, indirect intent, start activity\nhighly suspected source of ‘token’, the miniapp json generator the MiniArkShareModelBuilder transformArkShareJson ShareQQArkHelper MiniProgramShareUtils MiniProgramShareUtils.newShareInfoRequest ShareManager MiniProgramShareUtils.shareToChatDirectly\nqq jumpparser\nmqqapi doc\nmqqapi example\nmqqapi 聊天 加群 名片\nAndroid常用代码-微信QQ分享文件和文字\n常用的URL Scheme\nAndroid am help 帮助信息\nadb shell am start -d 启动应用之uri被*吃了\nam start 启动activity 命令\ninspeckage Android Package Inspector - dynamic analysis with api hooks, start unexported activities and more. (Xposed Module)\n找出APP的SchemeURL（抓取APP意图/intent）的常用方法\n隐式启动 这是一款开发者辅助工具，帮助开发者发现手机上的应用的快捷启动，原理是利用 Android 提供的隐式启动 Activity 来快速启动某个应用的某个界面，如快速发微博、发朋友圈、扫一扫，快速切换 vpn 等\nadb/安卓/按键精灵/autojs/uniapp/ec打开SchemeURL的方法及常用SchemeURL整理\nIntent 拦截者_1.1.apk\ncom.zwk.xintent (intent traffic monitoring tool) release orginal repo\nuse am broadcast to send indirect intent\nsending a boot-complete broadcast\nexploiting broadcast receivers\nusage of am and common android shell commands"
  },
  {
    "objectID": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#腾讯微视",
    "href": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#腾讯微视",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "腾讯微视",
    "text": "腾讯微视\nhttps://h5.weishi.qq.com/webapp/json/weishi/WSH5GetPlayPage?t=0.7532600494918984&g_tk=&feedid=71yYpleeM1HghTttk&recommendtype=0&datalvl=&qua=&uin=&format=json&inCharset=utf-8&outCharset=utf-8"
  },
  {
    "objectID": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#淘宝短视频",
    "href": "posts/9ef1a494-e3c9-4662-a4c0-1c16a2d17552/index.html#淘宝短视频",
    "title": "ui automation and indirect intent interception (share to)",
    "section": "淘宝短视频",
    "text": "淘宝短视频\n淘宝x-sign算法分析\n淘宝抓包解决方案\n逆向闲鱼apk 抓包\npost content on we.taobao.com\n淘宝直播\nhttps://zhuanlan.zhihu.com/p/91192587\npacket capture + batch m3u8 download\n5 666:/鱼里家庭布偶猫舍的场间简直太火爆了，快来看！ 可爱的宝宝找家咯 ,快来场间 https://m.tb.cn/h.fJErCBC?sm=b4d048\n———————口——————— ！们那之学有为上家得人多啊\n淘宝网页无法播放直播\nhttp://huodong.m.taobao.com/act/talent/live.html?id=359158835379&type=508&livesource=share&cp_origin=taobaozhibo%7Ca2141.8001249%7C%7B%22account_id%22%3A%221897661676%22%2C%22app_key%22%3A%2221646297%22%2C%22feed_id%22%3A%22359158835379%22%2C%22os%22%3A%22android%22%2C%22spm-cnt%22%3A%22a2141.8001249%22%7D&sourceType=talent&suid=07ebc365-efc6-4e9c-9c14-c58c1bb8e522&ut_sk=1.W4yy2CtIMUMDAA1l3Dnx4jNG_21646297_1651743901078.Copy.zhibo&un=42ad1253bebcb796f3ba5a7177d3a823&share_crt_v=1&un_site=0&spm=a2159r.13376460.0.0&sp_abtk=common_zhibo_commonInfo&sp_tk=5Lus6YKj5LmL5a2m5pyJ5Li65LiK5a625b6X5Lq65aSa&cpp=1&shareurl=true&short_name=h.fJErCBC&bxsign=scdS6H1ZsIpmAMTuhs-TbALYgOScV_BU6U9ueNABqjzLXd9JSLZYxA6vuaR_tN9PI3n6qDUMtmf-5O_pZZqgnoLHg4WsX64s_Gkx–xc0vfG_87x3Boc1-uCbsYXCZO3Wtc\n最新版只有微淘入口\n淘宝逛逛 有用户名 ID\n67信生对在然有为上子是去你嘻 https://m.tb.cn/h.fJE9C6B?sm=ee59f9 怕鱼的小猫咪~~\nthis video is flipable\n淘宝网页版\nhttps://main.m.taobao.com/index.html\nhttps://market.m.taobao.com/app/tb-source-app/video-fullpage/pages/index?wh_weex=true&wx_navbar_hidden=true&contentId=346882467812&source=guess-guangguang&type=guangguang_cainixihuan&id=346882467812\nhttps://market.m.taobao.com/app/tb-source-app/video-fullpage/pages/index?wh_weex=true&wx_navbar_hidden=true&origin=VideoInteract%7Ca310p.13800399.0.0%7C%7B”contentId”%3A”346882467812”%7D&contentId=346882467812&source=guess-guangguang&type=guangguang_cainixihuan&spm=a2141.1.guessitemtab_1.3&accountId=0&videoUrl=https%3A%2F%2Fcloud.video.taobao.com%2Fplay%2Fu%2Fnull%2Fp%2F1%2Fe%2F6%2Ft%2F1%2F346882467812.mp4&coverImage=https%3A%2F%2Fimg.alicdn.com%2Fimgextra%2Fi2%2F604321789%2FO1CN01rVTgs31P5PIQ7r2JR_!!604321789.jpg&id=346882467812&sourceType=other&suid=7f31e56f-2878-4462-9a5a-acd7d5deeec5&ut_sk=1.W4yy2CtIMUMDAA1l3Dnx4jNG_21646297_1651742283972.Copy.tblive-video&un=42ad1253bebcb796f3ba5a7177d3a823&share_crt_v=1&un_site=0&sp_abtk=common_tblive-video_commonInfo&sp_tk=55Sf5a%2B55Zyo54S25pyJ5Li65LiK5a2Q5piv5Y675L2g&cpp=1&shareurl=true&short_name=h.fJE9C6B&bxsign=scdwHO4PyMrtSLzA7OBHe89rxDFffyg-UVrE4mtFb42ts8qjhHx_6DhU0VAdOy3PgJcoggVVt1dw63IPVDTdXhIGiWlqtdNZredQE5O2V8o1AhV8XE7zhYjf5gApjy90rf1&sm=ee59f9&app=chrome"
  },
  {
    "objectID": "posts/804f1fd2-d74a-4c8f-8667-2f679394b239/index.html",
    "href": "posts/804f1fd2-d74a-4c8f-8667-2f679394b239/index.html",
    "title": "use pyscenedetect dynamically in program",
    "section": "",
    "text": "use pyscenedetect dynamically in program\n对于单纯拼接起来的视频 这个算法就如同手术刀一样精准\n首尾有可能有一两帧看起来不太对 但是可以通过调节start和end来修正\n警惕频繁转场的视频 它们可能是属于同一个小片段的 但是如果不打乱顺序有可能会触发版权识别问题\n即使选出来了可以使用的片段 对于同一个视频的制作过程 依旧要隔一段时间采样 比如两个片段间隔至少5秒 不要单纯的把所有片段一次性提取出来 避免内容重复和版权问题\n当然对于有渐变 转场的视频 可能需要用其他的检测方法\nfrom scenedetect import open_video, SceneManager, split_video_ffmpeg\nfrom scenedetect.detectors import ContentDetector\nfrom scenedetect.video_splitter import split_video_ffmpeg\n\ndef split_video_into_scenes(video_path, threshold=27.0):\n    # Open our video, create a scene manager, and add a detector.\n    video = open_video(video_path)\n    scene_manager = SceneManager()\n    scene_manager.add_detector(\n        ContentDetector(threshold=threshold))\n    scene_manager.detect_scenes(video, show_progress=True)\n    scene_list = scene_manager.get_scene_list()\n    split_video_ffmpeg(video_path, scene_list, show_progress=True)"
  },
  {
    "objectID": "posts/050a84b4-634f-4904-8554-14d4e3518b83/index.html#open-source-virusmalware-in-your-arsenal",
    "href": "posts/050a84b4-634f-4904-8554-14d4e3518b83/index.html#open-source-virusmalware-in-your-arsenal",
    "title": "useful sources on cyber attack",
    "section": "open source virus/malware in your arsenal",
    "text": "open source virus/malware in your arsenal\npowershell obfuscator advanced, will bypass any av\n\npost-exploit framework, evasion\nthefatrat is an exploiting tool which compiles a malware with famous payload, and then the compiled maware can be executed on Linux , Windows , Mac and Android. TheFatRat Provides An Easy way to create Backdoors and Payload which can bypass most anti-virus. the author has some tools to share.\npupy is an opensource, cross-platform (Windows, Linux, OSX, Android) C2 and post-exploitation framework written in python and C\nvenom - C2 shellcode generator/compiler/handler\n\n\nvirus samples\nthe malware repo\nopen source virus\nthezoo A repository of LIVE malwares for your own joy and pleasure. theZoo is a project created to make the possibility of malware analysis open and available to the public.\nmalwares codebase, botnet\nopen source malware on github, repo list\nvirus for win10\nkafan virus samples\nvbgood\ndebugman reverse engineering\n\nofficial blackhat arsenal under toolswatch category arsenal\nmassive hacking tools collection\nburpa burp suite automation tool\ntwitter token generator register twitter in batch, has a large proxy list\ni0gan some hacker with automated tools like awd_script\nichunqiu ctf educational resources\ncyberchief online ctf interactive tools suite\nbugku tools\nctftools curated online tool list\nctf online tools\nkanxue home page, articles\n52pojie hack tools\nkanxue knowledge base\nctfshow\nctfhub tools\n渗透师导航\nresources recommended by ctfwiki\nshellcode storm database can be queried via api\nexploitdb find exploits, poc code, google hacking database for finding juicy information/urls, shellcodes with an advanced search interface\ncracking.org\nOSINT: open source (public source) intelligence is the practice of collecting information from published or otherwise publicly available sources\nosint tools:\nMaltego\nGoogle dorks\nMitaka\nSpiderFoot\nSpyse\nBuiltWith\nIntelligence X\nDarkSearch.io\nGrep.app\nRecon-ng\ntheHarvester\nShodan\nMetagoofil\nSearchcode\nSpiderFoot\nBabel X"
  },
  {
    "objectID": "posts/7f2a9786-7f69-410a-9ddb-b5788317aa7e/index.html",
    "href": "posts/7f2a9786-7f69-410a-9ddb-b5788317aa7e/index.html",
    "title": "video phash, video deduplication",
    "section": "",
    "text": "video phash, video deduplication\n视频降重\n每隔几帧抽一帧 视频延长 音频变调 加上背景音乐\n当然不要完全抄人家的 该打乱顺序就打乱 去水印 提取字幕 然后多抄几部视频"
  },
  {
    "objectID": "posts/6883d2e9-6adf-4598-8a24-550cf7185a48/index.html#video",
    "href": "posts/6883d2e9-6adf-4598-8a24-550cf7185a48/index.html#video",
    "title": "video quality assessment, audio quality assessment",
    "section": "video",
    "text": "video\npaperswithcode benchmark\nfast-vqa\nssim based vqs"
  },
  {
    "objectID": "posts/6883d2e9-6adf-4598-8a24-550cf7185a48/index.html#audio",
    "href": "posts/6883d2e9-6adf-4598-8a24-550cf7185a48/index.html#audio",
    "title": "video quality assessment, audio quality assessment",
    "section": "audio",
    "text": "audio\nmosquito"
  },
  {
    "objectID": "posts/c84709a9-454e-45fc-8476-b0bd1f262d50/index.html",
    "href": "posts/c84709a9-454e-45fc-8476-b0bd1f262d50/index.html",
    "title": "vscode extension create publisher",
    "section": "",
    "text": "vscode extension create publisher\nmedialang\nvsce token: xt2s4ohfn57ri5vfcxvwmb7yzddfnqmd2a37tfaidwhy3uaqwzlq"
  },
  {
    "objectID": "posts/797dc186-5747-416c-aa2f-8fd592f2e6fa/index.html",
    "href": "posts/797dc186-5747-416c-aa2f-8fd592f2e6fa/index.html",
    "title": "Bypassing Web Application Firewalls with bapp: A Comprehensive Guide",
    "section": "",
    "text": "waf bypass\nhow to bypass waf cheatsheet by hacken.io\nbapp for waf bypass"
  },
  {
    "objectID": "posts/6d5fce0a-1905-42c4-a937-7bf6d3c3de5e/index.html",
    "href": "posts/6d5fce0a-1905-42c4-a937-7bf6d3c3de5e/index.html",
    "title": "webpage translator plugin",
    "section": "",
    "text": "webpage translator plugin\ntraduzir\nsimple-translate"
  },
  {
    "objectID": "posts/472418b8-8b4e-4c96-864b-af3019569343/index.html",
    "href": "posts/472418b8-8b4e-4c96-864b-af3019569343/index.html",
    "title": "windows & office activation, install windows in virtualbox",
    "section": "",
    "text": "windows & office activation, install windows in virtualbox\nvisit: massgrave\nsteps before installing windows to virtualbox"
  },
  {
    "objectID": "posts/cc12a125-9ca1-41df-a412-abf5b6eba09d/index.html",
    "href": "posts/cc12a125-9ca1-41df-a412-abf5b6eba09d/index.html",
    "title": "x11vnc test on kali",
    "section": "",
    "text": "x11vnc test on kali\nbetter use nomachine instead, which is based on nx\npassword: 472831\ncommands:\n# necessary env for gui target, though may not suitable for xvfb\nexport XAUTHORITY=/root/.Xauthority\nexport DISPLAY=:1\n# kill previous running x11vnc, if exists\njoker list | grep x11vnc | awk '{print $1}' | xargs -iabc kill -s KILL abc\n# launch new vnc\njoker x11vnc -threads -forever -rfbauth /root/.vnc/passwd"
  },
  {
    "objectID": "posts/58a6074d-0e6a-42e6-8a4e-67e3b886cfba/index.html",
    "href": "posts/58a6074d-0e6a-42e6-8a4e-67e3b886cfba/index.html",
    "title": "youtube download and its fork",
    "section": "",
    "text": "youtube download and its fork\noriginal youtube-dl\nthe fork with faster (maybe?) download speed: yt-dlp"
  },
  {
    "objectID": "posts/ca8d0c24-a17a-4117-ada5-d6f437ca971d/index.html",
    "href": "posts/ca8d0c24-a17a-4117-ada5-d6f437ca971d/index.html",
    "title": "Introducing the Open-Source Chinese Font ‘LxgwWenKai’ Based on Klee One",
    "section": "",
    "text": "中文字体 open source chinese fonts\n百度输入法造字？\nhttps://github.com/lxgw/LxgwWenKai/ 一款开源中文字体，基于 FONTWORKS 出品字体 Klee One 衍生。\n感觉挺好看"
  },
  {
    "objectID": "posts/ab4a5877-b787-491d-9898-9987e9d659f5/index.html",
    "href": "posts/ab4a5877-b787-491d-9898-9987e9d659f5/index.html",
    "title": "人脸识别 Face Recognition",
    "section": "",
    "text": "人脸识别 Face Recognition\nhttps://github.com/ZhaoJ9014/face.evoLVe https://github.com/timesler/facenet-pytorch https://github.com/JDAI-CV/FaceX-Zoo https://github.com/justadudewhohacks/face-api.js https://github.com/cmusatyalab/openface https://github.com/davidsandberg/facenet https://github.com/ageitgey/face_recognition https://github.com/jerry1900/faceRecognition"
  },
  {
    "objectID": "posts/a2b5afa3-2266-4efa-9ec4-109560c94ea7/index.html",
    "href": "posts/a2b5afa3-2266-4efa-9ec4-109560c94ea7/index.html",
    "title": "传播学",
    "section": "",
    "text": "传播学 1"
  },
  {
    "objectID": "posts/deb8475f-b449-49b4-aefa-33973b72be54/index.html",
    "href": "posts/deb8475f-b449-49b4-aefa-33973b72be54/index.html",
    "title": "全自动电影解说软件介绍",
    "section": "",
    "text": "全自动电影解说软件介绍 全自动短视频合成\n自媒体自学网 新媒体运营 自动化运营 混剪： https://www.zmtzxw.com\ngenerate video from plain text using beatdetectorforgames: https://github.com/FireFragment/video-generator\nyoutube reddit text to speech video generator: https://github.com/HA6Bots/Automatic-Youtube-Reddit-Text-To-Speech-Video-Generator-and-Uploader\ntwitch clip compilation: https://github.com/HA6Bots/Twitch-Clips-Compilation-Generator-TCCG-\nslideshow video generator: https://github.com/oknoorap/vidshow\nbest of twitch video generator: https://github.com/BayoDev/Twitch-Best-Of-Gen\nvideo generator by scraping reddit videos and comments: https://github.com/charlypoirier/redditube\nyoutube video generation based on watson natural languahe understanding and google image search: https://github.com/rhenriquea/ai-video-generator\ntiktok video compilation based on custom filters: https://github.com/HA6Bots/TikTok-Compilation-Video-Generator\n12个搬运手法： 去水印 放大缩小 镜像 抽帧 加滤镜 加特效 调色 调速 转场 调整视频顺序 加画中画 其他视频元素\n文案加字幕 朗读方案： https://m.baidu.com/video/page?pd=video_page&nid=9603074179371472094&sign=5664314656417860263&word=自动合成视频&oword=自动合成视频&atn=index&frsrcid=4185&ext=%7B”jsy”%3A1%7D&top=%7B”sfhs”%3A1%2C”_hold”%3A2%7D&sl=4&fr0=A&fr1=A&ms=1&lid=12061699393737547668&referlid=12061699393737547668&frorder=6&_t=1653970095475\n知乎方案，模板加图片，BGM，配音\n文章自动生成视频，幕言 自动打轴（force alignment）： https://zhuanlan.zhihu.com/p/218000255 https://www.muyanpeiyin.com/?zhihu\n5种方式生成原创视频： https://zhuanlan.zhihu.com/p/140075360?from_voters_page=true https://zhuanlan.zhihu.com/p/119422109 https://m.baidu.com/video/page?pd=video_page&nid=11383613456893718608&sign=855254448776210471&word=AI全自动剪辑软件：2分钟自动合成一个影视解说视频，批量效率高&oword=自动合成视频&atn=index&frsrcid=5373&ext=%7B”jsy”%3A1%7D&top=%7B”sfhs”%3A1%2C”_hold”%3A2%7D&sl=4&fr0=A&fr1=C&title=AI全自动剪辑软件：2分钟自动合成一个影视解说视频，批量效率高&lid=12061699393737547668&ms=1&_t=1653971026899\n模式一：单视频+文案 一个视频配一个文案，软件将自动把文案转化成字幕以及真人发音，把视频和字幕添加到视频上 此模式适合电影解说，新闻讲解等等\n模式二：多视频+文案 多个视频会随机合成一个视频,然后把文案转化成字幕以及真人发音，把视频和字幕添加到视频上 此模式适合抖音带货等\n模式三：多图片+文案 多个图片会随机合成一个视频,然后把文案转化成字幕以及真人发音，把视频和字幕添加到视频上 此模式适合大批量却又苦于找不到视频素材的情况\n模式四：单视频混剪 适合抖音带货，或者搬运类的影视混剪\n模式五：文字转语音 现在头条也出了音频的创作专区，应广大用户的需求，添加这个功能，将txt文件批量放入video目录即可。"
  },
  {
    "objectID": "posts/614d96eb-aab5-4456-a537-dd37b73bf639/index.html#文章伪原创api-即将关站-站内关于伪原创的方法总结",
    "href": "posts/614d96eb-aab5-4456-a537-dd37b73bf639/index.html#文章伪原创api-即将关站-站内关于伪原创的方法总结",
    "title": "关于伪原创的方法总结 自动软文生成器 一键生成软文 伪原创 文案生成器 自动生成软文",
    "section": "文章伪原创API 即将关站 站内关于伪原创的方法总结",
    "text": "文章伪原创API 即将关站 站内关于伪原创的方法总结\n　　众所周知，百度搜索引擎现在对网站内容质量的要求越来越高。如果一个网站的内容质量差，即使有很多外部链接和高质量的外部链接，它通常也不会得到很高的排名，因为内容质量差的网站往往有很高的跳转率，这已经成为百度排名算法的一个重要元素\n　　然而，制作一个网站的少量原创内容并不困难，但是对于任何一个草根站长来说，每天更新都是非常困难的，尤其是对于一些垂直行业的网站。由于这个行业的内容是相对固定的，发布原创内容就更加困难，所以伪原创是一个重要的方式。然而，传统的伪原创方法已经难以提高内容质量，这将使网站成为垃圾网站。因此，从发展的角度来看，伪原创的质量更难提高。\n　　那么我们如何才能有效地提高伪原创内容的质量呢?我认为我们可以从以下几个方面入手，使伪原始内容和原始内容的质量相等。\n　　第一，伪原创的创新并购方式。\n　　我们知道伪原创通常在网上寻找一些内容，然后改变标题，混淆文章的段落，甚至用伪原创工具替换同义词，导致伪原创内容可读性差。因此，我们应该放弃这种伪原始方法，整合相关内容，并用我们自己的语言重新组织它。在梳理的过程中，我们可以结合相关内容进行一定的观点创新，使这种伪原创的内容呈现出新的思路。\n　　当合并相关内容时，我们必须确保第一段和最后一段都是原始内容，并在这两个地方建立您的中心内容。这个中心内容通常可以与不同概念的集成结合在一起。如果站长此时满脑子都是想法，有自己独立的想法，他也可以写出来，这样伪原创内容的质量就可以得到有效的保证。即使此时文本中有一些相似度很高的内容，百度也不会反感。\n　　二是内容与科学收藏的整合。\n　　我们知道互联网上的一些内容和市场上销售的书籍有一定的相关性，但它们不可能完全一样，否则这些书会被复制，所以我们可以把这些书的内容搬到互联网上，进行一些优化和创新，然后把它们转化成非常好的原创内容，这些内容具有很好的可读性和知识性，成为百度蜘蛛最喜欢的内容餐。\n　　另一种是整合互联网的现有内容，例如，制作一些论坛发帖的百科全书、游戏策略的百科全书等。这些内容往往不需要原创，只需要在网上收集相关内容，然后混合在一起，就可以形成非常有参考价值的内容。此外，这些内容也是百度蜘蛛最喜欢的食物，它有望成为百度主页的常客。\n　　第三，等价交换法\n　　(1)文本排序法:如果你随意拿这篇文章“游戏编辑写虚假原创文章的五大技巧”，如何做等价交换法?对等交换可以通过同义词和打乱标题关键词的顺序来实现。您可以将其更改为“游戏编辑撰写虚假原创文章的五大技巧”和“协助游戏编辑撰写虚假原创文章的五大技巧”。你可以看到标题被巧妙地改变了，但是意思没有变。这是等价交换法。\n　　②数字交流方法:如标题:五种伪主动性技能。你可以停止移除一些伪主动性技能或者增加一些伪主动性技能。至少，你可以让搜索引擎至少认为你的标题是非传统的。\n　　(3)换词法:看图造义是指交换词语的相关或同义词，从而达到变汤不换药的效果。\n　　第四，标题组合法\n　　组合方法是使用上面总结的三种方法或两种方法。例如，网站管理员网站中的一篇文章的标题“网站管理员如何进行网站营销分析并制定策略”，可以改为“进行网络营销分析的好策略”，其中使用了等价交换法和文本修改法。\n　　五、文本修改方法\n　　当标题准确时，我们可以进行一定的加工和修饰，如加问句、反问句、比较级、隐喻、拟人，并与原标题完全分离，从而增加标题的影响力。例如，“五种伪主动性技能”可以改为“五种伪主动性技能有用吗”?\n　　第六，标题与内容相关\n　　标题的修改是为了减少搜索引擎中的重复，而不是在修改后改变原文的意思，这样就失去了伪主动性的初衷。不管如何停止修改标题，首先，要忠于原来的标题;第二，我们应该参与更适合读者需求的特色。只有这样，我们才能达到伪主动性的意想不到的结果。\n　　七、文本内容修正方法\n　　1.第一段总结:为我写第一段，就像引言一样。如果你有这种精神，阅读完整的文本做一个总结，并把它放在头版。如果你觉得你没有时间阅读它，这也很简单:我编辑了它，必须把它整合到我网站的关键词中;\n　　②在文本中插入链接锚文本:我想每个人都知道锚文本的作用，它可以帮助提高相关关键词的排名，并且可以在别人收集你的资料时收集锚文本链接，这相当于给你增加了一个外部链条:如果你收集我，我会申请你，这是公平的。每200-300字，可以适当增加2-3个锚文本链接;\n　　3、尾部总结法:总结整篇文章，其实，关于搜索引擎优化，不仅仅是这些内容，还有小技巧必须注意，玩搜索引擎是一项细致的工作，所以你不仅会做，而且会考虑它。有快速进步和进步的能力，绕过班级;\n　　④新图片:每个人都会知道一张图片胜过千言万语。当然，目前大多数本地搜索引擎不能读取图片的内容，但是图片中的alt属性可以停止标注，这将给搜索引擎一个新的外观，认为您的内容是新的和包含的;\n　　⑤段落交换法:这种方法是为了停止内容交换，但注意不要影响原文的阅读。尤其是一种操作方法，绝对不能使用，否则，你知道的。因此，这种方法并不符合一切，应该避免逻辑文章。\n　　上述伪原创方法可以有效提高内容创作速度，同时拓展内容创作空间，但在进行伪原创时必须注意内容的可读性，而不是简单地用软件替换同义词，打乱段落。尝试将自己的一些观点融入到伪原创中，让伪原创中的内容有一个新的生命，从而为网站质量的提高做出更大的贡献。"
  },
  {
    "objectID": "posts/d8f78040-eac8-4f70-968f-d9d99a90679d/index.html",
    "href": "posts/d8f78040-eac8-4f70-968f-d9d99a90679d/index.html",
    "title": "Unlocking the Potential of AI-Assisted Live Streaming and Audience Data",
    "section": "",
    "text": "关于直播的思路\n可以用长音频 长视频替代直播源\nYukio 23:00:49 这个我还在研究这玩意\n卑劣的写作者 23:01:13 [图片]\nYukio 23:01:19 尤其是怎么把别人的皮套拿来当成自己的\nYukio 23:01:44 追踪虚拟Vtuber的动作然后放到我的皮套上\nYukio 23:02:50 搞媒体不都靠抄么\nYukio 23:03:38 你们要是能把别人一个月之前的直播弄下来 视频音频分别杂交处理一下 弄的人看不出来是抄的\n卑劣的写作者 23:03:48 那不是塞里斯特色媒体吗\nYukio 23:03:50 你就躺赚啊\ngjz010 23:03:52 你偷大物皮套感觉会被版权炸弹\ngjz010 23:04:13 你看即使是怪盗也不敢把自己的皮套偷过来用\ngjz010 23:04:48 那你还不如用阿b的公用皮套\nYukio 23:04:49 你随便弄个b站提供的免费皮套\nYukio 23:05:00 或者原神的\nYukio 23:05:32 一天换一个啊 肯定有人看的\ngjz010 23:05:44 也不一定\ngjz010 23:05:58 皮套有商标的意味\nYukio 23:06:03 把别人的皮套动作追踪之后 绑定到免费皮套上面\ngjz010 23:06:14 啥 皮套动作不都是跟着你走的吗\ngjz010 23:06:20 偷别人的动作有啥用\nYukio 23:06:20 把别人的中文语音截取下来 随机播放\ngjz010 23:06:30 你还不如找个ai念\nYukio 23:06:39 我为什么要绑我的动作\ngjz010 23:06:54 就是不追踪瞎摇的\ngjz010 23:07:01 动捕坏了的时候用\nYukio 23:07:08 我这个不是瞎摇晃\nYukio 23:07:18 我这个是重播\nYukio 23:07:36 把别人的动作再播送一遍\nYukio 23:07:49 所以只要你记忆力没有一个月\nYukio 23:07:59 没法把全网的直播都看一遍\nYukio 23:08:14 你不可能知道我究竟这期节目抄的谁\nYukio 23:08:41 我不仅动作和语音不是一个人 画面也是另外一个人\n卑劣的写作者 23:08:58 ？\nYukio 23:09:12 我还会把所有和原作者有关的东西自动清除\nYukio 23:09:24 比如任何QQ号码 任何联系方式\n卑劣的写作者 23:09:26 这人不能处\nYukio 23:09:37 任何作者署名\nYukio 23:10:32 我会把语音变声处理\nYukio 23:11:51 只要有机会 我直接下载外网twitch直播 把国内的语音放上来 都是同类游戏\nYukio 23:14:06 我用谷歌翻译流行的游戏名字 拿到外网去搜索\nYukio 23:16:17 同时我还有一个自动读评论的插件\nYukio 23:16:36 每隔几分钟读一次 让你们以为这是个真人\nYukio 23:17:03 我通过图片截图搜索 得到游戏名字\nYukio 23:17:45 通过相似图片得到关键词 生成标题 主题 标签 分区\nYukio 23:20:47 皮套人的动作有自动过渡系统\nYukio 23:20:57 不会出现跳变\nYukio 23:22:47 利用智能匹配 选取最适合的主题 动作 语音 自动生成连续的内容\n小晴清风揽月 23:24:01 见到皮套人就恶心\nYukio 23:24:19 皮套人是资本收割机\nYukio 23:24:38 可以把处男的jy转化为软妹币\nYukio 23:24:58 非常的节能环保 非常高效\n重庆人快融化啦 23:26:20 [图片]\nYukio 23:26:40 如果我算力充足 完全可以跳出这个抄别人的逻辑 进行完全的所谓原创直播\nYukio 23:27:10 但是就一台笔记本 抄直播是最为经济有效的\nYukio 23:28:01 也为之后定制更高端的原创模型打好基础\nYukio 23:30:30 我可以用观众的弹幕数据作为搜索分类的数据 可以拿来衡量情绪激烈程度\nYukio 23:30:56 语音数据也是如此\n小晴清风揽月 23:30:56 你语言混乱，先去看看医生\nYukio 23:31:06 不需要\nYukio 23:31:28 觉得我混乱的 你压根还不懂\nYukio 23:31:42 也就是没想清楚\n小晴清风揽月 23:32:01 我开玩笑的\n小晴清风揽月 23:32:08 对不起\n小晴清风揽月 23:32:16 我只是在学仰山杨爱民说话"
  },
  {
    "objectID": "posts/c03f1576-9fcd-4364-baac-6787cdf19d0b/index.html#vits变声",
    "href": "posts/c03f1576-9fcd-4364-baac-6787cdf19d0b/index.html#vits变声",
    "title": "变声软件 Morphvox alternatives",
    "section": "vits变声",
    "text": "vits变声\nhttps://github.com/w4123/vits\n白嫖原神语音 有对如何训练原神语音作出的修改 想白嫖访问demo的api 这个模型读英语不行 可能需要原神英文语音包吧 当然也可以直接考虑变声器模型 读阿拉伯数字也不可以 如何把非汉字内容变为可以读的内容\n阿拉伯数字转汉字 从funnlp看到的\n原神语音包解压\n米游社 原神语音包\nobtain all genshin impact voices in all languages in quotes, with text\ngenshin voice scraper with text, also have scraped voice and text inside\ngenshin limited english voice"
  },
  {
    "objectID": "posts/c03f1576-9fcd-4364-baac-6787cdf19d0b/index.html#tactron2-变声-训练",
    "href": "posts/c03f1576-9fcd-4364-baac-6787cdf19d0b/index.html#tactron2-变声-训练",
    "title": "变声软件 Morphvox alternatives",
    "section": "tactron2 变声 训练",
    "text": "tactron2 变声 训练\nMoeTTS是一个Tacotron2/HifiGAN模型+编译好的GUI版本发布仓库 有多个语音包 项目地址：https://github.com/luoyily/MoeTTS\n主要的vst变声插件：\n变声插件以及其他VST的选择，大家可以参考上一篇专栏，本人现在用的是Avox Mutator调整声调，Little Alterboy调整共振峰的搭配：\ngachikoe! core sign in with pixiv to download for free\nVST机架 变声 设置教程\n需要多个vst插件相互连接\n可能只适合个别声音 如果是野生音源 需要预处理 再进行输入\n本篇教程是上一篇教程的延续，咕咕了大半年的我也做了很多新的尝试，本篇文章包含的内容是：1. 介绍一个免费的更加适合直播用途的机架Cantabile（替代Reaper）；2. 介绍目前咱自己调出来的，可以实现比较自然变声效果的VST链。关于如何使用OBS矫正变声器延迟导致的与模型嘴型、歌回时伴奏不同步的问题，我会在下一期中介绍（我真的不会再咕咕半年了）。\n关于Voicemeeter与声卡配置的补充\n请参照上一期，完成硬件设备以及Voicemeeter Banana的配置（重要！），Reaper的部分用下文的Cantabile代替~\n本文中将会使用上一篇专栏中外置声卡的Asio驱动+第二张声卡（或者使用电脑自带的输出，比如一般电脑都有Realtek High Definition Audio）的方案。打开Voicemeeter的设置界面，在Output A1中点击ASIO设备的名称的话，会跳出声卡的配置界面：\n点击红框处\n声卡配置界面 - 采样率（Sample Rage）\n声卡配置界面 - 缓存大小（Buffer Size） 采样率建议选择48kHz足够满足直播用途，太高的话会提高音频处理时的资源占用；如果在之后配置完变声器发现有爆音的现象，可以尝试提高Buffer Size（推荐512左右）。需要注意的是，Voicemeeter的ASIO方案虽然效率很高但可能是因为驱动的原因，并不适用于所有声卡，比如Focusrite的Scarlett系列。咱财力有限，只测试了Steinberg的UR系列声卡，不过在官方论坛上暂时也只看到了对Focusrite驱动支持问题的反馈，所以理论上大部分常用的声卡应该没有问题（大概\n至此，前期准备完成！\nCantabile配置\n下载地址：https://www.cantabilesoftware.com/download/\n下载Stable Build并完成安装后，根据自己的操作系统选择运行64位/32位版本，选择Cantabile Lite版本（免费）。如果要求注册账户，按照步骤使用邮箱完成注册后，会在邮箱内收到注册码，使用注册码激活即可。\n选择“Cantabile 3 Lite” 进入Cantabile后，在菜单中选择Tools→Options，在Audio Engine中选择ASIO - Voicemeeter Virtual ASIO：\nAudio Engine 将Audio Ports如下图配置（先按照上一篇专栏配置好Voicemeeter哦）：\nAudio Ports 同时在下面的Plugin Options中选择Add→Browse可以添加自己安装VST插件的文件夹，然后等待扫描完成，这样才可以使用已经安装的插件：\nPlugins Options 在Cantabile的主界面中黑色部分右键选择Insert Plugin可以插入插件，右键已经插入的插件选择Delete可以删除该插件。实现变声器需要的插件的连接方法也非常简单，从Main Microphone拖出一条线到第一个插件的Stereo / Mono in，再将插件的Stereo / Mono Out连接到下一个插件的Stereo / Mono in，一直到最后一个插件的Stereo / Mono Out连接到Main Speakers。这样连接的原理很简单，就是将一个插件处理完的音频继续交由下一个插件处理，打到叠加的效果。下图是一个示例：\n插件连接示例 为了方便监听效果，记得按照上一篇教程Voicemeeter配置部分的最后所说，保持Voicemeeter开启，点亮Voicemeeter绿框中的A2与B2，将Main Microphone到Main Speaker的线路连通应该就能从Voicemeeter右上角A2你选择的设备中听到此时经过处理的声音了，如果未连通应该是不会听到任何声音的。\n至此，Cantabile配置完成！\n搭建变声器所需插件\n首先，介绍一下在搭建变声器的过程中需要的插件，下载与购买地址在文章末尾。在保证效果的前提下咱已经尽量把插件的选择精简，比如Waves、Soundtoys、Fabfilter的插件有捆绑包而不需要一个个购买，文章里没有提到的插件大家也可以自己玩一玩。个人的配置方案会在后文贴出：\n（一）变声器插件（当然是必选）\n经过一大堆尝试（Elastique Pitch，KeroVee，Antares Throat，等等…），效果最让咱满意的是来自Soundtoys的Little Alter Boy（售价$99，很贵，某些地方可以搜到Soundtoys的插件合辑但希望大家可以支持正版）。可以用的替代品是插件版的Gachikoe，需要加入作者桜音さち老师的Fanbox才能下载，要求一个月1000日元，下载完了可以取消，同样尽量支持作者~\n变声器插件调节的是人声的音调（Pitch）以及共振峰（Formant）。在很多变声器插件中，Pitch的范围是-12到+12。一个八度有12个半音，从降一个八度到升一个八度，就是-12到+12这个范围的含义。咱推荐把Pitch直接调到+12，因为升高一个八度的话在歌回时不必另外对歌曲进行降调操作。相应的Formant请通过监听自己的声音慢慢调节，一般在3-4左右。如果想要自然一些并且不介意声音低沉一些的话，低一些的Pitch也是可以的。如何在OBS中进行对声音延迟的校正，让变声处理后的声音与耳机里听到的伴奏同步输出咱会写在下一篇专栏里~\n（二）均衡器 / EQ（强烈推荐）\n简单来说，均衡器调整的是各个频段的响度。由于男生和女生发生结构导致的响度分布不同，在调整音调的之前之后，我们都需要用到均衡器，不然可能会导致中频过强等问题。本人用的EQ是Fabfilter Pro Q3。\n（三） 降噪器 / De-noiser（强烈推荐）\n降噪器自然是为了处理噪声。在通过变声器之前，一些噪声可能并不刺耳，甚至可能都不会被注意到，但是在经过了变声器处理后，一些中低频的噪声会随着音调提高而变得刺耳，比如风声和电流声。因此，在声音通过变声器之前咱通常会放一个降噪器。本人用的是Waves WNS 1。\n（四）限制器 / Limiter（强烈推荐）\n限制器是其实可以说是压缩器的一种，将超出声音阈值的部分完全削除。在输出之前加一个-1分贝左右的限制器可以防止爆音以及大音量造成的失真保护观众的耳膜。咱用的是Waves Vcomp压缩器附带的限制器。\n（五）Roth-AIR（推荐）\nRoth-AIR是一个免费的、增加声音“空气感”的插件。本质上来说，应该属于EQ，但是使用非常方便（其实只需要调节一个旋钮）并且效果很好因此单独列出，咱在EQ之后会继续用Roth-Air调节高频。\n（六）齿音消除器 / De-esser（推荐）\n所谓齿音，是在说话或者唱歌时，开口说“嘶”、“次”这些音节时的尖锐声音。这些声音同样也会被变声器放大而变得刺耳。解决方法的方法，一种是使用插件，一种时给麦克风加上防喷网，也可结合使用。咱用的是防喷网+Waves DeEsser。\n（七）压缩器 / Compressor（可选）\n压缩器是当声音强度超过一定阈值时，对超出部分按照一定的比例进行响度衰减，以此减小声音的动态范围，同时不同的压缩器也会给声音带来不同的音染。希望让自己的声音更加饱满或者和麦克风距离忽近忽远导致声音忽大忽小的小伙伴可以尝试一下这类插件。本人在VST链最后加了Waves Vcomp插件。\n介绍完毕，可以正式开工了！\n正式配置变声器\n大致的VST链顺序：\n输入→降噪器→均衡器1→变声器→齿音消除器→EQ2→RothAIR→压缩器→输出\nCantabile配置 降噪插件的参数可以在自己不说话的情况下，点击频谱图右边的Suggest，会自动适配参数：\nWNS 1 参数设置 第一个均衡器的配置，个人方案，请根据自己情况调节：\n均衡器参数设置 变声器的配置，个人方案，请根据自己情况调节：\n变声器配置 齿音消除器，第二个均衡器，RothAIR以及最后的压缩器参数就不贴图了，各位自己根据自己的声音多做尝试吧~\n变声器教程完结！撒花！\n一些大家可能会问的问题： Q：只要有变声器就好了吗？\nA：并不是，想要达到最好的效果还是需要控制自己的说话方式以及呼吸，之后可能会出专门的专栏讨论这个问题。\nQ：这个方案的缺点？\nA：资源占用不低，且有较大的延迟，不适合直播时监听变声过后的效果，因此需要练习把握住自己的语气。至于直播时变声器延迟导致的与伴奏不同步，与模型嘴型不同步我会在下期讲解怎么解决（咕咕咕）。以及，正版的插件价格很贵土真好吃，但还是希望大家尽可能支持正版。至于值不值得，大家可以听一下效果演示再做决定~\nQ：除了文中提到的软件，是否有更好的选择？\nA：有。本人自用的机架是Gig Performer 3（$149），价格贵但是更加稳定，对VST3插件的支持更好。以及，Waves插件之外，iZotope全家桶的效果也很好，但是因为巨大的延迟，比起直播更加适合后期处理，有兴趣和钱的话可以研究一下。\n写在最后的话：\n首先，咱只是一个爱好者，并不是什么后期调音man，甚至耳朵也很木，但我写在这里的是我自己目前为止研究出来的，毫无保留的最佳方案。当然，这个方案有着巨大的改进余地，希望它能抛砖引玉，各位有更好的方案希望能不吝分享。写这篇专栏的原因是在搜寻的过程中看到了不少效果尚不尽如人意的变声器，甚至有打着“免费变声器”、“主播同款”名号的视频，提供QQ群号，提供破解的机架下载，然后推荐声卡，最后再收费调音，被质疑调完音效果仍然不好就消失换个号继续，所谓的演示视频也很明显是由一男一女分开录音的。当然，这些也是个别现象，我还是遇见了很多前辈们有启发性的视频，但大家还是要对这类陷阱提高警惕~\n最后，谢谢看到这里的你！祝早日成为美少女\nSoundtoys官网：\nhttps://www.soundtoys.com/\nGachikoe插件版Fanbox链接：\nhttps://sakuranesachi.fanbox.cc/posts/498211\nRoth-AIR官网：\nhttps://www.danielrothmann.com/#downloads\nFabfilter官网：\nhttps://www.fabfilter.com/\nWaves插件官网：\nhttps://www.waves.com/\nxidada’s tts: https://huggingface.co/spaces/Xi-JinPing/Xi-JinPing-TTS # remove asterisks!\n哔哩哔哩上看到的免费变声器 下载地址： https://yuanqiyinpin.github.io/ 本机架为二次开源软件，优点是占用率滴，不吃电脑配置，上手简单，免费使用\nSoundTouch 萝莉音 青年音 https://github.com/jrising/pysoundtouch\ngan based voice changer: https://github.com/yl4579/StarGANv2-VC\ninstall crossover to run windows app on linux\ncompile crossover from source on macos(code avaliable from official website): https://gist.github.com/Alex4386/4cce275760367e9f5e90e2553d655309 https://www.codeweavers.com/crossover/source\n变声器一般是vst类型的\nrun vst on linux headlessly: https://github.com/hq9000/cython-vst-loader https://github.com/hq9000/py_headless_daw\nlinux vst wrapper/bridge: https://github.com/osxmidi/LinVst\nVST bridge for Windows vst on Linux https://github.com/abique/vst-bridge\nuse vst 2.4 on macos with obs studio: https://github.com/obsproject/obs-vst\npyvst vst wrapper for windows: https://github.com/mbrucher/PyVST\npython vst2 wrapper for windows: https://pypi.org/project/neil-vst/\nyabridge use windows vst3, vst2 plugins on linux using wine, with reaper: https://github.com/robbert-vdh/yabridge\nlyrebird voice changer for linux gtk3: https://github.com/lyrebird-voice-changer/lyrebird\nvoice changer based on MHW Audio Modding Tool (not recommended): https://github.com/ItsBurpee/MHWVoiceChanger\nmozilla voice changer and visualizer based on web api: https://github.com/mdn/voice-change-o-matic\nReal time voice changer in python: https://github.com/symphonly/figaro\nPyvoicechanger: https://github.com/juancarlospaco/pyvoicechanger\nchange the Pitch of the voice: https://github.com/wittymindstech/change-voice-pitch\nchange pitch in real time: https://github.com/jmt329/PitchShifter"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#d-pose-tracker",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#d-pose-tracker",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "3d pose tracker",
    "text": "3d pose tracker\nrendered on unity. needs GPU."
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#sysmocap",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#sysmocap",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "Sysmocap",
    "text": "Sysmocap\nWHAT I WANT FOR (or nearly) requires real 3d models, written in javascript\ncannot output video?\nA cross-platform real-time video-driven motion capture and 3D virtual character rendering system for VTuber/Live/AR/VR.\nDoes not require a discrete graphics card and runs smoothly even on eight-year-old computers"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#vtuber-python-unity",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#vtuber-python-unity",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "Vtuber python unity",
    "text": "Vtuber python unity\nsearch for “vtuber” along with “motion capture” you will get many head-only trackers and renderers for windows but not linux, also some “broadcast templates/frameworks”. many support one single image (anime head + remove background) as input instead of 2d/3d models\nface tracking only, showing face, mouth and eyes, head directions, bind to live2d models"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#虚拟数字人-metahuman",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#虚拟数字人-metahuman",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "虚拟数字人 metahuman",
    "text": "虚拟数字人 metahuman\nNextHuman Beta0.9上线公测，5分钟高品质讲解，带你进入数字人“零门槛”创作新时代，体验直通车 -&gt; https://nexthuman.cn 免费版是Windows上面跑的 需要高端1070显卡"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#anime-character-segmentation",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#anime-character-segmentation",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "anime character segmentation",
    "text": "anime character segmentation\nto remove false positives, make sure we have anime face in view, otherwise mark it as a false positive.\nyou can use anime character recognition like moeflow or opencv anime face detector along with some phash or perceptual hash library to group similar characters, compare perceptual image similarity and line them up in a series.\naniseg, able to segment anime character and head, using mask-rcnn\nyet another anime character segmentation model using solov2 and condinst\nwaifu segmentation\nhigh accuracy anime character segmentation\n自动画漫画 画几笔就成某个人像 动漫头像 https://menyifang.github.io/projects/DCTNet/DCTNet.html\n自动捏脸 gan给人脸戴口罩 https://github.com/futscdav/Chunkmogrify"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#selfie-to-anime-picture-to-anime-photos",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#selfie-to-anime-picture-to-anime-photos",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "selfie to anime, picture to anime photos",
    "text": "selfie to anime, picture to anime photos\nselfie2anime with trained models\n##原神mmd下载模型\n模之屋（需要注册）： https://www.aplaybox.com/u/680828836\n夕蓝资源网（可直接下载） 也有其他的3d模型可以下载： https://www.seoliye.com/tags/53.html"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#use-voice-to-power-up-static-images",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#use-voice-to-power-up-static-images",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "use voice to power up static images",
    "text": "use voice to power up static images\nvoice powered animated cartoon figure"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#jeeliz-some-web-deep-learning-runtime-like-tensorflow.js-powered",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#jeeliz-some-web-deep-learning-runtime-like-tensorflow.js-powered",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "jeeliz (some web deep learning runtime, like tensorflow.js) powered",
    "text": "jeeliz (some web deep learning runtime, like tensorflow.js) powered\nweboji, highly similar to animoji, with three.js and cute fox avatar face filter, alter the face like putting glass, minor changes to avoid privacy/copyright concerns?"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#openface",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#openface",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "openface",
    "text": "openface\nfacial features extraction"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#facerig",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#facerig",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "facerig",
    "text": "facerig\nfacerig location: /Software/Program Files (x86)/FaceRig\ni’ve seen python code inside facerig. facerig does not offer head-only rendering, but that could be changed i suppose?"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#avatarify-python",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#avatarify-python",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "avatarify python",
    "text": "avatarify python\ninfinite avatars by using style gan, first order motion model create static portrait avatar (svg?)"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#animoji-from-apple",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#animoji-from-apple",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "animoji from apple",
    "text": "animoji from apple\nfacial landmark detection in python, animoji-animate animoji apple private framework 实际上这个就是之前看到的会动的狗屎的视频来源"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#d模型-皮套-可动-虚拟vtuber-talking-head",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#d模型-皮套-可动-虚拟vtuber-talking-head",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "2d模型 皮套 可动 虚拟Vtuber talking head",
    "text": "2d模型 皮套 可动 虚拟Vtuber talking head\nhttps://github.com/yuyuyzl/EasyVtuber https://github.com/pkhungurn/talking-head-anime-3-demo https://github.com/GunwooHan/EasyVtuber"
  },
  {
    "objectID": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#b站官方",
    "href": "posts/363ed554-0de3-40ab-8fc6-097e347d2a82/index.html#b站官方",
    "title": "哔哩哔哩 直播姬 2d模型 3d模型",
    "section": "b站官方",
    "text": "b站官方\n直播姬现在支持2d面部捕捉 3d模型动作捕捉\n直播姬版本有windows macos(m1) Android版本\n2d模型是live2d的模型\n有待研究"
  },
  {
    "objectID": "posts/c53cb6fa-8eb4-408d-8e98-90207e123047/index.html",
    "href": "posts/c53cb6fa-8eb4-408d-8e98-90207e123047/index.html",
    "title": "Exploring Chinese Music Platform APIs and Repositories",
    "section": "",
    "text": "国内音乐平台api\nhttps://listen1.github.io/listen1/ https://github.com/LIU9293/musicafe https://github.com/872409/music-get https://github.com/HuberTRoy/MusicBox https://github.com/caiyonglong/MusicApi https://github.com/caiyonglong/MusicLake https://github.com/QiuChenly/QQFlacMusicDownloader https://github.com/Rain120/qq-music-api https://github.com/sunzongzheng/musicApi https://github.com/sunzongzheng/music"
  },
  {
    "objectID": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#时序数据库",
    "href": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#时序数据库",
    "title": "复读机 Chatbot",
    "section": "时序数据库",
    "text": "时序数据库\ntdengine stream processing\ninfluxdb python client"
  },
  {
    "objectID": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#智能问答",
    "href": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#智能问答",
    "title": "复读机 Chatbot",
    "section": "智能问答",
    "text": "智能问答\n智能问答与深度学习 附带代码"
  },
  {
    "objectID": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#近义词",
    "href": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#近义词",
    "title": "复读机 Chatbot",
    "section": "近义词",
    "text": "近义词\nuse wordnet to find hyponyms and antonyms\nfind antonyms for chinese with wordnet\n中文近义词 以及如何扩充词库"
  },
  {
    "objectID": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#话题建模-句向量",
    "href": "posts/c405ce45-3f38-4518-8c06-42b2fe653550/index.html#话题建模-句向量",
    "title": "复读机 Chatbot",
    "section": "话题建模 句向量",
    "text": "话题建模 句向量\n10 nlp libraries\ngensim word2vec\nword embedding using word2vec\ngensym word2vec complete guide\ngo-cqhttp 自定义合并转发消息 生成不存在的合并转发消息\n\n渐进式领红包 对于某个群 先是两分钟（左右）之后领一次 领不到就时间减半下一次再领 如果领到了就不减半 最快6秒领 不能再减了 防止某些群为了检测机器人而发红包\n处理信息不要流水线处理 放在messagepool里面 要有重要度排序 相关性排序\nQQ漂流瓶机器人 捡漂流瓶API\n改回群昵称 总有些脑瘫喜欢给我乱起名 一天检查一次 模仿其他人的群昵称 看看有没有能用的马甲\nmitm Chatbot\n\nchatbot frameworks:\nconvai-bot 1337 the best hybrid convai bot\nomeglemiddleman\nchatterbot able to learn while having conversation\nqary: nlpia-bot a hybrid framework for developing chatbot by mannings\nmitm-omegle watch strangers talk\nai chatbot framework\n\n用sentence bert做search based dialog 替代levenshtein 最好是asymetrical semantic search\n有人有测试红包外挂的红包 可能有“test”、“测试”、“别抢”、“不要”之类的字眼 这种红包不要抢 抢了飞机票\n群聊的下一句话不一定是上一句话的回答 训练模型寻找句子相关性 计算相关度 以及句子顺序\n对接小冰\n管理员/群主在的时候 或者管理员经常出现的群里面 不要冒泡 不然容易被封\n\n转发的图片 至少要在之前一小时以内或更长时间内没有被重复发送才行 同一个信息内也不能出现重复图片 否则不发送这个信息（很有可能是广告） 有二维码不发送 有网址不发送 图片里面的文字要是有广告也是不能要的 文字信息不要广告 用简单分类器\n个性化搜索推荐 elasticsearch\n按照老毛的思想 要一边造谣一边辟谣 一边承认一边否定 同样的话颠三倒四可以说无数遍 也可以选择不说 这样可以和很多的类似故事杂交\n\n处理私聊信息 每回复一个人就清除他的所有历史发言 每隔一段时间处理其中的一个人 不会相互挤占 只有在不闲聊的时候处理私聊信息 特定的人不能进行私聊\n白天聊天 收集数据 晚上离线训练 （此逻辑可以推广到任意的机器学习驱动的平台）\n增加训练数据的context 不要只是一问一答 总语句数量要增加\n占用系统显卡训练的时候 需要专门acquire一个filelock 表示大量资源被占用 系统忙\n选取质量好有情感的聊天样本 长短适中 不要广告不要偏激违禁词 去掉表情包 去掉链接 清洗数据 同时模型用于对话的时候不要输入输出一些违禁词 可以通过话题建模进一步细分归类对话数据之间的联系\n\nschedule the training on minute basis first for complete test, then schedule it on fixed time per day.\nfor qq client: dump 500 continual sentences when adding one new while holding the filelock, do not block or stop running if GPT not responding\nfor gpt2 server: (where to train? how to prevent maching from burning? for how long?) rename the dataset while holding the filelock always keep the latest 2 models, remove those not readable first, then delete older ones.\nif train on CPU, still need to limit training time, sleep while doing so. GPU for sure we need sleep during training, and do not use VRAM for other applications. - [ ] 把”汪汪”翻译成表情包 同时可以随机添加其他表情 - [x] 根据实时群聊数据训练gpt2 - [ ] 根据离线群聊数据训练gpt2\n自动骂人 https://github.com/liuke-wuhan/ZuAnBot\n\n添加一个FileLock在gpt2 main server里面 不要让多个对话同时进行处理\n在人多的群里面少说话 具体表现为每次说话的时间间隔变长 次数变少 同时要注意 聊天内容过于严肃 专业的群尽量不要水\n\ndialogpt documentation\n闲聊chitchat dialog bot training framework by facebook: https://github.com/facebookresearch/ParlAI\ndebug the consecutive group reply thresholding protocol\nreply according to individual description and group description\n\n同时推广自己和别人的视频或者内容 收集推荐反馈 同时逐步减小推荐别人视频或者内容的频率\n推广视频的时候可以加入别人的视频高赞评论 动态的GIF 音频 或者是短视频 然后再发送xml\n增加复读图片的功能 增加chatlocal返回图片的功能\n增加反馈功能 根据发言之后群里面的回复来确定发言是否有益\n用txtai或者其他information retrieval (semantic search, smart search)语义查找工具来代替levenshtein的history based reply logic 查找时要包括上下文\n复读机不能使得死群活起来 但是主动推送可以 推送长的 自言自语的对话到群里面 不能是同一个群 主题要相关 filter out too negative ones\n拉人到别的群里面来 最好是多个号不共享群但是话题有交集的人\nadd involution option, allow to append unqualified replies to input message, separated by space.\nadd extend conversation option, allow to reply more than one sentence at a time (proper delay needed) -&gt; could be achieved by using GPT2 alike generation model\n可以给群友点赞\n可以发语音\n\n每次对话输入的context不能太小 不然看起来假\n\n添加复读原句子的功能 触发条件为sentiment\n\n往群里面发b站视频广告的话 最好和群聊主题相关 和最近接收到的消息相关 同时频率不能太高 要设置全局的counter 群聊每发送一条消息trigger一次counter counter mod period == 0 的时候就执行发广告命令 同时可以考虑渲染任务 和发广告的逻辑要解耦合 同时访问一片数据 比如redis 根据最近聊到的内容制作和上传视频 不能在同一个群里面以太快的频率发送相同视频 相同的视频必须间隔一段时间再往其他群发送 最好用schedule库实现 方法内部要实现delay或者放弃schedule的效果\n如果群聊被踢 可以考虑换头像 换昵称 更改个人资料 然后重新申请 同样可以考虑更改b站的信息 用外网网红信息来填充自己的信息 更改资料频率和申请频率都需要控制 需要单独设置每天的quota quota保存在文件里面 申请的信息最好用ai生成 或者paraphrase一下 或者到网上搜索 收集相关内容 先训练一下 头像可以全网到处爬 可以选择二次元头像（动漫头识别）对比度高的 可以是类似头像 不能是系统默认头像不然太过无聊 可以和群聊主题相关 资料抄别人的 别的群里面的 抄该群群成员的资料 或者别的群的资料 不能是管理员资料\n\n根据模板生成下一句 不要直接生成 素材可以是群公告 群主题 接收到的信息 模板生成要和新词发现结合 模板生成 paraphraser可以和chatlocal或者repeater结合\n\n&gt;&gt;&gt; import re\n&gt;&gt;&gt; re.split(r\"(abc|acd)\",\"aaabcaaacdaaa\")\n['aa', 'abc', 'aa', 'acd', 'aaa']\n&gt;&gt;&gt; word=\"aaabcaaacdaaa\"\n&gt;&gt;&gt; word=\"aaabcaaacdaaa\"\n&gt;&gt;&gt; re.escape(\"abc\")   \n'abc'\n&gt;&gt;&gt; re.escape(\"efgh\")\n'efgh'\n&gt;&gt;&gt;\n可以拆分句子为列表\n\n去除经常生成的话语 比如你好之类的\n\n挑选levenshtein距离大于0（不能是它本身）的上一句，排序 选择10句 根据情绪激烈程度（正负皆可 去掉过于负面的）排序 输出第一名 选择下一句作为回答 然后记录这个回答在机器人的回答历史中\n句子如果是取同一个group里面的 不能太recent 起码距离要有50个句子的距离\n文字 图片 视频 都可以搜索百度 搜狗 中文搜索api 根据相关度和情绪来排序 （语种一致）回答文字或者多媒体\n拆分大句子为小句子 依次放入 注意要过滤掉广告 一般广告比较长 有链接？\n\n输入的内容不能有违禁词否则不回答\n输出内容的时候不能有违禁词语 放进来的可以违禁 或者用拼音或者拆字转换这些违禁词语 保证上下文一致性 文本审查\n\nbad chinese -&gt; letter(pinyin initials) -&gt; leetspeek\n下一次挑选的时候自动过滤掉这些下一句在历史回答里面的句子对\n那个lock 要限制自身的读取/删除操作以及新消息的append操作\n\n关于情绪激烈程度 如何提高生成器的情绪激烈度 做一个鉴别器 可以选择性的不去back propagate情绪不激烈的生成结果 或者直接用鉴别器筛选输入的语料"
  },
  {
    "objectID": "posts/bf1ed982-632e-4985-af44-bc654bb069a5/index.html",
    "href": "posts/bf1ed982-632e-4985-af44-bc654bb069a5/index.html",
    "title": "如何永久的影响世界",
    "section": "",
    "text": "如何永久的影响世界 剧本\n核弹 权力 大量金钱 基因改造 革命性技术 大众传媒 大规模战争 永生 时空穿越 和外星文明交流 编程 宗教 语言\nfeedback: 不结婚 不生娃 数学 喝酒 用人 忠诚 领导力 智慧 人类思想 人类本性 一句话改变世界"
  },
  {
    "objectID": "posts/85cfb4d1-f017-4e9f-9493-2190233e503d/index.html",
    "href": "posts/85cfb4d1-f017-4e9f-9493-2190233e503d/index.html",
    "title": "床上用键盘的技巧：垫枕头",
    "section": "",
    "text": "床上用键盘的技巧：垫枕头\n通过在腿的两侧添加两个枕头 成功解决因为天气寒冷被子加厚导致被子压手 没有空间在键盘上面打字的问题 一定程度上也解决了被子压脚的问题"
  },
  {
    "objectID": "posts/54496c66-731d-4f1e-ad78-2ff207caab6d/index.html",
    "href": "posts/54496c66-731d-4f1e-ad78-2ff207caab6d/index.html",
    "title": "影视聚合 社交聚合 网盘聚合搜索引擎",
    "section": "",
    "text": "影视聚合 社交聚合 网盘聚合搜索引擎\n1、云铺子 - 百度网盘搜索引擎\n地址：http://www.yunpz.net/ 查看方式：直接打开 推荐指数：★★★★★ 备注：聚合类，体验好，推荐！ 2、橘子盘搜-好用的影视资源搜索引擎\n地址：https://www.nmme.cc/ 查看方式：直接打开 推荐指数：★★★★★ 备注：专攻影视搜索，度盘、迅雷、阿里，体验好，推荐！ 3、优聚搜\n地址：https://ujuso.com/ 查看方式：直接打开 推荐指数：★★★★★ 备注：支持度盘、蓝奏、阿里，体验好，推荐！ 4、蓝瘦网盘在线搜索网页版\n地址：http://www.sixyin.com/disk-search 查看方式：直接打开 推荐指数：★★★★☆ 备注：蓝奏云搜索，推荐！ 5、阿里盘搜 - 阿里云盘资源搜索神器\n地址：https://www.alipanso.com/ 查看方式：直接打开 推荐指数：★★★★☆ 备注：阿里盘搜索，推荐！ 6、懒盘搜索聚合官网\n地址：https://lzpan.com/ 查看方式：各种都有 推荐指数：★★★★☆ 备注：聚合类，含16个搜索引擎 7、超能搜 - 百度网盘搜索神器\n地址：http://www.chaonengso.com/ 查看方式：各种都有 推荐指数：★★★★☆ 备注：聚合类，含18个搜索引擎 8、万网搜 - 资源搜索聚合神器\n地址：http://www.wanwangsou.com/ 查看方式：各种都有 推荐指数：★★★★☆ 备注：聚合类，含15个搜索引擎 9、云盘狗-百度云网盘搜索\n地址：http://www.yunpangou.com/ 查看方式：直接打开 推荐指数：★★★☆☆ 10、学搜搜\n地址：http://www.xuesousou.com/ 查看方式：直接打开 推荐指数：★★★☆☆ 备注：学习资源搜索 11、盘131 - 云盘资源搜索引擎\n地址：https://www.pan131.com/ 查看方式：直接打开 推荐指数：★★★☆☆ 12、58网盘搜索\n地址：https://www.58wangpan.com/ 查看方式：直接打开 推荐指数：★★★☆☆ 13、56网盘搜索\n地址：https://www.56wangpan.net/ 查看方式：直接打开 推荐指数：★★★☆☆ 14、一个好用的网盘搜索引擎 - 乌鸦搜\n地址：https://www.wuyasou.com/ 查看方式：直接打开 推荐指数：★★★☆☆ 15、bdy搜\n地址：http://www.bdyso.com/ 查看方式：直接打开 推荐指数：★★★☆☆"
  },
  {
    "objectID": "posts/fdb89635-3ed2-4dad-a83b-bf9f424bfc3c/index.html#notice",
    "href": "posts/fdb89635-3ed2-4dad-a83b-bf9f424bfc3c/index.html#notice",
    "title": "微软小冰 机器人 用requests库访问最好",
    "section": "notice",
    "text": "notice\nwhen using this, first extract topic from recent chats or group name, then send message.\nor you just use the default topic. whatever."
  },
  {
    "objectID": "posts/fdb89635-3ed2-4dad-a83b-bf9f424bfc3c/index.html#client",
    "href": "posts/fdb89635-3ed2-4dad-a83b-bf9f424bfc3c/index.html#client",
    "title": "微软小冰 机器人 用requests库访问最好",
    "section": "client",
    "text": "client\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; r = requests.get(\"http://localhost:8735/chat\",params={\"topic\":\"python\",\"message\":\"吃了没有\"})\n&gt;&gt;&gt; r.json()\n{'msg': 'success', 'reply': '你这么一说，我好像是有点饿'}\n&gt;&gt;&gt; exit()"
  },
  {
    "objectID": "posts/fdb89635-3ed2-4dad-a83b-bf9f424bfc3c/index.html#server",
    "href": "posts/fdb89635-3ed2-4dad-a83b-bf9f424bfc3c/index.html#server",
    "title": "微软小冰 机器人 用requests库访问最好",
    "section": "server",
    "text": "server\nlocation: /root/Desktop/works/pyjom/tests/microsoft_xiaobing_conversation_bing/chat_with_session_id.js\nvar request = require(\"request\");\n// var mysqld = require(\"./mysql\");\n// const { init: initDB, Counter, Chatid } = require(\"./db\");\nfunction getRequestId() {\n    return (ot() + ot() + ot() + ot() + ot() + ot() + ot() + ot()).toLowerCase();\n}\n\nconst sleep = (ms) =&gt; {\n  return new Promise(resolve =&gt; setTimeout(resolve, ms))\n}\n\nfunction ot() {\n    return (((1 + Math.random()) * 65536) | 0).toString(16).substring(1);\n}\n\nfunction i(n, i) {\n    for (\n        var s, c, e = 4, l = i.length / e - 1, r = [\n            [],\n            [],\n            [],\n            []\n        ], o = 0; o &lt; 4 * e; o++\n    )\n        r[o % 4][Math.floor(o / 4)] = n[o];\n    for (r = t(r, i, 0, e), s = 1; s &lt; l; s++)\n        (r = u(r, e)), (r = f(r, e)), (r = h(r, e)), (r = t(r, i, s, e));\n    for (\n        r = u(r, e), r = f(r, e), r = t(r, i, l, e), c = new Array(4 * e), o = 0; o &lt; 4 * e; o++\n    )\n        c[o] = r[o % 4][Math.floor(o / 4)];\n    return c;\n}\n\nfunction u(n, t) {\n    for (var r, i = 0; i &lt; 4; i++)\n        for (r = 0; r &lt; t; r++) n[i][r] = o[n[i][r]];\n    return n;\n}\n\nfunction f(n, t) {\n    for (var i, u = new Array(4), r = 1; r &lt; 4; r++) {\n        for (i = 0; i &lt; 4; i++) u[i] = n[r][(i + r) % t];\n        for (i = 0; i &lt; 4; i++) n[r][i] = u[i];\n    }\n    return n;\n}\n\nfunction h(n) {\n    for (var t, r, u, i = 0; i &lt; 4; i++) {\n        for (t = new Array(4), r = new Array(4), u = 0; u &lt; 4; u++)\n            (t[u] = n[u][i]),\n            (r[u] = n[u][i] & 128 ? (n[u][i] &lt;&lt; 1) ^ 283 : n[u][i] &lt;&lt; 1);\n        n[0][i] = r[0] ^ t[1] ^ r[1] ^ t[2] ^ t[3];\n        n[1][i] = t[0] ^ r[1] ^ t[2] ^ r[2] ^ t[3];\n        n[2][i] = t[0] ^ t[1] ^ r[2] ^ t[3] ^ r[3];\n        n[3][i] = t[0] ^ r[0] ^ t[1] ^ t[2] ^ r[3];\n    }\n    return n;\n}\n\nfunction t(n, t, i, r) {\n    for (var f, u = 0; u &lt; 4; u++)\n        for (f = 0; f &lt; r; f++) n[u][f] ^= t[i * 4 + f][u];\n    return n;\n}\n\nfunction e(n) {\n    for (var t = 0; t &lt; 4; t++) n[t] = o[n[t]];\n    return n;\n}\n\nfunction c(n) {\n    for (var i = n[0], t = 0; t &lt; 3; t++) n[t] = n[t + 1];\n    return (n[3] = i), n;\n}\n\nfunction rr(n) {\n    for (\n        var h,\n            i,\n            o = 4,\n            r = n.length / 4,\n            s = r + 6,\n            f = new Array(o * (s + 1)),\n            u = new Array(4),\n            t = 0; t &lt; r; t++\n    )\n        (h = [n[4 * t], n[4 * t + 1], n[4 * t + 2], n[4 * t + 3]]), (f[t] = h);\n    for (t = r; t &lt; o * (s + 1); t++) {\n        for (f[t] = new Array(4), i = 0; i &lt; 4; i++) u[i] = f[t - 1][i];\n        if (t % r == 0)\n            for (u = e(c(u)), i = 0; i &lt; 4; i++) u[i] ^= l[t / r][i];\n        else r &gt; 6 && t % r == 4 && (u = e(u));\n        for (i = 0; i &lt; 4; i++) f[t][i] = f[t - r][i] ^ u[i];\n    }\n    return f;\n}\n\nfunction r(n) {\n    for (\n        var h,\n            i,\n            o = 4,\n            r = n.length / 4,\n            s = r + 6,\n            f = new Array(o * (s + 1)),\n            u = new Array(4),\n            t = 0; t &lt; r; t++\n    )\n        (h = [n[4 * t], n[4 * t + 1], n[4 * t + 2], n[4 * t + 3]]), (f[t] = h);\n    for (t = r; t &lt; o * (s + 1); t++) {\n        for (f[t] = new Array(4), i = 0; i &lt; 4; i++) u[i] = f[t - 1][i];\n        if (t % r == 0)\n            for (u = e(c(u)), i = 0; i &lt; 4; i++) u[i] ^= l[t / r][i];\n        else r &gt; 6 && t % r == 4 && (u = e(u));\n        for (i = 0; i &lt; 4; i++) f[t][i] = f[t - r][i] ^ u[i];\n    }\n    return f;\n}\n\nfunction a(n, t, u) {\n    var c = 16,\n        a,\n        y,\n        l,\n        w,\n        o,\n        e,\n        f,\n        nt;\n    if (!(u == 128 || u == 192 || u == 256)) return \"\";\n    for (n = s(n), t = s(t), a = u / 8, y = new Array(a), f = 0; f &lt; a; f++)\n        y[f] = isNaN(t.charCodeAt(f)) ? 0 : t.charCodeAt(f);\n    l = i(y, rr(y));\n    l = l.concat(l.slice(0, a - 16));\n    var h = new Array(c),\n        k = new Date().getTime(),\n        tt = k % 1e3,\n        it = Math.floor(k / 1e3),\n        rt = Math.floor(Math.random() * 65535);\n    for (f = 0; f &lt; 2; f++) h[f] = (tt &gt;&gt;&gt; (f * 8)) & 255;\n    for (f = 0; f &lt; 2; f++) h[f + 2] = (rt &gt;&gt;&gt; (f * 8)) & 255;\n    for (f = 0; f &lt; 4; f++) h[f + 4] = (it &gt;&gt;&gt; (f * 8)) & 255;\n    for (w = \"\", f = 0; f &lt; 8; f++) w += String.fromCharCode(h[f]);\n    var ut = rr(l),\n        b = Math.ceil(n.length / c),\n        d = new Array(b);\n    for (o = 0; o &lt; b; o++) {\n        for (e = 0; e &lt; 4; e++) h[15 - e] = (o &gt;&gt;&gt; (e * 8)) & 255;\n        for (e = 0; e &lt; 4; e++) h[11 - e] = (o / 4294967296) &gt;&gt;&gt; (e * 8);\n        var ft = i(h, ut),\n            g = o &lt; b - 1 ? c : ((n.length - 1) % c) + 1,\n            p = new Array(g);\n        for (f = 0; f &lt; g; f++)\n            (p[f] = ft[f] ^ n.charCodeAt(o * c + f)),\n            (p[f] = String.fromCharCode(p[f]));\n        d[o] = p.join(\"\");\n    }\n    return (nt = w + d.join(\"\")), v(nt);\n}\n\nfunction v(n) {\n    for (\n        var i = \"0x\",\n            r = [\n                \"0\",\n                \"1\",\n                \"2\",\n                \"3\",\n                \"4\",\n                \"5\",\n                \"6\",\n                \"7\",\n                \"8\",\n                \"9\",\n                \"a\",\n                \"b\",\n                \"c\",\n                \"d\",\n                \"e\",\n                \"f\",\n            ],\n            t = 0; t &lt; n.length; t++\n    )\n        i += r[n.charCodeAt(t) &gt;&gt; 4] + r[n.charCodeAt(t) & 15];\n    return i;\n}\n\nfunction s(n) {\n    var t = n.replace(/[\\u0080-\\u07ff]/g, function(n) {\n        var t = n.charCodeAt(0);\n        return String.fromCharCode(192 | (t &gt;&gt; 6), 128 | (t & 63));\n    });\n    return t.replace(/[\\u0800-\\uffff]/g, function(n) {\n        var t = n.charCodeAt(0);\n        return String.fromCharCode(\n            224 | (t &gt;&gt; 12),\n            128 | ((t &gt;&gt; 6) & 63),\n            128 | (t & 63)\n        );\n    });\n}\n\nvar o = [\n        99, 124, 119, 123, 242, 107, 111, 197, 48, 1, 103, 43, 254, 215, 171, 118,\n        202, 130, 201, 125, 250, 89, 71, 240, 173, 212, 162, 175, 156, 164, 114,\n        192, 183, 253, 147, 38, 54, 63, 247, 204, 52, 165, 229, 241, 113, 216, 49,\n        21, 4, 199, 35, 195, 24, 150, 5, 154, 7, 18, 128, 226, 235, 39, 178, 117, 9,\n        131, 44, 26, 27, 110, 90, 160, 82, 59, 214, 179, 41, 227, 47, 132, 83, 209,\n        0, 237, 32, 252, 177, 91, 106, 203, 190, 57, 74, 76, 88, 207, 208, 239, 170,\n        251, 67, 77, 51, 133, 69, 249, 2, 127, 80, 60, 159, 168, 81, 163, 64, 143,\n        146, 157, 56, 245, 188, 182, 218, 33, 16, 255, 243, 210, 205, 12, 19, 236,\n        95, 151, 68, 23, 196, 167, 126, 61, 100, 93, 25, 115, 96, 129, 79, 220, 34,\n        42, 144, 136, 70, 238, 184, 20, 222, 94, 11, 219, 224, 50, 58, 10, 73, 6,\n        36, 92, 194, 211, 172, 98, 145, 149, 228, 121, 231, 200, 55, 109, 141, 213,\n        78, 169, 108, 86, 244, 234, 101, 122, 174, 8, 186, 120, 37, 46, 28, 166,\n        180, 198, 232, 221, 116, 31, 75, 189, 139, 138, 112, 62, 181, 102, 72, 3,\n        246, 14, 97, 53, 87, 185, 134, 193, 29, 158, 225, 248, 152, 17, 105, 217,\n        142, 148, 155, 30, 135, 233, 206, 85, 40, 223, 140, 161, 137, 13, 191, 230,\n        66, 104, 65, 153, 45, 15, 176, 84, 187, 22,\n    ],\n    l = [\n        [0, 0, 0, 0],\n        [1, 0, 0, 0],\n        [2, 0, 0, 0],\n        [4, 0, 0, 0],\n        [8, 0, 0, 0],\n        [16, 0, 0, 0],\n        [32, 0, 0, 0],\n        [64, 0, 0, 0],\n        [128, 0, 0, 0],\n        [27, 0, 0, 0],\n        [54, 0, 0, 0],\n    ];\n// n.encrypt = a\nasync function iceAI_word(\n    // ToUserName,\n    // FromUserName,\n    // CreateTime,\n    // MsgType,\n    Content,\n    config\n    // MsgId,\n) {\n  await sleep(1000);\n  // for whatever reason you have to wait for this long.\n\n  try{\n    var wquery = a(Content, \"3d9d5f16-5df0-43d7-902e-19274eecdc41\", 256);\n    console.log(\"encrypt:\" + wquery);\n    // let config = {};\n\n    // if ((await mysqld.isHaveChatIdIn(fromQQ)) == true) {\n    //     console.log(\"没有chatid，获取新id\")\n    //     config = await mysqld.getChatId(fromQQ);\n    // } else {\n    //     config = await newChatId(fromQQ);\n    // }\n    if (config) {\n        console.log(\"config:\" + config);\n    } else {\n      console.log('no config for xiaoice chat.')\n        return;\n    }\n    var h = {\n        zoTextResponse: \"\",\n        zoIsGCSResponse: false,\n        zoSearchQuery: \"hhh\",\n        zoTimestampUtc: \"\",\n        zoIsStartOfSession: true,\n        zoRequestId: getRequestId(),\n        conversationId: config.conversationId,\n        query: { NormalizedQuery: wquery },\n        from: \"chatbox\",\n        traceId: config.traceId,\n    };\n    var url = \"https://cn.bing.com/english/zochatv2?cc=cn&ensearch=0\";\n    // {\"zoTextResponse\":\"\",\"zoIsGCSResponse\":\"false\",\"zoSearchQuery\":\"123\",\"zoTimestampUtc\":\"\",\"zoIsStartOfSession\":\"true\",\"zoRequestId\":\"ff90e6f70a6048d4fe5cc3c3327bbd32\",\"conversationId\":\"4a91fb33-73f7-43d4-b7b6-ba86a16e32fb\",\"query\":{\"NormalizedQuery\":\"0x23028811be44f661169365\"},\"from\":\"chatbox\",\"traceId\":\"B224B190F87941CD94AD0AC31A189D30\"}\n    let result = await getContents({\n        url: url,\n        method: \"POST\",\n        headers: {\n            \"content-type\": \"text/plain;charset=UTF-8\",\n            origin: \"https://cn.bing.com\",\n            referer: \"https://cn.bing.com/search?q=123&form=QBLH&sp=-1&pq=123&sc=6-3&qs=n&sk=&cvid=566F001FDA424EEB805E1C175363B5AE\",\n            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\",\n            Connection: \"keep-alive\",\n        },\n        body: JSON.stringify(h),\n    });\n\n    // {\"content\":\"嘿 啾 嘿 啾啊\",\"type\":1,\"delayContents\":null,\"entityInfo\":[{\"Entity\":\"嘿 啾 嘿 啾啊\",\"IsEntity\":false}],\"target\":\"b\",\"history\":null,\"hasClientIdinMem\":true,\"needSayHello\":false,\"isHookStr\":false,\"showChatBox\":true,\"metadata\":{\"AnswerFeed\":\"RandomChitChatService\",\"EmotionInfo\":\"{\\\"EmotionClassificationInfo\\\":[{\\\"Category\\\":\\\"Sad\\\",\\\"Score\\\":0.0651140139},{\\\"Category\\\":\\\"Happy\\\",\\\"Score\\\":0.139467061},{\\\"Category\\\":\\\"Surprise\\\",\\\"Score\\\":0.176786855},{\\\"Category\\\":\\\"Angry\\\",\\\"Score\\\":0.358794},{\\\"Category\\\":\\\"Disgust\\\",\\\"Score\\\":0.2598381}],\\\"NeutralScore\\\":0.9992748,\\\"DomainInMatchScenario\\\":\\\"None\\\"}\"}}\n    result = JSON.parse(result);\n    if (result.content) {\n        var reply = result.content;\n        reply = reply.replace(\"小冰\", \"小姝\");\n        var message = 1;\n        var unuseless =\n            \"看的我一脸懵逼，都开始怀疑我的智商了。哎呀，不好意思，我刚刚好像走神了,感觉你知道的挺多的呢,额，我现在也不知道该说些什么,这个…不太好说啊,我语文不太好，不确定是不是懂了你的意思,刚刚不小心溜号了，真是不好意思\";\n        if (unuseless.indexOf(reply) != -1) {\n          console.log('xiaoice is returning useless reply', reply)\n            //   message = 2;\n            //   Log.trace(\"iceAi have unuseless message\");\n            //   request(\n            //     {\n            //       url:\n            //         \"http://api.qingyunke.com/api.php?key=free&appid=0&msg=\" +\n            //         encodeURIComponent(msg2),\n            //       method: \"GET\",\n            //     },\n            //     function (error, response, body) {\n            //       var result = JSON.parse(body);\n            //       reply = result.content;\n            //       var logtext = \"\";\n            //       return;\n            //     }\n            //   );\n        } else {\n            return reply;\n        }\n    }\n  } catch(e){\n    console.log('ERROR FETCHING XIAOBING CHAT',e)\n    // will return nothing.\n    // sleep for 1 second?\n    // would you sleep for a while?\n  }\n}\n\nasync function newChatId(query) {\n    var options = options || {};\n    var httpOptions = {\n        url: \"https://cn.bing.com/search?q=\"+query+\"&form=QBLH&rdr=1&rdrig=E8F3C1A722454F949CCC4B98C4570A4A\",\n        method: \"get\",\n        timeout: 1000,\n        headers: {\n            accept: \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n            \"accept-language\": \"zh-CN,zh;q=0.9\",\n            \"cache-control\": \"max-age=0\",\n            \"sec-ch-ua\": '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"102\", \"Google Chrome\";v=\"102\"',\n            \"sec-ch-ua-arch\": '\"x86\"',\n            \"sec-ch-ua-bitness\": '\"64\"',\n            \"sec-ch-ua-full-version\": '\"102.0.5005.63\"',\n            \"sec-ch-ua-mobile\": \"?0\",\n            \"sec-ch-ua-model\": '\"\"',\n            \"sec-ch-ua-platform\": '\"Windows\"',\n            \"sec-ch-ua-platform-version\": '\"10.0.0\"',\n            \"sec-fetch-dest\": \"document\",\n            \"sec-fetch-mode\": \"navigate\",\n            \"sec-fetch-site\": \"same-origin\",\n            cookie: \"MUID=005F25E7699168532D05342768F769B3; MUIDB=005F25E7699168532D05342768F769B3; _EDGE_V=1; SRCHD=AF=NOFORM; SRCHUID=V=2&GUID=31127A3BD4B84FF08E8E51EEEA34857F&dmnchg=1; _UR=QS=0&TQS=0; _HPVN=CS=eyJQbiI6eyJDbiI6MSwiU3QiOjAsIlFzIjowLCJQcm9kIjoiUCJ9LCJTYyI6eyJDbiI6MSwiU3QiOjAsIlFzIjowLCJQcm9kIjoiSCJ9LCJReiI6eyJDbiI6MSwiU3QiOjAsIlFzIjowLCJQcm9kIjoiVCJ9LCJBcCI6dHJ1ZSwiTXV0ZSI6dHJ1ZSwiTGFkIjoiMjAyMi0wNi0xMVQwMDowMDowMFoiLCJJb3RkIjowLCJHd2IiOjAsIkRmdCI6bnVsbCwiTXZzIjowLCJGbHQiOjAsIkltcCI6NH0=; SUID=M; SRCHUSR=DOB=20220611&T=1659599964000&TPC=1659599966000; ZHCHATSTRONGATTRACT=TRUE; ZHCHATWEAKATTRACT=TRUE; _EDGE_S=SID=05C5058B7100688001DB147D702E698C; _SS=SID=05C5058B7100688001DB147D702E698C; _tarLang=default=zh-Hans; _TTSS_IN=hist=WyJlbiIsImF1dG8tZGV0ZWN0Il0=; _TTSS_OUT=hist=WyJ6aC1IYW5zIl0=; ipv6=hit=1659603639345&t=4; SNRHOP=I=&TS=; SRCHHPGUSR=SRCHLANG=zh-Hans&BRW=NOTP&BRH=S&CW=599&CH=657&SW=1366&SH=768&DPR=1&UTC=480&DM=0&PV=0.3.0&BZA=0&HV=1659600073&WTS=63795196764\",\n            \"sec-fetch-user\": \"?1\",\n            accept: \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n            \"accept-language\": \"zh-CN,zh;q=0.9\",\n            \"cache-control\": \"max-age=0\",\n            \"upgrade-insecure-requests\": \"1\",\n            Referer: \"referer: https://cn.bing.com/search?q=\"+query+\"&form=QBLHCN&sp=-1&pq=a&sc=6-1&qs=n&sk=&cvid=A91AB41228AD45E694D5F2EEBF87FE70\",\n            \"Referrer-Policy\": \"strict-origin-when-cross-origin\",\n            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36\",\n        },\n    };\n    let body = await getContents(httpOptions)\n\n    //console.log(body)\n    if (body.indexOf(\"conversationId\") == -1) {\n        console.log(\"请求chatid失败\");\n        return;\n    }\n    console.log(body.indexOf(\"conversationId\"));\n    console.log(body.indexOf(\"iframeTalkStatus\"));\n    let config =\n        '{\"' +\n        body.substring(\n            body.indexOf(\"conversationId\"),\n            body.indexOf(\"iframeTalkStatus\")\n        ) +\n        '\":\"\"}';\n    config = JSON.parse(config);\n    console.log(config);\n    // mysqld.addChatId(fromQQ, config);\n    return config;\n}\nasync function getAuth(opts, redis) {\n    cookie = await post(opts);\n    //redis.set(\"ice_cookie\", cookie)\n\n    log.info(\"new cookie:\" + cookie);\n    return cookie;\n}\n\nfunction post(opts) {\n    return new Promise((resolve, reject) =&gt; {\n        request(opts, function(error, response) {\n            if (error) throw new Error(error);\n            if (response.statusCode != \"200\") {\n                console.log(\"requestCode:\" + response.statusCode);\n            }\n            console.log(\"requestCode:\" + response.statusCode);\n            var responseCookies = response.headers[\"set-cookie\"];\n            console.log(response.body);\n            var requestCookies = \"\";\n            for (var i = 0; i &lt; responseCookies.length; i++) {\n                var oneCookie = responseCookies[i];\n                oneCookie = oneCookie.split(\";\");\n                requestCookies = requestCookies + oneCookie[0] + \";\";\n            }\n            resolve(requestCookies);\n        });\n    });\n}\n\nfunction getContents(opts) {\n    return new Promise((resolve, reject) =&gt; {\n        request(opts, function(error, response) {\n            if (error) reject(error);\n            if (response.statusCode != \"200\") {\n                console.log(\"requestCode:\" + response.statusCode);\n            }\n            console.log(\"requestCode:\" + response.statusCode);\n            var responseCookies = response.headers[\"set-cookie\"];\n\n            resolve(response.body);\n        });\n    });\n}\n// module.exports = { iceAI_word };\n// let test_request = \"不会吧\"\n// let test_request = \"python\"\nconst http = require('http');\nfunction getQueryParams(reqUrl) {\n  current_url = new URL('http://localhost' + reqUrl)\n  params = current_url.searchParams\n  console.log('query parameters:', params)\n  return params\n}\nlet topic_chatId_dict = {}\nconst requestListener = function (req, res){\n  console.log(\"________________________________________________\")\n    console.log(\"REQUEST AT:\", req.url, req.method)\n    if (req.url == \"/\") {\n      res.writeHead(200);\n      res.end('xiaoice chat server');\n  } else if (req.url.split(\"?\")[0] == '/chat'){\n    callback = (result) =&gt; {\n      res.writeHead(200);\n      content = {\"msg\": 'success','reply': result}\n      res.end(JSON.stringify(content))\n  }\n  params = getQueryParams(req.url)\n  message =params.get(\"message\")\n  topic = params.get(\"topic\")\n  if (message==null){\n    message = \"你好呀\"\n  }\n  if (topic == null){\n    topic = \"hhh\"\n  }\n  console.log(\"MESSAGE:\", message)\n  console.log(\"TOPIC:\", topic)\n  if (topic_chatId_dict[topic] == null){\n    topic_chatId_dict[topic] = newChatId(topic)\n  }\n  chatId = topic_chatId_dict[topic]\n  if (chatId !=null){\n    response = iceAI_word(message, chatId)\n    response.then((content) =&gt; {\n      console.log(\"REAL RESPONSE:\", content)\n      if (content !=null){\n        callback(content)\n      }else{\n        res.writeHead(401);\n        res.end(JSON.stringify({'msg':'empty response from microsoft xiaoice'}))\n      }\n    })\n\n  }else{\n    res.writeHead(401)\n    res.end(JSON.stringify({'msg':'error when getting chatid'}))\n  }\n\n  }else{\n    res.writeHead(400);\n    res.end('please use /chat?topic={topic}&message={message} to chat with xiaoice.')\n  }\n}\nconst server = http.createServer(requestListener);\nport = 8735\nserver.listen(port);\nconsole.log('xiaoice server running on http://localhost:' + port);\n\n// // these code are just for test.\n// let test_request = \"你吃了没有\"\n// // let test_request2 = \"你吃了没有\"\n// query = 'python'\n// let config = newChatId(query)\n// response = iceAI_word(test_request, config) // automatically retry once. if keeping generating useless shits, we may decide to give it up?\n// // it is a promise.\n\n// // this is async shit.\n// // what if there's some error?\n// response.then((content) =&gt; {console.log(\"REAL RESPONSE:\", content)})\n// // REAL RESPONSE: 不想就不说了\n// // console.log(\"RESPONSE:\", response)\n// // response = iceAI_word(test_request2, config)\n// // console.log(\"RESPONSE:\", response)"
  },
  {
    "objectID": "posts/ece4babc-9aba-4364-a5da-5cacc9910d46/index.html#注意事项",
    "href": "posts/ece4babc-9aba-4364-a5da-5cacc9910d46/index.html#注意事项",
    "title": "批量扫描书 批量学习理解全流程",
    "section": "注意事项",
    "text": "注意事项\n首先如果网上有电子书，不必购买纸质书。\n书里面如果有二维码，附送的代码，要下载下来利用。"
  },
  {
    "objectID": "posts/ece4babc-9aba-4364-a5da-5cacc9910d46/index.html#切割-扫描-装订",
    "href": "posts/ece4babc-9aba-4364-a5da-5cacc9910d46/index.html#切割-扫描-装订",
    "title": "批量扫描书 批量学习理解全流程",
    "section": "切割 扫描 装订",
    "text": "切割 扫描 装订\n切书用重型切纸机，扫描用双面批量扫描仪，扫描完毕需要用热熔胶粘书装订机装回 用卡纸做背封 用滚筒双面胶粘封面和背封的连接处"
  },
  {
    "objectID": "posts/ece4babc-9aba-4364-a5da-5cacc9910d46/index.html#存储-识别-索引-搜索-理解",
    "href": "posts/ece4babc-9aba-4364-a5da-5cacc9910d46/index.html#存储-识别-索引-搜索-理解",
    "title": "批量扫描书 批量学习理解全流程",
    "section": "存储 识别 索引 搜索 理解",
    "text": "存储 识别 索引 搜索 理解\n用OCR latex识别器 图片识别器（识别并分割配图） 表格识别器（分割表格）无纸化还原文档原本结构 最好用markdown表示\n搜索用bm25加语义搜索 加latex识图搜索 图像识别搜索\n把整理好的数据加入到ChatGPT模型或者RETRO模型的预训练集中"
  },
  {
    "objectID": "posts/8e3b3247-e67b-4e00-aadb-c95d05f21afd/index.html",
    "href": "posts/8e3b3247-e67b-4e00-aadb-c95d05f21afd/index.html",
    "title": "控油 祛痘",
    "section": "",
    "text": "控油 祛痘\n痘坑修护 水杨酸 果酸（加速角质增生） 乳糖酸 海藻糖（提供营养） 洋甘菊 芦荟（降油） 苦参 香叶天竺葵 马齿苋（促进再生）\n燃脂 瘦腿霜 看起来更像女的 减肚子 减油\n清水洗脸 不要过度清洁 不要搓 用氨基酸洗面奶 不要用皂基 油的时候就清水洗脸 不要抹乳膏\n往气温低的地方走 开空调\n刷酸 果酸 水杨酸 杏仁酸\n控制雄性激素 减少压力 不要紫薇 不要熬夜\n涂吸油的粉 玉米淀粉\n防晒 spf值高的防晒霜 物理防晒 不是化学防晒 不油的防晒霜\n饮食调节 不要吃肉 碳水化合物 糖 乳制品 不吃油 吃蛋白质 少盐 吃大豆 大豆异黄酮（植物雌激素） 吃番茄 番茄红素（植物的双氢睾酮转化酶抑制剂）\n吃非那雄胺 雌激素 螺内酯\n干燥的空气 去湿气\n维生素 微量元素： 维他命B6和B2 维他命A 维他命C 锌 可杀灭痤疮杆菌 轻度减少油脂分泌\n烟酰胺\n抑制还原酶活性： 丹参酮 抗雄 茶多酚 抑制酶活性 壬二酸/锯棕榈提取物：抑制5α还原酶的活性 烟酰胺：减少皮肤表面的油脂量 染料木黄酮：一种植物性雌激素（新鲜的豆浆里面就有~），被认为是抗雄激素成分以减少油脂产生。 金缕梅：有收敛作用，能够去除面部多余的油脂。"
  },
  {
    "objectID": "posts/b69b3ca1-eae1-47f1-95f8-a0a1c8ac89b0/index.html",
    "href": "posts/b69b3ca1-eae1-47f1-95f8-a0a1c8ac89b0/index.html",
    "title": "搜狗输入法AI功能",
    "section": "",
    "text": "搜狗输入法AI功能\nAI配图 AI帮写 趣聊 翻译 校对"
  },
  {
    "objectID": "posts/6f51e20d-9e83-4497-a6a8-402f2c7a10d8/index.html",
    "href": "posts/6f51e20d-9e83-4497-a6a8-402f2c7a10d8/index.html",
    "title": "智能手表防水 泡温泉",
    "section": "",
    "text": "智能手表防水 泡温泉 外壳\n智能手表都不能泡温泉 洗澡\n可以考虑做智能手表的时候添加耐温耐水蒸汽的胶水 也可以考虑做防水汽的外壳 塑料透明保护壳 胶圈要和塑料壳之间用耐温耐水汽的胶水粘连 胶圈之间添加波纹 纹路 增加密封强度 耐压 用铰链链接 卡扣扣住 或者双卡扣\n如果外壳需要留空间给按钮 用橡胶按钮加耐压防水胶 或者粘贴实体按钮 硬质按钮加橡胶密封层 注意连接处面积要大\n旋转的按钮就不要旋转了 因为无法密封 比如苹果iwatch 只能点按\n外壳一般有配套的表带 不用原来的连接装置"
  },
  {
    "objectID": "posts/e253b2c3-d381-4240-837d-d13972af6354/index.html#网页转文章",
    "href": "posts/e253b2c3-d381-4240-837d-d13972af6354/index.html#网页转文章",
    "title": "模板创作模式 自媒体 洗稿",
    "section": "网页转文章",
    "text": "网页转文章\nreadbility.js\npagescraper in php\nelinks -dump &lt;url&gt;\n可以把一个文字或者其他类型的内容当成模板 其他文字 视频 图片当作素材 根据模板收集素材 形成内容 注意素材不能是模板本身 素材不能单一 不然被认定为抄袭\n文章洗稿 基于标题和context生成段落： https://github.com/yangjianxin1/CPM\nbert mask: https://huggingface.co/fnlp/bart-base-chinese https://huggingface.co/hfl/chinese-macbert-base\nchinese paraphrase: https://github.com/ZhuiyiTechnology/roformer https://github.com/ZhuiyiTechnology/simbert 可能不是paraphrase模型 https://huggingface.co/lijingxin/mt5-for-zh-paraphrase/tree/main https://huggingface.co/facebook/m2m100_418M https://github.com/jiangnanboy/chinese_sentence_paraphrase\nchinese summarize generator: 一般抽取式的提取 都需要有gpt生成器在中间插入一些句子 hanlp自带抽取文本方案 抽取式文本摘要 bart t5 pegasus中文文本摘要 有训练数据集 训练教程 一直在想怎么能正确高效的处理seo中，采集的文章怎么去伪原创和洗稿。如果是人工操作的话，那就太麻烦了。采集下来的文章不进行伪原创又害怕被飓风算法命中。\n1，tr算法提取摘要再人工重组新的文章。\n正好今天发现了python中的textrank4zh库，依赖于jieba、numpy和networkx库，可以通过tr算法进行文章的摘要提取。然后根据摘要再人工洗稿，整合成一篇全新的文章。\n测试一篇蚂蜂窝上面的问答，蚂蜂窝问答下面是有很多个答主的内容，通过python爬取所有内容，然后再利用tr算法提取摘要，根据摘要进行重组出一篇新的文章。这样基本上可以成功躲避飓风算法。\n先安装依赖库，然后再利用tr4进行摘要提取。\nfrom textrank4zh import TextRank4Keyword, TextRank4Sentence\ncontent = \"\" # 这里是python采集下来的content html内容\ntext = re.sub('&lt;.*?&gt;','',content)\ntext = re.sub(r'\\s','',text)\nzy = ''\ntr4s = TextRank4Sentence()\ntr4s.analyze(text=text, lower=True, source = 'all_filters')\n# 可修改num值，设置摘要长度。\nfor item in tr4s.get_key_sentences(num=10): \n  zy = zy + item.sentence\n2，利用google翻译双向翻译洗稿\n之前有接触一个所谓人工智能洗稿的网站小发猫，说的是利用NLP算法进行洗稿，本来我以为洗稿只有同义词替换这个办法。\n后来研究了一下小发猫，我首先觉得这个绝对不是利用什么所谓的NLP算法来洗稿，研究了一下发现可能是利用google翻译进行双向翻译，就是先中文翻译英文，然后再拿翻译出来的英文再翻译成中文。\n自己也开发了一个这样的伪原创工具，发现其实并不好用。如果不仔细读，这样双向翻译出来的文章还能读，但是仔细读的话。其实语法习惯还有用词根本不准确，甚至有些情况还改变了这句话原有的语义。"
  },
  {
    "objectID": "posts/1e0068c8-32d6-441d-95f4-d459cf32c808/index.html",
    "href": "posts/1e0068c8-32d6-441d-95f4-d459cf32c808/index.html",
    "title": "水冷散热注意",
    "section": "",
    "text": "水冷散热注意\n水里加醇类物质可以防止导电\n软管加弹簧防止弯折\n液体生料带 ergo 5500陶瓷胶 密封胶 液态密封圈 堵漏 用油管防止老化\n用水管变径器来改变管径 先用相同大小软管连接目标接头 再用变径器链接变径软管\n气压计 肥皂水测试是否漏水\n水泵串联并联增加流量和扬程\n多水道设计增加导热效率\n显卡mos管需要水冷散热 建议看显卡发热红外图其他未水冷的地方贴上散热脊片\n主板本来有热管 风扇散热的地方 例如南北桥 供电 如果要拆除 必须替换成水冷 背面也应该加上水冷\n氟化液沉浸式散热 可以用潜水泵抽水加冷排\n压缩机28度以上防止冷凝水聚集\n用水冷弹性弹簧喉夹来链接软管 有快拧接口的要有快拧头连接硬管或软管\n用热缩编织管来避免磨损 用阻燃波纹管套住最外面\n打磨弹簧套管的两端 避免戳穿软管\n用全开放式机架 铝合金框架 方便主板背面 显卡背面冷却装置的安装\n工业装甲带缠绕接头部分"
  },
  {
    "objectID": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#notice",
    "href": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#notice",
    "title": "涩图api setu bot",
    "section": "notice",
    "text": "notice\n涩图可以发到qq群里面活跃气氛 可以发到专栏里面 可以添加到视频里面“截图选老婆” 涩图分为二次元和三次元涩图 皆要控制尺度 除了涩图之外，能够随时使用的番剧clip也是很重要的 如何获取“动漫名场面”呢"
  },
  {
    "objectID": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#projects",
    "href": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#projects",
    "title": "涩图api setu bot",
    "section": "projects",
    "text": "projects\nhttps://github.com/opq-osc/OPQ-SetuBot 直接搜索的pixiv"
  },
  {
    "objectID": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#二次元涩图api",
    "href": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#二次元涩图api",
    "title": "涩图api setu bot",
    "section": "二次元涩图api",
    "text": "二次元涩图api\nhttps://api.lolicon.app/#/setu 注意不要r18的 要用nsfw检查一下至少"
  },
  {
    "objectID": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#三次元涩图api",
    "href": "posts/8c72de02-7538-4448-b698-a11fb76ced44/index.html#三次元涩图api",
    "title": "涩图api setu bot",
    "section": "三次元涩图api",
    "text": "三次元涩图api"
  },
  {
    "objectID": "posts/62e15baf-8905-4649-99ec-5dfaaac05c64/index.html",
    "href": "posts/62e15baf-8905-4649-99ec-5dfaaac05c64/index.html",
    "title": "现代 后现代 Vtuber 流行趋势",
    "section": "",
    "text": "现代 后现代 Vtuber 流行趋势\n把内容生产者的内容拿来训练 当模板 生成类似内容 把大众的评论 互动 弹幕拿来当鉴别器的训练资料 聚类观众 建立观众群体和内容的对应关系\n现代就是烂大街的内容 大家都接受 后现代就是一部分人接受 一部分不接受的内容 有流行的趋势\n将现代的内容（已经流行过的内容）作为素材 将后现代（将要流行 或者根据以往经验生成的模板）作为模板 合成内容 可以满足后现代群体需要 具有流行趋势"
  },
  {
    "objectID": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#首页",
    "href": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#首页",
    "title": "百度贴吧app接口",
    "section": "首页",
    "text": "首页\n大家都在搜\n热搜榜 热吧榜 游戏榜（手游 端游 主机）\n关注 推荐\n热榜 （贴吧话题榜，热帖榜（总榜，视频，长更，游戏，数码）\n直播 （我的关注，排行榜，讨论区，个人中心，我要直播，推荐，颜值）\n视频"
  },
  {
    "objectID": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#进吧",
    "href": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#进吧",
    "title": "百度贴吧app接口",
    "section": "进吧",
    "text": "进吧\n关注的吧 吧广场 最近逛的吧"
  },
  {
    "objectID": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#频道",
    "href": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#频道",
    "title": "百度贴吧app接口",
    "section": "频道",
    "text": "频道\n游戏 数码 娱乐 影视 动漫 体育 小说 同城"
  },
  {
    "objectID": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#消息",
    "href": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#消息",
    "title": "百度贴吧app接口",
    "section": "消息",
    "text": "消息\n@我的 点赞 回复 粉丝"
  },
  {
    "objectID": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#我的",
    "href": "posts/ff1994bc-2a88-450b-a001-824e0ce412a8/index.html#我的",
    "title": "百度贴吧app接口",
    "section": "我的",
    "text": "我的\n关注 粉丝 吧\n我的帖子 大神认证 创作学院 热门活动\n我的收藏 浏览历史 直播 话题（贴吧话题榜）"
  },
  {
    "objectID": "posts/40203879-512a-4ed1-91a4-54d5e7426b37/index.html",
    "href": "posts/40203879-512a-4ed1-91a4-54d5e7426b37/index.html",
    "title": "盗版影视站",
    "section": "",
    "text": "盗版影视站\n奈菲影视 https://www.nfmovies.com/\n团长资源 https://tzfile.com/\n低端影视 http://ddrk.me/\n人人影视 http://www.zmz2019.com/\n远鉴字幕组 https://yj.apkgm.top/\ntg帮找资源频道 https://t.me/s/lovesource\nhttps://www.netflixstar.top/\nhttps://1090ys.com/"
  },
  {
    "objectID": "posts/02ed220b-7400-4594-bff6-a3a9c388a9ea/index.html",
    "href": "posts/02ed220b-7400-4594-bff6-a3a9c388a9ea/index.html",
    "title": "睡觉时间 内脏工作时间",
    "section": "",
    "text": "睡觉时间 内脏工作时间\n1、内脏器官工作时间：\n晚上9-11点为免疫系统（淋巴）排毒时间，此段时间应安静或听音乐，避免太过兴奋。\n2、晚间\n11-凌晨1点，肝的排毒，需在熟睡中进行，这是美容的黄金时间喔。\n3、凌晨1-3点\n凌晨1-3点，是胆的排毒，亦同。凌晨3-5点，肺的排毒。此即为何咳嗽的人在这段时间咳得最剧烈，因排毒动作已走到肺；不应用止咳药，以免抑制废积物的排除。\n4、凌晨5-7点\n凌晨5-7点，大肠的排毒，应上厕所排便。凌晨7-9点，小肠大量吸收营养的时段，应吃早餐。疗病者最好早吃，在６点半前，养生者在７点半前，不吃早餐者应改变习惯，要养成良好的生活习惯，按时吃饭也是很重要的。\n5、半夜至凌晨４点\n半夜至凌晨４点为脊椎造血时段，必须熟睡，不宜熬夜，年轻人不要再熬夜啦，否则对身体不好。"
  },
  {
    "objectID": "posts/88059193-9784-4977-8178-04b91397d518/index.html#perform-responsiveness-check-by-interval-using-some-deterministic-responses-or-commands-something-different-must-happen-because-of-something",
    "href": "posts/88059193-9784-4977-8178-04b91397d518/index.html#perform-responsiveness-check-by-interval-using-some-deterministic-responses-or-commands-something-different-must-happen-because-of-something",
    "title": "Controlling Computers with Hardware Operations and Software Tools: A Comprehensive Guide",
    "section": "perform responsiveness check by interval, using some deterministic responses or commands (something (different) must happen because of something)",
    "text": "perform responsiveness check by interval, using some deterministic responses or commands (something (different) must happen because of something)\n使用USB3.0录屏卡（HDMI）作为视频输入（类似于摄像头），延迟越低越好\nyou may configure pixel format (jpeg for fast computation) when using different capture cards\n为了通用一般用专门的硬件键鼠模拟器 或者带OTG的RPi模拟键鼠 接收操控方电脑的指令 输出HID信号\n\nreference\nFor recent raspbian you only need to turn on overlay switch in system configuration. (do not use other tools, since they will interfere)\nFor debian-like distros (ubuntu) you can use bilibop-lockfs or fsprotect (install/enable aufs-dkms or overlay filesystem before that)\nFor linux that is set to run in ram (tinycore linux), you can use it as-is, but it may oom so quick that you have to abandon it.\n\nstackoverflow 提到可以用蓝牙进行鼠标键盘模拟 (requires extra setup)\nLinux有驱动可以实现HID输出\nUse USB Gadget with OTG cables.\n用台湾的数据线\nRPi4支持OTG（通过USB-C供电接口） micro HDMI需要转接\nscrcpy –otg 可以识别周边设备 发送HID指令\n定时开关机电源线 加类似于Deep Freeze或者Live CD机制 使得电脑可以接收任意操作而不崩溃\npython usb-gadget wrapper"
  },
  {
    "objectID": "posts/f181e8b1-0196-4a41-91a6-379ff3ff8de4/index.html",
    "href": "posts/f181e8b1-0196-4a41-91a6-379ff3ff8de4/index.html",
    "title": "网上接单注意",
    "section": "",
    "text": "网上接单注意\n不管什么单子 必须在虚拟机里面跑\n不得物理机运行未知应用程序 否则就会出事"
  },
  {
    "objectID": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#tutorials-and-code",
    "href": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#tutorials-and-code",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "tutorials and code",
    "text": "tutorials and code\n综合能源系统分析的统一能路理论系列：\n综合能源系统分析的统一能路理论(一)：气路\n综合能源系统分析的统一能路理论(二)：水路与热路\n综合能源系统分析的统一能路理论(三)：《稳态与动态潮流计算》 &Python代码 & 讲解 （研学社？卖能管系统调优的代码）\nData and codes for energy circuit method-based optimal energy flow\nreinforcement learning (PPO) for NeurIPS Competition 2020: Learning to Run a Power Network (L2RPN)\n\n基于改进DaNN的综合能源系统多能负荷预测, DaNN (Domain Adversarial Neural Network, Unsupervised Domain Adaptation by Backpropagation (for digital twins?)) or DDAN (Deep Domain Adaptation Networks)\n综合能源系统（冷、热、电 (CCHP)）案例/论文/数据整理分享\n\n王子豪提供的综合能源系统优化运行专题：\nSection 1: 开篇：综合能源系统基本模型和gurobi基本语法 Section 2: 综合能源系统目标函数建立 Section 3: 综合能源系统最优电力潮流（OPF）模型建立与Gurobi实现 Section 4: 综合能源系统最优热力潮流（OTF）模型建立与Gurobi实现 Code: IESOptimization Section 5: 综合能源系统多时刻优化模型建立与求解"
  },
  {
    "objectID": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#tools",
    "href": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#tools",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "tools",
    "text": "tools\n\nmac m1 compatibility on windows software\ninstall by brew install wine-stable (version &gt;= 6.0.2)\nthen run wine64\n\n\npython doc generation\n\npydoc\nstart server using:\npython3 -m pydoc -p &lt;port&gt; &lt;module_name&gt;\n\n\npdoc3\npip3 install pdoc3\npdoc --html &lt;module_name&gt;\n\n\ndocstring\nclass myClass:\n  \"\"\"\n  myClass doc\n  \"\"\"\n  def __init__(self):\n    \"\"\"\n    init doc\n    \"\"\"\n\n\n\ncontrolling & monitoring\nOpenMUC is some advanced software only SCADA bridging system, with analysing but no simulation!\nOpenEMS is for monitoring, controlling and simulation based on historical data (not digital twin!)\nmyEMS用于能源管理项目的设备管理、数据采集、处理、分析、可视化和报表。\n\n\noptimization\nsolvers:\nglpk: gnu linear programming kit (LP/MIP problems), can bridge with gnu mathprog language (GMPL, subset of AMPL)\non blackbox optimization there are:\n\nGradient Free Optimizers like: meta-heuristic, simulated-annealing, hill-climbing, particle-swarm-optimization, evolution-strategies, blackbox-optimization, gradient-free-optimization, tree-of-parzen-estimator and many more\nvizier by google for blackbox and hyperparameter optimization\nparmoo for parallel multiobjective simulation optimization\n\n\nilqr: Iterative Linear Quadratic Regulator with auto-differentiatiable dynamics models\nRAVEN is a flexible and multi-purpose probabilistic risk analysis, validation and uncertainty quantification, parameter optimization, model reduction and data knowledge-discovering framework.\nRAVEN includes the following major capabilities:\n\nSampling of codes for uncertainty quantification and reliability analyses\nGeneration and use of reduced-order models (also known as surrogate)\nData post-processing (time dependent and steady state)\nTime dependent and steady state, statistical estimation and sensitivity analysis (mean, variance, sensitivity coefficients, etc.).\n\nThe RAVEN statistical analysis framework can be employed for several types of applications:\n\nUncertainty Quantification\nSensitivity Analysis / Regression Analysis\nProbabilistic Risk and Reliability Analysis (PRA)\nData Mining Analysis\nModel Optimization\n\n\nVSA-FINE: generating energy system optimization models, using tsam (for Time series aggregation, Pareto-Optimal Temporal Aggregation of Energy System Models) and pyomo, compatible for both commercial solvers and open-source solvers.\noptimization using PuLP (by coin-or)\npython-mip (install by pip install mip) provides tools for modeling and solving Mixed-Integer Linear Programming Problems.\nGEKKO is a Python package for machine learning and optimization of mixed-integer and differential algebraic equations. Modes of operation include parameter regression, data reconciliation, real-time optimization, dynamic simulation, and nonlinear predictive control. (MPC? see APM Python with Demo Applications on GitHub)\nnumdifftools Solves automatic numerical differentiation problems in one or more variables (Jacobian?)\nNEOS is a free service for numerical optimization, which almost only accepts GAMS/AMPL/SMPS code.\nCeres Solver is for non-linear least squares (curve fitting, can be done in lmfit-py and scipy.optimize.curve_fit (from python numerical methods, a tutorial on numerical processing)) and can be accelerated by multiprocessing or CUDA\nCOIN-OR projects (many things!) are usually solver and optimization related. Pyomo (a collection of Python software packages for formulating optimization models, similar to linopy (only for labeled data, linear optimization)) is part of the project.\nOpenSolvers is for microsoft excel and uses linear solvers like COIN-OR CBC (on which mentioned a lot of modeling languages/tools it supports) and non-linear solvers like Bonmin (Basic Open-source Nonlinear Mixed INteger programming) and Couenne (Convex Over and Under ENvelopes for Nonlinear Estimation) powered by IPOPT. details on solvers\nPareto optimization using:\n\npymmo is for multi-objective optimization. usage in NSGA2\npyomo is a Python-based, open-source optimization modeling language with a diverse set of optimization capabilities.\njMetalPy and introduction\nNSGA3\npartical group and intro in python\n\nCode for NIPS 2018: Multi-Task Learning as Multi-Objective Optimization, an exact algorithm for multi-objective optimization of deep networks with negligible computational overhead.\n\nmachine learning & neural networks\nflux.jl is machine/deep learning in julia, with GPU support. model zoo (examples) and doc. DiffEqFlux.jl can add differential equation layers to neural networks, details here\nMLJ.jl: non-DNN machine learning framework\nfacebook prophet\npymc based prophet\nnumenta nupic sparse encoding\npyro forcasting and time series\nuber orbit (A Python package for Bayesian forecasting with object-oriented design and probabilistic models under the hood) and doc\n\n\nreinforcement learning\nsample code and intro for adaptive dynamic programming(ADP)\nmicrosoft machine teaching is like automl for reinforcement learning (autorl), based on bonsai (on [github[(https://github.com/BonsaiAI)) (doc) is a low-code platform for autonomous AI systems (bonsai BRAIN is close-sourced), doc before acquiantaince. mentioned “optimize HVAC (heating, ventilation, and air conditioning) with EnergyPlus and BCVTB (Building Controls Virtual Test Bed)”. specify enviorments, rewards and targets with Inkling (declarative)\nopenai baselines\nstable baselines3\nautorl-research by microsoft\nautonomous learning library for pytorch, building deep reinforcement learning agents\nbrain autorl by google\nrlang: a declarative language for expressing partial world knowledge to RL agents and decision process. doc\n\n\n\nNLP\nRETRO-pytorch without weights\nLangChain: combine LLMs with other sources of computation or knowledge.\nELIF LFQA retrieval based\nhaystack (+ LLM = ChatGPT?)\nchatgpt (which is currently way too busy?)\nPaLM-RLHF\nOpen-Assistant\nNTM (neural turing machine) (best?) for translation, question answering, planning and decision-making. tensorflow 1.14.0 includes it into tf.contrib which also has timeseries module.\n\n\nmodel predictive control\nMPC is mentioned along with PID (Proportional Integral Derivative) found in libraries like simple-pid, pypid and control.\ngradcem: Model-Predictive Control via Cross-Entropy and Gradient-Based Optimization\ndo-mpc (in python) is a comprehensive open-source toolbox for robust model predictive control (MPC) and moving horizon estimation (MHE).\nmpc-pytorch is a fast PyTorch library for solving the non-convex control problem\n\n\nmodeling & simulation\nfor interfaces i’d like jupyter. does julia/modelica/octave support jupyter?\nthermalcorr: (c++) A collection of thermohydraulic correlations for thermal systems and heat exchangers\nneural operator for PDE/ODE neural network approximation (speedup solving) and doc\nhydraulic: A python package to compute pressure, flows and temperatures in hydraulic circuits\nfluids: is open-source software for engineers and technicians working in the fields of chemical, mechanical, or civil engineering. It includes modules for piping, fittings, pumps, tanks, compressible flow, open-channel flow, atmospheric properties, solar properties, particle size distributions, two phase flow, friction factors, control valves, orifice plates and other flow meters, ejectors, relief valves, and more.\nCityLearn: reinforcement learning environment for controlling the storage of domestic hot water (DHW), chilled water (for sensible cooling and dehumidification) hot water (for sensible heating) and electricity, also including models of air-to-water heat pumps, electric heaters, solar photovoltaic arrays, and the pre-computed energy loads of the buildings, which include space cooling, dehumidification, appliances, DHW, and solar generation.\nOMF: The Open Modeling Framework for smart grid cost-benefit analysis.\nHELICS is a co-simulation framework, designed to bring together domain-specific modeling tools so they interact during run time. usage examples and doc\nPLEXOS by Energy Exemplar is the only solution available today that unifies market simulations across the electric, water, and gas industries.\nDistributed Energy Generation Model\nOpenHybridSim is the first-ever, open source tool for EMT and phasor domain hybrid simulation.\nopenmodelica-microgrid-gym: An OpenAI Gym Environment for Microgrids (and reinforcement learning)\nModelingToolkitStandardLibrary.jl: A standard library of components to model the world and beyond\nModelicaGym: Modelica models integration with Open AI Gym\nandes: Python toolbox / library for power system transient dynamics simulation with symbolic modeling and numerical analysis\nDPSim: Real-time power system simulator including powerflow, (dynamic) phasors and EMT. doc\ncalliope: A multi-scale energy systems modelling framework\nThermal Engineering Systems in Python (TESPy). This package provides a powerful simulation toolkit for thermal engineering plants such as power plants, district heating systems or heat pumps.\nEnergy-Hub-Market-Operation: Participation of an Energy Hub in Electricity and Heat Distribution Markets using MPEC (mathematic program with equilibrium constraints)\nOSeMOSYS in Pyomo (likely to be a large regional energy simulation)\nmicrogrid optimizer for system of hot water, thermal and electricity (CHP) optimization using MILP\nEMTSimulation (python) combined-heat-and-power-system-probabilistic-production-simulation: (in matlab) a fast algorithm for economic and adequacy evaluation of electricity-heating systems\nCHP_ORC: Combined heat and power orc cycle using geothermal heat source\nCCHP-MINLP: MINLP instances for short-term planning problem of combined heat and power (CHP) systems\nCombined-cooling-and-heat-Power-CCHP-Plant written in GAMS, with a report\nOpenFAST/kitefast for wind turbine simulation\nfmi (functional mock-up interface) is an open model exchange format that able to run on multiple languages, proposed by modelica. tools support this standard are usually for modeling and simulation, and are able to communicate with each other using this protocol.\nTRNSYS(Transient System Simulation Program, paid, not open source)最早是由美国威斯康星大学和Solar Energy 实验室开发的。容易与MATLAB、python、C++进行调用和编程。主要进行建筑负荷模拟相对于DEST来说较为复杂。可进行太阳能（光热、光电）、地源热泵、风电、光电、氢能、三联供、综合能源、全生命周期经济性系统模拟分析\nmultisim includes models like pipes, heat exchanger, thermal storage and controllers like PID, Bang–bang controller, Two sensor controller and Model predictive controller.\nIES analysis notebooks: Jupyter notebooks which analyse IES simulation results\nTools for Energy Model Optimization and Analysis (TEMOA) is an open source modeling framework for conducting energy system analysis. The energy system is described algebraically as a network of linked processes that convert a raw energy commodity (e.g., coal, oil, biomass, uranium) into an end-use demand (e.g., lighting, transport, water heating, conditioned air), doc is here\nDistributed Energy Generation Model: Code for “Natural Gas Combined Cycle Power Plants Have Lower Environmental Impact than Conventional Combined Heat and Power for Commercial Buildings, Environmental Science & Technology”\nflixOpt: vector based energy and material flow optimization framework in python\nWastewater_Energy_Optimization: Supplementary files for “Integrated Design and Optimization of Water-Energy Nexus: Combining Wastewater Treatment and Energy System”\nGAN_GA_ICML containing files to replicate experiments and results from “Using C-GANs to Boost High-dimensional Nonlinear Optimization for Sustainability Targets”\nIDEAS (Modelica library allowing simultaneous transient simulation of thermal and electrical systems at both building and feeder level.\nIESLAB for burst and leakage simulation/detection with SCADA data\nGrid2Op: a testbed platform to model sequential decision making in power systems (for Reinforcement Learning?), with lightsim2grid which implements a c++ backend targeting the Grid2Op (speedup simulation). doc\nEnergyCircuitTheory-EnergyFlowCalculation: 数值实验代码 for 《综合能源系统分析的统一能路理论(三)：稳态与动态潮流计算》\nThe Framework for Optimization of ResourCes and Economics (FORCE) is a collection of software tools developed under the Integrated Energy Systems (IES) program to enable analysis of technical and economic viability of myriad IES configurations. Each of these tools is openly available and free to use.\nHERON: Holistic Energy Resource Optimization Network (HERON, for Technoeconomic Assessments and Synthetic History Generation) is a modeling toolset and plugin for RAVEN to accelerate stochastic technoeconomic assessment of the economic viability of various grid-energy system configurations, especially with application to electrical grids and integrated energy systems (IES).\nTRANSFORM-Library: A Modelica based library for modeling thermal hydraulic energy systems and other multi-physics systems\nsmart-rl-mg: Reinforcement Learning + Microgrids for OpenDSS\nHYBRID (requires DYMOLA? just a Modelica runtime?) is a modeling toolset to assess the integration and economic viability of Integrated Energy Systems (IES) , including Modeling and Experimental Validation of Latent Heat Thermal Energy Storage System. Related to CENTAUR which has a GUI interface (very abstract), can be used for the design and simulation of hybrid solar PV-battery-diesel microgrids , similar to (only simulation, not optimization) HYBRID2 and HOMER (Hybrid Optimization Model for Multiple Energy Resources, with a data processing script found somewhere)\nin python-control (optional dependency of slycot for MIMO) there is an example of model predictive control for aircraft model\nEMSO is the acronym for Environment for Modeling, Simulation, and Optimization. can customize model using EMSO modeling language. it is about chemistry rather than CCHP according to its modeling library EML\nOpenModelica is an open-source Modelica-based1 modeling and simulation environment intended for industrial and academic usage.\nXcos by SciLab is a graphical editor to design hybrid dynamical systems models. Models (in modelica) can be designed, loaded, saved, compiled and simulated. All Xcos standard blocks grouped by categories (signal processing, electrical, hydraulics, derivative, integral, etc.).\nJModelica is an extensible Modelica-based open-source platform for optimization, simulation, and analysis of complex dynamic systems. The main objective of the project is to create an industrially viable open-source platform for simulation and optimization of Modelica models.\nScilab (by Dassault Systems) is a scientific software package for numerical computations providing a powerful open computing environment for engineering and scientific applications. Scilab is an open source software and includes hundreds of mathematical functions with the possibility to add interactively programs from various languages (C, C++, Fortran…).\nScicos is a graphical dynamical system modeler and simulator developed in the Metalau project at INRIA, Paris-Rocquencourt center. With Scicos, user can create block diagrams to model and simulate the dynamics of hybrid dynamical systems and compile models into executable code.\nSpyder is a free open-source Python development environment providing MATLAB-like features in a simple and light-weighted software.\nStaticDESim: Simulation and optimisation of integrated energy system in steady state written in MATLAB, with models like Micro Gas Turbine (MGT), Aqueous Lithium-Bromine Single-Effect Absorption Chiller (AC_ALB), R123 Organic Recycle Cycle (ORC_R123), Heat Pump (HP) and R134a Vapour Compression Chiller (VCC_R134a)\nOpenHydraulics: A free Modelica package providing components describing 1-dimensional fluid flow in hydraulic circuits.\npyDMPC: A Python tool for distributed model-based predictive control of energy suppy chains\nAi4EMetaPSE by Ai4Energy: 采用基于方程的面向对象建模，基于微分代数方程（DAE），对能源系统组件进行建模，用以对能源系统进行稳态、动态仿真。能够处理连续时间及离散事件问题。\nAi4ELab is a Virtual Simulation Lab of Ai4Energy deployed with docker. can use with ModelingToolkit.jl. doc\nsimupy: a ramework for modeling and simulating dynamical systems\nModelica Standard Library includes models for mechanical (1D/3D), electrical (analog, digital, machines), magnetic, thermal, fluid, control systems and hierarchical state machines, similar to Modeling Toolkit Standard Library from SciML\ncchp-minlp models including heat pump, gas turbine, auxiliary boilers, written in GAMS and AMPL\npymgrid only provides models related to electricity.\noemof: Open Energy Modelling Framework - Python toolbox for energy system modelling and optimization, with thermal simulation support. doc\nrenpass: Renewable Energy Pathways Simulation System (written in R)\nMESSAGEix is a framework written in GAMS that can be used to develop and run many different models, each describing a different energy system.\nMinpower is an open source toolkit for students and researchers in power systems.\nGNU Scientific Library (better on linux!) capabilities:\nComplex Numbers\nRoots of Polynomials\nSpecial Functions\nVectors and Matrices\nPermutations\nSorting\nBLAS Support\nLinear Algebra\nEigensystems\nFast Fourier Transforms\nQuadrature\nRandom Numbers\nQuasi-Random Sequences\nRandom Distributions\nStatistics\nHistograms\nN-Tuples\nMonte Carlo Integration\nSimulated Annealing\nDifferential Equations\nInterpolation\nNumerical Differentiation\nChebyshev Approximation\nSeries Acceleration\nDiscrete Hankel Transforms\nRoot-Finding\nMinimization\nLeast-Squares Fitting\nPhysical Constants\nIEEE Floating-Point\nDiscrete Wavelet Transforms\nBasis splines\nRunning Statistics\nSparse Matrices and Linear Algebra\n\nAMPL community edition must connect to internet for license validation. trial commercial solvers for 30 days.\nCMPL by coin-or is highly optimized for multiprocessing. can bridge to python via pyCMPL3.\nMiniZinc: open-source constraint modeling language.\nPandaThermal: District heating and cooling network design and simulation tool, largely inspired by PandaPower\nSciML is Scientific Computing + Machine Learning Toolbox. It has the best performant DifferentialEquations.jl (can run on CUDA with ease, connect to neural networks) and NeuralPDE.jl for Physics-Informed Neural Networks (PINN) and Deep BSDE Solvers of Differential Equations for Scientific Machine Learning (SciML) accelerated simulation, easily bridging to Python. In its tutorial we can learn differential equation modeling/simulation.\nPowerModelDistribution.jl is an extension package of PowerModels.jl for Steady-State Power Distribution Network Optimization.\nPowerSimulations.jl is a Julia package for power system modeling and simulation of Power Systems operations.\nTIMES model: The Integrated MARKAL-EFOM System, written in GAMS (General Algebraic Modelling System, a modeling language, paid, similar to Dyna (a declarative modeling language like prolog, in dyna2gams it can refine parameters on observation) with lots of solvers), able to model CHS systems and predict financial costs said in its documendation, is a technology rich, bottom-up model generator, which uses linear-programming to produce a least-cost energy system, optimized according to a number of user constraints, over medium to long-term time horizons.\n\njulia relates quite a bit to power and energy simulations. is it performance related?\ntype ] in julia’s REPL to get Pkg interface.\n\nModelica is a language for modeling of cyber-physical systems, supporting acausal connection of components governed by mathematical equations to facilitate modeling from first principles, used in CATIA Systems, Dymola, JModelica.org, LMS AMESim, MapleSim, Modelon Impact, MWorks, OpenModelica (for python you need this: PySimulator), SimulationX, and Wolfram SystemModeler (and more tools.\nOpenIPSL is a library of power system component models written in the Modelica language that can be used for power system dynamic analysis, such as phasor time-domain simulations.\nSTEPS & stepspy: Simulation Toolkit for Electrical Power Systems. doc\npandapower: (lacks storage unit models) Convenient Power System Modelling and Analysis based on PYPOWER and pandas. official site\nin pandapower’s paper there are lots of open source tools for electric power systems optimization mentioned:\nMATPOWER (with optional solvers, must be obtained separately) is a widely used power system analysis tool for matlab and octave that solves power flow and optimal power flow problems and also includes an optimal scheduling tool for market simulations.\nThere are ports of the original MATLAB based code to other languages, most notably Pythons PYPOWER pypower-dynamics extends PYPOWER for dynamic analysis of electric power systems.\nGridCal (abbriviation for grid calculator) includes power flow, time-series and short circuit calculation methods and comes with a comprehensive graphical user interface.\nThe simulation and optimization library PyPSA (Python for power system analysis) is aimed at time-series simulation of security-constrained linear optimal power flow and investment optimization.\nPowerGAMA ( Python-based lightweight simulation tool for high level analyses of renewable energy integration in large power systems) and psst (power system simulation toolbox) are also aimed at market optimization in electric networks.\nGridLAB-D is an advanced tool for static simulations using agent based simulation models, based on C/C++ with integration of SCADA controls, metering and market models.\n\nOpenDSS is a electrical power system simulation tool primarily for utility power distribution systems, written in a Delphi.\nMATPower: free, open-source tools for electric power system simulation and optimization\nenergyplus (open source, based on DOE2, a building energy analysis program that can predict the energy use and cost) is a whole building energy simulation program that engineers, architects, and researchers use to model both energy consumption—for heating, cooling, ventilation, lighting and plug and process loads—and water use in buildings.\nbcvtb is a software environment that allows users to couple different simulation programs for co-simulation, and to couple simulation programs with actual hardware. For example, the BCVTB allows to simulate a building in EnergyPlus and the HVAC and control system in Modelica, while exchanging data between the software as they simulate.\nwolfram mathematica and System Modeler\nmaple and MapleSim\nmatlab (can be cuda accelerated (jacket?)) and simulink\ngnu octave (used by cloudpss?)\nsagemath\nroot\n\ncomputational fluid dynamics (really?)\nopenFOAM (free CFD (computational fluid dynamics) software) and documentation\nCFD in github\nCFD machine learning in github\nawesome CFD machine learning: a curated list of machine learning papers, codes, libraries, and databases applied to fluid mechanics.\n\n\nfinite element analysis\nFEA (finite element analysis) open source software list"
  },
  {
    "objectID": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#cloudpss",
    "href": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#cloudpss",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "cloudpss",
    "text": "cloudpss\nthis thing is developed by tsinghua-eiri\nmultiple papers related to cloudpss were found on semanticscholar. maybe we just want the ieslab part?\nin its paper the computation graph is acyclic.\ncloudpss python sdk是基于CloudPSS-API封装的模型及软件开发套件。用户可通过编写Python、Matlab等脚本构建自定义模型，或是调用CloudPSS平台中的模型修改、仿真计算功能，实现诸如自动修改模型、批量仿真计算、自动化生成报告等复杂且繁琐的功能。用户也可在其自己的应用程序中调用CloudPSS仿真引擎，实现仿真驱动的高级分析应用。\nmain structure:\n\nSimStudio: 轻松组织和管理能源电力系统数字孪生仿真模型 in SimStudio it has “octave” keyword. does that mean it is using GNU octave? yes! but octave does not have Simulink-like functionalities. see octave packages for more. use Xcos instead? in order to read code in modules like https://cloudpss.net/model/CloudPSS/HeatPump(右键点击元件，选择打开模块) you have to obtain sufficient permission.\n\nwill raise error if we wire electricity to water pipelines. it is not so easy to wire these things. better do it with port routing.\ncomponents list:\n\n\n\n\n\nClassification\n\n\nComponents\n\n\n\n\n\n\nMeasurements\n\n\nOscilloscope Group, Output channel\n\n\n\n\nElectrical-Basic Passive Components\n\n\nGround, Resistor, Inductor, Capacitor, Single-phase Fault Resistor, Three-phase Fault Resistor, Single-phase Transformer\n\n\n\n\nElectrical-Basic Source Components\n\n\nDC Current Source, DC Voltage Source, Single-phase AC Voltage Source, Controlled Current Source, Controlled Voltage Source, Controlled AC Voltage Source (VF), Controlled AC Voltage Source (VP)\n\n\n\n\nElectrical-Power Electronic Switches\n\n\nDiode, Thyristor, IGBT\n\n\n\n\nElectrical-Three-phase Components\n\n\nShunt Capacitor/Reactor, Fixed Load, Line Cluster, Three-phase Transmission Line, Three-phase AC Bus, Three-phase AC Voltage Source, Three-phase Two-winding Transformer, Three-phase Three-winding Transformer, Synchronous Generator\n\n\n\n\nElectrical-Fast Power Electronic Modules\n\n\nHalf Bridge Submodule, Six-pulse Thyristor Bridge\n\n\n\n\nElectrical-Renewable Energy Components\n\n\nPhotovoltaic Source, Lead-acid Battery\n\n\n\n\nMeasure Components\n\n\nBranch Voltage Meter, Voltage Meter, Current Meter, RMS Meter, Three-phase Power Meter, Phase Locked Loop, FFT\n\n\n\n\nControl-Basic Components\n\n\nM script, Constant, Time, Simulation Time Step, Non Connection (NC), Loop Break Node, Channel Merge, Channel DeMerge\n\n\n\n\nControl-Basic Math Functions\n\n\nAdder/Subtractor, Multiplier, Divider, Absolute Value, Sign Function, Round Function, Trigonometric Function, Power Function, Exponential Function, Logarithm Function, Maximum/Minimum Function, Maximum/Minimum in One Cycle\n\n\n\n\nControl-Linear Transfer Functions\n\n\nGain, Integrator, Derivative, PI Controller, Zero-point, Real Pole, Differential Pole, Lead Lag Pole, Second Order Complex Pole, Nth Transfer Function\n\n\n\n\nControl-Nonlinear Functions\n\n\nHard Limiter, Delay, Angle Resolver, Piecewise Linear Function, Nonlinear Function\n\n\n\n\nControl-Analog Signal\n\n\nComparator, Hysteresis Comparator, Zero Detector, Sampler, Sample and Hold\n\n\n\n\nControl-Digital Signal\n\n\nLogic Gate, Binary Delay, Monostable MultiVibrator, Flip Flop, Selector, Edge Detector\n\n\n\n\nControl-Coordinate Transformation\n\n\nPark Transformation, Clark Transformation, dq-αβ Coordinates Transformation, Polar/Rectangular Coordinate Converter\n\n\n\n\nControl-Singal Generator\n\n\nTriangular Generator, Squar Generator, Sine Generator, Adjustable FPM Sine Generator, Single-impulse Generator, Impulse Generator, Step Generator, Ramp Generator, Surge Gennerator, Drop Generator, Random Number Generator\n\n\n\n\nControl-HVDC Control\n\n\nPhase Locked Oscillator, Nearest Level Modulation (NLM), SST Fire Pulse Generator\n\n\n\n\nControl-AC system Control\n\n\nST5B、Hydro Governor、 Hydro Turbine\n\n\n\n\nHeat-Basic Components\n\n\nPipeline, Heat Source, Bulding (Load), Connection Point, Relay Pump\n\n\n\n\n\n\nIESLab (Integrated Energy System): 综合能源系统规划设计云平台 a place where you can import weather, energy prices, device parameters and loads data, design the IES system by hand (how components connects), determine the best products to purchase based on different criterions and assess it by net profit, environmental effects and energy efficiency.\nFuncStudio: 助力能源电力系统数字孪生云边融合业务定制 install locally (windows only?) or download binary file of “header only” functions?\nAppStudio: 快捷构建能源电力系统数字孪生应用 low-code frontend design interface.\n\nthe platform uses code generator to make the simulation fast.\nsomething like siemens simcenter is also cloud based. collimator is self-labeled as better simulink alternative with ai and python code blocks inside. it also suggests model based development (and a hell lots of blogs) for a general guideline on simulation and optimized control systems.\nfound tsinghua’s cloudpss (linked to localhost?) from Allen-Sunboy, along with all rare urls exclusive to elites (social networks?)\ncloudpss is utilizing alibaba’s cloud computing. the simulation uses computing graph and cuda acceleration (diffcult to deploy?), suggested simulink and PSCAD (PyPSCAD does similar things, but far from complete) (with IncrediBuild-XGE for multi-core acceleration) for simulation. in the paper it describes itself as “power system simulator” and “electromagnetic transient simulator” (HVDC: high voltage direct current, highly efficient for transmitting large amounts of electricity over long distances)\n\n项目仿照cloudpss进行编写\n专注于复杂交直流电网、配电网、微电网、独立电力系统的精确电磁暂态建模及覆盖多时间尺度物理过程仿真\n本平台支持包括配电系统、供暖制冷系统、蒸汽供热系统及烟气余热回收系统在内的多能源系统耦合网络的建模仿真计算。与传统的综合能源系统仿真工具不同，平台集成了20余种常见的综合能源系统设备模型，允许用户灵活搭建任意能量梯级利用形式的综合能源系统，拓扑结构不受约束，同时支持并网系统、孤网系统的仿真计算，从而有效拓展了适用场景。"
  },
  {
    "objectID": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#系统架构",
    "href": "posts/978a7a70-019e-4656-84c7-16e909ba6d5b/index.html#系统架构",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "系统架构",
    "text": "系统架构\n系统具体设计参考文档。\n综合能源系统特指在规划、建设和运行等过程中，通过对能源的产生、传输与分配（能源网络）、转换、存储、消费等环节进行有机协调与优化后，形成的能源产供销一体化系统。\n本平台包含两大子系统，分别为设计规划系统和运行调度系统。\n涉及到数据，计算，仿真的模块：\n\n系统能量流拓扑\n\n基础数据\n\n环境信息库\n包含：地理位置、气象数据（风、光、温度）以及规范中的一些设计表格，与地理位置关联的相关设备。\n\n\n\n\n输入\n\n\n地理位置（地名或者坐标），气象数据（默认已选择的地理坐标），可以从文件导入或者历史数据库导入\n\n\n\n\n\n\n设备信息库\n包含：发电、制冷制热、储能设备、配电传输、供热传输五个分类。不低于25种设备。还包含市政资源（市政天然气、市政电网、市政蒸汽、市政热水）。\n需要考虑设备效率、设备寿命、网络损耗。包含建设费用等虚拟模型（电缆、管道、基建等）。\n\n\n\n\n输入\n\n\n输入相应设备相应属性值，或者从典型库导入相应设备信息（生产厂商 设备型号 额定功率 运行约束 经济性参数）\n\n\n\n\n\n\n负荷信息库\n包含：蒸汽负荷、采暖负荷、制冷负荷、电负荷\n输入形式：\n\n负荷指标 • 采暖、制冷、电负荷有其特殊场景，属性面板有额外参数： • 模型：粗略模型（每月平均值数据） 或者详细模型（每个小时）\n负荷参数：是否包含工作日和非工作日、具体时间段、建筑类型、面积\n负荷曲线：更直观的对负情况进行展示\n\n\n\n能源信息库\n包含：电、热、冷、气的价格信息\n输入形式：\n定价规则或者曲线描述\n电价格分为：\n\n常数电价\n分时电价\n阶梯电价\n分时阶梯\n\n热和冷的价格分为：\n\n面积\n热量\n\n气的价格随当地行情\n\n\n\n设计规划\n根据已经设定的能源类型、负荷需求、建设规模、资金来源进行方案优化，得到设备的容量配置及各种设备的设备成本、工程初始投资、运行费用及各种设备的出力情况，以及经济指标、环保指标，并输出相应报告\n\n\n仿真计算\n根据已经设定的基本数据进行仿真计算，并输出设备的出力曲线及相应的经济指标、环保指标的报告（除了不需要输出容量配置之外，其余的输出项与设计规划一样）\n\n\n\n能源汇总\n\n能源运行实时数据看板\n汇总当前各设备运行时的能源生产与消耗汇总，并以图表的形式展示\n\n\n\n运行调度\n\n方案列表\n对已经规划的方案进行展示\n\n\n运行日志\n对已经运行的方案进行日志记录\n\n\n\n系统结构拓扑\n\n基础数据\n\n环境数据\n设备数据\n负荷信息库\n能源信息库\n\n\n\n仿真模拟\n根据已经设计的运行方案进行带拓扑结构的仿真模拟\n\n\n调度优化\n一种算法策略，对具体的综合能源系统进行协调优化计算（可以结合实时数据），并实时输出优化结果，下发指令给控制系统。\n\n\n\n能源监测\n\n实时数据\n以图表的形式展示能源生产和消耗数据、告警数据\n\n\n历史数据\n选择历史某段时间，查询当时的能源消耗和生产数据\n\n\n能源设备监控\n实时显示所有设备的运行状态、生产消耗数据、告警信息\n\n\n告警中心\n显示今日所有告警的设备信息\n\n\n\n数据分析\n\n能效评估\n对电、气、冷、热进行能效评估展示\n\n\n能源明细\n展示产量明细和消耗明细\n\n\n排放明细\n展示排放明细数据"
  },
  {
    "objectID": "posts/b3b8af2d-68fb-4666-90e4-91a867a137b2/index.html",
    "href": "posts/b3b8af2d-68fb-4666-90e4-91a867a137b2/index.html",
    "title": "自媒体违禁词获取平台 在线更新违禁词语 censored word online query with latest update",
    "section": "",
    "text": "自媒体违禁词获取平台 在线更新违禁词语 censored word online query with latest update\n自媒体违禁词查询平台"
  },
  {
    "objectID": "posts/7f0da49a-114c-4559-94d5-264344634819/index.html",
    "href": "posts/7f0da49a-114c-4559-94d5-264344634819/index.html",
    "title": "视频分析处理 剧本生成",
    "section": "",
    "text": "视频分析处理 视频摘要 剧本生成\n自动抠像 最新 2022 较小的性能消耗： https://github.com/hkchengrex/XMem 我fork的项目：https://github.com/ProphetHJK/XMem 我fork后添加了一些小工具，包括绿幕生成，蒙版视频生成，中文教程等\nsimple video captioning: https://pythonawesome.com/a-simple-implementation-of-video-captioning/ https://github.com/232525/videocaptioning.pytorch?ref=pythonawesome.com https://github.com/xiadingZ/video-caption.pytorch\n3d cnn for video classification: https://github.com/kcct-fujimotolab/3DCNN\nend-to-end video image classification by facebook: https://github.com/facebookresearch/ClassyVision\nvideo understanding models and datasets: https://github.com/sujiongming/awesome-video-understanding\nvideo classification dataset: ​video_type_dict​ ​=​ {​‘360VR’​: ​‘VR’​, ​‘4k’​: ​‘4K’​, ​‘Technology’​: ​‘科技’​, ​‘Sport’​: ​‘运动’​, ​‘Timelapse’​: ​‘延时’​,                    ​‘Aerial’​: ​‘航拍’​, ​‘Animals’​: ​‘动物’​, ​‘Sea’​: ​‘大海’​, ​‘Beach’​: ​‘海滩’​, ​‘space’​: ​‘太空’​,                    ​‘stars’​: ​‘星空’​, ​‘City’​: ​‘城市’​, ​‘Business’​: ​‘商业’​, ​‘Underwater’​: ​‘水下摄影’​,                    ​‘Wedding’​: ​‘婚礼’​, ​‘Archival’​: ​‘档案’​, ​‘Backgrounds’​: ​‘背景’​, ​‘Alpha Channel’​: ​‘透明通道’​,                    ​‘Intro’​: ​‘开场’​, ​‘Celebration’​: ​‘庆典’​, ​‘Clouds’​: ​‘云彩’​, ​‘Corporate’​: ​‘企业’​,                    ​‘Explosion’​: ​‘爆炸’​, ​‘Film’​: ​‘电影镜头’​, ​‘Green Screen’​: ​‘绿幕’​, ​‘Military’​: ​‘军事’​,                    ​‘Nature’​: ​‘自然’​, ​‘News’​: ​‘新闻’​, ​‘R3d’​: ​‘R3d’​, ​‘Romantic’​: ​‘浪漫’​, ​‘Abstract’​: ​‘抽象’​} https://github.com/yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model\nrnn for human action recognization: https://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input\nvideo script introduction and generation: https://sharetxt.live/blog/how-to-generate-a-youtube-video-script-with-ai#:~:text=%20How%20to%20use%20Chibi.ai%20to%20create%20a,scan%20through%20your%20text%20and%20generate…%20More%20\nfight detection using pose estimation and rnn: https://github.com/imsoo/fight_detection\nvideo summarizer to summarized video based on video feature: https://github.com/Lalit-ai/Video-Summary-Generator\nawesome action recognition: https://github.com/jinwchoi/awesome-action-recognition\ntemporal model for video understanding: https://github.com/mit-han-lab/temporal-shift-module https://github.com/mit-han-lab/temporal-shift-module https://github.com/yjxiong/tsn-pytorch\ntime space attention for video understanding(timesformer): https://github.com/facebookresearch/TimeSformer\nvideo understanding by alibaba: https://github.com/alibaba-mmai-research/pytorch-video-understanding\nvideo object segmentation: https://github.com/yoxu515/aot-benchmark?ref=pythonawesome.com\nvideo scene segmentation: https://github.com/kakaobrain/bassl?ref=pythonawesome.com\nmmaction detect actions in video: https://pythonawesome.com/an-open-source-toolbox-for-video-understanding-based-on-pytorch/ https://github.com/open-mmlab/mmaction2\ndense video captioning: https://www.opensourceagenda.com/projects/dense-video-captioning-pytorch https://www.opensourceagenda.com/projects/dense-video-captioning-pytorch\nseq2seq video captioning: https://blog.csdn.net/u013010889/article/details/80087601\n2d cnn with LSTM video classification: https://blog.csdn.net/qq_43493208/article/details/104387182\nspp-net for image shape unification: https://github.com/peace195/sppnet https://github.com/yueruchen/sppnet-pytorch\nrunning pretrained pytorchvideo video classification model from zoo: https://pytorchvideo.org/docs/tutorial_torchhub_inference\npytorchvideo model zoo: https://pytorchvideo.readthedocs.io/en/latest/model_zoo.html\n(arxiv) end to end generative pretraining multimodal video captioning mv-gpt: https://arxiv.org/abs/2201.08264v1\nvideo captioning using encoder-decoder: https://github.com/Shreyz-max/Video-Captioning\nvideo captioning video2text keras implementation: https://github.com/alvinbhou/Video2Text\nvideo summarization: https://github.com/shruti-jadon/Video-Summarization-using-Keyframe-Extraction-and-Video-Skimming\npytorch_video video classification: https://pytorchvideo.org/docs/tutorial_classification\nvideo feature extractor: https://github.com/hobincar/pytorch-video-feature-extractor"
  },
  {
    "objectID": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#概述",
    "href": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#概述",
    "title": "识别视频语言",
    "section": "概述",
    "text": "概述\n视频里面的语言分为图片上面打出来的字幕以及人说的话\n涉及到的问题分别为： 图片文字的语言分类 以及音频语言分类"
  },
  {
    "objectID": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#音频识别",
    "href": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#音频识别",
    "title": "识别视频语言",
    "section": "音频识别",
    "text": "音频识别\nonline speech recognition pip install SpeechRecognition\noffline, need to provide language id: https://pypi.org/project/automatic-speech-recognition/\nuse paddlespeech if possible, for chinese and english"
  },
  {
    "objectID": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#图片语言识别",
    "href": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#图片语言识别",
    "title": "识别视频语言",
    "section": "图片语言识别",
    "text": "图片语言识别\nuse google cloud to detect language type in image: https://github.com/deduced/ml-ocr-lang-detection\nDetects and Recognizes text and font language in an image https://github.com/JAIJANYANI/Language-Detection-in-Image\n图片语言文字分类 可以用easyocr实现 加载多个模型 比如 中文加英文加日语 b站其他语言的可能也不怎么受欢迎 最多再加韩语\n可以从视频简介 标题 链接里面提取出句子 每个句子进行语言分类 确定要使用的OCR模型 也有可能出现描述语言和视频图片文字语言不一致的情况\nwolfram language提供了一个图片分类器 分类出来的结果可能很有意思 可以结合苹果的图片关注区域生成器来结合使用\nImageIdentify[pictureObj]\n这个方法还支持subcategory分类 支持多输出 具体看文档\nhttps://www.imageidentify.com/about/how-it-works\nwolfram支持cloud deploy 到wolfram cloud不过那样可能不行"
  },
  {
    "objectID": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#文本语言识别分类",
    "href": "posts/d9f3275d-50d0-47d5-b348-1f1aace64776/index.html#文本语言识别分类",
    "title": "识别视频语言",
    "section": "文本语言识别分类",
    "text": "文本语言识别分类\nlingua performs good in short text, can be used in java or kotlin\nsupporting detecting different languages: cld2 containing useful vectors containing text spans python binding\n&gt;&gt;&gt; import pycld2 as cld2\n&gt;&gt;&gt; text_content = \"\"\" A accès aux chiens et aux frontaux qui lui ont été il peut consulter et modifier ses collections et exporter Cet article concerne le pays européen aujourd’hui appelé République française. \nPour d’autres usages du nom France, Pour une aide rapide et effective, veuiller trouver votre aide dans le menu ci-dessus. \nWelcome, to this world of Data Scientist. Today is a lovely day.\"\"\"\n&gt;&gt;&gt; _, _, _, detected_language = cld2.detect(text_content,  returnVectors=True)\n&gt;&gt;&gt; print(detected_language)\n((0, 323, 'FRENCH', 'fr'), (323, 64, 'ENGLISH', 'en'))\noriginal cld3 is designed for chromium and it relies on chromium code to run official cld3 python bindings\nadditional Python language related library from geeksforgeeks: textblob is a natural language processing toolkit\nfrom textblob import TextBlob\ntext = \"это компьютерный портал для гиков. It was a beautiful day .\"\nlang = TextBlob(text)\nprint(lang.detect_language())\n# ru\nlangid performs good in short text\ntextcat (r package)\ngoogle language detection library in python: langdetect\njavascript: https://github.com/wooorm/franc\npython version of franc: pyfranc\nwlatlang.org provides whatlang-rs as rust package, also whatlang-py as python bindings"
  },
  {
    "objectID": "posts/c5e171c2-9143-4eea-8679-7f85e5368d23/index.html",
    "href": "posts/c5e171c2-9143-4eea-8679-7f85e5368d23/index.html",
    "title": "资本 政治 商业 统治 管理 原理",
    "section": "",
    "text": "资本 政治 商业 统治 管理 原理\n画大饼（永远兑现不了的承诺 只兑现一点点） 自相矛盾（给一个有争议的话题 或者让人群分化 对立） 撒谎（一切都按照别人的愿望回答 然而不去实现 不去操作 反向实现 反向操作 或者虚拟化 电子化 意识形态化）"
  },
  {
    "objectID": "posts/890bbfd9-43f0-4420-90dd-368e96b2c1ab/index.html",
    "href": "posts/890bbfd9-43f0-4420-90dd-368e96b2c1ab/index.html",
    "title": "蹭网WiFi天线 雷达扫描 五轴机械臂",
    "section": "",
    "text": "蹭网WiFi天线 雷达扫描 五轴机械臂\n利用淘宝铜片焊接的WiFi天线 安装在开源机械臂上 利用固定点抵达算法 扫描算法 自动探测WiFi源与方向的对应关系 机械手臂应当安装在比较高的支撑点上 周围不要挡着WiFi天线 有比较长的延长线 扫描算法不得超过线材的限制（旋转角度控制）必须得知初始态的绝对位置"
  },
  {
    "objectID": "posts/356f484f-fe30-4aab-9b5e-bc9902c6b45f/index.html",
    "href": "posts/356f484f-fe30-4aab-9b5e-bc9902c6b45f/index.html",
    "title": "适合夏天佩戴的耳机",
    "section": "",
    "text": "适合夏天佩戴的耳机\n夏天用音响最好，用什么耳机\n耳机不能夹头 不能夹耳朵 不能长时间佩戴后耳朵化脓\n开放式耳机适合夏天佩戴\n\ncanyon挂耳式耳机\n飞利浦 shp9500\n高斯 portapro (夹头发)\n\n看起来可能适合夏天佩戴的封闭式头戴\n\nairpods max (华强北版？)\n赛睿 寒冰raw"
  },
  {
    "objectID": "posts/a811577e-e4e2-4296-92d1-8c602ef68d6f/index.html",
    "href": "posts/a811577e-e4e2-4296-92d1-8c602ef68d6f/index.html",
    "title": "途家scraping api",
    "section": "",
    "text": "途家scraping api\n搜索api 先通过fetch的api获得不同的限制条件\n从0开始 最多58页 每页30个 相同条件最多爬1740个 可以倒序排序来翻倍 可合并其他排序来收集更多\n用地区做限制 加上价格限制 或者加更多限制 使得总数少于1740*2=3480 用启发式策略 如果实在超过了预设限制不管了直接开始爬 这种策略可能没法暂停继续爬取"
  },
  {
    "objectID": "posts/32219f38-dc6e-4219-8626-6f68d7f08772/index.html",
    "href": "posts/32219f38-dc6e-4219-8626-6f68d7f08772/index.html",
    "title": "cybergod related projects",
    "section": "",
    "text": "cybergod related projects\ngit clone https://github.com/ruvnet/q-star\ngit clone https://github.com/tairov/QStarLearning.mojo\ngit clone https://github.com/estill01/open_qstar\n\ngit clone https://github.com/openai/Video-Pre-Training\n\ngit clone https://github.com/abhiprojectz/SingularGPT\ngit clone https://github.com/ddupont808/GPT-4V-Act\ngit clone https://github.com/Charmve/gpt-eyes\n\ngit clone https://github.com/OthersideAI/self-operating-computer\ngit clone https://github.com/unconv/gpt4v-browsing\n\ngit clone https://github.com/THUDM/CogVLM\ngit clone https://github.com/mnotgod96/AppAgent"
  },
  {
    "objectID": "posts/9ae42506-7926-4134-a0fd-5548f64fb0a6/index.html",
    "href": "posts/9ae42506-7926-4134-a0fd-5548f64fb0a6/index.html",
    "title": "typing backtick “`” with my current splitable keyboard",
    "section": "",
    "text": "it used to work with meta+esc key, but it fails sometimes.\nthere’s a universal way: shift+alt+esc\ntype tlide “~”: shift+esc"
  },
  {
    "objectID": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html",
    "href": "posts/f8398512-6f0b-433a-ad9f-89f730d636f4/index.html",
    "title": "连续区间 离散区间 从离散数据中获得离散区间 交并补",
    "section": "",
    "text": "离散区间的获得可以用边界条件判定 即最近n个连续的概率大于多少 容忍值为多少 最近n个小于多少直接作为结束边界的条件 也可以用convolution Gaussian blur\n离散区间交并补可以转化为连续区间交并补 更简单省事\n如果要做下面的运算 建议用第三方库 比如wolfram swi-prolog的clpr sympy\n连续区间交并补 先排序 设置首末端的操作 然后进行相应区间选取 进行下一步操作直到结束 输出总的结果"
  },
  {
    "objectID": "posts/3b1f1642-1532-4716-9f64-8573e566e14f/index.html",
    "href": "posts/3b1f1642-1532-4716-9f64-8573e566e14f/index.html",
    "title": "语音转文字 stt speech to text",
    "section": "",
    "text": "# 语音转文字 asr stt speech to text ## online 字说APP的api 逆向搜狗输入法 绕过签名验证 搜狗输入法apk的api 微软stt https://github.com/cuberwr/bilibiliSTT 多家免费stt https://github.com/1c7/Translate-Subtitle-File ## offline pyannote segment audio according to different speakers, detect voice activity speechbrain very advanced speech related ai library, with almost everything related to speech vosk paddlespeech\n\n\n\n\npaper of Google USM (universal speech model) supporting 1000 languages\n\n\n\nwhisper.cpp perform fast voice to text operation using cpu rather than gpu whisperx improve time accuracy with forced alignment whisper gui buzz whisper by openai, with multilingual and translation avaliable, can detect under background music and noise, with slience,"
  },
  {
    "objectID": "posts/ad067139-0361-422f-bd71-7c6aedcfc933/index.html",
    "href": "posts/ad067139-0361-422f-bd71-7c6aedcfc933/index.html",
    "title": "股票数据源 tick级别数据源 逐笔交易",
    "section": "",
    "text": "和股票有关的程序必须运行在服务器上面 要有ecc 网速要快"
  },
  {
    "objectID": "posts/bb35f592-24c7-44cb-b45f-7bb51d5fa343/index.html",
    "href": "posts/bb35f592-24c7-44cb-b45f-7bb51d5fa343/index.html",
    "title": "标题生成",
    "section": "",
    "text": "标题生成 封面生成\ncomparing different image caption models in which you have a bunch of models ready to use ## template extraction, neural template generation 封面来源： 利用标题进行图片搜索 其实只能站内搜索 因为站外没有这种图片与文字的对应关系 截取视频截图 b站原图 histogram match 20% 去掉文字 镜像反转 加入随机噪声 旋转1度 利用封面进行图片反向搜索 效果其实不好 并没有想要的照片 只能找到原图 有可能起到去水印的效果 但是有限 ### reverse image search engine reverse image search engine meta image search engine telegram reverse image search bot __________________________________ neural template gen is a natural language generator based on templates from harvard nlp, can be used for title generation ## 根据标签生成广告 同样可以根据标签生成视频标题（推荐） 在千言数据集上训练过 https://huggingface.co/cocoshe/gpt2-chinese-gen-ads-by-keywords?text=My+name+is+Clara+and+I+am title generator(from description): https://github.com/harveyaot/DianJing/blob/master/scripts/title_generation_lm.py https://blog.csdn.net/stay_foolish12/article/details/111661358 cover generation rectangle packing allow overlapping when solution is not found, decrease the size of rectangles. youtube title generator using AI: https://github.com/gdemos01/YoutubeVideoIdeasGeneratorAI ai thumbnail generator using pyscenedetect: https://github.com/yoonhero/ai-thumbnail-generator image captioning: https://github.com/ruotianluo/ImageCaptioning.pytorch youzan clip product title generation: https://huggingface.co/youzanai/clip-product-title-chinese paper title generator without description: https://github.com/csinva/gpt2-paper-title-generator image captioning using cnn and rnn: https://github.com/SCK22/image_and_video image captioning can also be used for video captioning. but that will suffice the accuracy. keras.io image captioning https://keras.io/examples/vision/image_captioning/ generate image captions using CLIP and GPT(on medium, click continue reading) https://towardsai.net/p/l/image-captioning-with-clip-and-gpt gpt3demo.com has provided a lot of interesting tasks that gpt3 can do. including image captioning. may find video captioning, video classification. gpt3demo.com provided image captioning libs: https://gpt3demo.com/category/image-captioning clipclap gpt-3 x image captions visualgpt: generate image captions https://github.com/Vision-CAIR/VisualGPT generate stories from pictures, using image transformers and gpt-2, just intro no code https://www.dataversity.net/image-captioning-generating-stories-from-unstructured-data-using-applied-nlg/"
  },
  {
    "objectID": "posts/5732e839-ee46-438a-860b-2a48b8f0aad6/index.html",
    "href": "posts/5732e839-ee46-438a-860b-2a48b8f0aad6/index.html",
    "title": "夏天制冷装置",
    "section": "",
    "text": "站着操作电脑 需要脚踏板式的跑步机\n\n循环水床垫\n循环水马甲\n带风扇的坐垫和靠背\n地板瓷砖\n加湿器风扇\n水空调 自动加水 工业\n除湿机 自动排水\n高锰酸钾\n软加硬空调出风挡板 强力胶带 防水\n移动双风道空调"
  },
  {
    "objectID": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html",
    "href": "posts/5693eb80-e80b-4444-97cc-21b52bc125c9/index.html",
    "title": "临时存储文件 temp fiiles host api",
    "section": "",
    "text": "临时存储文件 temp files host api\n用于给粉丝发放福利 充值之后发涩图 sharex a screen capture, file sharing, productivity tool ## tools pyupload catmoe recommend tools uguu tools ## 支持api存储 anonyfiles api need login list of pomf based temp file hosts uguu api catbox.moe api referred as sharex format tmpfiles api transfer.sh gofile.io nopaste.net with curl and netcat endpoint ## 不支持api 需要探索 privfile with download limit helix tempd.link"
  },
  {
    "objectID": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html",
    "href": "posts/062d0daa-79a1-4d08-9940-1716178b767c/index.html",
    "title": "useful java patterns",
    "section": "",
    "text": "java stream guide\nlearn java and kotlin the same time?\nbeanshell syntax highlight seems to be rare. beanshell workspace has the highlight.\nuse v2.1.1 and above for varargs support.\nthere are eclipse and jetbrains plugin support for beanshell."
  },
  {
    "objectID": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html",
    "href": "posts/4bafb1e7-a9ec-4fe8-afd2-5be076703113/index.html",
    "title": "teach puppies to speak english (video script)",
    "section": "",
    "text": "you create a stylish intro for this script? outro? joke? all with chatgpt.\nrefer to “how to use ai to generate video, distribute them and advertise” for batch video generation"
  },
  {
    "objectID": "posts/1d8bbb71-e114-4fa4-8883-22ba3886632b/index.html",
    "href": "posts/1d8bbb71-e114-4fa4-8883-22ba3886632b/index.html",
    "title": "scrape podcasts, filter keywords, convert voices by gender and pitch",
    "section": "",
    "text": "some live streaming may come into the same category of podcasts\nfilter out the name of the podcast volume, name of calling each others in the podcast\nsort by review and feedback\nenhance audio and skip slience, just like what apple voice memo app does\nsplit voice from music, be extremely cautious to music podcasts, don’t know what to do with them unless with hands on experience"
  },
  {
    "objectID": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html",
    "href": "posts/832dec42-6ecb-473f-981c-123cc7a13ea8/index.html",
    "title": "recreating cloudpss",
    "section": "",
    "text": "chats with our dearly chatgpt alternatives:"
  },
  {
    "objectID": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html",
    "href": "posts/ca3e1b76-cbfa-4656-b026-6e684d808de4/index.html",
    "title": "pyro and pymc3 basics",
    "section": "",
    "text": "using pyro for mnist classification and tutorial (benefits: knowing if it doesn’t know what’s in front)"
  },
  {
    "objectID": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html",
    "href": "posts/d1b3f9fd-7290-4688-954b-aabcfc8c155a/index.html",
    "title": "paddlepaddle applications",
    "section": "",
    "text": "## tips you can find solutions from kaggle notebooks or aistudio notebooks. you may consider to query them conveniently in one api. ## repo location (all source code can be found there) archive zip git repo ## 🎉全新发布 ## 3月31日晚8:30，飞桨产业实践范例直播课程继续开讲！！！ 国内众多行业都在基于人工智能技术推进行业变革与创新，积极探寻有效、有价值的应用场景进行商业化落地。百度飞桨结合实际经验，选取了几个经典的场景，提供了从数据准备、模型训练优化，到模型部署的全流程可复用方案，降低产业落地门槛,让大家在真实数据环境下深入地了解这些案例，获取产业实现方案。 3月31日晚8:30，飞桨官方将推出 火灾烟雾检测 产业实践范例直播： * 火灾烟雾检测 此外，还有交通、能源、金融、通信、互联网、零售及教育等等各个行业的精彩范例，大家拭目以待～ 欢迎报名直播课加入交流群，如需更多技术交流与合作可扫描下面二维码：\n\n\n\n\n往期案例直播回放： | 案例 | 直播回放 | | ———————————————————— | ———————————————————— | | 花样滑冰 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2251581 | | 多模态视频打标签 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2251583 | | 视频精彩时刻剪辑 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2257667 | | 电瓶车进电梯检测 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2273969 | | 异常行为识别 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2273989 | | 多类别车辆跟踪 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2274692 | | 多类别电表读数识别落地方案 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2309177 | | 多类别通信塔识别 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2377623 | | 基于车载影像的驾驶环境感知 | https://aistudio.baidu.com/aistudio/education/lessonvideo/2376819 | # 一、项目简介 本项目是飞桨官方出品的一站式深度学习在线百科，飞桨致力于让深度学习技术的创新与应用更简单，更多飞桨内容欢迎访问飞桨官网。本项目内容涵盖： 📒课程类：零基础实践深度学习、产业实践深度学习、特色课程、飞桨套件课程汇总资料 📒书籍类：《动手学深度学习》paddle版 📒宝典类：深度学习百问、面试宝典 📒案例类：飞桨产业实践范例库（包含智慧城市：火灾烟雾检测、 安全帽检测 ；智能制造：钢材缺陷检测 、 机械手抓取；互联网：财报识别与关键字段抽取 等。 从理论到实践，从科研到产业应用，各类学习材料一应俱全，旨在帮助开发者高效地学习和掌握深度学习知识，快速成为AI跨界人才。"
  },
  {
    "objectID": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html",
    "href": "posts/013d8cdb-d2c0-4d00-982b-593c52721c61/index.html",
    "title": "mini server, portable server, itx, Mac studio",
    "section": "",
    "text": "says that the cost of building some mini-itx with enormous ram costs a lot (more than te mac studio), and with a lot of headaches with custom designing, cnc and stl. worth it?\nalso the power consumption will be higher than mac studio.\nassemble the machine with proper thermo, wires and some open space, then enclose the thing with design.\nthe weight:\nmac studio (m1 ultra) for 3.6kg\nmini-itx machine: 6.3 kg - 10 kg (won’t lose weight)"
  },
  {
    "objectID": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html",
    "href": "posts/1161d1ab-ffae-4fd7-b835-0ba7eec79b4e/index.html",
    "title": "make-a-video and its related text to video projects",
    "section": "",
    "text": "saying “video2video” is much simpler than “text2video”, I also want to add basic editing and semantic alignment is also simpler than this."
  },
  {
    "objectID": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html",
    "href": "posts/62cd69ba-827f-4252-a15e-01fcc93a3fe7/index.html",
    "title": "let chatgpt describe how to build itself",
    "section": "",
    "text": "Autonomous artificial intelligence, autonomous learning, machine teaching, AGI"
  },
  {
    "objectID": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html",
    "href": "posts/6d61d8e4-a3d2-4611-818d-d155b9bb294d/index.html",
    "title": "leaderboards, paperswithcode.com",
    "section": "",
    "text": "provide tasks and give the best model for given task\ni’m afraid paperswithcode.com takes huge amount of time for one to categorize and classify. better get basic task categories out before you need/search it."
  },
  {
    "objectID": "posts/63eeaf5e-73d1-4bed-b5a6-320ac4a831a0/index.html",
    "href": "posts/63eeaf5e-73d1-4bed-b5a6-320ac4a831a0/index.html",
    "title": "disco diffusion and ai art",
    "section": "",
    "text": "tune-a-video first recognize video content, then tweak it to fit the need\ntextdiffuser\n\nComfyUI: A powerful and modular stable diffusion GUI.\n\ncivitai is a place for sharing stable diffusion models like anything v5 and surreality and ai arts.\n\nnow you can use controlnet to enhance the generation, give the figure skeleton. huggingface introduction\nkarlo: dalle2 replicate, karlo huggingface space, text to image (can be used for semantic search)\ndalle2-laion\nDiT diffusion with transformer\ncustom diffusion rlhf?\nscribble-diffusion turn sketch into drawings\nstable diffusion on macos\nvideo generation ebsynth\n字体普遍画的很拉 需要用专门的ocr强化训练字体\nfontdiffusion?\nfont-diffusion\nstable diffusion font generating\nfontdesign gan\nhandwrite\ndeep fonts\ndiffusionbee stable diffusion for macos m1\nQQ搜索 异次元的我 免费画画 AI合成 (seems this can only be opened within qq, currently)\nnovel-ai-bot\nhttps://huggingface.co/hakurei/waifu-diffusion，这个ai是可以本地部署的，电脑配置可以的朋友们试试\nnovelai 有泄露的模型\nimagen\ndreambooth\ndalle-mini, with space hosted on huggingface\n中文版DALL-E is not open sourced (yet). it provides api for evaluation\nimport numpy as np\nimport gradio as gr\nimport paddlehub as hub\nmodel = hub.Module(name='ernie_vilg')\nlanguage_translation_model = hub.Module(name='baidu_translate')\nlanguage_recognition_model = hub.Module(name='baidu_language_recognition')\nstyle_list = ['水彩','油画', '粉笔画', '卡通', '蜡笔画', '儿童画', '探索无限']\ntips = {\"en\": \"Tips: The input text will be translated into Chinese for generation\",\n\"jp\": \"ヒント: 入力テキストは生成のために中国語に翻訳されます\",\n\"kor\": \"힌트: 입력 텍스트는 생성을 위해 중국어로 번역됩니다\"}\ncount = 0\ndef translate_language(text_prompts):\nglobal count\ntry:\ncount += 1\ntips_text = None\nlanguage_code = language_recognition_model.recognize(text_prompts)\nif language_code != 'zh':\ntext_prompts = language_translation_model.translate(text_prompts, language_code, 'zh')\nexcept Exception as e:\nerror_text = str(e)\nreturn {status_text:error_text, language_tips_text:gr.update(visible=False)}\nif language_code in tips:\ntips_text = tips[language_code]\nelse:\ntips_text = tips['en']\nif language_code == 'zh':\nreturn {language_tips_text:gr.update(visible=False), translated_language:text_prompts, trigger_component: gr.update(value=count, visible=False)}\nelse:\nreturn {language_tips_text:gr.update(visible=True, value=tips_text), translated_language:text_prompts, trigger_component:  gr.update(value=count, visible=False)}\ndef inference(text_prompts, style_indx):\ntry:\nstyle = style_list[style_indx]\nresults = model.generate_image(\ntext_prompts=text_prompts, style=style, visualization=False)\nexcept Exception as e:\nerror_text = str(e)\nreturn {status_text:error_text, gallery:None}\nreturn {status_text:'Success', gallery:results[:6]}\ntitle=\"ERNIE-ViLG\"\ndescription=\"ERNIE-ViLG model, which supports text-to-image task.\"\ncss = \"\"\"\n.gradio-container {\nfont-family: 'IBM Plex Sans', sans-serif;\n}\n.gr-button {\ncolor: white;\nborder-color: black;\nbackground: black;\n}\ninput[type='range'] {\naccent-color: black;\n}\n.dark input[type='range'] {\naccent-color: #dfdfdf;\n}\n.container {\nmax-width: 730px;\nmargin: auto;\npadding-top: 1.5rem;\n}\n#gallery {\nmin-height: 22rem;\nmargin-bottom: 15px;\nmargin-left: auto;\nmargin-right: auto;\nborder-bottom-right-radius: .5rem !important;\nborder-bottom-left-radius: .5rem !important;\n}\n#gallery&gt;div&gt;.h-full {\nmin-height: 20rem;\n}\n.details:hover {\ntext-decoration: underline;\n}\n.gr-button {\nwhite-space: nowrap;\n}\n.gr-button:focus {\nborder-color: rgb(147 197 253 / var(--tw-border-opacity));\noutline: none;\nbox-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);\n--tw-border-opacity: 1;\n--tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);\n--tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px var(--tw-ring-offset-width)) var(--tw-ring-color);\n--tw-ring-color: rgb(191 219 254 / var(--tw-ring-opacity));\n--tw-ring-opacity: .5;\n}\n.footer {\nmargin-bottom: 45px;\nmargin-top: 35px;\ntext-align: center;\nborder-bottom: 1px solid #e5e5e5;\n}\n.footer&gt;p {\nfont-size: .8rem;\ndisplay: inline-block;\npadding: 0 10px;\ntransform: translateY(10px);\nbackground: white;\n}\n.dark .footer {\nborder-color: #303030;\n}\n.dark .footer&gt;p {\nbackground: #0b0f19;\n}\n.prompt h4{\nmargin: 1.25em 0 .25em 0;\nfont-weight: bold;\nfont-size: 115%;\n}\n\"\"\"\nblock = gr.Blocks(css=css)\nexamples = [\n[\n'戴着眼镜的猫',\n'油画(Oil painting)'\n],\n[\n'A cat with glasses',\n'油画(Oil painting)'\n],\n[\n'眼鏡をかけた猫',\n'油画(Oil painting)'\n],\n[\n'안경을 쓴 고양이',\n'油画(Oil painting)'\n],\n[\n'日落时的城市天际线,史前遗迹风格',\n'油画(Oil painting)'\n],\n[\n'一只猫坐在椅子上，戴着一副墨镜, low poly 风格',\n'卡通(Cartoon)'\n],\n[\n'A cat sitting on a chair, wearing a pair of sunglasses, low poly style',\n'油画(Oil painting)'\n],\n[\n'猫が椅子に座ってサングラスをかけている、low polyスタイル',\n'油画(Oil painting)'\n],\n[\n'고양이 한 마리가 의자에 앉아 선글라스를 끼고 low poly 스타일을 하고 있다',\n'油画(Oil painting)'\n],\n[\n'一只猫坐在椅子上，戴着一副墨镜,秋天风格',\n'探索无限(Explore infinity)'\n],\n[\n'蒙娜丽莎，赛博朋克，宝丽来，33毫米,蒸汽波艺术',\n'探索无限(Explore infinity)'\n],\n[\n'一只猫坐在椅子上，戴着一副墨镜,海盗风格',\n'探索无限(Explore infinity)'\n],\n[\n'一条由闪电制成的令人敬畏的龙,概念艺术',\n'探索无限(Explore infinity)'\n],\n[\n'An awesome dragon made of lightning, conceptual art',\n'油画(Oil painting)'\n],\n[\n'稲妻で作られた畏敬の念を抱かせる竜、コンセプトアート',\n'油画(Oil painting)'\n],\n[\n'번개로 만든 경외스러운 용, 개념 예술',\n'油画(Oil painting)'\n],\n[\n'梵高猫头鹰,蒸汽波艺术',\n'探索无限(Explore infinity)'\n],\n[\n'萨尔瓦多·达利描绘古代文明的超现实主义梦幻油画,写实风格',\n'探索无限(Explore infinity)'\n],\n[\n'夕阳日落时，阳光落在云层上，海面波涛汹涌，风景，胶片感',\n'探索无限(Explore infinity)'\n],\n[\n'Sunset, the sun falls on the clouds, the sea is rough, the scenery is filmy',\n'油画(Oil painting)'\n],\n[\n'夕日が沈むと、雲の上に太陽の光が落ち、海面は波が荒く、風景、フィルム感',\n'油画(Oil painting)'\n],\n[\n'석양이 질 때 햇빛이 구름 위에 떨어지고, 해수면의 파도가 용솟음치며, 풍경, 필름감',\n'油画(Oil painting)'\n],\n]\nwith block:\ngr.HTML(\n\"\"\"\n&lt;div style=\"text-align: center; max-width: 650px; margin: 0 auto;\"&gt;\n&lt;div\nstyle=\"\ndisplay: inline-flex;\ngap: 0.8rem;\nfont-size: 1.75rem;\nmargin-bottom: 10px;\nmargin-left: 220px;\njustify-content: center;\n\"\n&gt;\n&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/187387422-f6c9ccab-7fda-416e-a24d-7d6084c46f67.jpg\" alt=\"Paddlehub\" width=\"40%\"&gt;&lt;/a&gt;\n&lt;/div&gt;\n&lt;div\nstyle=\"\ndisplay: inline-flex;\nalign-items: center;\ngap: 0.8rem;\nfont-size: 1.75rem;\nmargin-bottom: 10px;\njustify-content: center;\n\"&gt;\n&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;h1 style=\"font-weight: 900; margin-bottom: 7px;\"&gt;\nERNIE-ViLG Demo\n&lt;/h1&gt;&lt;/a&gt;\n&lt;/div&gt;\n&lt;p style=\"margin-bottom: 10px; font-size: 94%\"&gt;\nERNIE-ViLG is a state-of-the-art text-to-image model that generates\nimages from Chinese text.\n&lt;/p&gt;\n&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/188184795-98605a22-9af2-4106-827b-e58548f8892f.png\" alt=\"star Paddlehub\" width=\"100%\"&gt;&lt;/a&gt;\n&lt;/div&gt;\n\"\"\"\n)\nwith gr.Group():\nwith gr.Box():\nwith gr.Row().style(mobile_collapse=False, equal_height=True):\ntext = gr.Textbox(\nlabel=\"Prompt\",\nshow_label=False,\nmax_lines=1,\nplaceholder=\"Enter your prompt, multiple languages are supported now.\",\n).style(\nborder=(True, False, True, True),\nrounded=(True, False, False, True),\ncontainer=False,\n)\nbtn = gr.Button(\"Generate image\").style(\nmargin=False,\nrounded=(False, True, True, False),\n)\nlanguage_tips_text = gr.Textbox(label=\"language tips\", show_label=False, visible=False, max_lines=1)\nstyles = gr.Dropdown(label=\"风格(style)\", choices=['水彩(Watercolor)','油画(Oil painting)', '粉笔画(Chalk drawing)', '卡通(Cartoon)', '蜡笔画(Crayon drawing)', '儿童画(Children\\'s drawing)', '探索无限(Explore infinity)'], value='探索无限(Explore infinity)', type=\"index\")\ngallery = gr.Gallery(\nlabel=\"Generated images\", show_label=False, elem_id=\"gallery\"\n).style(grid=[2, 3], height=\"auto\")\nstatus_text = gr.Textbox(\nlabel=\"处理状态(Process status)\",\nshow_label=True,\nmax_lines=1,\ninteractive=False\n)\ntrigger_component = gr.Textbox(vaule=\"\", visible=False) # This component is used for triggering inference funtion.\ntranslated_language = gr.Textbox(vaule=\"\", visible=False)\nex = gr.Examples(examples=examples, fn=translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language], cache_examples=False)\nex.dataset.headers = [\"\"]\ntext.submit(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\nbtn.click(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\ntrigger_component.change(fn=inference, inputs=[translated_language, styles], outputs=[status_text, gallery])\ngr.HTML(\n\"\"\"\n&lt;div class=\"prompt\"&gt;\n&lt;p&gt;&lt;h4&gt;Prompt公式&lt;/h4&gt;\n&lt;span&gt; Prompt = [形容词] [主语] ，[细节设定]， [修饰语或者艺术家]。 &lt;/span&gt;\n关于各部分的构造方式和效果，可以参考&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe指南&lt;/a&gt;。\n更多的模型，请关注&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub 官方Repo &lt;/a&gt;， 如果你觉得不错，请star收藏吧。\n&lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\n同时，可以在 &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; 上使用免费的GPU体验更多案例。\n&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"prompt\"&gt;\n&lt;p&gt;&lt;h4&gt;Prompt format&lt;/h4&gt;\n&lt;span&gt; Prompt = [adjective] [object], [details], [styles or artists]. &lt;/span&gt;\nFor more details, please refer to &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe Guide&lt;/a&gt;.\nThere are more interesting models in PaddleHub, if you think it's great, welcome to star &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub&lt;/a&gt;.\n&lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\nBesides, you can use free GPU resourses in &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; to enjoy more cases, have fun.\n&lt;/p&gt;\n&lt;/div&gt;\n\"\"\"\n)\ngr.Markdown(\n\"\"\"\n在\"探索无限\"的风格模式下，画作的真实风格完全可以由你的prompt来决定。下面是一些参考案例:\nIn \"Explore infinity\" style mode, how the image looks like is totally up to your prompt. Below are some cases:\n### 复古未来主义风格\n| ![00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格.jpg) | ![00472_000_日落时的城市天际线,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_日落时的城市天际线,复古未来主义风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格              | 日落时的城市天际线,复古未来主义风格                          |\n### 粉彩朋克风格\n| ![00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格.jpg) | ![00029_001_日落时的城市天际线，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00029_001_日落时的城市天际线，粉彩朋克风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,粉彩朋克风格                  | 日落时的城市天际线,粉彩朋克风格                              |\n### 史前遗迹风格\n| ![00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格.jpg) | ![00443_005_日落时的城市天际线,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_日落时的城市天际线,史前遗迹风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格                  | 日落时的城市天际线,史前遗迹风格                              |\n### 波普艺术风格\n| ![00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格.jpg) | ![00434_002_日落时的城市天际线,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_002_日落时的城市天际线,波普艺术风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,波普艺术风格                  | 日落时的城市天际线,后世界末日风格                            |\n### 迷幻风格\n| ![00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格.jpg) | ![00451_001_日落时的城市天际线,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_001_日落时的城市天际线,迷幻药风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,迷幻风格                      | 日落时的城市天际线,迷幻风格                                  |\n### &lt;u&gt;[更多内容...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南)([Explore more...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南))&lt;/u&gt;\n\"\"\"\n)\ngr.HTML('''\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;Model by &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;PaddleHub&lt;/a&gt; and &lt;a href=\"https://wenxin.baidu.com\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;文心大模型&lt;/a&gt; - Gradio Demo by 🤗 Hugging Face\n&lt;/p&gt;\n&lt;/div&gt;\n''')\nblock.queue(concurrency_count=128).launch()\ntext to image minimal example\nhttps://github.com/jina-ai/discoart\ndalle-2\nstable diffusion as dalle2 alternative\nnvidia provided ai paint tool\ntext to image:\nhttps://github.com/lucidrains/imagen-pytorch"
  },
  {
    "objectID": "posts/63eeaf5e-73d1-4bed-b5a6-320ac4a831a0/index.html#civitai-is-a-place-for-sharing-stable-diffusion-models-like-anything-v5-and-surreality-and-ai-arts.",
    "href": "posts/63eeaf5e-73d1-4bed-b5a6-320ac4a831a0/index.html#civitai-is-a-place-for-sharing-stable-diffusion-models-like-anything-v5-and-surreality-and-ai-arts.",
    "title": "disco diffusion and ai art",
    "section": "civitai is a place for sharing stable diffusion models like anything v5 and surreality and ai arts.",
    "text": "civitai is a place for sharing stable diffusion models like anything v5 and surreality and ai arts.\nnow you can use controlnet to enhance the generation, give the figure skeleton. huggingface introduction karlo: dalle2 replicate, karlo huggingface space, text to image (can be used for semantic search) dalle2-laion DiT diffusion with transformer custom diffusion rlhf? scribble-diffusion turn sketch into drawings stable diffusion on macos video generation ebsynth 字体普遍画的很拉 需要用专门的ocr强化训练字体 fontdiffusion? font-diffusion stable diffusion font generating fontdesign gan handwrite deep fonts diffusionbee stable diffusion for macos m1 QQ搜索 异次元的我 免费画画 AI合成 (seems this can only be opened within qq, currently) novel-ai-bot https://huggingface.co/hakurei/waifu-diffusion，这个ai是可以本地部署的，电脑配置可以的朋友们试试 novelai 有泄露的模型 imagen dreambooth dalle-mini, with space hosted on huggingface 中文版DALL-E is not open sourced (yet). it provides api for evaluation\nimport numpy as np\nimport gradio as gr\nimport paddlehub as hub\nmodel = hub.Module(name='ernie_vilg')\nlanguage_translation_model = hub.Module(name='baidu_translate')\nlanguage_recognition_model = hub.Module(name='baidu_language_recognition')\nstyle_list = ['水彩','油画', '粉笔画', '卡通', '蜡笔画', '儿童画', '探索无限']\ntips = {\"en\": \"Tips: The input text will be translated into Chinese for generation\",\n\"jp\": \"ヒント: 入力テキストは生成のために中国語に翻訳されます\",\n\"kor\": \"힌트: 입력 텍스트는 생성을 위해 중국어로 번역됩니다\"}\ncount = 0\ndef translate_language(text_prompts):\nglobal count\ntry:\ncount += 1\ntips_text = None\nlanguage_code = language_recognition_model.recognize(text_prompts)\nif language_code != 'zh':\ntext_prompts = language_translation_model.translate(text_prompts, language_code, 'zh')\nexcept Exception as e:\nerror_text = str(e)\nreturn {status_text:error_text, language_tips_text:gr.update(visible=False)}\nif language_code in tips:\ntips_text = tips[language_code]\nelse:\ntips_text = tips['en']\nif language_code == 'zh':\nreturn {language_tips_text:gr.update(visible=False), translated_language:text_prompts, trigger_component: gr.update(value=count, visible=False)}\nelse:\nreturn {language_tips_text:gr.update(visible=True, value=tips_text), translated_language:text_prompts, trigger_component:  gr.update(value=count, visible=False)}\ndef inference(text_prompts, style_indx):\ntry:\nstyle = style_list[style_indx]\nresults = model.generate_image(\ntext_prompts=text_prompts, style=style, visualization=False)\nexcept Exception as e:\nerror_text = str(e)\nreturn {status_text:error_text, gallery:None}\nreturn {status_text:'Success', gallery:results[:6]}\ntitle=\"ERNIE-ViLG\"\ndescription=\"ERNIE-ViLG model, which supports text-to-image task.\"\ncss = \"\"\"\n.gradio-container {\nfont-family: 'IBM Plex Sans', sans-serif;\n}\n.gr-button {\ncolor: white;\nborder-color: black;\nbackground: black;\n}\ninput[type='range'] {\naccent-color: black;\n}\n.dark input[type='range'] {\naccent-color: #dfdfdf;\n}\n.container {\nmax-width: 730px;\nmargin: auto;\npadding-top: 1.5rem;\n}\n#gallery {\nmin-height: 22rem;\nmargin-bottom: 15px;\nmargin-left: auto;\nmargin-right: auto;\nborder-bottom-right-radius: .5rem !important;\nborder-bottom-left-radius: .5rem !important;\n}\n#gallery&gt;div&gt;.h-full {\nmin-height: 20rem;\n}\n.details:hover {\ntext-decoration: underline;\n}\n.gr-button {\nwhite-space: nowrap;\n}\n.gr-button:focus {\nborder-color: rgb(147 197 253 / var(--tw-border-opacity));\noutline: none;\nbox-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);\n--tw-border-opacity: 1;\n--tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);\n--tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px var(--tw-ring-offset-width)) var(--tw-ring-color);\n--tw-ring-color: rgb(191 219 254 / var(--tw-ring-opacity));\n--tw-ring-opacity: .5;\n}\n.footer {\nmargin-bottom: 45px;\nmargin-top: 35px;\ntext-align: center;\nborder-bottom: 1px solid #e5e5e5;\n}\n.footer&gt;p {\nfont-size: .8rem;\ndisplay: inline-block;\npadding: 0 10px;\ntransform: translateY(10px);\nbackground: white;\n}\n.dark .footer {\nborder-color: #303030;\n}\n.dark .footer&gt;p {\nbackground: #0b0f19;\n}\n.prompt h4{\nmargin: 1.25em 0 .25em 0;\nfont-weight: bold;\nfont-size: 115%;\n}\n\"\"\"\nblock = gr.Blocks(css=css)\nexamples = [\n[\n'戴着眼镜的猫',\n'油画(Oil painting)'\n],\n[\n'A cat with glasses',\n'油画(Oil painting)'\n],\n[\n'眼鏡をかけた猫',\n'油画(Oil painting)'\n],\n[\n'안경을 쓴 고양이',\n'油画(Oil painting)'\n],\n[\n'日落时的城市天际线,史前遗迹风格',\n'油画(Oil painting)'\n],\n[\n'一只猫坐在椅子上，戴着一副墨镜, low poly 风格',\n'卡通(Cartoon)'\n],\n[\n'A cat sitting on a chair, wearing a pair of sunglasses, low poly style',\n'油画(Oil painting)'\n],\n[\n'猫が椅子に座ってサングラスをかけている、low polyスタイル',\n'油画(Oil painting)'\n],\n[\n'고양이 한 마리가 의자에 앉아 선글라스를 끼고 low poly 스타일을 하고 있다',\n'油画(Oil painting)'\n],\n[\n'一只猫坐在椅子上，戴着一副墨镜,秋天风格',\n'探索无限(Explore infinity)'\n],\n[\n'蒙娜丽莎，赛博朋克，宝丽来，33毫米,蒸汽波艺术',\n'探索无限(Explore infinity)'\n],\n[\n'一只猫坐在椅子上，戴着一副墨镜,海盗风格',\n'探索无限(Explore infinity)'\n],\n[\n'一条由闪电制成的令人敬畏的龙,概念艺术',\n'探索无限(Explore infinity)'\n],\n[\n'An awesome dragon made of lightning, conceptual art',\n'油画(Oil painting)'\n],\n[\n'稲妻で作られた畏敬の念を抱かせる竜、コンセプトアート',\n'油画(Oil painting)'\n],\n[\n'번개로 만든 경외스러운 용, 개념 예술',\n'油画(Oil painting)'\n],\n[\n'梵高猫头鹰,蒸汽波艺术',\n'探索无限(Explore infinity)'\n],\n[\n'萨尔瓦多·达利描绘古代文明的超现实主义梦幻油画,写实风格',\n'探索无限(Explore infinity)'\n],\n[\n'夕阳日落时，阳光落在云层上，海面波涛汹涌，风景，胶片感',\n'探索无限(Explore infinity)'\n],\n[\n'Sunset, the sun falls on the clouds, the sea is rough, the scenery is filmy',\n'油画(Oil painting)'\n],\n[\n'夕日が沈むと、雲の上に太陽の光が落ち、海面は波が荒く、風景、フィルム感',\n'油画(Oil painting)'\n],\n[\n'석양이 질 때 햇빛이 구름 위에 떨어지고, 해수면의 파도가 용솟음치며, 풍경, 필름감',\n'油画(Oil painting)'\n],\n]\nwith block:\ngr.HTML(\n\"\"\"\n&lt;div style=\"text-align: center; max-width: 650px; margin: 0 auto;\"&gt;\n&lt;div\nstyle=\"\ndisplay: inline-flex;\ngap: 0.8rem;\nfont-size: 1.75rem;\nmargin-bottom: 10px;\nmargin-left: 220px;\njustify-content: center;\n\"\n&gt;\n&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/187387422-f6c9ccab-7fda-416e-a24d-7d6084c46f67.jpg\" alt=\"Paddlehub\" width=\"40%\"&gt;&lt;/a&gt;\n&lt;/div&gt;\n&lt;div\nstyle=\"\ndisplay: inline-flex;\nalign-items: center;\ngap: 0.8rem;\nfont-size: 1.75rem;\nmargin-bottom: 10px;\njustify-content: center;\n\"&gt;\n&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;h1 style=\"font-weight: 900; margin-bottom: 7px;\"&gt;\nERNIE-ViLG Demo\n&lt;/h1&gt;&lt;/a&gt;\n&lt;/div&gt;\n&lt;p style=\"margin-bottom: 10px; font-size: 94%\"&gt;\nERNIE-ViLG is a state-of-the-art text-to-image model that generates\nimages from Chinese text.\n&lt;/p&gt;\n&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;img src=\"https://user-images.githubusercontent.com/22424850/188184795-98605a22-9af2-4106-827b-e58548f8892f.png\" alt=\"star Paddlehub\" width=\"100%\"&gt;&lt;/a&gt;\n&lt;/div&gt;\n\"\"\"\n)\nwith gr.Group():\nwith gr.Box():\nwith gr.Row().style(mobile_collapse=False, equal_height=True):\ntext = gr.Textbox(\nlabel=\"Prompt\",\nshow_label=False,\nmax_lines=1,\nplaceholder=\"Enter your prompt, multiple languages are supported now.\",\n).style(\nborder=(True, False, True, True),\nrounded=(True, False, False, True),\ncontainer=False,\n)\nbtn = gr.Button(\"Generate image\").style(\nmargin=False,\nrounded=(False, True, True, False),\n)\nlanguage_tips_text = gr.Textbox(label=\"language tips\", show_label=False, visible=False, max_lines=1)\nstyles = gr.Dropdown(label=\"风格(style)\", choices=['水彩(Watercolor)','油画(Oil painting)', '粉笔画(Chalk drawing)', '卡通(Cartoon)', '蜡笔画(Crayon drawing)', '儿童画(Children\\'s drawing)', '探索无限(Explore infinity)'], value='探索无限(Explore infinity)', type=\"index\")\ngallery = gr.Gallery(\nlabel=\"Generated images\", show_label=False, elem_id=\"gallery\"\n).style(grid=[2, 3], height=\"auto\")\nstatus_text = gr.Textbox(\nlabel=\"处理状态(Process status)\",\nshow_label=True,\nmax_lines=1,\ninteractive=False\n)\ntrigger_component = gr.Textbox(vaule=\"\", visible=False) # This component is used for triggering inference funtion.\ntranslated_language = gr.Textbox(vaule=\"\", visible=False)\nex = gr.Examples(examples=examples, fn=translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language], cache_examples=False)\nex.dataset.headers = [\"\"]\ntext.submit(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\nbtn.click(translate_language, inputs=[text], outputs=[language_tips_text, status_text, trigger_component, translated_language])\ntrigger_component.change(fn=inference, inputs=[translated_language, styles], outputs=[status_text, gallery])\ngr.HTML(\n\"\"\"\n&lt;div class=\"prompt\"&gt;\n&lt;p&gt;&lt;h4&gt;Prompt公式&lt;/h4&gt;\n&lt;span&gt; Prompt = [形容词] [主语] ，[细节设定]， [修饰语或者艺术家]。 &lt;/span&gt;\n关于各部分的构造方式和效果，可以参考&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe指南&lt;/a&gt;。\n更多的模型，请关注&lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub 官方Repo &lt;/a&gt;， 如果你觉得不错，请star收藏吧。\n&lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\n同时，可以在 &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; 上使用免费的GPU体验更多案例。\n&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"prompt\"&gt;\n&lt;p&gt;&lt;h4&gt;Prompt format&lt;/h4&gt;\n&lt;span&gt; Prompt = [adjective] [object], [details], [styles or artists]. &lt;/span&gt;\nFor more details, please refer to &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;YouPromptMe Guide&lt;/a&gt;.\nThere are more interesting models in PaddleHub, if you think it's great, welcome to star &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt; PaddleHub&lt;/a&gt;.\n&lt;p&gt;&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"90\" height=\"20\"&gt;&lt;style&gt;a:hover #llink{fill:url(#b);stroke:#ccc}a:hover #rlink{fill:#4183c4}&lt;/style&gt;&lt;linearGradient id=\"a\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#fcfcfc\" stop-opacity=\"0\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;linearGradient id=\"b\" x2=\"0\" y2=\"100%\"&gt;&lt;stop offset=\"0\" stop-color=\"#ccc\" stop-opacity=\".1\"/&gt;&lt;stop offset=\"1\" stop-opacity=\".1\"/&gt;&lt;/linearGradient&gt;&lt;g stroke=\"#d5d5d5\"&gt;&lt;rect stroke=\"none\" fill=\"#fcfcfc\" x=\"0.5\" y=\"0.5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;rect x=\"60.5\" y=\"0.5\" width=\"29\" height=\"19\" rx=\"2\" fill=\"#fafafa\"/&gt;&lt;rect x=\"60\" y=\"7.5\" width=\"0.5\" height=\"5\" stroke=\"#fafafa\"/&gt;&lt;path d=\"M60.5 6.5 l-3 3v1 l3 3\" stroke=\"d5d5d5\" fill=\"#fafafa\"/&gt;&lt;/g&gt;&lt;image x=\"5\" y=\"3\" width=\"14\" height=\"14\" xlink:href=\"data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjMTgxNzE3IiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2l0SHViPC90aXRsZT48cGF0aCBkPSJNMTIgLjI5N2MtNi42MyAwLTEyIDUuMzczLTEyIDEyIDAgNS4zMDMgMy40MzggOS44IDguMjA1IDExLjM4NS42LjExMy44Mi0uMjU4LjgyLS41NzcgMC0uMjg1LS4wMS0xLjA0LS4wMTUtMi4wNC0zLjMzOC43MjQtNC4wNDItMS42MS00LjA0Mi0xLjYxQzQuNDIyIDE4LjA3IDMuNjMzIDE3LjcgMy42MzMgMTcuN2MtMS4wODctLjc0NC4wODQtLjcyOS4wODQtLjcyOSAxLjIwNS4wODQgMS44MzggMS4yMzYgMS44MzggMS4yMzYgMS4wNyAxLjgzNSAyLjgwOSAxLjMwNSAzLjQ5NS45OTguMTA4LS43NzYuNDE3LTEuMzA1Ljc2LTEuNjA1LTIuNjY1LS4zLTUuNDY2LTEuMzMyLTUuNDY2LTUuOTMgMC0xLjMxLjQ2NS0yLjM4IDEuMjM1LTMuMjItLjEzNS0uMzAzLS41NC0xLjUyMy4xMDUtMy4xNzYgMCAwIDEuMDA1LS4zMjIgMy4zIDEuMjMuOTYtLjI2NyAxLjk4LS4zOTkgMy0uNDA1IDEuMDIuMDA2IDIuMDQuMTM4IDMgLjQwNSAyLjI4LTEuNTUyIDMuMjg1LTEuMjMgMy4yODUtMS4yMy42NDUgMS42NTMuMjQgMi44NzMuMTIgMy4xNzYuNzY1Ljg0IDEuMjMgMS45MSAxLjIzIDMuMjIgMCA0LjYxLTIuODA1IDUuNjI1LTUuNDc1IDUuOTIuNDIuMzYuODEgMS4wOTYuODEgMi4yMiAwIDEuNjA2LS4wMTUgMi44OTYtLjAxNSAzLjI4NiAwIC4zMTUuMjEuNjkuODI1LjU3QzIwLjU2NSAyMi4wOTIgMjQgMTcuNTkyIDI0IDEyLjI5N2MwLTYuNjI3LTUuMzczLTEyLTEyLTEyIi8+PC9zdmc+\"/&gt;&lt;g aria-hidden=\"false\" fill=\"#333\" text-anchor=\"middle\" font-family=\"Helvetica Neue,Helvetica,Arial,sans-serif\" text-rendering=\"geometricPrecision\" font-weight=\"700\" font-size=\"110px\" line-height=\"14px\"&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub\"&gt;&lt;text aria-hidden=\"true\" x=\"355\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;text x=\"355\" y=\"140\" transform=\"scale(.1)\" textLength=\"270\"&gt;Stars&lt;/text&gt;&lt;rect id=\"llink\" stroke=\"#d5d5d5\" fill=\"url(#a)\" x=\".5\" y=\".5\" width=\"54\" height=\"19\" rx=\"2\"/&gt;&lt;/a&gt;&lt;a target=\"_blank\" xlink:href=\"https://github.com/PaddlePaddle/PaddleHub/stargazers\"&gt;&lt;rect width=\"30\" x=\"60\" height=\"20\" fill=\"rgba(0,0,0,0)\"/&gt;&lt;text aria-hidden=\"true\" x=\"745\" y=\"150\" fill=\"#fff\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;text id=\"rlink\" x=\"745\" y=\"140\" transform=\"scale(.1)\" textLength=\"210\"&gt;8.4k&lt;/text&gt;&lt;/a&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/p&gt;\nBesides, you can use free GPU resourses in &lt;a href=\"https://aistudio.baidu.com/aistudio/projectdetail/4462918\", style=\"text-decoration: underline;\" target=\"_blank\"&gt; aistudio &lt;/a&gt; to enjoy more cases, have fun.\n&lt;/p&gt;\n&lt;/div&gt;\n\"\"\"\n)\ngr.Markdown(\n\"\"\"\n在\"探索无限\"的风格模式下，画作的真实风格完全可以由你的prompt来决定。下面是一些参考案例:\nIn \"Explore infinity\" style mode, how the image looks like is totally up to your prompt. Below are some cases:\n### 复古未来主义风格\n| ![00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格.jpg) | ![00472_000_日落时的城市天际线,复古未来主义风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00472_000_日落时的城市天际线,复古未来主义风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,复古未来主义风格              | 日落时的城市天际线,复古未来主义风格                          |\n### 粉彩朋克风格\n| ![00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00017_004_一只猫坐在椅子上，戴着一副墨镜，粉彩朋克风格.jpg) | ![00029_001_日落时的城市天际线，粉彩朋克风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00029_001_日落时的城市天际线，粉彩朋克风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,粉彩朋克风格                  | 日落时的城市天际线,粉彩朋克风格                              |\n### 史前遗迹风格\n| ![00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格.jpg) | ![00443_005_日落时的城市天际线,史前遗迹风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00443_005_日落时的城市天际线,史前遗迹风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,史前遗迹风格                  | 日落时的城市天际线,史前遗迹风格                              |\n### 波普艺术风格\n| ![00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_005_一只猫坐在椅子上，戴着一副墨镜,波普艺术风格.jpg) | ![00434_002_日落时的城市天际线,波普艺术风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00434_002_日落时的城市天际线,波普艺术风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,波普艺术风格                  | 日落时的城市天际线,后世界末日风格                            |\n### 迷幻风格\n| ![00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_000_一只猫坐在椅子上，戴着一副墨镜,迷幻药风格.jpg) | ![00451_001_日落时的城市天际线,迷幻药风格](https://raw.githubusercontent.com/OleNet/YouPromptMe/gh-pages/you-prompt-me/images/art-style-1024/00451_001_日落时的城市天际线,迷幻药风格.jpg) |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 一只猫坐在椅子上，戴着一副墨镜,迷幻风格                      | 日落时的城市天际线,迷幻风格                                  |\n### &lt;u&gt;[更多内容...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南)([Explore more...](https://github.com/PaddlePaddle/PaddleHub/blob/develop/modules/image/text_to_image/ernie_vilg/README.md#四-prompt-指南))&lt;/u&gt;\n\"\"\"\n)\ngr.HTML('''\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;Model by &lt;a href=\"https://github.com/PaddlePaddle/PaddleHub\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;PaddleHub&lt;/a&gt; and &lt;a href=\"https://wenxin.baidu.com\" style=\"text-decoration: underline;\" target=\"_blank\"&gt;文心大模型&lt;/a&gt; - Gradio Demo by 🤗 Hugging Face\n&lt;/p&gt;\n&lt;/div&gt;\n''')\nblock.queue(concurrency_count=128).launch()\ntext to image minimal example https://github.com/jina-ai/discoart dalle-2 stable diffusion as dalle2 alternative nvidia provided ai paint tool text to image: https://github.com/lucidrains/imagen-pytorch"
  },
  {
    "objectID": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html",
    "href": "posts/aa3eebef-922c-465a-9bbc-767b7e6f2c6b/index.html",
    "title": "chatgpt on pyro and pytorch",
    "section": "",
    "text": "you better train a chatgpt yourself. understand the algorithm.\ncodegeex is not there yet. maybe you can fine-tune it a little bit?"
  },
  {
    "objectID": "posts/73f2a784-813b-4c25-bde5-61f690b56b9f/index.html",
    "href": "posts/73f2a784-813b-4c25-bde5-61f690b56b9f/index.html",
    "title": "aldente windows & linux alternative",
    "section": "",
    "text": "to increase stability, you need to prevent computer from overheating (throttle). also, replace normal laptop ram with ecc ram (not server-grade reg-ecc)\nbut ecc is only supported on Xeon processors.\nmoreover, you could just use UPS+NUC instead of laptop, to prevent this bloody battery issue.\nwill these charging limits still work if we close the lid? if not, we could possibly damage the battery.\nto prevent damage to computer battery due to overcharging"
  },
  {
    "objectID": "posts/f62f4fbb-f86f-4252-8323-ab73ac09e832/index.html",
    "href": "posts/f62f4fbb-f86f-4252-8323-ab73ac09e832/index.html",
    "title": "QQ 微信 信息提取 bot搭建",
    "section": "",
    "text": "qq聊天记录导出 qq消息导出\n微信聊天记录导出\n聊天记录渲染成图片 render chat record to picture\nconclusion so far: people like to use vue to recreate popular interfaces, and you may grab some interface from it.\nvue-wechat\n🔥 基于Vue2.0高仿微信App的单页应用\nvue-qq\n一个长得像QQ的demo\nvue qq 聊天界面组件库\nvue 本项目是一个在线聊天系统，最大程度的还原了Mac客户端QQ。\nvue-miniQQ————基于Vue2实现的仿手机QQ单页面应用\n基于Vue2实现的单页面应用 qq界面模仿\ndemo大师 qq界面模仿 vuejs 要钱\ndemo大师 vue3 仿微信/qq界面 免费\nrender chat record to picture 微信聊天记录渲染成图片\nhtml css渲染\n仿QQ android的聊天界面\nHTML5手机微信聊天界面代码\nHTML5 WebSocket 仿微信界面的网页群聊演示Demo\n用html5做的仿微信聊天界面\n基于H5技术实现的在线聊天室APP\nSimple chatbot exercise using only JavaScript, HTML, CSS\nMulti-Room Chat Application\n一个基于AngularJS、NodeJS、Express、socket.io搭建的在线聊天室。\nfacebook like chatroom\nqq空间发美女图片把人家的脸要挡住 或者要把脸换了 或者直接使用live2d three.js 甚至3d的渲染模型来把脸给它挡住\nsomehow the wechat web uos protocol is usable again? check it out.\nhttps://www.npmjs.com/package/wechaty-puppet-wechat\nhttps://github.com/wechaty/puppet-wechat/pull/206\nwould it be a lot easier if we can send those article/video links to external (out of gfw) social media platforms in their native language? still censorship will be applied.\nwechat frida hook on macos:\nhttps://github.com/dounine/wechat-frida\nWeChat PC Frida hook:\nhttps://github.com/K265/frida-wechat-sticker\nhttps://github.com/kingking888/frida_wechat_hook"
  },
  {
    "objectID": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html",
    "href": "posts/401df531-3db9-4556-a64d-1ce0f0b89bbc/index.html",
    "title": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code, edit and continue",
    "section": "",
    "text": "Python Bytecode, Time Travel Debugging, Resurrection, Ante-Mortem Debugging, Interactive Debugging, Resume after Exception, Python ignore all exceptions and continue execute next line in given section of code\nwhy i hate exceptions ## lisp-style resumption error-handling semantics python for lisp programmers practical common lisp arithmatic infix common lisp debugging common lisp related libraries slime portacle talk on reddit ## ruby pry-rescue may not resume execution? ## java eclipse hot code swap fix hot code replace in vscode for java ## python bytecode hack, pyhotswap python lisp-style exception as condition handling dump different level of reloading call history reload code blocks which are syntatically different, if black formatter fails after dedent then there shall be error decide to reload extra parts of functions in the next run if selected load newly added functions, remove old functions, execute added lines, reload entire module and update namespace depending on condition check other programming language whether it jas similar capabilities visit this thread of ruby in archive.org wallabyjs either bytecode or modify the source code ## bookmarks\nhttps://docs.python.org/3/library/code.html\nhttps://docs.python.org/3/library/cmd.html\nhttps://docs.python.org/3/library/threading.html#threading.settrace\nhttps://mail.python.org/archives/list/python-dev@python.org/thread/OGPO6KWHQGO47KOJKNEWNZS3LLMVXBEV/\nhttps://github.com/TomOnTime/timetravelpdb\nhttps://github.com/nfd/on_error_resume_next/blob/master/basic.py\nhttps://github.com/search?p=5&q=BEFORE_ASYNC_WITH&type=Code\nhttps://github.com/Martmists-GH/pyasm/blob/a306f23cbed13505687eb0ca86f010e5fe3101b5/asm/ops/py35.py\nhttps://github.com/Martmists-GH/pyasm\nhttps://github.com/kr1surb4n/copypaster_filedecks/blob/3f2ca44c4f984652585a1e7f1e589966e8867da6/filedecks_archive/python/library/dis/Python%20Bytecode%20Instructions/opcodeBEFOREASYNCWIT\nhttps://github.com/kholia/dedrop/blob/60da43889be89950cadbbb6b54489eb1841c70da/src/dedrop-ng/opcode_mapper.py\nhttps://github.com/brettlangdon/gython\nhttps://github.com/Exitialium/Github-Drive/blob/5284358a163c4ea25c63f4157d41af5f638950a2/deap/include/python3.9/opcode.h\nhttps://github.com/ajalt/fuckitpy\nhttps://code.lardcave.net/2020/12/29/1/\nhttps://github.com/asrp/python_terp/blob/master/test/buggy_ex.py\nhttps://github.com/HugoDelval/reversibleInterpreter\nhttps://github.com/topics/reversible-programming-language\nhttps://github.com/jndean/railway/wiki/Variables,-Data-and-Scope\nhttps://cn.bing.com/search?q=python+run+bytecode&qs=UT&pq=python+run+byteco&sc=1-17&cvid=79F89EEA4A564540BF79A8DBB63284CE&FORM=QBRE&sp=1\nhttps://opensource.com/article/18/4/introduction-python-bytecode\nhttp://www.aosabook.org/en/500L/a-python-interpreter-written-in-python.html\nhttps://github.com/nedbat/byterun\nhttps://unpyc.sourceforge.net/Opcodes.html\nhttps://docs.python.org/3/library/codeop.html\nhttps://docs.python.org/3/library/dis.html\nhttps://docs.python.org/3/library/dis.html\nhttps://docs.python.org/3/library/codeop.html\nhttps://blog.quarkslab.com/building-an-obfuscated-python-interpreter-we-need-more-opcodes.html\nhttps://github.com/fietensen/PyOpcodeAsm\nhttps://pypi.org/project/BytecodeAssembler/\nhttp://probablyprogramming.com/2008/04/18/ppya-python-assembler\nhttps://pypi.org/project/BytecodeAssembler/#description\nhttp://peak.telecommunity.com/DevCenter/BytecodeAssembler\nhttps://github.com/pib/papaya\nhttps://www.programcreek.com/python/?CodeExample=get+opcode\nhttps://unpyc.sourceforge.net/Opcodes.html\nhttps://www.synopsys.com/blogs/software-security/understanding-python-bytecode/\nhttps://github.com/neuroo/equip\nhttps://tenthousandmeters.com/blog/python-behind-the-scenes-4-how-python-bytecode-is-executed/\nhttps://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/\nhttps://discuss.python.org/t/exec-with-return-keyword/19916/25\nhttps://cn.bing.com/search?q=interactive%20debugging%20python&qs=n&form=QBRE&=%25eManage%20Your%20Search%20History%25E&sp=-1&pq=interactive%20debugging%20&sc=3-22&sk=&cvid=30D653A233984DD685DE7CE79AD46318&ghsh=0&ghacc=0&ghpl=\nhttps://www.digitalocean.com/community/tutorials/how-to-debug-python-with-an-interactive-console\nhttps://nedbatchelder.com/blog/200509/interactive_debugging_in_python.html\nhttps://derpops.bike/python/computers/kubernetes/2017/10/26/interactive-debugging-python-kubernetes.html\nhttps://bytes.com/topic/python/answers/46053-resume-after-exception\nhttps://pytrace.com/\nhttps://github.com/gleb-sevruk/pycrunch-trace/issues\ncontextlib usage detail, to make customized “with” statements:\nfrom contextlib import AbstractContextManager\nclass suppress2(AbstractContextManager):\n\"\"\"Context manager to suppress specified exceptions\nAfter the exception is suppressed, execution proceeds with the next\nstatement following the with statement.\nwith suppress(FileNotFoundError):\nos.remove(somefile)\n# Execution still resumes here if the file was already removed\n\"\"\"\ndef __init__(self, *exceptions):\nself._exceptions = exceptions\ndef __enter__(self):\nprint(dir(self))\npass\ndef __exit__(self, exctype, excinst, exctb):\n# Unlike isinstance and issubclass, CPython exception handling\n# currently only looks at the concrete type hierarchy (ignoring\n# the instance and subclass checking hooks). While Guido considers\n# that a bug rather than a feature, it's a fairly hard one to fix\n# due to various internal implementation details. suppress provides\n# the simpler issubclass based semantics, rather than trying to\n# exactly reproduce the limitations of the CPython interpreter.\n#\n# See http://bugs.python.org/issue12029 for more details\nprint(\"EXCTYPE\", exctype)\nprint(\"EXCINST\", excinst)\nprint(\"EXCTB\",exctb) # exception\nprint(dir(exctb))\nbreakpoint()\nreturn exctype is not None and issubclass(exctype, self._exceptions)\npython grammar sugar: brackets https://pypi.org/project/brackets/ does that work in eval()? use contextlib.suppress to replace try…except: pass might investigate source code of the suppress object. https://opensource.com/article/18/5/how-retrieve-source-code-python-functions to execute code grouped by lowest level of indentation, we can def those lines of code and pass the code by dill.source.getsource(functionName) and eval within given global/local variables. my solution is down here, with concrete examples. hereby we recommend to insert a conditional return statement to ensure we will exit this buggy code at the best time. maybe we could put it into a dictionary somehow, tuples within string or something.\nimport dill\nfrom contextlib import suppress\nimport traceback\ndef skipException(func, debug_flag=False, breakpoint_flag=False):\ndef space_counter(line):\ncounter = 0\nfor x in line:\nif x == \" \": counter+=1\nelse: break\nreturn counter\ndef remove_extra_return(code):\nwhile True:\nif \"\\n\\n\" in code:\ncode = code.replace(\"\\n\\n\",\"\\n\")\nelse: break\nreturn code\ndef isEmptyLine(line):\nemptyChars = [\"\\n\",\"\\t\",\"\\r\",\" \"]\nlength = len(line)\nemptyCounts=0\nfor char in line:\nif char in emptyChars: emptyCounts += 1\nreturn emptyCounts == length\ndef getCodeBlocks(lines):\nmBlocks=[]\ncurrent_block = lines[0]\nlines = lines+[\"\"]\nkeywords = [\" \", \"def\", \"async def\", \"with\", \"class\", \"@\"]\nfor line in lines[1:]:\nif sum([line.startswith(keyword) for keyword in keywords]):\ncurrent_block+=\"\\n\"\ncurrent_block+=line\nelse:\nmBlocks.append(current_block)\ncurrent_block = line\nreturn mBlocks\ndef getExtendedLines(splited_code):\nsplited_code = [x.rstrip() for x in splited_code]\nsplited_code = \"\\n\".join(splited_code).replace(\"\\\\\\n\",\"\")\nsplited_code = remove_extra_return(splited_code)\nsplited_code = splited_code.split(\"\\n\")\nreturn splited_code\ndef new_func(*args, **kwargs):\nfunc_name = func.__name__\nfunc_code = dill.source.getsource(func)\nif debug_flag:\nprint(\"########## FUNCTION CODE #########\")\nprint(func_code) # do not use chained decorator since doing so will definitely fail everything?\nprint(\"########## FUNCTION CODE #########\")\nprint(\"########## FUNCTION #########\")\n# print(func_code)\nfunc_code = remove_extra_return(func_code)\nsplited_code = func_code.split(\"\\n\")\nsplited_code = getExtendedLines(splited_code)\n# index 0: decorator\n# index 1: function name\n# no recursion support. may work inside another undecorated function.\ntry:\nassert splited_code[0].strip().startswith(\"@skipException\")\nexcept:\nraise Exception(\"Do not nesting the use of @skipException decorator\")\nfunction_definition = splited_code[1]\nfunction_args=function_definition[:-1].replace(\"def {}\".format(func_name),\"\")\nif debug_flag:\nprint(\"FUNCTION ARGS:\", function_args)\nkwdefaults = func.__defaults__\npass_kwargs = {}\nif \"=\" in function_args:\nassert kwdefaults!=None\narg_remains = function_args.split(\"=\")[0]\nkwarg_remains = function_args.replace(arg_remains,\"\")\nkwarg_extra_names =[content.split(\",\")[-1].strip() for index, content in enumerate(kwarg_remains.split(\"=\")) if index%2 ==1]\nmfunctionArgsPrimitive = arg_remains.replace(\"(\",\"\").split(\",\")\nkwarg_names = [mfunctionArgsPrimitive[-1].strip()]+kwarg_extra_names\nmfunctionArgs = mfunctionArgsPrimitive[:-1]\nif debug_flag:\nprint(\"PASSED KEYWORD ARGS:\", kwargs)\nprint(\"KWARG NAMES:\", kwarg_names)\nfor key, value in zip(kwarg_names, kwdefaults):\npass_kwargs.update({key: value})\nfor key in kwargs.keys():\nassert key in kwarg_names\npass_kwargs[key] = kwargs[key]\nelse:\nassert kwdefaults == None\nmfunctionArgs = function_args.replace(\"(\",\"\").replace(\")\",\"\").split(\",\")\nmfunctionArgs = [x.strip() for x in mfunctionArgs]\nmfunctionArgs = [x for x in mfunctionArgs if not isEmptyLine(x)]\nif debug_flag:\nprint(\"POSITIONAL ARGS:\",mfunctionArgs)\nassert len(args) == len(mfunctionArgs)\nfor key, value in zip(mfunctionArgs, args):\nexec(\"{} = {}\".format(key, value))\nif kwdefaults is not None:\nfor key, value in pass_kwargs.items():\nexec(\"{} = {}\".format(key, value))\nactualCode = splited_code[2:]\nactualCode = [x for x in actualCode if not isEmptyLine(x)]\nminIndent = min([space_counter(line) for line in actualCode])\n# split the code into different sections.\nif debug_flag:\nprint(minIndent)\nnewLines = [line[minIndent:] for line in actualCode]\ncodeBlocks = getCodeBlocks(newLines)\nfor block in codeBlocks:\nif debug_flag:\nprint(\"##########CODEBLOCK##########\")\nprint(block)\nprint(\"##########CODEBLOCK##########\")\nif not debug_flag:\nwith suppress(Exception):\nexec(block)\nelse:\ntry:\nexec(block)\nexcept:\ntraceback.print_exc()\nif breakpoint_flag: breakpoint()\nif debug_flag:\nprint(\"########## FUNCTION #########\")\nreturn new_func\ndef skipExceptionVerbose(func): return skipException(func, debug_flag=True)\ndef skipExceptionBreakpoint(func): return skipException(func, breakpoint_flag=True)\ndef skipExceptionDebug(func): return skipException(func, breakpoint_flag=True, debug_flag=True)\n@skipException\ndef someOtherShit():\namd=[1,2,3]\namd[4]\nprint(\"shit happens\")\ndef anotherShit():\n@skipException\ndef mySuperFunction(d,e,f):\nsomeOtherShit()\nprint(\"YOU WIN\")\na = [1,2,3]\na[3] # will not continue execute the code down there\nprint(\"YOU WIN\")\na[4]\nprint(\"INSIDE FUNCTION\",d,e,f)\nprint(\"YOU WIN\")\nmySuperFunction(1,2,3)\n# print(dir(mySuperFunction))\nanotherShit()\n# breakpoint()"
  },
  {
    "objectID": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html",
    "href": "posts/e57e176f-0d28-4f9d-9391-5da1dd3cb20a/index.html",
    "title": "Mastering Interactive Interfaces and GUIs with Python",
    "section": "",
    "text": "Live coding, hacking, media\nI think hacking requires certain level of live coding, like fzf, interactive jq, interactive regex and repl, or my modded hy. Interactive searching is one such kind of live coding. It can also be manual labeling, training a model. on the other hand, media convey the idea of live coding, mostly by showing off the benefits, but hardly getting to the point when you really need it. media is not coding (requiring coding skill), it is just somehow interactive. ## interactive interfaces ### gui custom tkinter ### cli rich textual ## related infos the art of commandline awesome jq ## interactive tools ### web based tools xpath tester for html explainshell livegrep ### cli tools ijq interactive jq jiq [percol](https://github.com/mooz/percol] supports pinyin ugrep use ugrep -Q for interactive tui ## coding python design patterns"
  },
  {
    "objectID": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#better-exceptions",
    "href": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#better-exceptions",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "better-exceptions",
    "text": "better-exceptions"
  },
  {
    "objectID": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#to-ensure-the-consistency-of-tests-you-need-to-collect-inputoutput-pairs-and-compare-with-expectedactual-output-if-it-is-deterministic.",
    "href": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#to-ensure-the-consistency-of-tests-you-need-to-collect-inputoutput-pairs-and-compare-with-expectedactual-output-if-it-is-deterministic.",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "to ensure the consistency of tests, you need to collect input/output pairs (and compare with expected/actual output), if it is deterministic.",
    "text": "to ensure the consistency of tests, you need to collect input/output pairs (and compare with expected/actual output), if it is deterministic."
  },
  {
    "objectID": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#monkeytype-pytype-by-google-runtype-dispatch",
    "href": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#monkeytype-pytype-by-google-runtype-dispatch",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "monkeytype, pytype (by google), runtype (Dispatch)",
    "text": "monkeytype, pytype (by google), runtype (Dispatch)"
  },
  {
    "objectID": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#better-assertion",
    "href": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#better-assertion",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "better assertion",
    "text": "better assertion"
  },
  {
    "objectID": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#enum-class-in-python",
    "href": "posts/92fd1692-651c-42f9-a2b8-2b4972be284b/index.html#enum-class-in-python",
    "title": "Incremental testing, build tools, cacheing, logging",
    "section": "enum class in python",
    "text": "enum class in python\nuse cache in pytest use redis lru_cache, put decorators to json serializable functions use build tools, forcing program to read and write files in the process type checking using mypy code static analysis code formatter like black —- tools: pydoit with “up to date” signals for non-file objectives scons ruby rake"
  },
  {
    "objectID": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html",
    "href": "posts/bf0b54c7-e6fb-459e-8cd0-4a605ff8b56c/index.html",
    "title": "ChatGPT Local Version",
    "section": "",
    "text": "Run some community contributed ChatGPT-like models on commondity PCs."
  },
  {
    "objectID": "posts/28f2c636-2561-4c66-a195-5cc94df36bc5/index.html",
    "href": "posts/28f2c636-2561-4c66-a195-5cc94df36bc5/index.html",
    "title": "Automatic CMCC network switching",
    "section": "",
    "text": "the policy follows:\n如何校园网免流？\nkali, could you use some network card for sniffing while connecting to existing network? or could you automate the sniffing so that we don’t get bored?\ncould you extract some login default patterns/filters?"
  },
  {
    "objectID": "posts/28ea45cc-7d4f-41d2-a41c-51d0fecdec23/index.html",
    "href": "posts/28ea45cc-7d4f-41d2-a41c-51d0fecdec23/index.html",
    "title": "Advanced ASS subtitle Karaoke Effects",
    "section": "",
    "text": "Advanced ASS Subtitle Karaoke Effects\nlibrary collection and guide on how to create karakoe effects programmatically ## lrc files crop music that does not sing too early? maybe no need. we need to sort them out by time! prevent serious issues. skip empty lines? lrc files only have start time but no end time. we group parallel lyrics by time, if they are close enough we make it into a group. groups act as time separators. no two group share the same time. also group have maximum span time, minimum span time calculated by content, and group should always in bound. should apply the same min-max rule when selecting my video clips all ass file tags, for custom karaoke effects creation my karaoke effect:\n{\\k-50\\K400}\n{\\k-&lt;initial offset&gt;\\K&lt;total duration&gt;}\nplay ass file with mpv on demo video, full screen, no audio:\nrootpath=/Users/jamesbrown/desktop/works/pyjom_remote/\nmpv --fs --no-audio --sub-file=\"$rootpath/tests/karaoke_effects/pyonfx_test/examples/2 - Beginner/Output.ass\" \"$rootpath/samples/video/karaoke_effects_source.mp4\"\ncreate karaoke effects https://github.com/Kagu-chan/FXSpindle karaoke effects https://github.com/Youka/NyuFX pyonfx code recommend to use effect 2 beginners -&gt; 3 variants in examples, while 3 advanced -&gt; 2 testing pixels as reference (more advanced but incomplete, and might be very intensive) pyonfx documentation https://github.com/logarrhythmic/karaOK aegisub and its plugins https://github.com/Myaamori/aegisub-cli https://github.com/qwe7989199/Lyric-Importer-for-Aegisub https://github.com/qwe7989199/aegisub_scripts https://github.com/lyger/Aegisub_automation_scripts http://www.aegisub.org/ eyecandy create karaoke ass files: https://github.com/Alquimista/Eyecandy-py create karaoke effects subtitle with lrc file, support chinese https://github.com/DYY-Studio/lrc2ass_py3"
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html",
    "title": "AGI that controls computer",
    "section": "",
    "text": "make specialized (in RPA) tokenizer and embedding for this new model. add new words to the tokenizer.\nyou can just boot ubuntu/kali/parrot iso without installing.\nbut that would make us embarrasing. we need to check for the option.\nuse ChatGPT-derived projects for localized propaganda on CyberGod and The Frozen Forest."
  },
  {
    "objectID": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#for-ubuntu-arm-vm-mss-failed-on-wayland-but-pyautogui-works-in-both-cases.-write-one-python-script-to-pipe-raw-images-to-ffmpeg-for-better-compression-ratio-by-shell.-the-final-video-is-not-time-accurate.-it-is-frame-by-frame-matched-with-timestamps.",
    "href": "posts/f57039ce-6fc8-4be5-92ed-14f55b265fc8/index.html#for-ubuntu-arm-vm-mss-failed-on-wayland-but-pyautogui-works-in-both-cases.-write-one-python-script-to-pipe-raw-images-to-ffmpeg-for-better-compression-ratio-by-shell.-the-final-video-is-not-time-accurate.-it-is-frame-by-frame-matched-with-timestamps.",
    "title": "AGI that controls computer",
    "section": "for Ubuntu ARM VM, mss failed on wayland but pyautogui works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps.",
    "text": "for Ubuntu ARM VM, mss failed on wayland but pyautogui works in both cases. write one python script to pipe raw images to ffmpeg for better compression ratio by shell. the final video is not “time-accurate”. it is frame by frame, matched with timestamps.\nforcing ubuntu to use xorg by: sudo vim /etc/gdm3/custom.conf ## resize UTM VM disks you need to first resize the virtio disk in utm setting, then resize partition by using gparted, then update the device mapper"
  },
  {
    "objectID": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html",
    "href": "posts/4ab0471b-4672-43d3-9407-72131934ae43/index.html",
    "title": "AGI (Artificial General Intelligence) related projects",
    "section": "",
    "text": "said by HTM, AGI knows what it did to the world (self-awareness), also signals from sensors."
  },
  {
    "objectID": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html",
    "href": "posts/bba6278c-c13c-4c41-a1cb-3a084ad7df1c/index.html",
    "title": "0day exploits, AFL(american fuzzy lop), AFL++",
    "section": "",
    "text": "oss-fuzz supports fuzzing C/C++, Rust, Go, Python and Java/JVM code\nblog about greyone Discover Vulnerabilities with Flow Sensitive Fuzzing\nAFL（American Fuzzy Lop）是由安全研究员Michał Zalewski（@lcamtuf）开发的一款基于覆盖引导（Coverage-guided）的模糊测试工具，它通过记录输入样本的代码覆盖率，从而调整输入样本以提高覆盖率，增加发现漏洞的概率\nintro-to-american-fuzzy-lop-fuzzing-in-5-steps\nfuzzing-with-american-fuzzy-lop-afl\nAFL++ can fuzz c source code, binary targets, network services, gui programs\nMontage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer"
  },
  {
    "objectID": "posts/b7f08b1f-e6c0-4c0a-b740-b9d4b7fed842/index.html",
    "href": "posts/b7f08b1f-e6c0-4c0a-b740-b9d4b7fed842/index.html",
    "title": "Exploring Popular AI Libraries and Tools for Various Tasks",
    "section": "",
    "text": "popular AI libraries\nthers’s something missing in the agi field. xgboost binary classification awesome embedding models chakin: simple downloader for embedding models bpemb: pretrained subword embeddings for many languages prophet python tutorial time series forcast tflearn: high level wrappers for tensorflow h2o automl docs awesome h2o for h2o beginners numenta nupic doc deslib dynamic classifier and ensemble library ## recommendation system crab surprise python recsys recommendation system lightfm recsys"
  },
  {
    "objectID": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html",
    "href": "posts/4cf8e73f-7fcf-4672-9623-a9bea82fb7a1/index.html",
    "title": "Audio and Music Tools",
    "section": "",
    "text": "Audio and music processing tools.\nRelated links:\n🔗 Audio, Music, Radio, and Podcast Streaming Apps\n🔗 Audio and Music Tools\n🔗 Free Audio and Music"
  },
  {
    "objectID": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html",
    "href": "posts/f79db9b7-459c-4d4b-9922-b528ccee0c30/index.html",
    "title": "Awesome Transformer & Transfer Learning in NLP",
    "section": "",
    "text": "machine learning guide lots of links, broad topics\nThis repository contains a hand-curated of great machine (deep) learning resources for Natural Language Processing (NLP) with a focus on Bidirectional Encoder Representations from Transformers (BERT), attention mechanism, Transformer architectures/networks, and transfer learning in NLP.\nTransformer (BERT) (Source)"
  },
  {
    "objectID": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html",
    "href": "posts/2973b65b-d8fa-4967-9d49-758a3b55ad61/index.html",
    "title": "Deeplearning on MacOS M-series Processors",
    "section": "",
    "text": "it is funny that macOS still supports AMD GPUs, means any intel Mac (not M-series!) can now utilize internal/external AMD GPUs as long as frameworks like jax and pytorch support MPS/Metal.\ncalling python code from swift using pythonkit:\nrun macos in docker with kvm"
  },
  {
    "objectID": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#section",
    "href": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#section",
    "title": "Example Pydoc",
    "section": "",
    "text": "description: | API documentation for modules: example_docstring. lang: en classoption: oneside geometry: margin=1in papersize: a4 linkcolor: blue links-as-notes: true … # Module example_docstring {#id} a 狗 that will bark. ## Variables ### Variable global_var {#id} some global variable2 Default to None ### Variable global_var2 {#id} some other global variable ## Functions ### Function some_random_method {#id} &gt; def some_random_method( &gt; param_1: str, &gt; param_2, &gt; kw_param_1=None &gt; ) ‑&gt; None just a random method Args —–= param_1 : str : parameter at position 1 param_2 : str : parameter at position 2 kw_param_1 : Any, optional : keyword parameter 1. Defaults to None. Return —–= Nothing returned. Note —–= Extra Notes?\nimport os\nos.system(\"ls -lth\")"
  },
  {
    "objectID": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#classes",
    "href": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#classes",
    "title": "Example Pydoc",
    "section": "Classes",
    "text": "Classes\n\nClass Dog\n\nclass Dog(\n\n\n    name: str\n\n\n)\n\ndog class\nMake a Dog without any friends (yet).\n\nClass variables\n\nVariable friends\nType: List[example_docstring.Dog]\nThe friends of our dog.\n\n\nVariable name\nType: str\nThe name of our dog.\n\n\n\nMethods\n\nMethod bark\n\ndef bark(\n\n\n    self,\n\n\n    loud: bool = True\n\n\n)\n\nwoof\n\nGenerated by pdoc 0.10.0 (https://pdoc3.github.io)."
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "",
    "text": "use grammar or state machine to constraint how llm generate tokens, in order to perform actions and call tools correctly\nvoice auto translation by meta\nuse attention visualization to create pan effects, focus on different parts and illustrate separately\nto get response fast, you need to create content fast. sometimes it is important to degrade aspects like resolution and more.\nhttps://github.com/audio-agi/audiosep\nchangedetection get website updates\nlonglora\n自动删评机器人：\n根据对类似内容的评论预期（结合大模型）进行删除\n根据情感分析删除不利评论\n根据视频内容 标题调整封面人物表情\n造仿制b站 收集用户点击数据\nb站禁用了手机端搜索接口的页面数目，但没有限制电脑端搜索页面数目，估计是为了避免二创素材收集不受影响。\ndeep danbooru for anime comprehension, scene understanding etc\nDo not use removable drives (NAS?) as scratch/data disk for long-term programs. Instead, use internal drives.\nIf possible, first sync all necessary files from removable drives to internal disk, then run the long-running program from there, or first run from rootfs, then jump to removable drives. When error occurs, check if disk is unmounted, try different methods to reload them and rerun the program.\nAnother possible cause is insufficient current. Check for similar issues online.\n短视频内部模拟不同视频上下翻页效果\n如果封面提取关键词进行训练并更换 尝试自己生成配图和文字的方法难以实现 可以考虑更换字体和色彩 文字内容不变\n封面文字遵循一定的阅读顺序 从上到下 从左到右 可以设立排版以及合并（用于训练）规则\nyoutube now can auto generate video chapters, which might be part of text/video summarization.\nmultinational, multilingual, subtitles, localizations\nmodels for content generation:\none-for-all multi-modal generation\nmagma: a GPT-style multimodal model that can understand any combination of images and language\n视频创作导航 可以用来找自动化创作视频的思路\n字由 识别字体 下载免费字体\nStartup Toolbox\ntools for startup companies, including:\nAwesome Streaming\na list of live streaming and content creation tools:\n收集大up主的名字 根据提取出来的名词 清除文案中的含有名字的句子\nfor information cascade, treat recommendation system as your target data, and fit your content into the prediction of “to-view” video of popular videos\n分析弹幕关键词是否与大量其他视频标题相重合\nB站撞车搬运检测：\n油管有带有英文番剧名称的AMV/MAD剪辑\n通过B站搜索Weibo Tumblr Tiktok Youtube的视频ID 或者名称，可以找出视频是否被转载\n通过搜索其他网站的前缀 比如https://www.youtube.com 可以得到被转载视频的链接 但是感觉数据不是很靠谱 不是很火的那种 要看大流量的还是得爬首页推荐链接 根据话题搜索"
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#use-attention-visualization-to-create-pan-effects-focus-on-different-parts-and-illustrate-separately",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#use-attention-visualization-to-create-pan-effects-focus-on-different-parts-and-illustrate-separately",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "use attention visualization to create pan effects, focus on different parts and illustrate separately",
    "text": "use attention visualization to create pan effects, focus on different parts and illustrate separately"
  },
  {
    "objectID": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#to-get-response-fast-you-need-to-create-content-fast.-sometimes-it-is-important-to-degrade-aspects-like-resolution-and-more.",
    "href": "posts/b78c6699-f152-48c2-a57d-8d17f64c55f1/index.html#to-get-response-fast-you-need-to-create-content-fast.-sometimes-it-is-important-to-degrade-aspects-like-resolution-and-more.",
    "title": "Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots",
    "section": "to get response fast, you need to create content fast. sometimes it is important to degrade aspects like resolution and more.",
    "text": "to get response fast, you need to create content fast. sometimes it is important to degrade aspects like resolution and more.\nhttps://github.com/audio-agi/audiosep changedetection get website updates longlora 自动删评机器人： 根据对类似内容的评论预期（结合大模型）进行删除 根据情感分析删除不利评论 —- 根据视频内容 标题调整封面人物表情 —- 造仿制b站 收集用户点击数据 —- b站禁用了手机端搜索接口的页面数目，但没有限制电脑端搜索页面数目，估计是为了避免二创素材收集不受影响。 —- deep danbooru for anime comprehension, scene understanding etc —- Do not use removable drives (NAS?) as scratch/data disk for long-term programs. Instead, use internal drives. If possible, first sync all necessary files from removable drives to internal disk, then run the long-running program from there, or first run from rootfs, then jump to removable drives. When error occurs, check if disk is unmounted, try different methods to reload them and rerun the program. Another possible cause is insufficient current. Check for similar issues online. —- 短视频内部模拟不同视频上下翻页效果 —- 如果封面提取关键词进行训练并更换 尝试自己生成配图和文字的方法难以实现 可以考虑更换字体和色彩 文字内容不变 封面文字遵循一定的阅读顺序 从上到下 从左到右 可以设立排版以及合并（用于训练）规则 —- youtube now can auto generate video chapters, which might be part of text/video summarization. multinational, multilingual, subtitles, localizations —- models for content generation: one-for-all multi-modal generation magma: a GPT-style multimodal model that can understand any combination of images and language —- 视频创作导航 可以用来找自动化创作视频的思路 字由 识别字体 下载免费字体 Startup Toolbox tools for startup companies, including:\n[Website]\n[Design]\n[Support and customer communication]\n[Payments, billing and distribution]\n[User Analytics and Reporting]\n[Business Analytics]\n[Automation]\n[HR and Payroll]\n[Forms and Surveys]\n[Tech]\n[Product building]\n[Marketing and growth]\n[Collaboration]\n[Build a chatbot]\n[Domains and naming]\n[Legal, Account and Invoicing]\n[Funding]\n[Sales]\n[Communities]\n[Learn]\n[A/B testing]\n[Launch]\n[Other]\nAwesome Streaming a list of live streaming and content creation tools:\n[Content Creation]\n[Sponsors And Affiliate]\n[Setup Guides]\n[Branding]\n[Discord Creation]\n[Brand Website]\n[Uncopyrighted Music]\n[FPS Accuracy]\n[Subathon Framework]\n[Video Editing]\n[OpSec]\n[Stat Tracking]\n[Game Development]\n[V-Tubing]\n[How To Start An LLC]\n收集大up主的名字 根据提取出来的名词 清除文案中的含有名字的句子 for information cascade, treat recommendation system as your target data, and fit your content into the prediction of “to-view” video of popular videos 分析弹幕关键词是否与大量其他视频标题相重合 B站撞车搬运检测： 油管有带有英文番剧名称的AMV/MAD剪辑 通过B站搜索Weibo Tumblr Tiktok Youtube的视频ID 或者名称，可以找出视频是否被转载 通过搜索其他网站的前缀 比如https://www.youtube.com 可以得到被转载视频的链接 但是感觉数据不是很靠谱 不是很火的那种 要看大流量的还是得爬首页推荐链接 根据话题搜索 ## video highlights extraction although you may want to train/extract that manually, it would sure be tedious and not self-updating (unless using reinforcement learning). often we determine highlights by sound, visual and voice together. highlights often can be identified without too much context, so it can be chunk based. ### bilibili b站的高能进度条 在油管被叫做”most replayed” b站有弹幕 所以可以根据弹幕找到精彩片段 VClimax是一个浏览器插件 可以通过弹幕单位时间增长速率，设置相关的阈值，来定位最精彩的内容 (弹幕密度怕还是得要分析) 跳转部分番剧OP 视频搞笑片段精准定位 (怕还得是要机器学习) bilibili Danmaku Skip is another browser plugin which will identify highlights by analyzing danmaku with parameters like threshold, interval and bias ### youtube youtube’s most played data can be extracted by: youtube-heatmap (nodejs, using puppeteer (bad!)) youtube operational api’s (powered by shared API keys and info extractors without key), while apparantly youtube-most-replayed is using this service to retrieve the data from yt.lemonslife.com powered by this library heatmap extractor youtube.js (reverse engineered innertube api) added support for chapters and video heatmap ## youtube-dl search youtube video\nyoutube-dl \"ytsearch[optional_result_limit]:[query]\"\n# pass query url directly to allow pagination or filters\nyoutube-dl \"https://www.youtube.com/results?search_query=how+to+create+android+app+in+android+studio&page=1\""
  },
  {
    "objectID": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html",
    "href": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html",
    "title": "RSIBreak, Break Reminder",
    "section": "",
    "text": "## Smart Watch do not mix the water with the watch. you have been warned.\n\n\n\n\nPrefer WearOS watches like LG W100. Found 3D printable case on Shapeways but not downloadable. Shapeways provides service for printing. Shapeways builds ShapeJS which can construct 3D models with code."
  },
  {
    "objectID": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#use-pixle2mesh-to-recover-3d-meshes-from-multiple-images-dumped-at-desktopworksshapeways_reconstruct_from_image_lg_w100of-different-viewpoints.-determine-the-size-of-the-mesh-after-measurement-or-learning-specs.",
    "href": "posts/e07c3001-60e1-4b63-99fa-ae7c1b4c1966/index.html#use-pixle2mesh-to-recover-3d-meshes-from-multiple-images-dumped-at-desktopworksshapeways_reconstruct_from_image_lg_w100of-different-viewpoints.-determine-the-size-of-the-mesh-after-measurement-or-learning-specs.",
    "title": "RSIBreak, Break Reminder",
    "section": "Use Pixle2Mesh++ to recover 3D meshes from multiple images (dumped at ~/Desktop/works/shapeways_reconstruct_from_image_lg_w100)of different viewpoints. Determine the size of the mesh after measurement or learning specs.",
    "text": "Use Pixle2Mesh++ to recover 3D meshes from multiple images (dumped at ~/Desktop/works/shapeways_reconstruct_from_image_lg_w100)of different viewpoints. Determine the size of the mesh after measurement or learning specs.\nif you want iwatch instead, remember to buy some apple gift cards for buying watchos apps. remember to ask for battery life since older watches tend to die halfway in a day. buy iphone 6s and newer models with ios 14 and newer os to manage and install apps on iwatch. no need for 3d modeling since plenty tough-tested cases around. ## DIY if you want to do it on your own, you have to know how to send notifications on different operating systems. —- on macOS:\nosascript -e 'display notification \"This message should be showing on the notification\" with title \"Coding Tips\"'\nterminal-notifier (brew installable) alerter —- on linux:\nnotify-send \"Dinner ready!\"\nusing remind:\nremind \"I'm still here\" now\nremind \"Time to wake up!\" in 5 minutes\nremind \"Dinner\" in 1 hour\nremind \"Take a break\" at noon\nremind \"It's Friday pints time!\" at 17:00\n\non windows:\nmsg /SERVER:DestinationPC * /TIME:60 “This is the message to be sent to a PC named DestinationPC and closes in 60 seconds.\"\nnotify-send-for-Windows (needs AHK) tutorial ## break reminder tools RSIBreak is for linux, and it does not work well. stretchly has an online version. on macOS make sure your browser is allowed to post notifications. “Drink.” on mac app store is a water drinking reminder for macOS. BreakTimer has windows, macOS and linux version. on linux you better use snap or appimage version."
  },
  {
    "objectID": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html",
    "href": "posts/0b032f52-a3e2-44b4-b90f-a9aaf8fbeba2/index.html",
    "title": "Reverse Proxy Free Frp Providers, Remote Code Editing, Remote Development",
    "section": "",
    "text": "if you install p2p server nodes on primary server (with hard-to-crack password and proper configs (no brute-forcing)?) you might want to add that (n2n) server node at home."
  },
  {
    "objectID": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html",
    "href": "posts/4020a061-208a-40a7-9ad9-22acd5502321/index.html",
    "title": "SEO search engine optimization SEMrush alternative",
    "section": "",
    "text": "semrush contains multiple services, and it is paid. many online tools are paid as well. to find open source alternatives (usually it can’t be achieved with a single tool alone, from scraping to analyzing), let’s figure out what does this tool do, also few tech terms.\nsemrush does SEO, SEM, and SMM.\nput social media buttons on webpages to let users share the content, usually by passing parameters in url, which is part of SMM."
  },
  {
    "objectID": "posts/7407631d-b486-4c90-9577-45486922b9b1/index.html",
    "href": "posts/7407631d-b486-4c90-9577-45486922b9b1/index.html",
    "title": "SEO 蓝海词 竞争度",
    "section": "",
    "text": "SEO 蓝海词 飙升词 竞争度 搜索人气 转化率 成交价（视频长度）\nwe need suggestion, related topics, also search results. can be used in title generation. title/message as query (-&gt; keyword -&gt; suggested query) -&gt; search results -&gt; extract response/title suggestion, trending topics/keywords black hat seo, https://www.blackhatworld.com/forums/black-hat-seo.28/ paste your link ‘elsewhere’, submit your link to search engine somehow, visit your link from search engine somehow ## seo without website write a blog on github? create short links and submit them to search engine get query count, perform n-gram analysis https://www.aeripret.com/ngrams-analysis-seo/ https://www.pemavor.com/seo-keyword-clustering-with-python/ i have bookmarked links for further use on macbook chrome. advertools is a professional SEO library, productivity & analysis tools to scale your online marketing 可以用分析股价的方法分析搜索关键词 其中股价对应搜索频率（实时） 播放量对应成交量（实时）也可能不对 反正这个模型肯定要先收集数据然后再建模 画k线 当然也不必完全拘泥于全盘还原 收集到的数据能反映实际情况 得到最优解 也就是发个视频预估播放量最大就行 用深度学习模型 寻找潜在爆款话题 标签 快排参数 上首页 https://github.com/sopify-bot/seo 分为主动点击 换IP点击 以及优化自身关键词 被动优化两种方式 蓝海词可以从零开始做 可以由现有词语延伸 可以寻找已有的蓝海词 蓝海词是产品关键词的一种，又被称为“零少词”、“长尾词”。具体是指前台具备一定买家搜索热度，但供应商发布产品较少，通常该词下对应的精确匹配产品数量不超过3页，因而同行竞争度较低的关键词。一旦供应商能准确使用这些词语，并能结合信息质量发布一条合格的产品信息，将获得曝光和点击的快速提升 红海泛指竞争相当激烈的市场。在红海中，产业边界是明晰和确定的，游戏的竞争规则是已知的。身处红海的企业试图表现得超过竞争对手，以攫取已知需求下的更大市场份额 淘宝标题撰写技巧：标题流量的3架马车，飙升词+蓝海词+销量卡位词 什么是飙升词？就是在短时间内热度迅速攀升，并且持续上升的词！ 蓝海词就是那些搜索热度非常高，但这个词下面的在线产品却很少的词。 这种词可以让我们避免和红海大词竞争，获取很多隐藏流量！ 淘宝界面除了能够综合排序之外，我们还能通过销量来排序。 关键词卡位就是 寻找点击量和你差不多的视频 商品所拥有的关键词语 标签 这样按照播放量排序的时候就会排到这些视频中间"
  },
  {
    "objectID": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html",
    "href": "posts/2cbfa8d5-63ac-4696-bb14-58f5385ceb27/index.html",
    "title": "Waydroid installation steps",
    "section": "",
    "text": "cursed by the wall."
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html",
    "title": "chatgpt clones, computer automation with ai",
    "section": "",
    "text": "simply because the original note on chatgpt is too long, we start a new one, with more topics and more resources.\nvisit poe.com for a bunch of free chatbots, including GPT-4\nchathub is a browser plugin which you can use ChatGPT, Bing and Bard\nts_server supports a bunch of models like GPT-J, GPT-NeoX, GPT-Neo, OPT, Fairseq GPT, M2M100, CodeGen, GPT2, T5, RWKV, LLAMA and Stable Diffusion, used by textsynth.com\nto manage python versions and environments, pyenv and venv is lightweight and miniconda or mamba is more sophisticated.\njavascript code for extracting model list from huggingface personal homepage:\nconvert arxiv paper (pdf) into html: arxiv vanity (you will have a better view than before, though will not always work) code on github\naminer is similar to paperswithcode, in which you may find interesting papers.\nsomeone prefers bert4keras since it implements multiple LLM into Keras, also easy for GPT-2 LoRA training (by adding a single layer)\npeople love to post uncensorable links and torrents to internet archive and the-eye, just like the gpt-4chan\nto create a simple API (compatible with OpenAI APIs) for LLMs, use SimpleAI"
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#ts_server-supports-a-bunch-of-models-like-gpt-j-gpt-neox-gpt-neo-opt-fairseq-gpt-m2m100-codegen-gpt2-t5-rwkv-llama-and-stable-diffusion-used-by-textsynth.com",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#ts_server-supports-a-bunch-of-models-like-gpt-j-gpt-neox-gpt-neo-opt-fairseq-gpt-m2m100-codegen-gpt2-t5-rwkv-llama-and-stable-diffusion-used-by-textsynth.com",
    "title": "chatgpt clones, computer automation with ai",
    "section": "ts_server supports a bunch of models like GPT-J, GPT-NeoX, GPT-Neo, OPT, Fairseq GPT, M2M100, CodeGen, GPT2, T5, RWKV, LLAMA and Stable Diffusion, used by textsynth.com",
    "text": "ts_server supports a bunch of models like GPT-J, GPT-NeoX, GPT-Neo, OPT, Fairseq GPT, M2M100, CodeGen, GPT2, T5, RWKV, LLAMA and Stable Diffusion, used by textsynth.com"
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#to-manage-python-versions-and-environments-pyenv-and-venv-is-lightweight-and-miniconda-or-mamba-is-more-sophisticated.",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#to-manage-python-versions-and-environments-pyenv-and-venv-is-lightweight-and-miniconda-or-mamba-is-more-sophisticated.",
    "title": "chatgpt clones, computer automation with ai",
    "section": "to manage python versions and environments, pyenv and venv is lightweight and miniconda or mamba is more sophisticated.",
    "text": "to manage python versions and environments, pyenv and venv is lightweight and miniconda or mamba is more sophisticated.\njavascript code for extracting model list from huggingface personal homepage:\nvar arr = [];\nfor (var i of document.getElementsByTagName(\"h4\")) {var t = i.innerText; var tlist = t.split(\"/\"); var t0 = tlist[0]; var t1 = tlist[1]; arr.push(`| [${t1}](https://huggingface.co/${t}) | unknown | unknown | ${t0} |`)};\nconsole.log(arr.join('\n'));\n\n\n\nconvert arxiv paper (pdf) into html: arxiv vanity (you will have a better view than before, though will not always work) code on github aminer is similar to paperswithcode, in which you may find interesting papers.\n\n\n\n\nsomeone prefers bert4keras since it implements multiple LLM into Keras, also easy for GPT-2 LoRA training (by adding a single layer)"
  },
  {
    "objectID": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#people-love-to-post-uncensorable-links-and-torrents-to-internet-archive-and-the-eye-just-like-the-gpt-4chan",
    "href": "posts/50b7bfd9-9776-4c4e-bab7-eabe1be23d3d/index.html#people-love-to-post-uncensorable-links-and-torrents-to-internet-archive-and-the-eye-just-like-the-gpt-4chan",
    "title": "chatgpt clones, computer automation with ai",
    "section": "people love to post uncensorable links and torrents to internet archive and the-eye, just like the gpt-4chan",
    "text": "people love to post uncensorable links and torrents to internet archive and the-eye, just like the gpt-4chan\nto create a simple API (compatible with OpenAI APIs) for LLMs, use SimpleAI ## fine-tuning and tricks PEFT (Parameter Efficient Fine Tuning) supports LoRA, Prefix Tuning, P-Tuning and Prompt Tuning. ## computer automation with ai ### virtual machines and environments it is not feasible to install ubuntu arm on macos m1 with virtualbox. use utm.app instead. instructions on installing ubuntu with utm includes guides on sharing clipboard and directory. ### papers playing atari using q-learning (viewing deepmind paper with arxiv vanity) ### models video pretraining can perform minecraft diamond mining tasks with keyboard and mouse movements code and model —- mm-cot (multimodal chain-of-thought) by amazon, with model weights ### data collectors and controllers mss for screenshot, remember to save raw pixels to SSD, then compress into mp4 with ffmpeg for further training (mind the timestamp!) —- go-vncdriver by openai, to compile you need to clone the repo and modify code to find headers for libjpeg-turbo and python. libvncdriver asyncvnc (supports apple vnc), side project: asyncssh python-vnc-client with keydown/keyup event support vncdotool pyVNC —- pynput as input event listener and actor, listener may have some strange keycodes when pressing modifier keys on windows. note that special care needed for aligning mouse location with screenshot size —- ViT-pytorch can be used in many ViT-based models, listed and implemented in the repo. ### spaces openai universe (blog post here) and starter agents, remotes are using vnc protocol and a reward protocol using websocket sending json (can send actions). they prefer TigerVNC, maybe that will send the existing monitor instead of invisible ones. gym is classic and modular. atari-py enables old games retro deprecates universe, but might help with general computer controlling AI systems since they are compatible. human don’t play games all day and night. beware of this and don’t turn the model into a heavy gamer. there is no meaning of recording terminal input/output when using tools like vim. get screenshots, keystrokes and mouse clicks instead (using ttyd, gremlins.js or monkey.js). tkterminal won’t do. it is just a thin wrapper around subprocess.run talking of browser, you can spin up novnc server and let the gremlins.js do its job. ## accelerators ### cformers cpu only able to install from pip ### ggml cpu only cpp, only compile from source ### flexgen gpu is mandatory, better than deepspeed and Hugging Face Accelerate ## open source model and weights awesome decentralized llm listed up-to-date related chatgpt-like repositories, datasets, model weights and resources. —- model weights of open source chatgpt alternatives: | weight path | model size | model name | author | | – | – | – | – | | openchatgpt-neox-125m | 125m | gpt-neox | mrsteyk | | openchatgpt-neo-125m | 125m | gpt-neo | mrsteyk | ### LLaMA it’s public. | weight path | model name | author | | – | – | – | | llama-13b-hf-int4 | 13b |decapoda-research | | llama-65b-hf-int4 | 65b |decapoda-research | | llama-30b-hf-int4 | 30b |decapoda-research | | llama-7b-hf-int4 | 7b |decapoda-research | | llama-30b-hf | 30b |decapoda-research | | llama-65b-hf | 65b |decapoda-research | | llama-13b-hf | 13b |decapoda-research | | llama-7b-hf | 7b |decapoda-research | | llama-smallint-pt | unknown |decapoda-research | | llama-7b-hf-int8 | 7b | decapoda-research | ### ChatYuan v2 is censored. —- model weights: | weight path | model size | model name | author | | – | – | – | – | | ChatYuan-large-v1 | unknown | unknown | ClueAI | | ChatYuan-large-v2-paddle | unknown | unknown | ClueAI | | ChatYuan-large-v2 | unknown | unknown | ClueAI | | ChatYuan-large-v1-paddle | unknown | unknown | ClueAI | ### Deepshard LLaMA trained on custom instruction dataset. —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | deepshard-13B-ft | 13b | deepshard | swype | | deepshard-13B-raw | 13b | deepshard | swype | ### ChatGLM Currently only open-sourced 6B version. You can train ChatGLM using GXT3090: simple_thu_chatglm6b Using 7GB VRAM, train ChatGLM with P-tuning chatglm_finetuning supports loading from int4 weights —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | chatglm-6b-int4-slim | 6b | chatglm | silver | | chatglm-6b-slim | 6b | chatglm | silver | | chatglm-6b-int4-qe-slim | 6b | chatglm | silver | | chatglm-6b-int4 | 6b | chatglm | THUDM | | chatglm-6b-int4-qe | 6b | chatglm | THUDM | | chatglm-6b | 6b | chatglm | THUDM | ### ChatDoctor LLaMA-65B trained on medical dataset InstructorDoctor-200k ### BELLE 开源中文对话大模型 —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | BELLE-LLAMA-7B-0.6M | 7B | LLaMA | BelleGroup | | BELLE-LLAMA-7B-2M | 7B | LLaBLOOMZMA | BelleGroup | | BELLE-LLAMA-7B-2M-gptq | 7B | LLaMA | BelleGroup | | BELLE-LLAMA-13B-2M | 13B | LLaMA | BelleGroup | | BELLE-7B-gptq | 7B | BLOOMZ | BelleGroup | | BELLE-7B-2M | 7B | BLOOMZ | BelleGroup | | BELLE-7B-0.6M | 7B | BLOOMZ | BelleGroup | | BELLE-7B-0.2M | 7B | BLOOMZ | BelleGroup | | BELLE-7B-1M | 7B | BLOOMZ | BelleGroup | ### baize trained on ChatGPT self-chatting data —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | baize-lora-30B | 30b | baize | project-baize | | baize-lora-13B | 13b | baize | project-baize | | baize-healthcare-lora-7b | 7B | baize | project-baize | | baize-lora-7B | 7B | baize | project-baize | ### dolly model arch is gpt-j, trained on alpaca dataset —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | dolly-v1-6b | 6b | dolly | databricks | | dolly-lora | unknown | dolly | samwit | ### FastChat (Vicuna) web interface —- model weights: | weight path | weight size | model name | author | | – | – | – | | vicuna | unknown | Vicuna | chavinlo | | vicuna2 | unknown | Vicuna | chavinlo | | vicuna-13b-delta-v0 | 13b | Vicuna | lmsys | | vicuna-13b-GPTQ-4bit-128g | 13b | vicuna | anon8231489123 | | ggml-vicuna-13b-4bit | 13b | vicuna | eachadea | | vicuna-13b | 13b | vicuna | eachadea | | vicuna4all | 13b | vicuna | vicuna4all | download official delta weights via magnet ### Bloom-z there is bloomz.cpp, converted model weights on huggingface ### Alpaca alpaca is LLaMA tuned on ChatGPT self-instruct dataset. officially there is just code and dataset, model weights are community provided. ggml version: alpaca.cpp example on how to load PEFT patched alpaca model: alpaca-lora/generate.py it’s better to check for python bindings and webui like Alpaca-Turbo and Dalai for further development and interactions. —- fine-tuning: simple-llama-finetuner using LoRA, 16GB VRAM minimum alpaca-lora: the OG LoRA alpaca —- community model weights: | weight path | weight size | model name | author | | – | – | – | – | | alpaca-lora-7b | 7b | Alpaca | tloen | | Alpaca Native | 7B | Alpaca | chavinlo | | Alpaca-65B | 65B | Alpaca | chavinlo | | Alpaca 13B | 13B | Alpaca | chavinlo | | GPT4-X-Alpaca | 13B | Alpaca | chavinlo | | Toolpaca | 13B | Alpaca | chavinlo | | instruct-gpt-j-fp16 | 6B | GPT-J | nlpcloud | | alpaca-30b | 30b | Alpaca | baseten | | alpaca-lora-65b | 65b | alpaca | chansung | | alpaca-lora-30b | 30b | alpaca | chansung | | koalpaca-lora-13b | 13b | koalpaca | chansung | | alpaca-lora-13b | 13b | alpaca | chansung | | alpaca13B-lora | 13b | alpaca | samwit | | alpaca7B-lora | 7b | alpaca | samwit | | bloompaca-7b1-lora | 7b | bloom | samwit | | gpt4-x-alpaca-native-13B-ggml | 13b | alpaca | Pi3141 | | alpaca-native-7B-ggml | 7b | alpaca | Pi3141 | | alpaca-native-13B-ggml | 13b | alpaca | Pi3141 | | alpaca-lora-30B-ggml | 30b | alpaca | Pi3141 | | alpaca-lora-7B-ggml | 7b | alpaca | Pi3141 | | alpaca-lora-13B-ggml | 13b | alpaca | Pi3141 | | alpaca-7b-native-enhanced | 7b | alpaca | Pi3141 | | gpt4-x-alpaca-13b-native-4bit-128g | 13b | alpaca | anon8231489123 | | ggml-gpt4-x-alpaca-13b-native-4bit | 13b | alpaca | eachadea | | alpaca-13b-hf-fp16 | 13b | alpaca | teknium | —- codealpaca only provides dataset for training a code generation model, there are multiple models trained on this dataset, including bloom-7b1-lora-codealpaca20k ### togethercomputer released openchatkit with retrieval ability and its huggingface space —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | GPT-NeoXT-Chat-Base-20B | 20B | GPT-NeoXT | togethercomputer | | Pythia-Chat-Base-7B | 7B | Pythia | togethercomputer | —- moderation model weights: | weight path | weight size | model name | author | | – | – | – | – | | GPT-JT-Moderation-6B | 6B | GPT-JT | togethercomputer | ### SpikeGPT inspired by RWKV —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | SpikeGPT-BookCorpus | unknown | SpikeGPT | ridger | ### RWKV —- RWKV combines attention with RNN so the token window can be much larger. Longformer is similar to this. Model weights in github repo or huggingface. —- now we have rwkv.cpp (4bit quantization), build upon ggml and sure it works on cpu. rwkvstic (with 8bit & offload for low VRAM GPUs) —- RWKV-LoRA supports RWKV-v4-NeoX —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | RWKV-7B-alpaca-finetuned | 7b | RWKV | BlueSunflower | | rwkv-4-14B-alpaca-finetune-lora-weights | 14b | RWKV | BlueSunflower | | rwkv-fastquant | unknown | rwkv | Hazzzardous | | rwkv-onnx | unknown | rwkv | Hazzzardous | | RWKV-8Bit | unknown | rwkv | Hazzzardous | | rwkv-4-raven | unknown | rwkv | BlinkDL | | rwkv-4-pile-7b | 7b | rwkv | BlinkDL | | rwkv-4-pile-14b | 14b | rwkv | BlinkDL | | rwkv-4-pile-430m | 430m | rwkv | BlinkDL | | rwkv-4-pile-3b | 3b | rwkv | BlinkDL | | rwkv-4-pile-1b5 | 1.5b | rwkv | BlinkDL | | rwkv-4-pile-169m | 169m | unknown | BlinkDL | | rwkv-3-pile-1b5 | 1.5b | rwkv | BlinkDL | | rwkv-3-pile-430m | 430m | rwkv | BlinkDL | | rwkv-2-pile-430m | 430m | rwkv | BlinkDL | | rwkv-3-pile-169m | 169m | rwkv | BlinkDL | | RWKV-LM-safetensors | unknown | RWKV | mrsteyk | | openchatrwkv-430m-r2.0.1 | 430m | RWKV | mrsteyk | | openchatrwkw-430m-r2 | 430m | RWKV | mrsteyk | | openchatrwkv-430m | 430m | RWKV | mrsteyk | encrypted alpaca model weights released by point-network: point-alpaca ### gpt4all by nomic LLaMA trained on massive collection of clean assistant dialog data, with model weights you need to install nomic to run the model:\npip3 install nomic\nto run it on gpu, you need to install this ### openassistant researchers of open-assistant like andreaskoepf has releasesed oasst-sft-3-pythia-12b-epoch-3.5 and still updating —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | oasst-llama-13b-2-epochs | 13b | llama | dvruette | | oasst-llama-13b-1000-steps | 13b | llama | dvruette | | oasst-gpt-neox-20b-1000-steps | 20b | gpt-neox | dvruette | | oasst-gpt-neox-20b-3000-steps | 20b | gpt-neox | dvruette | | oasst-pythia-12b-6000-steps | 12b | pythia | dvruette | | oasst-pythia-12b-3000-steps | 12b | pythia | dvruette | | oasst-pythia-12b-flash-attn-5000-steps | 12b | pythia | dvruette | | oasst-pythia-6.9b-4000-steps | 12b | pythia | dvruette | | oasst-sft-1-pythia-12b | 12b | pythia | OpenAssistant | | galactica-6.7b-finetuned | 6.7b | galatica | OpenAssistant | | oasst-sft-4-pythia-12b-epoch-3.5 | 12b | pythia | andreaskoepf | | pythia-12b-pre-2000 | 12b | pythia | andreaskoepf | | pythia-12b-pre-3500 | 12b | pythia | andreaskoepf | | oasst-sft-3-pythia-12b-epoch-3.5 | 12b | pythia | andreaskoepf | | oasst-sft-3-pythia-12b-epoch-2.35 | 12b | pythia | andreaskoepf | | oasst-sft-2-candidiate-0 | unknown | unknown | andreaskoepf | | oasst-sft-2-pythia-12b-4000 | 12b | pythia | andreaskoepf | | oasst-sft-1-gpt-neox-2000 | unknown | gpt-neox | andreaskoepf | | oasst-1_12b_4500 | 12b | unknown | andreaskoepf | | oasst-1_12b_1500 | 12b | unknown | andreaskoepf | | oasst-1_12b_3000 | 12b | unknown | andreaskoepf | —- reward model weights: | weight path | weight size | model name | author | | – | – | – | – | | reward-model-deberta-v3-large | unknown | deberta-v3 | OpenAssistant | | reward-model-deberta-v3-large-v2 | unknown | deberta-v3 | OpenAssistant | | reward-model-electra-large-discriminator | unknown | electra-large | OpenAssistant | | reward-model-deberta-v3-base | unknown | deberta-v3 | OpenAssistant | | oasst-rm-1-pythia-1b | 1b | pythia | andreaskoepf | ### openflamingo using CLIP ViT-L and LLaMA-7B, model weights on huggingface ### cerebras gpt open sourced model weights and training code —- model weights: | weight path | weight size | model name | author | | – | – | – | – | | cerebras-gpt-6.7b-lora | 6.7b | cerebras-gpt | samwit | | Cerebras-GPT-2.7B-Alpaca-SP | 2.7b | cerebras-gpt | lxe | | Cerebras-GPT-2.7B-Alpaca-SP-ggml | 2.7b | cerebras-gpt | lxe | | lora-cerebras-gpt2.7b-alpaca-shortprompt | 2.7b | cerebras-gpt | lxe | | Cerebras-GPT-13B | 13b | cerebras-gpt | cerebras | | Cerebras-GPT-6.7B | 6.7b | cerebras-gpt | cerebras | | Cerebras-GPT-2.7B | 2.7b | cerebras-gpt | cerebras | | Cerebras-GPT-1.3B | 1.3b | cerebras-gpt | cerebras | | Cerebras-GPT-590M | 590m | cerebras-gpt | cerebras | | Cerebras-GPT-256M | 256m | cerebras-gpt | cerebras | | Cerebras-GPT-111M | 111m | cerebras-gpt | cerebras | ### ColossalChat Coati-7B has no public model weights, but claimed to be trained efficiently you need to install LLaMA compatible transformers library train on InstructionWild ## enhancements ### using external tools toolformer-pytorch (WORK IN PROGRESS) —- engshell: using LLM to execute command ### using ai models Microsoft JARVIS aka HuggingGPT leverages huggingface models so ChatGPT can complete complex multimodal tasks. ### retrieval plugins long term memory for oobabooga/text-generation-webui (can run pythia, galatica, opt, gpt-j, gpt-4chan, rwkv and support quantization/acceleration), also complex memory (KoboldAI-like) —- chatpaper summarize paper content. similar website: typeset.io (can ask questions and explain confusing text, math symbols and tables) related projects: ChatReviewer ChatImprovement ChatResponse ChatGenTitle —- chatgpt retrieval plugin chop document into chunks, process them into vectors and search them using one of many vector search backends. hosted as a fastapi service. ## datasets ### assistant dialogue botbots dataset (two chatgpt talking to each other), created by using datasetGPT (LLM automation tool) —- ShareGPT52k, also ShareGPT90k (Vicuna) —- instruct-102.4k by swype —- datasets by BELLE: train_1M_CN train_0.5M_CN multiturn_chat_0.8M school_math_0.25M ### unsupervised pretraining Fandom23K (text classification), part of BigKnow2022 Kinda LLaMA replicates LLaMA dataset, including scraped webpages, code and stackexchange data. oscar-corpus needs to be downloaded with access token, by accepting agreement with account. containing categorized content and adult content. ## dataset preprocessing deduplicate text dataset in rust, may remove verbose substrings like “to go to the” oscar project (Open Super-large Crawled Aggregated coRpus) contains some tool for adult content filtering and deduplication. ## NLP tools & training methods fasttext for efficient learning of word representations and sentence classification. —- langchain prompt-engine chatml: markup language for ChatGPT, by openai react-agent-ts enables LLM to chat and use tools by internal dialogues. babyagi: AI-powered task management system. original post on twitter —- Chain-of-hindsights (can learn from negative feedback) in jax and pytorch ## interfaces serge is dockerized and the needs of RAM is according to the size of the model (alpaca), using CPU only"
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html",
    "title": "chatgpt",
    "section": "",
    "text": "GPT4 is out.\n三个国内镜像站：\nhttps://chat.forchange.cn\nhttps://aigcfun.com\nhttps://ai.askai.top\nbesides from decent processors, RAM and optimized runtime, in order to load LLMs fast, one would store the model weights on SSDs.\nnow colossalai supports chatgpt training with a single gpu, using open-source code\ncheck humata for paper QA and information extraction/language understanding from PDF files\nthe syntax of chatgpt’s response is obviously markdown.\nin order to be unblocked by chatgpt just because we are using static ip of corp’s wifi, we can connect through our phone’s hotspot.\nMicrosoft’s EdgeGPT needs you to open in Edge browser and join the waitlist of new Bing, having 3rd party API here\nMerlin is an extension based on ChatGPT which is avaliable for free and all countries, with 11 queries for free each day. Pro subscriptions incoming.\nRallio67 builds dataset for RLHF and has released multiple chatgpt-like models on huggingface. namely, joi, chip and rosey, all based on pythia or neox-20b. laion people tend to share loads to CPU in order to run these huge models properly.\nKoboldAI considered OPT and GPT-Neo as generic LMs. special models like NSFW shits may serve some purposes better.\nmany alternatives, but many are specialized in marketing and content generation, some are chatgpt replica, like chatsonic (with google knowledge) and youchat (from you.com (awesome!))\nopen assistant now has a data collection website, in which you can only perform tasks given and earn points (working for free? nah?)\nit is adviced to run this chatgpt program with libraries instead of manually, to prevent issues.\nmy account has been banned from trying chatgpt. though it is not going to be free forever, you need to moderate your input (multi-language support, not only english but chinese) using some api to prevent similar incidents. also some topics outside of blacklist are banned intentionally so you need to check if the model is really producing the answer. if not you should avoid or change the way of asking it.\nmoderation via official openai api, perspective api (free), or via some projects like content moderation deeplearning, bert text moderation, bert-base-uncased-hatexplain, toxic-bert, copilot-toxicity and multilingual-hate-speech-robacofi, train on datasets like hate_speech_offensive, toxicity (by surge-ai, a dataset labelling workforce) and multilingual-hate-speech\nfrom my point of view, this is a service you cannot replicate at home, either requires smaller models with different architecture, or requires crowd-sourced computational power.\nsaying chatgpt is powered by ray, increasing parallelism.\nbigscience petals colab and petals repo\ndiscord chatroom for reproducing chatgpt\nsince many different models are derived from the original pretrained language model, opendelta can save disk space by freezing main parameters, only tuning few of them.\nthis gpt seems really good. currently only api access.\nbut it is provided by openai which is no longer so “open” in the sense of “open-source”.\nstability.ai is providing alternative open-source implementations of SOTA AI algorithms, which includes carper.ai, eleuther.ai, dreamstudio, harmonai (audio), laion.ai (datasets and projects)"
  },
  {
    "objectID": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#besides-from-decent-processors-ram-and-optimized-runtime-in-order-to-load-llms-fast-one-would-store-the-model-weights-on-ssds.",
    "href": "posts/ffec2fb0-c2fd-492e-8a84-8d8dd06c0096/index.html#besides-from-decent-processors-ram-and-optimized-runtime-in-order-to-load-llms-fast-one-would-store-the-model-weights-on-ssds.",
    "title": "chatgpt",
    "section": "besides from decent processors, RAM and optimized runtime, in order to load LLMs fast, one would store the model weights on SSDs.",
    "text": "besides from decent processors, RAM and optimized runtime, in order to load LLMs fast, one would store the model weights on SSDs.\nnow colossalai supports chatgpt training with a single gpu, using open-source code check humata for paper QA and information extraction/language understanding from PDF files —- the syntax of chatgpt’s response is obviously markdown. in order to be unblocked by chatgpt just because we are using static ip of corp’s wifi, we can connect through our phone’s hotspot. Microsoft’s EdgeGPT needs you to open in Edge browser and join the waitlist of new Bing, having 3rd party API here Merlin is an extension based on ChatGPT which is avaliable for free and all countries, with 11 queries for free each day. Pro subscriptions incoming. Rallio67 builds dataset for RLHF and has released multiple chatgpt-like models on huggingface. namely, joi, chip and rosey, all based on pythia or neox-20b. laion people tend to share loads to CPU in order to run these huge models properly. KoboldAI considered OPT and GPT-Neo as generic LMs. special models like NSFW shits may serve some purposes better. many alternatives, but many are specialized in marketing and content generation, some are chatgpt replica, like chatsonic (with google knowledge) and youchat (from you.com (awesome!)) open assistant now has a data collection website, in which you can only perform tasks given and earn points (working for free? nah?) it is adviced to run this chatgpt program with libraries instead of manually, to prevent issues. my account has been banned from trying chatgpt. though it is not going to be free forever, you need to moderate your input (multi-language support, not only english but chinese) using some api to prevent similar incidents. also some topics outside of blacklist are banned intentionally so you need to check if the model is really producing the answer. if not you should avoid or change the way of asking it. moderation via official openai api, perspective api (free), or via some projects like content moderation deeplearning, bert text moderation, bert-base-uncased-hatexplain, toxic-bert, copilot-toxicity and multilingual-hate-speech-robacofi, train on datasets like hate_speech_offensive, toxicity (by surge-ai, a dataset labelling workforce) and multilingual-hate-speech from my point of view, this is a service you cannot replicate at home, either requires smaller models with different architecture, or requires crowd-sourced computational power. saying chatgpt is powered by ray, increasing parallelism. bigscience petals colab and petals repo discord chatroom for reproducing chatgpt since many different models are derived from the original pretrained language model, opendelta can save disk space by freezing main parameters, only tuning few of them. this gpt seems really good. currently only api access. but it is provided by openai which is no longer so “open” in the sense of “open-source”. stability.ai is providing alternative open-source implementations of SOTA AI algorithms, which includes carper.ai, eleuther.ai, dreamstudio, harmonai (audio), laion.ai (datasets and projects) ## viable approaches to chatgpt according to my point of view, chatgpt is just specialized on chat, or socialized in other words. the elo rating system is the key to facebook social network, many zero-sum games. basically it is some revolution rating system. to do such rating system effectively one shall use along with classifiers and embeddings. according to the training process of instructgpt and webgpt, we know that gpt has learned more by interacting with people (multiple QA), doing self-examination (learning a reward model) and performing actions (searching and quoting on web). ### RLHF #### chainer, prompt engineering awesome chatgpt prompts langchain extending llm by advanced prompts, llm wrappers actions, databases and memories #### RL algorithms, tools for providing feedback Awesome-RLHF paper and code about RLHF openai baselines stable-baselines 3 SetFit Efficient few-shot learning with Sentence Transformers, used by FewShotRLGPT (no updates till now?) #### RLHF models ##### non-language models image_to_text_rlhf algorithm-distillation-rlhf ##### language models chatrwkv pure rnn language model, with chinese support lamda-rlhf-chatgpt blenderbot2 a bot which can search internet, blenderbot3 is US only. install ParlAI then clone ParlAI_SearchEngine. tutorial promptCLUE based on T5, created by clueai, trained on pCLUE openassistant openchatgpt-neox-125m trained on chatgpt prompts, can be tested here, trained from pythia copycat chatgpt replicate medicine-chatgpt shit sick of COVID-19 baby-rlhf both cartpole and languge model rlhf-shapespeare textrl 100+stars PaLM-RLHF claims RETRO will be integrated soon? RL4LMs with multiple rl methods minRLHF webgpt-cli interface openai api to browse web and answer questions lm-human-preferences by openai rlhf-magic using trlx (supports GPT3-like models) which has PPO and ILQL (as trainable model) trl only has PPO on GPT2 Tk-Instruct T5 trained on natural instruct dataset. is it trained on RLHF systems? ### datasets whisperhub collection of chatgpt prompts by plugin hh-rlhf instructgpt samples natural instructions ### dataset building tools open-chatgpt-prompt-collective crowd-kit purify noisy data promptsource ### reward models rankgen scores model generations given a prefix (or prompt) electra-webgpt-rm and electra-large-reward-model is based on electra discriminator ### GPT3-like models galactica is opt trained on scientific data bloomz and mt0 trained on xP3 (multilingual prompts and code) T0PP T0 optimized for zero-shot prompts, despite much smaller than GPT-3 RETRO another model with GPT-3 capabilities with fewer parameters? gpt3 is gpt2 with sparse attension, which enables it to generate long sequence Diffusion-LM PaLM metaseq provides OPT, which is basically GPT3 GPT-JT altered in many ways, trained on natural instructions huggingface space GPT-Neo GPT-J GPT-NeoX Bloom large language model by bigscience ### autonomous learning autonomous-learning-library doc and repo Gu-X doing god-knows-what experiments ## analysis about how to make such model gpt3 is capable of imitation (cause it is unsupervised.) but! if you want to get things done (when you really need it!), you better want some aligned AI. two similar models by openai: webgpt and instructgpt ### about instructgpt it is first fine-tuned on supervised datasets, then train some reward model, then use the reward model to handle prompts and do reinforcement learning with PPO. ### details on webgpt environment guess: create states by performing actions, then generate templates to allow model filling blanks.\nOur text-based web-browsing environment is written mostly in Python with some JavaScript. For a\nhigh-level overview, see Section 2. Further details are as follows:\n• When a search is performed, we send the query to the Microsoft Bing Web Search API, and\nconvert this to a simplified web page of results.\n• When a link to a new page is clicked, we call a Node.js script that fetches the HTML of the\nweb page and simplifies it using Mozilla’s Readability.js.\n• We remove any search results or links to reddit.com or quora.com, to prevent the model\ncopying answers from those sites.\n• We take the simplified HTML and convert links to the special format\n【&lt;link ID&gt;†&lt;link text&gt;†&lt;destination domain&gt;】, or\n【&lt;link ID&gt;†&lt;link text&gt;】 if the destination and source domains are the same. Here,\nthe link ID is the index of the link on the page, which is also used for the link-clicking\ncommand. We use special characters such as 【 and 】 because they are rare and encoded\nin the same few ways by the tokenizer, and if they appear in the page text then we replace\nthem by similar alternatives.\n• We convert superscripts and subscripts to text using ^ and _, and convert images to the\nspecial format [Image: &lt;alt text&gt;], or [Image] if there is no alt text.\n• We convert the remaining HTML to text using html2text.\n• For text-based content types other than HTML, we use the raw text. For PDFs, we convert\nthem to text using pdfminer.six. For all other content types, and for errors and timeouts, we\nuse an error message.\n• We censor any pages that contain a 10-gram overlap with the question (or reference answer,\nif provided) to prevent the model from cheating, and use an error message instead.\n• We convert the title of the page to text using the format &lt;page title&gt; (&lt;page domain&gt;).\nFor search results pages, we use Search results for: &lt;query&gt;.\n• When a find in page or quote action is performed, we compare the text from the command\nagainst the page text with any links stripped (i.e., including only the text from each link).\nWe also ignore case. For quoting, we also ignore whitespace, and allow the abbreviated\nformat &lt;start text&gt;━&lt;end text&gt; to save tokens.\n• During browsing, the state of the browser is converted to text as shown in Figure 1(b).\nFor the answering phase (the last step of the episode), we convert the question to\ntext using the format &lt;question&gt;■, and follow this by each of the collected quotes\nin the format [&lt;quote number&gt;] &lt;quote page title&gt; (&lt;quote page domain&gt;)\n&lt;double new line&gt;&lt;quote extract&gt;■."
  },
  {
    "objectID": "posts/bae26c6f-804c-40ce-ad99-55629d7522cf/index.html",
    "href": "posts/bae26c6f-804c-40ce-ad99-55629d7522cf/index.html",
    "title": "download/collect info of hack tools",
    "section": "",
    "text": "what to do when chatgpt is not for everyone?"
  },
  {
    "objectID": "posts/75081e5b-3fa5-4857-8ae1-47a472634c24/index.html",
    "href": "posts/75081e5b-3fa5-4857-8ae1-47a472634c24/index.html",
    "title": "comprehensive page dump from multiple devices",
    "section": "",
    "text": "i said taking notes manually is always a bad idea if you can just do it with LLM. since web browsing is just like playing video games\nto get latest personal news (like https://github.com/James4Ever0.private.atom?token=&lt;token&gt;), trends from github, use some rss feeds.\nto monitor discord channels, monitor QQ chats, wechat messages and filter links out of it.\nto dump pages and clipboards from devices, which is what we are trying to do.\nbetter keep it tight. when doing so, you want to make it is absolutely private. nothing is public.\nyou can use a filter or something. you can also just keep it discrete."
  },
  {
    "objectID": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html",
    "href": "posts/f867e0e7-a473-4b9a-af9d-d01e7d4c871f/index.html",
    "title": "free proxies: openit proxy pool has been seized, what to do",
    "section": "",
    "text": "there are some code in his repo about scraping proxies. running this on kaggle or github ci providers.\non github search for “clash” “ssr” “proxy” “shadowsocks” “v2ray” “fanqiang” or some keywords obvious to you then sort by “recently updated” since available proxy pool will be constantly updated.\nor you could use lantern."
  },
  {
    "objectID": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html",
    "href": "posts/f65f508f-260b-484f-92e0-dfce948c5925/index.html",
    "title": "cpu/gpu temperature monitor",
    "section": "",
    "text": "we’ve got archey4, a cross-platform sysinfo gather tool, with info on temperature monitor tools"
  },
  {
    "objectID": "posts/b787c379-0a24-41f4-9f5e-40c1e7349186/index.html",
    "href": "posts/b787c379-0a24-41f4-9f5e-40c1e7349186/index.html",
    "title": "hackthebox",
    "section": "",
    "text": "这是一个靶场 和一般的CTF不一样 是有真的服务器在里面的\ndiscord chats"
  },
  {
    "objectID": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html",
    "href": "posts/4ddede5c-aacc-4393-be5e-a227d168b38e/index.html",
    "title": "how to use ai to generate video, distribute them and advertise",
    "section": "",
    "text": "notice: QA based websites are popular now. inspired by that and jumpcut, you can mine summaries/questions/prompts/examples relating to some topic, generating answers/scripts from chatgpt (imagination is the limit)\nvideos are similar by title, author and topic. you demand the bot to generate new embeddings by any “abstractive” means, giving sample embeddings (subtitles, voice, sentiment, music, scene), and output needed embeddings. cool!\nThere are a few different ways you can use AI to generate video content and distribute it for advertising purposes. Here are a few options:\nUse an AI video creation tool: There are several AI tools available that allow you to input text, images, or other media and have the AI generate a video for you. These tools can be useful for creating promotional videos, explainer videos, or other types of content quickly and easily.\nUse an AI-powered video editor: Some video editing software includes AI-powered features that can help you edit and enhance your videos more efficiently. For example, you might be able to use AI to automatically color grade your footage or to stabilize shaky video.\nUse an AI-powered video platform: There are also platforms that use AI to optimize and distribute your video content for maximum reach and engagement. These platforms can help you target specific audiences, measure the effectiveness of your videos, and more.\nIt’s important to note that while AI can be a useful tool for creating and distributing video content, it’s not a replacement for human creativity and insight. The best results will often come from a combination of AI and human input."
  },
  {
    "objectID": "posts/8dbae3bf-81b2-4793-8f82-d28bd719367a/index.html",
    "href": "posts/8dbae3bf-81b2-4793-8f82-d28bd719367a/index.html",
    "title": "lazero search tool document preparation",
    "section": "",
    "text": "because of the diversity of info sources, lazero is a meta search engine"
  },
  {
    "objectID": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html",
    "href": "posts/b906edab-ffa1-4e82-97e6-679b6150b57c/index.html",
    "title": "learn about ai hacking",
    "section": "",
    "text": "you should consider automatic problem generation, post it to chatgpt to get answers. really? how to?"
  },
  {
    "objectID": "posts/93902e98-2508-4d74-80af-9afb6ecff3ae/index.html#lucidrains-is-a-workaholic-on-transformer-implementations.-we-should-scrape-all-the-repos-and-index-them.-there-are-faster-language-models-to-train.",
    "href": "posts/93902e98-2508-4d74-80af-9afb6ecff3ae/index.html#lucidrains-is-a-workaholic-on-transformer-implementations.-we-should-scrape-all-the-repos-and-index-them.-there-are-faster-language-models-to-train.",
    "title": "video generation/modification (vfx) from text",
    "section": "lucidrains is a workaholic on transformer implementations. we should scrape all the repos and index them. there are faster language models to train.",
    "text": "lucidrains is a workaholic on transformer implementations. we should scrape all the repos and index them. there are faster language models to train.\nPhenaki Video, which uses Mask GIT to produce text guided videos of up to 2 minutes in length, in Pytorch dreamix (not open-source) instruct-pix2pix requires 16GB+ VRAM text2live modify video by text prompt (such as add fire in mouth) recurrent-interface-network-pytorch using diffusion to generate images and video high quality! imagegen-video code with demo and paper 抄视频 视频的时间要讲究 看看是抄一年前的好还是抄刚刚发布的好 在发布的一个视频当中 最多抄某个作者的两三个符合要求的片段 use editly smooth/slick transitions and subtitles to beat the copy-detection algorithm, also consider color change in ffmpeg 动态 专栏也可以抄 make-a-video 谷歌AI歌手震撼来袭！AudioLM简单听几秒，便能谱曲写歌 https://www.kuxai.com/article/398"
  },
  {
    "objectID": "posts/8d94f4cd-d5b8-4319-a838-fdc35491066b/index.html",
    "href": "posts/8d94f4cd-d5b8-4319-a838-fdc35491066b/index.html",
    "title": "openai codex chatgpt dalle-2 account registration",
    "section": "",
    "text": "chatgpt is based on instructGPT\nchatgpt interface\nthere are discord chats for openai and hackthebox\nconsider bugmenot to find openai accounts?\nchatgpt sucks. it seems a tailored search engine. it might help filter out useless information. no zeroday exploits (rasp like openrasp) since it does not interact with program and hooks.\norder paid openai accounts here\nif you use openai to register new accounts, try to send sms successfully (may not receive sms even sent) multiple times, you will be blocked\ntutorial on how to use this platform for openai registration"
  },
  {
    "objectID": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html",
    "href": "posts/ea0a5ae1-86b7-44d7-9bb9-bcc5c115f2a0/index.html",
    "title": "prerequisites for running autogpt/open intepreter and multimodal computer agents (such as cybergod), targets, and similar projects collections",
    "section": "",
    "text": "kosmos-2.5"
  },
  {
    "objectID": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html",
    "href": "posts/6792c6e8-11df-4e8c-ba24-f5ad2854cf39/index.html",
    "title": "pyjom schedules",
    "section": "",
    "text": "# pyjom dev schedules\n\n\n## 整活\n\n\n- [ ] 应 急 诈 骗 食 品 (派蒙加Rick Ashley 如何混合？）\n\n\n## recommendation\n\n\n- [ ] use txtai to do NLU and recommend things to people\n\n\n## topic discovery/acquiring\n\n\n### trending topics\n\n\n- [ ] baidu search trending\n\n\n- [ ] sogou trending\n\n\n- [ ] bilibili trending\n\n\n- [ ] wechat trending\n\n\n- [ ] toutiao trending\n\n\n- [ ] tencent trending\n\n\n- [ ] netease trending\n\n\n- [ ] youtube trending\n\n\n- [ ] reddit trending\n\n\n- [ ] twitch trending\n\n\n### popular topics\n\n\n- [ ] baijiahao popular topics\n\n\n- [ ] bilibili popular topics\n\n\n- [ ] douyin popular topics\n\n\n### personal/customized topics\n\n\n- [ ] tencent qq customized (can associate with mail)\n\n\n- [ ] wechat customized\n\n\n- [ ] bilibili per user customized\n\n\n## dog/cat video generation\n\n\n### make render engine runnable\n\n\nissues:\n\n\n- [x] video length too long (10 mins)\n\n\nit was the speed calculation error.\n\n\n- [x] bgm somehow not in sync (too broad bpm/clip ranges?)\n\n\n- [ ] to analyze the peaks (abrupt changes) in bgm and grab louder peaks using pyloudnorm (getting audio volume)\n\n\n```bash\n\n\npip3 install pyloudnorm\n\n\n```\n\n\n```python\n\n\nimport soundfile as sf\n\n\nimport pyloudnorm as pyln\n\n\ndata, rate = sf.read(“0055014.wav”) # load audio (with shape (samples, channels))\n\n\nprint(data.shape)\n\n\nmeter = pyln.Meter(rate) # create BS.1770 meter\n\n\nloudness = meter.integrated_loudness(data) # measure loudness\n\n\nprint(loudness)\n\n\n```\n\n\n- [ ] place video on loudest points, abrupt changes detected by talib or just take direvative and gaussian average\n\n\n- [ ] video too repetitive (small corpus?)\n\n\n- [x] do not remove subtitle and crop active region (reviewer’s resource not used? but i rather advise you to do it directly since it requires less computational power)\n\n\n- [ ] do not have minimum motion threshold (reviewer’s fault? also recommend you to do this in producer)\n\n\n\n\nremove all watermarks, subtitles and crop video boundaries accordingly\nsource video and audio (infinite, basic test is to find 500 sources at once without duplicate, second test is to find 500 second is to find 500 without duplicate twice), improve highlight algorithm\nfind 500 songs without duplicate at once\nfind 500 songs no duplicate twice\nfind 500 animal videos without duplicate\nfind 500 animal videos no duplicate twice\ngenerate appropriate title, cover, info and tags\ncollect feedback after the post\nfind some shocking fonts for cover and subtitle, english and chinese\nmake that karaoke effect\nmake ass with karaoke effect with lrc files\nmake lyrics sync logic fluent, according to what have learned from karaoke effects\nmake selected video clips fluent, no abrupt cuts, maybe we need pyscenedetect? ## text to video, template based video generator (this is perhaps the most complex video generator ever. do it with caution, it might also includes the flipcard, narrator and slideshow based generators) ### generator models subarchitecture (subcategories of template based generators) #### flipcard #### slideshow (video and audio, might also include the dog&cat video!) #### narrator #### summarized video ________________________ ### policy evasion, NSFW filters\nremove all hints from image, video, audio and script that may lead to copyright issues ________________________ ### analyze the media content and metadata, relationships\nanalyze danmaku\nparaphrase the script\ncut the crap and understand each clip’s meaning ________________________ ### process the video clips, like changing the human figure, changing face, stylish the video, adding 2d to 3d effects ________________________ ### process the audio clips, like changing voice, adding sound effects, separating audio/music tracks, ducking ________________________ ### index, retrieve and align video and audio content according to our collected database ________________________ ### retrieve and align video and audio according to our smart search agent (keyword extractor, related words) and do live compilation ________________________ ## qq managing\nmitm chats in friends\nmitm chats in groups\nsource and send pictures to qzone\nsource and send pictures to chat\nreduce posting frequency by group size and feedback\npost relative video link relative to group topic ## personal info collecting and email/sms bulk sending\navoid mail being trashed or turned into junk\ncollect and make mail templates for mail posting ## voice changer\nvst based voice changer\ntrain or find a decent voice generator 御姐音语料库 小受音语料库 请在b站或者qq群里面寻找 或者什么其他的有关的地方寻找 谢谢 ## 直播 live streaming\nsource the video 如果是同一个站的 尽量放一个月以前的视频 半个月以前的音频\nprepare some space for storing live streaming data\nsource the audio\nautomatic interactions\nhandle the vtuber model’s actions"
  },
  {
    "objectID": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html",
    "href": "posts/eb70151f-b5bc-4f08-9dd0-ca4f1462b465/index.html",
    "title": "quantatitive financial stock market analysis",
    "section": "",
    "text": "# quantative financial stock market analysis\n\n\npyportfolioopt\n\n\namplfinance\n\n\n\n造模拟炒股软件 走势跟着大盘 收集用户交易数据 随机假设买卖点 随机假设成交 构成无数虚拟账户交易 或者用某种假设原理拆分不同来源的买卖单 time-series-transformers huggingface blog 深入浅出Python量化交易 配套代码 ## 数据来源 pandas_datareader by yahoo 是国外股票的数据 tushare 国内股票数据 ## 模型建立 open source code for economics modeling in python/julia pandas pipe for streamline processing of real time data time series forcast 有类似的软件 我下载到windows上面过 (agent based simulation/agent based modeling) called altreva adaptive modeler fms 还原持仓的对象 每一个账户都要详细分析 分析每个账户什么时候买入 卖出 还有不买入 不卖出 观望的那些人 所有人都要还原 ## 实盘接口 tools for high frequency trading low latency trading tool 高频交易工具 低延迟交易工具 要抢涨停板 网络必须要好 下单速度要快 joinquant easytrader 实盘易 支持多个客户端 服务端要钱的 sdk都是服务端的client ## tools mytt 通达信公式转换器 funcat 通达信公式转换器 ## models and frameworks general reinforcement learning: https://github.com/DLR-RM/stable-baselines3 crypto trading bot, support all crypto trading markets: https://github.com/freqtrade/freqtrade qlib by microsoft, quantatitive financial analysis: https://github.com/microsoft/qlib reinforcement financial deep learning package: https://github.com/AI4Finance-Foundation/FinRL openbb_terminal: https://github.com/OpenBB-finance/OpenBBTerminal zipline https://github.com/quantopian/zipline pyalgotrade https://github.com/gbeced/pyalgotrade quantaxis: https://github.com/yutiansut/QUANTAXIS vn.py: https://github.com/vnpy/vnpy https://www.vnpy.com/docs/ talib: https://github.com/mrjbq7/ta-lib https://www.programcreek.com/python/example/92322/talib.EMA?msclkid=425d0f6cb5dd11ec9da2a03aa72194cd superalgos: https://github.com/Superalgos/Superalgos https://superalgos.org"
  },
  {
    "objectID": "posts/08f3ffb0-7168-44c7-b57f-a211c8218085/index.html",
    "href": "posts/08f3ffb0-7168-44c7-b57f-a211c8218085/index.html",
    "title": "recycle bin, trash can cli alternative",
    "section": "",
    "text": "trash-cli (with python binding) may work cross-platform, but manage its own recycle bin instead of the system if using windows or macos.\nempty-trash-cli"
  },
  {
    "objectID": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html",
    "href": "posts/a40af93d-6ad7-4f21-b874-5391fc45fa2e/index.html",
    "title": "reset usb",
    "section": "",
    "text": "the same for /sys/bus/usb/drivers/*.\nin case kali failed to detect presence of hard disks, shall you pop up a dialog for us to decide whether to reset to usb or not."
  },
  {
    "objectID": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html",
    "href": "posts/a60440bd-9482-44c5-9844-d747da208f69/index.html",
    "title": "talk to openai chatgpt to learn a few on paraphrasing, title generation",
    "section": "",
    "text": "it’s like a huge search engine which can talk.\ngithub topic on paraphrase\n小发猫\n文章伪原创工具 and backup 有提到用扫描仪来扫描原创文章的方法\nonline paraphrase tool translation based, can process chinese\nchatgpt says creativity matters, such as hackers, video producers and your evil sex shit."
  },
  {
    "objectID": "posts/fe91bcb4-5849-446b-a33a-54c44e8f3192/index.html",
    "href": "posts/fe91bcb4-5849-446b-a33a-54c44e8f3192/index.html",
    "title": "useful sources on cyber attack",
    "section": "",
    "text": "## open source virus/malware in your arsenal\n\n\npowershell obfuscator advanced, will bypass any av\n\n\n### post-exploit framework, evasion\n\n\nthefatrat is an exploiting tool which compiles a malware with famous payload, and then the compiled maware can be executed on Linux , Windows , Mac and Android. TheFatRat Provides An Easy way to create Backdoors and Payload which can bypass most anti-virus. the author has some tools to share.\n\n\npupy is an opensource, cross-platform (Windows, Linux, OSX, Android) C2 and post-exploitation framework written in python and C\n\n\nvenom - C2 shellcode generator/compiler/handler\n\n\n### virus samples\n\n\nthe malware repo\n\n\nopen source virus\n\n\nthezoo A repository of LIVE malwares for your own joy and pleasure. theZoo is a project created to make the possibility of malware analysis open and available to the public.\n\n\nmalwares codebase, botnet\n\n\nopen source malware on github, repo list\n\n\nvirus for win10\n\n\nkafan virus samples\n\n\nvbgood\n\n\ndebugman reverse engineering\n\n\n\nofficial blackhat arsenal under toolswatch category arsenal massive hacking tools collection burpa burp suite automation tool twitter token generator register twitter in batch, has a large proxy list i0gan some hacker with automated tools like awd_script ichunqiu ctf educational resources cyberchief online ctf interactive tools suite bugku tools ctftools curated online tool list ctf online tools kanxue home page, articles 52pojie hack tools kanxue knowledge base ctfshow ctfhub tools 渗透师导航 resources recommended by ctfwiki shellcode storm database can be queried via api exploitdb find exploits, poc code, google hacking database for finding juicy information/urls, shellcodes with an advanced search interface cracking.org OSINT: open source (public source) intelligence is the practice of collecting information from published or otherwise publicly available sources osint tools:\nMaltego\nGoogle dorks\nMitaka\nSpiderFoot\nSpyse\nBuiltWith\nIntelligence X\nDarkSearch.io\nGrep.app\nRecon-ng\ntheHarvester\nShodan\nMetagoofil\nSearchcode\nSpiderFoot\nBabel X"
  },
  {
    "objectID": "posts/eb135d81-fc34-42e6-94e6-10a74bf20e4f/index.html",
    "href": "posts/eb135d81-fc34-42e6-94e6-10a74bf20e4f/index.html",
    "title": "关于伪原创的方法总结 自动软文生成器 一键生成软文 伪原创 文案生成器 自动生成软文",
    "section": "",
    "text": "这些是paraphrase相关的关键字 国外的工具相当齐全了 summarizer paraphraser 看相关的paraphrase的供应商就知道该用什么工具\n国内现成的平台比较多 工具可能欠探索 所以在这里罗列关键字 方便搜索\n搜索相关视频 文章 提取关键字 摘要 然后拼接"
  },
  {
    "objectID": "posts/f51c92c0-ee87-44d6-8fc1-6356d1f6f5b0/index.html",
    "href": "posts/f51c92c0-ee87-44d6-8fc1-6356d1f6f5b0/index.html",
    "title": "变声软件 Morphvox alternatives",
    "section": "",
    "text": "Real Time Voice Cloning by CorentinJ\n感谢关注，UP在B站制作各种AI变声器模型。\nAI白菜原创变声器软件下载链接：\nhttps://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/vits_vc_gpu.7z\n有超级会员的建议下度盘\nhttps://pan.baidu.com/s/1EyM7SzFUpxlemJlrqaJbdQ\n提取码j24b\n已开源的模型在线使用链接（很久以前了）：\nhttps://huggingface.co/spaces/innnky/trump\nhttps://huggingface.co/spaces/innnky/nanami\n白嫖微软azure tts\nAPI下线，原因见动态。\n推理脚本\n声线转换：https://colab.research.google.com/drive/1W6aoDMuTku8EDTuH7-okVaj-6kzbXz1m\nTTS：https://colab.research.google.com/drive/1kpHzOHfWqM4pXxUiqxON9SvDTOeXGNI1\n声线转换模型：https://obs.baimianxiao.cn/share/obs/sankagenkeshi/G_1293000.pth\nTTS模型（多人物）：https://obs.baimianxiao.cn/share/obs/sankagenkeshi/G_809000.pth\nVITS仓库地址 https://github.com/jaywalnut310/vits/\n本模型迭代1300 Epochs\n使用2xA100训练六天，效果还可以。\n感谢国家超级计算广州中心提供的算力支持。\n猫雷唱歌\n在线使用demo（45秒限制）：https://huggingface.co/spaces/innnky/nyaru-svc2.0\n模型github链接：https://github.com/innnky/so-vits-svc\n自己训练数据集、离线使用、一键训练、一键合成：https://github.com/IceKyrin/sovits_guide\n本模型训练使用数据集：猫雷歌回1小时+杂谈回6小时；opencpop5小时 虚拟歌手云灏 半小时\nmoegoe\n多种语言混合tts\nmultilingual tts dl models\n项目地址：https://github.com/luoyily/MoeTTS\nMoeTTS V1.2.1 Update\n适配Windows DPI缩放\n加入中文g2p工具\n加入FFmepg 音频转换工具\n支持批量合成\n支持自定义文件名\n支持VITS语速调节\n修复日语g2p gbk错误\n支持主题切换\nGUI设计优化：\n弃用原项目中的text模块，重写了text to sequence，使用无需再替换symbols，无需替换cleaners 实现模型解压即用\n加入专用配置文件，目前仅用于指定模型symbols\n（另外我这莫得中文模型，去隔壁CjangCjengh那边薅了一个来为视频配音\n基于StarGANv2-VC的声音转换模型\n声音质量当然赶不上VITS这种基于TTS的VC，但效果已经挺不错的了。转换后的语音噪音大应该不是StarGAN的问题i，而是\n后面接的vocoder（用的ParallelWaveGAN）。本来想使用HiFi-GAN的，但找到的预训练模型都和StarGAN不适配，我也不想\n自己从头训一个HiFi-GAN……\nColab Demo:\nhttps://colab.research.google.com/drive/1Xpn9yKBuJD59llXNJOrdUpFuiQNkwDqo?usp=sharing\nGithub：\nhttps://github.com/Francis-Komizu/StarGANv2-VC\nvits可以模仿声优的声线\nsoftvc vits联合模型\nColab demo:\nhttps://colab.research.google.com/drive/1OjfH2zpRkLFRp92aU6jAGhqZNopfZMjC?usp=sharing\n项目代码：\nhttps://github.com/Francis-Komizu/Sovits\n歌曲变声 男的需要提高八度再变声 softvc Vits\n猫雷歌曲变声器 singingvoiceconversion\n派蒙在COLAB上面训练的notebook：\n派蒙语音合成地址：\nhttps://colab.research.google.com/drive/1HDV84t3N-yUEBXN8dDIDSv6CzEJykCLw#scrollTo=oiPvCIJ_MHot\n请注意不要输入英文标点符号（忘记改了）[脱单doge]。切勿商用或进行18+、暴力、血腥内容传播\n这个人还在训练其他人物的语音\nb站有这些插件如何下载的教程\n宿主：Studio One 5\n降噪插件：RX系列Voice De-noise（可替换）\n变声插件：LittleAlterBoy（不可替换）（是目前变声插件的最优选择，实在不行，老版本的Auto Tune也可以）\n压缩器、去齿音：肥波系列Pro-C2,Pro-DS（可替换）\nEQ均衡器：肥波系列Pro-Q3（可替换）\n（再推荐一个soothe2，简单说这个插件可以让声音更自然一些，但是比较贵，可以搜索教学视频了解一下。）\n最后，有问题可以在评论区，私信问我，看到的话会给予解答。\n视频内BGM：\nFluffing a Duck–Kevin MacLeod\nひとときの安らぎ–上松範康\n边境之国的半夏迷梦–花之祭P\nぽかぽかうさぎ日和–川田瑠夏\nリンゴ日和～The Wolf Whistling Song–ROCKY CHACK"
  },
  {
    "objectID": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html",
    "href": "posts/4887de13-b333-4e89-b106-dcf7ddcef5cf/index.html",
    "title": "复读机 Chatbot",
    "section": "",
    "text": "利用带时间戳的QQ消息 提取和天气有关的内容 根据历史天气预报推断群友位置\n根据聊天记录推断群友位置\n测试聊天机器人的方式就是对聊 测试自媒体可以用自动测试 假数据进行测试\n带二维码的图片 二维码对比度要低 避免被qq管家撤回\nclassify bilibili video which users recommend, then train the model against recent chats and topics with video tags\nfor our potential viewers, you may send them popular/hot things, place trackers (短链接统计) on those links, guess their favourites.\nyou may fool bilibili trackers, official parameter-based trackers.\n对于qq上面聊骚的可以发a片给他们\nget bilibili user email address by asking them from chat. if they give the email address, send setu as gift (regularly?)\nof course you need to pass uid to us. either by parameters or by asking.\n建立用户画像 cache足够多的信息 总结出来足够精确的话题 标签\n发点啥吸引人的 提供某种服务 不然就会被踢\n大晚上的不要说话 大家都睡觉 说话容易被踢\n一般被引用的图片 发图之后被回复 图片下面比较激烈的回复代表着图片质量比较好 要取决于图片具体内容进行分类\nnote: in order to install libraries and dependencies, you need ubuntu inside termux. create shortcuts and alias to launch ubuntu. link files and directories to ububtu proot filesystem. also never attempt to update kali since that will break shit, especially for bumping python versions."
  },
  {
    "objectID": "posts/578cd41c-a854-463d-a38c-4ae95dacccfa/index.html",
    "href": "posts/578cd41c-a854-463d-a38c-4ae95dacccfa/index.html",
    "title": "模板创作模式 自媒体 洗稿",
    "section": "",
    "text": "媒体的意义和AI类似 别人知道的就不要发了 有可能出错 别人不知道的就发 有可能有用 在兴趣圈周围探索 拓宽视野"
  },
  {
    "objectID": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html",
    "href": "posts/41ba851b-f785-414c-9812-84d6199b9423/index.html",
    "title": "百度贴吧app接口",
    "section": "",
    "text": "百度贴吧移动端app接口分为："
  },
  {
    "objectID": "posts/bf0191c3-1c1c-4bf6-a7ce-742e4f5f58b2/index.html",
    "href": "posts/bf0191c3-1c1c-4bf6-a7ce-742e4f5f58b2/index.html",
    "title": "Controlling Computers with Hardware Operations and Software Tools: A Comprehensive Guide",
    "section": "",
    "text": "硬件操作电脑\nhttps://github.com/kyegomez/CyberTron\nhttps://github.com/eric-ai-lab/MiniGPT-5\nbubogpt has attached many spacial adaptors, which may help controlling computers\n\nuse larq for low-end neural network training.\n\napplications:\ngame playing/live streaming\nhacking\nassistent\nvirtual worker\ndigital life\n\nhigh level self-replication: ideology reconstruction\nself-consciousness (internal mirror)\nbased on low-level self-replication\n\ninstall snapshot-free oses to eliminate data corruption and save time from rolling back to previous state when running virtual machines, or use docker containers with xfs support.\n\nperform responsiveness check by interval, using some deterministic responses or commands (something (different) must happen because of something)\n\n使用USB3.0录屏卡（HDMI）作为视频输入（类似于摄像头），延迟越低越好\nyou may configure pixel format (jpeg for fast computation) when using different capture cards\n为了通用一般用专门的硬件键鼠模拟器 或者带OTG的RPi模拟键鼠 接收操控方电脑的指令 输出HID信号\n\nreference\nFor recent raspbian you only need to turn on overlay switch in system configuration. (do not use other tools, since they will interfere)\nFor debian-like distros (ubuntu) you can use bilibop-lockfs or fsprotect (install/enable aufs-dkms or overlay filesystem before that)\nFor linux that is set to run in ram (tinycore linux), you can use it as-is, but it may oom so quick that you have to abandon it.\n\nstackoverflow 提到可以用蓝牙进行鼠标键盘模拟 (requires extra setup)\nLinux有驱动可以实现HID输出\nUse USB Gadget with OTG cables.\n用台湾的数据线\nRPi4支持OTG（通过USB-C供电接口） micro HDMI需要转接\nscrcpy –otg 可以识别周边设备 发送HID指令\n定时开关机电源线 加类似于Deep Freeze或者Live CD机制 使得电脑可以接收任意操作而不崩溃\npython usb-gadget wrapper"
  },
  {
    "objectID": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html",
    "href": "posts/5061f4e6-2fe3-4ba5-8568-2b4c52d9b10a/index.html",
    "title": "能源优化配置（购置，设计）计算投资收益 自动控制（能源调度）预测",
    "section": "",
    "text": "to speed up numpy performance, either use multicore enabled BLAS library, intel MKL or use cupy (ROCm ready)\nto check if numpy is not using multicore, run:\nuse scipy.optimize\ngurobi v9.0 cracked keygen\ngurobi v9.0 破解版和使用教程\noperations research (OR) is somehow related to machine learning and artificial intelligence. there’s a book for reference. however, a solid solver is the backbone of energy system optimization.\ntechnical terms for operations research:\ntechnical terms for integrated systems:\npaid IES simulation & optimization code collection by 研学社, use for searching the names elseware to get for free\npyVISA is a Python package that enables you to control all kinds of measurement devices independently of the interface (e.g. GPIB, RS232, USB, Ethernet). VISA is a protocol (almost) shared by all modern hardware connection standards\na list of energy models including “domenestic hot water” on openmod.org\nOpen Energy System Models on wikipedia, including Electricity sector models and Energy system models\nmultiple SciML and neural network related differential equation projects were found on github topic ODE\n图书： 能源互联系统的最优控制与安全运行 涉及到综合能源系统稳态与暂态建模\n推荐购买图书 未来能源技术丛书 综合能源系统建模 从入门到实践 有多系统耦合调优的代码实践 mentioned CPLEX solver from IBM\nAi4Energy (浙江大学的项目) and 智慧能源系统导论—综合能源系统建模、仿真、优化与控制课程\nwikipedia maintains a list of mathematical optimization software including modeling tools and various solvers\na huge collection of up-to-date tools called open sustainable technology by protontypes has been found.\nin order to execute control in real time, either FPGA or RTOS like RT-Lab is used (maybe not needed?)\nin simulation, unlike real-world systems, can be quite “chess-like”. you can pause the system, revert the operation, revert the time, in order to manually control all components to guide the system to optimal.\n微电网 (microgrid) 耦合优化调度 综合能源系统 优化调度 电气热耦合\nCCHP: Combined Cooling, Heat and Power\nweibull distribution\ndifferential equations: ODE (Ordinary Differential Equation), SDE (Stochastic Differential Equation), DDE (Delay Differential Equation), DAE (Differential Algebraic Equation)\nwhat they are talking is SCADA: supervisory control and data acquisition. SCADAS by siemens is for signal processing and recording. is it the system used in the current project? nope. is SCADAS similar to SCADA? yes."
  },
  {
    "objectID": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html",
    "href": "posts/4a155226-8aa5-4d6c-b799-00088190b9d6/index.html",
    "title": "识别视频语言",
    "section": "",
    "text": "speechbrain has features of Speech Recognition, Speaker Recognition, Speech Enhancement, Speech Processing, Multi Microphone Processing, Text-to-Speech, and also supports Spoken Language Understanding, Language Modeling, Diarization, Speech Translation, Language Identification, Voice Activity Detection, Sound classification, Grapheme-to-Phoneme, and many others."
  },
  {
    "objectID": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#variables",
    "href": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#variables",
    "title": "Example Pydoc",
    "section": "Variables",
    "text": "Variables\n\nVariable global_var\nsome global variable2 Default to None\n\n\nVariable global_var2\nsome other global variable"
  },
  {
    "objectID": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#functions",
    "href": "posts/a9ca02ba-908b-474f-9c09-714c07c7b196/index.html#functions",
    "title": "Example Pydoc",
    "section": "Functions",
    "text": "Functions\n\nFunction some_random_method\n\ndef some_random_method(\n\n\n    param_1: str,\n\n\n    param_2,\n\n\n    kw_param_1=None\n\n\n) ‑&gt; None\n\njust a random method\nArgs\n—–=\n\nparam_1 : str\n\nparameter at position 1\n\nparam_2 : str\n\nparameter at position 2\n\nkw_param_1 : Any, optional\n\nkeyword parameter 1. Defaults to None.\n\n\nReturn\n—–=\nNothing returned.\nNote\n—–=\nExtra Notes?\nimport os\nos.system(\"ls -lth\")"
  }
]