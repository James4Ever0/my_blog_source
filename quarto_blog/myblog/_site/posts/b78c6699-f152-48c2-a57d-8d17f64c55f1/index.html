<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-01-09">
<meta name="description" content="This article highlights the importance of using effective video editing tools and analyzing social media data to create, improve, and predict the success of viral videos and live streaming content. It delves into various methods and techniques that can help enhance the impact of such content, ultimately leading to increased engagement and visibility on social media platforms.">

<title>James’ Blog - Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">James’ Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/james4ever0" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Everything you need to startup your media project: viral video generator, viral video analyzer, trend analyzer, automated email account registration, download only a portion of video, peek video screenshots</h1>
  <div class="quarto-categories">
    <div class="quarto-category">videos</div>
    <div class="quarto-category">social media</div>
    <div class="quarto-category">video editing tools</div>
    <div class="quarto-category">live streaming</div>
    <div class="quarto-category">data analysis</div>
    <div class="quarto-category">viral videos</div>
    <div class="quarto-category">success prediction</div>
  </div>
  </div>

<div>
  <div class="description">
    This article highlights the importance of using effective video editing tools and analyzing social media data to create, improve, and predict the success of viral videos and live streaming content. It delves into various methods and techniques that can help enhance the impact of such content, ultimately leading to increased engagement and visibility on social media platforms.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 9, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<hr>
<p>use grammar or state machine to constraint how llm generate tokens, in order to perform actions and call tools correctly</p>
<hr>
<p><a href="https://github.com/facebookresearch/seamless_communication">voice auto translation</a> by meta</p>
<hr>
<p>use attention visualization to create pan effects, focus on different parts and illustrate separately</p>
<hr>
<p>to get response fast, you need to create content fast. sometimes it is important to degrade aspects like resolution and more.</p>
<hr>
<p>https://github.com/audio-agi/audiosep</p>
<p><a href="https://github.com/dgtlmoon/changedetection.io">changedetection</a> get website updates</p>
<p><a href="https://github.com/dvlab-research/LongLoRA">longlora</a></p>
<p>自动删评机器人：</p>
<p>根据对类似内容的评论预期（结合大模型）进行删除</p>
<p>根据情感分析删除不利评论</p>
<hr>
<p>根据视频内容 标题调整封面人物表情</p>
<hr>
<p>造仿制b站 收集用户点击数据</p>
<hr>
<p>b站禁用了手机端搜索接口的页面数目，但没有限制电脑端搜索页面数目，估计是为了避免二创素材收集不受影响。</p>
<hr>
<p><a href="https://dambooru.donmai.us">deep danbooru</a> for anime comprehension, scene understanding etc</p>
<hr>
<p>Do not use removable drives (NAS?) as scratch/data disk for long-term programs. Instead, use internal drives.</p>
<p>If possible, first sync all necessary files from removable drives to internal disk, then run the long-running program from there, or first run from rootfs, then jump to removable drives. When error occurs, check if disk is unmounted, try different methods to reload them and rerun the program.</p>
<p>Another possible cause is insufficient current. Check for similar issues online.</p>
<hr>
<p>短视频内部模拟不同视频上下翻页效果</p>
<hr>
<p>如果封面提取关键词进行训练并更换 尝试自己生成配图和文字的方法难以实现 可以考虑更换字体和色彩 文字内容不变</p>
<p>封面文字遵循一定的阅读顺序 从上到下 从左到右 可以设立排版以及合并（用于训练）规则</p>
<hr>
<p>youtube now can auto generate video chapters, which might be part of text/video summarization.</p>
<p>multinational, multilingual, subtitles, localizations</p>
<hr>
<p>models for content generation:</p>
<p><a href="https://github.com/OFA-Sys/OFA">one-for-all</a> multi-modal generation</p>
<p><a href="https://github.com/Aleph-Alpha/magma">magma</a>: a GPT-style multimodal model that can understand any combination of images and language</p>
<hr>
<p><a href="https://www.aewz.com/">视频创作导航</a> 可以用来找自动化创作视频的思路</p>
<p><a href="https://www.hellofont.cn/font-list">字由</a> 识别字体 下载免费字体</p>
<p><a href="https://github.com/alexanderisora/startuptoolbox/blob/master/README.md">Startup Toolbox</a></p>
<p>tools for startup companies, including:</p>
<pre><code>[Website]
[Design]
[Support and customer communication]
[Payments, billing and distribution]
[User Analytics and Reporting]
[Business Analytics]
[Automation]
[HR and Payroll]
[Forms and Surveys]
[Tech]
[Product building]
[Marketing and growth]
[Collaboration]
[Build a chatbot]
[Domains and naming]
[Legal, Account and Invoicing]
[Funding]
[Sales]
[Communities]
[Learn]
[A/B testing]
[Launch]
[Other]
</code></pre>
<p><a href="https://github.com/VertioseLabs/Awesome-Streaming">Awesome Streaming</a></p>
<p>a list of live streaming and content creation tools:</p>
<pre><code>[Content Creation]
[Sponsors And Affiliate]
[Setup Guides]
[Branding]
[Discord Creation]
[Brand Website]
[Uncopyrighted Music]
[FPS Accuracy]
[Subathon Framework]
[Video Editing]
[OpSec]
[Stat Tracking]
[Game Development]
[V-Tubing]
[How To Start An LLC]
</code></pre>
<p>收集大up主的名字 根据提取出来的名词 清除文案中的含有名字的句子</p>
<p>for information cascade, treat recommendation system as your target data, and fit your content into the prediction of “to-view” video of popular videos</p>
<p>分析弹幕关键词是否与大量其他视频标题相重合</p>
<p>B站撞车搬运检测：</p>
<p>油管有带有英文番剧名称的AMV/MAD剪辑</p>
<p>通过B站搜索Weibo Tumblr Tiktok Youtube的视频ID 或者名称，可以找出视频是否被转载</p>
<p>通过搜索其他网站的前缀 比如<code>https://www.youtube.com</code> 可以得到被转载视频的链接 但是感觉数据不是很靠谱 不是很火的那种 要看大流量的还是得爬首页推荐链接 根据话题搜索</p>
<section id="video-highlights-extraction" class="level2">
<h2 class="anchored" data-anchor-id="video-highlights-extraction">video highlights extraction</h2>
<p>although you may want to train/extract that manually, it would sure be tedious and not self-updating (unless using reinforcement learning).</p>
<p>often we determine highlights by sound, visual and voice together. highlights often can be identified without too much context, so it can be chunk based.</p>
<section id="bilibili" class="level3">
<h3 class="anchored" data-anchor-id="bilibili">bilibili</h3>
<p><a href="https://github.com/SocialSIsterYi/bilibili-API-collect/blob/master/video/pbp.md">b站的高能进度条</a> 在油管被叫做”most replayed”</p>
<p>b站有弹幕 所以可以根据弹幕找到精彩片段 <a href="https://github.com/baolintian/VClimax">VClimax</a>是一个浏览器插件 可以通过弹幕单位时间增长速率，设置相关的阈值，来定位最精彩的内容 (弹幕密度怕还是得要分析) 跳转部分番剧OP 视频搞笑片段精准定位 (怕还得是要机器学习)</p>
<p><a href="https://github.com/ZhangEliot/bilibiliDanmuSkip">bilibili Danmaku Skip</a> is another browser plugin which will identify highlights by analyzing danmaku with parameters like threshold, interval and bias</p>
</section>
<section id="youtube" class="level3">
<h3 class="anchored" data-anchor-id="youtube">youtube</h3>
<p>youtube’s most played data can be extracted by:</p>
<p><a href="https://www.npmjs.com/package/youtube-heatmap">youtube-heatmap</a> (nodejs, using puppeteer (bad!))</p>
<p><a href="https://github.com/Benjamin-Loison/YouTube-operational-API">youtube operational api</a>’s (powered by shared API keys and info extractors without key), while apparantly <a href="https://github.com/Woojin-Choi/youtube-most-replayed/blob/master/src/App.js">youtube-most-replayed</a> is using this service to retrieve the data from <a href="https://yt.lemnoslife.com">yt.lemonslife.com</a> powered by this library</p>
<p><a href="https://github.com/Benjamin-Loison/YouTube-operational-API/blob/main/videos.php">heatmap extractor</a></p>
<p><a href="https://github.com/LuanRT/YouTube.js">youtube.js</a> (reverse engineered innertube api) added <a href="https://github.com/LuanRT/YouTube.js/pull/263">support for chapters and video heatmap</a></p>
</section>
</section>
<section id="youtube-dl-search-youtube-video" class="level2">
<h2 class="anchored" data-anchor-id="youtube-dl-search-youtube-video">youtube-dl search youtube video</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">youtube-dl</span> <span class="st">"ytsearch[optional_result_limit]:[query]"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># pass query url directly to allow pagination or filters</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="ex">youtube-dl</span> <span class="st">"https://www.youtube.com/results?search_query=how+to+create+android+app+in+android+studio&amp;page=1"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="record-live-streaming-video-upload-video" class="level2">
<h2 class="anchored" data-anchor-id="record-live-streaming-video-upload-video">record live streaming video, upload video</h2>
<section id="biliup-biliup-rs-commandline-program" class="level3">
<h3 class="anchored" data-anchor-id="biliup-biliup-rs-commandline-program"><a href="https://github.com/biliup/biliup/">biliup</a> &amp; <a href="https://github.com/ForgQi/biliup-rs">biliup-rs</a> (commandline program)</h3>
<p>全自动录播、投稿工具，也支持twitch、ytb频道搬运。提供分p上传b站接口</p>
<p>其实直播回放没有什么好看的 很单调 另外b站上传之后可以获得视频预测标签</p>
</section>
<section id="youtube-automation-toolkit-post-same-content-to-multiple-platforms-bilibili-douyin-douyu-instagram-reddit-spotify-tiktok-twitch" class="level3">
<h3 class="anchored" data-anchor-id="youtube-automation-toolkit-post-same-content-to-multiple-platforms-bilibili-douyin-douyu-instagram-reddit-spotify-tiktok-twitch"><a href="https://github.com/wanghaisheng/youtube-automation-toolkit">youtube automation toolkit</a> post same content to multiple platforms: bilibili, douyin, douyu, instagram, reddit, spotify, tiktok, twitch</h3>
<p>though the idea is correct by posting original content to multiple platforms to prevent pirating, but the description/title generation is a vital part of the process, which must be done intelligibly (AI or human). as for now the repo is just full of links. if you want tools you click given link.</p>
</section>
</section>
<section id="download-a-portion-of-video" class="level2">
<h2 class="anchored" data-anchor-id="download-a-portion-of-video">Download a portion of video</h2>
<section id="yt-dlp-latest" class="level3">
<h3 class="anchored" data-anchor-id="yt-dlp-latest">yt-dlp (latest)</h3>
<p>check <code>pyjom/tests/download_sections_video_portion_partial_download_youtube_yt_dlp_bilibili/test_bilibili.sh</code> for advanced usage of yt-dlp and more on bilibili parsing.</p>
<p><strong>SINCE YT-DLP IS UPDATED YOU CAN USE <code>--download-sections</code> ARGUMENT FOR YOUTUBE</strong></p>
<p>If you want to download multiple sections of same video, you must specify video output format string via <code>-o</code></p>
<p>But when using that without “–force-keyframes-at-cuts” (skip re-encoding which can speed up thing but not ensuring quality of video at tail), you better keep margin at tail for 10 seconds (could glitch at last 5 seconds) and head for 5 seconds (maybe head margin is not needed?).</p>
</section>
<section id="youtube-dl" class="level3">
<h3 class="anchored" data-anchor-id="youtube-dl">youtube-dl</h3>
<p>first acquire download url: <code>youtube-dl [--youtube-skip-dash-manifest] [-f 18] -g "https://www.youtube.com/watch?v=V_f2QkBdbRI"</code> (you need to force the format.)</p>
<p>then use ffmpeg with the url to chop the slice: <code>ffmpeg -ss 00:00:15.00 -i "OUTPUT-OF-FIRST URL" -t 00:00:10.00 -c copy out.mp4</code></p>
</section>
<section id="rangedownloader-by-a-soul-database" class="level3">
<h3 class="anchored" data-anchor-id="rangedownloader-by-a-soul-database"><a href="https://github.com/A-Soul-Database/RangeDownloader">RangeDownloader</a> by A-Soul-Database</h3>
<p>A-Soul-Database is a live-streaming replay record database designed for vtubers, organized in some way for easy information retrieval.</p>
<p>RangeDownloader is acting like a server, though sometimes we are not sure how fast(er) it can really be.</p>
</section>
</section>
<section id="viral-videos" class="level2">
<h2 class="anchored" data-anchor-id="viral-videos">Viral videos</h2>
<section id="data-sources-and-monitors" class="level3">
<h3 class="anchored" data-anchor-id="data-sources-and-monitors">Data sources and monitors</h3>
<section id="rebang.today" class="level4">
<h4 class="anchored" data-anchor-id="rebang.today"><a href="https://www.rebang.today">Rebang.today</a></h4>
<p>通过B站推荐标签接口可以得到观众的实时需求</p>
<p>提供全站 知乎 微博 IT之家 百度 虎扑 直播吧 少数派 36氪 吾爱破解 天涯 小众软件 反斗限免 哔哩哔哩 抖音 技术期刊 v2ex GitHub的热榜</p>
<p>API：<code>https://api.rebang.today/v1/items?tab=&lt;TAB_NAME&gt;&amp;page=&lt;PAGE_NUM&gt;</code> (potential parameters: sub_tab, date_type (default:now))</p>
<p>知乎有个专门的热榜，地址：<code>https://www.zhihu.com/billboard</code></p>
<p><a href="https://www.zhihu.com/roundtable">知乎圆桌</a> <a href="https://www.zhihu.com/explore">知乎发现</a> | name | tab | | — | — | | 全站热榜 | top-all | | 微博 | weibo | | V2EX | v2ex | | 知乎 | zhihu | | 哔哩哔哩 | bilibili| | GitHub | github| | 抖音 | douyin| | 技术期刊 |journal-tech| | 虎扑| hupu| | 少数派 | sspai| | 百度 | baidu| | 36氪 | 36kr| | 天涯 | tianya| | 吾爱破解 | 52pojie| | IT之家 | ithome| |全站24小时 | top-daylong| |直播吧 | zhibo8| |小众软件 |appinn| |反斗限免| apprcn|</p>
</section>
<section id="番茄数据" class="level4">
<h4 class="anchored" data-anchor-id="番茄数据"><a href="https://www.tomatodata.cn/news/1355.html">番茄数据</a></h4>
<p>番茄数据提供了从近24小时–近90天B站的最新热门视频，你既可以通过“搜索标题、简介、标签、评论出现关键词”，也可以通过行业分类、播放数、点赞数、投币数、视频时长、观众画像等高级条件，精准定位想要查找领域的热门视频。传播指数的计算方法有待研究。传播指数是根据UP主的粉丝数、视频点赞数、播放数、投币数、分析数等分析出来的综合得分。根据评论热词分析视频观众热点，根据评论用户分析用户画像。</p>
<p>对于各大数据网站 都存在一个收录的接口 如果up主从来没有上过首页 大概率不会被收录 需要手动提交 间接说明大up主是如何被找到的</p>
</section>
</section>
<section id="image-recognizers" class="level3">
<h3 class="anchored" data-anchor-id="image-recognizers">Image recognizers</h3>
<section id="baidu-image-recognizer-百度识图" class="level4">
<h4 class="anchored" data-anchor-id="baidu-image-recognizer-百度识图"><a href="https://github.com/chenguanyou/BaiduSerchImgApi">Baidu Image recognizer</a> 百度识图</h4>
<p>与此相关的识图项目位置：<code>pyjom/tests/search_engine_suggestion_based_qa_bot</code></p>
<p>可以获取关键字，标签，同样的图，秒懂百科视频，百度百科数据，包含图片的信息，颜值信息</p>
<p>通过把上传接口修改 以及http改成https 现在可以继续使用</p>
<p>位置：<code>pyjom/tests/viral_video_experiments/BaiduSerchImgApi</code></p>
<p>通过http改成https 修改好了<a href="https://github.com/chenguanyou/360ImageSearch">360识图的接口</a></p>
<p>位置：<code>tests/viral_video_experiments/360ImageSearch</code></p>
</section>
</section>
<section id="video-collectors" class="level3">
<h3 class="anchored" data-anchor-id="video-collectors">Video collectors</h3>
<section id="tiktok-compilation-video-generator" class="level4">
<h4 class="anchored" data-anchor-id="tiktok-compilation-video-generator"><a href="https://github.com/HA6Bots/TikTok-Compilation-Video-Generator">tiktok compilation video generator</a></h4>
<p>collect popular video on tiktok by multiple filters such as hashtags, categories , popularities and search queries</p>
</section>
<section id="weibospider" class="level4">
<h4 class="anchored" data-anchor-id="weibospider"><a href="https://github.com/nghuyong/WeiboSpider">WeiboSpider</a></h4>
<p>需要cookie 收集用户信息 用户粉丝列表 用户关注列表 微博采集 微博评论采集 微博转发采集 基于关键词的微博检索</p>
</section>
<section id="bottuber-a-instagram-compilation-reposter-to-youtube" class="level4">
<h4 class="anchored" data-anchor-id="bottuber-a-instagram-compilation-reposter-to-youtube"><a href="https://github.com/sam5epi0l/BotTuber">botTuber: a instagram compilation reposter to youtube</a></h4>
<p>Using <code>instaloader</code> and <code>instalooter</code>, it can download videos from instagram. It merges a series of video and add intro and outro. It only contains one default title starts with “TRY NOT TO LAUGH” in its “auto” mode.</p>
</section>
<section id="reddit-hot-videos-to-youtube" class="level4">
<h4 class="anchored" data-anchor-id="reddit-hot-videos-to-youtube"><a href="https://github.com/spantheslayer/yt-upload-automation">reddit hot videos to youtube</a></h4>
<p>In “TiktokCringe” reddit channel, we are able to get hot posts and video links prefixed by <code>https://v.redd.it</code> (from tiktok to reddit) in json format: <code>https://www.reddit.com/r/TikTokCringe/hot.json?limit=12</code>. This link looks like some API or subscription. Maybe Bilibili and other sites have similar “hot” json urls. The way to extract video links is in <a href="https://github.com/spantheslayer/yt-upload-automation/blob/main/atmt.sh">atmt.sh</a>. It adds transitions to every video clip.</p>
</section>
</section>
<section id="video-editors" class="level3">
<h3 class="anchored" data-anchor-id="video-editors">Video editors</h3>
<section id="vced" class="level4">
<h4 class="anchored" data-anchor-id="vced"><a href="https://github.com/datawhalechina/vced">vced</a></h4>
<p>i think it needs to be fine-tuned on large diversive training data.</p>
<p>VCED 可以通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑。该项目基于跨模态搜索与向量检索技术搭建，通过前后端分离的模式，帮助你快速的接触新一代搜索技术。</p>
</section>
<section id="videofy" class="level4">
<h4 class="anchored" data-anchor-id="videofy"><a href="https://github.com/mohtamohit/Videofy">videofy</a></h4>
<p>it is a self-hosted service, summarize article, get relevant text and image, determine mood to select BGM. try for yourself!</p>
</section>
<section id="meme-video-maker" class="level4">
<h4 class="anchored" data-anchor-id="meme-video-maker"><a href="https://github.com/FOLLGAD/meme-video-maker/blob/a9bc7bc3f804da05353faa23fde56cff410f16bb/server/src/video.ts">meme video maker</a></h4>
<p>It uses google cloud to select “English” words on image, enable the user to edit the “stage” to show meme step by step.</p>
<p>It requires amazon cloud services and google cloud services.</p>
</section>
<section id="回声工坊-trpg-replay-generator" class="level4">
<h4 class="anchored" data-anchor-id="回声工坊-trpg-replay-generator"><a href="https://github.com/DanDDXuanX/TRPG-Replay-Generator">回声工坊 TRPG Replay Generator</a></h4>
<p>TRPG：桌上角色扮演游戏 有丢骰子（随机元素）的RPG</p>
<p>角色立绘可以是动态的 但是是多个png文件</p>
<p>背景可以设定为 <code>{'black','white','greenscreen'}</code> 中的一个，以建立纯色背景</p>
<p>Has special requirements to media sources. Use <code>.ogg</code> format for BGM. Use <code>.wav</code> format for AFX and voices. Use <code>.png</code> for image. Cannot get background video layers working so you might consider some “green screen” effects.</p>
<p>Use <code>--ExportVideo</code> flag to export video without GUI.</p>
</section>
<section id="openshot-and-libopenshot-for-python-bindings" class="level4">
<h4 class="anchored" data-anchor-id="openshot-and-libopenshot-for-python-bindings">openshot and libopenshot (for python bindings)</h4>
<p><a href="https://github.com/thomashuss/nightcoreify/blob/545265c054c0d127b6dd81d4038f56c8c092a739/nightcorei.py#L38">Nightcorify</a> is accelerating audio and raising pitch (<code>asetrate</code> strenches the timeline to change sample rate, <code>atempo</code> (not used in here) change the timeline but not the pitch, while <code>aresample</code> changes the sample rate but not timeline), also showing audio wave shape with <code>showwaves</code>.</p>
<p>This library is complex <strong>AND WITHOUT PROPER DOC FOR PYTHON</strong> thus not recommend for using</p>
</section>
<section id="keybert-and-summarization-transformer-pipeline" class="level4">
<h4 class="anchored" data-anchor-id="keybert-and-summarization-transformer-pipeline"><a href="https://github.com/pawanreddy-u/videocreation/blob/main/generateVideo.py">keybert and summarization transformer pipeline</a></h4>
<p>Check <a href="https://huggingface.co/transformers/v4.10.1/_modules/transformers/pipelines.html">docs on transformers pipelines</a> for default and fine-tuned task-specific models for each pipeline.</p>
<p><a href="https://pypi.org/project/keybert/">Keybert</a> uses “sentence-transformers”. The author would advise either “all-MiniLM-L6-v2” for English documents or “paraphrase-multilingual-MiniLM-L12-v2” for multi-lingual documents or any other language. <a href="https://huggingface.co/models?pipeline_tag=summarization&amp;sort=downloads&amp;search=multi">Search</a> for “multi” with tag “summarization in huggingface, then you would get huge models. A <a href="https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum">mT5</a> model is very large, size upto 2.33GB</p>
<p>Keywords-image pairs can be used for CLIP model training.</p>
</section>
<section id="watson-based-video-maker" class="level4">
<h4 class="anchored" data-anchor-id="watson-based-video-maker"><a href="https://github.com/talesdsp/video-maker">watson based video maker</a></h4>
<p>It first downloads wikipedia content from algorithmia, then uses regex to filter out unwanted parts, uses watson AI for sentence cutting, set a limit for max sentences (notice: not summarization), then search image with keywords, finally create video.</p>
<p>In <a href="https://github.com/maykbrito/automatic-video-creator/blob/b37d93651e016ac3f8a0731289d84764802c7afc/robots/input/trends.js">another similar project</a> IMDB (Popular Film/TV series) and Google search trends (as RSS) are included.</p>
</section>
<section id="auto-editor" class="level4">
<h4 class="anchored" data-anchor-id="auto-editor"><a href="https://github.com/WyattBlue/auto-editor">Auto-Editor</a></h4>
<p>By passing <code>--edit</code> option, you can remove unwanted parts identified by motion or audio (can be combined). It can import clip with manual “cut-out”. It can export as json.</p>
</section>
<section id="pictory" class="level4">
<h4 class="anchored" data-anchor-id="pictory"><a href="https://pictory.ai/">Pictory</a></h4>
<p>Leveraging 3 millions of tagged video clips and audio, choosing most semantically similar clip to current scene (by extracting keyword -&gt; search images -&gt; compare images to video sources with all embedding things going under the hood (CLIP)), map video word by word to the timeline (to create extractive highlights and remove unwanted words like “um”)</p>
</section>
<section id="wisecut" class="level4">
<h4 class="anchored" data-anchor-id="wisecut"><a href="https://www.wisecut.video">Wisecut</a></h4>
<p>Short videos can attract your viewers and converting them into followers (to view more of your long videos). <a href="https://www.wisecut.video/post/leverage-short-videos-to-grow-your-audience">Make short videos</a> with music, subtitles and facial recognition auto-reframe (detect main speaker). It match the right BGM with the type of content, with audio ducking, which can be achieved with ffmpeg or editly.</p>
<p>It is listed among an <a href="https://github.com/mhmmyu/awesomeAI">AI marketing tools list</a>, which mentions copywriting, social media/email/blog marketing text/content generation (like <a href="https://copy.ai">copy.ai</a>), text to video</p>
</section>
<section id="jumpcutter" class="level4">
<h4 class="anchored" data-anchor-id="jumpcutter"><a href="https://github.com/potato3d/jumpcutter">Jumpcutter</a></h4>
<p>An audio-slience based video cutter. In <code>jumpcut_file.py</code> it chops audio into chunks and decide if it is slience or not. The core logic is to first compare max volume of each chunk against threshold, then check in neighbors of every chunk if all of them are slient and cut them out. It has audio speed changing methods from <a href="https://pypi.org/project/audiotsm/">audiotsm</a>.</p>
<p>In <a href="https://github.com/madsbacha/jumpcut/blob/master/jumpcut.py">another implementation</a>, it uses ring buffer by <code>collections.deque</code> and applies VAD (Voice Activity Detetion) by <a href="https://pypi.org/project/webrtcvad/">webrtcvad</a> to every chunk of audio.</p>
</section>
<section id="gifcurry" class="level4">
<h4 class="anchored" data-anchor-id="gifcurry"><a href="https://github.com/lettier/gifcurry">Gifcurry</a></h4>
<p>Adding text to video, has typing effects, written in haskell. You can add <code>-m</code> flag to export video instead of GIF.</p>
</section>
<section id="backgroundremover" class="level4">
<h4 class="anchored" data-anchor-id="backgroundremover"><a href="https://github.com/nadermx/backgroundremover">Backgroundremover</a></h4>
<p>A commandline tool powered by torch, removing background from images and video</p>
</section>
<section id="moviepy-most-loved-commandline-video-editor" class="level4">
<h4 class="anchored" data-anchor-id="moviepy-most-loved-commandline-video-editor"><a href="https://github.com/Zulko/moviepy">Moviepy</a> most loved commandline video editor?</h4>
<p>There are some <a href="https://zulko.github.io/moviepy/examples/moving_letters.html">cool text effects</a> called “Text with moving letters” (PPT-like), and a <a href="https://zulko.github.io/moviepy/examples/dancing_knights.html">dancing video generator</a> based on tempo finder and video loop maker, which can help you adjust video speed according to video period and music bpm. The <a href="https://zulko.github.io/moviepy/examples/star_worms.html">Star-Wars Text Effect</a> reminds me of easing functions used with page scrolling.</p>
</section>
</section>
<section id="data-collectanalyze" class="level3">
<h3 class="anchored" data-anchor-id="data-collectanalyze">Data collect/analyze</h3>
<p>Social media statistics are time series data which should be collected regularly and predictable with time forcasting models.</p>
<section id="open-sir" class="level4">
<h4 class="anchored" data-anchor-id="open-sir"><a href="https://github.com/open-sir/open-sir">open-sir</a></h4>
<p>Use sirx over sir.</p>
<p>I think it is hard to use. Many “presumed” parameters are out there. It can fit “reproduction rate” but no individual “alpha” and “beta” values.</p>
<p>In tradirional SIR models, beta is infection rate, gamma is recovery rate. While in open-sir it is different. alpha now is beta, beta now is gamma.</p>
</section>
<section id="youtube-viral-video-machine-learning-analysis" class="level4">
<h4 class="anchored" data-anchor-id="youtube-viral-video-machine-learning-analysis"><a href="https://github.com/gdemos01/yttresearch-machine-learning-algorithms-analysis">Youtube Viral Video Machine Learning Analysis</a></h4>
<p>Refer to this <a href="https://github.com/gdemos01/yttresearch-machine-learning-algorithms-analysis/blob/master/Documentation/Thesis.pdf">document</a> for details in data collection and machine learning methods.</p>
<p>Usage:</p>
<p>You can decide whether to copy a video or not when it is posted for only a few days.</p>
<p>Dataset creation:</p>
<p>Monitoring video right at the time it is posted, monitor for a few days, calculate features, then wait for a month or two (it must stablize then), judge the video is viral or not by view counts.</p>
<p>Using multiple machine learning techniques, there are some top features matters the most for viral video forecasting (though you can derive your own by collecting more data (like the follower-view theory if applied), and beware if your video all sucks, you may not get an accurate model out of your data alone): | Rank | Feature Name | Importance| |—|—|—| | 1 | views_acc | 12%| | 2 | views_1 | 11%| | 3 | ageRatioReviews_1 | 9% | | 4 | video_duration| 9% | | 5 | comments_1| 5%| | 6 | channel_uploads|5%| | 7 | ageRatioLikes_1 | 4%| | 8 | comments_acc | 4% | | 9 | channel_views| 4% | | 10 | comments_sentiment_compound |3%|</p>
</section>
<section id="viralcaster" class="level4">
<h4 class="anchored" data-anchor-id="viralcaster"><a href="https://github.com/jjbreen/ViralCaster">ViralCaster</a></h4>
<p><a href="https://github.com/jjbreen/ViralCaster/blob/master/TitleParser.py">TitleParser.py</a> analyses views along with words, getting the most “popular” word or word combinations. It has demo data. It generates “max” “min” “mean” views related to single word or word combinations.</p>
</section>
<section id="predictube" class="level4">
<h4 class="anchored" data-anchor-id="predictube"><a href="https://github.com/dubstack/Predictube">Predictube</a></h4>
<p><a href="https://github.com/dubstack/Predictube/blob/master/predictube/analyze/peak_detection/peak_detection.py">peak_detection.py</a> use daily view count to categorize and identify trends. “MonoIncr” might be our desired category.</p>
</section>
<section id="video-viralization-tool" class="level4">
<h4 class="anchored" data-anchor-id="video-viralization-tool"><a href="https://github.com/FilipePires98/VideoViralizationTool">Video Viralization Tool</a></h4>
<p>It uses relative infection ratio instead of absolute to predict the trend. By “information cascade” it means statistics can be used to predict future view counts. It considers individuals and viewers as nodes. It suggests different relationships between parameters in SIR model and data (likes, shares, comments, new subscribers, subscribers, length, quality, tag keywords, description keywords).</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>